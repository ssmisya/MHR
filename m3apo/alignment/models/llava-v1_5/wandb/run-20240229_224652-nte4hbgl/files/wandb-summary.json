{"train/loss": 0.6931, "train/learning_rate": 1.1433926897844423e-07, "train/rewards/chosen": -0.00793690700083971, "train/rewards/rejected": -0.00793690700083971, "train/rewards/accuracies": 0.0, "train/rewards/margins": 0.0, "train/policy_logps/rejected": -280.83258056640625, "train/policy_logps/chosen": -280.83258056640625, "train/referece_logps/rejected": -280.7532043457031, "train/referece_logps/chosen": -280.7532043457031, "train/logits/rejected": -0.06954043358564377, "train/logits/chosen": -0.06954043358564377, "train/epoch": 0.0, "train/global_step": 61, "_timestamp": 1709219295.8244083, "_runtime": 1283.3869273662567, "_step": 60}