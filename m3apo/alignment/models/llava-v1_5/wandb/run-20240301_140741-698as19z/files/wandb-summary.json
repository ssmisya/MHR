{"train/loss": 0.3334, "train/learning_rate": 1.7709359539938396e-06, "train/rewards/chosen": -2.676474094390869, "train/rewards/rejected": -6.074628829956055, "train/rewards/accuracies": 0.8125, "train/rewards/margins": 3.3981549739837646, "train/policy_logps/rejected": -310.05377197265625, "train/policy_logps/chosen": -338.03558349609375, "train/referece_logps/rejected": -249.3074493408203, "train/referece_logps/chosen": -311.27081298828125, "train/logits/rejected": 0.005295522511005402, "train/logits/chosen": 0.13595767319202423, "train/epoch": 0.24, "train/global_step": 8644, "_timestamp": 1709453954.1405087, "_runtime": 180692.5440146923, "_step": 8643}