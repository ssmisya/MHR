{"train/loss": 0.3355, "train/learning_rate": 1.985974955297148e-06, "train/rewards/chosen": -1.3057565689086914, "train/rewards/rejected": -3.8148550987243652, "train/rewards/accuracies": 0.875, "train/rewards/margins": 2.509098529815674, "train/policy_logps/rejected": -393.26593017578125, "train/policy_logps/chosen": -301.38043212890625, "train/referece_logps/rejected": -355.11737060546875, "train/referece_logps/chosen": -288.3228454589844, "train/logits/rejected": -0.39415520429611206, "train/logits/chosen": -1.0679363012313843, "train/epoch": 0.08, "train/global_step": 2907, "_timestamp": 1709529180.450659, "_runtime": 60675.77048492432, "_step": 2906}