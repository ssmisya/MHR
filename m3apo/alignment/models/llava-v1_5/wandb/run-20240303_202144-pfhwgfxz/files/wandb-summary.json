{"train/loss": 0.354, "train/learning_rate": 1.9651152903074317e-06, "train/rewards/chosen": -1.2522656917572021, "train/rewards/rejected": -3.4377198219299316, "train/rewards/accuracies": 0.875, "train/rewards/margins": 2.1854543685913086, "train/policy_logps/rejected": -279.9129333496094, "train/policy_logps/chosen": -336.0260925292969, "train/referece_logps/rejected": -245.5357666015625, "train/referece_logps/chosen": -323.50341796875, "train/logits/rejected": -0.07970337569713593, "train/logits/chosen": -0.4932224154472351, "train/epoch": 0.11, "train/global_step": 3974, "_timestamp": 1709551432.9584885, "_runtime": 82928.27831435204, "_step": 3973}