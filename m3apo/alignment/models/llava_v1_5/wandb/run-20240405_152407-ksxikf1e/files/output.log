  0%|          | 0/16104 [00:00<?, ?it/s]/mnt/petrelfs/songmingyang/code/mm/MAPO/m3apo/alignment/trainer/llava_dpo_trainer.py:179: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/16104 [00:15<67:33:48, 15.10s/it]
{'loss': 0.6931, 'learning_rate': 4.132231404958678e-09, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'policy_logps/rejected': -347.6641540527344, 'policy_logps/chosen': -379.93817138671875, 'referece_logps/rejected': -347.6641540527344, 'referece_logps/chosen': -379.93817138671875, 'logits/rejected': 0.47267836332321167, 'logits/chosen': 0.3541351556777954, 'epoch': 0.0}


  0%|          | 3/16104 [00:48<75:33:49, 16.90s/it]
{'loss': 0.6951, 'learning_rate': 1.2396694214876033e-08, 'rewards/chosen': 0.0195146556943655, 'rewards/rejected': 0.0014436249621212482, 'rewards/accuracies': 0.5, 'rewards/margins': 0.01807103119790554, 'policy_logps/rejected': -324.79595947265625, 'policy_logps/chosen': -411.457275390625, 'referece_logps/rejected': -324.8104248046875, 'referece_logps/chosen': -411.65240478515625, 'logits/rejected': 0.15519683063030243, 'logits/chosen': 0.26168501377105713, 'epoch': 0.0}

  0%|          | 4/16104 [00:59<65:15:48, 14.59s/it]


  0%|          | 6/16104 [01:28<63:19:55, 14.16s/it]

  0%|          | 7/16104 [01:43<65:08:15, 14.57s/it]
{'loss': 0.6909, 'learning_rate': 2.8925619834710743e-08, 'rewards/chosen': 0.026088334619998932, 'rewards/rejected': -0.012589264661073685, 'rewards/accuracies': 0.875, 'rewards/margins': 0.03867759928107262, 'policy_logps/rejected': -299.0986633300781, 'policy_logps/chosen': -378.218994140625, 'referece_logps/rejected': -298.9727783203125, 'referece_logps/chosen': -378.47991943359375, 'logits/rejected': -0.5488215684890747, 'logits/chosen': -0.4897348880767822, 'epoch': 0.0}


  0%|          | 9/16104 [02:07<59:34:00, 13.32s/it]

  0%|          | 10/16104 [02:24<64:06:00, 14.34s/it]

  0%|          | 11/16104 [02:38<63:21:20, 14.17s/it]
{'loss': 0.6912, 'learning_rate': 4.545454545454545e-08, 'rewards/chosen': -0.005010413937270641, 'rewards/rejected': 0.009387589059770107, 'rewards/accuracies': 0.375, 'rewards/margins': -0.014398002997040749, 'policy_logps/rejected': -430.17852783203125, 'policy_logps/chosen': -565.0265502929688, 'referece_logps/rejected': -430.2724304199219, 'referece_logps/chosen': -564.9764404296875, 'logits/rejected': 0.18687447905540466, 'logits/chosen': 0.21007466316223145, 'epoch': 0.0}


  0%|          | 13/16104 [03:02<57:46:24, 12.93s/it]
{'loss': 0.6928, 'learning_rate': 5.3719008264462806e-08, 'rewards/chosen': 0.006201363168656826, 'rewards/rejected': -2.8228620067238808e-05, 'rewards/accuracies': 0.5, 'rewards/margins': 0.006229591555893421, 'policy_logps/rejected': -385.50665283203125, 'policy_logps/chosen': -399.65966796875, 'referece_logps/rejected': -385.50640869140625, 'referece_logps/chosen': -399.7217102050781, 'logits/rejected': -1.1650950908660889, 'logits/chosen': -1.0928369760513306, 'epoch': 0.0}


  0%|          | 15/16104 [03:42<73:27:44, 16.44s/it]
{'loss': 0.6969, 'learning_rate': 6.198347107438017e-08, 'rewards/chosen': -0.034580424427986145, 'rewards/rejected': -0.009522629901766777, 'rewards/accuracies': 0.125, 'rewards/margins': -0.02505779266357422, 'policy_logps/rejected': -322.7077331542969, 'policy_logps/chosen': -441.5775146484375, 'referece_logps/rejected': -322.6125183105469, 'referece_logps/chosen': -441.231689453125, 'logits/rejected': -0.7114010453224182, 'logits/chosen': -0.6760113835334778, 'epoch': 0.01}


  0%|          | 17/16104 [04:18<76:04:34, 17.02s/it]

  0%|          | 18/16104 [04:34<74:44:18, 16.73s/it]
{'loss': 0.6882, 'learning_rate': 7.438016528925619e-08, 'rewards/chosen': -0.0051412577740848064, 'rewards/rejected': -0.0035286671482026577, 'rewards/accuracies': 0.25, 'rewards/margins': -0.0016125908587127924, 'policy_logps/rejected': -301.90618896484375, 'policy_logps/chosen': -254.1787109375, 'referece_logps/rejected': -301.8708801269531, 'referece_logps/chosen': -254.12728881835938, 'logits/rejected': -0.2536427676677704, 'logits/chosen': 0.2047172337770462, 'epoch': 0.01}


  0%|          | 20/16104 [04:57<64:02:43, 14.33s/it]

  0%|          | 21/16104 [05:08<59:07:26, 13.23s/it]
{'loss': 0.6989, 'learning_rate': 8.677685950413223e-08, 'rewards/chosen': -0.0017141364514827728, 'rewards/rejected': 0.0033381935209035873, 'rewards/accuracies': 0.625, 'rewards/margins': -0.005052329506725073, 'policy_logps/rejected': -298.89471435546875, 'policy_logps/chosen': -354.28814697265625, 'referece_logps/rejected': -298.9281005859375, 'referece_logps/chosen': -354.27105712890625, 'logits/rejected': -0.9036732912063599, 'logits/chosen': -0.8723427653312683, 'epoch': 0.01}


  0%|          | 23/16104 [05:40<65:07:35, 14.58s/it]
{'loss': 0.6966, 'learning_rate': 9.504132231404959e-08, 'rewards/chosen': 0.015223884955048561, 'rewards/rejected': 0.03292122110724449, 'rewards/accuracies': 0.375, 'rewards/margins': -0.01769733801484108, 'policy_logps/rejected': -307.99713134765625, 'policy_logps/chosen': -407.3422546386719, 'referece_logps/rejected': -308.3263244628906, 'referece_logps/chosen': -407.4945068359375, 'logits/rejected': -0.537614643573761, 'logits/chosen': -0.44113054871559143, 'epoch': 0.01}

  0%|          | 24/16104 [05:56<67:29:31, 15.11s/it]


  0%|          | 26/16104 [06:20<59:23:02, 13.30s/it]
{'loss': 0.7006, 'learning_rate': 1.0743801652892561e-07, 'rewards/chosen': -0.009583855047821999, 'rewards/rejected': -0.0011347774416208267, 'rewards/accuracies': 0.25, 'rewards/margins': -0.008449077606201172, 'policy_logps/rejected': -287.25982666015625, 'policy_logps/chosen': -349.10662841796875, 'referece_logps/rejected': -287.24847412109375, 'referece_logps/chosen': -349.01080322265625, 'logits/rejected': -0.8031367063522339, 'logits/chosen': -0.71314936876297, 'epoch': 0.01}

  0%|          | 27/16104 [06:30<55:42:14, 12.47s/it]

  0%|          | 28/16104 [06:43<55:31:41, 12.43s/it]

  0%|          | 29/16104 [07:03<66:12:45, 14.83s/it]

  0%|          | 30/16104 [07:15<61:56:25, 13.87s/it]


  0%|          | 32/16104 [07:48<68:11:52, 15.28s/it]
[2024-04-05 15:32:02,938] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6937, 'learning_rate': 1.3223140495867768e-07, 'rewards/chosen': -0.05339260771870613, 'rewards/rejected': -0.024935150519013405, 'rewards/accuracies': 0.5, 'rewards/margins': -0.02845745161175728, 'policy_logps/rejected': -458.60125732421875, 'policy_logps/chosen': -344.97747802734375, 'referece_logps/rejected': -458.3519287109375, 'referece_logps/chosen': -344.4435729980469, 'logits/rejected': -0.12152084708213806, 'logits/chosen': -0.015541791915893555, 'epoch': 0.01}


  0%|          | 34/16104 [08:14<62:40:01, 14.04s/it]
{'loss': 0.6974, 'learning_rate': 1.4049586776859503e-07, 'rewards/chosen': 0.012734223157167435, 'rewards/rejected': 0.00491151912137866, 'rewards/accuracies': 0.5, 'rewards/margins': 0.007822704501450062, 'policy_logps/rejected': -221.69175720214844, 'policy_logps/chosen': -245.74447631835938, 'referece_logps/rejected': -221.74087524414062, 'referece_logps/chosen': -245.871826171875, 'logits/rejected': -0.25821417570114136, 'logits/chosen': -0.22299078106880188, 'epoch': 0.01}

  0%|          | 35/16104 [08:29<64:25:06, 14.43s/it]


  0%|          | 37/16104 [09:00<66:16:19, 14.85s/it]

  0%|          | 38/16104 [09:15<66:01:14, 14.79s/it]
{'loss': 0.6908, 'learning_rate': 1.5702479338842976e-07, 'rewards/chosen': 0.012855147942900658, 'rewards/rejected': -0.006005097180604935, 'rewards/accuracies': 0.75, 'rewards/margins': 0.01886024698615074, 'policy_logps/rejected': -467.7106018066406, 'policy_logps/chosen': -639.8878173828125, 'referece_logps/rejected': -467.65057373046875, 'referece_logps/chosen': -640.016357421875, 'logits/rejected': 0.5563411712646484, 'logits/chosen': 0.5122538805007935, 'epoch': 0.01}

  0%|          | 39/16104 [09:29<65:07:43, 14.59s/it]


  0%|          | 41/16104 [10:08<75:58:11, 17.03s/it]
{'loss': 0.7003, 'learning_rate': 1.6942148760330577e-07, 'rewards/chosen': -0.017533304169774055, 'rewards/rejected': 0.038735583424568176, 'rewards/accuracies': 0.25, 'rewards/margins': -0.05626888573169708, 'policy_logps/rejected': -339.105224609375, 'policy_logps/chosen': -390.8269958496094, 'referece_logps/rejected': -339.49261474609375, 'referece_logps/chosen': -390.6516418457031, 'logits/rejected': -0.39934593439102173, 'logits/chosen': -0.5201223492622375, 'epoch': 0.02}


  0%|          | 43/16104 [10:36<68:04:16, 15.26s/it]
{'loss': 0.6905, 'learning_rate': 1.7768595041322312e-07, 'rewards/chosen': -0.028261948376893997, 'rewards/rejected': 0.017800619825720787, 'rewards/accuracies': 0.375, 'rewards/margins': -0.046062566339969635, 'policy_logps/rejected': -378.9692687988281, 'policy_logps/chosen': -349.8938293457031, 'referece_logps/rejected': -379.14727783203125, 'referece_logps/chosen': -349.6112060546875, 'logits/rejected': -0.07385420799255371, 'logits/chosen': -0.03556235879659653, 'epoch': 0.02}


  0%|          | 45/16104 [11:00<61:04:30, 13.69s/it]

  0%|          | 46/16104 [11:18<66:23:54, 14.89s/it]

  0%|          | 47/16104 [11:38<73:18:45, 16.44s/it]
{'loss': 0.6973, 'learning_rate': 1.9421487603305784e-07, 'rewards/chosen': -0.003166007809340954, 'rewards/rejected': 0.013865280896425247, 'rewards/accuracies': 0.375, 'rewards/margins': -0.017031289637088776, 'policy_logps/rejected': -256.5755310058594, 'policy_logps/chosen': -206.30078125, 'referece_logps/rejected': -256.71417236328125, 'referece_logps/chosen': -206.26910400390625, 'logits/rejected': -0.4676224887371063, 'logits/chosen': -0.41720283031463623, 'epoch': 0.02}

  0%|          | 48/16104 [12:01<82:10:07, 18.42s/it]

  0%|          | 49/16104 [12:20<82:31:36, 18.50s/it]

  0%|          | 50/16104 [12:41<86:47:37, 19.46s/it]


  0%|          | 52/16104 [13:16<79:35:36, 17.85s/it]
{'loss': 0.692, 'learning_rate': 2.1487603305785122e-07, 'rewards/chosen': -0.007901190780103207, 'rewards/rejected': -0.029774285852909088, 'rewards/accuracies': 0.5, 'rewards/margins': 0.021873094141483307, 'policy_logps/rejected': -487.2835693359375, 'policy_logps/chosen': -425.9371032714844, 'referece_logps/rejected': -486.9858703613281, 'referece_logps/chosen': -425.85809326171875, 'logits/rejected': -0.5159927010536194, 'logits/chosen': -0.39694568514823914, 'epoch': 0.02}


  0%|          | 54/16104 [13:54<82:59:25, 18.61s/it]
{'loss': 0.6905, 'learning_rate': 2.231404958677686e-07, 'rewards/chosen': 0.041090965270996094, 'rewards/rejected': -0.033600859344005585, 'rewards/accuracies': 0.625, 'rewards/margins': 0.07469182461500168, 'policy_logps/rejected': -292.6921081542969, 'policy_logps/chosen': -536.4998779296875, 'referece_logps/rejected': -292.3561096191406, 'referece_logps/chosen': -536.9107666015625, 'logits/rejected': 0.09650373458862305, 'logits/chosen': 0.10332122445106506, 'epoch': 0.02}
[2024-04-05 15:38:27,979] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  0%|          | 56/16104 [14:34<86:38:29, 19.44s/it]
{'loss': 0.6944, 'learning_rate': 2.3140495867768595e-07, 'rewards/chosen': 0.023218629881739616, 'rewards/rejected': -0.0010995861375704408, 'rewards/accuracies': 0.625, 'rewards/margins': 0.024318218231201172, 'policy_logps/rejected': -282.2508239746094, 'policy_logps/chosen': -471.44598388671875, 'referece_logps/rejected': -282.23980712890625, 'referece_logps/chosen': -471.6781921386719, 'logits/rejected': -0.7444769144058228, 'logits/chosen': -0.8199664950370789, 'epoch': 0.02}

  0%|          | 57/16104 [14:53<86:13:05, 19.34s/it]


  0%|          | 59/16104 [15:30<84:35:46, 18.98s/it]
{'loss': 0.7037, 'learning_rate': 2.43801652892562e-07, 'rewards/chosen': -0.022661015391349792, 'rewards/rejected': 0.0338624007999897, 'rewards/accuracies': 0.375, 'rewards/margins': -0.05652342364192009, 'policy_logps/rejected': -378.96136474609375, 'policy_logps/chosen': -328.0860290527344, 'referece_logps/rejected': -379.29998779296875, 'referece_logps/chosen': -327.85943603515625, 'logits/rejected': -0.04070926457643509, 'logits/chosen': 0.04458199441432953, 'epoch': 0.02}


  0%|          | 61/16104 [16:04<78:23:09, 17.59s/it]

  0%|          | 62/16104 [16:16<71:27:22, 16.04s/it]

  0%|          | 63/16104 [16:32<70:51:42, 15.90s/it]

  0%|          | 64/16104 [16:44<66:02:49, 14.82s/it]

  0%|          | 65/16104 [16:56<62:29:36, 14.03s/it]
{'loss': 0.6969, 'learning_rate': 2.6859504132231406e-07, 'rewards/chosen': 0.027260400354862213, 'rewards/rejected': 0.021544456481933594, 'rewards/accuracies': 0.5, 'rewards/margins': 0.00571594201028347, 'policy_logps/rejected': -340.9825134277344, 'policy_logps/chosen': -349.3990783691406, 'referece_logps/rejected': -341.19793701171875, 'referece_logps/chosen': -349.67169189453125, 'logits/rejected': -1.047860860824585, 'logits/chosen': -0.8170825242996216, 'epoch': 0.02}

  0%|          | 66/16104 [17:17<71:33:56, 16.06s/it]


  0%|          | 68/16104 [17:50<72:45:03, 16.33s/it]
{'loss': 0.6941, 'learning_rate': 2.8099173553719007e-07, 'rewards/chosen': 0.004545402713119984, 'rewards/rejected': -0.02082195319235325, 'rewards/accuracies': 0.75, 'rewards/margins': 0.025367356836795807, 'policy_logps/rejected': -501.24591064453125, 'policy_logps/chosen': -501.238525390625, 'referece_logps/rejected': -501.03765869140625, 'referece_logps/chosen': -501.2839660644531, 'logits/rejected': -1.3933082818984985, 'logits/chosen': -1.2184042930603027, 'epoch': 0.03}


  0%|          | 70/16104 [18:18<66:41:21, 14.97s/it]
{'loss': 0.6932, 'learning_rate': 2.892561983471074e-07, 'rewards/chosen': -0.014936685562133789, 'rewards/rejected': -0.006634235382080078, 'rewards/accuracies': 0.25, 'rewards/margins': -0.008302450180053711, 'policy_logps/rejected': -382.12335205078125, 'policy_logps/chosen': -443.27398681640625, 'referece_logps/rejected': -382.05706787109375, 'referece_logps/chosen': -443.1246337890625, 'logits/rejected': -0.28611865639686584, 'logits/chosen': -0.3297880291938782, 'epoch': 0.03}

  0%|          | 71/16104 [18:40<75:43:19, 17.00s/it]


  0%|          | 73/16104 [19:20<83:48:20, 18.82s/it]

  0%|          | 74/16104 [19:31<73:01:25, 16.40s/it]

  0%|          | 75/16104 [19:44<68:58:47, 15.49s/it]

  0%|          | 76/16104 [20:05<75:34:02, 16.97s/it]

  0%|          | 77/16104 [20:24<78:56:32, 17.73s/it]
{'loss': 0.698, 'learning_rate': 3.1818181818181815e-07, 'rewards/chosen': 0.006481361575424671, 'rewards/rejected': -0.009376239962875843, 'rewards/accuracies': 0.75, 'rewards/margins': 0.015857603400945663, 'policy_logps/rejected': -270.4651184082031, 'policy_logps/chosen': -440.4598083496094, 'referece_logps/rejected': -270.371337890625, 'referece_logps/chosen': -440.524658203125, 'logits/rejected': -1.4012356996536255, 'logits/chosen': -1.51719069480896, 'epoch': 0.03}


  0%|          | 79/16104 [21:07<88:08:23, 19.80s/it]
{'loss': 0.6887, 'learning_rate': 3.264462809917355e-07, 'rewards/chosen': 0.03387918323278427, 'rewards/rejected': -0.013988876715302467, 'rewards/accuracies': 0.875, 'rewards/margins': 0.04786805808544159, 'policy_logps/rejected': -216.81919860839844, 'policy_logps/chosen': -402.4106750488281, 'referece_logps/rejected': -216.67929077148438, 'referece_logps/chosen': -402.74945068359375, 'logits/rejected': -1.2497972249984741, 'logits/chosen': -1.300443410873413, 'epoch': 0.03}


  1%|          | 81/16104 [21:45<86:37:19, 19.46s/it]

  1%|          | 82/16104 [21:59<78:54:00, 17.73s/it]
{'loss': 0.6893, 'learning_rate': 3.3884297520661153e-07, 'rewards/chosen': -0.007837486453354359, 'rewards/rejected': 0.010554694570600986, 'rewards/accuracies': 0.5, 'rewards/margins': -0.018392181023955345, 'policy_logps/rejected': -237.1098175048828, 'policy_logps/chosen': -287.9249572753906, 'referece_logps/rejected': -237.2153778076172, 'referece_logps/chosen': -287.8465576171875, 'logits/rejected': -0.17856135964393616, 'logits/chosen': -0.23577019572257996, 'epoch': 0.03}
[2024-04-05 15:46:34,549] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 83/16104 [22:20<83:47:48, 18.83s/it]
[2024-04-05 15:46:52,109] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  1%|          | 85/16104 [22:55<80:16:03, 18.04s/it]
{'loss': 0.6951, 'learning_rate': 3.512396694214876e-07, 'rewards/chosen': 0.00312118511646986, 'rewards/rejected': 0.005189514718949795, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0020683296024799347, 'policy_logps/rejected': -426.73760986328125, 'policy_logps/chosen': -697.12353515625, 'referece_logps/rejected': -426.78948974609375, 'referece_logps/chosen': -697.1547241210938, 'logits/rejected': -0.631725549697876, 'logits/chosen': -0.49513986706733704, 'epoch': 0.03}


  1%|          | 87/16104 [23:19<66:24:37, 14.93s/it]

  1%|          | 88/16104 [23:40<75:21:36, 16.94s/it]

  1%|          | 89/16104 [23:55<71:57:02, 16.17s/it]

  1%|          | 90/16104 [24:09<69:21:39, 15.59s/it]
{'loss': 0.6911, 'learning_rate': 3.71900826446281e-07, 'rewards/chosen': 0.013117791153490543, 'rewards/rejected': -0.007720184978097677, 'rewards/accuracies': 0.75, 'rewards/margins': 0.020837973803281784, 'policy_logps/rejected': -316.3706970214844, 'policy_logps/chosen': -359.6737060546875, 'referece_logps/rejected': -316.2934875488281, 'referece_logps/chosen': -359.8048095703125, 'logits/rejected': -0.22393761575222015, 'logits/chosen': -0.30172136425971985, 'epoch': 0.03}

  1%|          | 91/16104 [24:30<76:34:05, 17.21s/it]

  1%|          | 92/16104 [24:45<73:48:39, 16.60s/it]
[2024-04-05 15:49:20,528] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 93/16104 [25:06<79:13:38, 17.81s/it]


  1%|          | 95/16104 [25:33<68:55:09, 15.50s/it]
{'loss': 0.6925, 'learning_rate': 3.9256198347107437e-07, 'rewards/chosen': -0.001583481440320611, 'rewards/rejected': -0.001233958639204502, 'rewards/accuracies': 0.5, 'rewards/margins': -0.00034952256828546524, 'policy_logps/rejected': -327.211181640625, 'policy_logps/chosen': -509.1217041015625, 'referece_logps/rejected': -327.1988220214844, 'referece_logps/chosen': -509.10589599609375, 'logits/rejected': -0.3874713182449341, 'logits/chosen': -0.49750974774360657, 'epoch': 0.04}

  1%|          | 96/16104 [25:54<76:39:50, 17.24s/it]

  1%|          | 97/16104 [26:13<79:47:39, 17.95s/it]

  1%|          | 98/16104 [26:37<86:41:03, 19.50s/it]

  1%|          | 99/16104 [27:00<91:59:25, 20.69s/it]


  1%|          | 101/16104 [27:31<81:18:27, 18.29s/it]

  1%|          | 102/16104 [27:43<73:14:23, 16.48s/it]

  1%|          | 103/16104 [27:55<67:27:24, 15.18s/it]

  1%|          | 104/16104 [28:15<73:30:42, 16.54s/it]
{'loss': 0.6993, 'learning_rate': 4.2975206611570245e-07, 'rewards/chosen': 0.019548654556274414, 'rewards/rejected': 0.03116474114358425, 'rewards/accuracies': 0.375, 'rewards/margins': -0.011616088449954987, 'policy_logps/rejected': -342.16375732421875, 'policy_logps/chosen': -352.8961181640625, 'referece_logps/rejected': -342.47540283203125, 'referece_logps/chosen': -353.09161376953125, 'logits/rejected': -0.5405881404876709, 'logits/chosen': -0.6845707893371582, 'epoch': 0.04}

  1%|          | 105/16104 [28:27<67:13:25, 15.13s/it]


  1%|          | 107/16104 [29:03<75:11:04, 16.92s/it]

  1%|          | 108/16104 [29:21<77:09:33, 17.37s/it]

  1%|          | 109/16104 [29:33<69:45:43, 15.70s/it]
{'loss': 0.69, 'learning_rate': 4.5041322314049583e-07, 'rewards/chosen': 0.017299938946962357, 'rewards/rejected': 0.003020238596946001, 'rewards/accuracies': 0.625, 'rewards/margins': 0.014279701747000217, 'policy_logps/rejected': -171.9756317138672, 'policy_logps/chosen': -195.9060516357422, 'referece_logps/rejected': -172.0058135986328, 'referece_logps/chosen': -196.0790557861328, 'logits/rejected': -0.2512326240539551, 'logits/chosen': -0.08910199999809265, 'epoch': 0.04}

  1%|          | 110/16104 [29:44<63:50:52, 14.37s/it]

  1%|          | 111/16104 [30:03<69:10:23, 15.57s/it]

  1%|          | 112/16104 [30:21<72:14:12, 16.26s/it]


  1%|          | 114/16104 [30:47<66:35:51, 14.99s/it]
{'loss': 0.6962, 'learning_rate': 4.710743801652892e-07, 'rewards/chosen': 0.01622791402041912, 'rewards/rejected': -0.013337518088519573, 'rewards/accuracies': 0.75, 'rewards/margins': 0.02956542931497097, 'policy_logps/rejected': -385.3457336425781, 'policy_logps/chosen': -302.462158203125, 'referece_logps/rejected': -385.21234130859375, 'referece_logps/chosen': -302.6244201660156, 'logits/rejected': -1.378653645515442, 'logits/chosen': -1.5375224351882935, 'epoch': 0.04}


  1%|          | 116/16104 [31:29<80:54:30, 18.22s/it]
{'loss': 0.6854, 'learning_rate': 4.793388429752066e-07, 'rewards/chosen': -0.06361732631921768, 'rewards/rejected': -0.023122599348425865, 'rewards/accuracies': 0.375, 'rewards/margins': -0.040494728833436966, 'policy_logps/rejected': -405.8614501953125, 'policy_logps/chosen': -409.7261657714844, 'referece_logps/rejected': -405.6302490234375, 'referece_logps/chosen': -409.0899658203125, 'logits/rejected': 0.5671951174736023, 'logits/chosen': 0.5807844400405884, 'epoch': 0.04}

  1%|          | 117/16104 [31:46<79:21:01, 17.87s/it]

  1%|          | 118/16104 [32:00<73:39:02, 16.59s/it]


  1%|          | 120/16104 [32:33<73:54:51, 16.65s/it]

  1%|          | 121/16104 [32:55<80:38:33, 18.16s/it]

  1%|          | 122/16104 [33:16<83:41:47, 18.85s/it]
{'loss': 0.6794, 'learning_rate': 5.041322314049586e-07, 'rewards/chosen': 0.009616279974579811, 'rewards/rejected': 0.0008419044315814972, 'rewards/accuracies': 0.625, 'rewards/margins': 0.008774375542998314, 'policy_logps/rejected': -329.63018798828125, 'policy_logps/chosen': -386.83599853515625, 'referece_logps/rejected': -329.6385803222656, 'referece_logps/chosen': -386.9321594238281, 'logits/rejected': -0.9991878867149353, 'logits/chosen': -1.0889546871185303, 'epoch': 0.05}

  1%|          | 123/16104 [33:28<74:58:07, 16.89s/it]

  1%|          | 124/16104 [33:50<81:51:05, 18.44s/it]

  1%|          | 125/16104 [34:06<78:36:17, 17.71s/it]

  1%|          | 126/16104 [34:27<82:29:52, 18.59s/it]

  1%|          | 127/16104 [34:46<83:55:59, 18.91s/it]

  1%|          | 128/16104 [35:07<86:27:33, 19.48s/it]

  1%|          | 129/16104 [35:29<89:21:33, 20.14s/it]

  1%|          | 130/16104 [35:51<92:19:07, 20.81s/it]


  1%|          | 132/16104 [36:24<80:50:39, 18.22s/it]
{'loss': 0.6884, 'learning_rate': 5.454545454545454e-07, 'rewards/chosen': -0.0018520355224609375, 'rewards/rejected': 0.017432596534490585, 'rewards/accuracies': 0.5, 'rewards/margins': -0.019284630194306374, 'policy_logps/rejected': -415.5065612792969, 'policy_logps/chosen': -367.67279052734375, 'referece_logps/rejected': -415.680908203125, 'referece_logps/chosen': -367.6542663574219, 'logits/rejected': -1.7760355472564697, 'logits/chosen': -1.7783823013305664, 'epoch': 0.05}

  1%|          | 133/16104 [36:45<84:49:22, 19.12s/it]


  1%|          | 135/16104 [37:20<81:40:25, 18.41s/it]
{'loss': 0.6946, 'learning_rate': 5.578512396694215e-07, 'rewards/chosen': -0.016730118542909622, 'rewards/rejected': 0.014419554732739925, 'rewards/accuracies': 0.25, 'rewards/margins': -0.03114967606961727, 'policy_logps/rejected': -416.1839599609375, 'policy_logps/chosen': -365.05816650390625, 'referece_logps/rejected': -416.328125, 'referece_logps/chosen': -364.890869140625, 'logits/rejected': -0.39913830161094666, 'logits/chosen': -0.29613032937049866, 'epoch': 0.05}

  1%|          | 136/16104 [37:32<73:47:57, 16.64s/it]

  1%|          | 137/16104 [37:48<73:17:04, 16.52s/it]


  1%|          | 139/16104 [38:24<75:55:07, 17.12s/it]
{'loss': 0.6903, 'learning_rate': 5.743801652892561e-07, 'rewards/chosen': 0.03386335074901581, 'rewards/rejected': -0.02701711654663086, 'rewards/accuracies': 1.0, 'rewards/margins': 0.060880471020936966, 'policy_logps/rejected': -224.4644012451172, 'policy_logps/chosen': -347.9543762207031, 'referece_logps/rejected': -224.19424438476562, 'referece_logps/chosen': -348.2929992675781, 'logits/rejected': -0.2067764699459076, 'logits/chosen': -0.3258071541786194, 'epoch': 0.05}

  1%|          | 140/16104 [38:39<72:41:43, 16.39s/it]

  1%|          | 141/16104 [38:49<65:08:09, 14.69s/it]

  1%|          | 142/16104 [39:01<60:51:39, 13.73s/it]

  1%|          | 143/16104 [39:11<56:52:28, 12.83s/it]

  1%|          | 144/16104 [39:22<54:09:02, 12.21s/it]

  1%|          | 145/16104 [39:34<53:49:28, 12.14s/it]

  1%|          | 146/16104 [39:57<67:35:52, 15.25s/it]

  1%|          | 147/16104 [40:18<74:59:26, 16.92s/it]

  1%|          | 148/16104 [40:33<73:37:03, 16.61s/it]

  1%|          | 149/16104 [40:46<68:11:30, 15.39s/it]

  1%|          | 150/16104 [41:01<68:00:19, 15.35s/it]

  1%|          | 151/16104 [41:21<73:54:37, 16.68s/it]

  1%|          | 152/16104 [41:38<73:48:13, 16.66s/it]

  1%|          | 153/16104 [41:51<69:21:58, 15.66s/it]

  1%|          | 154/16104 [42:13<77:20:41, 17.46s/it]

  1%|          | 155/16104 [42:26<71:28:53, 16.13s/it]

  1%|          | 156/16104 [42:37<65:19:57, 14.75s/it]

  1%|          | 157/16104 [42:58<73:13:52, 16.53s/it]

  1%|          | 158/16104 [43:09<66:22:27, 14.98s/it]

  1%|          | 159/16104 [43:29<73:10:07, 16.52s/it]

  1%|          | 160/16104 [43:51<80:35:13, 18.20s/it]

  1%|          | 161/16104 [44:08<78:50:10, 17.80s/it]

  1%|          | 162/16104 [44:24<76:02:59, 17.17s/it]

  1%|          | 163/16104 [44:45<80:28:23, 18.17s/it]

  1%|          | 164/16104 [45:02<79:13:09, 17.89s/it]

  1%|          | 165/16104 [45:14<71:18:54, 16.11s/it]

  1%|          | 166/16104 [45:30<71:46:09, 16.21s/it]

  1%|          | 167/16104 [45:52<79:14:37, 17.90s/it]

  1%|          | 168/16104 [46:06<74:29:29, 16.83s/it]

  1%|          | 169/16104 [46:20<69:39:04, 15.74s/it]

  1%|          | 170/16104 [46:33<67:07:54, 15.17s/it]

  1%|          | 171/16104 [46:44<61:36:45, 13.92s/it]

  1%|          | 172/16104 [46:58<61:36:22, 13.92s/it]

  1%|          | 173/16104 [47:19<70:57:28, 16.03s/it]

  1%|          | 174/16104 [47:32<66:41:58, 15.07s/it]

  1%|          | 175/16104 [47:47<66:08:38, 14.95s/it]

  1%|          | 176/16104 [47:57<60:27:10, 13.66s/it]

  1%|          | 177/16104 [48:08<56:49:48, 12.85s/it]

  1%|          | 178/16104 [48:19<53:49:39, 12.17s/it]

  1%|          | 179/16104 [48:30<51:56:31, 11.74s/it]

  1%|          | 180/16104 [48:42<53:08:53, 12.02s/it]

  1%|          | 181/16104 [49:00<60:14:53, 13.62s/it]

  1%|          | 182/16104 [49:18<66:44:05, 15.09s/it]

  1%|          | 183/16104 [49:37<72:14:36, 16.34s/it]

  1%|          | 184/16104 [49:55<73:50:17, 16.70s/it]

  1%|          | 185/16104 [50:06<66:04:36, 14.94s/it]

  1%|          | 186/16104 [50:17<60:26:04, 13.67s/it]

  1%|          | 187/16104 [50:30<60:28:53, 13.68s/it]

  1%|          | 188/16104 [50:47<64:56:49, 14.69s/it]

  1%|          | 189/16104 [51:01<64:16:37, 14.54s/it]

  1%|          | 190/16104 [51:21<70:13:39, 15.89s/it]

  1%|          | 191/16104 [51:37<71:03:11, 16.07s/it]

  1%|          | 192/16104 [51:54<72:22:50, 16.38s/it]

  1%|          | 193/16104 [52:10<71:46:01, 16.24s/it]
[2024-04-05 16:16:46,979] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 194/16104 [52:32<79:49:32, 18.06s/it]
[2024-04-05 16:17:01,780] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 195/16104 [52:47<75:29:48, 17.08s/it]

  1%|          | 196/16104 [53:05<76:31:25, 17.32s/it]

  1%|          | 197/16104 [53:27<82:05:04, 18.58s/it]

  1%|          | 198/16104 [53:47<84:33:53, 19.14s/it]
[2024-04-05 16:18:25,076] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 199/16104 [54:10<90:17:42, 20.44s/it]
[2024-04-05 16:18:44,535] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 200/16104 [54:30<88:59:29, 20.14s/it]
[2024-04-05 16:19:07,208] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 201/16104 [54:53<92:20:15, 20.90s/it]

  1%|▏         | 202/16104 [55:09<86:23:52, 19.56s/it]

  1%|▏         | 203/16104 [55:23<79:39:08, 18.03s/it]
[2024-04-05 16:20:00,164] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 204/16104 [55:46<84:58:59, 19.24s/it]
[2024-04-05 16:20:17,090] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 205/16104 [56:02<81:54:27, 18.55s/it]

  1%|▏         | 206/16104 [56:17<76:12:53, 17.26s/it]

  1%|▏         | 207/16104 [56:30<71:01:37, 16.08s/it]

  1%|▏         | 208/16104 [56:43<66:19:50, 15.02s/it]

  1%|▏         | 209/16104 [56:57<65:29:21, 14.83s/it]

  1%|▏         | 210/16104 [57:12<65:07:40, 14.75s/it]

  1%|▏         | 211/16104 [57:25<62:57:18, 14.26s/it]
[2024-04-05 16:22:00,813] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 212/16104 [57:46<72:33:25, 16.44s/it]
[2024-04-05 16:22:12,637] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 213/16104 [57:58<66:26:59, 15.05s/it]

  1%|▏         | 214/16104 [58:18<73:22:34, 16.62s/it]

  1%|▏         | 215/16104 [58:33<71:21:40, 16.17s/it]

  1%|▏         | 216/16104 [58:53<76:25:59, 17.32s/it]

  1%|▏         | 217/16104 [59:13<79:59:36, 18.13s/it]

  1%|▏         | 218/16104 [59:31<79:19:23, 17.98s/it]

  1%|▏         | 219/16104 [59:52<83:31:54, 18.93s/it]

  1%|▏         | 220/16104 [1:00:13<85:56:41, 19.48s/it]

  1%|▏         | 221/16104 [1:00:26<77:41:48, 17.61s/it]

  1%|▏         | 222/16104 [1:00:37<68:38:01, 15.56s/it]

  1%|▏         | 223/16104 [1:00:48<62:10:00, 14.09s/it]

  1%|▏         | 224/16104 [1:01:00<60:06:15, 13.63s/it]

  1%|▏         | 225/16104 [1:01:17<64:31:19, 14.63s/it]

  1%|▏         | 226/16104 [1:01:40<75:36:22, 17.14s/it]

  1%|▏         | 227/16104 [1:02:01<80:42:04, 18.30s/it]
[2024-04-05 16:26:32,096] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 228/16104 [1:02:17<78:03:40, 17.70s/it]

  1%|▏         | 229/16104 [1:02:33<74:51:46, 16.98s/it]

  1%|▏         | 230/16104 [1:02:48<72:10:36, 16.37s/it]

  1%|▏         | 231/16104 [1:03:00<66:30:01, 15.08s/it]

  1%|▏         | 232/16104 [1:03:12<62:31:29, 14.18s/it]

  1%|▏         | 233/16104 [1:03:27<63:30:57, 14.41s/it]

  1%|▏         | 234/16104 [1:03:47<71:39:52, 16.26s/it]

  1%|▏         | 235/16104 [1:04:06<74:41:44, 16.95s/it]

  1%|▏         | 236/16104 [1:04:19<69:36:15, 15.79s/it]

  1%|▏         | 237/16104 [1:04:41<77:11:42, 17.51s/it]

  1%|▏         | 238/16104 [1:04:58<77:34:26, 17.60s/it]

  1%|▏         | 239/16104 [1:05:13<73:23:42, 16.65s/it]

  1%|▏         | 240/16104 [1:05:34<78:46:35, 17.88s/it]

  1%|▏         | 241/16104 [1:05:53<80:42:24, 18.32s/it]

  2%|▏         | 242/16104 [1:06:09<77:26:59, 17.58s/it]

  2%|▏         | 243/16104 [1:06:27<78:41:00, 17.86s/it]


  2%|▏         | 245/16104 [1:07:01<76:33:30, 17.38s/it]
{'loss': 0.6715, 'learning_rate': 1.012396694214876e-06, 'rewards/chosen': -0.013699531555175781, 'rewards/rejected': -0.0529441311955452, 'rewards/accuracies': 0.625, 'rewards/margins': 0.03924460709095001, 'policy_logps/rejected': -269.1534118652344, 'policy_logps/chosen': -229.77639770507812, 'referece_logps/rejected': -268.62396240234375, 'referece_logps/chosen': -229.639404296875, 'logits/rejected': -0.7982140779495239, 'logits/chosen': -0.655014157295227, 'epoch': 0.09}
[2024-04-05 16:31:36,462] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  2%|▏         | 247/16104 [1:07:41<81:34:54, 18.52s/it]

  2%|▏         | 248/16104 [1:08:03<86:05:16, 19.55s/it]
[2024-04-05 16:32:17,306] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 249/16104 [1:08:15<76:47:27, 17.44s/it]

  2%|▏         | 250/16104 [1:08:26<68:37:03, 15.58s/it]

  2%|▏         | 251/16104 [1:08:48<76:03:23, 17.27s/it]

  2%|▏         | 252/16104 [1:08:59<68:49:09, 15.63s/it]

  2%|▏         | 253/16104 [1:09:22<78:26:10, 17.81s/it]
[2024-04-05 16:33:36,997] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 254/16104 [1:09:36<73:02:07, 16.59s/it]
[2024-04-05 16:33:50,727] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 255/16104 [1:09:47<66:07:44, 15.02s/it]

  2%|▏         | 256/16104 [1:10:00<62:59:46, 14.31s/it]

  2%|▏         | 257/16104 [1:10:16<65:45:28, 14.94s/it]

  2%|▏         | 258/16104 [1:10:39<75:10:57, 17.08s/it]
[2024-04-05 16:34:53,224] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 259/16104 [1:11:01<82:14:24, 18.69s/it]
[2024-04-05 16:35:15,653] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 260/16104 [1:11:17<78:20:18, 17.80s/it]
[2024-04-05 16:35:31,387] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 261/16104 [1:11:33<75:44:20, 17.21s/it]

  2%|▏         | 262/16104 [1:11:44<68:35:45, 15.59s/it]
{'loss': 0.6792, 'learning_rate': 1.0826446280991735e-06, 'rewards/chosen': -0.05684509128332138, 'rewards/rejected': -0.036538124084472656, 'rewards/accuracies': 0.375, 'rewards/margins': -0.020306972786784172, 'policy_logps/rejected': -378.7125244140625, 'policy_logps/chosen': -448.10809326171875, 'referece_logps/rejected': -378.34716796875, 'referece_logps/chosen': -447.5396423339844, 'logits/rejected': -0.8869150876998901, 'logits/chosen': -0.7723358869552612, 'epoch': 0.1}


  2%|▏         | 264/16104 [1:12:13<66:12:23, 15.05s/it]

  2%|▏         | 265/16104 [1:12:35<74:35:54, 16.96s/it]

  2%|▏         | 266/16104 [1:12:47<67:59:47, 15.46s/it]

  2%|▏         | 267/16104 [1:13:07<74:07:11, 16.85s/it]

  2%|▏         | 268/16104 [1:13:20<69:54:19, 15.89s/it]

  2%|▏         | 269/16104 [1:13:33<65:40:59, 14.93s/it]

  2%|▏         | 270/16104 [1:13:45<61:42:50, 14.03s/it]

  2%|▏         | 271/16104 [1:14:08<73:10:35, 16.64s/it]

  2%|▏         | 272/16104 [1:14:19<66:26:03, 15.11s/it]

  2%|▏         | 273/16104 [1:14:36<68:11:41, 15.51s/it]

  2%|▏         | 274/16104 [1:14:53<70:03:54, 15.93s/it]

  2%|▏         | 275/16104 [1:15:10<71:49:32, 16.34s/it]

  2%|▏         | 276/16104 [1:15:25<70:17:56, 15.99s/it]
[2024-04-05 16:39:39,649] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 277/16104 [1:15:45<75:01:11, 17.06s/it]

  2%|▏         | 278/16104 [1:16:03<77:07:13, 17.54s/it]

  2%|▏         | 279/16104 [1:16:15<69:30:22, 15.81s/it]

  2%|▏         | 280/16104 [1:16:36<75:52:27, 17.26s/it]

  2%|▏         | 281/16104 [1:16:58<82:29:04, 18.77s/it]
{'loss': 0.6898, 'learning_rate': 1.1611570247933884e-06, 'rewards/chosen': -0.012897873297333717, 'rewards/rejected': 0.04588642343878746, 'rewards/accuracies': 0.375, 'rewards/margins': -0.05878429487347603, 'policy_logps/rejected': -463.515869140625, 'policy_logps/chosen': -422.64788818359375, 'referece_logps/rejected': -463.9747009277344, 'referece_logps/chosen': -422.5189208984375, 'logits/rejected': -0.22886542975902557, 'logits/chosen': -0.08413203060626984, 'epoch': 0.1}


  2%|▏         | 283/16104 [1:17:38<86:16:58, 19.63s/it]

  2%|▏         | 284/16104 [1:17:58<86:34:26, 19.70s/it]
{'loss': 0.6924, 'learning_rate': 1.1735537190082645e-06, 'rewards/chosen': -0.04205475002527237, 'rewards/rejected': -0.018416978418827057, 'rewards/accuracies': 0.375, 'rewards/margins': -0.02363777346909046, 'policy_logps/rejected': -421.6099853515625, 'policy_logps/chosen': -423.3428649902344, 'referece_logps/rejected': -421.4258117675781, 'referece_logps/chosen': -422.92230224609375, 'logits/rejected': -0.2530873715877533, 'logits/chosen': -0.21162953972816467, 'epoch': 0.11}

  2%|▏         | 285/16104 [1:18:21<91:17:20, 20.78s/it]
[2024-04-05 16:42:57,176] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  2%|▏         | 287/16104 [1:19:03<92:06:57, 20.97s/it]

  2%|▏         | 288/16104 [1:19:24<91:49:16, 20.90s/it]
{'loss': 0.6567, 'learning_rate': 1.190082644628099e-06, 'rewards/chosen': -0.057602882385253906, 'rewards/rejected': -0.11261120438575745, 'rewards/accuracies': 0.625, 'rewards/margins': 0.05500831454992294, 'policy_logps/rejected': -346.18377685546875, 'policy_logps/chosen': -431.11822509765625, 'referece_logps/rejected': -345.05767822265625, 'referece_logps/chosen': -430.54217529296875, 'logits/rejected': -0.9043937921524048, 'logits/chosen': -0.840251088142395, 'epoch': 0.11}

  2%|▏         | 289/16104 [1:19:37<81:06:15, 18.46s/it]

  2%|▏         | 290/16104 [1:19:55<80:46:16, 18.39s/it]


  2%|▏         | 292/16104 [1:20:20<67:29:01, 15.36s/it]

  2%|▏         | 293/16104 [1:20:31<62:29:41, 14.23s/it]
{'loss': 0.6705, 'learning_rate': 1.2107438016528926e-06, 'rewards/chosen': -0.029294205829501152, 'rewards/rejected': -0.16671447455883026, 'rewards/accuracies': 0.75, 'rewards/margins': 0.13742028176784515, 'policy_logps/rejected': -422.6510009765625, 'policy_logps/chosen': -577.7650146484375, 'referece_logps/rejected': -420.9838562011719, 'referece_logps/chosen': -577.47216796875, 'logits/rejected': 0.1789671629667282, 'logits/chosen': -0.019210562109947205, 'epoch': 0.11}


  2%|▏         | 295/16104 [1:21:06<68:01:14, 15.49s/it]

  2%|▏         | 296/16104 [1:21:22<68:52:05, 15.68s/it]

  2%|▏         | 297/16104 [1:21:40<71:44:44, 16.34s/it]

  2%|▏         | 298/16104 [1:21:59<74:37:26, 17.00s/it]

  2%|▏         | 299/16104 [1:22:14<72:31:19, 16.52s/it]

  2%|▏         | 300/16104 [1:22:38<82:18:08, 18.75s/it]
[2024-04-05 16:46:52,642] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 301/16104 [1:22:50<72:46:01, 16.58s/it]

  2%|▏         | 302/16104 [1:23:12<80:40:17, 18.38s/it]
{'loss': 0.6747, 'learning_rate': 1.2479338842975206e-06, 'rewards/chosen': -0.08788556605577469, 'rewards/rejected': -0.23025932908058167, 'rewards/accuracies': 0.875, 'rewards/margins': 0.14237375557422638, 'policy_logps/rejected': -277.77392578125, 'policy_logps/chosen': -436.723388671875, 'referece_logps/rejected': -275.4713134765625, 'referece_logps/chosen': -435.84454345703125, 'logits/rejected': -0.7576819062232971, 'logits/chosen': -0.8002800941467285, 'epoch': 0.11}

  2%|▏         | 303/16104 [1:23:25<73:10:57, 16.67s/it]

  2%|▏         | 304/16104 [1:23:39<70:15:07, 16.01s/it]


  2%|▏         | 306/16104 [1:24:20<80:51:03, 18.42s/it]

  2%|▏         | 307/16104 [1:24:42<84:51:24, 19.34s/it]
{'loss': 0.6621, 'learning_rate': 1.2685950413223142e-06, 'rewards/chosen': 0.010201072320342064, 'rewards/rejected': -0.08434620499610901, 'rewards/accuracies': 0.875, 'rewards/margins': 0.09454727172851562, 'policy_logps/rejected': -401.3734436035156, 'policy_logps/chosen': -443.8331604003906, 'referece_logps/rejected': -400.52996826171875, 'referece_logps/chosen': -443.9352111816406, 'logits/rejected': -1.096331238746643, 'logits/chosen': -1.0493965148925781, 'epoch': 0.11}
[2024-04-05 16:49:20,045] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  2%|▏         | 309/16104 [1:25:24<87:24:31, 19.92s/it]
{'loss': 0.6709, 'learning_rate': 1.2768595041322314e-06, 'rewards/chosen': -0.09636125713586807, 'rewards/rejected': -0.13965249061584473, 'rewards/accuracies': 0.5, 'rewards/margins': 0.04329123720526695, 'policy_logps/rejected': -220.00706481933594, 'policy_logps/chosen': -279.3852844238281, 'referece_logps/rejected': -218.61056518554688, 'referece_logps/chosen': -278.42169189453125, 'logits/rejected': -0.05055009573698044, 'logits/chosen': -0.05507087707519531, 'epoch': 0.12}


  2%|▏         | 311/16104 [1:25:55<77:40:35, 17.71s/it]
{'loss': 0.6755, 'learning_rate': 1.2851239669421487e-06, 'rewards/chosen': -0.01881704106926918, 'rewards/rejected': -0.1839078962802887, 'rewards/accuracies': 0.75, 'rewards/margins': 0.16509085893630981, 'policy_logps/rejected': -302.20928955078125, 'policy_logps/chosen': -423.1595764160156, 'referece_logps/rejected': -300.3702087402344, 'referece_logps/chosen': -422.9714050292969, 'logits/rejected': 0.1548805832862854, 'logits/chosen': -0.11887987703084946, 'epoch': 0.12}

  2%|▏         | 312/16104 [1:26:13<78:34:26, 17.91s/it]


  2%|▏         | 314/16104 [1:26:40<68:28:40, 15.61s/it]
{'loss': 0.6655, 'learning_rate': 1.2975206611570246e-06, 'rewards/chosen': -0.02054290659725666, 'rewards/rejected': -0.11393938213586807, 'rewards/accuracies': 0.625, 'rewards/margins': 0.09339647740125656, 'policy_logps/rejected': -265.4339904785156, 'policy_logps/chosen': -522.079345703125, 'referece_logps/rejected': -264.2945861816406, 'referece_logps/chosen': -521.8739013671875, 'logits/rejected': -0.251271516084671, 'logits/chosen': -0.00564836710691452, 'epoch': 0.12}


  2%|▏         | 316/16104 [1:27:12<69:19:30, 15.81s/it]
{'loss': 0.6506, 'learning_rate': 1.305785123966942e-06, 'rewards/chosen': 0.0007338523864746094, 'rewards/rejected': -0.08390560746192932, 'rewards/accuracies': 0.75, 'rewards/margins': 0.08463945984840393, 'policy_logps/rejected': -197.4020233154297, 'policy_logps/chosen': -398.38507080078125, 'referece_logps/rejected': -196.56295776367188, 'referece_logps/chosen': -398.3924255371094, 'logits/rejected': -0.8602077960968018, 'logits/chosen': -0.6888957023620605, 'epoch': 0.12}


  2%|▏         | 318/16104 [1:27:55<83:12:57, 18.98s/it]
[2024-04-05 16:52:09,228] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 319/16104 [1:28:18<89:25:51, 20.40s/it]
{'loss': 0.6427, 'learning_rate': 1.318181818181818e-06, 'rewards/chosen': -0.05333786457777023, 'rewards/rejected': -0.12844648957252502, 'rewards/accuracies': 0.625, 'rewards/margins': 0.07510862499475479, 'policy_logps/rejected': -266.3360595703125, 'policy_logps/chosen': -356.9112548828125, 'referece_logps/rejected': -265.05157470703125, 'referece_logps/chosen': -356.37786865234375, 'logits/rejected': -0.3925166428089142, 'logits/chosen': -0.36905568838119507, 'epoch': 0.12}


  2%|▏         | 321/16104 [1:28:56<85:22:38, 19.47s/it]

  2%|▏         | 322/16104 [1:29:13<81:28:51, 18.59s/it]

  2%|▏         | 323/16104 [1:29:34<84:52:20, 19.36s/it]
[2024-04-05 16:53:48,622] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 324/16104 [1:29:47<76:18:34, 17.41s/it]

  2%|▏         | 325/16104 [1:30:07<79:52:37, 18.22s/it]
{'loss': 0.6456, 'learning_rate': 1.3429752066115702e-06, 'rewards/chosen': -0.05935211479663849, 'rewards/rejected': -0.08722458779811859, 'rewards/accuracies': 0.5, 'rewards/margins': 0.027872463688254356, 'policy_logps/rejected': -298.34552001953125, 'policy_logps/chosen': -366.3436584472656, 'referece_logps/rejected': -297.4732666015625, 'referece_logps/chosen': -365.7500915527344, 'logits/rejected': -1.6106313467025757, 'logits/chosen': -1.7714496850967407, 'epoch': 0.12}


  2%|▏         | 327/16104 [1:30:42<77:23:20, 17.66s/it]
{'loss': 0.6653, 'learning_rate': 1.3512396694214875e-06, 'rewards/chosen': -0.10249443352222443, 'rewards/rejected': -0.13041363656520844, 'rewards/accuracies': 0.625, 'rewards/margins': 0.027919195592403412, 'policy_logps/rejected': -336.2394104003906, 'policy_logps/chosen': -383.82476806640625, 'referece_logps/rejected': -334.9352722167969, 'referece_logps/chosen': -382.7998352050781, 'logits/rejected': -0.693430483341217, 'logits/chosen': -0.6815571784973145, 'epoch': 0.12}


  2%|▏         | 329/16104 [1:31:15<73:14:30, 16.71s/it]

  2%|▏         | 330/16104 [1:31:32<74:05:26, 16.91s/it]

  2%|▏         | 331/16104 [1:31:52<77:44:59, 17.75s/it]
{'loss': 0.6486, 'learning_rate': 1.3677685950413222e-06, 'rewards/chosen': -0.04634971544146538, 'rewards/rejected': -0.10264625400304794, 'rewards/accuracies': 0.625, 'rewards/margins': 0.05629653483629227, 'policy_logps/rejected': -428.4981994628906, 'policy_logps/chosen': -359.62152099609375, 'referece_logps/rejected': -427.47174072265625, 'referece_logps/chosen': -359.1580505371094, 'logits/rejected': -0.602653980255127, 'logits/chosen': -0.4501207768917084, 'epoch': 0.12}

  2%|▏         | 332/16104 [1:32:12<80:18:00, 18.33s/it]
[2024-04-05 16:56:42,616] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  2%|▏         | 334/16104 [1:32:47<78:42:32, 17.97s/it]

  2%|▏         | 335/16104 [1:33:07<81:29:27, 18.60s/it]

  2%|▏         | 336/16104 [1:33:29<86:15:11, 19.69s/it]
[2024-04-05 16:57:43,525] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 337/16104 [1:33:46<83:08:25, 18.98s/it]

  2%|▏         | 338/16104 [1:34:04<81:52:23, 18.69s/it]

  2%|▏         | 339/16104 [1:34:26<86:16:02, 19.70s/it]
[2024-04-05 16:58:40,918] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 340/16104 [1:34:48<88:49:43, 20.29s/it]

  2%|▏         | 341/16104 [1:35:07<86:43:39, 19.81s/it]

  2%|▏         | 342/16104 [1:35:29<90:27:03, 20.66s/it]

  2%|▏         | 343/16104 [1:35:51<92:11:30, 21.06s/it]
[2024-04-05 17:00:05,897] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 344/16104 [1:36:11<90:36:33, 20.70s/it]
{'loss': 0.6507, 'learning_rate': 1.421487603305785e-06, 'rewards/chosen': -0.01779184117913246, 'rewards/rejected': -0.2876083552837372, 'rewards/accuracies': 0.75, 'rewards/margins': 0.26981648802757263, 'policy_logps/rejected': -402.355712890625, 'policy_logps/chosen': -440.3781433105469, 'referece_logps/rejected': -399.4796447753906, 'referece_logps/chosen': -440.2001953125, 'logits/rejected': -0.5008562207221985, 'logits/chosen': -0.527668833732605, 'epoch': 0.13}


  2%|▏         | 346/16104 [1:36:43<80:00:11, 18.28s/it]

  2%|▏         | 347/16104 [1:37:01<79:52:28, 18.25s/it]
{'loss': 0.6239, 'learning_rate': 1.433884297520661e-06, 'rewards/chosen': -0.1958521008491516, 'rewards/rejected': -0.5010650753974915, 'rewards/accuracies': 0.875, 'rewards/margins': 0.30521294474601746, 'policy_logps/rejected': -418.25592041015625, 'policy_logps/chosen': -457.794677734375, 'referece_logps/rejected': -413.2452697753906, 'referece_logps/chosen': -455.8361511230469, 'logits/rejected': -0.48834601044654846, 'logits/chosen': -0.3225405514240265, 'epoch': 0.13}


  2%|▏         | 349/16104 [1:37:37<79:44:51, 18.22s/it]

  2%|▏         | 350/16104 [1:37:49<71:07:24, 16.25s/it]

  2%|▏         | 351/16104 [1:38:01<65:59:06, 15.08s/it]

  2%|▏         | 352/16104 [1:38:13<62:36:49, 14.31s/it]
{'loss': 0.6749, 'learning_rate': 1.4545454545454544e-06, 'rewards/chosen': 0.004791163839399815, 'rewards/rejected': -0.10529471933841705, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1100858747959137, 'policy_logps/rejected': -354.55853271484375, 'policy_logps/chosen': -377.4961853027344, 'referece_logps/rejected': -353.50555419921875, 'referece_logps/chosen': -377.5440979003906, 'logits/rejected': -0.1527472734451294, 'logits/chosen': -0.20393185317516327, 'epoch': 0.13}


  2%|▏         | 354/16104 [1:38:51<72:52:07, 16.66s/it]
{'loss': 0.6705, 'learning_rate': 1.462809917355372e-06, 'rewards/chosen': -0.1403791457414627, 'rewards/rejected': -0.23914414644241333, 'rewards/accuracies': 0.75, 'rewards/margins': 0.09876500070095062, 'policy_logps/rejected': -300.1849365234375, 'policy_logps/chosen': -339.24688720703125, 'referece_logps/rejected': -297.7934875488281, 'referece_logps/chosen': -337.8431091308594, 'logits/rejected': -0.8172168135643005, 'logits/chosen': -0.778076171875, 'epoch': 0.13}


  2%|▏         | 356/16104 [1:39:23<70:24:06, 16.09s/it]

  2%|▏         | 357/16104 [1:39:39<69:55:13, 15.98s/it]
[2024-04-05 17:03:53,316] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6088, 'learning_rate': 1.475206611570248e-06, 'rewards/chosen': -0.27093562483787537, 'rewards/rejected': -0.5328952670097351, 'rewards/accuracies': 0.875, 'rewards/margins': 0.26195967197418213, 'policy_logps/rejected': -415.3359069824219, 'policy_logps/chosen': -332.8350830078125, 'referece_logps/rejected': -410.0069885253906, 'referece_logps/chosen': -330.125732421875, 'logits/rejected': 0.39037904143333435, 'logits/chosen': 0.3118523061275482, 'epoch': 0.13}


  2%|▏         | 359/16104 [1:40:21<80:21:42, 18.37s/it]
[2024-04-05 17:04:35,476] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 360/16104 [1:40:47<90:14:52, 20.64s/it]
[2024-04-05 17:05:01,389] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6706, 'learning_rate': 1.487603305785124e-06, 'rewards/chosen': -0.20046329498291016, 'rewards/rejected': -0.2812480032444, 'rewards/accuracies': 0.75, 'rewards/margins': 0.08078470081090927, 'policy_logps/rejected': -398.4992980957031, 'policy_logps/chosen': -400.7823181152344, 'referece_logps/rejected': -395.68682861328125, 'referece_logps/chosen': -398.77764892578125, 'logits/rejected': 0.049105480313301086, 'logits/chosen': 0.1460723578929901, 'epoch': 0.13}
[2024-04-05 17:05:23,097] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  2%|▏         | 362/16104 [1:41:29<90:47:55, 20.76s/it]

  2%|▏         | 363/16104 [1:41:41<80:12:55, 18.35s/it]

  2%|▏         | 364/16104 [1:42:03<84:59:30, 19.44s/it]
[2024-04-05 17:06:18,103] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 365/16104 [1:42:18<78:12:18, 17.89s/it]
[2024-04-05 17:06:32,371] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6431, 'learning_rate': 1.5082644628099173e-06, 'rewards/chosen': -0.14302672445774078, 'rewards/rejected': -0.28916770219802856, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1461409628391266, 'policy_logps/rejected': -505.01495361328125, 'policy_logps/chosen': -483.49072265625, 'referece_logps/rejected': -502.123291015625, 'referece_logps/chosen': -482.0604553222656, 'logits/rejected': -0.1579141914844513, 'logits/chosen': 0.017428390681743622, 'epoch': 0.14}


  2%|▏         | 367/16104 [1:42:58<82:40:08, 18.91s/it]

  2%|▏         | 368/16104 [1:43:13<78:03:46, 17.86s/it]

  2%|▏         | 369/16104 [1:43:24<68:40:18, 15.71s/it]

  2%|▏         | 370/16104 [1:43:41<70:55:36, 16.23s/it]

  2%|▏         | 371/16104 [1:44:02<76:39:04, 17.54s/it]

  2%|▏         | 372/16104 [1:44:23<81:30:21, 18.65s/it]

  2%|▏         | 373/16104 [1:44:37<75:32:09, 17.29s/it]

  2%|▏         | 374/16104 [1:44:50<69:46:36, 15.97s/it]

  2%|▏         | 375/16104 [1:45:01<63:11:33, 14.46s/it]

  2%|▏         | 376/16104 [1:45:22<72:15:35, 16.54s/it]

  2%|▏         | 377/16104 [1:45:33<64:39:19, 14.80s/it]
{'loss': 0.6685, 'learning_rate': 1.5578512396694213e-06, 'rewards/chosen': -0.1422114372253418, 'rewards/rejected': -0.22658061981201172, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08436919748783112, 'policy_logps/rejected': -283.34405517578125, 'policy_logps/chosen': -324.2763366699219, 'referece_logps/rejected': -281.0782470703125, 'referece_logps/chosen': -322.85418701171875, 'logits/rejected': 0.2599998116493225, 'logits/chosen': 0.17190508544445038, 'epoch': 0.14}

  2%|▏         | 378/16104 [1:45:51<68:20:26, 15.64s/it]


  2%|▏         | 380/16104 [1:46:19<64:22:46, 14.74s/it]

  2%|▏         | 381/16104 [1:46:37<68:37:10, 15.71s/it]

  2%|▏         | 382/16104 [1:46:51<66:06:11, 15.14s/it]

  2%|▏         | 383/16104 [1:47:09<70:24:58, 16.12s/it]

  2%|▏         | 384/16104 [1:47:20<63:25:39, 14.53s/it]

  2%|▏         | 385/16104 [1:47:37<65:53:46, 15.09s/it]

  2%|▏         | 386/16104 [1:47:56<70:59:31, 16.26s/it]

  2%|▏         | 387/16104 [1:48:14<73:33:44, 16.85s/it]

  2%|▏         | 388/16104 [1:48:32<74:41:37, 17.11s/it]

  2%|▏         | 389/16104 [1:48:53<80:12:16, 18.37s/it]

  2%|▏         | 390/16104 [1:49:11<79:29:08, 18.21s/it]

  2%|▏         | 391/16104 [1:49:32<83:58:08, 19.24s/it]

  2%|▏         | 392/16104 [1:49:44<74:13:01, 17.00s/it]

  2%|▏         | 393/16104 [1:49:55<65:56:59, 15.11s/it]

  2%|▏         | 394/16104 [1:50:09<64:15:59, 14.73s/it]

  2%|▏         | 395/16104 [1:50:20<60:03:27, 13.76s/it]

  2%|▏         | 396/16104 [1:50:42<71:18:33, 16.34s/it]

  2%|▏         | 397/16104 [1:50:58<70:25:53, 16.14s/it]

  2%|▏         | 398/16104 [1:51:22<80:40:19, 18.49s/it]

  2%|▏         | 399/16104 [1:51:40<80:27:19, 18.44s/it]

  2%|▏         | 400/16104 [1:52:00<81:45:53, 18.74s/it]

  2%|▏         | 401/16104 [1:52:11<71:06:47, 16.30s/it]
{'loss': 0.666, 'learning_rate': 1.6570247933884296e-06, 'rewards/chosen': -0.2060760259628296, 'rewards/rejected': -0.1986987143754959, 'rewards/accuracies': 0.5, 'rewards/margins': -0.007377337664365768, 'policy_logps/rejected': -333.479736328125, 'policy_logps/chosen': -451.0350341796875, 'referece_logps/rejected': -331.49273681640625, 'referece_logps/chosen': -448.97430419921875, 'logits/rejected': 0.25681978464126587, 'logits/chosen': 0.22449009120464325, 'epoch': 0.15}


  3%|▎         | 403/16104 [1:52:43<71:54:51, 16.49s/it]

  3%|▎         | 404/16104 [1:52:58<70:34:16, 16.18s/it]
{'loss': 0.6771, 'learning_rate': 1.6694214876033058e-06, 'rewards/chosen': -0.32213878631591797, 'rewards/rejected': -0.3019520044326782, 'rewards/accuracies': 0.625, 'rewards/margins': -0.020186811685562134, 'policy_logps/rejected': -403.42657470703125, 'policy_logps/chosen': -317.7738342285156, 'referece_logps/rejected': -400.40704345703125, 'referece_logps/chosen': -314.5524597167969, 'logits/rejected': -0.5003125667572021, 'logits/chosen': -0.24566204845905304, 'epoch': 0.15}


  3%|▎         | 406/16104 [1:53:34<73:00:20, 16.74s/it]

  3%|▎         | 407/16104 [1:53:47<67:37:35, 15.51s/it]

  3%|▎         | 408/16104 [1:53:59<63:34:40, 14.58s/it]
{'loss': 0.6341, 'learning_rate': 1.6859504132231403e-06, 'rewards/chosen': -0.29239529371261597, 'rewards/rejected': -0.2815501391887665, 'rewards/accuracies': 0.5, 'rewards/margins': -0.010845188051462173, 'policy_logps/rejected': -296.2680358886719, 'policy_logps/chosen': -429.45306396484375, 'referece_logps/rejected': -293.4525146484375, 'referece_logps/chosen': -426.52911376953125, 'logits/rejected': -1.0301388502120972, 'logits/chosen': -0.9089851975440979, 'epoch': 0.15}


  3%|▎         | 410/16104 [1:54:38<73:07:09, 16.77s/it]
{'loss': 0.5961, 'learning_rate': 1.6942148760330578e-06, 'rewards/chosen': -0.11612281948328018, 'rewards/rejected': -0.38268718123435974, 'rewards/accuracies': 0.75, 'rewards/margins': 0.26656436920166016, 'policy_logps/rejected': -365.29766845703125, 'policy_logps/chosen': -436.54150390625, 'referece_logps/rejected': -361.4707946777344, 'referece_logps/chosen': -435.38031005859375, 'logits/rejected': -0.21588748693466187, 'logits/chosen': -0.20739713311195374, 'epoch': 0.15}

  3%|▎         | 411/16104 [1:54:52<68:51:47, 15.80s/it]


  3%|▎         | 413/16104 [1:55:36<82:24:50, 18.91s/it]
[2024-04-05 17:19:50,901] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6289, 'learning_rate': 1.7066115702479339e-06, 'rewards/chosen': -0.49341145157814026, 'rewards/rejected': -0.5128511786460876, 'rewards/accuracies': 0.625, 'rewards/margins': 0.019439689815044403, 'policy_logps/rejected': -603.220703125, 'policy_logps/chosen': -481.7652282714844, 'referece_logps/rejected': -598.0921630859375, 'referece_logps/chosen': -476.8310852050781, 'logits/rejected': -0.08325579762458801, 'logits/chosen': 0.22160768508911133, 'epoch': 0.15}
[2024-04-05 17:20:04,100] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  3%|▎         | 415/16104 [1:56:10<79:26:35, 18.23s/it]
{'loss': 0.6357, 'learning_rate': 1.7148760330578512e-06, 'rewards/chosen': -0.1785268634557724, 'rewards/rejected': -0.32855963706970215, 'rewards/accuracies': 0.75, 'rewards/margins': 0.15003274381160736, 'policy_logps/rejected': -257.16839599609375, 'policy_logps/chosen': -328.21417236328125, 'referece_logps/rejected': -253.88278198242188, 'referece_logps/chosen': -326.4289245605469, 'logits/rejected': -1.1491163969039917, 'logits/chosen': -0.9529029130935669, 'epoch': 0.15}


  3%|▎         | 417/16104 [1:56:43<75:14:15, 17.27s/it]

  3%|▎         | 418/16104 [1:56:54<67:22:24, 15.46s/it]
{'loss': 0.6797, 'learning_rate': 1.7272727272727273e-06, 'rewards/chosen': -0.3236227035522461, 'rewards/rejected': -0.5756983160972595, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2520756125450134, 'policy_logps/rejected': -604.6829223632812, 'policy_logps/chosen': -399.525634765625, 'referece_logps/rejected': -598.9259033203125, 'referece_logps/chosen': -396.2893981933594, 'logits/rejected': -0.44767674803733826, 'logits/chosen': -0.40143054723739624, 'epoch': 0.16}


  3%|▎         | 420/16104 [1:57:26<70:26:35, 16.17s/it]
[2024-04-05 17:21:40,932] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 421/16104 [1:57:45<73:50:18, 16.95s/it]
{'loss': 0.6224, 'learning_rate': 1.7396694214876034e-06, 'rewards/chosen': -0.36749956011772156, 'rewards/rejected': -0.37345412373542786, 'rewards/accuracies': 0.5, 'rewards/margins': 0.00595456175506115, 'policy_logps/rejected': -333.1212158203125, 'policy_logps/chosen': -318.0995178222656, 'referece_logps/rejected': -329.38665771484375, 'referece_logps/chosen': -314.4245300292969, 'logits/rejected': -0.22955048084259033, 'logits/chosen': 0.010288886725902557, 'epoch': 0.16}


  3%|▎         | 423/16104 [1:58:17<73:19:56, 16.84s/it]
{'loss': 0.611, 'learning_rate': 1.7479338842975207e-06, 'rewards/chosen': -0.126146137714386, 'rewards/rejected': -0.48738202452659607, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3612358868122101, 'policy_logps/rejected': -430.3338317871094, 'policy_logps/chosen': -345.7296142578125, 'referece_logps/rejected': -425.4599914550781, 'referece_logps/chosen': -344.4681396484375, 'logits/rejected': 0.1354193091392517, 'logits/chosen': 0.23611505329608917, 'epoch': 0.16}
[2024-04-05 17:22:52,476] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  3%|▎         | 425/16104 [1:58:50<70:56:51, 16.29s/it]

  3%|▎         | 426/16104 [1:59:03<66:15:45, 15.22s/it]

  3%|▎         | 427/16104 [1:59:19<67:30:26, 15.50s/it]
{'loss': 0.6181, 'learning_rate': 1.7644628099173552e-06, 'rewards/chosen': -0.21740439534187317, 'rewards/rejected': -0.38327282667160034, 'rewards/accuracies': 0.625, 'rewards/margins': 0.16586849093437195, 'policy_logps/rejected': -342.36871337890625, 'policy_logps/chosen': -481.8530578613281, 'referece_logps/rejected': -338.5359802246094, 'referece_logps/chosen': -479.6790466308594, 'logits/rejected': -0.8783835172653198, 'logits/chosen': -0.834185004234314, 'epoch': 0.16}

  3%|▎         | 428/16104 [1:59:32<63:44:01, 14.64s/it]

  3%|▎         | 429/16104 [1:59:54<73:30:26, 16.88s/it]


  3%|▎         | 431/16104 [2:00:31<76:52:12, 17.66s/it]
{'loss': 0.564, 'learning_rate': 1.78099173553719e-06, 'rewards/chosen': -0.2983091473579407, 'rewards/rejected': -0.8014848232269287, 'rewards/accuracies': 0.75, 'rewards/margins': 0.503175675868988, 'policy_logps/rejected': -461.4293518066406, 'policy_logps/chosen': -427.195068359375, 'referece_logps/rejected': -453.41448974609375, 'referece_logps/chosen': -424.21197509765625, 'logits/rejected': -0.9934526085853577, 'logits/chosen': -0.745713472366333, 'epoch': 0.16}


  3%|▎         | 433/16104 [2:01:02<70:26:00, 16.18s/it]
{'loss': 0.6679, 'learning_rate': 1.7892561983471072e-06, 'rewards/chosen': -0.29625701904296875, 'rewards/rejected': -0.6097084283828735, 'rewards/accuracies': 1.0, 'rewards/margins': 0.3134513795375824, 'policy_logps/rejected': -421.8539123535156, 'policy_logps/chosen': -410.1064453125, 'referece_logps/rejected': -415.7568359375, 'referece_logps/chosen': -407.1438903808594, 'logits/rejected': -0.8815026879310608, 'logits/chosen': -0.5578442811965942, 'epoch': 0.16}

  3%|▎         | 434/16104 [2:01:18<69:28:00, 15.96s/it]


  3%|▎         | 436/16104 [2:01:53<74:48:32, 17.19s/it]

  3%|▎         | 437/16104 [2:02:07<70:43:37, 16.25s/it]

  3%|▎         | 438/16104 [2:02:23<71:08:37, 16.35s/it]

  3%|▎         | 439/16104 [2:02:43<75:38:18, 17.38s/it]

  3%|▎         | 440/16104 [2:03:05<80:51:23, 18.58s/it]

  3%|▎         | 441/16104 [2:03:25<83:19:52, 19.15s/it]
{'loss': 0.5999, 'learning_rate': 1.8223140495867767e-06, 'rewards/chosen': -0.23559626936912537, 'rewards/rejected': -0.5535305738449097, 'rewards/accuracies': 1.0, 'rewards/margins': 0.3179343342781067, 'policy_logps/rejected': -303.061767578125, 'policy_logps/chosen': -412.7093505859375, 'referece_logps/rejected': -297.5264587402344, 'referece_logps/chosen': -410.3533630371094, 'logits/rejected': -1.1313121318817139, 'logits/chosen': -1.116841197013855, 'epoch': 0.16}

  3%|▎         | 442/16104 [2:03:40<78:27:36, 18.03s/it]


  3%|▎         | 444/16104 [2:04:13<76:03:44, 17.49s/it]

  3%|▎         | 445/16104 [2:04:29<73:27:58, 16.89s/it]
{'loss': 0.6363, 'learning_rate': 1.8388429752066115e-06, 'rewards/chosen': -0.49109309911727905, 'rewards/rejected': -0.688530445098877, 'rewards/accuracies': 0.375, 'rewards/margins': 0.1974373459815979, 'policy_logps/rejected': -266.125732421875, 'policy_logps/chosen': -316.53076171875, 'referece_logps/rejected': -259.2404479980469, 'referece_logps/chosen': -311.61981201171875, 'logits/rejected': -0.816530168056488, 'logits/chosen': -0.8902667164802551, 'epoch': 0.17}

  3%|▎         | 446/16104 [2:04:50<78:52:26, 18.13s/it]


  3%|▎         | 448/16104 [2:05:27<80:42:51, 18.56s/it]
{'loss': 0.6127, 'learning_rate': 1.8512396694214876e-06, 'rewards/chosen': -0.6850420236587524, 'rewards/rejected': -0.8651164770126343, 'rewards/accuracies': 0.75, 'rewards/margins': 0.18007449805736542, 'policy_logps/rejected': -481.4867248535156, 'policy_logps/chosen': -460.1551208496094, 'referece_logps/rejected': -472.8355712890625, 'referece_logps/chosen': -453.3046569824219, 'logits/rejected': -0.0722743421792984, 'logits/chosen': 0.03553782403469086, 'epoch': 0.17}


  3%|▎         | 450/16104 [2:06:02<78:26:58, 18.04s/it]
{'loss': 0.6324, 'learning_rate': 1.8595041322314049e-06, 'rewards/chosen': -0.2928963303565979, 'rewards/rejected': -0.6058623194694519, 'rewards/accuracies': 0.75, 'rewards/margins': 0.312965989112854, 'policy_logps/rejected': -247.50454711914062, 'policy_logps/chosen': -286.8396911621094, 'referece_logps/rejected': -241.44593811035156, 'referece_logps/chosen': -283.91070556640625, 'logits/rejected': -0.7485480308532715, 'logits/chosen': -0.8071994781494141, 'epoch': 0.17}


  3%|▎         | 452/16104 [2:06:35<76:03:58, 17.50s/it]

  3%|▎         | 453/16104 [2:06:57<82:31:25, 18.98s/it]

  3%|▎         | 454/16104 [2:07:08<71:37:12, 16.47s/it]
{'loss': 0.6229, 'learning_rate': 1.8760330578512396e-06, 'rewards/chosen': -0.18780003488063812, 'rewards/rejected': -0.3869573771953583, 'rewards/accuracies': 0.75, 'rewards/margins': 0.19915734231472015, 'policy_logps/rejected': -310.1789855957031, 'policy_logps/chosen': -303.0683288574219, 'referece_logps/rejected': -306.3094177246094, 'referece_logps/chosen': -301.1903076171875, 'logits/rejected': -0.47443658113479614, 'logits/chosen': -0.3125483989715576, 'epoch': 0.17}

  3%|▎         | 455/16104 [2:07:28<76:50:01, 17.68s/it]


  3%|▎         | 457/16104 [2:08:04<76:56:25, 17.70s/it]
{'loss': 0.5826, 'learning_rate': 1.8884297520661157e-06, 'rewards/chosen': -0.359309583902359, 'rewards/rejected': -0.6074643731117249, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24815475940704346, 'policy_logps/rejected': -333.15777587890625, 'policy_logps/chosen': -517.4161987304688, 'referece_logps/rejected': -327.0831604003906, 'referece_logps/chosen': -513.8231201171875, 'logits/rejected': -0.7797855138778687, 'logits/chosen': -0.7181719541549683, 'epoch': 0.17}

  3%|▎         | 458/16104 [2:08:16<70:03:42, 16.12s/it]

  3%|▎         | 459/16104 [2:08:33<70:19:50, 16.18s/it]

  3%|▎         | 460/16104 [2:08:50<72:24:15, 16.66s/it]


  3%|▎         | 462/16104 [2:09:29<78:42:22, 18.11s/it]
{'loss': 0.5876, 'learning_rate': 1.909090909090909e-06, 'rewards/chosen': -0.6350833773612976, 'rewards/rejected': -0.7742608785629272, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13917751610279083, 'policy_logps/rejected': -405.39129638671875, 'policy_logps/chosen': -423.8656005859375, 'referece_logps/rejected': -397.648681640625, 'referece_logps/chosen': -417.5147705078125, 'logits/rejected': 0.13606691360473633, 'logits/chosen': 0.062209419906139374, 'epoch': 0.17}


  3%|▎         | 464/16104 [2:10:00<71:02:27, 16.35s/it]

  3%|▎         | 465/16104 [2:10:14<68:07:15, 15.68s/it]

  3%|▎         | 466/16104 [2:10:31<69:55:09, 16.10s/it]
{'loss': 0.6174, 'learning_rate': 1.9256198347107436e-06, 'rewards/chosen': -0.36142656207084656, 'rewards/rejected': -0.44779667258262634, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0863700807094574, 'policy_logps/rejected': -546.6820068359375, 'policy_logps/chosen': -457.4129943847656, 'referece_logps/rejected': -542.2039794921875, 'referece_logps/chosen': -453.7987060546875, 'logits/rejected': -1.0648841857910156, 'logits/chosen': -0.9821463227272034, 'epoch': 0.17}

  3%|▎         | 467/16104 [2:10:43<64:01:42, 14.74s/it]

  3%|▎         | 468/16104 [2:11:01<68:24:57, 15.75s/it]


  3%|▎         | 470/16104 [2:11:28<63:58:58, 14.73s/it]
{'loss': 0.669, 'learning_rate': 1.9421487603305786e-06, 'rewards/chosen': -0.20786410570144653, 'rewards/rejected': -0.35513925552368164, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1472751647233963, 'policy_logps/rejected': -440.1990661621094, 'policy_logps/chosen': -453.35845947265625, 'referece_logps/rejected': -436.64764404296875, 'referece_logps/chosen': -451.2798156738281, 'logits/rejected': -0.44995376467704773, 'logits/chosen': -0.4877146780490875, 'epoch': 0.18}


  3%|▎         | 472/16104 [2:11:53<60:36:42, 13.96s/it]

  3%|▎         | 473/16104 [2:12:04<56:19:37, 12.97s/it]
{'loss': 0.598, 'learning_rate': 1.9545454545454545e-06, 'rewards/chosen': -0.2440788298845291, 'rewards/rejected': -0.5904601812362671, 'rewards/accuracies': 0.875, 'rewards/margins': 0.34638139605522156, 'policy_logps/rejected': -374.0440368652344, 'policy_logps/chosen': -509.55615234375, 'referece_logps/rejected': -368.139404296875, 'referece_logps/chosen': -507.1153564453125, 'logits/rejected': -0.49832117557525635, 'logits/chosen': -0.33955252170562744, 'epoch': 0.18}


  3%|▎         | 475/16104 [2:12:25<51:10:49, 11.79s/it]

  3%|▎         | 476/16104 [2:12:36<49:46:41, 11.47s/it]

  3%|▎         | 477/16104 [2:12:54<58:32:59, 13.49s/it]

  3%|▎         | 478/16104 [2:13:07<58:06:18, 13.39s/it]

  3%|▎         | 479/16104 [2:13:20<57:01:12, 13.14s/it]
{'loss': 0.5322, 'learning_rate': 1.9793388429752063e-06, 'rewards/chosen': -0.08522491157054901, 'rewards/rejected': -0.7105637192726135, 'rewards/accuracies': 1.0, 'rewards/margins': 0.6253387928009033, 'policy_logps/rejected': -369.2845764160156, 'policy_logps/chosen': -496.64453125, 'referece_logps/rejected': -362.178955078125, 'referece_logps/chosen': -495.79229736328125, 'logits/rejected': -0.4415585398674011, 'logits/chosen': -0.4369416832923889, 'epoch': 0.18}


  3%|▎         | 481/16104 [2:14:04<76:08:36, 17.55s/it]

  3%|▎         | 482/16104 [2:14:25<81:23:09, 18.75s/it]

  3%|▎         | 483/16104 [2:14:40<76:12:25, 17.56s/it]
{'loss': 0.6369, 'learning_rate': 1.9958677685950413e-06, 'rewards/chosen': -0.36536890268325806, 'rewards/rejected': -0.5051817893981934, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1398128867149353, 'policy_logps/rejected': -231.32968139648438, 'policy_logps/chosen': -208.47714233398438, 'referece_logps/rejected': -226.2778778076172, 'referece_logps/chosen': -204.82345581054688, 'logits/rejected': -0.3409072756767273, 'logits/chosen': -0.28094181418418884, 'epoch': 0.18}


  3%|▎         | 485/16104 [2:15:18<77:23:35, 17.84s/it]
{'loss': 0.6949, 'learning_rate': 1.9999999797741076e-06, 'rewards/chosen': -0.3544246256351471, 'rewards/rejected': -0.5231219530105591, 'rewards/accuracies': 0.625, 'rewards/margins': 0.16869741678237915, 'policy_logps/rejected': -241.12742614746094, 'policy_logps/chosen': -405.7789306640625, 'referece_logps/rejected': -235.89620971679688, 'referece_logps/chosen': -402.23468017578125, 'logits/rejected': -0.0660228431224823, 'logits/chosen': -0.08968643844127655, 'epoch': 0.18}


  3%|▎         | 487/16104 [2:15:40<61:32:54, 14.19s/it]

  3%|▎         | 488/16104 [2:15:50<56:42:57, 13.07s/it]

  3%|▎         | 489/16104 [2:16:12<68:00:55, 15.68s/it]
{'loss': 0.6734, 'learning_rate': 1.9999994943527346e-06, 'rewards/chosen': -0.4666331708431244, 'rewards/rejected': -0.5474886298179626, 'rewards/accuracies': 0.625, 'rewards/margins': 0.08085545897483826, 'policy_logps/rejected': -514.8182373046875, 'policy_logps/chosen': -526.5723876953125, 'referece_logps/rejected': -509.34332275390625, 'referece_logps/chosen': -521.906005859375, 'logits/rejected': -0.8055424094200134, 'logits/chosen': -0.8118661642074585, 'epoch': 0.18}

  3%|▎         | 490/16104 [2:16:25<65:03:14, 15.00s/it]


  3%|▎         | 492/16104 [2:16:50<58:22:20, 13.46s/it]
{'loss': 0.6348, 'learning_rate': 1.999998705543171e-06, 'rewards/chosen': -0.24989521503448486, 'rewards/rejected': -0.475228875875473, 'rewards/accuracies': 0.625, 'rewards/margins': 0.22533369064331055, 'policy_logps/rejected': -684.4988403320312, 'policy_logps/chosen': -316.27972412109375, 'referece_logps/rejected': -679.74658203125, 'referece_logps/chosen': -313.7807922363281, 'logits/rejected': -0.5456697940826416, 'logits/chosen': -0.38021916151046753, 'epoch': 0.18}


  3%|▎         | 494/16104 [2:17:25<68:38:10, 15.83s/it]

  3%|▎         | 495/16104 [2:17:42<70:04:32, 16.16s/it]

  3%|▎         | 496/16104 [2:18:02<75:44:16, 17.47s/it]
[2024-04-05 17:42:16,693] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 497/16104 [2:18:18<73:36:11, 16.98s/it]
{'loss': 0.6339, 'learning_rate': 1.999996581826146e-06, 'rewards/chosen': -0.40471041202545166, 'rewards/rejected': -0.45401427149772644, 'rewards/accuracies': 0.5, 'rewards/margins': 0.049303896725177765, 'policy_logps/rejected': -348.2043762207031, 'policy_logps/chosen': -383.51251220703125, 'referece_logps/rejected': -343.66424560546875, 'referece_logps/chosen': -379.4654541015625, 'logits/rejected': -0.1393999308347702, 'logits/chosen': -0.19060678780078888, 'epoch': 0.19}


  3%|▎         | 499/16104 [2:18:52<75:42:12, 17.46s/it]

  3%|▎         | 500/16104 [2:19:04<67:49:56, 15.65s/it]
  3%|▎         | 500/16104 [2:19:04<67:49:56, 15.65s/it]/mnt/petrelfs/songmingyang/anaconda3/envs/vcd_origin/lib/python3.9/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
  3%|▎         | 501/16104 [2:19:30<81:30:00, 18.80s/it]

  3%|▎         | 502/16104 [2:19:48<80:28:51, 18.57s/it]

  3%|▎         | 503/16104 [2:19:59<70:16:34, 16.22s/it]
{'loss': 0.583, 'learning_rate': 1.99999269846176e-06, 'rewards/chosen': -0.45232313871383667, 'rewards/rejected': -0.7558934688568115, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3035702705383301, 'policy_logps/rejected': -326.86859130859375, 'policy_logps/chosen': -392.72991943359375, 'referece_logps/rejected': -319.3096618652344, 'referece_logps/chosen': -388.2066650390625, 'logits/rejected': -0.9518986344337463, 'logits/chosen': -1.0294969081878662, 'epoch': 0.19}

  3%|▎         | 504/16104 [2:20:16<71:38:17, 16.53s/it]

  3%|▎         | 505/16104 [2:20:37<77:33:42, 17.90s/it]


  3%|▎         | 507/16104 [2:21:19<84:01:37, 19.39s/it]

  3%|▎         | 508/16104 [2:21:32<76:53:32, 17.75s/it]
{'loss': 0.631, 'learning_rate': 1.999988349908648e-06, 'rewards/chosen': -0.17815648019313812, 'rewards/rejected': -0.8233499526977539, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6451935172080994, 'policy_logps/rejected': -313.3497314453125, 'policy_logps/chosen': -299.5708312988281, 'referece_logps/rejected': -305.11627197265625, 'referece_logps/chosen': -297.7892761230469, 'logits/rejected': -0.8626139760017395, 'logits/chosen': -0.8043009042739868, 'epoch': 0.19}

  3%|▎         | 509/16104 [2:21:54<81:16:18, 18.76s/it]

  3%|▎         | 510/16104 [2:22:17<87:39:31, 20.24s/it]

  3%|▎         | 511/16104 [2:22:36<85:36:05, 19.76s/it]

  3%|▎         | 512/16104 [2:22:50<78:30:42, 18.13s/it]


  3%|▎         | 514/16104 [2:23:15<64:46:45, 14.96s/it]
{'loss': 0.6131, 'learning_rate': 1.9999817967521444e-06, 'rewards/chosen': -0.3334224820137024, 'rewards/rejected': -0.48259416222572327, 'rewards/accuracies': 0.75, 'rewards/margins': 0.14917168021202087, 'policy_logps/rejected': -270.9549865722656, 'policy_logps/chosen': -370.72119140625, 'referece_logps/rejected': -266.1290588378906, 'referece_logps/chosen': -367.3869323730469, 'logits/rejected': 0.0014906227588653564, 'logits/chosen': 0.10186579823493958, 'epoch': 0.19}

  3%|▎         | 515/16104 [2:23:25<59:18:31, 13.70s/it]


  3%|▎         | 517/16104 [2:23:51<57:21:12, 13.25s/it]
{'loss': 0.5705, 'learning_rate': 1.999977974084128e-06, 'rewards/chosen': -0.191443532705307, 'rewards/rejected': -0.6126881241798401, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4212445318698883, 'policy_logps/rejected': -287.95074462890625, 'policy_logps/chosen': -399.7065124511719, 'referece_logps/rejected': -281.8238525390625, 'referece_logps/chosen': -397.79205322265625, 'logits/rejected': -0.27847036719322205, 'logits/chosen': -0.17297130823135376, 'epoch': 0.19}


  3%|▎         | 519/16104 [2:24:19<58:03:44, 13.41s/it]

  3%|▎         | 520/16104 [2:24:33<59:07:34, 13.66s/it]
{'loss': 0.5831, 'learning_rate': 1.9999737873580796e-06, 'rewards/chosen': -0.03769979625940323, 'rewards/rejected': -0.5312480926513672, 'rewards/accuracies': 0.625, 'rewards/margins': 0.49354833364486694, 'policy_logps/rejected': -355.15869140625, 'policy_logps/chosen': -275.8835754394531, 'referece_logps/rejected': -349.8462219238281, 'referece_logps/chosen': -275.506591796875, 'logits/rejected': -0.876819908618927, 'logits/chosen': -0.5611584782600403, 'epoch': 0.19}


  3%|▎         | 522/16104 [2:24:59<57:04:00, 13.18s/it]

  3%|▎         | 523/16104 [2:25:19<65:43:58, 15.19s/it]
{'loss': 0.5382, 'learning_rate': 1.9999692365755243e-06, 'rewards/chosen': -0.48880940675735474, 'rewards/rejected': -0.9902399182319641, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5014305114746094, 'policy_logps/rejected': -273.68829345703125, 'policy_logps/chosen': -470.7781066894531, 'referece_logps/rejected': -263.785888671875, 'referece_logps/chosen': -465.8900146484375, 'logits/rejected': -0.034574270248413086, 'logits/chosen': -0.1001313328742981, 'epoch': 0.19}


  3%|▎         | 525/16104 [2:25:55<72:51:26, 16.84s/it]
{'loss': 0.6384, 'learning_rate': 1.999966000467684e-06, 'rewards/chosen': -0.32876625657081604, 'rewards/rejected': -0.4279769957065582, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0992107093334198, 'policy_logps/rejected': -379.53082275390625, 'policy_logps/chosen': -331.8824157714844, 'referece_logps/rejected': -375.2510681152344, 'referece_logps/chosen': -328.5947570800781, 'logits/rejected': -0.22417086362838745, 'logits/chosen': -0.2613476514816284, 'epoch': 0.2}

  3%|▎         | 526/16104 [2:26:08<68:26:39, 15.82s/it]

  3%|▎         | 527/16104 [2:26:22<65:42:39, 15.19s/it]

  3%|▎         | 528/16104 [2:26:33<59:54:59, 13.85s/it]

  3%|▎         | 529/16104 [2:26:52<67:10:04, 15.53s/it]

  3%|▎         | 530/16104 [2:27:09<68:35:19, 15.85s/it]

  3%|▎         | 531/16104 [2:27:30<75:52:55, 17.54s/it]


  3%|▎         | 533/16104 [2:28:07<76:11:46, 17.62s/it]
{'loss': 0.5618, 'learning_rate': 1.9999514380256047e-06, 'rewards/chosen': -1.0251481533050537, 'rewards/rejected': -1.3032993078231812, 'rewards/accuracies': 0.625, 'rewards/margins': 0.278151273727417, 'policy_logps/rejected': -332.7619934082031, 'policy_logps/chosen': -432.7267150878906, 'referece_logps/rejected': -319.72900390625, 'referece_logps/chosen': -422.4752502441406, 'logits/rejected': -0.2514619827270508, 'logits/chosen': -0.1306704431772232, 'epoch': 0.2}

  3%|▎         | 534/16104 [2:28:20<70:22:38, 16.27s/it]


  3%|▎         | 536/16104 [2:28:57<76:15:28, 17.63s/it]
{'loss': 0.5332, 'learning_rate': 1.999945309685697e-06, 'rewards/chosen': -0.6497430801391602, 'rewards/rejected': -1.0821495056152344, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4324064552783966, 'policy_logps/rejected': -439.35369873046875, 'policy_logps/chosen': -436.6869812011719, 'referece_logps/rejected': -428.5322265625, 'referece_logps/chosen': -430.1896057128906, 'logits/rejected': 0.10963983088731766, 'logits/chosen': 0.2392912358045578, 'epoch': 0.2}

  3%|▎         | 537/16104 [2:29:18<80:48:43, 18.69s/it]


  3%|▎         | 539/16104 [2:29:59<83:48:18, 19.38s/it]
{'loss': 0.6117, 'learning_rate': 1.9999388172996495e-06, 'rewards/chosen': -0.7137223482131958, 'rewards/rejected': -1.1780760288238525, 'rewards/accuracies': 1.0, 'rewards/margins': 0.46435368061065674, 'policy_logps/rejected': -521.5242309570312, 'policy_logps/chosen': -504.923095703125, 'referece_logps/rejected': -509.7434387207031, 'referece_logps/chosen': -497.785888671875, 'logits/rejected': -0.32156071066856384, 'logits/chosen': -0.18859153985977173, 'epoch': 0.2}

  3%|▎         | 540/16104 [2:30:18<83:35:07, 19.33s/it]

  3%|▎         | 541/16104 [2:30:33<77:19:42, 17.89s/it]

  3%|▎         | 542/16104 [2:30:52<79:30:33, 18.39s/it]

  3%|▎         | 543/16104 [2:31:13<82:10:51, 19.01s/it]

  3%|▎         | 544/16104 [2:31:27<75:39:49, 17.51s/it]

  3%|▎         | 545/16104 [2:31:38<67:43:46, 15.67s/it]


  3%|▎         | 547/16104 [2:31:59<56:41:30, 13.12s/it]
{'loss': 0.623, 'learning_rate': 1.9999197245074567e-06, 'rewards/chosen': -0.31830307841300964, 'rewards/rejected': -0.6093007326126099, 'rewards/accuracies': 0.75, 'rewards/margins': 0.290997713804245, 'policy_logps/rejected': -422.41607666015625, 'policy_logps/chosen': -320.8908996582031, 'referece_logps/rejected': -416.3230895996094, 'referece_logps/chosen': -317.7078857421875, 'logits/rejected': -0.8931732773780823, 'logits/chosen': -0.9160321950912476, 'epoch': 0.2}

  3%|▎         | 548/16104 [2:32:10<53:21:36, 12.35s/it]


  3%|▎         | 550/16104 [2:32:47<67:47:12, 15.69s/it]
{'loss': 0.7135, 'learning_rate': 1.999911897306794e-06, 'rewards/chosen': -0.7553818225860596, 'rewards/rejected': -0.7086725234985352, 'rewards/accuracies': 0.5, 'rewards/margins': -0.04670923203229904, 'policy_logps/rejected': -526.63818359375, 'policy_logps/chosen': -618.634765625, 'referece_logps/rejected': -519.5514526367188, 'referece_logps/chosen': -611.0809326171875, 'logits/rejected': -0.6715733408927917, 'logits/chosen': -0.8180666565895081, 'epoch': 0.2}

  3%|▎         | 551/16104 [2:33:00<64:18:28, 14.89s/it]


  3%|▎         | 553/16104 [2:33:35<70:10:05, 16.24s/it]
{'loss': 0.5968, 'learning_rate': 1.9999037060721556e-06, 'rewards/chosen': -0.5388364791870117, 'rewards/rejected': -0.750072181224823, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21123570203781128, 'policy_logps/rejected': -260.1523132324219, 'policy_logps/chosen': -741.8078002929688, 'referece_logps/rejected': -252.65158081054688, 'referece_logps/chosen': -736.41943359375, 'logits/rejected': -0.996852457523346, 'logits/chosen': -1.2757568359375, 'epoch': 0.21}

  3%|▎         | 554/16104 [2:33:50<68:33:00, 15.87s/it]

  3%|▎         | 555/16104 [2:34:08<70:59:51, 16.44s/it]

  3%|▎         | 556/16104 [2:34:26<73:14:18, 16.96s/it]

  3%|▎         | 557/16104 [2:34:38<66:42:41, 15.45s/it]

  3%|▎         | 558/16104 [2:34:50<62:47:41, 14.54s/it]


  3%|▎         | 560/16104 [2:35:22<65:38:41, 15.20s/it]

  3%|▎         | 561/16104 [2:35:35<63:40:09, 14.75s/it]
{'loss': 0.6167, 'learning_rate': 1.9998800830812287e-06, 'rewards/chosen': -0.486602246761322, 'rewards/rejected': -0.6395118236541748, 'rewards/accuracies': 0.75, 'rewards/margins': 0.15290957689285278, 'policy_logps/rejected': -299.547607421875, 'policy_logps/chosen': -277.39288330078125, 'referece_logps/rejected': -293.1524963378906, 'referece_logps/chosen': -272.52685546875, 'logits/rejected': -0.851952314376831, 'logits/chosen': -0.7932764291763306, 'epoch': 0.21}

  3%|▎         | 562/16104 [2:35:48<61:00:03, 14.13s/it]

  3%|▎         | 563/16104 [2:36:00<58:23:01, 13.52s/it]


  4%|▎         | 565/16104 [2:36:28<59:30:21, 13.79s/it]
{'loss': 0.6297, 'learning_rate': 1.9998673008554796e-06, 'rewards/chosen': -0.5909748077392578, 'rewards/rejected': -0.6259033679962158, 'rewards/accuracies': 0.375, 'rewards/margins': 0.034928563982248306, 'policy_logps/rejected': -294.1139221191406, 'policy_logps/chosen': -305.1443176269531, 'referece_logps/rejected': -287.8548583984375, 'referece_logps/chosen': -299.234619140625, 'logits/rejected': -0.2855552136898041, 'logits/chosen': -0.29156988859176636, 'epoch': 0.21}

  4%|▎         | 566/16104 [2:36:48<67:47:46, 15.71s/it]

  4%|▎         | 567/16104 [2:37:04<68:06:13, 15.78s/it]

  4%|▎         | 568/16104 [2:37:25<75:03:31, 17.39s/it]


  4%|▎         | 570/16104 [2:38:03<77:57:47, 18.07s/it]

  4%|▎         | 571/16104 [2:38:20<75:47:43, 17.57s/it]

  4%|▎         | 572/16104 [2:38:38<76:26:31, 17.72s/it]

  4%|▎         | 573/16104 [2:38:57<78:45:21, 18.26s/it]

  4%|▎         | 574/16104 [2:39:10<71:01:13, 16.46s/it]
{'loss': 0.666, 'learning_rate': 1.999836174745576e-06, 'rewards/chosen': -0.37382450699806213, 'rewards/rejected': -0.5106117725372314, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13678723573684692, 'policy_logps/rejected': -368.05645751953125, 'policy_logps/chosen': -359.7821044921875, 'referece_logps/rejected': -362.9503173828125, 'referece_logps/chosen': -356.04388427734375, 'logits/rejected': -0.4635617434978485, 'logits/chosen': -0.4245302975177765, 'epoch': 0.21}

  4%|▎         | 575/16104 [2:39:25<69:21:10, 16.08s/it]

  4%|▎         | 576/16104 [2:39:45<74:54:40, 17.37s/it]

  4%|▎         | 577/16104 [2:40:07<81:04:48, 18.80s/it]

  4%|▎         | 578/16104 [2:40:27<81:54:08, 18.99s/it]

  4%|▎         | 579/16104 [2:40:46<82:40:35, 19.17s/it]

  4%|▎         | 580/16104 [2:41:04<80:51:46, 18.75s/it]

  4%|▎         | 581/16104 [2:41:19<75:58:00, 17.62s/it]

  4%|▎         | 582/16104 [2:41:36<75:28:28, 17.50s/it]

  4%|▎         | 583/16104 [2:41:55<76:27:41, 17.73s/it]


  4%|▎         | 585/16104 [2:42:22<66:41:57, 15.47s/it]
{'loss': 0.5587, 'learning_rate': 1.9997936827673683e-06, 'rewards/chosen': -0.33971837162971497, 'rewards/rejected': -0.4088866710662842, 'rewards/accuracies': 0.5, 'rewards/margins': 0.06916828453540802, 'policy_logps/rejected': -300.7904357910156, 'policy_logps/chosen': -258.7547912597656, 'referece_logps/rejected': -296.70159912109375, 'referece_logps/chosen': -255.3576202392578, 'logits/rejected': -1.2412059307098389, 'logits/chosen': -1.3466484546661377, 'epoch': 0.22}

  4%|▎         | 586/16104 [2:42:33<61:08:18, 14.18s/it]


  4%|▎         | 588/16104 [2:43:06<67:05:42, 15.57s/it]
{'loss': 0.5781, 'learning_rate': 1.999781244724849e-06, 'rewards/chosen': -0.4910438656806946, 'rewards/rejected': -1.2588642835617065, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7678203582763672, 'policy_logps/rejected': -288.25445556640625, 'policy_logps/chosen': -420.60955810546875, 'referece_logps/rejected': -275.6658020019531, 'referece_logps/chosen': -415.6991271972656, 'logits/rejected': -0.4111482501029968, 'logits/chosen': -0.3645102083683014, 'epoch': 0.22}


  4%|▎         | 590/16104 [2:43:32<61:39:20, 14.31s/it]
{'loss': 0.5356, 'learning_rate': 1.999772750481546e-06, 'rewards/chosen': -0.8307300806045532, 'rewards/rejected': -0.9462975859642029, 'rewards/accuracies': 0.5, 'rewards/margins': 0.11556749045848846, 'policy_logps/rejected': -401.42742919921875, 'policy_logps/chosen': -380.5278015136719, 'referece_logps/rejected': -391.9645080566406, 'referece_logps/chosen': -372.220458984375, 'logits/rejected': 0.5021467804908752, 'logits/chosen': 0.4404299855232239, 'epoch': 0.22}


  4%|▎         | 592/16104 [2:44:08<69:50:20, 16.21s/it]

  4%|▎         | 593/16104 [2:44:22<66:47:07, 15.50s/it]

  4%|▎         | 594/16104 [2:44:38<67:59:50, 15.78s/it]
{'loss': 0.5529, 'learning_rate': 1.999755276685243e-06, 'rewards/chosen': -0.30714645981788635, 'rewards/rejected': -0.7077519297599792, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4006054401397705, 'policy_logps/rejected': -263.7607116699219, 'policy_logps/chosen': -360.26043701171875, 'referece_logps/rejected': -256.68316650390625, 'referece_logps/chosen': -357.18896484375, 'logits/rejected': 0.11654148250818253, 'logits/chosen': 0.2593817412853241, 'epoch': 0.22}

  4%|▎         | 595/16104 [2:44:59<73:54:24, 17.16s/it]


  4%|▎         | 597/16104 [2:45:38<80:29:32, 18.69s/it]
{'loss': 0.5632, 'learning_rate': 1.9997417466976105e-06, 'rewards/chosen': -1.2381609678268433, 'rewards/rejected': -1.4610753059387207, 'rewards/accuracies': 0.75, 'rewards/margins': 0.22291433811187744, 'policy_logps/rejected': -477.5926513671875, 'policy_logps/chosen': -529.5374145507812, 'referece_logps/rejected': -462.9819030761719, 'referece_logps/chosen': -517.1558227539062, 'logits/rejected': 0.5814402103424072, 'logits/chosen': 0.612114429473877, 'epoch': 0.22}

  4%|▎         | 598/16104 [2:45:56<79:10:12, 18.38s/it]

  4%|▎         | 599/16104 [2:46:11<75:50:27, 17.61s/it]

  4%|▎         | 600/16104 [2:46:29<76:17:58, 17.72s/it]


  4%|▎         | 602/16104 [2:47:10<83:00:19, 19.28s/it]
{'loss': 0.5316, 'learning_rate': 1.999718387893984e-06, 'rewards/chosen': -0.2766467332839966, 'rewards/rejected': -1.14483642578125, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8681896328926086, 'policy_logps/rejected': -234.11952209472656, 'policy_logps/chosen': -409.6495666503906, 'referece_logps/rejected': -222.671142578125, 'referece_logps/chosen': -406.8831481933594, 'logits/rejected': -0.5445192456245422, 'logits/chosen': -0.5527719259262085, 'epoch': 0.22}

  4%|▎         | 603/16104 [2:47:30<83:50:23, 19.47s/it]

  4%|▍         | 604/16104 [2:47:48<81:30:33, 18.93s/it]

  4%|▍         | 605/16104 [2:48:08<83:44:27, 19.45s/it]
[2024-04-05 18:12:43,266] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  4%|▍         | 607/16104 [2:48:44<79:25:54, 18.45s/it]
[2024-04-05 18:12:58,764] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5383, 'learning_rate': 1.99969401808062e-06, 'rewards/chosen': -0.6628425717353821, 'rewards/rejected': -1.6006898880004883, 'rewards/accuracies': 1.0, 'rewards/margins': 0.937847375869751, 'policy_logps/rejected': -359.5802917480469, 'policy_logps/chosen': -428.65557861328125, 'referece_logps/rejected': -343.5733947753906, 'referece_logps/chosen': -422.027099609375, 'logits/rejected': -0.8266690373420715, 'logits/chosen': -0.5982584357261658, 'epoch': 0.23}

  4%|▍         | 608/16104 [2:49:03<79:22:39, 18.44s/it]

  4%|▍         | 609/16104 [2:49:14<70:13:51, 16.32s/it]

  4%|▍         | 610/16104 [2:49:25<63:45:55, 14.82s/it]

  4%|▍         | 611/16104 [2:49:38<61:42:14, 14.34s/it]

  4%|▍         | 612/16104 [2:49:59<69:42:05, 16.20s/it]

  4%|▍         | 613/16104 [2:50:16<70:34:24, 16.40s/it]

  4%|▍         | 614/16104 [2:50:27<63:11:00, 14.68s/it]

  4%|▍         | 615/16104 [2:50:47<70:29:53, 16.39s/it]

  4%|▍         | 616/16104 [2:51:05<72:49:01, 16.93s/it]

  4%|▍         | 617/16104 [2:51:23<74:04:54, 17.22s/it]

  4%|▍         | 618/16104 [2:51:38<71:47:49, 16.69s/it]
[2024-04-05 18:16:15,806] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 619/16104 [2:52:01<79:35:38, 18.50s/it]
[2024-04-05 18:16:31,769] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 620/16104 [2:52:17<76:18:37, 17.74s/it]

  4%|▍         | 621/16104 [2:52:34<75:05:01, 17.46s/it]

  4%|▍         | 622/16104 [2:52:50<72:48:04, 16.93s/it]

  4%|▍         | 623/16104 [2:53:07<73:47:48, 17.16s/it]

  4%|▍         | 624/16104 [2:53:20<68:18:32, 15.89s/it]

  4%|▍         | 625/16104 [2:53:38<71:04:06, 16.53s/it]

  4%|▍         | 626/16104 [2:54:00<77:22:28, 18.00s/it]

  4%|▍         | 627/16104 [2:54:19<78:47:13, 18.33s/it]

  4%|▍         | 628/16104 [2:54:36<76:57:59, 17.90s/it]

  4%|▍         | 629/16104 [2:54:55<78:52:12, 18.35s/it]

  4%|▍         | 630/16104 [2:55:09<72:54:26, 16.96s/it]

  4%|▍         | 631/16104 [2:55:29<77:01:53, 17.92s/it]


  4%|▍         | 633/16104 [2:56:07<81:07:14, 18.88s/it]
{'loss': 0.5315, 'learning_rate': 1.999550998569155e-06, 'rewards/chosen': -0.6289839148521423, 'rewards/rejected': -1.067008137702942, 'rewards/accuracies': 0.875, 'rewards/margins': 0.43802425265312195, 'policy_logps/rejected': -324.55810546875, 'policy_logps/chosen': -301.2649230957031, 'referece_logps/rejected': -313.8880310058594, 'referece_logps/chosen': -294.97503662109375, 'logits/rejected': -0.7316833138465881, 'logits/chosen': -0.6001935601234436, 'epoch': 0.24}

  4%|▍         | 634/16104 [2:56:28<83:51:12, 19.51s/it]

  4%|▍         | 635/16104 [2:56:48<84:46:16, 19.73s/it]

  4%|▍         | 636/16104 [2:57:12<89:41:54, 20.88s/it]


  4%|▍         | 638/16104 [2:57:55<91:34:51, 21.32s/it]
[2024-04-05 18:22:09,787] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 639/16104 [2:58:11<84:42:57, 19.72s/it]

  4%|▍         | 640/16104 [2:58:23<75:09:08, 17.50s/it]

  4%|▍         | 641/16104 [2:58:40<74:05:03, 17.25s/it]

  4%|▍         | 642/16104 [2:58:59<76:42:32, 17.86s/it]
[2024-04-05 18:23:14,045] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 643/16104 [2:59:11<68:11:31, 15.88s/it]

  4%|▍         | 644/16104 [2:59:22<61:53:58, 14.41s/it]

  4%|▍         | 645/16104 [2:59:44<71:49:18, 16.73s/it]
[2024-04-05 18:23:58,415] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 646/16104 [3:00:03<74:56:50, 17.45s/it]

  4%|▍         | 647/16104 [3:00:24<79:31:43, 18.52s/it]

  4%|▍         | 648/16104 [3:00:40<76:55:10, 17.92s/it]

  4%|▍         | 649/16104 [3:01:00<79:21:48, 18.49s/it]

  4%|▍         | 650/16104 [3:01:17<76:55:32, 17.92s/it]

  4%|▍         | 651/16104 [3:01:31<71:57:31, 16.76s/it]

  4%|▍         | 652/16104 [3:01:51<76:12:44, 17.76s/it]

  4%|▍         | 653/16104 [3:02:08<74:47:11, 17.42s/it]

  4%|▍         | 654/16104 [3:02:28<78:13:31, 18.23s/it]

  4%|▍         | 655/16104 [3:02:44<75:38:36, 17.63s/it]

  4%|▍         | 656/16104 [3:03:04<79:17:20, 18.48s/it]

  4%|▍         | 657/16104 [3:03:17<71:14:51, 16.60s/it]

  4%|▍         | 658/16104 [3:03:37<76:13:49, 17.77s/it]

  4%|▍         | 659/16104 [3:03:59<81:54:23, 19.09s/it]
[2024-04-05 18:28:13,973] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 660/16104 [3:04:17<80:10:49, 18.69s/it]
[2024-04-05 18:28:31,728] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 661/16104 [3:04:30<72:18:39, 16.86s/it]

  4%|▍         | 662/16104 [3:04:46<72:09:46, 16.82s/it]

  4%|▍         | 663/16104 [3:05:02<70:18:16, 16.39s/it]

  4%|▍         | 664/16104 [3:05:23<76:54:14, 17.93s/it]

  4%|▍         | 665/16104 [3:05:42<77:32:45, 18.08s/it]

  4%|▍         | 666/16104 [3:06:03<82:13:58, 19.18s/it]

  4%|▍         | 667/16104 [3:06:25<85:40:00, 19.98s/it]

  4%|▍         | 668/16104 [3:06:47<87:48:41, 20.48s/it]

  4%|▍         | 669/16104 [3:07:08<88:11:54, 20.57s/it]

  4%|▍         | 670/16104 [3:07:21<78:49:02, 18.38s/it]

  4%|▍         | 671/16104 [3:07:39<78:30:03, 18.31s/it]

  4%|▍         | 672/16104 [3:07:58<78:51:12, 18.40s/it]

  4%|▍         | 673/16104 [3:08:08<68:53:04, 16.07s/it]

  4%|▍         | 674/16104 [3:08:22<65:33:04, 15.29s/it]

  4%|▍         | 675/16104 [3:08:34<61:18:20, 14.30s/it]

  4%|▍         | 676/16104 [3:08:45<56:44:17, 13.24s/it]

  4%|▍         | 677/16104 [3:09:04<64:29:00, 15.05s/it]
[2024-04-05 18:33:18,564] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 678/16104 [3:09:19<64:04:59, 14.96s/it]

  4%|▍         | 679/16104 [3:09:35<66:14:46, 15.46s/it]

  4%|▍         | 680/16104 [3:09:54<69:48:03, 16.29s/it]

  4%|▍         | 681/16104 [3:10:04<62:46:49, 14.65s/it]

  4%|▍         | 682/16104 [3:10:18<62:03:50, 14.49s/it]

  4%|▍         | 683/16104 [3:10:39<70:04:12, 16.36s/it]

  4%|▍         | 684/16104 [3:10:57<72:15:26, 16.87s/it]

  4%|▍         | 685/16104 [3:11:16<75:06:05, 17.53s/it]

  4%|▍         | 686/16104 [3:11:32<72:58:36, 17.04s/it]

  4%|▍         | 687/16104 [3:11:50<73:56:05, 17.26s/it]

  4%|▍         | 688/16104 [3:12:05<70:44:26, 16.52s/it]

  4%|▍         | 689/16104 [3:12:26<77:17:38, 18.05s/it]

  4%|▍         | 690/16104 [3:12:44<76:26:52, 17.85s/it]

  4%|▍         | 691/16104 [3:12:55<67:16:10, 15.71s/it]

  4%|▍         | 692/16104 [3:13:11<68:14:59, 15.94s/it]

  4%|▍         | 693/16104 [3:13:29<70:44:41, 16.53s/it]
{'loss': 0.537, 'learning_rate': 1.9991166428818033e-06, 'rewards/chosen': -0.7119489908218384, 'rewards/rejected': -1.1584490537643433, 'rewards/accuracies': 0.625, 'rewards/margins': 0.44650009274482727, 'policy_logps/rejected': -519.8137817382812, 'policy_logps/chosen': -479.2550964355469, 'referece_logps/rejected': -508.2292785644531, 'referece_logps/chosen': -472.1356201171875, 'logits/rejected': 0.025139406323432922, 'logits/chosen': 0.010874561965465546, 'epoch': 0.26}


  4%|▍         | 695/16104 [3:14:10<79:03:05, 18.47s/it]

  4%|▍         | 696/16104 [3:14:31<82:33:34, 19.29s/it]
{'loss': 0.5962, 'learning_rate': 1.99909110521087e-06, 'rewards/chosen': -1.1684925556182861, 'rewards/rejected': -1.617621898651123, 'rewards/accuracies': 0.375, 'rewards/margins': 0.4491293132305145, 'policy_logps/rejected': -485.5194091796875, 'policy_logps/chosen': -488.5401611328125, 'referece_logps/rejected': -469.3431396484375, 'referece_logps/chosen': -476.8552551269531, 'logits/rejected': -0.7639854550361633, 'logits/chosen': -0.8102084994316101, 'epoch': 0.26}


  4%|▍         | 698/16104 [3:15:07<78:57:01, 18.45s/it]

  4%|▍         | 699/16104 [3:15:27<81:43:47, 19.10s/it]
[2024-04-05 18:39:42,046] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 700/16104 [3:15:42<75:52:36, 17.73s/it]

  4%|▍         | 701/16104 [3:15:54<68:21:33, 15.98s/it]
{'loss': 0.5203, 'learning_rate': 1.9990477341302936e-06, 'rewards/chosen': -0.577497124671936, 'rewards/rejected': -0.8858954310417175, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3083983063697815, 'policy_logps/rejected': -233.19691467285156, 'policy_logps/chosen': -276.8493957519531, 'referece_logps/rejected': -224.3379669189453, 'referece_logps/chosen': -271.0744323730469, 'logits/rejected': -1.3595654964447021, 'logits/chosen': -1.3703722953796387, 'epoch': 0.26}

  4%|▍         | 702/16104 [3:16:08<66:21:35, 15.51s/it]


  4%|▍         | 704/16104 [3:16:45<71:38:30, 16.75s/it]
{'loss': 0.5827, 'learning_rate': 1.9990212265199736e-06, 'rewards/chosen': -1.1311416625976562, 'rewards/rejected': -1.8008296489715576, 'rewards/accuracies': 0.75, 'rewards/margins': 0.669687807559967, 'policy_logps/rejected': -426.3026123046875, 'policy_logps/chosen': -452.06787109375, 'referece_logps/rejected': -408.2943420410156, 'referece_logps/chosen': -440.75640869140625, 'logits/rejected': -1.1201791763305664, 'logits/chosen': -1.0987608432769775, 'epoch': 0.26}


  4%|▍         | 706/16104 [3:17:21<74:44:48, 17.48s/it]

  4%|▍         | 707/16104 [3:17:36<70:53:31, 16.58s/it]

  4%|▍         | 708/16104 [3:17:51<69:10:52, 16.18s/it]

  4%|▍         | 709/16104 [3:18:08<69:56:00, 16.35s/it]

  4%|▍         | 710/16104 [3:18:26<71:34:11, 16.74s/it]
{'loss': 0.6005, 'learning_rate': 1.9989671201799792e-06, 'rewards/chosen': -0.8121122121810913, 'rewards/rejected': -1.4609036445617676, 'rewards/accuracies': 0.875, 'rewards/margins': 0.648791491985321, 'policy_logps/rejected': -398.96875, 'policy_logps/chosen': -390.32684326171875, 'referece_logps/rejected': -384.3597106933594, 'referece_logps/chosen': -382.2056884765625, 'logits/rejected': -0.05836029350757599, 'logits/chosen': 0.015984296798706055, 'epoch': 0.26}


  4%|▍         | 712/16104 [3:19:05<77:55:46, 18.23s/it]
{'loss': 0.5944, 'learning_rate': 1.9989487614493796e-06, 'rewards/chosen': -0.8169040083885193, 'rewards/rejected': -1.2172996997833252, 'rewards/accuracies': 0.625, 'rewards/margins': 0.40039563179016113, 'policy_logps/rejected': -358.8893127441406, 'policy_logps/chosen': -308.4825439453125, 'referece_logps/rejected': -346.71630859375, 'referece_logps/chosen': -300.31353759765625, 'logits/rejected': -0.6334846019744873, 'logits/chosen': -0.5766791701316833, 'epoch': 0.27}

  4%|▍         | 713/16104 [3:19:23<76:53:07, 17.98s/it]


  4%|▍         | 715/16104 [3:19:53<70:49:13, 16.57s/it]

  4%|▍         | 716/16104 [3:20:11<72:44:03, 17.02s/it]

  4%|▍         | 717/16104 [3:20:31<76:45:58, 17.96s/it]

  4%|▍         | 718/16104 [3:20:44<69:58:41, 16.37s/it]

  4%|▍         | 719/16104 [3:20:57<66:04:24, 15.46s/it]

  4%|▍         | 720/16104 [3:21:18<73:05:08, 17.10s/it]
{'loss': 0.5781, 'learning_rate': 1.9988737101866934e-06, 'rewards/chosen': -0.5204848647117615, 'rewards/rejected': -0.9195452928543091, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3990604281425476, 'policy_logps/rejected': -421.8415832519531, 'policy_logps/chosen': -424.2959289550781, 'referece_logps/rejected': -412.6461486816406, 'referece_logps/chosen': -419.091064453125, 'logits/rejected': -0.972778856754303, 'logits/chosen': -1.0348707437515259, 'epoch': 0.27}


  4%|▍         | 722/16104 [3:21:48<66:27:17, 15.55s/it]
{'loss': 0.5784, 'learning_rate': 1.99885454330113e-06, 'rewards/chosen': -0.8056712746620178, 'rewards/rejected': -1.5587775707244873, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7531063556671143, 'policy_logps/rejected': -313.4017639160156, 'policy_logps/chosen': -398.326171875, 'referece_logps/rejected': -297.8139953613281, 'referece_logps/chosen': -390.2694396972656, 'logits/rejected': -1.007412314414978, 'logits/chosen': -1.0551625490188599, 'epoch': 0.27}


  4%|▍         | 724/16104 [3:22:26<74:11:01, 17.36s/it]
{'loss': 0.5426, 'learning_rate': 1.9988352147937735e-06, 'rewards/chosen': -0.5483114123344421, 'rewards/rejected': -1.103758692741394, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5554472208023071, 'policy_logps/rejected': -421.13531494140625, 'policy_logps/chosen': -454.97686767578125, 'referece_logps/rejected': -410.0977478027344, 'referece_logps/chosen': -449.4937438964844, 'logits/rejected': -1.0284042358398438, 'logits/chosen': -1.018094778060913, 'epoch': 0.27}

  5%|▍         | 725/16104 [3:22:41<70:42:18, 16.55s/it]


  5%|▍         | 727/16104 [3:23:06<62:20:11, 14.59s/it]

  5%|▍         | 728/16104 [3:23:19<60:39:01, 14.20s/it]
{'loss': 0.5822, 'learning_rate': 1.998796072926217e-06, 'rewards/chosen': -0.4054921865463257, 'rewards/rejected': -0.7600987553596497, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3546065390110016, 'policy_logps/rejected': -423.8050842285156, 'policy_logps/chosen': -523.4449462890625, 'referece_logps/rejected': -416.2041320800781, 'referece_logps/chosen': -519.3900146484375, 'logits/rejected': -0.7372875809669495, 'logits/chosen': -0.7994161248207092, 'epoch': 0.27}

  5%|▍         | 729/16104 [3:23:31<57:36:04, 13.49s/it]


  5%|▍         | 731/16104 [3:24:01<61:54:49, 14.50s/it]

  5%|▍         | 732/16104 [3:24:18<64:25:39, 15.09s/it]

  5%|▍         | 733/16104 [3:24:37<69:00:17, 16.16s/it]
{'loss': 0.4813, 'learning_rate': 1.998746236525447e-06, 'rewards/chosen': -0.9513366222381592, 'rewards/rejected': -1.6816108226776123, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7302741408348083, 'policy_logps/rejected': -264.15191650390625, 'policy_logps/chosen': -355.851806640625, 'referece_logps/rejected': -247.3358154296875, 'referece_logps/chosen': -346.3384094238281, 'logits/rejected': 0.34136247634887695, 'logits/chosen': 0.5059454441070557, 'epoch': 0.27}


  5%|▍         | 735/16104 [3:25:10<72:08:08, 16.90s/it]
{'loss': 0.5095, 'learning_rate': 1.9987260191548326e-06, 'rewards/chosen': -0.6074442267417908, 'rewards/rejected': -1.1391916275024414, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5317474603652954, 'policy_logps/rejected': -387.93341064453125, 'policy_logps/chosen': -458.6295471191406, 'referece_logps/rejected': -376.54144287109375, 'referece_logps/chosen': -452.55511474609375, 'logits/rejected': -1.8098617792129517, 'logits/chosen': -1.6477370262145996, 'epoch': 0.27}

  5%|▍         | 736/16104 [3:25:23<67:05:24, 15.72s/it]

  5%|▍         | 737/16104 [3:25:41<69:47:03, 16.35s/it]

  5%|▍         | 738/16104 [3:26:01<74:42:46, 17.50s/it]


  5%|▍         | 740/16104 [3:26:37<77:02:18, 18.05s/it]

  5%|▍         | 741/16104 [3:26:48<67:27:13, 15.81s/it]

  5%|▍         | 742/16104 [3:27:08<72:39:56, 17.03s/it]

  5%|▍         | 743/16104 [3:27:29<78:19:41, 18.36s/it]

  5%|▍         | 744/16104 [3:27:42<71:24:18, 16.74s/it]
{'loss': 0.7158, 'learning_rate': 1.998633041222571e-06, 'rewards/chosen': -0.5270735621452332, 'rewards/rejected': -0.4796893298625946, 'rewards/accuracies': 0.625, 'rewards/margins': -0.047384265810251236, 'policy_logps/rejected': -253.6597900390625, 'policy_logps/chosen': -354.0050048828125, 'referece_logps/rejected': -248.8629150390625, 'referece_logps/chosen': -348.7342834472656, 'logits/rejected': -0.9234388470649719, 'logits/chosen': -1.018040657043457, 'epoch': 0.28}

  5%|▍         | 745/16104 [3:27:57<68:42:20, 16.10s/it]


  5%|▍         | 747/16104 [3:28:23<61:47:14, 14.48s/it]

  5%|▍         | 748/16104 [3:28:43<69:05:31, 16.20s/it]
{'loss': 0.5078, 'learning_rate': 1.998590667370204e-06, 'rewards/chosen': -0.8352795839309692, 'rewards/rejected': -1.3160054683685303, 'rewards/accuracies': 0.625, 'rewards/margins': 0.48072579503059387, 'policy_logps/rejected': -370.28741455078125, 'policy_logps/chosen': -479.5574645996094, 'referece_logps/rejected': -357.1273193359375, 'referece_logps/chosen': -471.20465087890625, 'logits/rejected': -0.8300317525863647, 'logits/chosen': -0.8436181545257568, 'epoch': 0.28}


  5%|▍         | 750/16104 [3:29:10<62:17:06, 14.60s/it]

  5%|▍         | 751/16104 [3:29:27<65:00:23, 15.24s/it]

  5%|▍         | 752/16104 [3:29:41<63:13:02, 14.82s/it]

  5%|▍         | 753/16104 [3:29:58<66:02:33, 15.49s/it]

  5%|▍         | 754/16104 [3:30:18<72:22:54, 16.98s/it]
{'loss': 0.5555, 'learning_rate': 1.9985258947571646e-06, 'rewards/chosen': -1.0954768657684326, 'rewards/rejected': -1.8411002159118652, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7456234097480774, 'policy_logps/rejected': -255.37820434570312, 'policy_logps/chosen': -471.36480712890625, 'referece_logps/rejected': -236.9672088623047, 'referece_logps/chosen': -460.4100036621094, 'logits/rejected': -0.8393990993499756, 'logits/chosen': -0.7551851868629456, 'epoch': 0.28}

  5%|▍         | 755/16104 [3:30:31<67:47:33, 15.90s/it]


  5%|▍         | 757/16104 [3:31:05<71:03:46, 16.67s/it]

  5%|▍         | 758/16104 [3:31:23<72:45:43, 17.07s/it]

  5%|▍         | 759/16104 [3:31:42<75:56:07, 17.81s/it]

  5%|▍         | 760/16104 [3:32:03<79:44:14, 18.71s/it]
{'loss': 0.5495, 'learning_rate': 1.9984596680267423e-06, 'rewards/chosen': -0.8419725894927979, 'rewards/rejected': -1.3567765951156616, 'rewards/accuracies': 0.375, 'rewards/margins': 0.5148040652275085, 'policy_logps/rejected': -407.0001220703125, 'policy_logps/chosen': -441.60662841796875, 'referece_logps/rejected': -393.432373046875, 'referece_logps/chosen': -433.1868896484375, 'logits/rejected': -0.5030261874198914, 'logits/chosen': -0.4927993714809418, 'epoch': 0.28}

  5%|▍         | 761/16104 [3:32:23<81:56:29, 19.23s/it]

  5%|▍         | 762/16104 [3:32:42<80:29:21, 18.89s/it]


  5%|▍         | 764/16104 [3:33:13<75:03:30, 17.61s/it]

  5%|▍         | 765/16104 [3:33:31<75:06:58, 17.63s/it]
{'loss': 0.6063, 'learning_rate': 1.998403368370127e-06, 'rewards/chosen': -1.0510777235031128, 'rewards/rejected': -1.4782711267471313, 'rewards/accuracies': 0.5, 'rewards/margins': 0.42719346284866333, 'policy_logps/rejected': -456.1651916503906, 'policy_logps/chosen': -524.5414428710938, 'referece_logps/rejected': -441.3824462890625, 'referece_logps/chosen': -514.0307006835938, 'logits/rejected': -0.332221657037735, 'logits/chosen': -0.2772639989852905, 'epoch': 0.29}
[2024-04-05 18:58:06,143] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  5%|▍         | 767/16104 [3:34:12<81:45:54, 19.19s/it]
[2024-04-05 18:58:26,692] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 768/16104 [3:34:27<75:57:50, 17.83s/it]

  5%|▍         | 769/16104 [3:34:42<72:58:14, 17.13s/it]

  5%|▍         | 770/16104 [3:35:03<77:01:28, 18.08s/it]
[2024-04-05 18:59:17,149] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 771/16104 [3:35:24<81:27:58, 19.13s/it]

  5%|▍         | 772/16104 [3:35:44<82:54:19, 19.47s/it]
[2024-04-05 18:59:58,970] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 773/16104 [3:36:00<77:58:55, 18.31s/it]

  5%|▍         | 774/16104 [3:36:11<68:22:35, 16.06s/it]
{'loss': 0.502, 'learning_rate': 1.99829948463387e-06, 'rewards/chosen': -0.5820995569229126, 'rewards/rejected': -1.477099061012268, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8949995040893555, 'policy_logps/rejected': -405.61669921875, 'policy_logps/chosen': -368.2339782714844, 'referece_logps/rejected': -390.845703125, 'referece_logps/chosen': -362.4129638671875, 'logits/rejected': -0.3538001477718353, 'logits/chosen': -0.5206259489059448, 'epoch': 0.29}


  5%|▍         | 776/16104 [3:36:45<71:33:22, 16.81s/it]

  5%|▍         | 777/16104 [3:37:03<72:55:50, 17.13s/it]
{'loss': 0.5342, 'learning_rate': 1.998264129810942e-06, 'rewards/chosen': -0.39104223251342773, 'rewards/rejected': -1.2922695875167847, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9012272357940674, 'policy_logps/rejected': -211.4701690673828, 'policy_logps/chosen': -396.33575439453125, 'referece_logps/rejected': -198.5474853515625, 'referece_logps/chosen': -392.42535400390625, 'logits/rejected': -0.5550539493560791, 'logits/chosen': -0.5276142358779907, 'epoch': 0.29}


  5%|▍         | 779/16104 [3:37:39<74:01:10, 17.39s/it]

  5%|▍         | 780/16104 [3:37:59<77:21:13, 18.17s/it]

  5%|▍         | 781/16104 [3:38:17<76:20:13, 17.93s/it]
{'loss': 0.5426, 'learning_rate': 1.99821642470738e-06, 'rewards/chosen': -0.5789467096328735, 'rewards/rejected': -0.795496940612793, 'rewards/accuracies': 0.875, 'rewards/margins': 0.21655026078224182, 'policy_logps/rejected': -337.8246765136719, 'policy_logps/chosen': -348.19293212890625, 'referece_logps/rejected': -329.8697509765625, 'referece_logps/chosen': -342.4034729003906, 'logits/rejected': -0.08737124502658844, 'logits/chosen': -0.26033827662467957, 'epoch': 0.29}

  5%|▍         | 782/16104 [3:38:36<78:07:30, 18.36s/it]


  5%|▍         | 784/16104 [3:39:11<75:23:38, 17.72s/it]

  5%|▍         | 785/16104 [3:39:25<71:19:13, 16.76s/it]

  5%|▍         | 786/16104 [3:39:43<72:46:44, 17.10s/it]

  5%|▍         | 787/16104 [3:39:59<71:24:33, 16.78s/it]
[2024-04-05 19:04:13,992] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 788/16104 [3:40:13<67:13:19, 15.80s/it]

  5%|▍         | 789/16104 [3:40:31<70:43:02, 16.62s/it]
{'loss': 0.5406, 'learning_rate': 1.998119076309136e-06, 'rewards/chosen': -1.1346299648284912, 'rewards/rejected': -1.2197338342666626, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08510378003120422, 'policy_logps/rejected': -415.2937927246094, 'policy_logps/chosen': -354.6073303222656, 'referece_logps/rejected': -403.0964660644531, 'referece_logps/chosen': -343.26104736328125, 'logits/rejected': -0.8890732526779175, 'logits/chosen': -0.8486979007720947, 'epoch': 0.29}


  5%|▍         | 791/16104 [3:41:07<73:31:19, 17.28s/it]
{'loss': 0.4996, 'learning_rate': 1.9980943354426915e-06, 'rewards/chosen': -0.5712094902992249, 'rewards/rejected': -1.025106430053711, 'rewards/accuracies': 0.625, 'rewards/margins': 0.45389682054519653, 'policy_logps/rejected': -274.72210693359375, 'policy_logps/chosen': -296.1882629394531, 'referece_logps/rejected': -264.4710388183594, 'referece_logps/chosen': -290.4761962890625, 'logits/rejected': -1.0455541610717773, 'logits/chosen': -0.9715791344642639, 'epoch': 0.29}


  5%|▍         | 793/16104 [3:41:43<76:05:33, 17.89s/it]
[2024-04-05 19:05:57,427] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 794/16104 [3:41:58<72:08:39, 16.96s/it]
{'loss': 0.6341, 'learning_rate': 1.9980569213340582e-06, 'rewards/chosen': -0.8869036436080933, 'rewards/rejected': -0.8395801782608032, 'rewards/accuracies': 0.5, 'rewards/margins': -0.047323428094387054, 'policy_logps/rejected': -402.2259216308594, 'policy_logps/chosen': -437.7702331542969, 'referece_logps/rejected': -393.8301086425781, 'referece_logps/chosen': -428.90118408203125, 'logits/rejected': 0.07804413139820099, 'logits/chosen': 0.04754252731800079, 'epoch': 0.3}
[2024-04-05 19:06:30,825] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 795/16104 [3:42:16<74:13:24, 17.45s/it]

  5%|▍         | 796/16104 [3:42:31<70:33:02, 16.59s/it]

  5%|▍         | 797/16104 [3:42:52<76:55:32, 18.09s/it]


  5%|▍         | 799/16104 [3:43:21<70:14:50, 16.52s/it]
{'loss': 0.6002, 'learning_rate': 1.9979937570294745e-06, 'rewards/chosen': -0.9844176173210144, 'rewards/rejected': -1.199097990989685, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21468037366867065, 'policy_logps/rejected': -449.1108093261719, 'policy_logps/chosen': -386.60601806640625, 'referece_logps/rejected': -437.11981201171875, 'referece_logps/chosen': -376.7618408203125, 'logits/rejected': -0.5950303077697754, 'logits/chosen': -0.5426648855209351, 'epoch': 0.3}


  5%|▍         | 801/16104 [3:43:45<59:33:48, 14.01s/it]

  5%|▍         | 802/16104 [3:43:58<58:06:16, 13.67s/it]

  5%|▍         | 803/16104 [3:44:16<63:41:38, 14.99s/it]
{'loss': 0.4897, 'learning_rate': 1.9979424989114555e-06, 'rewards/chosen': -0.2598825693130493, 'rewards/rejected': -0.720365047454834, 'rewards/accuracies': 0.625, 'rewards/margins': 0.46048250794410706, 'policy_logps/rejected': -430.5152587890625, 'policy_logps/chosen': -409.8440246582031, 'referece_logps/rejected': -423.3116149902344, 'referece_logps/chosen': -407.2451477050781, 'logits/rejected': 0.24050243198871613, 'logits/chosen': 0.28130102157592773, 'epoch': 0.3}

  5%|▍         | 804/16104 [3:44:29<61:08:15, 14.39s/it]

  5%|▍         | 805/16104 [3:44:46<64:35:44, 15.20s/it]

  5%|▌         | 806/16104 [3:45:01<64:13:50, 15.12s/it]


  5%|▌         | 808/16104 [3:45:43<77:41:51, 18.29s/it]
{'loss': 0.5283, 'learning_rate': 1.99787751797542e-06, 'rewards/chosen': -0.7522737979888916, 'rewards/rejected': -1.3421683311462402, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5898944735527039, 'policy_logps/rejected': -299.8613586425781, 'policy_logps/chosen': -382.0357666015625, 'referece_logps/rejected': -286.4397277832031, 'referece_logps/chosen': -374.5129699707031, 'logits/rejected': -0.5679788589477539, 'logits/chosen': -0.5642416477203369, 'epoch': 0.3}


  5%|▌         | 810/16104 [3:46:15<72:47:08, 17.13s/it]
{'loss': 0.6549, 'learning_rate': 1.9978512430358297e-06, 'rewards/chosen': -0.4477465748786926, 'rewards/rejected': -0.7299142479896545, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2821677327156067, 'policy_logps/rejected': -301.52996826171875, 'policy_logps/chosen': -402.3729248046875, 'referece_logps/rejected': -294.2308044433594, 'referece_logps/chosen': -397.89544677734375, 'logits/rejected': -0.8024214506149292, 'logits/chosen': -0.798306941986084, 'epoch': 0.3}

  5%|▌         | 811/16104 [3:46:35<75:38:14, 17.81s/it]


  5%|▌         | 813/16104 [3:47:14<79:39:15, 18.75s/it]
{'loss': 0.5296, 'learning_rate': 1.9978115278913075e-06, 'rewards/chosen': -0.8012210726737976, 'rewards/rejected': -1.9026910066604614, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1014699935913086, 'policy_logps/rejected': -409.7658996582031, 'policy_logps/chosen': -554.7244262695312, 'referece_logps/rejected': -390.739013671875, 'referece_logps/chosen': -546.7122192382812, 'logits/rejected': -0.25216007232666016, 'logits/chosen': -0.19164180755615234, 'epoch': 0.3}
[2024-04-05 19:11:49,256] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▌         | 814/16104 [3:47:35<82:01:54, 19.31s/it]


  5%|▌         | 816/16104 [3:48:03<72:12:50, 17.00s/it]

  5%|▌         | 817/16104 [3:48:14<64:11:11, 15.12s/it]
{'loss': 0.6361, 'learning_rate': 1.9977580092822155e-06, 'rewards/chosen': -0.796203076839447, 'rewards/rejected': -0.9892494678497314, 'rewards/accuracies': 0.625, 'rewards/margins': 0.19304640591144562, 'policy_logps/rejected': -342.01171875, 'policy_logps/chosen': -341.5325927734375, 'referece_logps/rejected': -332.11920166015625, 'referece_logps/chosen': -333.570556640625, 'logits/rejected': -0.819861650466919, 'logits/chosen': -0.7675907015800476, 'epoch': 0.3}


  5%|▌         | 819/16104 [3:48:48<68:16:16, 16.08s/it]
{'loss': 0.5859, 'learning_rate': 1.9977310078089485e-06, 'rewards/chosen': -0.7906169891357422, 'rewards/rejected': -1.1011261940002441, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3105091154575348, 'policy_logps/rejected': -440.80023193359375, 'policy_logps/chosen': -556.1600341796875, 'referece_logps/rejected': -429.7889709472656, 'referece_logps/chosen': -548.2538452148438, 'logits/rejected': -0.13897347450256348, 'logits/chosen': -0.13215932250022888, 'epoch': 0.31}

  5%|▌         | 820/16104 [3:48:59<61:51:21, 14.57s/it]


  5%|▌         | 822/16104 [3:49:29<61:29:49, 14.49s/it]

  5%|▌         | 823/16104 [3:49:40<56:43:37, 13.36s/it]
{'loss': 0.5585, 'learning_rate': 1.997676520546818e-06, 'rewards/chosen': -0.7831337451934814, 'rewards/rejected': -1.0989192724227905, 'rewards/accuracies': 0.375, 'rewards/margins': 0.31578558683395386, 'policy_logps/rejected': -427.5766296386719, 'policy_logps/chosen': -507.7037048339844, 'referece_logps/rejected': -416.5874328613281, 'referece_logps/chosen': -499.872314453125, 'logits/rejected': 0.6701050400733948, 'logits/chosen': 0.7882448434829712, 'epoch': 0.31}


  5%|▌         | 825/16104 [3:50:04<53:22:38, 12.58s/it]
{'loss': 0.5954, 'learning_rate': 1.997649034766771e-06, 'rewards/chosen': -0.7351146936416626, 'rewards/rejected': -0.8319952487945557, 'rewards/accuracies': 0.5, 'rewards/margins': 0.09688061475753784, 'policy_logps/rejected': -323.2125244140625, 'policy_logps/chosen': -310.7695617675781, 'referece_logps/rejected': -314.8925476074219, 'referece_logps/chosen': -303.4184265136719, 'logits/rejected': -0.8279492855072021, 'logits/chosen': -1.0312644243240356, 'epoch': 0.31}


  5%|▌         | 827/16104 [3:50:26<50:09:42, 11.82s/it]
{'loss': 0.6452, 'learning_rate': 1.997621387559991e-06, 'rewards/chosen': -0.4783931076526642, 'rewards/rejected': -0.8705217838287354, 'rewards/accuracies': 0.75, 'rewards/margins': 0.39212867617607117, 'policy_logps/rejected': -389.36138916015625, 'policy_logps/chosen': -352.8104248046875, 'referece_logps/rejected': -380.65618896484375, 'referece_logps/chosen': -348.0264587402344, 'logits/rejected': -0.6701726913452148, 'logits/chosen': -0.6893020868301392, 'epoch': 0.31}


  5%|▌         | 829/16104 [3:50:58<59:08:35, 13.94s/it]
{'loss': 0.5769, 'learning_rate': 1.997593578930951e-06, 'rewards/chosen': -0.9743896722793579, 'rewards/rejected': -1.1819546222686768, 'rewards/accuracies': 0.625, 'rewards/margins': 0.20756493508815765, 'policy_logps/rejected': -384.56964111328125, 'policy_logps/chosen': -416.68572998046875, 'referece_logps/rejected': -372.7501220703125, 'referece_logps/chosen': -406.9418029785156, 'logits/rejected': -0.6261826753616333, 'logits/chosen': -0.6031438112258911, 'epoch': 0.31}


  5%|▌         | 831/16104 [3:51:28<60:48:15, 14.33s/it]

  5%|▌         | 832/16104 [3:51:44<62:47:23, 14.80s/it]
{'loss': 0.5608, 'learning_rate': 1.9975515633305037e-06, 'rewards/chosen': -0.62117600440979, 'rewards/rejected': -1.2125991582870483, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5914232134819031, 'policy_logps/rejected': -385.864990234375, 'policy_logps/chosen': -295.7132263183594, 'referece_logps/rejected': -373.7390441894531, 'referece_logps/chosen': -289.5014343261719, 'logits/rejected': -0.500805675983429, 'logits/chosen': -0.4835384786128998, 'epoch': 0.31}

  5%|▌         | 833/16104 [3:51:59<63:03:53, 14.87s/it]


  5%|▌         | 835/16104 [3:52:22<56:01:22, 13.21s/it]
{'loss': 0.6583, 'learning_rate': 1.997509184555398e-06, 'rewards/chosen': -1.0538355112075806, 'rewards/rejected': -1.083858609199524, 'rewards/accuracies': 0.5, 'rewards/margins': 0.030022993683815002, 'policy_logps/rejected': -471.7068176269531, 'policy_logps/chosen': -590.9754028320312, 'referece_logps/rejected': -460.8682861328125, 'referece_logps/chosen': -580.43701171875, 'logits/rejected': -1.1542093753814697, 'logits/chosen': -1.0796689987182617, 'epoch': 0.31}


  5%|▌         | 837/16104 [3:52:58<66:43:36, 15.73s/it]

  5%|▌         | 838/16104 [3:53:10<61:47:39, 14.57s/it]
{'loss': 0.5317, 'learning_rate': 1.9974664426210636e-06, 'rewards/chosen': -0.5007472634315491, 'rewards/rejected': -1.4981974363327026, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9974501132965088, 'policy_logps/rejected': -421.26715087890625, 'policy_logps/chosen': -380.4681701660156, 'referece_logps/rejected': -406.2851867675781, 'referece_logps/chosen': -375.460693359375, 'logits/rejected': 0.5238966941833496, 'logits/chosen': 0.5686111450195312, 'epoch': 0.31}


  5%|▌         | 840/16104 [3:53:40<63:48:56, 15.05s/it]

  5%|▌         | 841/16104 [3:53:50<58:08:02, 13.71s/it]

  5%|▌         | 842/16104 [3:54:04<58:22:53, 13.77s/it]

  5%|▌         | 843/16104 [3:54:16<56:02:10, 13.22s/it]
{'loss': 0.573, 'learning_rate': 1.9973943990856535e-06, 'rewards/chosen': -0.9770148992538452, 'rewards/rejected': -1.182495355606079, 'rewards/accuracies': 0.625, 'rewards/margins': 0.20548047125339508, 'policy_logps/rejected': -297.97088623046875, 'policy_logps/chosen': -257.0791320800781, 'referece_logps/rejected': -286.1459045410156, 'referece_logps/chosen': -247.30897521972656, 'logits/rejected': -0.3452712595462799, 'logits/chosen': -0.37311065196990967, 'epoch': 0.31}


  5%|▌         | 845/16104 [3:54:48<64:28:03, 15.21s/it]

  5%|▌         | 846/16104 [3:55:00<59:51:55, 14.12s/it]

  5%|▌         | 847/16104 [3:55:20<67:01:01, 15.81s/it]

  5%|▌         | 848/16104 [3:55:38<69:53:01, 16.49s/it]

  5%|▌         | 849/16104 [3:55:54<69:30:04, 16.40s/it]
{'loss': 0.593, 'learning_rate': 1.9973066154191046e-06, 'rewards/chosen': -0.9257381558418274, 'rewards/rejected': -1.6308214664459229, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7050833106040955, 'policy_logps/rejected': -281.10870361328125, 'policy_logps/chosen': -306.46563720703125, 'referece_logps/rejected': -264.8005065917969, 'referece_logps/chosen': -297.2082824707031, 'logits/rejected': -0.7980828285217285, 'logits/chosen': -0.7721395492553711, 'epoch': 0.32}

  5%|▌         | 850/16104 [3:56:14<73:36:46, 17.37s/it]


  5%|▌         | 852/16104 [3:56:46<70:24:03, 16.62s/it]
{'loss': 0.5477, 'learning_rate': 1.9972621789495863e-06, 'rewards/chosen': -0.49650850892066956, 'rewards/rejected': -0.8670259714126587, 'rewards/accuracies': 0.75, 'rewards/margins': 0.37051743268966675, 'policy_logps/rejected': -229.18515014648438, 'policy_logps/chosen': -311.6490478515625, 'referece_logps/rejected': -220.514892578125, 'referece_logps/chosen': -306.6839599609375, 'logits/rejected': -0.7360805869102478, 'logits/chosen': -0.6712937355041504, 'epoch': 0.32}

  5%|▌         | 853/16104 [3:57:05<73:20:46, 17.31s/it]


  5%|▌         | 855/16104 [3:57:38<72:05:33, 17.02s/it]
{'loss': 0.5424, 'learning_rate': 1.997217379410765e-06, 'rewards/chosen': -0.7986823916435242, 'rewards/rejected': -1.3337639570236206, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5350816249847412, 'policy_logps/rejected': -319.49603271484375, 'policy_logps/chosen': -347.44189453125, 'referece_logps/rejected': -306.15838623046875, 'referece_logps/chosen': -339.4550476074219, 'logits/rejected': -0.18588973581790924, 'logits/chosen': -0.2374916821718216, 'epoch': 0.32}

  5%|▌         | 856/16104 [3:57:56<72:31:53, 17.12s/it]

  5%|▌         | 857/16104 [3:58:13<73:08:33, 17.27s/it]

  5%|▌         | 858/16104 [3:58:36<79:39:00, 18.81s/it]


  5%|▌         | 860/16104 [3:59:12<77:40:12, 18.34s/it]
{'loss': 0.5146, 'learning_rate': 1.9971419067364148e-06, 'rewards/chosen': -0.6646953821182251, 'rewards/rejected': -1.2215087413787842, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5568134188652039, 'policy_logps/rejected': -516.340576171875, 'policy_logps/chosen': -512.3147583007812, 'referece_logps/rejected': -504.1254577636719, 'referece_logps/chosen': -505.6678466796875, 'logits/rejected': -0.5955670475959778, 'logits/chosen': -0.46980398893356323, 'epoch': 0.32}


  5%|▌         | 862/16104 [3:59:47<76:53:34, 18.16s/it]
{'loss': 0.638, 'learning_rate': 1.9971114353092026e-06, 'rewards/chosen': -1.06072199344635, 'rewards/rejected': -1.2016645669937134, 'rewards/accuracies': 0.75, 'rewards/margins': 0.14094257354736328, 'policy_logps/rejected': -350.7740783691406, 'policy_logps/chosen': -390.98883056640625, 'referece_logps/rejected': -338.7574157714844, 'referece_logps/chosen': -380.381591796875, 'logits/rejected': -1.2910120487213135, 'logits/chosen': -1.3045098781585693, 'epoch': 0.32}


  5%|▌         | 864/16104 [4:00:10<62:44:35, 14.82s/it]
{'loss': 0.6341, 'learning_rate': 1.997080802542244e-06, 'rewards/chosen': -0.5476259589195251, 'rewards/rejected': -1.3390393257141113, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7914133071899414, 'policy_logps/rejected': -379.1240539550781, 'policy_logps/chosen': -353.56207275390625, 'referece_logps/rejected': -365.7336120605469, 'referece_logps/chosen': -348.0858154296875, 'logits/rejected': -0.07522836327552795, 'logits/chosen': -0.0640491396188736, 'epoch': 0.32}

  5%|▌         | 865/16104 [4:00:29<68:16:32, 16.13s/it]


  5%|▌         | 867/16104 [4:01:05<70:56:16, 16.76s/it]

  5%|▌         | 868/16104 [4:01:22<71:40:50, 16.94s/it]
{'loss': 0.5793, 'learning_rate': 1.9970190530089426e-06, 'rewards/chosen': -0.4416782855987549, 'rewards/rejected': -1.3420370817184448, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9003588557243347, 'policy_logps/rejected': -419.40234375, 'policy_logps/chosen': -327.84625244140625, 'referece_logps/rejected': -405.9819641113281, 'referece_logps/chosen': -323.4294738769531, 'logits/rejected': -0.2643601894378662, 'logits/chosen': -0.17448297142982483, 'epoch': 0.32}


  5%|▌         | 870/16104 [4:01:55<68:57:44, 16.30s/it]

  5%|▌         | 871/16104 [4:02:15<73:51:35, 17.46s/it]

  5%|▌         | 872/16104 [4:02:28<69:00:23, 16.31s/it]
{'loss': 0.506, 'learning_rate': 1.9969566581764753e-06, 'rewards/chosen': -0.65767502784729, 'rewards/rejected': -1.7760615348815918, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1183866262435913, 'policy_logps/rejected': -284.70404052734375, 'policy_logps/chosen': -486.6019287109375, 'referece_logps/rejected': -266.9434509277344, 'referece_logps/chosen': -480.0251770019531, 'logits/rejected': -0.43655669689178467, 'logits/chosen': -0.5143200755119324, 'epoch': 0.32}

  5%|▌         | 873/16104 [4:02:42<65:11:48, 15.41s/it]

  5%|▌         | 874/16104 [4:02:54<60:57:55, 14.41s/it]


  5%|▌         | 876/16104 [4:03:33<72:17:20, 17.09s/it]
{'loss': 0.5009, 'learning_rate': 1.996893618085227e-06, 'rewards/chosen': -0.7077094316482544, 'rewards/rejected': -1.4779670238494873, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7702576518058777, 'policy_logps/rejected': -222.025390625, 'policy_logps/chosen': -320.62127685546875, 'referece_logps/rejected': -207.24571228027344, 'referece_logps/chosen': -313.5442199707031, 'logits/rejected': -1.013695478439331, 'logits/chosen': -1.083337426185608, 'epoch': 0.33}

  5%|▌         | 877/16104 [4:03:51<74:27:29, 17.60s/it]


  5%|▌         | 879/16104 [4:04:21<68:43:06, 16.25s/it]
{'loss': 0.548, 'learning_rate': 1.9968459145902443e-06, 'rewards/chosen': -0.6923829317092896, 'rewards/rejected': -1.3201934099197388, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6278104782104492, 'policy_logps/rejected': -296.86297607421875, 'policy_logps/chosen': -269.6430358886719, 'referece_logps/rejected': -283.66107177734375, 'referece_logps/chosen': -262.7192077636719, 'logits/rejected': 0.19748619198799133, 'logits/chosen': 0.05369076877832413, 'epoch': 0.33}

  5%|▌         | 880/16104 [4:04:40<71:34:57, 16.93s/it]

  5%|▌         | 881/16104 [4:04:54<68:30:00, 16.20s/it]


  5%|▌         | 883/16104 [4:05:35<77:36:43, 18.36s/it]

  5%|▌         | 884/16104 [4:05:51<74:21:12, 17.59s/it]

  5%|▌         | 885/16104 [4:06:13<79:22:53, 18.78s/it]
{'loss': 0.5513, 'learning_rate': 1.996749418864512e-06, 'rewards/chosen': -1.2043612003326416, 'rewards/rejected': -1.4533275365829468, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2489662766456604, 'policy_logps/rejected': -322.6789855957031, 'policy_logps/chosen': -498.56890869140625, 'referece_logps/rejected': -308.14569091796875, 'referece_logps/chosen': -486.5252685546875, 'logits/rejected': -0.24584200978279114, 'logits/chosen': -0.2685871124267578, 'epoch': 0.33}

  6%|▌         | 886/16104 [4:06:36<85:09:55, 20.15s/it]

  6%|▌         | 887/16104 [4:06:56<84:51:08, 20.07s/it]


  6%|▌         | 889/16104 [4:07:29<77:56:04, 18.44s/it]
{'loss': 0.4948, 'learning_rate': 1.9966842819661714e-06, 'rewards/chosen': -0.6637814044952393, 'rewards/rejected': -1.460176944732666, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7963956594467163, 'policy_logps/rejected': -412.4547424316406, 'policy_logps/chosen': -393.1306457519531, 'referece_logps/rejected': -397.85296630859375, 'referece_logps/chosen': -386.49285888671875, 'logits/rejected': -0.18263843655586243, 'logits/chosen': -0.11557433009147644, 'epoch': 0.33}


  6%|▌         | 891/16104 [4:08:01<72:53:55, 17.25s/it]
{'loss': 0.4631, 'learning_rate': 1.996651471608415e-06, 'rewards/chosen': -0.7840760350227356, 'rewards/rejected': -1.7812789678573608, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9972028136253357, 'policy_logps/rejected': -318.0146484375, 'policy_logps/chosen': -351.8836364746094, 'referece_logps/rejected': -300.2018737792969, 'referece_logps/chosen': -344.0428771972656, 'logits/rejected': -0.6309309005737305, 'logits/chosen': -0.5590934753417969, 'epoch': 0.33}

  6%|▌         | 892/16104 [4:08:16<70:19:40, 16.64s/it]

  6%|▌         | 893/16104 [4:08:40<79:42:50, 18.87s/it]

  6%|▌         | 894/16104 [4:08:58<78:19:07, 18.54s/it]


  6%|▌         | 896/16104 [4:09:33<76:11:23, 18.04s/it]

  6%|▌         | 897/16104 [4:09:53<78:37:05, 18.61s/it]
{'loss': 0.5173, 'learning_rate': 1.9965520729645895e-06, 'rewards/chosen': -0.9626612663269043, 'rewards/rejected': -1.5290615558624268, 'rewards/accuracies': 0.75, 'rewards/margins': 0.566400408744812, 'policy_logps/rejected': -245.7527313232422, 'policy_logps/chosen': -368.4896240234375, 'referece_logps/rejected': -230.46209716796875, 'referece_logps/chosen': -358.8630065917969, 'logits/rejected': -1.3723225593566895, 'logits/chosen': -1.3814514875411987, 'epoch': 0.33}

  6%|▌         | 898/16104 [4:10:15<82:08:24, 19.45s/it]

  6%|▌         | 899/16104 [4:10:36<84:17:02, 19.96s/it]
[2024-04-05 19:35:12,368] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  6%|▌         | 901/16104 [4:11:18<85:46:43, 20.31s/it]
[2024-04-05 19:35:32,196] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 902/16104 [4:11:39<87:38:19, 20.75s/it]
{'loss': 0.581, 'learning_rate': 1.9964681321668095e-06, 'rewards/chosen': -0.744377076625824, 'rewards/rejected': -1.1516036987304688, 'rewards/accuracies': 0.5, 'rewards/margins': 0.40722665190696716, 'policy_logps/rejected': -446.8565368652344, 'policy_logps/chosen': -442.40484619140625, 'referece_logps/rejected': -435.3404541015625, 'referece_logps/chosen': -434.9610900878906, 'logits/rejected': -0.4846901595592499, 'logits/chosen': -0.5024456977844238, 'epoch': 0.34}


  6%|▌         | 904/16104 [4:12:17<83:19:08, 19.73s/it]
{'loss': 0.5689, 'learning_rate': 1.996434273680533e-06, 'rewards/chosen': -1.1053539514541626, 'rewards/rejected': -1.187809944152832, 'rewards/accuracies': 0.625, 'rewards/margins': 0.08245597034692764, 'policy_logps/rejected': -311.9942932128906, 'policy_logps/chosen': -290.31268310546875, 'referece_logps/rejected': -300.1162109375, 'referece_logps/chosen': -279.2591552734375, 'logits/rejected': -1.1741690635681152, 'logits/chosen': -1.1784343719482422, 'epoch': 0.34}

  6%|▌         | 905/16104 [4:12:39<85:37:47, 20.28s/it]


  6%|▌         | 907/16104 [4:13:19<85:38:28, 20.29s/it]

  6%|▌         | 908/16104 [4:13:36<80:50:48, 19.15s/it]
[2024-04-05 19:37:50,200] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 909/16104 [4:13:57<84:03:21, 19.91s/it]

  6%|▌         | 910/16104 [4:14:15<81:42:49, 19.36s/it]

  6%|▌         | 911/16104 [4:14:31<77:33:10, 18.38s/it]
{'loss': 0.4457, 'learning_rate': 1.9963144993271165e-06, 'rewards/chosen': -0.5912052392959595, 'rewards/rejected': -1.3737417459487915, 'rewards/accuracies': 0.75, 'rewards/margins': 0.782536506652832, 'policy_logps/rejected': -282.89178466796875, 'policy_logps/chosen': -395.17999267578125, 'referece_logps/rejected': -269.15435791015625, 'referece_logps/chosen': -389.2679138183594, 'logits/rejected': -1.0965056419372559, 'logits/chosen': -1.0426160097122192, 'epoch': 0.34}

  6%|▌         | 912/16104 [4:14:50<78:00:54, 18.49s/it]
[2024-04-05 19:39:22,710] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  6%|▌         | 914/16104 [4:15:28<78:59:12, 18.72s/it]

  6%|▌         | 915/16104 [4:15:50<83:02:20, 19.68s/it]
{'loss': 0.604, 'learning_rate': 1.9962451701648167e-06, 'rewards/chosen': -0.4773588180541992, 'rewards/rejected': -1.342036485671997, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8646776676177979, 'policy_logps/rejected': -289.0767517089844, 'policy_logps/chosen': -371.9910888671875, 'referece_logps/rejected': -275.6564025878906, 'referece_logps/chosen': -367.217529296875, 'logits/rejected': -0.03435643017292023, 'logits/chosen': -0.14297175407409668, 'epoch': 0.34}


  6%|▌         | 917/16104 [4:16:24<77:33:08, 18.38s/it]
{'loss': 0.5404, 'learning_rate': 1.9962102637814892e-06, 'rewards/chosen': -0.7971451282501221, 'rewards/rejected': -1.2707573175430298, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4736122786998749, 'policy_logps/rejected': -539.204833984375, 'policy_logps/chosen': -349.79022216796875, 'referece_logps/rejected': -526.4971923828125, 'referece_logps/chosen': -341.8187561035156, 'logits/rejected': -1.9138364791870117, 'logits/chosen': -1.8517898321151733, 'epoch': 0.34}

  6%|▌         | 918/16104 [4:16:44<80:04:58, 18.98s/it]


  6%|▌         | 920/16104 [4:17:28<85:54:28, 20.37s/it]
{'loss': 0.6264, 'learning_rate': 1.996157601969651e-06, 'rewards/chosen': -1.2556582689285278, 'rewards/rejected': -1.5095998048782349, 'rewards/accuracies': 0.5, 'rewards/margins': 0.25394153594970703, 'policy_logps/rejected': -300.0562744140625, 'policy_logps/chosen': -434.2277526855469, 'referece_logps/rejected': -284.9602966308594, 'referece_logps/chosen': -421.6711120605469, 'logits/rejected': -0.558627188205719, 'logits/chosen': -0.7864561080932617, 'epoch': 0.34}

  6%|▌         | 921/16104 [4:17:44<81:04:56, 19.23s/it]

  6%|▌         | 922/16104 [4:18:06<84:42:28, 20.09s/it]

  6%|▌         | 923/16104 [4:18:27<85:24:49, 20.25s/it]


  6%|▌         | 925/16104 [4:19:10<88:16:06, 20.93s/it]

  6%|▌         | 926/16104 [4:19:30<86:50:16, 20.60s/it]
{'loss': 0.5187, 'learning_rate': 1.9960511903637875e-06, 'rewards/chosen': -0.9631630182266235, 'rewards/rejected': -1.3148404359817505, 'rewards/accuracies': 0.75, 'rewards/margins': 0.35167741775512695, 'policy_logps/rejected': -269.5220031738281, 'policy_logps/chosen': -291.3137512207031, 'referece_logps/rejected': -256.37359619140625, 'referece_logps/chosen': -281.68206787109375, 'logits/rejected': -1.4120070934295654, 'logits/chosen': -1.400528907775879, 'epoch': 0.35}

  6%|▌         | 927/16104 [4:19:43<76:57:52, 18.26s/it]


  6%|▌         | 929/16104 [4:20:08<64:08:52, 15.22s/it]
{'loss': 0.5798, 'learning_rate': 1.995997440608503e-06, 'rewards/chosen': -1.2112287282943726, 'rewards/rejected': -1.2642767429351807, 'rewards/accuracies': 0.5, 'rewards/margins': 0.053047940135002136, 'policy_logps/rejected': -448.9029541015625, 'policy_logps/chosen': -360.44287109375, 'referece_logps/rejected': -436.26019287109375, 'referece_logps/chosen': -348.33056640625, 'logits/rejected': -0.48630291223526, 'logits/chosen': -0.15979021787643433, 'epoch': 0.35}

  6%|▌         | 930/16104 [4:20:22<62:59:25, 14.94s/it]

  6%|▌         | 931/16104 [4:20:33<57:40:43, 13.69s/it]

  6%|▌         | 932/16104 [4:20:45<55:33:22, 13.18s/it]

  6%|▌         | 933/16104 [4:21:01<59:02:27, 14.01s/it]

  6%|▌         | 934/16104 [4:21:23<69:08:43, 16.41s/it]


  6%|▌         | 936/16104 [4:21:58<70:40:02, 16.77s/it]
{'loss': 0.5797, 'learning_rate': 1.995870614401362e-06, 'rewards/chosen': -0.4731139838695526, 'rewards/rejected': -0.9956516623497009, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5225375890731812, 'policy_logps/rejected': -336.9344787597656, 'policy_logps/chosen': -431.0986328125, 'referece_logps/rejected': -326.97796630859375, 'referece_logps/chosen': -426.3675537109375, 'logits/rejected': -0.22636161744594574, 'logits/chosen': -0.2511996030807495, 'epoch': 0.35}

  6%|▌         | 937/16104 [4:22:15<71:22:33, 16.94s/it]

  6%|▌         | 938/16104 [4:22:36<75:50:48, 18.00s/it]


  6%|▌         | 940/16104 [4:23:06<68:17:07, 16.21s/it]
{'loss': 0.4812, 'learning_rate': 1.995797256002498e-06, 'rewards/chosen': -0.5468648672103882, 'rewards/rejected': -1.2684342861175537, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7215694189071655, 'policy_logps/rejected': -257.5435485839844, 'policy_logps/chosen': -592.7894897460938, 'referece_logps/rejected': -244.8592071533203, 'referece_logps/chosen': -587.3208618164062, 'logits/rejected': -0.510129451751709, 'logits/chosen': -0.8663135766983032, 'epoch': 0.35}


  6%|▌         | 942/16104 [4:23:40<68:13:50, 16.20s/it]
{'loss': 0.6285, 'learning_rate': 1.995760335109438e-06, 'rewards/chosen': -0.42767924070358276, 'rewards/rejected': -1.014305830001831, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5866266489028931, 'policy_logps/rejected': -426.4100341796875, 'policy_logps/chosen': -377.0749816894531, 'referece_logps/rejected': -416.2669677734375, 'referece_logps/chosen': -372.7982177734375, 'logits/rejected': -0.29009145498275757, 'logits/chosen': -0.39827650785446167, 'epoch': 0.35}

  6%|▌         | 943/16104 [4:23:56<68:33:11, 16.28s/it]

  6%|▌         | 944/16104 [4:24:13<69:21:24, 16.47s/it]

  6%|▌         | 945/16104 [4:24:29<67:45:06, 16.09s/it]


  6%|▌         | 947/16104 [4:25:06<74:29:25, 17.69s/it]
{'loss': 0.5034, 'learning_rate': 1.9956673279849854e-06, 'rewards/chosen': -0.5285230875015259, 'rewards/rejected': -0.9403795003890991, 'rewards/accuracies': 0.625, 'rewards/margins': 0.411856472492218, 'policy_logps/rejected': -348.26171875, 'policy_logps/chosen': -566.7469482421875, 'referece_logps/rejected': -338.85791015625, 'referece_logps/chosen': -561.4617309570312, 'logits/rejected': -0.610443115234375, 'logits/chosen': -0.6750489473342896, 'epoch': 0.35}

  6%|▌         | 948/16104 [4:25:19<68:36:16, 16.30s/it]

  6%|▌         | 949/16104 [4:25:37<70:34:09, 16.76s/it]

  6%|▌         | 950/16104 [4:26:00<77:49:02, 18.49s/it]

  6%|▌         | 951/16104 [4:26:17<76:53:51, 18.27s/it]

  6%|▌         | 952/16104 [4:26:29<68:23:09, 16.25s/it]

  6%|▌         | 953/16104 [4:26:48<71:56:03, 17.09s/it]
[2024-04-05 19:51:24,850] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 954/16104 [4:27:10<78:21:02, 18.62s/it]

  6%|▌         | 955/16104 [4:27:23<71:03:28, 16.89s/it]

  6%|▌         | 956/16104 [4:27:35<65:15:14, 15.51s/it]

  6%|▌         | 957/16104 [4:27:52<67:16:39, 15.99s/it]

  6%|▌         | 958/16104 [4:28:11<70:33:11, 16.77s/it]

  6%|▌         | 959/16104 [4:28:30<73:03:57, 17.37s/it]

  6%|▌         | 960/16104 [4:28:49<75:42:02, 18.00s/it]

  6%|▌         | 961/16104 [4:29:03<70:24:14, 16.74s/it]

  6%|▌         | 962/16104 [4:29:19<68:57:30, 16.39s/it]

  6%|▌         | 963/16104 [4:29:30<62:57:37, 14.97s/it]

  6%|▌         | 964/16104 [4:29:47<64:31:39, 15.34s/it]

  6%|▌         | 965/16104 [4:30:02<65:05:00, 15.48s/it]

  6%|▌         | 966/16104 [4:30:13<58:54:17, 14.01s/it]

  6%|▌         | 967/16104 [4:30:34<67:49:57, 16.13s/it]

  6%|▌         | 968/16104 [4:30:50<67:32:23, 16.06s/it]
[2024-04-05 19:55:25,728] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 969/16104 [4:31:11<74:00:18, 17.60s/it]

  6%|▌         | 970/16104 [4:31:25<69:18:28, 16.49s/it]
[2024-04-05 19:55:57,538] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 971/16104 [4:31:43<71:07:16, 16.92s/it]

  6%|▌         | 972/16104 [4:31:59<69:56:14, 16.64s/it]

  6%|▌         | 973/16104 [4:32:10<62:23:20, 14.84s/it]

  6%|▌         | 974/16104 [4:32:20<57:08:52, 13.60s/it]

  6%|▌         | 975/16104 [4:32:31<53:27:38, 12.72s/it]

  6%|▌         | 976/16104 [4:32:42<50:52:09, 12.11s/it]

  6%|▌         | 977/16104 [4:32:57<55:17:40, 13.16s/it]

  6%|▌         | 978/16104 [4:33:11<56:14:37, 13.39s/it]

  6%|▌         | 979/16104 [4:33:24<55:38:57, 13.25s/it]

  6%|▌         | 980/16104 [4:33:35<53:02:24, 12.63s/it]

  6%|▌         | 981/16104 [4:33:46<50:41:28, 12.07s/it]

  6%|▌         | 982/16104 [4:33:57<49:01:16, 11.67s/it]

  6%|▌         | 983/16104 [4:34:08<48:03:26, 11.44s/it]

  6%|▌         | 984/16104 [4:34:26<56:51:58, 13.54s/it]

  6%|▌         | 985/16104 [4:34:43<61:41:17, 14.69s/it]

  6%|▌         | 986/16104 [4:34:56<59:20:40, 14.13s/it]

  6%|▌         | 987/16104 [4:35:09<57:40:46, 13.74s/it]

  6%|▌         | 988/16104 [4:35:31<68:04:29, 16.21s/it]

  6%|▌         | 989/16104 [4:35:48<68:39:45, 16.35s/it]

  6%|▌         | 990/16104 [4:36:04<68:27:15, 16.31s/it]

  6%|▌         | 991/16104 [4:36:19<67:08:43, 15.99s/it]

  6%|▌         | 992/16104 [4:36:32<63:29:45, 15.13s/it]

  6%|▌         | 993/16104 [4:36:53<70:49:06, 16.87s/it]

  6%|▌         | 994/16104 [4:37:10<70:34:24, 16.81s/it]
[2024-04-05 20:01:47,115] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 995/16104 [4:37:32<77:47:09, 18.53s/it]

  6%|▌         | 996/16104 [4:37:52<79:10:03, 18.86s/it]

  6%|▌         | 997/16104 [4:38:11<79:45:02, 19.00s/it]

  6%|▌         | 998/16104 [4:38:27<75:32:59, 18.00s/it]

  6%|▌         | 999/16104 [4:38:48<79:41:35, 18.99s/it]

  6%|▌         | 1000/16104 [4:39:11<84:07:20, 20.05s/it]

  6%|▌         | 1001/16104 [4:39:49<106:24:45, 25.36s/it]

  6%|▌         | 1002/16104 [4:40:08<99:23:52, 23.69s/it]

  6%|▌         | 1003/16104 [4:40:26<91:36:22, 21.84s/it]

  6%|▌         | 1004/16104 [4:40:43<85:08:57, 20.30s/it]

  6%|▌         | 1005/16104 [4:41:00<81:16:34, 19.38s/it]
[2024-04-05 20:05:36,687] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 1006/16104 [4:41:22<84:42:13, 20.20s/it]

  6%|▋         | 1007/16104 [4:41:42<84:06:40, 20.06s/it]


  6%|▋         | 1009/16104 [4:42:20<82:40:18, 19.72s/it]

  6%|▋         | 1010/16104 [4:42:39<81:16:41, 19.39s/it]
[2024-04-05 20:06:53,515] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1011/16104 [4:42:52<73:25:35, 17.51s/it]

  6%|▋         | 1012/16104 [4:43:11<75:35:51, 18.03s/it]

  6%|▋         | 1013/16104 [4:43:26<71:48:47, 17.13s/it]

  6%|▋         | 1014/16104 [4:43:47<76:05:53, 18.15s/it]

  6%|▋         | 1015/16104 [4:44:03<73:08:34, 17.45s/it]

  6%|▋         | 1016/16104 [4:44:16<68:00:13, 16.23s/it]

  6%|▋         | 1017/16104 [4:44:40<77:15:56, 18.44s/it]
[2024-04-05 20:08:54,247] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1018/16104 [4:44:55<73:24:51, 17.52s/it]
[2024-04-05 20:09:09,624] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1019/16104 [4:45:17<78:36:36, 18.76s/it]

  6%|▋         | 1020/16104 [4:45:37<80:15:57, 19.16s/it]

  6%|▋         | 1021/16104 [4:45:57<81:15:29, 19.39s/it]

  6%|▋         | 1022/16104 [4:46:09<72:47:23, 17.37s/it]

  6%|▋         | 1023/16104 [4:46:31<78:39:51, 18.78s/it]

  6%|▋         | 1024/16104 [4:46:54<83:03:39, 19.83s/it]

  6%|▋         | 1025/16104 [4:47:05<72:08:39, 17.22s/it]

  6%|▋         | 1026/16104 [4:47:29<80:16:17, 19.17s/it]

  6%|▋         | 1027/16104 [4:47:48<80:11:37, 19.15s/it]

  6%|▋         | 1028/16104 [4:47:58<69:36:50, 16.62s/it]

  6%|▋         | 1029/16104 [4:48:13<66:41:04, 15.92s/it]

  6%|▋         | 1030/16104 [4:48:26<63:30:07, 15.17s/it]

  6%|▋         | 1031/16104 [4:48:39<60:53:20, 14.54s/it]

  6%|▋         | 1032/16104 [4:48:56<63:12:42, 15.10s/it]

  6%|▋         | 1033/16104 [4:49:18<72:23:22, 17.29s/it]

  6%|▋         | 1034/16104 [4:49:30<65:57:43, 15.76s/it]

  6%|▋         | 1035/16104 [4:49:51<72:38:06, 17.35s/it]

  6%|▋         | 1036/16104 [4:50:06<69:39:23, 16.64s/it]

  6%|▋         | 1037/16104 [4:50:17<62:20:11, 14.89s/it]

  6%|▋         | 1038/16104 [4:50:28<57:08:46, 13.66s/it]

  6%|▋         | 1039/16104 [4:50:38<53:27:44, 12.78s/it]

  6%|▋         | 1040/16104 [4:50:49<50:47:50, 12.14s/it]

  6%|▋         | 1041/16104 [4:51:09<60:20:43, 14.42s/it]

  6%|▋         | 1042/16104 [4:51:20<55:39:03, 13.30s/it]

  6%|▋         | 1043/16104 [4:51:32<55:01:30, 13.15s/it]

  6%|▋         | 1044/16104 [4:51:43<51:54:30, 12.41s/it]

  6%|▋         | 1045/16104 [4:52:00<58:07:25, 13.90s/it]

  6%|▋         | 1046/16104 [4:52:15<59:29:15, 14.22s/it]

  7%|▋         | 1047/16104 [4:52:26<55:04:42, 13.17s/it]

  7%|▋         | 1048/16104 [4:52:42<57:58:19, 13.86s/it]

  7%|▋         | 1049/16104 [4:52:55<57:55:41, 13.85s/it]

  7%|▋         | 1050/16104 [4:53:17<67:13:32, 16.08s/it]

  7%|▋         | 1051/16104 [4:53:37<72:15:51, 17.28s/it]
[2024-04-05 20:17:51,409] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1052/16104 [4:53:57<76:06:08, 18.20s/it]

  7%|▋         | 1053/16104 [4:54:08<66:42:15, 15.95s/it]

  7%|▋         | 1054/16104 [4:54:23<65:36:34, 15.69s/it]

  7%|▋         | 1055/16104 [4:54:43<70:32:19, 16.87s/it]

  7%|▋         | 1056/16104 [4:55:03<74:56:51, 17.93s/it]

  7%|▋         | 1057/16104 [4:55:22<75:56:36, 18.17s/it]

  7%|▋         | 1058/16104 [4:55:38<74:05:29, 17.73s/it]

  7%|▋         | 1059/16104 [4:55:59<78:08:09, 18.70s/it]

  7%|▋         | 1060/16104 [4:56:16<75:49:19, 18.14s/it]

  7%|▋         | 1061/16104 [4:56:32<72:56:57, 17.46s/it]

  7%|▋         | 1062/16104 [4:56:44<66:05:59, 15.82s/it]

  7%|▋         | 1063/16104 [4:56:55<59:49:18, 14.32s/it]

  7%|▋         | 1064/16104 [4:57:07<56:54:41, 13.62s/it]

  7%|▋         | 1065/16104 [4:57:23<59:57:58, 14.35s/it]

  7%|▋         | 1066/16104 [4:57:41<65:16:29, 15.63s/it]

  7%|▋         | 1067/16104 [4:57:59<68:07:30, 16.31s/it]

  7%|▋         | 1068/16104 [4:58:14<65:36:48, 15.71s/it]

  7%|▋         | 1069/16104 [4:58:33<70:43:01, 16.93s/it]
{'loss': 0.5025, 'learning_rate': 1.9930861755521917e-06, 'rewards/chosen': -0.6566759943962097, 'rewards/rejected': -1.499665379524231, 'rewards/accuracies': 0.625, 'rewards/margins': 0.842989444732666, 'policy_logps/rejected': -244.588134765625, 'policy_logps/chosen': -233.91030883789062, 'referece_logps/rejected': -229.59146118164062, 'referece_logps/chosen': -227.34356689453125, 'logits/rejected': -0.5833751559257507, 'logits/chosen': -0.3234236538410187, 'epoch': 0.4}


  7%|▋         | 1071/16104 [4:59:15<79:16:16, 18.98s/it]

  7%|▋         | 1072/16104 [4:59:36<81:10:33, 19.44s/it]
{'loss': 0.5033, 'learning_rate': 1.9930151655862993e-06, 'rewards/chosen': -0.5291349291801453, 'rewards/rejected': -1.2202718257904053, 'rewards/accuracies': 0.875, 'rewards/margins': 0.69113689661026, 'policy_logps/rejected': -207.57711791992188, 'policy_logps/chosen': -194.67416381835938, 'referece_logps/rejected': -195.37440490722656, 'referece_logps/chosen': -189.38282775878906, 'logits/rejected': -0.4137057662010193, 'logits/chosen': -0.396973192691803, 'epoch': 0.4}


  7%|▋         | 1074/16104 [5:00:02<68:52:16, 16.50s/it]

  7%|▋         | 1075/16104 [5:00:16<65:31:31, 15.70s/it]
{'loss': 0.4462, 'learning_rate': 1.9929437940972972e-06, 'rewards/chosen': -0.9197428226470947, 'rewards/rejected': -1.2691025733947754, 'rewards/accuracies': 0.75, 'rewards/margins': 0.34935978055000305, 'policy_logps/rejected': -191.28160095214844, 'policy_logps/chosen': -298.6275939941406, 'referece_logps/rejected': -178.59056091308594, 'referece_logps/chosen': -289.4301452636719, 'logits/rejected': -0.1669107973575592, 'logits/chosen': -0.1542356014251709, 'epoch': 0.4}


  7%|▋         | 1077/16104 [5:00:44<60:43:00, 14.55s/it]

  7%|▋         | 1078/16104 [5:00:56<58:01:01, 13.90s/it]
{'loss': 0.5912, 'learning_rate': 1.9928720611111695e-06, 'rewards/chosen': -0.5814773440361023, 'rewards/rejected': -0.8943517208099365, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3128744065761566, 'policy_logps/rejected': -293.2622985839844, 'policy_logps/chosen': -412.81536865234375, 'referece_logps/rejected': -284.3188171386719, 'referece_logps/chosen': -407.0006103515625, 'logits/rejected': 0.3830909729003906, 'logits/chosen': 0.5061495304107666, 'epoch': 0.4}


  7%|▋         | 1080/16104 [5:01:32<67:09:07, 16.09s/it]

  7%|▋         | 1081/16104 [5:01:54<75:19:02, 18.05s/it]

  7%|▋         | 1082/16104 [5:02:09<70:32:30, 16.91s/it]

  7%|▋         | 1083/16104 [5:02:31<77:11:49, 18.50s/it]

  7%|▋         | 1084/16104 [5:02:51<78:48:55, 18.89s/it]

  7%|▋         | 1085/16104 [5:03:12<81:44:23, 19.59s/it]
{'loss': 0.4663, 'learning_rate': 1.992703278468328e-06, 'rewards/chosen': -0.9160910844802856, 'rewards/rejected': -1.6770492792129517, 'rewards/accuracies': 0.875, 'rewards/margins': 0.760958194732666, 'policy_logps/rejected': -325.56475830078125, 'policy_logps/chosen': -474.2507629394531, 'referece_logps/rejected': -308.79425048828125, 'referece_logps/chosen': -465.08984375, 'logits/rejected': -0.6629364490509033, 'logits/chosen': -0.7477584481239319, 'epoch': 0.4}

  7%|▋         | 1086/16104 [5:03:31<81:20:41, 19.50s/it]


  7%|▋         | 1088/16104 [5:04:04<74:24:53, 17.84s/it]

  7%|▋         | 1089/16104 [5:04:18<69:33:25, 16.68s/it]

  7%|▋         | 1090/16104 [5:04:38<74:45:49, 17.93s/it]

  7%|▋         | 1091/16104 [5:05:01<80:26:28, 19.29s/it]
{'loss': 0.5918, 'learning_rate': 1.992557041510931e-06, 'rewards/chosen': -1.687151312828064, 'rewards/rejected': -2.0680696964263916, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3809185028076172, 'policy_logps/rejected': -455.37701416015625, 'policy_logps/chosen': -506.420654296875, 'referece_logps/rejected': -434.6963195800781, 'referece_logps/chosen': -489.5491027832031, 'logits/rejected': 0.03059312328696251, 'logits/chosen': -0.05284533649682999, 'epoch': 0.41}

  7%|▋         | 1092/16104 [5:05:13<71:33:24, 17.16s/it]


  7%|▋         | 1094/16104 [5:05:58<83:29:44, 20.03s/it]
{'loss': 0.5281, 'learning_rate': 1.9924833809844063e-06, 'rewards/chosen': -1.0212178230285645, 'rewards/rejected': -1.2098321914672852, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1886143684387207, 'policy_logps/rejected': -235.85606384277344, 'policy_logps/chosen': -356.7993469238281, 'referece_logps/rejected': -223.7577362060547, 'referece_logps/chosen': -346.587158203125, 'logits/rejected': -0.2428802102804184, 'logits/chosen': -0.22677446901798248, 'epoch': 0.41}


  7%|▋         | 1096/16104 [5:06:40<85:03:29, 20.40s/it]

  7%|▋         | 1097/16104 [5:06:52<74:45:01, 17.93s/it]
{'loss': 0.7098, 'learning_rate': 1.9924093591283767e-06, 'rewards/chosen': -0.7452363967895508, 'rewards/rejected': -0.9741960763931274, 'rewards/accuracies': 0.75, 'rewards/margins': 0.22895967960357666, 'policy_logps/rejected': -381.74609375, 'policy_logps/chosen': -639.1004638671875, 'referece_logps/rejected': -372.0041809082031, 'referece_logps/chosen': -631.6481323242188, 'logits/rejected': 0.3924180865287781, 'logits/chosen': 0.12505018711090088, 'epoch': 0.41}


  7%|▋         | 1099/16104 [5:07:17<63:16:12, 15.18s/it]

  7%|▋         | 1100/16104 [5:07:29<59:05:09, 14.18s/it]

  7%|▋         | 1101/16104 [5:07:48<65:27:00, 15.70s/it]

  7%|▋         | 1102/16104 [5:08:09<71:44:26, 17.22s/it]

  7%|▋         | 1103/16104 [5:08:26<71:36:03, 17.18s/it]

  7%|▋         | 1104/16104 [5:08:45<73:50:38, 17.72s/it]
{'loss': 0.3902, 'learning_rate': 1.9922352364456372e-06, 'rewards/chosen': -1.1785969734191895, 'rewards/rejected': -2.0677363872528076, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8891394138336182, 'policy_logps/rejected': -374.4597473144531, 'policy_logps/chosen': -453.16375732421875, 'referece_logps/rejected': -353.78240966796875, 'referece_logps/chosen': -441.3778381347656, 'logits/rejected': -0.10690686106681824, 'logits/chosen': 0.08159363269805908, 'epoch': 0.41}


  7%|▋         | 1106/16104 [5:09:08<60:39:00, 14.56s/it]

  7%|▋         | 1107/16104 [5:09:29<68:18:55, 16.40s/it]
{'loss': 0.615, 'learning_rate': 1.9921600103532942e-06, 'rewards/chosen': -1.1185373067855835, 'rewards/rejected': -1.1583837270736694, 'rewards/accuracies': 0.375, 'rewards/margins': 0.039846405386924744, 'policy_logps/rejected': -367.8209228515625, 'policy_logps/chosen': -516.0930786132812, 'referece_logps/rejected': -356.23712158203125, 'referece_logps/chosen': -504.90771484375, 'logits/rejected': -0.5819594860076904, 'logits/chosen': -0.6537649631500244, 'epoch': 0.41}

  7%|▋         | 1108/16104 [5:09:40<61:17:40, 14.71s/it]


  7%|▋         | 1110/16104 [5:10:07<57:31:09, 13.81s/it]

  7%|▋         | 1111/16104 [5:10:19<55:56:29, 13.43s/it]

  7%|▋         | 1112/16104 [5:10:35<59:10:34, 14.21s/it]
{'loss': 0.5327, 'learning_rate': 1.9920338308534707e-06, 'rewards/chosen': -0.656974732875824, 'rewards/rejected': -2.1110429763793945, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4540685415267944, 'policy_logps/rejected': -290.0706787109375, 'policy_logps/chosen': -541.0823364257812, 'referece_logps/rejected': -268.9602355957031, 'referece_logps/chosen': -534.5126342773438, 'logits/rejected': 0.17637237906455994, 'logits/chosen': -0.06035454198718071, 'epoch': 0.41}

  7%|▋         | 1113/16104 [5:10:47<56:48:20, 13.64s/it]

  7%|▋         | 1114/16104 [5:11:02<57:46:25, 13.87s/it]

  7%|▋         | 1115/16104 [5:11:14<55:10:15, 13.25s/it]


  7%|▋         | 1117/16104 [5:11:43<59:38:14, 14.33s/it]

  7%|▋         | 1118/16104 [5:12:03<66:43:03, 16.03s/it]

  7%|▋         | 1119/16104 [5:12:21<68:59:30, 16.57s/it]

  7%|▋         | 1120/16104 [5:12:41<73:12:36, 17.59s/it]
{'loss': 0.4897, 'learning_rate': 1.9918298569713706e-06, 'rewards/chosen': -1.499411940574646, 'rewards/rejected': -1.901660680770874, 'rewards/accuracies': 0.625, 'rewards/margins': 0.402248740196228, 'policy_logps/rejected': -255.89044189453125, 'policy_logps/chosen': -491.5782775878906, 'referece_logps/rejected': -236.87387084960938, 'referece_logps/chosen': -476.58416748046875, 'logits/rejected': -0.2646811008453369, 'logits/chosen': -0.22669386863708496, 'epoch': 0.42}


  7%|▋         | 1122/16104 [5:13:18<76:04:03, 18.28s/it]
[2024-04-05 20:37:33,024] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1123/16104 [5:13:31<69:24:53, 16.68s/it]
{'loss': 0.5026, 'learning_rate': 1.9917527047359027e-06, 'rewards/chosen': -1.0300357341766357, 'rewards/rejected': -1.147416114807129, 'rewards/accuracies': 0.625, 'rewards/margins': 0.11738044768571854, 'policy_logps/rejected': -388.9250183105469, 'policy_logps/chosen': -392.9989929199219, 'referece_logps/rejected': -377.45086669921875, 'referece_logps/chosen': -382.6986999511719, 'logits/rejected': 0.15244528651237488, 'logits/chosen': 0.2051182985305786, 'epoch': 0.42}


  7%|▋         | 1125/16104 [5:13:59<61:55:42, 14.88s/it]
{'loss': 0.6801, 'learning_rate': 1.99170106931969e-06, 'rewards/chosen': -0.8573009967803955, 'rewards/rejected': -1.0769675970077515, 'rewards/accuracies': 0.375, 'rewards/margins': 0.21966657042503357, 'policy_logps/rejected': -393.8006286621094, 'policy_logps/chosen': -328.7950439453125, 'referece_logps/rejected': -383.0308837890625, 'referece_logps/chosen': -320.2220458984375, 'logits/rejected': -0.6305015087127686, 'logits/chosen': -0.6789732575416565, 'epoch': 0.42}

  7%|▋         | 1126/16104 [5:14:12<59:44:44, 14.36s/it]


  7%|▋         | 1128/16104 [5:14:35<53:20:09, 12.82s/it]
{'loss': 0.5663, 'learning_rate': 1.991623315327408e-06, 'rewards/chosen': -0.957115888595581, 'rewards/rejected': -1.5739136934280396, 'rewards/accuracies': 0.75, 'rewards/margins': 0.616797685623169, 'policy_logps/rejected': -233.5159912109375, 'policy_logps/chosen': -461.6476135253906, 'referece_logps/rejected': -217.77685546875, 'referece_logps/chosen': -452.07647705078125, 'logits/rejected': -0.6906938552856445, 'logits/chosen': -0.7126979827880859, 'epoch': 0.42}

  7%|▋         | 1129/16104 [5:14:54<61:23:22, 14.76s/it]


  7%|▋         | 1131/16104 [5:15:23<60:38:17, 14.58s/it]
{'loss': 0.4964, 'learning_rate': 1.9915452003187414e-06, 'rewards/chosen': -1.047305941581726, 'rewards/rejected': -1.552122712135315, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5048167109489441, 'policy_logps/rejected': -254.6397705078125, 'policy_logps/chosen': -227.07505798339844, 'referece_logps/rejected': -239.1185302734375, 'referece_logps/chosen': -216.60198974609375, 'logits/rejected': -0.1965186446905136, 'logits/chosen': -0.23129919171333313, 'epoch': 0.42}


  7%|▋         | 1133/16104 [5:16:03<71:16:05, 17.14s/it]

  7%|▋         | 1134/16104 [5:16:27<79:03:56, 19.01s/it]

  7%|▋         | 1135/16104 [5:16:42<73:51:03, 17.76s/it]

  7%|▋         | 1136/16104 [5:17:00<75:14:37, 18.10s/it]
{'loss': 0.4409, 'learning_rate': 1.991414206456301e-06, 'rewards/chosen': -0.7637140154838562, 'rewards/rejected': -1.4046686887741089, 'rewards/accuracies': 1.0, 'rewards/margins': 0.6409547328948975, 'policy_logps/rejected': -297.0686950683594, 'policy_logps/chosen': -252.94711303710938, 'referece_logps/rejected': -283.0220031738281, 'referece_logps/chosen': -245.3099365234375, 'logits/rejected': -0.87028568983078, 'logits/chosen': -0.7554203867912292, 'epoch': 0.42}


  7%|▋         | 1138/16104 [5:17:33<69:51:21, 16.80s/it]

  7%|▋         | 1139/16104 [5:17:51<70:38:20, 16.99s/it]
{'loss': 0.5947, 'learning_rate': 1.991335128876669e-06, 'rewards/chosen': -1.3342907428741455, 'rewards/rejected': -1.141656517982483, 'rewards/accuracies': 0.375, 'rewards/margins': -0.1926341950893402, 'policy_logps/rejected': -311.5506286621094, 'policy_logps/chosen': -507.27935791015625, 'referece_logps/rejected': -300.134033203125, 'referece_logps/chosen': -493.9364013671875, 'logits/rejected': -0.7042263746261597, 'logits/chosen': -0.7191030979156494, 'epoch': 0.42}


  7%|▋         | 1141/16104 [5:18:21<67:30:08, 16.24s/it]

  7%|▋         | 1142/16104 [5:18:45<76:52:54, 18.50s/it]
{'loss': 0.5952, 'learning_rate': 1.9912556903855722e-06, 'rewards/chosen': -1.2441134452819824, 'rewards/rejected': -1.5913481712341309, 'rewards/accuracies': 0.5, 'rewards/margins': 0.34723472595214844, 'policy_logps/rejected': -251.86721801757812, 'policy_logps/chosen': -356.468505859375, 'referece_logps/rejected': -235.95370483398438, 'referece_logps/chosen': -344.0273742675781, 'logits/rejected': -0.8083784580230713, 'logits/chosen': -1.0618643760681152, 'epoch': 0.43}

  7%|▋         | 1143/16104 [5:19:00<72:36:17, 17.47s/it]

  7%|▋         | 1144/16104 [5:19:16<71:11:06, 17.13s/it]

  7%|▋         | 1145/16104 [5:19:30<67:22:37, 16.21s/it]


  7%|▋         | 1147/16104 [5:20:03<68:57:34, 16.60s/it]

  7%|▋         | 1148/16104 [5:20:16<64:28:54, 15.52s/it]

  7%|▋         | 1149/16104 [5:20:35<68:48:12, 16.56s/it]

  7%|▋         | 1150/16104 [5:20:51<68:46:01, 16.55s/it]

  7%|▋         | 1151/16104 [5:21:13<75:30:55, 18.18s/it]
{'loss': 0.4043, 'learning_rate': 1.9910152097333557e-06, 'rewards/chosen': -2.440706729888916, 'rewards/rejected': -3.61515474319458, 'rewards/accuracies': 1.0, 'rewards/margins': 1.174447774887085, 'policy_logps/rejected': -422.0786437988281, 'policy_logps/chosen': -524.6876220703125, 'referece_logps/rejected': -385.9270935058594, 'referece_logps/chosen': -500.28057861328125, 'logits/rejected': -0.6461002826690674, 'logits/chosen': -0.5884233713150024, 'epoch': 0.43}


  7%|▋         | 1153/16104 [5:21:56<81:46:05, 19.69s/it]

  7%|▋         | 1154/16104 [5:22:17<83:54:44, 20.21s/it]
{'loss': 0.5043, 'learning_rate': 1.9909343278869205e-06, 'rewards/chosen': -0.7766581773757935, 'rewards/rejected': -1.482835054397583, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7061768770217896, 'policy_logps/rejected': -222.03848266601562, 'policy_logps/chosen': -200.50808715820312, 'referece_logps/rejected': -207.21014404296875, 'referece_logps/chosen': -192.74154663085938, 'logits/rejected': -0.8317734599113464, 'logits/chosen': -0.7317246794700623, 'epoch': 0.43}


  7%|▋         | 1156/16104 [5:22:49<75:38:53, 18.22s/it]
{'loss': 0.5431, 'learning_rate': 1.9908802062288364e-06, 'rewards/chosen': -0.6839244365692139, 'rewards/rejected': -1.0836706161499023, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3997461199760437, 'policy_logps/rejected': -303.1194763183594, 'policy_logps/chosen': -297.60589599609375, 'referece_logps/rejected': -292.28277587890625, 'referece_logps/chosen': -290.76666259765625, 'logits/rejected': -1.0674843788146973, 'logits/chosen': -1.04076087474823, 'epoch': 0.43}


  7%|▋         | 1158/16104 [5:23:28<78:20:08, 18.87s/it]
{'loss': 0.388, 'learning_rate': 1.990825924239264e-06, 'rewards/chosen': -1.3448036909103394, 'rewards/rejected': -1.3221169710159302, 'rewards/accuracies': 0.25, 'rewards/margins': -0.022686704993247986, 'policy_logps/rejected': -293.1701354980469, 'policy_logps/chosen': -405.12823486328125, 'referece_logps/rejected': -279.9489440917969, 'referece_logps/chosen': -391.6802062988281, 'logits/rejected': 0.07926827669143677, 'logits/chosen': 0.08976764976978302, 'epoch': 0.43}


  7%|▋         | 1160/16104 [5:24:07<80:12:43, 19.32s/it]

  7%|▋         | 1161/16104 [5:24:28<82:10:25, 19.80s/it]
{'loss': 0.5813, 'learning_rate': 1.9907442006525843e-06, 'rewards/chosen': -0.8979468941688538, 'rewards/rejected': -1.6963406801223755, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7983936667442322, 'policy_logps/rejected': -503.85748291015625, 'policy_logps/chosen': -478.669189453125, 'referece_logps/rejected': -486.89404296875, 'referece_logps/chosen': -469.6897277832031, 'logits/rejected': -0.2465839684009552, 'logits/chosen': -0.165875643491745, 'epoch': 0.43}


  7%|▋         | 1163/16104 [5:25:01<77:12:38, 18.60s/it]

  7%|▋         | 1164/16104 [5:25:22<80:03:40, 19.29s/it]
{'loss': 0.4775, 'learning_rate': 1.9906621163695766e-06, 'rewards/chosen': -1.536249041557312, 'rewards/rejected': -2.2925453186035156, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7562965154647827, 'policy_logps/rejected': -365.2135314941406, 'policy_logps/chosen': -406.8968200683594, 'referece_logps/rejected': -342.2880859375, 'referece_logps/chosen': -391.5343322753906, 'logits/rejected': -0.7963024377822876, 'logits/chosen': -0.8558303713798523, 'epoch': 0.43}


  7%|▋         | 1166/16104 [5:25:56<76:14:21, 18.37s/it]

  7%|▋         | 1167/16104 [5:26:13<74:58:23, 18.07s/it]

  7%|▋         | 1168/16104 [5:26:32<76:11:03, 18.36s/it]
{'loss': 0.6225, 'learning_rate': 1.9905521096273925e-06, 'rewards/chosen': -1.4262348413467407, 'rewards/rejected': -2.166498899459839, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7402639985084534, 'policy_logps/rejected': -342.6557312011719, 'policy_logps/chosen': -587.0436401367188, 'referece_logps/rejected': -320.99072265625, 'referece_logps/chosen': -572.7813720703125, 'logits/rejected': -0.8518930077552795, 'logits/chosen': -0.9509824514389038, 'epoch': 0.44}

  7%|▋         | 1169/16104 [5:26:47<71:30:54, 17.24s/it]


  7%|▋         | 1171/16104 [5:27:11<60:57:42, 14.70s/it]
{'loss': 0.499, 'learning_rate': 1.9904691838360617e-06, 'rewards/chosen': -0.48328346014022827, 'rewards/rejected': -1.2351306676864624, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7518473267555237, 'policy_logps/rejected': -430.5811767578125, 'policy_logps/chosen': -389.2323913574219, 'referece_logps/rejected': -418.2298278808594, 'referece_logps/chosen': -384.3995361328125, 'logits/rejected': -1.1539092063903809, 'logits/chosen': -1.1138173341751099, 'epoch': 0.44}

  7%|▋         | 1172/16104 [5:27:22<56:41:00, 13.67s/it]


  7%|▋         | 1174/16104 [5:27:48<53:42:00, 12.95s/it]

  7%|▋         | 1175/16104 [5:27:59<51:50:17, 12.50s/it]
{'loss': 0.485, 'learning_rate': 1.9903580551920957e-06, 'rewards/chosen': -0.4722379446029663, 'rewards/rejected': -1.812339425086975, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3401014804840088, 'policy_logps/rejected': -228.70481872558594, 'policy_logps/chosen': -313.1994934082031, 'referece_logps/rejected': -210.58143615722656, 'referece_logps/chosen': -308.4770812988281, 'logits/rejected': -0.8899343013763428, 'logits/chosen': -0.9492459297180176, 'epoch': 0.44}
[2024-04-05 20:52:35,204] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  7%|▋         | 1177/16104 [5:28:36<63:33:58, 15.33s/it]
{'loss': 0.5394, 'learning_rate': 1.9903022504951095e-06, 'rewards/chosen': -1.2327650785446167, 'rewards/rejected': -1.8816461563110352, 'rewards/accuracies': 0.75, 'rewards/margins': 0.648881196975708, 'policy_logps/rejected': -501.54193115234375, 'policy_logps/chosen': -453.12518310546875, 'referece_logps/rejected': -482.7254638671875, 'referece_logps/chosen': -440.7975158691406, 'logits/rejected': -0.5926148891448975, 'logits/chosen': -0.46242237091064453, 'epoch': 0.44}
[2024-04-05 20:53:09,206] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1178/16104 [5:28:55<67:16:55, 16.23s/it]


  7%|▋         | 1180/16104 [5:29:26<66:14:17, 15.98s/it]

  7%|▋         | 1181/16104 [5:29:36<59:39:31, 14.39s/it]
{'loss': 0.5844, 'learning_rate': 1.9901901603962788e-06, 'rewards/chosen': -1.4707069396972656, 'rewards/rejected': -2.0700786113739014, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5993716716766357, 'policy_logps/rejected': -432.6845703125, 'policy_logps/chosen': -326.84234619140625, 'referece_logps/rejected': -411.9837951660156, 'referece_logps/chosen': -312.13525390625, 'logits/rejected': -0.381542444229126, 'logits/chosen': -0.22898541390895844, 'epoch': 0.44}


  7%|▋         | 1183/16104 [5:30:06<62:33:21, 15.09s/it]

  7%|▋         | 1184/16104 [5:30:24<66:29:07, 16.04s/it]
{'loss': 0.5756, 'learning_rate': 1.9901056722411253e-06, 'rewards/chosen': -1.0588178634643555, 'rewards/rejected': -1.1407278776168823, 'rewards/accuracies': 0.375, 'rewards/margins': 0.08190988004207611, 'policy_logps/rejected': -295.0736389160156, 'policy_logps/chosen': -428.2587890625, 'referece_logps/rejected': -283.66632080078125, 'referece_logps/chosen': -417.67059326171875, 'logits/rejected': 0.12800443172454834, 'logits/chosen': 0.3576500415802002, 'epoch': 0.44}

  7%|▋         | 1185/16104 [5:30:36<60:20:45, 14.56s/it]

  7%|▋         | 1186/16104 [5:30:59<71:07:25, 17.16s/it]


  7%|▋         | 1188/16104 [5:31:30<70:13:47, 16.95s/it]
{'loss': 0.4601, 'learning_rate': 1.989992460651359e-06, 'rewards/chosen': -1.0205459594726562, 'rewards/rejected': -1.6921484470367432, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6716026067733765, 'policy_logps/rejected': -279.996826171875, 'policy_logps/chosen': -299.452880859375, 'referece_logps/rejected': -263.07537841796875, 'referece_logps/chosen': -289.2474365234375, 'logits/rejected': -1.1877143383026123, 'logits/chosen': -1.0663479566574097, 'epoch': 0.44}

  7%|▋         | 1189/16104 [5:31:47<70:16:38, 16.96s/it]

  7%|▋         | 1190/16104 [5:32:01<66:40:14, 16.09s/it]

  7%|▋         | 1191/16104 [5:32:19<69:07:43, 16.69s/it]


  7%|▋         | 1193/16104 [5:32:53<70:35:55, 17.04s/it]
{'loss': 0.5347, 'learning_rate': 1.9898500451161864e-06, 'rewards/chosen': -1.270567536354065, 'rewards/rejected': -2.166125535964966, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8955579996109009, 'policy_logps/rejected': -413.41741943359375, 'policy_logps/chosen': -324.1495666503906, 'referece_logps/rejected': -391.75616455078125, 'referece_logps/chosen': -311.4438781738281, 'logits/rejected': -0.08679717779159546, 'logits/chosen': 0.055487602949142456, 'epoch': 0.44}


  7%|▋         | 1195/16104 [5:33:28<72:26:07, 17.49s/it]
[2024-04-05 20:57:42,963] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1196/16104 [5:33:44<70:38:43, 17.06s/it]

  7%|▋         | 1197/16104 [5:34:02<71:22:01, 17.23s/it]
{'loss': 0.6242, 'learning_rate': 1.9897353919395462e-06, 'rewards/chosen': -0.6490604281425476, 'rewards/rejected': -0.9330444931983948, 'rewards/accuracies': 0.75, 'rewards/margins': 0.28398406505584717, 'policy_logps/rejected': -258.3432312011719, 'policy_logps/chosen': -320.12860107421875, 'referece_logps/rejected': -249.01280212402344, 'referece_logps/chosen': -313.637939453125, 'logits/rejected': -0.7025489807128906, 'logits/chosen': -0.7915132641792297, 'epoch': 0.45}

  7%|▋         | 1198/16104 [5:34:18<69:48:03, 16.86s/it]

  7%|▋         | 1199/16104 [5:34:33<67:52:30, 16.39s/it]

  7%|▋         | 1200/16104 [5:34:45<61:38:08, 14.89s/it]


  7%|▋         | 1202/16104 [5:35:06<52:52:54, 12.78s/it]
{'loss': 0.5809, 'learning_rate': 1.989591174654865e-06, 'rewards/chosen': -0.8695625066757202, 'rewards/rejected': -1.1040914058685303, 'rewards/accuracies': 0.5, 'rewards/margins': 0.23452892899513245, 'policy_logps/rejected': -345.6321105957031, 'policy_logps/chosen': -306.0014343261719, 'referece_logps/rejected': -334.59124755859375, 'referece_logps/chosen': -297.30584716796875, 'logits/rejected': -0.7817767262458801, 'logits/chosen': -0.7453305721282959, 'epoch': 0.45}

  7%|▋         | 1203/16104 [5:35:17<50:20:22, 12.16s/it]

  7%|▋         | 1204/16104 [5:35:28<48:31:57, 11.73s/it]

  7%|▋         | 1205/16104 [5:35:46<56:45:11, 13.71s/it]


  7%|▋         | 1207/16104 [5:36:18<62:58:40, 15.22s/it]
{'loss': 0.4218, 'learning_rate': 1.9894459566020416e-06, 'rewards/chosen': -1.3093992471694946, 'rewards/rejected': -2.48301100730896, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1736118793487549, 'policy_logps/rejected': -361.27789306640625, 'policy_logps/chosen': -429.2506103515625, 'referece_logps/rejected': -336.44775390625, 'referece_logps/chosen': -416.1566162109375, 'logits/rejected': -0.6325006484985352, 'logits/chosen': -0.6220703125, 'epoch': 0.45}


  8%|▊         | 1209/16104 [5:36:48<63:26:58, 15.34s/it]

  8%|▊         | 1210/16104 [5:37:05<64:37:31, 15.62s/it]

  8%|▊         | 1211/16104 [5:37:26<72:00:47, 17.41s/it]
{'loss': 0.5884, 'learning_rate': 1.9893290617053748e-06, 'rewards/chosen': -1.4058932065963745, 'rewards/rejected': -1.7976140975952148, 'rewards/accuracies': 0.375, 'rewards/margins': 0.3917209208011627, 'policy_logps/rejected': -550.8301391601562, 'policy_logps/chosen': -485.6377868652344, 'referece_logps/rejected': -532.85400390625, 'referece_logps/chosen': -471.57891845703125, 'logits/rejected': -1.7461973428726196, 'logits/chosen': -1.9011276960372925, 'epoch': 0.45}


  8%|▊         | 1213/16104 [5:38:05<75:23:13, 18.23s/it]

  8%|▊         | 1214/16104 [5:38:25<77:55:34, 18.84s/it]
{'loss': 0.4725, 'learning_rate': 1.9892409703174202e-06, 'rewards/chosen': -0.90887051820755, 'rewards/rejected': -2.4062442779541016, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4973738193511963, 'policy_logps/rejected': -315.5048522949219, 'policy_logps/chosen': -392.6822204589844, 'referece_logps/rejected': -291.4424133300781, 'referece_logps/chosen': -383.59356689453125, 'logits/rejected': -0.33574944734573364, 'logits/chosen': -0.2769891023635864, 'epoch': 0.45}

  8%|▊         | 1215/16104 [5:38:39<72:38:12, 17.56s/it]
[2024-04-05 21:03:10,501] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  8%|▊         | 1217/16104 [5:39:06<62:58:56, 15.23s/it]
{'loss': 0.5383, 'learning_rate': 1.989152518780412e-06, 'rewards/chosen': -0.6843239665031433, 'rewards/rejected': -1.3388813734054565, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6545573472976685, 'policy_logps/rejected': -373.26678466796875, 'policy_logps/chosen': -549.1126708984375, 'referece_logps/rejected': -359.8779602050781, 'referece_logps/chosen': -542.2694091796875, 'logits/rejected': -0.39208918809890747, 'logits/chosen': -0.3825419247150421, 'epoch': 0.45}


  8%|▊         | 1219/16104 [5:39:37<61:02:39, 14.76s/it]
{'loss': 0.5826, 'learning_rate': 1.9890933510221633e-06, 'rewards/chosen': -0.5862503051757812, 'rewards/rejected': -1.5075533390045166, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9213031530380249, 'policy_logps/rejected': -307.1415100097656, 'policy_logps/chosen': -422.8116455078125, 'referece_logps/rejected': -292.06597900390625, 'referece_logps/chosen': -416.9491882324219, 'logits/rejected': 0.6050924062728882, 'logits/chosen': 0.5866633653640747, 'epoch': 0.45}


  8%|▊         | 1221/16104 [5:40:05<60:56:12, 14.74s/it]
[2024-04-05 21:04:19,631] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1222/16104 [5:40:17<57:06:43, 13.82s/it]

  8%|▊         | 1223/16104 [5:40:37<64:49:09, 15.68s/it]
[2024-04-05 21:04:51,324] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4735, 'learning_rate': 1.988974535388177e-06, 'rewards/chosen': -0.6250818967819214, 'rewards/rejected': -1.9321469068527222, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3070648908615112, 'policy_logps/rejected': -315.3714904785156, 'policy_logps/chosen': -318.98187255859375, 'referece_logps/rejected': -296.050048828125, 'referece_logps/chosen': -312.73101806640625, 'logits/rejected': -0.2692098319530487, 'logits/chosen': -0.3064834177494049, 'epoch': 0.46}

  8%|▊         | 1224/16104 [5:40:53<66:03:50, 15.98s/it]

  8%|▊         | 1225/16104 [5:41:10<66:50:09, 16.17s/it]


  8%|▊         | 1227/16104 [5:41:45<69:34:41, 16.84s/it]
{'loss': 0.5374, 'learning_rate': 1.9888550796616665e-06, 'rewards/chosen': -1.1275440454483032, 'rewards/rejected': -1.3206886053085327, 'rewards/accuracies': 0.375, 'rewards/margins': 0.19314461946487427, 'policy_logps/rejected': -301.8077392578125, 'policy_logps/chosen': -250.47744750976562, 'referece_logps/rejected': -288.600830078125, 'referece_logps/chosen': -239.20201110839844, 'logits/rejected': 0.09734019637107849, 'logits/chosen': 0.1656760275363922, 'epoch': 0.46}

  8%|▊         | 1228/16104 [5:42:04<71:33:45, 17.32s/it]


  8%|▊         | 1230/16104 [5:42:33<67:06:03, 16.24s/it]
{'loss': 0.6326, 'learning_rate': 1.9887650678525593e-06, 'rewards/chosen': -1.0811691284179688, 'rewards/rejected': -1.150078535079956, 'rewards/accuracies': 0.625, 'rewards/margins': 0.06890954077243805, 'policy_logps/rejected': -393.7756652832031, 'policy_logps/chosen': -362.29656982421875, 'referece_logps/rejected': -382.27484130859375, 'referece_logps/chosen': -351.4848327636719, 'logits/rejected': -0.6702320575714111, 'logits/chosen': -0.6935980319976807, 'epoch': 0.46}

  8%|▊         | 1231/16104 [5:42:47<64:12:22, 15.54s/it]


  8%|▊         | 1233/16104 [5:43:27<74:13:14, 17.97s/it]

  8%|▊         | 1234/16104 [5:43:47<76:59:01, 18.64s/it]
{'loss': 0.4762, 'learning_rate': 1.9886444921504207e-06, 'rewards/chosen': -0.9197860956192017, 'rewards/rejected': -1.7527981996536255, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8330122232437134, 'policy_logps/rejected': -267.3350524902344, 'policy_logps/chosen': -366.6837158203125, 'referece_logps/rejected': -249.80706787109375, 'referece_logps/chosen': -357.4858703613281, 'logits/rejected': -0.5980347394943237, 'logits/chosen': -0.527496337890625, 'epoch': 0.46}

  8%|▊         | 1235/16104 [5:44:06<77:25:50, 18.75s/it]

  8%|▊         | 1236/16104 [5:44:26<78:31:32, 19.01s/it]

  8%|▊         | 1237/16104 [5:44:41<73:36:13, 17.82s/it]

  8%|▊         | 1238/16104 [5:45:01<76:20:23, 18.49s/it]


  8%|▊         | 1240/16104 [5:45:33<69:50:16, 16.91s/it]

  8%|▊         | 1241/16104 [5:45:48<67:04:14, 16.25s/it]
{'loss': 0.6908, 'learning_rate': 1.9884319450102292e-06, 'rewards/chosen': -0.9792426824569702, 'rewards/rejected': -1.1118357181549072, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13259312510490417, 'policy_logps/rejected': -301.628662109375, 'policy_logps/chosen': -296.5899658203125, 'referece_logps/rejected': -290.5102844238281, 'referece_logps/chosen': -286.7975158691406, 'logits/rejected': -0.652213454246521, 'logits/chosen': -0.6489485502243042, 'epoch': 0.46}

  8%|▊         | 1242/16104 [5:46:04<67:13:08, 16.28s/it]

  8%|▊         | 1243/16104 [5:46:26<74:41:40, 18.09s/it]


  8%|▊         | 1245/16104 [5:47:01<72:47:35, 17.64s/it]
{'loss': 0.4643, 'learning_rate': 1.988309609830116e-06, 'rewards/chosen': -0.2932083010673523, 'rewards/rejected': -1.1066325902938843, 'rewards/accuracies': 0.875, 'rewards/margins': 0.813424289226532, 'policy_logps/rejected': -224.54176330566406, 'policy_logps/chosen': -378.48248291015625, 'referece_logps/rejected': -213.47543334960938, 'referece_logps/chosen': -375.5503845214844, 'logits/rejected': -1.0054675340652466, 'logits/chosen': -0.9313849806785583, 'epoch': 0.46}


  8%|▊         | 1247/16104 [5:47:23<58:24:06, 14.15s/it]
{'loss': 0.5141, 'learning_rate': 1.9882482023617826e-06, 'rewards/chosen': -0.6275463104248047, 'rewards/rejected': -1.3343908786773682, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7068443894386292, 'policy_logps/rejected': -247.23968505859375, 'policy_logps/chosen': -384.6106872558594, 'referece_logps/rejected': -233.89578247070312, 'referece_logps/chosen': -378.3352355957031, 'logits/rejected': -0.6486690640449524, 'logits/chosen': -0.9759769439697266, 'epoch': 0.46}

  8%|▊         | 1248/16104 [5:47:35<55:28:47, 13.44s/it]

  8%|▊         | 1249/16104 [5:47:59<68:17:06, 16.55s/it]

  8%|▊         | 1250/16104 [5:48:20<74:19:04, 18.01s/it]


  8%|▊         | 1252/16104 [5:49:04<82:12:46, 19.93s/it]
[2024-04-05 21:13:18,289] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.436, 'learning_rate': 1.9880939841256974e-06, 'rewards/chosen': -0.6877942681312561, 'rewards/rejected': -1.6319313049316406, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9441369771957397, 'policy_logps/rejected': -450.54913330078125, 'policy_logps/chosen': -497.86248779296875, 'referece_logps/rejected': -434.2298278808594, 'referece_logps/chosen': -490.98455810546875, 'logits/rejected': 0.48502317070961, 'logits/chosen': 0.3060336709022522, 'epoch': 0.47}

  8%|▊         | 1253/16104 [5:49:23<81:21:19, 19.72s/it]
[2024-04-05 21:13:48,797] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  8%|▊         | 1255/16104 [5:49:45<63:29:02, 15.39s/it]
{'loss': 0.5481, 'learning_rate': 1.9880009735320827e-06, 'rewards/chosen': -1.0215060710906982, 'rewards/rejected': -1.4434897899627686, 'rewards/accuracies': 0.5, 'rewards/margins': 0.42198362946510315, 'policy_logps/rejected': -251.74830627441406, 'policy_logps/chosen': -294.6286926269531, 'referece_logps/rejected': -237.31341552734375, 'referece_logps/chosen': -284.41363525390625, 'logits/rejected': -0.652456521987915, 'logits/chosen': -0.5797410011291504, 'epoch': 0.47}


  8%|▊         | 1257/16104 [5:50:13<59:25:37, 14.41s/it]
{'loss': 0.4805, 'learning_rate': 1.9879387666355706e-06, 'rewards/chosen': -0.8796827793121338, 'rewards/rejected': -1.6819922924041748, 'rewards/accuracies': 0.75, 'rewards/margins': 0.802309513092041, 'policy_logps/rejected': -286.50384521484375, 'policy_logps/chosen': -380.9467468261719, 'referece_logps/rejected': -269.68389892578125, 'referece_logps/chosen': -372.1499328613281, 'logits/rejected': -0.7986267805099487, 'logits/chosen': -0.6831892728805542, 'epoch': 0.47}

  8%|▊         | 1258/16104 [5:50:24<54:58:06, 13.33s/it]


  8%|▊         | 1260/16104 [5:50:57<59:23:57, 14.41s/it]

  8%|▊         | 1261/16104 [5:51:10<57:00:54, 13.83s/it]
{'loss': 0.531, 'learning_rate': 1.9878138732860092e-06, 'rewards/chosen': -0.8697850108146667, 'rewards/rejected': -1.6249864101409912, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7552012801170349, 'policy_logps/rejected': -353.5825500488281, 'policy_logps/chosen': -354.89324951171875, 'referece_logps/rejected': -337.33270263671875, 'referece_logps/chosen': -346.19537353515625, 'logits/rejected': 0.021887540817260742, 'logits/chosen': 0.09104499220848083, 'epoch': 0.47}


  8%|▊         | 1263/16104 [5:51:49<69:33:49, 16.87s/it]
{'loss': 0.4478, 'learning_rate': 1.987751186853169e-06, 'rewards/chosen': -0.894745945930481, 'rewards/rejected': -2.155291795730591, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2605459690093994, 'policy_logps/rejected': -319.6353759765625, 'policy_logps/chosen': -400.83685302734375, 'referece_logps/rejected': -298.08245849609375, 'referece_logps/chosen': -391.88934326171875, 'logits/rejected': -0.9456527829170227, 'logits/chosen': -0.8024091720581055, 'epoch': 0.47}


  8%|▊         | 1265/16104 [5:52:24<71:09:54, 17.26s/it]
[2024-04-05 21:16:38,277] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4636, 'learning_rate': 1.9876883405951377e-06, 'rewards/chosen': -0.893391489982605, 'rewards/rejected': -1.8573483228683472, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9639568328857422, 'policy_logps/rejected': -424.6282958984375, 'policy_logps/chosen': -463.53070068359375, 'referece_logps/rejected': -406.0548095703125, 'referece_logps/chosen': -454.5967712402344, 'logits/rejected': -0.23087017238140106, 'logits/chosen': -0.20848903059959412, 'epoch': 0.47}

  8%|▊         | 1266/16104 [5:52:44<75:19:30, 18.28s/it]

  8%|▊         | 1267/16104 [5:53:00<72:26:13, 17.58s/it]


  8%|▊         | 1269/16104 [5:53:30<66:24:50, 16.12s/it]
{'loss': 0.4698, 'learning_rate': 1.987562168644204e-06, 'rewards/chosen': -0.6845320463180542, 'rewards/rejected': -1.7863675355911255, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1018354892730713, 'policy_logps/rejected': -235.0082244873047, 'policy_logps/chosen': -318.4577941894531, 'referece_logps/rejected': -217.14454650878906, 'referece_logps/chosen': -311.6124572753906, 'logits/rejected': -1.0904691219329834, 'logits/chosen': -1.076820731163025, 'epoch': 0.47}


  8%|▊         | 1271/16104 [5:53:57<61:48:36, 15.00s/it]
{'loss': 0.4383, 'learning_rate': 1.9874988429717173e-06, 'rewards/chosen': -1.066859245300293, 'rewards/rejected': -1.9789042472839355, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9120447635650635, 'policy_logps/rejected': -289.0490417480469, 'policy_logps/chosen': -405.3350524902344, 'referece_logps/rejected': -269.260009765625, 'referece_logps/chosen': -394.6664733886719, 'logits/rejected': 0.29317378997802734, 'logits/chosen': 0.36670565605163574, 'epoch': 0.47}
[2024-04-05 21:18:31,347] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  8%|▊         | 1273/16104 [5:54:34<68:26:21, 16.61s/it]

  8%|▊         | 1274/16104 [5:54:52<69:28:30, 16.87s/it]
{'loss': 0.4245, 'learning_rate': 1.987403554870521e-06, 'rewards/chosen': -1.1565474271774292, 'rewards/rejected': -2.329115629196167, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1725685596466064, 'policy_logps/rejected': -236.47982788085938, 'policy_logps/chosen': -306.2463684082031, 'referece_logps/rejected': -213.1886749267578, 'referece_logps/chosen': -294.6808776855469, 'logits/rejected': -1.3803642988204956, 'logits/chosen': -1.4679731130599976, 'epoch': 0.47}


  8%|▊         | 1276/16104 [5:55:14<57:03:40, 13.85s/it]
{'loss': 0.4222, 'learning_rate': 1.9873398297564034e-06, 'rewards/chosen': -0.9973834156990051, 'rewards/rejected': -1.8308972120285034, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8335137367248535, 'policy_logps/rejected': -276.8745422363281, 'policy_logps/chosen': -308.381103515625, 'referece_logps/rejected': -258.5655822753906, 'referece_logps/chosen': -298.4072570800781, 'logits/rejected': -0.7530359625816345, 'logits/chosen': -0.5151972770690918, 'epoch': 0.48}
[2024-04-05 21:19:49,773] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1277/16104 [5:55:35<66:38:47, 16.18s/it]


  8%|▊         | 1279/16104 [5:56:00<57:54:12, 14.06s/it]
{'loss': 0.4461, 'learning_rate': 1.987243942541024e-06, 'rewards/chosen': -0.5999502539634705, 'rewards/rejected': -2.09586501121521, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4959149360656738, 'policy_logps/rejected': -348.4736022949219, 'policy_logps/chosen': -414.0914001464844, 'referece_logps/rejected': -327.5149230957031, 'referece_logps/chosen': -408.0919494628906, 'logits/rejected': -1.1204454898834229, 'logits/chosen': -0.993455171585083, 'epoch': 0.48}


  8%|▊         | 1281/16104 [5:56:34<66:25:25, 16.13s/it]
[2024-04-05 21:20:48,465] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6025, 'learning_rate': 1.98717981804972e-06, 'rewards/chosen': -0.5962370038032532, 'rewards/rejected': -1.2114932537078857, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6152562499046326, 'policy_logps/rejected': -411.1636962890625, 'policy_logps/chosen': -339.6589660644531, 'referece_logps/rejected': -399.04876708984375, 'referece_logps/chosen': -333.69659423828125, 'logits/rejected': 0.21398958563804626, 'logits/chosen': 0.24668626487255096, 'epoch': 0.48}


  8%|▊         | 1283/16104 [5:56:58<57:48:00, 14.04s/it]

  8%|▊         | 1284/16104 [5:57:18<64:46:46, 15.74s/it]

  8%|▊         | 1285/16104 [5:57:36<67:40:20, 16.44s/it]

  8%|▊         | 1286/16104 [5:57:50<64:28:16, 15.66s/it]

  8%|▊         | 1287/16104 [5:58:06<64:54:37, 15.77s/it]
{'loss': 0.6523, 'learning_rate': 1.9869864862210045e-06, 'rewards/chosen': -0.7047522068023682, 'rewards/rejected': -1.6187217235565186, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9139696359634399, 'policy_logps/rejected': -320.1927185058594, 'policy_logps/chosen': -375.0753479003906, 'referece_logps/rejected': -304.0054931640625, 'referece_logps/chosen': -368.0278625488281, 'logits/rejected': -0.8007322549819946, 'logits/chosen': -0.7750707864761353, 'epoch': 0.48}


  8%|▊         | 1289/16104 [5:58:30<56:57:41, 13.84s/it]
{'loss': 0.6198, 'learning_rate': 1.986921722861256e-06, 'rewards/chosen': -0.97370445728302, 'rewards/rejected': -1.119728922843933, 'rewards/accuracies': 0.75, 'rewards/margins': 0.14602439105510712, 'policy_logps/rejected': -287.0260314941406, 'policy_logps/chosen': -314.2196044921875, 'referece_logps/rejected': -275.8287658691406, 'referece_logps/chosen': -304.4825439453125, 'logits/rejected': -1.0067555904388428, 'logits/chosen': -1.1546120643615723, 'epoch': 0.48}


  8%|▊         | 1291/16104 [5:58:56<54:23:48, 13.22s/it]

  8%|▊         | 1292/16104 [5:59:14<60:25:09, 14.68s/it]
{'loss': 0.633, 'learning_rate': 1.9868242784043324e-06, 'rewards/chosen': -1.1556549072265625, 'rewards/rejected': -1.672039270401001, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5163843035697937, 'policy_logps/rejected': -356.5034484863281, 'policy_logps/chosen': -267.00482177734375, 'referece_logps/rejected': -339.78302001953125, 'referece_logps/chosen': -255.4482421875, 'logits/rejected': -0.7979298830032349, 'logits/chosen': -0.8003754019737244, 'epoch': 0.48}

  8%|▊         | 1293/16104 [5:59:25<55:41:19, 13.54s/it]


  8%|▊         | 1295/16104 [6:00:02<66:11:17, 16.09s/it]
{'loss': 0.5334, 'learning_rate': 1.986726474678191e-06, 'rewards/chosen': -0.7837491035461426, 'rewards/rejected': -1.4978755712509155, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7141265869140625, 'policy_logps/rejected': -261.3441162109375, 'policy_logps/chosen': -331.42010498046875, 'referece_logps/rejected': -246.36538696289062, 'referece_logps/chosen': -323.5826110839844, 'logits/rejected': 0.285746306180954, 'logits/chosen': 0.3177322745323181, 'epoch': 0.48}

  8%|▊         | 1296/16104 [6:00:20<67:46:07, 16.48s/it]
[2024-04-05 21:24:55,516] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  8%|▊         | 1298/16104 [6:01:00<74:40:39, 18.16s/it]
{'loss': 0.5797, 'learning_rate': 1.986628311718439e-06, 'rewards/chosen': -1.575043797492981, 'rewards/rejected': -2.1803994178771973, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6053556203842163, 'policy_logps/rejected': -388.451171875, 'policy_logps/chosen': -551.1121215820312, 'referece_logps/rejected': -366.64715576171875, 'referece_logps/chosen': -535.3616943359375, 'logits/rejected': 0.44545167684555054, 'logits/chosen': 0.49541035294532776, 'epoch': 0.48}

  8%|▊         | 1299/16104 [6:01:21<78:03:08, 18.98s/it]


  8%|▊         | 1301/16104 [6:02:00<79:10:47, 19.26s/it]
{'loss': 0.4689, 'learning_rate': 1.986529789560814e-06, 'rewards/chosen': -1.1144533157348633, 'rewards/rejected': -1.2464905977249146, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13203726708889008, 'policy_logps/rejected': -381.62939453125, 'policy_logps/chosen': -624.5386962890625, 'referece_logps/rejected': -369.1645202636719, 'referece_logps/chosen': -613.3941040039062, 'logits/rejected': -0.11194905638694763, 'logits/chosen': -0.3229251205921173, 'epoch': 0.48}

  8%|▊         | 1302/16104 [6:02:19<78:43:35, 19.15s/it]

  8%|▊         | 1303/16104 [6:02:33<72:19:24, 17.59s/it]

  8%|▊         | 1304/16104 [6:02:51<72:32:54, 17.65s/it]

  8%|▊         | 1305/16104 [6:03:03<66:04:31, 16.07s/it]

  8%|▊         | 1306/16104 [6:03:14<59:27:31, 14.46s/it]

  8%|▊         | 1307/16104 [6:03:37<70:34:48, 17.17s/it]

  8%|▊         | 1308/16104 [6:03:54<70:27:59, 17.15s/it]

  8%|▊         | 1309/16104 [6:04:14<73:39:12, 17.92s/it]

  8%|▊         | 1310/16104 [6:04:30<70:37:31, 17.19s/it]

  8%|▊         | 1311/16104 [6:04:51<75:15:19, 18.31s/it]

  8%|▊         | 1312/16104 [6:05:04<68:49:11, 16.75s/it]

  8%|▊         | 1313/16104 [6:05:16<63:39:02, 15.49s/it]

  8%|▊         | 1314/16104 [6:05:31<62:47:26, 15.28s/it]

  8%|▊         | 1315/16104 [6:05:53<70:58:26, 17.28s/it]
[2024-04-05 21:30:29,195] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1316/16104 [6:06:15<76:19:37, 18.58s/it]

  8%|▊         | 1317/16104 [6:06:34<77:51:51, 18.96s/it]

  8%|▊         | 1318/16104 [6:06:56<81:23:00, 19.81s/it]

  8%|▊         | 1319/16104 [6:07:17<82:39:18, 20.13s/it]

  8%|▊         | 1320/16104 [6:07:32<76:28:41, 18.62s/it]

  8%|▊         | 1321/16104 [6:07:46<70:34:52, 17.19s/it]

  8%|▊         | 1322/16104 [6:08:06<74:07:41, 18.05s/it]

  8%|▊         | 1323/16104 [6:08:28<79:16:32, 19.31s/it]

  8%|▊         | 1324/16104 [6:08:41<71:39:59, 17.46s/it]


  8%|▊         | 1326/16104 [6:09:03<57:33:20, 14.02s/it]
{'loss': 0.5549, 'learning_rate': 1.985694807611164e-06, 'rewards/chosen': -0.5482069253921509, 'rewards/rejected': -0.6889297962188721, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1407228410243988, 'policy_logps/rejected': -467.5174560546875, 'policy_logps/chosen': -436.97613525390625, 'referece_logps/rejected': -460.628173828125, 'referece_logps/chosen': -431.4940490722656, 'logits/rejected': -0.37780460715293884, 'logits/chosen': -0.3398938775062561, 'epoch': 0.49}
[2024-04-05 21:33:29,012] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  8%|▊         | 1328/16104 [6:09:25<51:11:31, 12.47s/it]

  8%|▊         | 1329/16104 [6:09:41<55:33:05, 13.54s/it]
{'loss': 0.5141, 'learning_rate': 1.9855929346872335e-06, 'rewards/chosen': -0.4963511824607849, 'rewards/rejected': -1.3294992446899414, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8331481218338013, 'policy_logps/rejected': -270.5110778808594, 'policy_logps/chosen': -329.3004455566406, 'referece_logps/rejected': -257.2160949707031, 'referece_logps/chosen': -324.3370056152344, 'logits/rejected': -0.830642819404602, 'logits/chosen': -0.8243683576583862, 'epoch': 0.5}

  8%|▊         | 1330/16104 [6:09:52<52:56:20, 12.90s/it]

  8%|▊         | 1331/16104 [6:10:13<61:59:50, 15.11s/it]

  8%|▊         | 1332/16104 [6:10:26<59:34:08, 14.52s/it]

  8%|▊         | 1333/16104 [6:10:39<58:30:03, 14.26s/it]


  8%|▊         | 1335/16104 [6:11:15<66:17:26, 16.16s/it]
{'loss': 0.456, 'learning_rate': 1.9853881124138096e-06, 'rewards/chosen': -0.9403276443481445, 'rewards/rejected': -1.818530559539795, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8782027959823608, 'policy_logps/rejected': -295.08599853515625, 'policy_logps/chosen': -496.7092590332031, 'referece_logps/rejected': -276.90069580078125, 'referece_logps/chosen': -487.30596923828125, 'logits/rejected': -0.8661230802536011, 'logits/chosen': -0.9281297326087952, 'epoch': 0.5}

  8%|▊         | 1336/16104 [6:11:29<63:08:50, 15.39s/it]

  8%|▊         | 1337/16104 [6:11:46<65:44:17, 16.03s/it]

  8%|▊         | 1338/16104 [6:12:05<68:44:39, 16.76s/it]

  8%|▊         | 1339/16104 [6:12:20<67:13:23, 16.39s/it]

  8%|▊         | 1340/16104 [6:12:36<66:06:31, 16.12s/it]

  8%|▊         | 1341/16104 [6:12:55<70:26:58, 17.18s/it]


  8%|▊         | 1343/16104 [6:13:27<67:29:51, 16.46s/it]
{'loss': 0.5047, 'learning_rate': 1.985112783901739e-06, 'rewards/chosen': -0.552280068397522, 'rewards/rejected': -1.6496986150741577, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0974185466766357, 'policy_logps/rejected': -288.7227783203125, 'policy_logps/chosen': -331.8892822265625, 'referece_logps/rejected': -272.22576904296875, 'referece_logps/chosen': -326.3664855957031, 'logits/rejected': -0.48864108324050903, 'logits/chosen': -0.41744109988212585, 'epoch': 0.5}

  8%|▊         | 1344/16104 [6:13:48<73:14:46, 17.86s/it]

  8%|▊         | 1345/16104 [6:14:01<66:36:30, 16.25s/it]

  8%|▊         | 1346/16104 [6:14:12<60:25:57, 14.74s/it]

  8%|▊         | 1347/16104 [6:14:26<58:59:54, 14.39s/it]

  8%|▊         | 1348/16104 [6:14:40<58:54:18, 14.37s/it]

  8%|▊         | 1349/16104 [6:14:52<55:24:54, 13.52s/it]

  8%|▊         | 1350/16104 [6:15:04<54:26:51, 13.29s/it]

  8%|▊         | 1351/16104 [6:15:22<60:29:39, 14.76s/it]

  8%|▊         | 1352/16104 [6:15:41<65:02:04, 15.87s/it]

  8%|▊         | 1353/16104 [6:15:58<66:37:17, 16.26s/it]

  8%|▊         | 1354/16104 [6:16:18<71:00:27, 17.33s/it]

  8%|▊         | 1355/16104 [6:16:36<72:13:32, 17.63s/it]

  8%|▊         | 1356/16104 [6:16:57<76:16:28, 18.62s/it]

  8%|▊         | 1357/16104 [6:17:08<66:33:57, 16.25s/it]

  8%|▊         | 1358/16104 [6:17:19<59:39:17, 14.56s/it]

  8%|▊         | 1359/16104 [6:17:32<58:50:08, 14.36s/it]

  8%|▊         | 1360/16104 [6:17:49<62:00:47, 15.14s/it]

  8%|▊         | 1361/16104 [6:18:11<69:50:44, 17.06s/it]

  8%|▊         | 1362/16104 [6:18:29<70:32:06, 17.22s/it]

  8%|▊         | 1363/16104 [6:18:50<76:07:08, 18.59s/it]
[2024-04-05 21:43:27,264] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1364/16104 [6:19:13<80:41:23, 19.71s/it]

  8%|▊         | 1365/16104 [6:19:31<78:58:57, 19.29s/it]

  8%|▊         | 1366/16104 [6:19:44<71:06:56, 17.37s/it]

  8%|▊         | 1367/16104 [6:20:02<71:33:38, 17.48s/it]
{'loss': 0.4705, 'learning_rate': 1.9842714990181026e-06, 'rewards/chosen': -0.5296434164047241, 'rewards/rejected': -1.2526451349258423, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7230017185211182, 'policy_logps/rejected': -251.15489196777344, 'policy_logps/chosen': -271.19757080078125, 'referece_logps/rejected': -238.62844848632812, 'referece_logps/chosen': -265.901123046875, 'logits/rejected': -0.7466083765029907, 'logits/chosen': -0.6919764280319214, 'epoch': 0.51}

  8%|▊         | 1368/16104 [6:20:21<73:32:53, 17.97s/it]

  9%|▊         | 1369/16104 [6:20:42<78:11:22, 19.10s/it]

  9%|▊         | 1370/16104 [6:21:04<81:07:20, 19.82s/it]


  9%|▊         | 1372/16104 [6:21:44<81:46:38, 19.98s/it]

  9%|▊         | 1373/16104 [6:22:04<81:47:20, 19.99s/it]
{'loss': 0.6164, 'learning_rate': 1.9840575936282177e-06, 'rewards/chosen': -0.7087602019309998, 'rewards/rejected': -0.9687765836715698, 'rewards/accuracies': 0.5, 'rewards/margins': 0.26001644134521484, 'policy_logps/rejected': -293.127685546875, 'policy_logps/chosen': -347.9977722167969, 'referece_logps/rejected': -283.4399108886719, 'referece_logps/chosen': -340.9101867675781, 'logits/rejected': -0.6108105182647705, 'logits/chosen': -0.7778003215789795, 'epoch': 0.51}

  9%|▊         | 1374/16104 [6:22:14<70:28:04, 17.22s/it]

  9%|▊         | 1375/16104 [6:22:25<62:23:50, 15.25s/it]

  9%|▊         | 1376/16104 [6:22:37<58:10:36, 14.22s/it]
[2024-04-05 21:47:09,943] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▊         | 1377/16104 [6:22:55<63:14:31, 15.46s/it]

  9%|▊         | 1378/16104 [6:23:16<69:13:10, 16.92s/it]

  9%|▊         | 1379/16104 [6:23:36<73:37:20, 18.00s/it]

  9%|▊         | 1380/16104 [6:23:59<79:28:15, 19.43s/it]

  9%|▊         | 1381/16104 [6:24:20<81:36:26, 19.95s/it]

  9%|▊         | 1382/16104 [6:24:39<79:56:14, 19.55s/it]

  9%|▊         | 1383/16104 [6:24:59<80:59:49, 19.81s/it]

  9%|▊         | 1384/16104 [6:25:14<75:30:38, 18.47s/it]

  9%|▊         | 1385/16104 [6:25:28<69:50:57, 17.08s/it]

  9%|▊         | 1386/16104 [6:25:47<71:54:29, 17.59s/it]

  9%|▊         | 1387/16104 [6:26:05<72:06:56, 17.64s/it]

  9%|▊         | 1388/16104 [6:26:26<75:56:29, 18.58s/it]
[2024-04-05 21:51:01,288] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▊         | 1389/16104 [6:26:47<78:58:03, 19.32s/it]

  9%|▊         | 1390/16104 [6:27:04<76:01:17, 18.60s/it]


  9%|▊         | 1392/16104 [6:27:46<81:01:41, 19.83s/it]
{'loss': 0.3921, 'learning_rate': 1.9833707739230564e-06, 'rewards/chosen': -0.8463202714920044, 'rewards/rejected': -2.0271155834198, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1807951927185059, 'policy_logps/rejected': -437.6055908203125, 'policy_logps/chosen': -437.44830322265625, 'referece_logps/rejected': -417.3345031738281, 'referece_logps/chosen': -428.98504638671875, 'logits/rejected': 0.09679970145225525, 'logits/chosen': -0.1880083680152893, 'epoch': 0.52}

  9%|▊         | 1393/16104 [6:28:04<78:28:41, 19.20s/it]

  9%|▊         | 1394/16104 [6:28:25<80:52:13, 19.79s/it]

  9%|▊         | 1395/16104 [6:28:43<78:36:43, 19.24s/it]

  9%|▊         | 1396/16104 [6:29:01<77:26:18, 18.95s/it]

  9%|▊         | 1397/16104 [6:29:17<73:25:30, 17.97s/it]

  9%|▊         | 1398/16104 [6:29:36<74:14:35, 18.17s/it]

  9%|▊         | 1399/16104 [6:29:55<76:20:12, 18.69s/it]

  9%|▊         | 1400/16104 [6:30:08<68:28:14, 16.76s/it]

  9%|▊         | 1401/16104 [6:30:22<65:39:28, 16.08s/it]

  9%|▊         | 1402/16104 [6:30:43<71:13:23, 17.44s/it]


  9%|▊         | 1404/16104 [6:31:20<75:09:51, 18.41s/it]

  9%|▊         | 1405/16104 [6:31:34<69:35:04, 17.04s/it]

  9%|▊         | 1406/16104 [6:31:55<74:39:14, 18.29s/it]

  9%|▊         | 1407/16104 [6:32:08<68:04:50, 16.68s/it]

  9%|▊         | 1408/16104 [6:32:29<72:20:10, 17.72s/it]

  9%|▊         | 1409/16104 [6:32:39<63:36:16, 15.58s/it]

  9%|▉         | 1410/16104 [6:32:50<57:39:28, 14.13s/it]

  9%|▉         | 1411/16104 [6:33:00<53:19:35, 13.07s/it]

  9%|▉         | 1412/16104 [6:33:11<50:24:32, 12.35s/it]

  9%|▉         | 1413/16104 [6:33:30<58:57:03, 14.45s/it]

  9%|▉         | 1414/16104 [6:33:53<68:50:46, 16.87s/it]
{'loss': 0.4494, 'learning_rate': 1.98255756931815e-06, 'rewards/chosen': -1.1051324605941772, 'rewards/rejected': -1.8091089725494385, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7039765119552612, 'policy_logps/rejected': -426.8128967285156, 'policy_logps/chosen': -426.257568359375, 'referece_logps/rejected': -408.7218017578125, 'referece_logps/chosen': -415.20623779296875, 'logits/rejected': 1.0064657926559448, 'logits/chosen': 1.028847336769104, 'epoch': 0.53}


  9%|▉         | 1416/16104 [6:34:36<78:38:47, 19.28s/it]

  9%|▉         | 1417/16104 [6:34:50<72:10:39, 17.69s/it]

  9%|▉         | 1418/16104 [6:35:05<69:33:07, 17.05s/it]

  9%|▉         | 1419/16104 [6:35:26<74:19:31, 18.22s/it]

  9%|▉         | 1420/16104 [6:35:38<66:25:05, 16.28s/it]

  9%|▉         | 1421/16104 [6:35:49<59:36:45, 14.62s/it]
{'loss': 0.5042, 'learning_rate': 1.9822947873957138e-06, 'rewards/chosen': -0.5806358456611633, 'rewards/rejected': -1.478455901145935, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8978198170661926, 'policy_logps/rejected': -399.29827880859375, 'policy_logps/chosen': -383.2886047363281, 'referece_logps/rejected': -384.51373291015625, 'referece_logps/chosen': -377.48223876953125, 'logits/rejected': 0.07942406833171844, 'logits/chosen': 0.12051941454410553, 'epoch': 0.53}


  9%|▉         | 1423/16104 [6:36:18<60:19:30, 14.79s/it]

  9%|▉         | 1424/16104 [6:36:37<65:16:27, 16.01s/it]

  9%|▉         | 1425/16104 [6:36:48<58:56:16, 14.45s/it]

  9%|▉         | 1426/16104 [6:37:08<65:38:24, 16.10s/it]

  9%|▉         | 1427/16104 [6:37:25<67:02:07, 16.44s/it]

  9%|▉         | 1428/16104 [6:37:42<67:02:41, 16.45s/it]

  9%|▉         | 1429/16104 [6:37:58<67:16:56, 16.51s/it]

  9%|▉         | 1430/16104 [6:38:15<67:47:21, 16.63s/it]
{'loss': 0.5312, 'learning_rate': 1.981954064036261e-06, 'rewards/chosen': -0.8037315011024475, 'rewards/rejected': -2.0698461532592773, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2661147117614746, 'policy_logps/rejected': -657.3464965820312, 'policy_logps/chosen': -625.7543334960938, 'referece_logps/rejected': -636.6480712890625, 'referece_logps/chosen': -617.717041015625, 'logits/rejected': -0.7079994678497314, 'logits/chosen': -0.7420114278793335, 'epoch': 0.53}


  9%|▉         | 1432/16104 [6:38:45<63:56:24, 15.69s/it]

  9%|▉         | 1433/16104 [6:39:04<69:00:53, 16.93s/it]

  9%|▉         | 1434/16104 [6:39:26<74:36:07, 18.31s/it]

  9%|▉         | 1435/16104 [6:39:43<72:40:08, 17.83s/it]
{'loss': 0.5262, 'learning_rate': 1.9817633829466908e-06, 'rewards/chosen': -0.8198021054267883, 'rewards/rejected': -1.3164136409759521, 'rewards/accuracies': 0.625, 'rewards/margins': 0.49661147594451904, 'policy_logps/rejected': -283.7686462402344, 'policy_logps/chosen': -366.40289306640625, 'referece_logps/rejected': -270.6044921875, 'referece_logps/chosen': -358.20489501953125, 'logits/rejected': -0.34073853492736816, 'logits/chosen': -0.3627871572971344, 'epoch': 0.53}


  9%|▉         | 1437/16104 [6:40:21<76:38:40, 18.81s/it]

  9%|▉         | 1438/16104 [6:40:32<67:54:59, 16.67s/it]

  9%|▉         | 1439/16104 [6:40:49<67:57:14, 16.68s/it]

  9%|▉         | 1440/16104 [6:41:01<62:18:59, 15.30s/it]

  9%|▉         | 1441/16104 [6:41:21<67:58:11, 16.69s/it]

  9%|▉         | 1442/16104 [6:41:43<74:08:33, 18.20s/it]

  9%|▉         | 1443/16104 [6:41:56<68:21:55, 16.79s/it]

  9%|▉         | 1444/16104 [6:42:12<67:40:58, 16.62s/it]

  9%|▉         | 1445/16104 [6:42:27<64:57:27, 15.95s/it]
{'loss': 0.5378, 'learning_rate': 1.98137904240557e-06, 'rewards/chosen': -1.0989443063735962, 'rewards/rejected': -1.6939362287521362, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5949918627738953, 'policy_logps/rejected': -344.4360046386719, 'policy_logps/chosen': -343.0541076660156, 'referece_logps/rejected': -327.49664306640625, 'referece_logps/chosen': -332.064697265625, 'logits/rejected': -0.09509459137916565, 'logits/chosen': -0.12642768025398254, 'epoch': 0.54}


  9%|▉         | 1447/16104 [6:43:06<72:09:25, 17.72s/it]

  9%|▉         | 1448/16104 [6:43:26<75:13:17, 18.48s/it]

  9%|▉         | 1449/16104 [6:43:40<69:00:54, 16.95s/it]

  9%|▉         | 1450/16104 [6:43:58<70:31:04, 17.32s/it]
{'loss': 0.5053, 'learning_rate': 1.9811853833427013e-06, 'rewards/chosen': -1.0475695133209229, 'rewards/rejected': -2.3001022338867188, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2525326013565063, 'policy_logps/rejected': -612.4293823242188, 'policy_logps/chosen': -525.4915771484375, 'referece_logps/rejected': -589.4283447265625, 'referece_logps/chosen': -515.015869140625, 'logits/rejected': -0.0031308233737945557, 'logits/chosen': 0.0455460250377655, 'epoch': 0.54}


  9%|▉         | 1452/16104 [6:44:23<60:26:16, 14.85s/it]

  9%|▉         | 1453/16104 [6:44:43<66:00:36, 16.22s/it]

  9%|▉         | 1454/16104 [6:45:06<74:54:37, 18.41s/it]

  9%|▉         | 1455/16104 [6:45:19<68:00:20, 16.71s/it]

  9%|▉         | 1456/16104 [6:45:35<67:24:11, 16.57s/it]

  9%|▉         | 1457/16104 [6:45:48<63:29:08, 15.60s/it]

  9%|▉         | 1458/16104 [6:46:11<72:18:15, 17.77s/it]
{'loss': 0.5249, 'learning_rate': 1.9808734650077437e-06, 'rewards/chosen': -0.8748756647109985, 'rewards/rejected': -1.0040088891983032, 'rewards/accuracies': 0.625, 'rewards/margins': 0.12913323938846588, 'policy_logps/rejected': -351.3963928222656, 'policy_logps/chosen': -453.5804443359375, 'referece_logps/rejected': -341.3562927246094, 'referece_logps/chosen': -444.8316345214844, 'logits/rejected': -0.8900002837181091, 'logits/chosen': -0.8259032368659973, 'epoch': 0.54}


  9%|▉         | 1460/16104 [6:46:46<72:09:57, 17.74s/it]
{'loss': 0.5683, 'learning_rate': 1.98079508861158e-06, 'rewards/chosen': -0.9055359363555908, 'rewards/rejected': -1.044288158416748, 'rewards/accuracies': 0.5, 'rewards/margins': 0.138752281665802, 'policy_logps/rejected': -390.45330810546875, 'policy_logps/chosen': -311.17236328125, 'referece_logps/rejected': -380.01043701171875, 'referece_logps/chosen': -302.11700439453125, 'logits/rejected': -0.28625375032424927, 'logits/chosen': -0.25529375672340393, 'epoch': 0.54}

  9%|▉         | 1461/16104 [6:47:02<69:26:16, 17.07s/it]


  9%|▉         | 1463/16104 [6:47:34<69:07:50, 17.00s/it]
{'loss': 0.4506, 'learning_rate': 1.9806772264594706e-06, 'rewards/chosen': -1.2843351364135742, 'rewards/rejected': -1.5526832342147827, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2683481276035309, 'policy_logps/rejected': -239.93612670898438, 'policy_logps/chosen': -445.541015625, 'referece_logps/rejected': -224.4093017578125, 'referece_logps/chosen': -432.6976318359375, 'logits/rejected': -1.0285451412200928, 'logits/chosen': -1.1588863134384155, 'epoch': 0.55}


  9%|▉         | 1465/16104 [6:48:13<74:24:47, 18.30s/it]

  9%|▉         | 1466/16104 [6:48:33<76:09:33, 18.73s/it]

  9%|▉         | 1467/16104 [6:48:55<80:15:53, 19.74s/it]

  9%|▉         | 1468/16104 [6:49:07<70:34:23, 17.36s/it]

  9%|▉         | 1469/16104 [6:49:26<73:06:15, 17.98s/it]

  9%|▉         | 1470/16104 [6:49:46<75:36:20, 18.60s/it]

  9%|▉         | 1471/16104 [6:50:05<75:05:57, 18.48s/it]

  9%|▉         | 1472/16104 [6:50:21<72:47:28, 17.91s/it]

  9%|▉         | 1473/16104 [6:50:33<65:47:43, 16.19s/it]

  9%|▉         | 1474/16104 [6:50:49<65:47:42, 16.19s/it]

  9%|▉         | 1475/16104 [6:51:10<71:29:16, 17.59s/it]
{'loss': 0.6029, 'learning_rate': 1.9802022079692308e-06, 'rewards/chosen': -1.2702186107635498, 'rewards/rejected': -1.4468204975128174, 'rewards/accuracies': 0.75, 'rewards/margins': 0.17660188674926758, 'policy_logps/rejected': -294.16241455078125, 'policy_logps/chosen': -289.8606872558594, 'referece_logps/rejected': -279.6942138671875, 'referece_logps/chosen': -277.15850830078125, 'logits/rejected': -0.5738054513931274, 'logits/chosen': -0.5740739107131958, 'epoch': 0.55}

  9%|▉         | 1476/16104 [6:51:22<64:08:47, 15.79s/it]


  9%|▉         | 1478/16104 [6:51:54<63:28:32, 15.62s/it]

  9%|▉         | 1479/16104 [6:52:13<67:29:19, 16.61s/it]

  9%|▉         | 1480/16104 [6:52:27<63:31:27, 15.64s/it]

  9%|▉         | 1481/16104 [6:52:48<70:52:41, 17.45s/it]

  9%|▉         | 1482/16104 [6:53:01<64:42:24, 15.93s/it]

  9%|▉         | 1483/16104 [6:53:18<66:07:12, 16.28s/it]
{'loss': 0.6343, 'learning_rate': 1.9798823567308173e-06, 'rewards/chosen': -0.7737041115760803, 'rewards/rejected': -1.4086412191390991, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6349371075630188, 'policy_logps/rejected': -306.32696533203125, 'policy_logps/chosen': -298.9829406738281, 'referece_logps/rejected': -292.2405700683594, 'referece_logps/chosen': -291.24591064453125, 'logits/rejected': -0.8417679667472839, 'logits/chosen': -0.711303174495697, 'epoch': 0.55}

  9%|▉         | 1484/16104 [6:53:30<61:16:51, 15.09s/it]


  9%|▉         | 1486/16104 [6:54:04<63:28:10, 15.63s/it]

  9%|▉         | 1487/16104 [6:54:23<68:35:09, 16.89s/it]

  9%|▉         | 1488/16104 [6:54:36<63:54:46, 15.74s/it]

  9%|▉         | 1489/16104 [6:54:59<72:20:10, 17.82s/it]

  9%|▉         | 1490/16104 [6:55:17<72:42:51, 17.91s/it]
{'loss': 0.4533, 'learning_rate': 1.979600405874712e-06, 'rewards/chosen': -1.032238245010376, 'rewards/rejected': -1.7408514022827148, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7086131572723389, 'policy_logps/rejected': -479.76409912109375, 'policy_logps/chosen': -541.4120483398438, 'referece_logps/rejected': -462.3555908203125, 'referece_logps/chosen': -531.089599609375, 'logits/rejected': -0.5138419270515442, 'logits/chosen': -0.46375107765197754, 'epoch': 0.56}

  9%|▉         | 1491/16104 [6:55:34<71:48:39, 17.69s/it]


  9%|▉         | 1493/16104 [6:56:16<78:04:00, 19.23s/it]

  9%|▉         | 1494/16104 [6:56:34<76:51:51, 18.94s/it]

  9%|▉         | 1495/16104 [6:56:55<79:42:53, 19.64s/it]

  9%|▉         | 1496/16104 [6:57:08<71:15:23, 17.56s/it]

  9%|▉         | 1497/16104 [6:57:27<72:53:43, 17.97s/it]

  9%|▉         | 1498/16104 [6:57:39<65:34:38, 16.16s/it]

  9%|▉         | 1499/16104 [6:57:59<70:52:16, 17.47s/it]

  9%|▉         | 1500/16104 [6:58:20<74:41:31, 18.41s/it]
{'loss': 0.4322, 'learning_rate': 1.9791942508175923e-06, 'rewards/chosen': -0.8403807878494263, 'rewards/rejected': -1.5889294147491455, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7485485076904297, 'policy_logps/rejected': -309.88037109375, 'policy_logps/chosen': -280.9987487792969, 'referece_logps/rejected': -293.9910583496094, 'referece_logps/chosen': -272.594970703125, 'logits/rejected': -0.27088820934295654, 'logits/chosen': -0.2687603533267975, 'epoch': 0.56}

  9%|▉         | 1501/16104 [6:58:55<94:31:39, 23.30s/it]


  9%|▉         | 1503/16104 [6:59:32<84:43:59, 20.89s/it]

  9%|▉         | 1504/16104 [6:59:53<85:31:15, 21.09s/it]

  9%|▉         | 1505/16104 [7:00:06<75:34:21, 18.64s/it]
{'loss': 0.5249, 'learning_rate': 1.978989687805412e-06, 'rewards/chosen': -0.8801311254501343, 'rewards/rejected': -1.4392879009246826, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5591567754745483, 'policy_logps/rejected': -366.13818359375, 'policy_logps/chosen': -338.7028503417969, 'referece_logps/rejected': -351.7453308105469, 'referece_logps/chosen': -329.9014892578125, 'logits/rejected': -0.5345269441604614, 'logits/chosen': -0.484283447265625, 'epoch': 0.56}


  9%|▉         | 1507/16104 [7:00:43<74:56:30, 18.48s/it]

  9%|▉         | 1508/16104 [7:00:58<70:25:56, 17.37s/it]
{'loss': 0.5624, 'learning_rate': 1.9788664747623017e-06, 'rewards/chosen': -0.8909814357757568, 'rewards/rejected': -1.1481633186340332, 'rewards/accuracies': 0.875, 'rewards/margins': 0.2571818232536316, 'policy_logps/rejected': -394.3630676269531, 'policy_logps/chosen': -436.9362487792969, 'referece_logps/rejected': -382.8814392089844, 'referece_logps/chosen': -428.0263977050781, 'logits/rejected': -0.1976739764213562, 'logits/chosen': -0.20334303379058838, 'epoch': 0.56}


  9%|▉         | 1510/16104 [7:01:30<66:16:09, 16.35s/it]

  9%|▉         | 1511/16104 [7:01:49<70:08:49, 17.30s/it]
{'loss': 0.557, 'learning_rate': 1.9787429053471403e-06, 'rewards/chosen': -0.7542139291763306, 'rewards/rejected': -1.4838060140609741, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7295921444892883, 'policy_logps/rejected': -342.43096923828125, 'policy_logps/chosen': -467.6222839355469, 'referece_logps/rejected': -327.5928955078125, 'referece_logps/chosen': -460.0801696777344, 'logits/rejected': -1.007527470588684, 'logits/chosen': -1.0651986598968506, 'epoch': 0.56}

  9%|▉         | 1512/16104 [7:02:10<74:48:27, 18.46s/it]

  9%|▉         | 1513/16104 [7:02:25<69:46:13, 17.21s/it]


  9%|▉         | 1515/16104 [7:02:57<65:38:26, 16.20s/it]
{'loss': 0.5618, 'learning_rate': 1.978577591848175e-06, 'rewards/chosen': -0.6806142330169678, 'rewards/rejected': -1.77238130569458, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0917669534683228, 'policy_logps/rejected': -478.18603515625, 'policy_logps/chosen': -360.7954406738281, 'referece_logps/rejected': -460.46221923828125, 'referece_logps/chosen': -353.9892883300781, 'logits/rejected': -1.5225692987442017, 'logits/chosen': -1.2489794492721558, 'epoch': 0.56}


  9%|▉         | 1517/16104 [7:03:24<60:10:16, 14.85s/it]
{'loss': 0.5811, 'learning_rate': 1.978494697580742e-06, 'rewards/chosen': -1.1980534791946411, 'rewards/rejected': -1.5881626605987549, 'rewards/accuracies': 0.625, 'rewards/margins': 0.39010921120643616, 'policy_logps/rejected': -443.8951110839844, 'policy_logps/chosen': -316.7055358886719, 'referece_logps/rejected': -428.01348876953125, 'referece_logps/chosen': -304.7250061035156, 'logits/rejected': -0.8481094241142273, 'logits/chosen': -0.7399268746376038, 'epoch': 0.57}


  9%|▉         | 1519/16104 [7:03:48<53:54:40, 13.31s/it]

  9%|▉         | 1520/16104 [7:04:03<55:42:43, 13.75s/it]
{'loss': 0.5765, 'learning_rate': 1.978370059319869e-06, 'rewards/chosen': -0.8903834819793701, 'rewards/rejected': -1.1954425573349, 'rewards/accuracies': 0.75, 'rewards/margins': 0.30505916476249695, 'policy_logps/rejected': -316.68670654296875, 'policy_logps/chosen': -383.6204833984375, 'referece_logps/rejected': -304.7322692871094, 'referece_logps/chosen': -374.7166442871094, 'logits/rejected': -0.6640231013298035, 'logits/chosen': -0.7187619805335999, 'epoch': 0.57}

  9%|▉         | 1521/16104 [7:04:15<53:04:17, 13.10s/it]


  9%|▉         | 1523/16104 [7:04:45<57:17:49, 14.15s/it]

  9%|▉         | 1524/16104 [7:04:57<54:58:25, 13.57s/it]

  9%|▉         | 1525/16104 [7:05:11<54:24:04, 13.43s/it]
{'loss': 0.4301, 'learning_rate': 1.9781615373712737e-06, 'rewards/chosen': -1.2163772583007812, 'rewards/rejected': -1.5513025522232056, 'rewards/accuracies': 0.875, 'rewards/margins': 0.33492541313171387, 'policy_logps/rejected': -202.55377197265625, 'policy_logps/chosen': -263.9091491699219, 'referece_logps/rejected': -187.04074096679688, 'referece_logps/chosen': -251.745361328125, 'logits/rejected': -0.6780242323875427, 'logits/chosen': -1.1207009553909302, 'epoch': 0.57}

  9%|▉         | 1526/16104 [7:05:27<57:44:18, 14.26s/it]


  9%|▉         | 1528/16104 [7:06:02<65:10:53, 16.10s/it]

  9%|▉         | 1529/16104 [7:06:13<58:32:31, 14.46s/it]
{'loss': 0.6509, 'learning_rate': 1.9779940075714647e-06, 'rewards/chosen': -0.7160667777061462, 'rewards/rejected': -1.0421512126922607, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3260844945907593, 'policy_logps/rejected': -429.6099853515625, 'policy_logps/chosen': -373.41192626953125, 'referece_logps/rejected': -419.1885070800781, 'referece_logps/chosen': -366.25128173828125, 'logits/rejected': -1.2785396575927734, 'logits/chosen': -1.0560839176177979, 'epoch': 0.57}

 10%|▉         | 1530/16104 [7:06:31<63:30:19, 15.69s/it]


 10%|▉         | 1532/16104 [7:07:02<61:28:39, 15.19s/it]

 10%|▉         | 1533/16104 [7:07:15<58:06:06, 14.35s/it]
{'loss': 0.4877, 'learning_rate': 1.9778258447860424e-06, 'rewards/chosen': -1.6133396625518799, 'rewards/rejected': -2.176351547241211, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5630117654800415, 'policy_logps/rejected': -357.2215881347656, 'policy_logps/chosen': -393.9588623046875, 'referece_logps/rejected': -335.45806884765625, 'referece_logps/chosen': -377.8254699707031, 'logits/rejected': -0.30564284324645996, 'logits/chosen': -0.4545111358165741, 'epoch': 0.57}

 10%|▉         | 1534/16104 [7:07:36<66:03:14, 16.32s/it]

 10%|▉         | 1535/16104 [7:07:55<70:04:12, 17.31s/it]

 10%|▉         | 1536/16104 [7:08:09<65:51:10, 16.27s/it]


 10%|▉         | 1538/16104 [7:08:38<62:35:39, 15.47s/it]

 10%|▉         | 1539/16104 [7:08:52<60:00:55, 14.83s/it]

 10%|▉         | 1540/16104 [7:09:05<57:45:56, 14.28s/it]

 10%|▉         | 1541/16104 [7:09:21<59:34:33, 14.73s/it]
{'loss': 0.4923, 'learning_rate': 1.9774876206941267e-06, 'rewards/chosen': -0.23296965658664703, 'rewards/rejected': -1.4857583045959473, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2527885437011719, 'policy_logps/rejected': -362.9422302246094, 'policy_logps/chosen': -442.2240905761719, 'referece_logps/rejected': -348.0846862792969, 'referece_logps/chosen': -439.8944091796875, 'logits/rejected': 0.7961122393608093, 'logits/chosen': 0.9092086553573608, 'epoch': 0.57}

 10%|▉         | 1542/16104 [7:09:40<64:53:51, 16.04s/it]

 10%|▉         | 1543/16104 [7:09:53<61:42:22, 15.26s/it]


 10%|▉         | 1545/16104 [7:10:29<67:08:15, 16.60s/it]

 10%|▉         | 1546/16104 [7:10:48<70:33:01, 17.45s/it]
{'loss': 0.3859, 'learning_rate': 1.9772749454947432e-06, 'rewards/chosen': -0.993362545967102, 'rewards/rejected': -2.4424638748168945, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4491015672683716, 'policy_logps/rejected': -520.9688720703125, 'policy_logps/chosen': -381.92730712890625, 'referece_logps/rejected': -496.54425048828125, 'referece_logps/chosen': -371.99371337890625, 'logits/rejected': -0.5727588534355164, 'logits/chosen': -0.585079550743103, 'epoch': 0.58}


 10%|▉         | 1548/16104 [7:11:31<78:32:18, 19.42s/it]
{'loss': 0.4086, 'learning_rate': 1.9771895986753263e-06, 'rewards/chosen': -0.35823822021484375, 'rewards/rejected': -2.038074016571045, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6798357963562012, 'policy_logps/rejected': -277.12554931640625, 'policy_logps/chosen': -277.3187255859375, 'referece_logps/rejected': -256.7447814941406, 'referece_logps/chosen': -273.736328125, 'logits/rejected': -0.5433462858200073, 'logits/chosen': -0.6192602515220642, 'epoch': 0.58}


 10%|▉         | 1550/16104 [7:12:00<68:53:25, 17.04s/it]
{'loss': 0.4618, 'learning_rate': 1.9771040937396584e-06, 'rewards/chosen': -0.6367195248603821, 'rewards/rejected': -1.9580821990966797, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3213626146316528, 'policy_logps/rejected': -338.8687744140625, 'policy_logps/chosen': -285.4847106933594, 'referece_logps/rejected': -319.2879638671875, 'referece_logps/chosen': -279.1175231933594, 'logits/rejected': -1.5669137239456177, 'logits/chosen': -1.3354209661483765, 'epoch': 0.58}


 10%|▉         | 1552/16104 [7:12:37<71:47:08, 17.76s/it]
{'loss': 0.5114, 'learning_rate': 1.977018430701575e-06, 'rewards/chosen': -1.0403473377227783, 'rewards/rejected': -1.8838809728622437, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8435336351394653, 'policy_logps/rejected': -485.6045837402344, 'policy_logps/chosen': -450.6282043457031, 'referece_logps/rejected': -466.7657470703125, 'referece_logps/chosen': -440.22479248046875, 'logits/rejected': -0.5247191786766052, 'logits/chosen': -0.5368319749832153, 'epoch': 0.58}

 10%|▉         | 1553/16104 [7:12:55<72:57:35, 18.05s/it]


 10%|▉         | 1555/16104 [7:13:33<73:38:01, 18.22s/it]

 10%|▉         | 1556/16104 [7:13:55<78:17:42, 19.37s/it]
{'loss': 0.5652, 'learning_rate': 1.9768466303736324e-06, 'rewards/chosen': -0.7999789118766785, 'rewards/rejected': -1.628475546836853, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8284967541694641, 'policy_logps/rejected': -442.6844177246094, 'policy_logps/chosen': -394.4463806152344, 'referece_logps/rejected': -426.399658203125, 'referece_logps/chosen': -386.44659423828125, 'logits/rejected': -0.9324623346328735, 'logits/chosen': -1.0768029689788818, 'epoch': 0.58}


 10%|▉         | 1558/16104 [7:14:29<74:57:49, 18.55s/it]

 10%|▉         | 1559/16104 [7:14:43<69:25:43, 17.18s/it]

 10%|▉         | 1560/16104 [7:14:59<68:15:32, 16.90s/it]

 10%|▉         | 1561/16104 [7:15:20<73:20:20, 18.15s/it]

 10%|▉         | 1562/16104 [7:15:32<65:59:58, 16.34s/it]
{'loss': 0.64, 'learning_rate': 1.9765877444609565e-06, 'rewards/chosen': -1.1002062559127808, 'rewards/rejected': -1.6355791091918945, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5353727340698242, 'policy_logps/rejected': -502.51287841796875, 'policy_logps/chosen': -575.1588745117188, 'referece_logps/rejected': -486.15704345703125, 'referece_logps/chosen': -564.1567993164062, 'logits/rejected': -0.5790053009986877, 'logits/chosen': -0.620836615562439, 'epoch': 0.58}

 10%|▉         | 1563/16104 [7:15:46<62:20:29, 15.43s/it]


 10%|▉         | 1565/16104 [7:16:19<65:17:05, 16.17s/it]

 10%|▉         | 1566/16104 [7:16:42<74:21:06, 18.41s/it]

 10%|▉         | 1567/16104 [7:16:59<72:27:44, 17.94s/it]
{'loss': 0.5923, 'learning_rate': 1.976370919804743e-06, 'rewards/chosen': -0.678429365158081, 'rewards/rejected': -1.276983380317688, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5985538959503174, 'policy_logps/rejected': -416.8652038574219, 'policy_logps/chosen': -392.4453430175781, 'referece_logps/rejected': -404.09539794921875, 'referece_logps/chosen': -385.6610412597656, 'logits/rejected': -0.44442903995513916, 'logits/chosen': -0.44026097655296326, 'epoch': 0.58}

 10%|▉         | 1568/16104 [7:17:16<71:10:45, 17.63s/it]

 10%|▉         | 1569/16104 [7:17:30<66:50:10, 16.55s/it]


 10%|▉         | 1571/16104 [7:18:10<74:13:19, 18.39s/it]

 10%|▉         | 1572/16104 [7:18:27<72:17:02, 17.91s/it]
{'loss': 0.499, 'learning_rate': 1.976153107749959e-06, 'rewards/chosen': -0.4717057943344116, 'rewards/rejected': -1.4346258640289307, 'rewards/accuracies': 0.875, 'rewards/margins': 0.962920069694519, 'policy_logps/rejected': -309.43109130859375, 'policy_logps/chosen': -295.434326171875, 'referece_logps/rejected': -295.0848388671875, 'referece_logps/chosen': -290.71728515625, 'logits/rejected': -0.3064931631088257, 'logits/chosen': -0.3337121903896332, 'epoch': 0.59}

 10%|▉         | 1573/16104 [7:18:44<71:11:53, 17.64s/it]

 10%|▉         | 1574/16104 [7:18:58<66:46:05, 16.54s/it]

 10%|▉         | 1575/16104 [7:19:10<61:04:28, 15.13s/it]

 10%|▉         | 1576/16104 [7:19:30<66:46:13, 16.55s/it]


 10%|▉         | 1578/16104 [7:20:05<68:30:29, 16.98s/it]
{'loss': 0.5448, 'learning_rate': 1.9758904302283175e-06, 'rewards/chosen': -0.4551669955253601, 'rewards/rejected': -1.4462156295776367, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9910486340522766, 'policy_logps/rejected': -364.61395263671875, 'policy_logps/chosen': -465.2225341796875, 'referece_logps/rejected': -350.15179443359375, 'referece_logps/chosen': -460.6708679199219, 'logits/rejected': -1.0201616287231445, 'logits/chosen': -0.956500232219696, 'epoch': 0.59}

 10%|▉         | 1579/16104 [7:20:24<70:45:05, 17.54s/it]

 10%|▉         | 1580/16104 [7:20:36<64:07:39, 15.90s/it]


 10%|▉         | 1582/16104 [7:21:19<75:14:28, 18.65s/it]
{'loss': 0.4326, 'learning_rate': 1.9757145223267645e-06, 'rewards/chosen': -0.7609775066375732, 'rewards/rejected': -2.09108567237854, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3301081657409668, 'policy_logps/rejected': -336.5072937011719, 'policy_logps/chosen': -336.9851989746094, 'referece_logps/rejected': -315.596435546875, 'referece_logps/chosen': -329.3753662109375, 'logits/rejected': -0.1553620547056198, 'logits/chosen': 0.055619314312934875, 'epoch': 0.59}

 10%|▉         | 1583/16104 [7:21:40<78:25:50, 19.44s/it]

 10%|▉         | 1584/16104 [7:21:58<76:14:09, 18.90s/it]


 10%|▉         | 1586/16104 [7:22:33<72:49:08, 18.06s/it]

 10%|▉         | 1587/16104 [7:22:51<72:06:28, 17.88s/it]
{'loss': 0.5506, 'learning_rate': 1.9754937494018935e-06, 'rewards/chosen': -1.7493399381637573, 'rewards/rejected': -2.1909103393554688, 'rewards/accuracies': 0.625, 'rewards/margins': 0.44157037138938904, 'policy_logps/rejected': -616.141357421875, 'policy_logps/chosen': -641.0968017578125, 'referece_logps/rejected': -594.2322387695312, 'referece_logps/chosen': -623.6034545898438, 'logits/rejected': 0.390088826417923, 'logits/chosen': 0.46337395906448364, 'epoch': 0.59}

 10%|▉         | 1588/16104 [7:23:06<68:47:26, 17.06s/it]


 10%|▉         | 1590/16104 [7:23:43<72:38:42, 18.02s/it]
{'loss': 0.5153, 'learning_rate': 1.9753608121071233e-06, 'rewards/chosen': -0.7154783606529236, 'rewards/rejected': -2.13533616065979, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4198579788208008, 'policy_logps/rejected': -373.8853759765625, 'policy_logps/chosen': -265.2518005371094, 'referece_logps/rejected': -352.5320129394531, 'referece_logps/chosen': -258.0970153808594, 'logits/rejected': 0.4164714217185974, 'logits/chosen': 0.5528473258018494, 'epoch': 0.59}

 10%|▉         | 1591/16104 [7:24:02<74:04:22, 18.37s/it]

 10%|▉         | 1592/16104 [7:24:18<70:47:05, 17.56s/it]

 10%|▉         | 1593/16104 [7:24:38<73:56:10, 18.34s/it]

 10%|▉         | 1594/16104 [7:24:50<66:05:22, 16.40s/it]


 10%|▉         | 1596/16104 [7:25:27<70:37:28, 17.52s/it]

 10%|▉         | 1597/16104 [7:25:42<67:06:28, 16.65s/it]

 10%|▉         | 1598/16104 [7:25:57<65:47:21, 16.33s/it]
{'loss': 0.5513, 'learning_rate': 1.975004576762555e-06, 'rewards/chosen': -0.7069649696350098, 'rewards/rejected': -1.8767327070236206, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1697678565979004, 'policy_logps/rejected': -721.5032348632812, 'policy_logps/chosen': -500.296142578125, 'referece_logps/rejected': -702.7359008789062, 'referece_logps/chosen': -493.2264709472656, 'logits/rejected': -1.0950298309326172, 'logits/chosen': -0.9470092058181763, 'epoch': 0.6}

 10%|▉         | 1599/16104 [7:26:09<59:32:56, 14.78s/it]

 10%|▉         | 1600/16104 [7:26:30<68:04:25, 16.90s/it]

 10%|▉         | 1601/16104 [7:26:45<64:53:36, 16.11s/it]

 10%|▉         | 1602/16104 [7:27:04<69:05:16, 17.15s/it]


 10%|▉         | 1604/16104 [7:27:36<66:10:37, 16.43s/it]
{'loss': 0.4773, 'learning_rate': 1.974735743695448e-06, 'rewards/chosen': -0.7814876437187195, 'rewards/rejected': -1.7200660705566406, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9385784268379211, 'policy_logps/rejected': -437.71148681640625, 'policy_logps/chosen': -517.9155883789062, 'referece_logps/rejected': -420.5108642578125, 'referece_logps/chosen': -510.1007080078125, 'logits/rejected': 0.11750203371047974, 'logits/chosen': 0.005413174629211426, 'epoch': 0.6}


 10%|▉         | 1606/16104 [7:28:15<72:38:28, 18.04s/it]

 10%|▉         | 1607/16104 [7:28:26<64:01:29, 15.90s/it]
{'loss': 0.541, 'learning_rate': 1.974600794835105e-06, 'rewards/chosen': -1.2120078802108765, 'rewards/rejected': -1.1564617156982422, 'rewards/accuracies': 0.625, 'rewards/margins': -0.05554629862308502, 'policy_logps/rejected': -336.2115783691406, 'policy_logps/chosen': -469.2198791503906, 'referece_logps/rejected': -324.64697265625, 'referece_logps/chosen': -457.09979248046875, 'logits/rejected': -0.47389933466911316, 'logits/chosen': -0.40773770213127136, 'epoch': 0.6}


 10%|▉         | 1609/16104 [7:28:51<58:20:10, 14.49s/it]
{'loss': 0.4113, 'learning_rate': 1.9745106318034705e-06, 'rewards/chosen': -1.6204603910446167, 'rewards/rejected': -3.03141713142395, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4109565019607544, 'policy_logps/rejected': -449.73004150390625, 'policy_logps/chosen': -401.762451171875, 'referece_logps/rejected': -419.4158630371094, 'referece_logps/chosen': -385.557861328125, 'logits/rejected': 0.03895552456378937, 'logits/chosen': -0.0025707310996949673, 'epoch': 0.6}

 10%|▉         | 1610/16104 [7:29:05<57:03:30, 14.17s/it]

 10%|█         | 1611/16104 [7:29:25<64:21:22, 15.99s/it]


 10%|█         | 1613/16104 [7:29:49<56:14:41, 13.97s/it]
{'loss': 0.5408, 'learning_rate': 1.9743298327064916e-06, 'rewards/chosen': -1.1728734970092773, 'rewards/rejected': -2.157712936401367, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9848396182060242, 'policy_logps/rejected': -297.06787109375, 'policy_logps/chosen': -380.10638427734375, 'referece_logps/rejected': -275.49072265625, 'referece_logps/chosen': -368.3776550292969, 'logits/rejected': -1.6108055114746094, 'logits/chosen': -1.5768858194351196, 'epoch': 0.6}


 10%|█         | 1615/16104 [7:30:15<54:36:54, 13.57s/it]
{'loss': 0.5061, 'learning_rate': 1.974239196670402e-06, 'rewards/chosen': -0.46908190846443176, 'rewards/rejected': -1.7239370346069336, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2548552751541138, 'policy_logps/rejected': -360.8963623046875, 'policy_logps/chosen': -417.8769226074219, 'referece_logps/rejected': -343.656982421875, 'referece_logps/chosen': -413.1860656738281, 'logits/rejected': -0.728592574596405, 'logits/chosen': -0.5804306864738464, 'epoch': 0.6}


 10%|█         | 1617/16104 [7:30:50<62:29:39, 15.53s/it]

 10%|█         | 1618/16104 [7:31:12<70:02:02, 17.40s/it]

 10%|█         | 1619/16104 [7:31:33<75:03:05, 18.65s/it]
{'loss': 0.5141, 'learning_rate': 1.9740574516963507e-06, 'rewards/chosen': -1.5638798475265503, 'rewards/rejected': -2.080181121826172, 'rewards/accuracies': 0.5, 'rewards/margins': 0.516301155090332, 'policy_logps/rejected': -342.3438415527344, 'policy_logps/chosen': -497.22271728515625, 'referece_logps/rejected': -321.5420227050781, 'referece_logps/chosen': -481.5839538574219, 'logits/rejected': 0.6441570520401001, 'logits/chosen': 0.6063930988311768, 'epoch': 0.6}


 10%|█         | 1621/16104 [7:31:58<61:58:39, 15.41s/it]
{'loss': 0.6207, 'learning_rate': 1.9739663427877963e-06, 'rewards/chosen': -1.180521845817566, 'rewards/rejected': -1.6726189851760864, 'rewards/accuracies': 0.75, 'rewards/margins': 0.49209707975387573, 'policy_logps/rejected': -335.01031494140625, 'policy_logps/chosen': -530.6461181640625, 'referece_logps/rejected': -318.2841491699219, 'referece_logps/chosen': -518.8409423828125, 'logits/rejected': -0.4558091163635254, 'logits/chosen': -0.5194287300109863, 'epoch': 0.6}


 10%|█         | 1623/16104 [7:32:32<63:34:16, 15.80s/it]

 10%|█         | 1624/16104 [7:32:44<58:57:30, 14.66s/it]

 10%|█         | 1625/16104 [7:32:58<58:32:41, 14.56s/it]

 10%|█         | 1626/16104 [7:33:19<66:37:18, 16.57s/it]
{'loss': 0.6019, 'learning_rate': 1.973737881071888e-06, 'rewards/chosen': -1.3522412776947021, 'rewards/rejected': -2.0838303565979004, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7315892577171326, 'policy_logps/rejected': -336.0478210449219, 'policy_logps/chosen': -419.6231994628906, 'referece_logps/rejected': -315.2095031738281, 'referece_logps/chosen': -406.10076904296875, 'logits/rejected': 0.19169190526008606, 'logits/chosen': 0.19993948936462402, 'epoch': 0.61}


 10%|█         | 1628/16104 [7:34:02<76:19:35, 18.98s/it]

 10%|█         | 1629/16104 [7:34:14<67:30:35, 16.79s/it]

 10%|█         | 1630/16104 [7:34:34<71:06:18, 17.69s/it]

 10%|█         | 1631/16104 [7:34:44<62:53:42, 15.64s/it]
{'loss': 0.6649, 'learning_rate': 1.9735084346201862e-06, 'rewards/chosen': -1.637438178062439, 'rewards/rejected': -1.1345614194869995, 'rewards/accuracies': 0.375, 'rewards/margins': -0.5028768181800842, 'policy_logps/rejected': -497.7891540527344, 'policy_logps/chosen': -369.22491455078125, 'referece_logps/rejected': -486.4435729980469, 'referece_logps/chosen': -352.85052490234375, 'logits/rejected': 0.2923003137111664, 'logits/chosen': 0.3251816928386688, 'epoch': 0.61}


 10%|█         | 1633/16104 [7:35:14<62:01:02, 15.43s/it]

 10%|█         | 1634/16104 [7:35:34<67:36:21, 16.82s/it]

 10%|█         | 1635/16104 [7:35:48<64:35:25, 16.07s/it]

 10%|█         | 1636/16104 [7:36:10<71:12:17, 17.72s/it]

 10%|█         | 1637/16104 [7:36:28<72:02:46, 17.93s/it]
{'loss': 0.4211, 'learning_rate': 1.973231799353677e-06, 'rewards/chosen': -1.012160062789917, 'rewards/rejected': -1.8169505596160889, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8047904968261719, 'policy_logps/rejected': -322.151123046875, 'policy_logps/chosen': -468.81298828125, 'referece_logps/rejected': -303.98162841796875, 'referece_logps/chosen': -458.6914367675781, 'logits/rejected': -1.1998635530471802, 'logits/chosen': -1.2986801862716675, 'epoch': 0.61}


 10%|█         | 1639/16104 [7:37:06<74:23:48, 18.52s/it]
{'loss': 0.5351, 'learning_rate': 1.9731392726265536e-06, 'rewards/chosen': -0.9422944784164429, 'rewards/rejected': -1.97991943359375, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0376248359680176, 'policy_logps/rejected': -365.6045837402344, 'policy_logps/chosen': -407.27960205078125, 'referece_logps/rejected': -345.80535888671875, 'referece_logps/chosen': -397.85662841796875, 'logits/rejected': 0.17884224653244019, 'logits/chosen': 0.20793689787387848, 'epoch': 0.61}


 10%|█         | 1641/16104 [7:37:37<66:40:28, 16.60s/it]
{'loss': 0.5588, 'learning_rate': 1.9730465884385513e-06, 'rewards/chosen': -1.087321400642395, 'rewards/rejected': -1.0297071933746338, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0576142743229866, 'policy_logps/rejected': -411.39752197265625, 'policy_logps/chosen': -377.3932189941406, 'referece_logps/rejected': -401.1004638671875, 'referece_logps/chosen': -366.5199890136719, 'logits/rejected': -1.3722240924835205, 'logits/chosen': -1.3629467487335205, 'epoch': 0.61}

 10%|█         | 1642/16104 [7:37:58<72:27:56, 18.04s/it]

 10%|█         | 1643/16104 [7:38:14<69:39:38, 17.34s/it]

 10%|█         | 1644/16104 [7:38:29<67:25:26, 16.79s/it]

 10%|█         | 1645/16104 [7:38:48<69:38:26, 17.34s/it]

 10%|█         | 1646/16104 [7:39:08<72:55:40, 18.16s/it]

 10%|█         | 1647/16104 [7:39:24<70:31:54, 17.56s/it]

 10%|█         | 1648/16104 [7:39:40<68:33:09, 17.07s/it]

 10%|█         | 1649/16104 [7:39:55<66:01:33, 16.44s/it]

 10%|█         | 1650/16104 [7:40:12<66:36:16, 16.59s/it]


 10%|█         | 1652/16104 [7:40:39<60:06:25, 14.97s/it]

 10%|█         | 1653/16104 [7:40:55<61:23:53, 15.30s/it]
{'loss': 0.44, 'learning_rate': 1.972487177473692e-06, 'rewards/chosen': -1.2700551748275757, 'rewards/rejected': -2.109609365463257, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8395544290542603, 'policy_logps/rejected': -264.49334716796875, 'policy_logps/chosen': -593.425537109375, 'referece_logps/rejected': -243.39723205566406, 'referece_logps/chosen': -580.7249755859375, 'logits/rejected': -0.49976634979248047, 'logits/chosen': -0.566866934299469, 'epoch': 0.62}

 10%|█         | 1654/16104 [7:41:14<66:46:04, 16.63s/it]

 10%|█         | 1655/16104 [7:41:34<70:33:22, 17.58s/it]

 10%|█         | 1656/16104 [7:41:46<63:26:30, 15.81s/it]


 10%|█         | 1658/16104 [7:42:19<66:35:25, 16.59s/it]
{'loss': 0.6145, 'learning_rate': 1.9722524174835506e-06, 'rewards/chosen': -0.6834689974784851, 'rewards/rejected': -0.9063127040863037, 'rewards/accuracies': 0.625, 'rewards/margins': 0.22284378111362457, 'policy_logps/rejected': -473.9267578125, 'policy_logps/chosen': -470.85369873046875, 'referece_logps/rejected': -464.8636474609375, 'referece_logps/chosen': -464.01904296875, 'logits/rejected': -0.7704856991767883, 'logits/chosen': -0.6862050294876099, 'epoch': 0.62}

 10%|█         | 1659/16104 [7:42:29<59:26:43, 14.82s/it]

 10%|█         | 1660/16104 [7:42:47<63:18:24, 15.78s/it]
[2024-04-05 23:07:15,798] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 10%|█         | 1661/16104 [7:43:01<60:53:12, 15.18s/it]

 10%|█         | 1662/16104 [7:43:14<58:19:10, 14.54s/it]

 10%|█         | 1663/16104 [7:43:34<64:21:43, 16.04s/it]

 10%|█         | 1664/16104 [7:43:45<58:26:52, 14.57s/it]

 10%|█         | 1665/16104 [7:43:56<53:45:40, 13.40s/it]


 10%|█         | 1667/16104 [7:44:17<48:16:25, 12.04s/it]
{'loss': 0.5268, 'learning_rate': 1.9718273719129205e-06, 'rewards/chosen': -0.8272348642349243, 'rewards/rejected': -1.2040998935699463, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3768649101257324, 'policy_logps/rejected': -336.8193054199219, 'policy_logps/chosen': -357.39935302734375, 'referece_logps/rejected': -324.7783203125, 'referece_logps/chosen': -349.1269836425781, 'logits/rejected': -0.35687631368637085, 'logits/chosen': -0.37338775396347046, 'epoch': 0.62}

 10%|█         | 1668/16104 [7:44:28<46:43:59, 11.65s/it]

 10%|█         | 1669/16104 [7:44:38<45:34:35, 11.37s/it]

 10%|█         | 1670/16104 [7:44:49<44:42:51, 11.15s/it]

 10%|█         | 1671/16104 [7:45:00<44:16:40, 11.04s/it]


 10%|█         | 1673/16104 [7:45:31<54:59:27, 13.72s/it]
[2024-04-05 23:09:45,461] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5151, 'learning_rate': 1.971542239066432e-06, 'rewards/chosen': -0.9974494576454163, 'rewards/rejected': -2.66583251953125, 'rewards/accuracies': 1.0, 'rewards/margins': 1.668383240699768, 'policy_logps/rejected': -400.04736328125, 'policy_logps/chosen': -309.16705322265625, 'referece_logps/rejected': -373.3890686035156, 'referece_logps/chosen': -299.19256591796875, 'logits/rejected': 0.7480698823928833, 'logits/chosen': 0.7616403698921204, 'epoch': 0.62}

 10%|█         | 1674/16104 [7:45:50<61:26:52, 15.33s/it]

 10%|█         | 1675/16104 [7:46:11<68:40:11, 17.13s/it]

 10%|█         | 1676/16104 [7:46:30<70:47:47, 17.66s/it]


 10%|█         | 1678/16104 [7:47:09<74:07:19, 18.50s/it]

 10%|█         | 1679/16104 [7:47:25<71:08:29, 17.75s/it]
[2024-04-05 23:11:39,509] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.481, 'learning_rate': 1.971255691397888e-06, 'rewards/chosen': -0.9576852917671204, 'rewards/rejected': -1.885087013244629, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9274017810821533, 'policy_logps/rejected': -420.7786560058594, 'policy_logps/chosen': -498.232177734375, 'referece_logps/rejected': -401.92779541015625, 'referece_logps/chosen': -488.65533447265625, 'logits/rejected': -0.2412114441394806, 'logits/chosen': -0.33125558495521545, 'epoch': 0.63}


 10%|█         | 1681/16104 [7:47:59<67:39:27, 16.89s/it]
{'loss': 0.5374, 'learning_rate': 1.9711598611755377e-06, 'rewards/chosen': -1.3965470790863037, 'rewards/rejected': -1.6166385412216187, 'rewards/accuracies': 0.375, 'rewards/margins': 0.22009143233299255, 'policy_logps/rejected': -408.3055419921875, 'policy_logps/chosen': -443.39337158203125, 'referece_logps/rejected': -392.13916015625, 'referece_logps/chosen': -429.4278564453125, 'logits/rejected': -0.39529290795326233, 'logits/chosen': -0.3495635390281677, 'epoch': 0.63}

 10%|█         | 1682/16104 [7:48:11<62:09:56, 15.52s/it]

 10%|█         | 1683/16104 [7:48:33<69:08:14, 17.26s/it]


 10%|█         | 1685/16104 [7:49:09<71:01:18, 17.73s/it]
{'loss': 0.4394, 'learning_rate': 1.970967729324579e-06, 'rewards/chosen': -1.2269933223724365, 'rewards/rejected': -2.5050742626190186, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2780811786651611, 'policy_logps/rejected': -282.9755554199219, 'policy_logps/chosen': -358.9230041503906, 'referece_logps/rejected': -257.9248352050781, 'referece_logps/chosen': -346.6531066894531, 'logits/rejected': -0.717534601688385, 'logits/chosen': -0.6853760480880737, 'epoch': 0.63}


 10%|█         | 1687/16104 [7:49:49<75:25:10, 18.83s/it]
{'loss': 0.4164, 'learning_rate': 1.97087142772706e-06, 'rewards/chosen': -1.0215718746185303, 'rewards/rejected': -2.413383960723877, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3918119668960571, 'policy_logps/rejected': -415.5693359375, 'policy_logps/chosen': -324.538818359375, 'referece_logps/rejected': -391.4355163574219, 'referece_logps/chosen': -314.3230895996094, 'logits/rejected': -1.417207956314087, 'logits/chosen': -1.1547504663467407, 'epoch': 0.63}

 10%|█         | 1688/16104 [7:50:03<69:12:40, 17.28s/it]

 10%|█         | 1689/16104 [7:50:21<70:49:38, 17.69s/it]

 10%|█         | 1690/16104 [7:50:40<72:19:42, 18.06s/it]

 11%|█         | 1691/16104 [7:50:57<70:31:32, 17.62s/it]

 11%|█         | 1692/16104 [7:51:20<77:21:40, 19.32s/it]

 11%|█         | 1693/16104 [7:51:37<73:53:45, 18.46s/it]
[2024-04-05 23:16:10,388] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1694/16104 [7:51:56<74:36:16, 18.64s/it]

 11%|█         | 1695/16104 [7:52:08<67:23:01, 16.84s/it]

 11%|█         | 1696/16104 [7:52:31<73:46:17, 18.43s/it]


 11%|█         | 1698/16104 [7:53:05<70:20:37, 17.58s/it]
{'loss': 0.5705, 'learning_rate': 1.970338961305864e-06, 'rewards/chosen': -1.0290393829345703, 'rewards/rejected': -1.6600151062011719, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6309757828712463, 'policy_logps/rejected': -459.4803466796875, 'policy_logps/chosen': -403.00103759765625, 'referece_logps/rejected': -442.88018798828125, 'referece_logps/chosen': -392.71063232421875, 'logits/rejected': -0.9537619352340698, 'logits/chosen': -0.9752907156944275, 'epoch': 0.63}

 11%|█         | 1699/16104 [7:53:20<67:03:12, 16.76s/it]

 11%|█         | 1700/16104 [7:53:43<74:32:24, 18.63s/it]
[2024-04-05 23:18:19,189] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1701/16104 [7:54:05<77:46:49, 19.44s/it]

 11%|█         | 1702/16104 [7:54:24<77:52:56, 19.47s/it]

 11%|█         | 1703/16104 [7:54:44<78:17:46, 19.57s/it]

 11%|█         | 1704/16104 [7:55:02<76:12:41, 19.05s/it]

 11%|█         | 1705/16104 [7:55:21<76:16:51, 19.07s/it]

 11%|█         | 1706/16104 [7:55:37<72:16:02, 18.07s/it]

 11%|█         | 1707/16104 [7:55:59<77:03:36, 19.27s/it]

 11%|█         | 1708/16104 [7:56:13<70:49:37, 17.71s/it]


 11%|█         | 1710/16104 [7:56:44<67:34:52, 16.90s/it]
{'loss': 0.5331, 'learning_rate': 1.969752672171191e-06, 'rewards/chosen': -1.206517219543457, 'rewards/rejected': -2.0042905807495117, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7977732419967651, 'policy_logps/rejected': -416.4558410644531, 'policy_logps/chosen': -394.558837890625, 'referece_logps/rejected': -396.4129333496094, 'referece_logps/chosen': -382.4936828613281, 'logits/rejected': -0.19152510166168213, 'logits/chosen': -0.07793761044740677, 'epoch': 0.64}

 11%|█         | 1711/16104 [7:57:02<69:33:41, 17.40s/it]


 11%|█         | 1713/16104 [7:57:40<72:37:24, 18.17s/it]
{'loss': 0.4697, 'learning_rate': 1.9696052171187328e-06, 'rewards/chosen': -1.0001283884048462, 'rewards/rejected': -1.5591689348220825, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5590404272079468, 'policy_logps/rejected': -505.663818359375, 'policy_logps/chosen': -522.989013671875, 'referece_logps/rejected': -490.0721740722656, 'referece_logps/chosen': -512.9877319335938, 'logits/rejected': 0.2447699010372162, 'logits/chosen': 0.3492441177368164, 'epoch': 0.64}


 11%|█         | 1715/16104 [7:58:16<71:43:24, 17.94s/it]
{'loss': 0.4788, 'learning_rate': 1.969506717635807e-06, 'rewards/chosen': -0.9274740219116211, 'rewards/rejected': -2.0833287239074707, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1558547019958496, 'policy_logps/rejected': -386.1528625488281, 'policy_logps/chosen': -455.8599548339844, 'referece_logps/rejected': -365.319580078125, 'referece_logps/chosen': -446.58526611328125, 'logits/rejected': -0.8175156116485596, 'logits/chosen': -0.8730113506317139, 'epoch': 0.64}

 11%|█         | 1716/16104 [7:58:35<73:38:27, 18.43s/it]


 11%|█         | 1718/16104 [7:59:20<82:20:22, 20.60s/it]
{'loss': 0.384, 'learning_rate': 1.969358674279333e-06, 'rewards/chosen': -0.7213307619094849, 'rewards/rejected': -1.6987262964248657, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9773957133293152, 'policy_logps/rejected': -287.55242919921875, 'policy_logps/chosen': -281.101806640625, 'referece_logps/rejected': -270.5651550292969, 'referece_logps/chosen': -273.88848876953125, 'logits/rejected': -0.9571138620376587, 'logits/chosen': -0.7908035516738892, 'epoch': 0.64}

 11%|█         | 1719/16104 [7:59:38<79:37:34, 19.93s/it]

 11%|█         | 1720/16104 [7:59:59<81:00:32, 20.27s/it]

 11%|█         | 1721/16104 [8:00:20<80:54:32, 20.25s/it]

 11%|█         | 1722/16104 [8:00:37<76:56:52, 19.26s/it]

 11%|█         | 1723/16104 [8:00:53<73:46:43, 18.47s/it]

 11%|█         | 1724/16104 [8:01:10<71:29:37, 17.90s/it]


 11%|█         | 1726/16104 [8:01:34<60:12:26, 15.07s/it]
{'loss': 0.5694, 'learning_rate': 1.9689621668015645e-06, 'rewards/chosen': -0.9462828636169434, 'rewards/rejected': -1.3992805480957031, 'rewards/accuracies': 0.625, 'rewards/margins': 0.45299768447875977, 'policy_logps/rejected': -575.8380737304688, 'policy_logps/chosen': -580.3829345703125, 'referece_logps/rejected': -561.8452758789062, 'referece_logps/chosen': -570.9201049804688, 'logits/rejected': -0.8439682722091675, 'logits/chosen': -0.5823515057563782, 'epoch': 0.64}

 11%|█         | 1727/16104 [8:01:45<55:09:42, 13.81s/it]

 11%|█         | 1728/16104 [8:01:56<51:29:21, 12.89s/it]

 11%|█         | 1729/16104 [8:02:17<61:28:22, 15.39s/it]

 11%|█         | 1730/16104 [8:02:37<67:26:39, 16.89s/it]

 11%|█         | 1731/16104 [8:03:00<74:04:06, 18.55s/it]


 11%|█         | 1733/16104 [8:03:36<74:46:20, 18.73s/it]

 11%|█         | 1734/16104 [8:03:54<73:45:43, 18.48s/it]
{'loss': 0.4915, 'learning_rate': 1.9685631507644087e-06, 'rewards/chosen': -1.6524302959442139, 'rewards/rejected': -2.448154926300049, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7957245111465454, 'policy_logps/rejected': -414.35968017578125, 'policy_logps/chosen': -456.4326171875, 'referece_logps/rejected': -389.87811279296875, 'referece_logps/chosen': -439.9082946777344, 'logits/rejected': -0.1473163366317749, 'logits/chosen': -0.14180749654769897, 'epoch': 0.65}

 11%|█         | 1735/16104 [8:04:14<75:16:23, 18.86s/it]

 11%|█         | 1736/16104 [8:04:33<75:45:57, 18.98s/it]

 11%|█         | 1737/16104 [8:04:52<75:32:20, 18.93s/it]

 11%|█         | 1738/16104 [8:05:05<68:41:15, 17.21s/it]


 11%|█         | 1740/16104 [8:05:46<74:52:23, 18.77s/it]
{'loss': 0.5318, 'learning_rate': 1.9682622431156245e-06, 'rewards/chosen': -1.0020701885223389, 'rewards/rejected': -2.1373491287231445, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1352790594100952, 'policy_logps/rejected': -385.70782470703125, 'policy_logps/chosen': -507.3337097167969, 'referece_logps/rejected': -364.3343505859375, 'referece_logps/chosen': -497.31298828125, 'logits/rejected': -0.08808527141809464, 'logits/chosen': 0.21419036388397217, 'epoch': 0.65}

 11%|█         | 1741/16104 [8:06:00<68:23:38, 17.14s/it]

 11%|█         | 1742/16104 [8:06:17<68:40:51, 17.22s/it]


 11%|█         | 1744/16104 [8:06:58<75:21:14, 18.89s/it]
{'loss': 0.4726, 'learning_rate': 1.968060854630682e-06, 'rewards/chosen': -1.2403310537338257, 'rewards/rejected': -3.049941062927246, 'rewards/accuracies': 1.0, 'rewards/margins': 1.80961012840271, 'policy_logps/rejected': -371.9289245605469, 'policy_logps/chosen': -441.69879150390625, 'referece_logps/rejected': -341.4295349121094, 'referece_logps/chosen': -429.29547119140625, 'logits/rejected': 0.26897603273391724, 'logits/chosen': 0.2661433219909668, 'epoch': 0.65}

 11%|█         | 1745/16104 [8:07:10<66:58:57, 16.79s/it]

 11%|█         | 1746/16104 [8:07:21<59:44:43, 14.98s/it]


 11%|█         | 1748/16104 [8:07:42<51:02:09, 12.80s/it]
{'loss': 0.7425, 'learning_rate': 1.967858839589146e-06, 'rewards/chosen': -1.279736042022705, 'rewards/rejected': -2.1944732666015625, 'rewards/accuracies': 0.375, 'rewards/margins': 0.9147372841835022, 'policy_logps/rejected': -312.31939697265625, 'policy_logps/chosen': -394.375732421875, 'referece_logps/rejected': -290.37469482421875, 'referece_logps/chosen': -381.5783386230469, 'logits/rejected': -0.16568294167518616, 'logits/chosen': -0.3943937420845032, 'epoch': 0.65}

 11%|█         | 1749/16104 [8:07:53<49:06:27, 12.32s/it]

 11%|█         | 1750/16104 [8:08:08<51:42:52, 12.97s/it]


 11%|█         | 1752/16104 [8:08:45<62:38:26, 15.71s/it]
{'loss': 0.5158, 'learning_rate': 1.9676561981217664e-06, 'rewards/chosen': -1.1987528800964355, 'rewards/rejected': -1.9396783113479614, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7409255504608154, 'policy_logps/rejected': -464.83502197265625, 'policy_logps/chosen': -436.1178894042969, 'referece_logps/rejected': -445.438232421875, 'referece_logps/chosen': -424.1303405761719, 'logits/rejected': -0.25747063755989075, 'logits/chosen': -0.12613967061042786, 'epoch': 0.65}

 11%|█         | 1753/16104 [8:08:55<56:34:28, 14.19s/it]

 11%|█         | 1754/16104 [8:09:06<52:32:49, 13.18s/it]

 11%|█         | 1755/16104 [8:09:17<49:29:41, 12.42s/it]

 11%|█         | 1756/16104 [8:09:27<47:25:17, 11.90s/it]


 11%|█         | 1758/16104 [8:09:49<44:51:19, 11.26s/it]
{'loss': 0.4631, 'learning_rate': 1.967351061659254e-06, 'rewards/chosen': -0.637935996055603, 'rewards/rejected': -1.7550134658813477, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1170772314071655, 'policy_logps/rejected': -490.0071105957031, 'policy_logps/chosen': -501.0611877441406, 'referece_logps/rejected': -472.45697021484375, 'referece_logps/chosen': -494.68182373046875, 'logits/rejected': -0.08037456125020981, 'logits/chosen': 0.11906125396490097, 'epoch': 0.65}

 11%|█         | 1759/16104 [8:09:59<44:14:17, 11.10s/it]

 11%|█         | 1760/16104 [8:10:15<49:35:47, 12.45s/it]

 11%|█         | 1761/16104 [8:10:29<51:51:03, 13.01s/it]

 11%|█         | 1762/16104 [8:10:47<57:16:32, 14.38s/it]

 11%|█         | 1763/16104 [8:11:01<57:22:32, 14.40s/it]
[2024-04-05 23:35:37,887] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1764/16104 [8:11:23<66:23:58, 16.67s/it]
[2024-04-05 23:35:55,716] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1765/16104 [8:11:41<67:46:48, 17.02s/it]

 11%|█         | 1766/16104 [8:11:53<61:47:34, 15.52s/it]

 11%|█         | 1767/16104 [8:12:14<68:32:43, 17.21s/it]

 11%|█         | 1768/16104 [8:12:26<61:58:51, 15.56s/it]

 11%|█         | 1769/16104 [8:12:44<65:05:53, 16.35s/it]

 11%|█         | 1770/16104 [8:12:57<61:25:11, 15.43s/it]

 11%|█         | 1771/16104 [8:13:10<57:45:23, 14.51s/it]

 11%|█         | 1772/16104 [8:13:28<62:16:53, 15.64s/it]

 11%|█         | 1773/16104 [8:13:45<63:20:53, 15.91s/it]

 11%|█         | 1774/16104 [8:14:01<64:18:29, 16.16s/it]
[2024-04-05 23:38:33,717] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1775/16104 [8:14:19<66:10:48, 16.63s/it]

 11%|█         | 1776/16104 [8:14:37<68:09:46, 17.13s/it]

 11%|█         | 1777/16104 [8:14:57<71:14:03, 17.90s/it]

 11%|█         | 1778/16104 [8:15:15<70:52:26, 17.81s/it]

 11%|█         | 1779/16104 [8:15:33<72:00:25, 18.10s/it]
[2024-04-05 23:40:09,571] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1780/16104 [8:15:55<76:03:28, 19.12s/it]

 11%|█         | 1781/16104 [8:16:14<75:30:12, 18.98s/it]

 11%|█         | 1782/16104 [8:16:26<67:49:50, 17.05s/it]

 11%|█         | 1783/16104 [8:16:47<72:38:37, 18.26s/it]

 11%|█         | 1784/16104 [8:17:10<78:12:07, 19.66s/it]

 11%|█         | 1785/16104 [8:17:30<78:09:38, 19.65s/it]

 11%|█         | 1786/16104 [8:17:45<72:35:51, 18.25s/it]
[2024-04-05 23:42:19,396] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1787/16104 [8:18:05<74:39:26, 18.77s/it]

 11%|█         | 1788/16104 [8:18:16<66:10:31, 16.64s/it]

 11%|█         | 1789/16104 [8:18:37<71:25:55, 17.96s/it]

 11%|█         | 1790/16104 [8:18:54<69:44:49, 17.54s/it]

 11%|█         | 1791/16104 [8:19:06<62:58:10, 15.84s/it]

 11%|█         | 1792/16104 [8:19:18<58:54:33, 14.82s/it]

 11%|█         | 1793/16104 [8:19:30<54:45:53, 13.78s/it]

 11%|█         | 1794/16104 [8:19:50<63:00:51, 15.85s/it]

 11%|█         | 1795/16104 [8:20:02<58:06:56, 14.62s/it]

 11%|█         | 1796/16104 [8:20:20<61:40:58, 15.52s/it]

 11%|█         | 1797/16104 [8:20:34<60:34:28, 15.24s/it]

 11%|█         | 1798/16104 [8:20:54<65:45:17, 16.55s/it]

 11%|█         | 1799/16104 [8:21:16<72:15:41, 18.19s/it]

 11%|█         | 1800/16104 [8:21:35<73:38:18, 18.53s/it]


 11%|█         | 1802/16104 [8:21:58<59:27:28, 14.97s/it]

 11%|█         | 1803/16104 [8:22:13<58:47:41, 14.80s/it]

 11%|█         | 1804/16104 [8:22:29<60:41:05, 15.28s/it]

 11%|█         | 1805/16104 [8:22:45<61:23:15, 15.46s/it]

 11%|█         | 1806/16104 [8:23:02<63:29:08, 15.98s/it]

 11%|█         | 1807/16104 [8:23:17<62:31:54, 15.75s/it]

 11%|█         | 1808/16104 [8:23:30<59:00:38, 14.86s/it]

 11%|█         | 1809/16104 [8:23:50<65:01:30, 16.38s/it]

 11%|█         | 1810/16104 [8:24:08<67:36:05, 17.03s/it]

 11%|█         | 1811/16104 [8:24:27<69:14:43, 17.44s/it]

 11%|█▏        | 1812/16104 [8:24:39<63:27:43, 15.99s/it]
{'loss': 0.5527, 'learning_rate': 1.9645414951597045e-06, 'rewards/chosen': -1.3091189861297607, 'rewards/rejected': -2.3363752365112305, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0272563695907593, 'policy_logps/rejected': -275.8415222167969, 'policy_logps/chosen': -398.8044128417969, 'referece_logps/rejected': -252.4777374267578, 'referece_logps/chosen': -385.71319580078125, 'logits/rejected': -1.0528124570846558, 'logits/chosen': -1.0642716884613037, 'epoch': 0.68}


 11%|█▏        | 1814/16104 [8:25:11<61:50:17, 15.58s/it]

 11%|█▏        | 1815/16104 [8:25:32<68:38:44, 17.29s/it]
[2024-04-05 23:49:46,694] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█▏        | 1816/16104 [8:25:52<72:01:51, 18.15s/it]
[2024-04-05 23:50:06,836] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█▏        | 1817/16104 [8:26:13<75:38:43, 19.06s/it]
{'loss': 0.5221, 'learning_rate': 1.964275589921878e-06, 'rewards/chosen': -1.059433102607727, 'rewards/rejected': -1.3605756759643555, 'rewards/accuracies': 0.625, 'rewards/margins': 0.30114275217056274, 'policy_logps/rejected': -335.11700439453125, 'policy_logps/chosen': -474.51116943359375, 'referece_logps/rejected': -321.51129150390625, 'referece_logps/chosen': -463.91680908203125, 'logits/rejected': -0.05719120427966118, 'logits/chosen': -0.09253284335136414, 'epoch': 0.68}


 11%|█▏        | 1819/16104 [8:26:42<66:20:08, 16.72s/it]
{'loss': 0.6005, 'learning_rate': 1.964168954764999e-06, 'rewards/chosen': -1.0425668954849243, 'rewards/rejected': -1.6829835176467896, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6404166221618652, 'policy_logps/rejected': -198.4743194580078, 'policy_logps/chosen': -405.5978698730469, 'referece_logps/rejected': -181.6444854736328, 'referece_logps/chosen': -395.1722106933594, 'logits/rejected': -0.8762593269348145, 'logits/chosen': -0.9458465576171875, 'epoch': 0.68}


 11%|█▏        | 1821/16104 [8:27:18<69:33:04, 17.53s/it]

 11%|█▏        | 1822/16104 [8:27:32<65:24:45, 16.49s/it]
{'loss': 0.4152, 'learning_rate': 1.9640087095174214e-06, 'rewards/chosen': -0.7981155514717102, 'rewards/rejected': -1.5939260721206665, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7958105802536011, 'policy_logps/rejected': -281.2582702636719, 'policy_logps/chosen': -353.28631591796875, 'referece_logps/rejected': -265.3190002441406, 'referece_logps/chosen': -345.3051452636719, 'logits/rejected': -0.0957651361823082, 'logits/chosen': -0.12785565853118896, 'epoch': 0.68}


 11%|█▏        | 1824/16104 [8:28:14<74:31:37, 18.79s/it]

 11%|█▏        | 1825/16104 [8:28:31<72:50:27, 18.36s/it]

 11%|█▏        | 1826/16104 [8:28:46<68:27:47, 17.26s/it]
{'loss': 0.4628, 'learning_rate': 1.963794503255219e-06, 'rewards/chosen': -0.731762170791626, 'rewards/rejected': -1.3335713148117065, 'rewards/accuracies': 0.875, 'rewards/margins': 0.601809024810791, 'policy_logps/rejected': -378.9476318359375, 'policy_logps/chosen': -382.60009765625, 'referece_logps/rejected': -365.6119079589844, 'referece_logps/chosen': -375.2825012207031, 'logits/rejected': -0.012011080980300903, 'logits/chosen': -0.20235052704811096, 'epoch': 0.68}

 11%|█▏        | 1827/16104 [8:29:04<69:03:36, 17.41s/it]
[2024-04-05 23:53:40,673] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 11%|█▏        | 1829/16104 [8:29:41<70:37:51, 17.81s/it]

 11%|█▏        | 1830/16104 [8:29:58<69:23:26, 17.50s/it]

 11%|█▏        | 1831/16104 [8:30:20<73:59:41, 18.66s/it]

 11%|█▏        | 1832/16104 [8:30:33<67:11:47, 16.95s/it]

 11%|█▏        | 1833/16104 [8:30:47<64:27:11, 16.26s/it]

 11%|█▏        | 1834/16104 [8:31:11<73:13:40, 18.47s/it]

 11%|█▏        | 1835/16104 [8:31:34<78:14:54, 19.74s/it]
[2024-04-05 23:55:48,235] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█▏        | 1836/16104 [8:31:54<79:31:58, 20.07s/it]

 11%|█▏        | 1837/16104 [8:32:12<76:11:48, 19.23s/it]

 11%|█▏        | 1838/16104 [8:32:32<77:55:05, 19.66s/it]

 11%|█▏        | 1839/16104 [8:32:53<78:29:26, 19.81s/it]

 11%|█▏        | 1840/16104 [8:33:06<70:31:18, 17.80s/it]

 11%|█▏        | 1841/16104 [8:33:26<73:09:40, 18.47s/it]

 11%|█▏        | 1842/16104 [8:33:45<74:46:25, 18.87s/it]
{'loss': 0.4798, 'learning_rate': 1.9629314416459777e-06, 'rewards/chosen': -1.581131100654602, 'rewards/rejected': -2.562971353530884, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9818402528762817, 'policy_logps/rejected': -391.6672058105469, 'policy_logps/chosen': -448.00244140625, 'referece_logps/rejected': -366.0374755859375, 'referece_logps/chosen': -432.19110107421875, 'logits/rejected': -0.039930254220962524, 'logits/chosen': -0.14583620429039001, 'epoch': 0.69}


 11%|█▏        | 1844/16104 [8:34:15<66:06:03, 16.69s/it]

 11%|█▏        | 1845/16104 [8:34:31<65:13:26, 16.47s/it]

 11%|█▏        | 1846/16104 [8:34:42<58:27:07, 14.76s/it]

 11%|█▏        | 1847/16104 [8:34:53<53:32:30, 13.52s/it]

 11%|█▏        | 1848/16104 [8:35:04<50:31:04, 12.76s/it]

 11%|█▏        | 1849/16104 [8:35:17<50:44:02, 12.81s/it]

 11%|█▏        | 1850/16104 [8:35:27<48:21:52, 12.21s/it]

 11%|█▏        | 1851/16104 [8:35:41<50:07:00, 12.66s/it]
{'loss': 0.5125, 'learning_rate': 1.96244158678432e-06, 'rewards/chosen': -0.5481476187705994, 'rewards/rejected': -2.309798002243042, 'rewards/accuracies': 1.0, 'rewards/margins': 1.761650562286377, 'policy_logps/rejected': -395.8293762207031, 'policy_logps/chosen': -567.6842651367188, 'referece_logps/rejected': -372.73138427734375, 'referece_logps/chosen': -562.2027587890625, 'logits/rejected': -0.5572086572647095, 'logits/chosen': -0.6290335655212402, 'epoch': 0.69}


 12%|█▏        | 1853/16104 [8:36:12<56:39:26, 14.31s/it]

 12%|█▏        | 1854/16104 [8:36:23<52:23:58, 13.24s/it]

 12%|█▏        | 1855/16104 [8:36:34<49:26:18, 12.49s/it]

 12%|█▏        | 1856/16104 [8:36:46<48:55:24, 12.36s/it]

 12%|█▏        | 1857/16104 [8:37:05<57:02:01, 14.41s/it]

 12%|█▏        | 1858/16104 [8:37:20<57:27:16, 14.52s/it]

 12%|█▏        | 1859/16104 [8:37:33<56:01:35, 14.16s/it]

 12%|█▏        | 1860/16104 [8:37:44<51:55:00, 13.12s/it]

 12%|█▏        | 1861/16104 [8:37:59<54:39:26, 13.81s/it]
{'loss': 0.6769, 'learning_rate': 1.9618936050902008e-06, 'rewards/chosen': -0.48923397064208984, 'rewards/rejected': -1.303110122680664, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8138760924339294, 'policy_logps/rejected': -462.0234375, 'policy_logps/chosen': -388.7303771972656, 'referece_logps/rejected': -448.9923095703125, 'referece_logps/chosen': -383.8380126953125, 'logits/rejected': -0.5711545348167419, 'logits/chosen': -0.47489309310913086, 'epoch': 0.69}


 12%|█▏        | 1863/16104 [8:38:40<67:46:03, 17.13s/it]

 12%|█▏        | 1864/16104 [8:38:55<65:38:25, 16.59s/it]

 12%|█▏        | 1865/16104 [8:39:08<60:21:47, 15.26s/it]

 12%|█▏        | 1866/16104 [8:39:21<58:00:32, 14.67s/it]

 12%|█▏        | 1867/16104 [8:39:42<65:53:50, 16.66s/it]

 12%|█▏        | 1868/16104 [8:40:04<71:30:45, 18.08s/it]

 12%|█▏        | 1869/16104 [8:40:16<65:19:24, 16.52s/it]

 12%|█▏        | 1870/16104 [8:40:37<70:23:45, 17.80s/it]

 12%|█▏        | 1871/16104 [8:40:59<74:40:43, 18.89s/it]

 12%|█▏        | 1872/16104 [8:41:15<71:57:19, 18.20s/it]

 12%|█▏        | 1873/16104 [8:41:34<72:09:08, 18.25s/it]
{'loss': 0.4369, 'learning_rate': 1.9612308910938562e-06, 'rewards/chosen': -0.7434672713279724, 'rewards/rejected': -1.0924642086029053, 'rewards/accuracies': 0.75, 'rewards/margins': 0.34899696707725525, 'policy_logps/rejected': -255.5967559814453, 'policy_logps/chosen': -303.419921875, 'referece_logps/rejected': -244.67210388183594, 'referece_logps/chosen': -295.9852294921875, 'logits/rejected': 0.16382160782814026, 'logits/chosen': 0.23548361659049988, 'epoch': 0.7}


 12%|█▏        | 1875/16104 [8:42:14<75:28:50, 19.10s/it]

 12%|█▏        | 1876/16104 [8:42:27<68:50:44, 17.42s/it]

 12%|█▏        | 1877/16104 [8:42:48<72:28:14, 18.34s/it]
{'loss': 0.5773, 'learning_rate': 1.961008741965279e-06, 'rewards/chosen': -0.7395526170730591, 'rewards/rejected': -1.5610756874084473, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8215230703353882, 'policy_logps/rejected': -373.4263610839844, 'policy_logps/chosen': -439.1370849609375, 'referece_logps/rejected': -357.81561279296875, 'referece_logps/chosen': -431.7415771484375, 'logits/rejected': 0.08441974222660065, 'logits/chosen': 0.10932494699954987, 'epoch': 0.7}


 12%|█▏        | 1879/16104 [8:43:16<63:12:28, 16.00s/it]
{'loss': 0.6158, 'learning_rate': 1.9608974341448883e-06, 'rewards/chosen': -0.8654654026031494, 'rewards/rejected': -1.7741683721542358, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9087029695510864, 'policy_logps/rejected': -279.3252868652344, 'policy_logps/chosen': -351.28485107421875, 'referece_logps/rejected': -261.5836181640625, 'referece_logps/chosen': -342.630126953125, 'logits/rejected': -0.5814211368560791, 'logits/chosen': -0.6093208193778992, 'epoch': 0.7}


 12%|█▏        | 1881/16104 [8:43:46<60:28:13, 15.31s/it]

 12%|█▏        | 1882/16104 [8:43:58<56:06:20, 14.20s/it]

 12%|█▏        | 1883/16104 [8:44:16<60:59:11, 15.44s/it]
{'loss': 0.6261, 'learning_rate': 1.9606743520819575e-06, 'rewards/chosen': -1.4100195169448853, 'rewards/rejected': -1.342455267906189, 'rewards/accuracies': 0.5, 'rewards/margins': -0.06756418198347092, 'policy_logps/rejected': -320.2621154785156, 'policy_logps/chosen': -485.55694580078125, 'referece_logps/rejected': -306.8375244140625, 'referece_logps/chosen': -471.456787109375, 'logits/rejected': -0.5786668062210083, 'logits/chosen': -0.37396448850631714, 'epoch': 0.7}


 12%|█▏        | 1885/16104 [8:44:38<51:40:43, 13.08s/it]

 12%|█▏        | 1886/16104 [8:44:49<48:52:30, 12.38s/it]
{'loss': 0.6729, 'learning_rate': 1.960506632486454e-06, 'rewards/chosen': -1.2764860391616821, 'rewards/rejected': -0.9128684997558594, 'rewards/accuracies': 0.5, 'rewards/margins': -0.363617479801178, 'policy_logps/rejected': -332.2814025878906, 'policy_logps/chosen': -359.6390380859375, 'referece_logps/rejected': -323.1527404785156, 'referece_logps/chosen': -346.8741760253906, 'logits/rejected': -1.007672905921936, 'logits/chosen': -1.2698955535888672, 'epoch': 0.7}


 12%|█▏        | 1888/16104 [8:45:10<45:29:43, 11.52s/it]
{'loss': 0.7585, 'learning_rate': 1.960394625147979e-06, 'rewards/chosen': -0.7260568737983704, 'rewards/rejected': -0.8256995677947998, 'rewards/accuracies': 0.5, 'rewards/margins': 0.09964264929294586, 'policy_logps/rejected': -351.66326904296875, 'policy_logps/chosen': -485.3677978515625, 'referece_logps/rejected': -343.40625, 'referece_logps/chosen': -478.10723876953125, 'logits/rejected': 0.6170933246612549, 'logits/chosen': 0.6223149299621582, 'epoch': 0.7}


 12%|█▏        | 1890/16104 [8:45:43<55:07:36, 13.96s/it]

 12%|█▏        | 1891/16104 [8:46:00<58:55:47, 14.93s/it]
{'loss': 0.4369, 'learning_rate': 1.9602263227733676e-06, 'rewards/chosen': -1.0059633255004883, 'rewards/rejected': -1.743592381477356, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7376289367675781, 'policy_logps/rejected': -260.0872802734375, 'policy_logps/chosen': -175.36190795898438, 'referece_logps/rejected': -242.6513671875, 'referece_logps/chosen': -165.30227661132812, 'logits/rejected': -1.1629624366760254, 'logits/chosen': -1.132658839225769, 'epoch': 0.7}


 12%|█▏        | 1893/16104 [8:46:35<63:36:12, 16.11s/it]

 12%|█▏        | 1894/16104 [8:46:51<63:56:17, 16.20s/it]
{'loss': 0.563, 'learning_rate': 1.960057670812951e-06, 'rewards/chosen': -0.9955488443374634, 'rewards/rejected': -1.2712385654449463, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2756897807121277, 'policy_logps/rejected': -277.3660583496094, 'policy_logps/chosen': -385.9547119140625, 'referece_logps/rejected': -264.6536865234375, 'referece_logps/chosen': -375.9992370605469, 'logits/rejected': -0.6731297373771667, 'logits/chosen': -0.573554515838623, 'epoch': 0.71}


 12%|█▏        | 1896/16104 [8:47:28<68:03:47, 17.25s/it]
{'loss': 0.4367, 'learning_rate': 1.9599450419886533e-06, 'rewards/chosen': -0.9710752367973328, 'rewards/rejected': -2.0088796615600586, 'rewards/accuracies': 0.875, 'rewards/margins': 1.037804365158081, 'policy_logps/rejected': -274.2520751953125, 'policy_logps/chosen': -393.9161376953125, 'referece_logps/rejected': -254.16329956054688, 'referece_logps/chosen': -384.2054138183594, 'logits/rejected': -0.6502221822738647, 'logits/chosen': -0.5612343549728394, 'epoch': 0.71}


 12%|█▏        | 1898/16104 [8:48:10<75:39:22, 19.17s/it]
{'loss': 0.4414, 'learning_rate': 1.959832257838397e-06, 'rewards/chosen': -0.8554584383964539, 'rewards/rejected': -1.849264144897461, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9938057661056519, 'policy_logps/rejected': -325.2667236328125, 'policy_logps/chosen': -368.17510986328125, 'referece_logps/rejected': -306.7740478515625, 'referece_logps/chosen': -359.6204833984375, 'logits/rejected': -0.7107127904891968, 'logits/chosen': -0.49171799421310425, 'epoch': 0.71}


 12%|█▏        | 1900/16104 [8:48:34<61:54:02, 15.69s/it]
{'loss': 0.4027, 'learning_rate': 1.9597193183804318e-06, 'rewards/chosen': -1.2174859046936035, 'rewards/rejected': -2.4249107837677, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2074246406555176, 'policy_logps/rejected': -419.8192138671875, 'policy_logps/chosen': -518.1053466796875, 'referece_logps/rejected': -395.57012939453125, 'referece_logps/chosen': -505.93048095703125, 'logits/rejected': -0.019901424646377563, 'logits/chosen': -0.08021560311317444, 'epoch': 0.71}


 12%|█▏        | 1902/16104 [8:49:15<71:05:10, 18.02s/it]
{'loss': 0.4868, 'learning_rate': 1.959606223633032e-06, 'rewards/chosen': -0.7319465279579163, 'rewards/rejected': -1.4072264432907104, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6752797961235046, 'policy_logps/rejected': -344.4740295410156, 'policy_logps/chosen': -256.4313659667969, 'referece_logps/rejected': -330.4017639160156, 'referece_logps/chosen': -249.11190795898438, 'logits/rejected': -0.315460741519928, 'logits/chosen': -0.3459055423736572, 'epoch': 0.71}

 12%|█▏        | 1903/16104 [8:49:33<71:41:24, 18.17s/it]


 12%|█▏        | 1905/16104 [8:50:02<62:58:07, 15.97s/it]
{'loss': 0.4917, 'learning_rate': 1.9594362903842798e-06, 'rewards/chosen': -0.9302481412887573, 'rewards/rejected': -1.6209608316421509, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6907126307487488, 'policy_logps/rejected': -300.50604248046875, 'policy_logps/chosen': -374.33673095703125, 'referece_logps/rejected': -284.2964172363281, 'referece_logps/chosen': -365.03424072265625, 'logits/rejected': -0.10448242723941803, 'logits/chosen': -0.05881522595882416, 'epoch': 0.71}


 12%|█▏        | 1907/16104 [8:50:25<53:21:26, 13.53s/it]

 12%|█▏        | 1908/16104 [8:50:36<51:02:39, 12.94s/it]
{'loss': 0.5212, 'learning_rate': 1.9592660078373463e-06, 'rewards/chosen': -0.9052540063858032, 'rewards/rejected': -1.6176583766937256, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7124043107032776, 'policy_logps/rejected': -277.5810241699219, 'policy_logps/chosen': -329.9889221191406, 'referece_logps/rejected': -261.4044494628906, 'referece_logps/chosen': -320.9363708496094, 'logits/rejected': -0.6979882717132568, 'logits/chosen': -0.6013532280921936, 'epoch': 0.71}

 12%|█▏        | 1909/16104 [8:50:52<53:59:03, 13.69s/it]


 12%|█▏        | 1911/16104 [8:51:28<62:21:38, 15.82s/it]

 12%|█▏        | 1912/16104 [8:51:40<57:50:03, 14.67s/it]

 12%|█▏        | 1913/16104 [8:52:01<64:52:51, 16.46s/it]

 12%|█▏        | 1914/16104 [8:52:23<71:41:57, 18.19s/it]
[2024-04-06 00:16:37,619] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 12%|█▏        | 1915/16104 [8:52:43<73:34:21, 18.67s/it]

 12%|█▏        | 1916/16104 [8:53:03<75:09:31, 19.07s/it]
[2024-04-06 00:17:17,411] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 12%|█▏        | 1917/16104 [8:53:25<78:53:20, 20.02s/it]
{'loss': 0.5387, 'learning_rate': 1.958753065028037e-06, 'rewards/chosen': -0.9503146409988403, 'rewards/rejected': -1.5715618133544922, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6212472319602966, 'policy_logps/rejected': -222.68299865722656, 'policy_logps/chosen': -234.00936889648438, 'referece_logps/rejected': -206.96734619140625, 'referece_logps/chosen': -224.5062255859375, 'logits/rejected': 0.1917671263217926, 'logits/chosen': 0.1977546215057373, 'epoch': 0.71}


 12%|█▏        | 1919/16104 [8:53:57<71:28:45, 18.14s/it]
[2024-04-06 00:18:11,293] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 12%|█▏        | 1920/16104 [8:54:15<71:24:58, 18.13s/it]

 12%|█▏        | 1921/16104 [8:54:31<69:26:49, 17.63s/it]

 12%|█▏        | 1922/16104 [8:54:55<76:27:47, 19.41s/it]
{'loss': 0.4579, 'learning_rate': 1.958466739278465e-06, 'rewards/chosen': -0.352647602558136, 'rewards/rejected': -2.014026165008545, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6613785028457642, 'policy_logps/rejected': -421.6681213378906, 'policy_logps/chosen': -365.5995788574219, 'referece_logps/rejected': -401.52783203125, 'referece_logps/chosen': -362.0731201171875, 'logits/rejected': -1.1298449039459229, 'logits/chosen': -1.0609533786773682, 'epoch': 0.72}


 12%|█▏        | 1924/16104 [8:55:29<74:04:11, 18.80s/it]

 12%|█▏        | 1925/16104 [8:55:50<77:11:05, 19.60s/it]
{'loss': 0.491, 'learning_rate': 1.958294478549907e-06, 'rewards/chosen': -1.6091500520706177, 'rewards/rejected': -1.7397148609161377, 'rewards/accuracies': 0.75, 'rewards/margins': 0.13056480884552002, 'policy_logps/rejected': -245.45602416992188, 'policy_logps/chosen': -305.5257568359375, 'referece_logps/rejected': -228.05885314941406, 'referece_logps/chosen': -289.43426513671875, 'logits/rejected': 0.2079022228717804, 'logits/chosen': 0.10709932446479797, 'epoch': 0.72}

 12%|█▏        | 1926/16104 [8:56:12<79:30:35, 20.19s/it]


 12%|█▏        | 1928/16104 [8:56:51<78:00:39, 19.81s/it]

 12%|█▏        | 1929/16104 [8:57:03<68:19:57, 17.35s/it]
{'loss': 0.5822, 'learning_rate': 1.9580642548832653e-06, 'rewards/chosen': -1.136074185371399, 'rewards/rejected': -1.662054419517517, 'rewards/accuracies': 0.375, 'rewards/margins': 0.5259801149368286, 'policy_logps/rejected': -488.41705322265625, 'policy_logps/chosen': -411.93841552734375, 'referece_logps/rejected': -471.7965087890625, 'referece_logps/chosen': -400.5777282714844, 'logits/rejected': -0.7624056935310364, 'logits/chosen': -0.6405591368675232, 'epoch': 0.72}


 12%|█▏        | 1931/16104 [8:57:29<58:47:00, 14.93s/it]
{'loss': 0.5006, 'learning_rate': 1.9579489105081746e-06, 'rewards/chosen': -1.0457592010498047, 'rewards/rejected': -1.3075486421585083, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2617895007133484, 'policy_logps/rejected': -249.84490966796875, 'policy_logps/chosen': -297.9684753417969, 'referece_logps/rejected': -236.76942443847656, 'referece_logps/chosen': -287.5108947753906, 'logits/rejected': -1.0298798084259033, 'logits/chosen': -0.8760782480239868, 'epoch': 0.72}


 12%|█▏        | 1933/16104 [8:58:03<64:48:36, 16.46s/it]
{'loss': 0.3974, 'learning_rate': 1.9578334111301143e-06, 'rewards/chosen': -1.0915277004241943, 'rewards/rejected': -2.578812837600708, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4872851371765137, 'policy_logps/rejected': -346.74090576171875, 'policy_logps/chosen': -389.0339660644531, 'referece_logps/rejected': -320.9527282714844, 'referece_logps/chosen': -378.11865234375, 'logits/rejected': -0.7929876446723938, 'logits/chosen': -0.6888152360916138, 'epoch': 0.72}


 12%|█▏        | 1935/16104 [8:58:31<58:59:14, 14.99s/it]

 12%|█▏        | 1936/16104 [8:58:53<67:14:53, 17.09s/it]

 12%|█▏        | 1937/16104 [8:59:13<71:24:00, 18.14s/it]

 12%|█▏        | 1938/16104 [8:59:35<75:53:50, 19.29s/it]

 12%|█▏        | 1939/16104 [8:59:53<74:32:24, 18.94s/it]

 12%|█▏        | 1940/16104 [9:00:05<66:32:47, 16.91s/it]
{'loss': 0.4811, 'learning_rate': 1.9574279429285574e-06, 'rewards/chosen': -1.4706156253814697, 'rewards/rejected': -1.940725564956665, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4701099693775177, 'policy_logps/rejected': -463.01678466796875, 'policy_logps/chosen': -466.0668640136719, 'referece_logps/rejected': -443.60955810546875, 'referece_logps/chosen': -451.3607177734375, 'logits/rejected': -0.38919365406036377, 'logits/chosen': -0.4055306911468506, 'epoch': 0.72}


 12%|█▏        | 1942/16104 [9:00:46<72:48:30, 18.51s/it]
{'loss': 0.5482, 'learning_rate': 1.957311746268766e-06, 'rewards/chosen': -1.1149568557739258, 'rewards/rejected': -1.633776307106018, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5188194513320923, 'policy_logps/rejected': -372.43414306640625, 'policy_logps/chosen': -504.49395751953125, 'referece_logps/rejected': -356.09637451171875, 'referece_logps/chosen': -493.3443908691406, 'logits/rejected': -0.9313588738441467, 'logits/chosen': -1.0904725790023804, 'epoch': 0.72}


 12%|█▏        | 1944/16104 [9:01:23<71:39:16, 18.22s/it]

 12%|█▏        | 1945/16104 [9:01:45<76:07:46, 19.36s/it]
{'loss': 0.6493, 'learning_rate': 1.9571371608477004e-06, 'rewards/chosen': -0.9096804261207581, 'rewards/rejected': -1.2309350967407227, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3212548494338989, 'policy_logps/rejected': -415.7674560546875, 'policy_logps/chosen': -368.2911071777344, 'referece_logps/rejected': -403.4580383300781, 'referece_logps/chosen': -359.1943054199219, 'logits/rejected': -0.12526799738407135, 'logits/chosen': 0.028845272958278656, 'epoch': 0.72}


 12%|█▏        | 1947/16104 [9:02:25<77:49:11, 19.79s/it]
{'loss': 0.5599, 'learning_rate': 1.957020576973536e-06, 'rewards/chosen': -1.326084852218628, 'rewards/rejected': -1.7431612014770508, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4170762896537781, 'policy_logps/rejected': -334.82159423828125, 'policy_logps/chosen': -602.4134521484375, 'referece_logps/rejected': -317.3899841308594, 'referece_logps/chosen': -589.152587890625, 'logits/rejected': -0.15475994348526, 'logits/chosen': -0.18607811629772186, 'epoch': 0.73}


 12%|█▏        | 1949/16104 [9:03:05<78:06:48, 19.87s/it]
{'loss': 0.5738, 'learning_rate': 1.9569038382466124e-06, 'rewards/chosen': -1.2643455266952515, 'rewards/rejected': -1.828293800354004, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5639482736587524, 'policy_logps/rejected': -304.86212158203125, 'policy_logps/chosen': -393.1797790527344, 'referece_logps/rejected': -286.5792236328125, 'referece_logps/chosen': -380.53631591796875, 'logits/rejected': -1.2245936393737793, 'logits/chosen': -1.2861669063568115, 'epoch': 0.73}


 12%|█▏        | 1951/16104 [9:03:39<70:39:49, 17.97s/it]
{'loss': 0.5963, 'learning_rate': 1.956786944685819e-06, 'rewards/chosen': -1.1529282331466675, 'rewards/rejected': -1.7614549398422241, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6085268259048462, 'policy_logps/rejected': -340.1618957519531, 'policy_logps/chosen': -332.41741943359375, 'referece_logps/rejected': -322.54736328125, 'referece_logps/chosen': -320.8881530761719, 'logits/rejected': -0.38285934925079346, 'logits/chosen': -0.37071648240089417, 'epoch': 0.73}

 12%|█▏        | 1952/16104 [9:04:00<73:55:18, 18.80s/it]


 12%|█▏        | 1954/16104 [9:04:25<62:07:23, 15.81s/it]

 12%|█▏        | 1955/16104 [9:04:38<58:48:26, 14.96s/it]

 12%|█▏        | 1956/16104 [9:04:59<66:06:43, 16.82s/it]
[2024-04-06 00:29:13,827] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 12%|█▏        | 1957/16104 [9:05:15<65:00:51, 16.54s/it]
{'loss': 0.4905, 'learning_rate': 1.9564353351894876e-06, 'rewards/chosen': -1.1480352878570557, 'rewards/rejected': -1.522768259048462, 'rewards/accuracies': 0.75, 'rewards/margins': 0.37473294138908386, 'policy_logps/rejected': -380.99871826171875, 'policy_logps/chosen': -313.9373474121094, 'referece_logps/rejected': -365.77105712890625, 'referece_logps/chosen': -302.4570007324219, 'logits/rejected': -1.0444716215133667, 'logits/chosen': -0.9257376194000244, 'epoch': 0.73}

 12%|█▏        | 1958/16104 [9:05:34<68:17:05, 17.38s/it]

 12%|█▏        | 1959/16104 [9:05:52<68:54:21, 17.54s/it]


 12%|█▏        | 1961/16104 [9:06:33<74:56:28, 19.08s/it]
[2024-04-06 00:30:48,023] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3987, 'learning_rate': 1.9562001550366793e-06, 'rewards/chosen': -0.9716898202896118, 'rewards/rejected': -2.4747939109802246, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5031039714813232, 'policy_logps/rejected': -391.8080139160156, 'policy_logps/chosen': -415.7312316894531, 'referece_logps/rejected': -367.06005859375, 'referece_logps/chosen': -406.0143127441406, 'logits/rejected': 0.7297089695930481, 'logits/chosen': 0.7860971689224243, 'epoch': 0.73}


 12%|█▏        | 1963/16104 [9:07:07<70:24:44, 17.93s/it]

 12%|█▏        | 1964/16104 [9:07:27<72:51:42, 18.55s/it]

 12%|█▏        | 1965/16104 [9:07:42<68:23:07, 17.41s/it]
{'loss': 0.3886, 'learning_rate': 1.9559643560038606e-06, 'rewards/chosen': -0.7717511653900146, 'rewards/rejected': -2.245274782180786, 'rewards/accuracies': 1.0, 'rewards/margins': 1.473523736000061, 'policy_logps/rejected': -261.4303894042969, 'policy_logps/chosen': -628.3800048828125, 'referece_logps/rejected': -238.97764587402344, 'referece_logps/chosen': -620.6624145507812, 'logits/rejected': 0.12697064876556396, 'logits/chosen': 0.025450482964515686, 'epoch': 0.73}

 12%|█▏        | 1966/16104 [9:07:57<65:06:02, 16.58s/it]

 12%|█▏        | 1967/16104 [9:08:11<62:26:55, 15.90s/it]

 12%|█▏        | 1968/16104 [9:08:23<57:55:19, 14.75s/it]


 12%|█▏        | 1970/16104 [9:08:56<61:41:07, 15.71s/it]

 12%|█▏        | 1971/16104 [9:09:18<69:10:49, 17.62s/it]

 12%|█▏        | 1972/16104 [9:09:36<69:07:52, 17.61s/it]

 12%|█▏        | 1973/16104 [9:09:50<64:51:51, 16.52s/it]
{'loss': 0.363, 'learning_rate': 1.955490901909057e-06, 'rewards/chosen': -1.1002416610717773, 'rewards/rejected': -2.1767802238464355, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0765388011932373, 'policy_logps/rejected': -253.57395935058594, 'policy_logps/chosen': -268.8651428222656, 'referece_logps/rejected': -231.80615234375, 'referece_logps/chosen': -257.86273193359375, 'logits/rejected': -0.976921796798706, 'logits/chosen': -0.8138372898101807, 'epoch': 0.74}

 12%|█▏        | 1974/16104 [9:10:11<70:45:34, 18.03s/it]


 12%|█▏        | 1976/16104 [9:10:46<68:26:25, 17.44s/it]
{'loss': 0.5593, 'learning_rate': 1.9553127188109526e-06, 'rewards/chosen': -0.8208027482032776, 'rewards/rejected': -1.9348974227905273, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1140947341918945, 'policy_logps/rejected': -364.94818115234375, 'policy_logps/chosen': -355.2579040527344, 'referece_logps/rejected': -345.5992431640625, 'referece_logps/chosen': -347.04986572265625, 'logits/rejected': 0.15877215564250946, 'logits/chosen': 0.4389789402484894, 'epoch': 0.74}


 12%|█▏        | 1978/16104 [9:11:20<68:33:26, 17.47s/it]

 12%|█▏        | 1979/16104 [9:11:38<68:56:12, 17.57s/it]
{'loss': 0.5547, 'learning_rate': 1.9551341879159198e-06, 'rewards/chosen': -1.1153148412704468, 'rewards/rejected': -1.715773582458496, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6004586815834045, 'policy_logps/rejected': -306.86212158203125, 'policy_logps/chosen': -289.86480712890625, 'referece_logps/rejected': -289.704345703125, 'referece_logps/chosen': -278.7116394042969, 'logits/rejected': -0.9840896129608154, 'logits/chosen': -0.9586210250854492, 'epoch': 0.74}

 12%|█▏        | 1980/16104 [9:11:51<63:06:26, 16.09s/it]

 12%|█▏        | 1981/16104 [9:12:09<65:45:35, 16.76s/it]

 12%|█▏        | 1982/16104 [9:12:21<60:02:35, 15.31s/it]


 12%|█▏        | 1984/16104 [9:12:56<64:55:55, 16.55s/it]
{'loss': 0.6126, 'learning_rate': 1.9548358637187266e-06, 'rewards/chosen': -0.6987371444702148, 'rewards/rejected': -2.0877888202667236, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3890516757965088, 'policy_logps/rejected': -472.9100341796875, 'policy_logps/chosen': -461.6424865722656, 'referece_logps/rejected': -452.03216552734375, 'referece_logps/chosen': -454.6551513671875, 'logits/rejected': 0.5452608466148376, 'logits/chosen': 0.4782957434654236, 'epoch': 0.74}

 12%|█▏        | 1985/16104 [9:13:11<63:13:43, 16.12s/it]


 12%|█▏        | 1987/16104 [9:13:40<58:31:36, 14.92s/it]

 12%|█▏        | 1988/16104 [9:13:57<60:29:26, 15.43s/it]
{'loss': 0.5655, 'learning_rate': 1.9545965090998523e-06, 'rewards/chosen': -1.1256389617919922, 'rewards/rejected': -1.6152291297912598, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4895901679992676, 'policy_logps/rejected': -332.6706848144531, 'policy_logps/chosen': -461.3768310546875, 'referece_logps/rejected': -316.5184020996094, 'referece_logps/chosen': -450.1203918457031, 'logits/rejected': -0.4296122193336487, 'logits/chosen': -0.5224205851554871, 'epoch': 0.74}

 12%|█▏        | 1989/16104 [9:14:13<62:09:24, 15.85s/it]

 12%|█▏        | 1990/16104 [9:14:33<66:28:05, 16.95s/it]

 12%|█▏        | 1991/16104 [9:14:54<71:02:18, 18.12s/it]

 12%|█▏        | 1992/16104 [9:15:12<70:52:39, 18.08s/it]


 12%|█▏        | 1994/16104 [9:15:39<61:32:51, 15.70s/it]

 12%|█▏        | 1995/16104 [9:15:55<61:49:18, 15.77s/it]
{'loss': 0.4767, 'learning_rate': 1.9541761519277233e-06, 'rewards/chosen': -1.091345191001892, 'rewards/rejected': -2.3842837810516357, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2929385900497437, 'policy_logps/rejected': -355.57086181640625, 'policy_logps/chosen': -476.3729553222656, 'referece_logps/rejected': -331.72802734375, 'referece_logps/chosen': -465.4595031738281, 'logits/rejected': -0.45605289936065674, 'logits/chosen': -0.4221484065055847, 'epoch': 0.74}

 12%|█▏        | 1996/16104 [9:16:18<70:52:12, 18.08s/it]


 12%|█▏        | 1998/16104 [9:16:54<71:31:33, 18.25s/it]

 12%|█▏        | 1999/16104 [9:17:15<73:41:30, 18.81s/it]
{'loss': 0.504, 'learning_rate': 1.953935098617087e-06, 'rewards/chosen': -0.7034305930137634, 'rewards/rejected': -1.7119022607803345, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0084717273712158, 'policy_logps/rejected': -216.20721435546875, 'policy_logps/chosen': -256.7720947265625, 'referece_logps/rejected': -199.08819580078125, 'referece_logps/chosen': -249.73776245117188, 'logits/rejected': -0.390034556388855, 'logits/chosen': -0.26735857129096985, 'epoch': 0.74}

 12%|█▏        | 2000/16104 [9:17:34<74:43:57, 19.08s/it]

 12%|█▏        | 2001/16104 [9:18:01<83:51:26, 21.41s/it]

 12%|█▏        | 2002/16104 [9:18:12<71:34:45, 18.27s/it]

 12%|█▏        | 2003/16104 [9:18:28<68:58:41, 17.61s/it]

 12%|█▏        | 2004/16104 [9:18:44<67:00:44, 17.11s/it]

 12%|█▏        | 2005/16104 [9:19:06<72:12:25, 18.44s/it]


 12%|█▏        | 2007/16104 [9:19:33<62:38:41, 16.00s/it]

 12%|█▏        | 2008/16104 [9:19:45<58:01:33, 14.82s/it]
{'loss': 0.508, 'learning_rate': 1.953390471486542e-06, 'rewards/chosen': -0.9569296836853027, 'rewards/rejected': -1.3219338655471802, 'rewards/accuracies': 0.75, 'rewards/margins': 0.36500418186187744, 'policy_logps/rejected': -284.6100769042969, 'policy_logps/chosen': -303.82513427734375, 'referece_logps/rejected': -271.3907470703125, 'referece_logps/chosen': -294.2558288574219, 'logits/rejected': -1.0194547176361084, 'logits/chosen': -1.0647257566452026, 'epoch': 0.75}

 12%|█▏        | 2009/16104 [9:20:01<59:54:30, 15.30s/it]

 12%|█▏        | 2010/16104 [9:20:21<65:20:51, 16.69s/it]


 12%|█▏        | 2012/16104 [9:20:57<67:38:17, 17.28s/it]

 12%|█▎        | 2013/16104 [9:21:15<68:04:06, 17.39s/it]
{'loss': 0.5003, 'learning_rate': 1.9530865509220658e-06, 'rewards/chosen': -1.1480494737625122, 'rewards/rejected': -1.3961313962936401, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24808178842067719, 'policy_logps/rejected': -423.2590026855469, 'policy_logps/chosen': -452.92877197265625, 'referece_logps/rejected': -409.2976989746094, 'referece_logps/chosen': -441.4483337402344, 'logits/rejected': -0.04870825260877609, 'logits/chosen': -0.08379892259836197, 'epoch': 0.75}

 13%|█▎        | 2014/16104 [9:21:25<60:18:43, 15.41s/it]

 13%|█▎        | 2015/16104 [9:21:45<65:30:19, 16.74s/it]

 13%|█▎        | 2016/16104 [9:22:02<65:54:11, 16.84s/it]

 13%|█▎        | 2017/16104 [9:22:18<64:06:14, 16.38s/it]


 13%|█▎        | 2019/16104 [9:22:47<59:38:20, 15.24s/it]
{'loss': 0.5423, 'learning_rate': 1.9527205739882045e-06, 'rewards/chosen': -0.9026408791542053, 'rewards/rejected': -1.3339792490005493, 'rewards/accuracies': 0.875, 'rewards/margins': 0.431338369846344, 'policy_logps/rejected': -296.57806396484375, 'policy_logps/chosen': -280.34173583984375, 'referece_logps/rejected': -283.23828125, 'referece_logps/chosen': -271.3153381347656, 'logits/rejected': -1.2235348224639893, 'logits/chosen': -1.0775936841964722, 'epoch': 0.75}


 13%|█▎        | 2021/16104 [9:23:21<61:36:32, 15.75s/it]

 13%|█▎        | 2022/16104 [9:23:39<64:17:29, 16.44s/it]

 13%|█▎        | 2023/16104 [9:23:51<59:29:42, 15.21s/it]

 13%|█▎        | 2024/16104 [9:24:11<64:56:41, 16.61s/it]
{'loss': 0.5095, 'learning_rate': 1.9524145333581313e-06, 'rewards/chosen': -1.040008544921875, 'rewards/rejected': -1.8289339542388916, 'rewards/accuracies': 0.625, 'rewards/margins': 0.788925290107727, 'policy_logps/rejected': -572.0333862304688, 'policy_logps/chosen': -320.28973388671875, 'referece_logps/rejected': -553.7440185546875, 'referece_logps/chosen': -309.8896484375, 'logits/rejected': -0.31770986318588257, 'logits/chosen': -0.1993817239999771, 'epoch': 0.75}

 13%|█▎        | 2025/16104 [9:24:23<60:05:40, 15.37s/it]

 13%|█▎        | 2026/16104 [9:24:42<63:39:21, 16.28s/it]

 13%|█▎        | 2027/16104 [9:25:01<67:31:37, 17.27s/it]


 13%|█▎        | 2029/16104 [9:25:41<71:55:02, 18.39s/it]
{'loss': 0.4798, 'learning_rate': 1.95210752955645e-06, 'rewards/chosen': -0.48480701446533203, 'rewards/rejected': -2.2958924770355225, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8110852241516113, 'policy_logps/rejected': -227.09494018554688, 'policy_logps/chosen': -287.0870361328125, 'referece_logps/rejected': -204.13600158691406, 'referece_logps/chosen': -282.2389831542969, 'logits/rejected': -0.2303367257118225, 'logits/chosen': -0.22298012673854828, 'epoch': 0.76}

 13%|█▎        | 2030/16104 [9:26:00<72:50:25, 18.63s/it]


 13%|█▎        | 2032/16104 [9:26:35<70:58:40, 18.16s/it]
{'loss': 0.5088, 'learning_rate': 1.951922865082185e-06, 'rewards/chosen': -1.2074264287948608, 'rewards/rejected': -2.248924970626831, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0414986610412598, 'policy_logps/rejected': -385.39404296875, 'policy_logps/chosen': -308.5826721191406, 'referece_logps/rejected': -362.90478515625, 'referece_logps/chosen': -296.50836181640625, 'logits/rejected': -0.640304684638977, 'logits/chosen': -0.5917277336120605, 'epoch': 0.76}


 13%|█▎        | 2034/16104 [9:27:05<65:15:13, 16.70s/it]
{'loss': 0.5434, 'learning_rate': 1.9517995628936316e-06, 'rewards/chosen': -1.403794288635254, 'rewards/rejected': -1.7647749185562134, 'rewards/accuracies': 0.375, 'rewards/margins': 0.3609805405139923, 'policy_logps/rejected': -439.3507080078125, 'policy_logps/chosen': -522.59765625, 'referece_logps/rejected': -421.70294189453125, 'referece_logps/chosen': -508.5597229003906, 'logits/rejected': -1.2067906856536865, 'logits/chosen': -1.3673862218856812, 'epoch': 0.76}

 13%|█▎        | 2035/16104 [9:27:18<61:25:41, 15.72s/it]

 13%|█▎        | 2036/16104 [9:27:30<56:10:10, 14.37s/it]


 13%|█▎        | 2038/16104 [9:27:59<56:00:06, 14.33s/it]
{'loss': 0.5094, 'learning_rate': 1.9515524965126164e-06, 'rewards/chosen': -0.660476803779602, 'rewards/rejected': -1.0904996395111084, 'rewards/accuracies': 0.75, 'rewards/margins': 0.43002283573150635, 'policy_logps/rejected': -360.1591796875, 'policy_logps/chosen': -390.1226501464844, 'referece_logps/rejected': -349.2542419433594, 'referece_logps/chosen': -383.51788330078125, 'logits/rejected': 0.0013880729675292969, 'logits/chosen': 0.043515950441360474, 'epoch': 0.76}

 13%|█▎        | 2039/16104 [9:28:17<59:21:16, 15.19s/it]


 13%|█▎        | 2041/16104 [9:28:51<61:51:11, 15.83s/it]
{'loss': 0.4688, 'learning_rate': 1.951366792552152e-06, 'rewards/chosen': -0.541621208190918, 'rewards/rejected': -1.4806926250457764, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9390714168548584, 'policy_logps/rejected': -264.4444885253906, 'policy_logps/chosen': -338.249267578125, 'referece_logps/rejected': -249.63754272460938, 'referece_logps/chosen': -332.8330383300781, 'logits/rejected': -0.15128099918365479, 'logits/chosen': 0.035002414137125015, 'epoch': 0.76}

 13%|█▎        | 2042/16104 [9:29:02<55:53:06, 14.31s/it]

 13%|█▎        | 2043/16104 [9:29:20<60:03:29, 15.38s/it]


 13%|█▎        | 2045/16104 [9:29:45<53:41:52, 13.75s/it]
{'loss': 0.5659, 'learning_rate': 1.9511186485004683e-06, 'rewards/chosen': -1.1386739015579224, 'rewards/rejected': -1.1571602821350098, 'rewards/accuracies': 0.375, 'rewards/margins': 0.018486471846699715, 'policy_logps/rejected': -455.870849609375, 'policy_logps/chosen': -283.8065185546875, 'referece_logps/rejected': -444.2992858886719, 'referece_logps/chosen': -272.4197998046875, 'logits/rejected': -0.8615837097167969, 'logits/chosen': -0.6489973068237305, 'epoch': 0.76}


 13%|█▎        | 2047/16104 [9:30:28<68:22:44, 17.51s/it]
{'loss': 0.5259, 'learning_rate': 1.9509943456179056e-06, 'rewards/chosen': -0.623582661151886, 'rewards/rejected': -1.5554379224777222, 'rewards/accuracies': 0.75, 'rewards/margins': 0.931855320930481, 'policy_logps/rejected': -381.807373046875, 'policy_logps/chosen': -478.0369873046875, 'referece_logps/rejected': -366.25299072265625, 'referece_logps/chosen': -471.8011779785156, 'logits/rejected': -0.9886492490768433, 'logits/chosen': -1.079634189605713, 'epoch': 0.76}

 13%|█▎        | 2048/16104 [9:30:40<62:28:02, 16.00s/it]

 13%|█▎        | 2049/16104 [9:30:51<56:17:57, 14.42s/it]

 13%|█▎        | 2050/16104 [9:31:11<62:51:54, 16.10s/it]


 13%|█▎        | 2052/16104 [9:31:38<56:31:03, 14.48s/it]
{'loss': 0.6184, 'learning_rate': 1.9506829152407426e-06, 'rewards/chosen': -1.2420172691345215, 'rewards/rejected': -1.3200407028198242, 'rewards/accuracies': 0.5, 'rewards/margins': 0.07802341878414154, 'policy_logps/rejected': -254.0824737548828, 'policy_logps/chosen': -302.3829650878906, 'referece_logps/rejected': -240.88204956054688, 'referece_logps/chosen': -289.9627685546875, 'logits/rejected': -0.20666815340518951, 'logits/chosen': -0.23250171542167664, 'epoch': 0.76}

 13%|█▎        | 2053/16104 [9:31:57<61:59:35, 15.88s/it]

 13%|█▎        | 2054/16104 [9:32:18<68:21:49, 17.52s/it]

 13%|█▎        | 2055/16104 [9:32:29<60:16:38, 15.45s/it]

 13%|█▎        | 2056/16104 [9:32:49<66:02:51, 16.93s/it]

 13%|█▎        | 2057/16104 [9:33:00<58:58:03, 15.11s/it]


 13%|█▎        | 2059/16104 [9:33:31<58:26:07, 14.98s/it]

 13%|█▎        | 2060/16104 [9:33:46<57:42:05, 14.79s/it]
{'loss': 0.5499, 'learning_rate': 1.950182627014165e-06, 'rewards/chosen': -1.1056135892868042, 'rewards/rejected': -2.614372730255127, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5087590217590332, 'policy_logps/rejected': -450.9794921875, 'policy_logps/chosen': -558.6707153320312, 'referece_logps/rejected': -424.8357849121094, 'referece_logps/chosen': -547.6146240234375, 'logits/rejected': 0.0027478784322738647, 'logits/chosen': 0.10396145284175873, 'epoch': 0.77}

 13%|█▎        | 2061/16104 [9:34:02<59:22:42, 15.22s/it]


 13%|█▎        | 2063/16104 [9:34:34<61:50:23, 15.86s/it]

 13%|█▎        | 2064/16104 [9:34:46<57:16:04, 14.68s/it]
{'loss': 0.5147, 'learning_rate': 1.949931560341885e-06, 'rewards/chosen': -0.8547411561012268, 'rewards/rejected': -1.6939892768859863, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8392480611801147, 'policy_logps/rejected': -313.3163757324219, 'policy_logps/chosen': -374.6580810546875, 'referece_logps/rejected': -296.37646484375, 'referece_logps/chosen': -366.11065673828125, 'logits/rejected': -0.23401564359664917, 'logits/chosen': -0.23075664043426514, 'epoch': 0.77}

 13%|█▎        | 2065/16104 [9:34:56<52:36:28, 13.49s/it]


 13%|█▎        | 2067/16104 [9:35:18<47:07:02, 12.08s/it]
{'loss': 0.6171, 'learning_rate': 1.949742856851312e-06, 'rewards/chosen': -0.8906732201576233, 'rewards/rejected': -1.9197745323181152, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0291013717651367, 'policy_logps/rejected': -315.84002685546875, 'policy_logps/chosen': -402.5414123535156, 'referece_logps/rejected': -296.64227294921875, 'referece_logps/chosen': -393.6346740722656, 'logits/rejected': -0.4907483458518982, 'logits/chosen': -0.49607226252555847, 'epoch': 0.77}

 13%|█▎        | 2068/16104 [9:35:29<45:31:13, 11.68s/it]


 13%|█▎        | 2070/16104 [9:36:06<58:01:14, 14.88s/it]
{'loss': 0.3966, 'learning_rate': 1.949553807591609e-06, 'rewards/chosen': -0.8782743811607361, 'rewards/rejected': -1.5503133535385132, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6720390319824219, 'policy_logps/rejected': -275.2829895019531, 'policy_logps/chosen': -359.5877685546875, 'referece_logps/rejected': -259.7798767089844, 'referece_logps/chosen': -350.80499267578125, 'logits/rejected': -1.1079615354537964, 'logits/chosen': -0.8545676469802856, 'epoch': 0.77}

 13%|█▎        | 2071/16104 [9:36:25<62:52:15, 16.13s/it]


 13%|█▎        | 2073/16104 [9:36:58<63:16:57, 16.24s/it]
{'loss': 0.5037, 'learning_rate': 1.9493644126316007e-06, 'rewards/chosen': -0.8802642822265625, 'rewards/rejected': -2.112666130065918, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2324016094207764, 'policy_logps/rejected': -356.7290344238281, 'policy_logps/chosen': -352.9700012207031, 'referece_logps/rejected': -335.6023864746094, 'referece_logps/chosen': -344.1673889160156, 'logits/rejected': -0.7485731244087219, 'logits/chosen': -0.8058528900146484, 'epoch': 0.77}


 13%|█▎        | 2075/16104 [9:37:32<64:56:05, 16.66s/it]

 13%|█▎        | 2076/16104 [9:37:48<64:02:00, 16.43s/it]

 13%|█▎        | 2077/16104 [9:38:06<66:04:32, 16.96s/it]
[2024-04-06 01:02:20,773] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2078/16104 [9:38:28<71:48:18, 18.43s/it]
{'loss': 0.5056, 'learning_rate': 1.949047986329357e-06, 'rewards/chosen': -2.2800097465515137, 'rewards/rejected': -3.6473612785339355, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3673515319824219, 'policy_logps/rejected': -520.6404418945312, 'policy_logps/chosen': -479.5746765136719, 'referece_logps/rejected': -484.16680908203125, 'referece_logps/chosen': -456.7745666503906, 'logits/rejected': -0.6411927342414856, 'logits/chosen': -0.7305880188941956, 'epoch': 0.77}

 13%|█▎        | 2079/16104 [9:38:45<70:42:06, 18.15s/it]


 13%|█▎        | 2081/16104 [9:39:30<78:23:47, 20.13s/it]
{'loss': 0.6346, 'learning_rate': 1.9488576698393116e-06, 'rewards/chosen': -0.8866599798202515, 'rewards/rejected': -1.207320213317871, 'rewards/accuracies': 0.375, 'rewards/margins': 0.32066020369529724, 'policy_logps/rejected': -384.05908203125, 'policy_logps/chosen': -423.20501708984375, 'referece_logps/rejected': -371.98590087890625, 'referece_logps/chosen': -414.3384094238281, 'logits/rejected': -0.5962471961975098, 'logits/chosen': -0.6085397005081177, 'epoch': 0.78}

 13%|█▎        | 2082/16104 [9:39:46<73:11:00, 18.79s/it]

 13%|█▎        | 2083/16104 [9:40:03<71:09:41, 18.27s/it]


 13%|█▎        | 2085/16104 [9:40:24<56:06:53, 14.41s/it]
{'loss': 0.5794, 'learning_rate': 1.9486033771694567e-06, 'rewards/chosen': -0.9382559657096863, 'rewards/rejected': -1.5769096612930298, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6386536359786987, 'policy_logps/rejected': -391.5033264160156, 'policy_logps/chosen': -504.1521911621094, 'referece_logps/rejected': -375.7342224121094, 'referece_logps/chosen': -494.76959228515625, 'logits/rejected': -0.9541404247283936, 'logits/chosen': -0.7153905630111694, 'epoch': 0.78}

 13%|█▎        | 2086/16104 [9:40:35<51:43:45, 13.28s/it]

 13%|█▎        | 2087/16104 [9:40:56<60:47:17, 15.61s/it]


 13%|█▎        | 2089/16104 [9:41:24<58:32:08, 15.04s/it]
{'loss': 0.5472, 'learning_rate': 1.9483484705364424e-06, 'rewards/chosen': -1.0435292720794678, 'rewards/rejected': -1.5766243934631348, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5330950021743774, 'policy_logps/rejected': -276.9253234863281, 'policy_logps/chosen': -208.91189575195312, 'referece_logps/rejected': -261.15911865234375, 'referece_logps/chosen': -198.4766082763672, 'logits/rejected': -0.8607693910598755, 'logits/chosen': -0.8102798461914062, 'epoch': 0.78}

 13%|█▎        | 2090/16104 [9:41:41<61:00:57, 15.67s/it]
[2024-04-06 01:06:16,514] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2091/16104 [9:42:02<66:38:11, 17.12s/it]


 13%|█▎        | 2093/16104 [9:42:32<61:12:06, 15.73s/it]

 13%|█▎        | 2094/16104 [9:42:54<68:10:44, 17.52s/it]

 13%|█▎        | 2095/16104 [9:43:14<71:09:34, 18.29s/it]
{'loss': 0.574, 'learning_rate': 1.947964959767006e-06, 'rewards/chosen': -0.6109245419502258, 'rewards/rejected': -1.2981836795806885, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6872591972351074, 'policy_logps/rejected': -351.6893310546875, 'policy_logps/chosen': -502.6065979003906, 'referece_logps/rejected': -338.70745849609375, 'referece_logps/chosen': -496.4974060058594, 'logits/rejected': -0.3957502841949463, 'logits/chosen': -0.5105942487716675, 'epoch': 0.78}

 13%|█▎        | 2096/16104 [9:43:26<63:38:06, 16.35s/it]


 13%|█▎        | 2098/16104 [9:44:06<70:46:40, 18.19s/it]
{'loss': 0.4351, 'learning_rate': 1.9477726866645626e-06, 'rewards/chosen': -0.7363091707229614, 'rewards/rejected': -1.7563871145248413, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0200780630111694, 'policy_logps/rejected': -299.1007995605469, 'policy_logps/chosen': -314.7906188964844, 'referece_logps/rejected': -281.53692626953125, 'referece_logps/chosen': -307.42755126953125, 'logits/rejected': -0.8143089413642883, 'logits/chosen': -0.7553636431694031, 'epoch': 0.78}

 13%|█▎        | 2099/16104 [9:44:17<62:20:50, 16.03s/it]

 13%|█▎        | 2100/16104 [9:44:29<57:09:00, 14.69s/it]

 13%|█▎        | 2101/16104 [9:44:50<64:45:02, 16.65s/it]

 13%|█▎        | 2102/16104 [9:45:12<71:05:39, 18.28s/it]


 13%|█▎        | 2104/16104 [9:45:53<75:03:15, 19.30s/it]
[2024-04-06 01:10:07,172] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4768, 'learning_rate': 1.9473871053742237e-06, 'rewards/chosen': -0.5449702739715576, 'rewards/rejected': -1.6699544191360474, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1249839067459106, 'policy_logps/rejected': -430.650390625, 'policy_logps/chosen': -473.3869934082031, 'referece_logps/rejected': -413.95086669921875, 'referece_logps/chosen': -467.93731689453125, 'logits/rejected': 0.5407578349113464, 'logits/chosen': 0.6234937906265259, 'epoch': 0.78}

 13%|█▎        | 2105/16104 [9:46:14<77:17:23, 19.88s/it]

 13%|█▎        | 2106/16104 [9:46:30<73:12:33, 18.83s/it]

 13%|█▎        | 2107/16104 [9:46:50<74:12:25, 19.09s/it]

 13%|█▎        | 2108/16104 [9:47:01<65:05:29, 16.74s/it]

 13%|█▎        | 2109/16104 [9:47:14<60:46:17, 15.63s/it]

 13%|█▎        | 2110/16104 [9:47:34<65:17:40, 16.80s/it]

 13%|█▎        | 2111/16104 [9:47:55<70:26:27, 18.12s/it]

 13%|█▎        | 2112/16104 [9:48:07<64:01:17, 16.47s/it]

 13%|█▎        | 2113/16104 [9:48:19<58:44:12, 15.11s/it]
[2024-04-06 01:12:45,947] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2114/16104 [9:48:31<54:57:14, 14.14s/it]


 13%|█▎        | 2116/16104 [9:49:05<60:02:34, 15.45s/it]
{'loss': 0.49, 'learning_rate': 1.946611804419659e-06, 'rewards/chosen': -0.9877499938011169, 'rewards/rejected': -1.752197027206421, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7644469738006592, 'policy_logps/rejected': -261.0386962890625, 'policy_logps/chosen': -294.4479064941406, 'referece_logps/rejected': -243.5167236328125, 'referece_logps/chosen': -284.5704040527344, 'logits/rejected': -0.3456442952156067, 'logits/chosen': -0.31608185172080994, 'epoch': 0.79}

 13%|█▎        | 2117/16104 [9:49:25<65:31:34, 16.87s/it]

 13%|█▎        | 2118/16104 [9:49:37<60:36:30, 15.60s/it]
[2024-04-06 01:14:10,074] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2119/16104 [9:49:55<63:21:21, 16.31s/it]

 13%|█▎        | 2120/16104 [9:50:08<59:06:53, 15.22s/it]

 13%|█▎        | 2121/16104 [9:50:21<56:39:34, 14.59s/it]

 13%|█▎        | 2122/16104 [9:50:35<55:13:44, 14.22s/it]

 13%|█▎        | 2123/16104 [9:50:54<61:50:35, 15.92s/it]

 13%|█▎        | 2124/16104 [9:51:12<63:18:42, 16.30s/it]

 13%|█▎        | 2125/16104 [9:51:22<56:48:51, 14.63s/it]

 13%|█▎        | 2126/16104 [9:51:33<52:15:10, 13.46s/it]

 13%|█▎        | 2127/16104 [9:51:44<49:00:11, 12.62s/it]

 13%|█▎        | 2128/16104 [9:51:57<49:48:24, 12.83s/it]

 13%|█▎        | 2129/16104 [9:52:15<56:00:07, 14.43s/it]

 13%|█▎        | 2130/16104 [9:52:33<59:49:09, 15.41s/it]

 13%|█▎        | 2131/16104 [9:52:53<65:22:07, 16.84s/it]

 13%|█▎        | 2132/16104 [9:53:10<64:50:46, 16.71s/it]

 13%|█▎        | 2133/16104 [9:53:27<65:25:24, 16.86s/it]

 13%|█▎        | 2134/16104 [9:53:44<66:21:12, 17.10s/it]

 13%|█▎        | 2135/16104 [9:53:55<59:18:26, 15.28s/it]

 13%|█▎        | 2136/16104 [9:54:12<60:15:07, 15.53s/it]

 13%|█▎        | 2137/16104 [9:54:22<54:44:17, 14.11s/it]

 13%|█▎        | 2138/16104 [9:54:33<50:49:27, 13.10s/it]

 13%|█▎        | 2139/16104 [9:54:44<48:13:21, 12.43s/it]

 13%|█▎        | 2140/16104 [9:54:56<47:11:03, 12.16s/it]

 13%|█▎        | 2141/16104 [9:55:09<48:27:56, 12.50s/it]

 13%|█▎        | 2142/16104 [9:55:30<58:48:25, 15.16s/it]

 13%|█▎        | 2143/16104 [9:55:48<62:09:33, 16.03s/it]

 13%|█▎        | 2144/16104 [9:56:00<56:45:16, 14.64s/it]

 13%|█▎        | 2145/16104 [9:56:15<57:54:37, 14.93s/it]

 13%|█▎        | 2146/16104 [9:56:34<61:56:12, 15.97s/it]

 13%|█▎        | 2147/16104 [9:56:47<59:01:00, 15.22s/it]

 13%|█▎        | 2148/16104 [9:57:01<56:55:02, 14.68s/it]

 13%|█▎        | 2149/16104 [9:57:15<56:17:02, 14.52s/it]

 13%|█▎        | 2150/16104 [9:57:26<52:19:40, 13.50s/it]

 13%|█▎        | 2151/16104 [9:57:41<53:58:36, 13.93s/it]

 13%|█▎        | 2152/16104 [9:57:57<56:21:21, 14.54s/it]

 13%|█▎        | 2153/16104 [9:58:15<60:21:24, 15.57s/it]

 13%|█▎        | 2154/16104 [9:58:27<56:08:54, 14.49s/it]

 13%|█▎        | 2155/16104 [9:58:47<62:46:58, 16.20s/it]
[2024-04-06 01:23:24,411] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2156/16104 [9:59:10<70:36:12, 18.22s/it]

 13%|█▎        | 2157/16104 [9:59:22<63:16:07, 16.33s/it]

 13%|█▎        | 2158/16104 [9:59:43<68:42:26, 17.74s/it]

 13%|█▎        | 2159/16104 [10:00:01<69:11:32, 17.86s/it]

 13%|█▎        | 2160/16104 [10:00:15<64:40:18, 16.70s/it]

 13%|█▎        | 2161/16104 [10:00:36<69:17:22, 17.89s/it]

 13%|█▎        | 2162/16104 [10:00:47<62:02:12, 16.02s/it]
[2024-04-06 01:25:16,581] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2163/16104 [10:01:02<60:35:22, 15.65s/it]

 13%|█▎        | 2164/16104 [10:01:16<59:17:26, 15.31s/it]

 13%|█▎        | 2165/16104 [10:01:27<54:10:25, 13.99s/it]

 13%|█▎        | 2166/16104 [10:01:45<58:42:31, 15.16s/it]

 13%|█▎        | 2167/16104 [10:02:03<61:37:28, 15.92s/it]

 13%|█▎        | 2168/16104 [10:02:14<56:14:35, 14.53s/it]
[2024-04-06 01:26:46,459] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2169/16104 [10:02:32<59:46:19, 15.44s/it]

 13%|█▎        | 2170/16104 [10:02:50<63:20:49, 16.37s/it]

 13%|█▎        | 2171/16104 [10:03:04<60:03:59, 15.52s/it]

 13%|█▎        | 2172/16104 [10:03:17<57:48:47, 14.94s/it]

 13%|█▎        | 2173/16104 [10:03:36<62:05:40, 16.05s/it]

 13%|█▎        | 2174/16104 [10:03:58<68:27:56, 17.69s/it]

 14%|█▎        | 2175/16104 [10:04:19<73:10:38, 18.91s/it]

 14%|█▎        | 2176/16104 [10:04:41<76:15:32, 19.71s/it]

 14%|█▎        | 2177/16104 [10:04:53<67:14:28, 17.38s/it]

 14%|█▎        | 2178/16104 [10:05:04<59:25:18, 15.36s/it]

 14%|█▎        | 2179/16104 [10:05:22<63:00:12, 16.29s/it]

 14%|█▎        | 2180/16104 [10:05:34<58:32:22, 15.14s/it]

 14%|█▎        | 2181/16104 [10:05:50<58:33:01, 15.14s/it]

 14%|█▎        | 2182/16104 [10:06:09<63:57:08, 16.54s/it]
[2024-04-06 01:30:45,891] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▎        | 2183/16104 [10:06:31<70:06:23, 18.13s/it]

 14%|█▎        | 2184/16104 [10:06:43<62:36:57, 16.19s/it]

 14%|█▎        | 2185/16104 [10:07:00<63:40:54, 16.47s/it]

 14%|█▎        | 2186/16104 [10:07:15<61:21:08, 15.87s/it]

 14%|█▎        | 2187/16104 [10:07:33<64:12:02, 16.61s/it]

 14%|█▎        | 2188/16104 [10:07:49<64:03:46, 16.57s/it]

 14%|█▎        | 2189/16104 [10:08:05<62:56:45, 16.28s/it]

 14%|█▎        | 2190/16104 [10:08:25<66:49:09, 17.29s/it]

 14%|█▎        | 2191/16104 [10:08:43<68:17:55, 17.67s/it]

 14%|█▎        | 2192/16104 [10:09:04<71:31:28, 18.51s/it]

 14%|█▎        | 2193/16104 [10:09:23<72:10:37, 18.68s/it]

 14%|█▎        | 2194/16104 [10:09:42<72:22:54, 18.73s/it]

 14%|█▎        | 2195/16104 [10:10:01<73:24:11, 19.00s/it]

 14%|█▎        | 2196/16104 [10:10:12<64:04:01, 16.58s/it]

 14%|█▎        | 2197/16104 [10:10:31<66:20:31, 17.17s/it]


 14%|█▎        | 2199/16104 [10:11:09<69:34:22, 18.01s/it]

 14%|█▎        | 2200/16104 [10:11:24<66:39:43, 17.26s/it]

 14%|█▎        | 2201/16104 [10:11:41<66:01:45, 17.10s/it]

 14%|█▎        | 2202/16104 [10:12:02<70:09:49, 18.17s/it]

 14%|█▎        | 2203/16104 [10:12:23<73:43:01, 19.09s/it]

 14%|█▎        | 2204/16104 [10:12:39<70:39:00, 18.30s/it]

 14%|█▎        | 2205/16104 [10:12:59<72:49:24, 18.86s/it]

 14%|█▎        | 2206/16104 [10:13:20<74:59:11, 19.42s/it]
{'loss': 0.4894, 'learning_rate': 1.9406216035992307e-06, 'rewards/chosen': -0.9657089114189148, 'rewards/rejected': -2.6949222087860107, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7292133569717407, 'policy_logps/rejected': -478.2414855957031, 'policy_logps/chosen': -495.0502624511719, 'referece_logps/rejected': -451.2922668457031, 'referece_logps/chosen': -485.3931884765625, 'logits/rejected': -0.9762333631515503, 'logits/chosen': -1.093828797340393, 'epoch': 0.82}


 14%|█▎        | 2208/16104 [10:13:56<71:35:58, 18.55s/it]

 14%|█▎        | 2209/16104 [10:14:07<62:21:18, 16.16s/it]

 14%|█▎        | 2210/16104 [10:14:18<55:59:14, 14.51s/it]

 14%|█▎        | 2211/16104 [10:14:39<63:30:09, 16.46s/it]

 14%|█▎        | 2212/16104 [10:14:52<59:37:57, 15.45s/it]

 14%|█▎        | 2213/16104 [10:15:02<54:00:49, 14.00s/it]

 14%|█▎        | 2214/16104 [10:15:13<50:07:35, 12.99s/it]

 14%|█▍        | 2215/16104 [10:15:24<47:25:32, 12.29s/it]

 14%|█▍        | 2216/16104 [10:15:34<45:35:32, 11.82s/it]

 14%|█▍        | 2217/16104 [10:15:54<54:34:50, 14.15s/it]

 14%|█▍        | 2218/16104 [10:16:07<53:13:58, 13.80s/it]

 14%|█▍        | 2219/16104 [10:16:20<51:49:37, 13.44s/it]

 14%|█▍        | 2220/16104 [10:16:42<61:45:40, 16.01s/it]

 14%|█▍        | 2221/16104 [10:16:54<57:20:46, 14.87s/it]

 14%|█▍        | 2222/16104 [10:17:14<63:03:43, 16.35s/it]

 14%|█▍        | 2223/16104 [10:17:37<71:34:27, 18.56s/it]

 14%|█▍        | 2224/16104 [10:17:53<68:33:26, 17.78s/it]

 14%|█▍        | 2225/16104 [10:18:10<67:24:31, 17.48s/it]

 14%|█▍        | 2226/16104 [10:18:25<64:08:27, 16.64s/it]

 14%|█▍        | 2227/16104 [10:18:43<66:20:06, 17.21s/it]

 14%|█▍        | 2228/16104 [10:19:04<70:12:17, 18.21s/it]

 14%|█▍        | 2229/16104 [10:19:22<70:13:20, 18.22s/it]

 14%|█▍        | 2230/16104 [10:19:42<72:19:58, 18.77s/it]

 14%|█▍        | 2231/16104 [10:19:59<70:32:48, 18.31s/it]

 14%|█▍        | 2232/16104 [10:20:11<62:35:13, 16.24s/it]

 14%|█▍        | 2233/16104 [10:20:30<65:55:54, 17.11s/it]

 14%|█▍        | 2234/16104 [10:20:41<58:41:04, 15.23s/it]

 14%|█▍        | 2235/16104 [10:20:51<53:25:47, 13.87s/it]

 14%|█▍        | 2236/16104 [10:21:08<56:32:45, 14.68s/it]

 14%|█▍        | 2237/16104 [10:21:22<55:36:08, 14.43s/it]

 14%|█▍        | 2238/16104 [10:21:40<59:34:47, 15.47s/it]
{'loss': 0.4674, 'learning_rate': 1.9384173785039063e-06, 'rewards/chosen': -0.6652463674545288, 'rewards/rejected': -1.642814040184021, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9775676727294922, 'policy_logps/rejected': -377.0920104980469, 'policy_logps/chosen': -410.6143798828125, 'referece_logps/rejected': -360.66387939453125, 'referece_logps/chosen': -403.9619445800781, 'logits/rejected': 0.2709409296512604, 'logits/chosen': 0.43957704305648804, 'epoch': 0.83}


 14%|█▍        | 2240/16104 [10:22:14<64:04:55, 16.64s/it]

 14%|█▍        | 2241/16104 [10:22:34<68:06:28, 17.69s/it]

 14%|█▍        | 2242/16104 [10:22:50<66:10:43, 17.19s/it]

 14%|█▍        | 2243/16104 [10:23:06<64:20:19, 16.71s/it]

 14%|█▍        | 2244/16104 [10:23:17<58:33:44, 15.21s/it]

 14%|█▍        | 2245/16104 [10:23:29<54:10:22, 14.07s/it]

 14%|█▍        | 2246/16104 [10:23:53<65:42:57, 17.07s/it]
[2024-04-06 01:48:07,524] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5213, 'learning_rate': 1.937860244943821e-06, 'rewards/chosen': -0.7270305752754211, 'rewards/rejected': -2.4253759384155273, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6983453035354614, 'policy_logps/rejected': -406.8983154296875, 'policy_logps/chosen': -533.9814453125, 'referece_logps/rejected': -382.6445617675781, 'referece_logps/chosen': -526.7111206054688, 'logits/rejected': 0.7302214503288269, 'logits/chosen': 0.755487322807312, 'epoch': 0.84}
[2024-04-06 01:48:26,373] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2247/16104 [10:24:12<67:45:46, 17.60s/it]


 14%|█▍        | 2249/16104 [10:24:42<61:22:55, 15.95s/it]

 14%|█▍        | 2250/16104 [10:24:59<62:22:53, 16.21s/it]

 14%|█▍        | 2251/16104 [10:25:14<60:57:25, 15.84s/it]

 14%|█▍        | 2252/16104 [10:25:29<59:45:11, 15.53s/it]

 14%|█▍        | 2253/16104 [10:25:47<62:54:31, 16.35s/it]

 14%|█▍        | 2254/16104 [10:26:07<67:26:53, 17.53s/it]
[2024-04-06 01:50:21,793] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2255/16104 [10:26:18<60:11:59, 15.65s/it]
{'loss': 0.5003, 'learning_rate': 1.9372305674952046e-06, 'rewards/chosen': -0.9616573452949524, 'rewards/rejected': -1.8011187314987183, 'rewards/accuracies': 0.375, 'rewards/margins': 0.8394613862037659, 'policy_logps/rejected': -375.6582336425781, 'policy_logps/chosen': -351.2702941894531, 'referece_logps/rejected': -357.6470642089844, 'referece_logps/chosen': -341.6536560058594, 'logits/rejected': -0.8325018882751465, 'logits/chosen': -0.8899446129798889, 'epoch': 0.84}

 14%|█▍        | 2256/16104 [10:26:31<57:01:55, 14.83s/it]


 14%|█▍        | 2258/16104 [10:27:07<61:56:09, 16.10s/it]

 14%|█▍        | 2259/16104 [10:27:27<66:57:42, 17.41s/it]

 14%|█▍        | 2260/16104 [10:27:48<71:09:26, 18.50s/it]
[2024-04-06 01:52:02,957] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2261/16104 [10:28:02<65:39:57, 17.08s/it]
{'loss': 0.547, 'learning_rate': 1.936809076332946e-06, 'rewards/chosen': -1.0862078666687012, 'rewards/rejected': -1.9904762506484985, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9042683243751526, 'policy_logps/rejected': -379.2119140625, 'policy_logps/chosen': -363.5957946777344, 'referece_logps/rejected': -359.3071594238281, 'referece_logps/chosen': -352.73370361328125, 'logits/rejected': -0.673764705657959, 'logits/chosen': -0.6253673434257507, 'epoch': 0.84}


 14%|█▍        | 2263/16104 [10:28:37<67:16:01, 17.50s/it]

 14%|█▍        | 2264/16104 [10:28:58<71:36:36, 18.63s/it]

 14%|█▍        | 2265/16104 [10:29:17<71:35:14, 18.62s/it]
{'loss': 0.3273, 'learning_rate': 1.9365273242749147e-06, 'rewards/chosen': -1.111901044845581, 'rewards/rejected': -2.514965772628784, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4030646085739136, 'policy_logps/rejected': -372.7857666015625, 'policy_logps/chosen': -292.623046875, 'referece_logps/rejected': -347.6361083984375, 'referece_logps/chosen': -281.5040588378906, 'logits/rejected': 0.1232963502407074, 'logits/chosen': 0.06601981073617935, 'epoch': 0.84}


 14%|█▍        | 2267/16104 [10:29:43<59:55:39, 15.59s/it]

 14%|█▍        | 2268/16104 [10:30:05<67:49:11, 17.65s/it]

 14%|█▍        | 2269/16104 [10:30:23<68:31:47, 17.83s/it]

 14%|█▍        | 2270/16104 [10:30:43<71:16:21, 18.55s/it]

 14%|█▍        | 2271/16104 [10:31:03<72:29:03, 18.86s/it]

 14%|█▍        | 2272/16104 [10:31:14<63:43:15, 16.58s/it]

 14%|█▍        | 2273/16104 [10:31:34<67:51:22, 17.66s/it]

 14%|█▍        | 2274/16104 [10:31:55<71:37:43, 18.65s/it]

 14%|█▍        | 2275/16104 [10:32:14<72:07:06, 18.77s/it]

 14%|█▍        | 2276/16104 [10:32:35<74:32:00, 19.40s/it]
{'loss': 0.5366, 'learning_rate': 1.935749381218764e-06, 'rewards/chosen': -1.0475481748580933, 'rewards/rejected': -1.448301076889038, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4007530212402344, 'policy_logps/rejected': -335.9381103515625, 'policy_logps/chosen': -348.6456604003906, 'referece_logps/rejected': -321.455078125, 'referece_logps/chosen': -338.1701965332031, 'logits/rejected': -1.3474092483520508, 'logits/chosen': -1.2429594993591309, 'epoch': 0.85}


 14%|█▍        | 2278/16104 [10:33:13<72:15:44, 18.82s/it]

 14%|█▍        | 2279/16104 [10:33:33<74:16:58, 19.34s/it]

 14%|█▍        | 2280/16104 [10:33:50<71:49:47, 18.71s/it]

 14%|█▍        | 2281/16104 [10:34:02<64:08:01, 16.70s/it]
{'loss': 0.4898, 'learning_rate': 1.9353942564003222e-06, 'rewards/chosen': -1.4204678535461426, 'rewards/rejected': -2.8264994621276855, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4060311317443848, 'policy_logps/rejected': -367.6674499511719, 'policy_logps/chosen': -362.5338439941406, 'referece_logps/rejected': -339.4024658203125, 'referece_logps/chosen': -348.32916259765625, 'logits/rejected': -1.1520183086395264, 'logits/chosen': -1.0903643369674683, 'epoch': 0.85}


 14%|█▍        | 2283/16104 [10:34:41<70:15:25, 18.30s/it]

 14%|█▍        | 2284/16104 [10:34:53<62:10:20, 16.20s/it]

 14%|█▍        | 2285/16104 [10:35:16<69:51:38, 18.20s/it]

 14%|█▍        | 2286/16104 [10:35:31<66:14:42, 17.26s/it]

 14%|█▍        | 2287/16104 [10:35:47<65:34:47, 17.09s/it]

 14%|█▍        | 2288/16104 [10:36:09<70:27:19, 18.36s/it]

 14%|█▍        | 2289/16104 [10:36:23<65:51:00, 17.16s/it]

 14%|█▍        | 2290/16104 [10:36:35<60:23:29, 15.74s/it]
{'loss': 0.5842, 'learning_rate': 1.934752648152156e-06, 'rewards/chosen': -0.917088508605957, 'rewards/rejected': -1.8351523876190186, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9180638790130615, 'policy_logps/rejected': -386.50738525390625, 'policy_logps/chosen': -403.16217041015625, 'referece_logps/rejected': -368.15582275390625, 'referece_logps/chosen': -393.9912414550781, 'logits/rejected': -0.5511606931686401, 'logits/chosen': -0.5485413670539856, 'epoch': 0.85}


 14%|█▍        | 2292/16104 [10:37:14<67:38:28, 17.63s/it]
{'loss': 0.6181, 'learning_rate': 1.9346096525308113e-06, 'rewards/chosen': -0.9340242743492126, 'rewards/rejected': -1.2313063144683838, 'rewards/accuracies': 0.75, 'rewards/margins': 0.29728204011917114, 'policy_logps/rejected': -432.861572265625, 'policy_logps/chosen': -344.1807556152344, 'referece_logps/rejected': -420.5484924316406, 'referece_logps/chosen': -334.8404846191406, 'logits/rejected': -0.12150397151708603, 'logits/chosen': 0.13762520253658295, 'epoch': 0.85}


 14%|█▍        | 2294/16104 [10:37:50<68:53:47, 17.96s/it]

 14%|█▍        | 2295/16104 [10:38:02<61:52:27, 16.13s/it]
{'loss': 0.4524, 'learning_rate': 1.934394875556323e-06, 'rewards/chosen': -0.9551343321800232, 'rewards/rejected': -2.7021968364715576, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7470626831054688, 'policy_logps/rejected': -492.4201965332031, 'policy_logps/chosen': -429.6368713378906, 'referece_logps/rejected': -465.3981628417969, 'referece_logps/chosen': -420.0855407714844, 'logits/rejected': -0.5740187168121338, 'logits/chosen': -0.5897216796875, 'epoch': 0.86}

 14%|█▍        | 2296/16104 [10:38:19<62:58:17, 16.42s/it]


 14%|█▍        | 2298/16104 [10:39:00<71:53:53, 18.75s/it]

 14%|█▍        | 2299/16104 [10:39:18<71:03:07, 18.53s/it]

 14%|█▍        | 2300/16104 [10:39:37<72:11:57, 18.83s/it]
{'loss': 0.4097, 'learning_rate': 1.9340361580120627e-06, 'rewards/chosen': -0.8385744094848633, 'rewards/rejected': -2.0818333625793457, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2432587146759033, 'policy_logps/rejected': -301.12359619140625, 'policy_logps/chosen': -382.304443359375, 'referece_logps/rejected': -280.3052978515625, 'referece_logps/chosen': -373.918701171875, 'logits/rejected': -0.09092094004154205, 'logits/chosen': -0.09455648064613342, 'epoch': 0.86}


 14%|█▍        | 2302/16104 [10:40:10<69:20:39, 18.09s/it]

 14%|█▍        | 2303/16104 [10:40:24<64:01:51, 16.70s/it]

 14%|█▍        | 2304/16104 [10:40:46<70:41:47, 18.44s/it]

 14%|█▍        | 2305/16104 [10:41:00<65:07:08, 16.99s/it]

 14%|█▍        | 2306/16104 [10:41:11<58:58:28, 15.39s/it]

 14%|█▍        | 2307/16104 [10:41:33<66:23:08, 17.32s/it]

 14%|█▍        | 2308/16104 [10:41:53<69:26:42, 18.12s/it]

 14%|█▍        | 2309/16104 [10:42:11<69:13:00, 18.06s/it]

 14%|█▍        | 2310/16104 [10:42:24<62:51:57, 16.41s/it]

 14%|█▍        | 2311/16104 [10:42:44<67:45:24, 17.68s/it]
{'loss': 0.4605, 'learning_rate': 1.933243654985366e-06, 'rewards/chosen': -1.2403910160064697, 'rewards/rejected': -2.5250742435455322, 'rewards/accuracies': 0.75, 'rewards/margins': 1.284683346748352, 'policy_logps/rejected': -419.59161376953125, 'policy_logps/chosen': -376.6020812988281, 'referece_logps/rejected': -394.3408508300781, 'referece_logps/chosen': -364.19818115234375, 'logits/rejected': -0.4286041855812073, 'logits/chosen': -0.36836501955986023, 'epoch': 0.86}


 14%|█▍        | 2313/16104 [10:43:25<73:56:49, 19.30s/it]

 14%|█▍        | 2314/16104 [10:43:37<65:42:25, 17.15s/it]

 14%|█▍        | 2315/16104 [10:43:59<71:08:31, 18.57s/it]

 14%|█▍        | 2316/16104 [10:44:14<66:31:32, 17.37s/it]

 14%|█▍        | 2317/16104 [10:44:33<68:55:04, 18.00s/it]

 14%|█▍        | 2318/16104 [10:44:50<67:44:15, 17.69s/it]

 14%|█▍        | 2319/16104 [10:45:04<63:22:38, 16.55s/it]

 14%|█▍        | 2320/16104 [10:45:20<62:06:34, 16.22s/it]
{'loss': 0.5205, 'learning_rate': 1.9325918456204613e-06, 'rewards/chosen': -1.1272226572036743, 'rewards/rejected': -1.9320034980773926, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8047808408737183, 'policy_logps/rejected': -372.42413330078125, 'policy_logps/chosen': -344.4541931152344, 'referece_logps/rejected': -353.10406494140625, 'referece_logps/chosen': -333.1820373535156, 'logits/rejected': 0.0864250659942627, 'logits/chosen': 0.21561509370803833, 'epoch': 0.86}


 14%|█▍        | 2322/16104 [10:45:54<64:02:01, 16.73s/it]

 14%|█▍        | 2323/16104 [10:46:13<66:44:46, 17.44s/it]

 14%|█▍        | 2324/16104 [10:46:32<68:43:41, 17.96s/it]

 14%|█▍        | 2325/16104 [10:46:54<72:44:35, 19.01s/it]

 14%|█▍        | 2326/16104 [10:47:10<69:04:30, 18.05s/it]

 14%|█▍        | 2327/16104 [10:47:30<72:15:36, 18.88s/it]
{'loss': 0.6282, 'learning_rate': 1.9320827700716866e-06, 'rewards/chosen': -1.0187121629714966, 'rewards/rejected': -1.3282362222671509, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3095240592956543, 'policy_logps/rejected': -387.31829833984375, 'policy_logps/chosen': -506.2203369140625, 'referece_logps/rejected': -374.0359191894531, 'referece_logps/chosen': -496.033203125, 'logits/rejected': -0.42093145847320557, 'logits/chosen': -0.3261750042438507, 'epoch': 0.87}


 14%|█▍        | 2329/16104 [10:48:03<69:30:31, 18.17s/it]

 14%|█▍        | 2330/16104 [10:48:24<72:46:13, 19.02s/it]
{'loss': 0.364, 'learning_rate': 1.9318640292114524e-06, 'rewards/chosen': -1.3040668964385986, 'rewards/rejected': -3.831571102142334, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5275042057037354, 'policy_logps/rejected': -439.1838684082031, 'policy_logps/chosen': -456.6069641113281, 'referece_logps/rejected': -400.86810302734375, 'referece_logps/chosen': -443.56634521484375, 'logits/rejected': -0.11712806671857834, 'logits/chosen': -0.032351117581129074, 'epoch': 0.87}

 14%|█▍        | 2331/16104 [10:48:45<74:44:59, 19.54s/it]

 14%|█▍        | 2332/16104 [10:49:03<73:06:27, 19.11s/it]


 14%|█▍        | 2334/16104 [10:49:40<71:44:04, 18.75s/it]

 14%|█▍        | 2335/16104 [10:49:56<68:42:11, 17.96s/it]

 15%|█▍        | 2336/16104 [10:50:12<65:57:20, 17.25s/it]

 15%|█▍        | 2337/16104 [10:50:24<59:48:39, 15.64s/it]
{'loss': 0.3802, 'learning_rate': 1.931352314664114e-06, 'rewards/chosen': -1.081333041191101, 'rewards/rejected': -1.8626400232315063, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7813069820404053, 'policy_logps/rejected': -305.9660339355469, 'policy_logps/chosen': -359.9810485839844, 'referece_logps/rejected': -287.3396301269531, 'referece_logps/chosen': -349.1676940917969, 'logits/rejected': -0.7745178937911987, 'logits/chosen': -0.6197097301483154, 'epoch': 0.87}

 15%|█▍        | 2338/16104 [10:50:43<64:29:12, 16.86s/it]


 15%|█▍        | 2340/16104 [10:51:08<55:29:36, 14.51s/it]

 15%|█▍        | 2341/16104 [10:51:28<60:51:49, 15.92s/it]
{'loss': 0.5534, 'learning_rate': 1.931059077439287e-06, 'rewards/chosen': -1.2887184619903564, 'rewards/rejected': -1.6341979503631592, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3454795181751251, 'policy_logps/rejected': -381.3016357421875, 'policy_logps/chosen': -444.71026611328125, 'referece_logps/rejected': -364.95965576171875, 'referece_logps/chosen': -431.82305908203125, 'logits/rejected': -1.051409125328064, 'logits/chosen': -1.014168620109558, 'epoch': 0.87}


 15%|█▍        | 2343/16104 [10:52:09<70:22:34, 18.41s/it]

 15%|█▍        | 2344/16104 [10:52:28<71:13:34, 18.63s/it]

 15%|█▍        | 2345/16104 [10:52:46<70:57:11, 18.56s/it]
{'loss': 0.4199, 'learning_rate': 1.930765237606473e-06, 'rewards/chosen': -1.2462745904922485, 'rewards/rejected': -2.4769093990325928, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2306345701217651, 'policy_logps/rejected': -453.44708251953125, 'policy_logps/chosen': -582.7943115234375, 'referece_logps/rejected': -428.6779479980469, 'referece_logps/chosen': -570.3316040039062, 'logits/rejected': 0.2583550214767456, 'logits/chosen': 0.24469956755638123, 'epoch': 0.87}


 15%|█▍        | 2347/16104 [10:53:19<64:37:52, 16.91s/it]

 15%|█▍        | 2348/16104 [10:53:30<58:13:10, 15.24s/it]

 15%|█▍        | 2349/16104 [10:53:51<64:32:26, 16.89s/it]
{'loss': 0.4291, 'learning_rate': 1.9304707953558517e-06, 'rewards/chosen': -1.2743172645568848, 'rewards/rejected': -2.0096805095672607, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7353631854057312, 'policy_logps/rejected': -244.781982421875, 'policy_logps/chosen': -333.0920104980469, 'referece_logps/rejected': -224.6851806640625, 'referece_logps/chosen': -320.3488464355469, 'logits/rejected': -0.8382073640823364, 'logits/chosen': -0.8794889450073242, 'epoch': 0.88}
[2024-04-06 02:18:25,907] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2350/16104 [10:54:11<68:41:52, 17.98s/it]
[2024-04-06 02:18:46,222] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 15%|█▍        | 2352/16104 [10:54:43<62:32:24, 16.37s/it]

 15%|█▍        | 2353/16104 [10:55:04<68:35:15, 17.96s/it]

 15%|█▍        | 2354/16104 [10:55:22<68:33:45, 17.95s/it]

 15%|█▍        | 2355/16104 [10:55:34<61:41:56, 16.16s/it]

 15%|█▍        | 2356/16104 [10:55:50<61:21:29, 16.07s/it]

 15%|█▍        | 2357/16104 [10:56:01<55:09:49, 14.45s/it]

 15%|█▍        | 2358/16104 [10:56:14<54:11:03, 14.19s/it]
{'loss': 0.5889, 'learning_rate': 1.9298060986895814e-06, 'rewards/chosen': -0.7370835542678833, 'rewards/rejected': -1.5405422449111938, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8034585118293762, 'policy_logps/rejected': -696.986328125, 'policy_logps/chosen': -457.01031494140625, 'referece_logps/rejected': -681.580810546875, 'referece_logps/chosen': -449.63946533203125, 'logits/rejected': -0.2117016315460205, 'logits/chosen': 0.0869646668434143, 'epoch': 0.88}

 15%|█▍        | 2359/16104 [10:56:35<62:03:20, 16.25s/it]

 15%|█▍        | 2360/16104 [10:56:54<64:42:24, 16.95s/it]

 15%|█▍        | 2361/16104 [10:57:08<61:06:20, 16.01s/it]

 15%|█▍        | 2362/16104 [10:57:30<68:03:16, 17.83s/it]

 15%|█▍        | 2363/16104 [10:57:44<63:37:06, 16.67s/it]


 15%|█▍        | 2365/16104 [10:58:05<52:02:42, 13.64s/it]
{'loss': 0.6285, 'learning_rate': 1.9292870059925787e-06, 'rewards/chosen': -1.250908374786377, 'rewards/rejected': -1.3814985752105713, 'rewards/accuracies': 0.625, 'rewards/margins': 0.13059020042419434, 'policy_logps/rejected': -379.58984375, 'policy_logps/chosen': -319.501220703125, 'referece_logps/rejected': -365.77484130859375, 'referece_logps/chosen': -306.99212646484375, 'logits/rejected': -1.2962926626205444, 'logits/chosen': -1.2462694644927979, 'epoch': 0.88}


 15%|█▍        | 2367/16104 [10:58:27<46:18:30, 12.14s/it]
{'loss': 0.5105, 'learning_rate': 1.929138355426543e-06, 'rewards/chosen': -1.0404090881347656, 'rewards/rejected': -1.3462915420532227, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3058824837207794, 'policy_logps/rejected': -304.47406005859375, 'policy_logps/chosen': -318.87384033203125, 'referece_logps/rejected': -291.01116943359375, 'referece_logps/chosen': -308.4697265625, 'logits/rejected': -0.07202962040901184, 'logits/chosen': -0.004135042428970337, 'epoch': 0.88}

 15%|█▍        | 2368/16104 [10:58:46<54:10:05, 14.20s/it]


 15%|█▍        | 2370/16104 [10:59:15<55:56:27, 14.66s/it]
{'loss': 0.3337, 'learning_rate': 1.928915097695232e-06, 'rewards/chosen': -0.7917643785476685, 'rewards/rejected': -2.5458824634552, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7541179656982422, 'policy_logps/rejected': -218.2852020263672, 'policy_logps/chosen': -301.0475769042969, 'referece_logps/rejected': -192.8263702392578, 'referece_logps/chosen': -293.12994384765625, 'logits/rejected': 0.21434074640274048, 'logits/chosen': 0.24074798822402954, 'epoch': 0.88}

 15%|█▍        | 2371/16104 [10:59:37<64:06:00, 16.80s/it]


 15%|█▍        | 2373/16104 [11:00:15<68:46:03, 18.03s/it]
{'loss': 0.4942, 'learning_rate': 1.9286915017774693e-06, 'rewards/chosen': -1.0664112567901611, 'rewards/rejected': -2.0224428176879883, 'rewards/accuracies': 0.625, 'rewards/margins': 0.956031858921051, 'policy_logps/rejected': -264.4922790527344, 'policy_logps/chosen': -272.3912658691406, 'referece_logps/rejected': -244.26785278320312, 'referece_logps/chosen': -261.7271423339844, 'logits/rejected': -0.3279707729816437, 'logits/chosen': -0.37804678082466125, 'epoch': 0.88}


 15%|█▍        | 2375/16104 [11:00:39<57:00:48, 14.95s/it]

 15%|█▍        | 2376/16104 [11:00:55<58:19:06, 15.29s/it]

 15%|█▍        | 2377/16104 [11:01:11<59:39:52, 15.65s/it]
{'loss': 0.5056, 'learning_rate': 1.9283928479600225e-06, 'rewards/chosen': -0.5007911324501038, 'rewards/rejected': -1.4951311349868774, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9943399429321289, 'policy_logps/rejected': -471.4803466796875, 'policy_logps/chosen': -369.5943298339844, 'referece_logps/rejected': -456.529052734375, 'referece_logps/chosen': -364.5863952636719, 'logits/rejected': 0.7560389637947083, 'logits/chosen': 0.6923717856407166, 'epoch': 0.89}


 15%|█▍        | 2379/16104 [11:01:49<65:45:03, 17.25s/it]
{'loss': 0.5432, 'learning_rate': 1.92824329570833e-06, 'rewards/chosen': -0.8239998817443848, 'rewards/rejected': -1.51850426197052, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6945043802261353, 'policy_logps/rejected': -477.9440002441406, 'policy_logps/chosen': -459.6429748535156, 'referece_logps/rejected': -462.75897216796875, 'referece_logps/chosen': -451.4029846191406, 'logits/rejected': -0.3254985213279724, 'logits/chosen': -0.2787345051765442, 'epoch': 0.89}

 15%|█▍        | 2380/16104 [11:02:06<65:06:29, 17.08s/it]
[2024-04-06 02:26:40,754] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 15%|█▍        | 2382/16104 [11:02:37<60:28:29, 15.87s/it]
{'loss': 0.4272, 'learning_rate': 1.928018685720129e-06, 'rewards/chosen': -0.8453695178031921, 'rewards/rejected': -1.8093640804290771, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9639944434165955, 'policy_logps/rejected': -370.56817626953125, 'policy_logps/chosen': -469.22930908203125, 'referece_logps/rejected': -352.47454833984375, 'referece_logps/chosen': -460.77557373046875, 'logits/rejected': -0.35953301191329956, 'logits/chosen': -0.3070194721221924, 'epoch': 0.89}

 15%|█▍        | 2383/16104 [11:02:54<61:14:51, 16.07s/it]

 15%|█▍        | 2384/16104 [11:03:04<55:09:47, 14.47s/it]

 15%|█▍        | 2385/16104 [11:03:26<62:53:46, 16.50s/it]


 15%|█▍        | 2387/16104 [11:04:07<71:06:48, 18.66s/it]
{'loss': 0.5221, 'learning_rate': 1.9276435849800147e-06, 'rewards/chosen': -1.2737175226211548, 'rewards/rejected': -1.8741800785064697, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6004625558853149, 'policy_logps/rejected': -274.1704406738281, 'policy_logps/chosen': -317.8811340332031, 'referece_logps/rejected': -255.42868041992188, 'referece_logps/chosen': -305.1439514160156, 'logits/rejected': -0.4955947995185852, 'logits/chosen': -0.5398521423339844, 'epoch': 0.89}


 15%|█▍        | 2389/16104 [11:04:43<69:37:56, 18.28s/it]
[2024-04-06 02:28:57,810] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2390/16104 [11:05:03<71:50:04, 18.86s/it]
{'loss': 0.5713, 'learning_rate': 1.927418074213605e-06, 'rewards/chosen': -0.8590187430381775, 'rewards/rejected': -2.1290366649627686, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2700178623199463, 'policy_logps/rejected': -348.1489562988281, 'policy_logps/chosen': -305.4267272949219, 'referece_logps/rejected': -326.85858154296875, 'referece_logps/chosen': -296.8365173339844, 'logits/rejected': -1.1720836162567139, 'logits/chosen': -1.1250933408737183, 'epoch': 0.89}


 15%|█▍        | 2392/16104 [11:05:32<62:03:59, 16.30s/it]

 15%|█▍        | 2393/16104 [11:05:52<66:17:40, 17.41s/it]
{'loss': 0.5911, 'learning_rate': 1.927192225805759e-06, 'rewards/chosen': -0.8305797576904297, 'rewards/rejected': -1.91532564163208, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0847457647323608, 'policy_logps/rejected': -324.399169921875, 'policy_logps/chosen': -373.6556701660156, 'referece_logps/rejected': -305.24591064453125, 'referece_logps/chosen': -365.3498840332031, 'logits/rejected': -0.2219950556755066, 'logits/chosen': -0.22179147601127625, 'epoch': 0.89}


 15%|█▍        | 2395/16104 [11:06:27<68:14:28, 17.92s/it]
[2024-04-06 02:30:41,986] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2396/16104 [11:06:49<72:41:19, 19.09s/it]
{'loss': 0.474, 'learning_rate': 1.926966039838702e-06, 'rewards/chosen': -1.464161992073059, 'rewards/rejected': -2.4247052669525146, 'rewards/accuracies': 0.75, 'rewards/margins': 0.960543155670166, 'policy_logps/rejected': -392.14532470703125, 'policy_logps/chosen': -384.2186279296875, 'referece_logps/rejected': -367.89825439453125, 'referece_logps/chosen': -369.57696533203125, 'logits/rejected': -0.7370717525482178, 'logits/chosen': -0.6190253496170044, 'epoch': 0.89}

 15%|█▍        | 2397/16104 [11:07:05<68:39:22, 18.03s/it]

 15%|█▍        | 2398/16104 [11:07:24<70:02:08, 18.40s/it]

 15%|█▍        | 2399/16104 [11:07:40<67:50:27, 17.82s/it]

 15%|█▍        | 2400/16104 [11:08:01<70:49:08, 18.60s/it]

 15%|█▍        | 2401/16104 [11:08:21<72:24:59, 19.03s/it]

 15%|█▍        | 2402/16104 [11:08:39<71:13:34, 18.71s/it]

 15%|█▍        | 2403/16104 [11:08:59<72:21:47, 19.01s/it]


 15%|█▍        | 2405/16104 [11:09:32<68:53:35, 18.10s/it]
{'loss': 0.5023, 'learning_rate': 1.9262854574063405e-06, 'rewards/chosen': -0.7583212852478027, 'rewards/rejected': -2.362527370452881, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6042060852050781, 'policy_logps/rejected': -330.847900390625, 'policy_logps/chosen': -419.1681213378906, 'referece_logps/rejected': -307.2226257324219, 'referece_logps/chosen': -411.58489990234375, 'logits/rejected': -0.21086014807224274, 'logits/chosen': -0.24115166068077087, 'epoch': 0.9}


 15%|█▍        | 2407/16104 [11:10:07<67:11:22, 17.66s/it]

 15%|█▍        | 2408/16104 [11:10:18<59:02:28, 15.52s/it]

 15%|█▍        | 2409/16104 [11:10:34<59:35:07, 15.66s/it]
{'loss': 0.4471, 'learning_rate': 1.925982001975244e-06, 'rewards/chosen': -1.2916303873062134, 'rewards/rejected': -2.5398430824279785, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2482126951217651, 'policy_logps/rejected': -296.50726318359375, 'policy_logps/chosen': -465.3489990234375, 'referece_logps/rejected': -271.1088562011719, 'referece_logps/chosen': -452.43267822265625, 'logits/rejected': 0.07192675769329071, 'logits/chosen': 0.09479258954524994, 'epoch': 0.9}

 15%|█▍        | 2410/16104 [11:10:50<60:35:10, 15.93s/it]

 15%|█▍        | 2411/16104 [11:11:09<63:38:56, 16.73s/it]


 15%|█▍        | 2413/16104 [11:11:48<69:03:18, 18.16s/it]

 15%|█▍        | 2414/16104 [11:12:04<66:50:24, 17.58s/it]
{'loss': 0.4888, 'learning_rate': 1.9256018399129213e-06, 'rewards/chosen': -0.6189631819725037, 'rewards/rejected': -1.782364845275879, 'rewards/accuracies': 0.875, 'rewards/margins': 1.16340172290802, 'policy_logps/rejected': -469.0234375, 'policy_logps/chosen': -642.14404296875, 'referece_logps/rejected': -451.19976806640625, 'referece_logps/chosen': -635.9544677734375, 'logits/rejected': -0.5108920335769653, 'logits/chosen': -0.5817372798919678, 'epoch': 0.9}

 15%|█▍        | 2415/16104 [11:12:14<58:55:58, 15.50s/it]

 15%|█▌        | 2416/16104 [11:12:34<63:41:13, 16.75s/it]

 15%|█▌        | 2417/16104 [11:12:54<67:36:44, 17.78s/it]

 15%|█▌        | 2418/16104 [11:13:15<70:51:54, 18.64s/it]

 15%|█▌        | 2419/16104 [11:13:32<69:33:08, 18.30s/it]

 15%|█▌        | 2420/16104 [11:13:55<73:55:23, 19.45s/it]

 15%|█▌        | 2421/16104 [11:14:08<67:25:26, 17.74s/it]

 15%|█▌        | 2422/16104 [11:14:27<68:32:50, 18.04s/it]

 15%|█▌        | 2423/16104 [11:14:39<61:28:37, 16.18s/it]

 15%|█▌        | 2424/16104 [11:14:55<60:50:37, 16.01s/it]


 15%|█▌        | 2426/16104 [11:15:22<55:57:36, 14.73s/it]
{'loss': 0.4519, 'learning_rate': 1.9246856325885337e-06, 'rewards/chosen': -1.6009327173233032, 'rewards/rejected': -2.2941582202911377, 'rewards/accuracies': 0.375, 'rewards/margins': 0.6932255029678345, 'policy_logps/rejected': -388.81103515625, 'policy_logps/chosen': -383.44903564453125, 'referece_logps/rejected': -365.8694763183594, 'referece_logps/chosen': -367.439697265625, 'logits/rejected': -0.7847201824188232, 'logits/chosen': -0.82062166929245, 'epoch': 0.9}

 15%|█▌        | 2427/16104 [11:15:39<58:17:15, 15.34s/it]


 15%|█▌        | 2429/16104 [11:16:06<54:32:40, 14.36s/it]
{'loss': 0.538, 'learning_rate': 1.92445573893204e-06, 'rewards/chosen': -0.9332656860351562, 'rewards/rejected': -1.5654380321502686, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6321724057197571, 'policy_logps/rejected': -303.82598876953125, 'policy_logps/chosen': -383.4556884765625, 'referece_logps/rejected': -288.1716003417969, 'referece_logps/chosen': -374.123046875, 'logits/rejected': -0.8911137580871582, 'logits/chosen': -0.7440773844718933, 'epoch': 0.9}

 15%|█▌        | 2430/16104 [11:16:28<62:33:15, 16.47s/it]


 15%|█▌        | 2432/16104 [11:17:04<67:15:53, 17.71s/it]

 15%|█▌        | 2433/16104 [11:17:18<62:51:33, 16.55s/it]

 15%|█▌        | 2434/16104 [11:17:38<66:28:33, 17.51s/it]

 15%|█▌        | 2435/16104 [11:17:54<64:37:52, 17.02s/it]
{'loss': 0.5398, 'learning_rate': 1.923994942014021e-06, 'rewards/chosen': -1.049480676651001, 'rewards/rejected': -1.1857928037643433, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13631200790405273, 'policy_logps/rejected': -375.2475280761719, 'policy_logps/chosen': -412.6730041503906, 'referece_logps/rejected': -363.3896179199219, 'referece_logps/chosen': -402.17816162109375, 'logits/rejected': 0.3370424807071686, 'logits/chosen': 0.40109288692474365, 'epoch': 0.91}

 15%|█▌        | 2436/16104 [11:18:11<65:22:12, 17.22s/it]

 15%|█▌        | 2437/16104 [11:18:31<67:32:24, 17.79s/it]

 15%|█▌        | 2438/16104 [11:18:53<72:48:15, 19.18s/it]

 15%|█▌        | 2439/16104 [11:19:12<72:15:51, 19.04s/it]

 15%|█▌        | 2440/16104 [11:19:34<75:47:08, 19.97s/it]

 15%|█▌        | 2441/16104 [11:19:56<77:42:19, 20.47s/it]
[2024-04-06 02:44:33,437] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2442/16104 [11:20:19<80:54:08, 21.32s/it]

 15%|█▌        | 2443/16104 [11:20:33<73:11:21, 19.29s/it]


 15%|█▌        | 2445/16104 [11:21:08<69:23:23, 18.29s/it]

 15%|█▌        | 2446/16104 [11:21:20<62:01:05, 16.35s/it]

 15%|█▌        | 2447/16104 [11:21:38<63:49:57, 16.83s/it]

 15%|█▌        | 2448/16104 [11:21:58<67:43:24, 17.85s/it]
[2024-04-06 02:46:13,017] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4472, 'learning_rate': 1.922991933500489e-06, 'rewards/chosen': -0.6589841842651367, 'rewards/rejected': -1.8593116998672485, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2003275156021118, 'policy_logps/rejected': -348.0238952636719, 'policy_logps/chosen': -400.19287109375, 'referece_logps/rejected': -329.4308166503906, 'referece_logps/chosen': -393.60302734375, 'logits/rejected': 0.4049844443798065, 'logits/chosen': 0.5110571384429932, 'epoch': 0.91}
[2024-04-06 02:46:33,680] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2449/16104 [11:22:19<70:54:56, 18.70s/it]

 15%|█▌        | 2450/16104 [11:22:37<70:23:19, 18.56s/it]


 15%|█▌        | 2452/16104 [11:23:14<70:25:12, 18.57s/it]
{'loss': 0.4965, 'learning_rate': 1.922682045730736e-06, 'rewards/chosen': -1.2128835916519165, 'rewards/rejected': -1.7947496175765991, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5818660259246826, 'policy_logps/rejected': -323.87921142578125, 'policy_logps/chosen': -385.0586853027344, 'referece_logps/rejected': -305.93170166015625, 'referece_logps/chosen': -372.92987060546875, 'logits/rejected': 1.1629849672317505, 'logits/chosen': 1.1789987087249756, 'epoch': 0.91}

 15%|█▌        | 2453/16104 [11:23:33<70:18:01, 18.54s/it]


 15%|█▌        | 2455/16104 [11:24:01<61:31:08, 16.23s/it]
{'loss': 0.5527, 'learning_rate': 1.922449237989038e-06, 'rewards/chosen': -1.1759458780288696, 'rewards/rejected': -1.9571762084960938, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7812304496765137, 'policy_logps/rejected': -379.103271484375, 'policy_logps/chosen': -304.860595703125, 'referece_logps/rejected': -359.5315246582031, 'referece_logps/chosen': -293.10113525390625, 'logits/rejected': -1.218259334564209, 'logits/chosen': -1.0685310363769531, 'epoch': 0.91}

 15%|█▌        | 2456/16104 [11:24:12<56:02:41, 14.78s/it]


 15%|█▌        | 2458/16104 [11:24:43<56:20:46, 14.86s/it]

 15%|█▌        | 2459/16104 [11:25:05<64:33:09, 17.03s/it]
{'loss': 0.4034, 'learning_rate': 1.9221383052754057e-06, 'rewards/chosen': -1.4196196794509888, 'rewards/rejected': -3.440082311630249, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0204625129699707, 'policy_logps/rejected': -524.3052978515625, 'policy_logps/chosen': -341.3313903808594, 'referece_logps/rejected': -489.9044494628906, 'referece_logps/chosen': -327.1352233886719, 'logits/rejected': -1.5427274703979492, 'logits/chosen': -1.1825308799743652, 'epoch': 0.92}


 15%|█▌        | 2461/16104 [11:25:37<63:24:35, 16.73s/it]
{'loss': 0.5106, 'learning_rate': 1.9219826150931682e-06, 'rewards/chosen': -1.4280717372894287, 'rewards/rejected': -1.974585771560669, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5465141534805298, 'policy_logps/rejected': -355.4039306640625, 'policy_logps/chosen': -393.5570373535156, 'referece_logps/rejected': -335.6580810546875, 'referece_logps/chosen': -379.27630615234375, 'logits/rejected': -0.03605866804718971, 'logits/chosen': 0.01277686282992363, 'epoch': 0.92}

 15%|█▌        | 2462/16104 [11:25:59<69:52:23, 18.44s/it]

 15%|█▌        | 2463/16104 [11:26:18<70:42:58, 18.66s/it]


 15%|█▌        | 2465/16104 [11:26:51<64:58:12, 17.15s/it]

 15%|█▌        | 2466/16104 [11:27:07<63:28:25, 16.76s/it]

 15%|█▌        | 2467/16104 [11:27:21<60:35:46, 16.00s/it]
{'loss': 0.4509, 'learning_rate': 1.9215146495471433e-06, 'rewards/chosen': -0.8998569846153259, 'rewards/rejected': -2.0837321281433105, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1838752031326294, 'policy_logps/rejected': -307.4067687988281, 'policy_logps/chosen': -268.5145263671875, 'referece_logps/rejected': -286.5694580078125, 'referece_logps/chosen': -259.51593017578125, 'logits/rejected': 0.03147830069065094, 'logits/chosen': 0.2620953917503357, 'epoch': 0.92}

 15%|█▌        | 2468/16104 [11:27:32<54:33:56, 14.41s/it]

 15%|█▌        | 2469/16104 [11:27:46<54:20:57, 14.35s/it]


 15%|█▌        | 2471/16104 [11:28:15<54:06:29, 14.29s/it]

 15%|█▌        | 2472/16104 [11:28:27<52:04:30, 13.75s/it]
{'loss': 0.4636, 'learning_rate': 1.92112365311485e-06, 'rewards/chosen': -1.1661083698272705, 'rewards/rejected': -2.1469459533691406, 'rewards/accuracies': 0.625, 'rewards/margins': 0.980837345123291, 'policy_logps/rejected': -446.0831604003906, 'policy_logps/chosen': -428.87359619140625, 'referece_logps/rejected': -424.61370849609375, 'referece_logps/chosen': -417.2124938964844, 'logits/rejected': -0.39054203033447266, 'logits/chosen': -0.5889936685562134, 'epoch': 0.92}


 15%|█▌        | 2474/16104 [11:28:49<46:16:22, 12.22s/it]
{'loss': 0.5241, 'learning_rate': 1.9209669936921105e-06, 'rewards/chosen': -1.0297759771347046, 'rewards/rejected': -2.5543150901794434, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5245388746261597, 'policy_logps/rejected': -342.761962890625, 'policy_logps/chosen': -392.6396179199219, 'referece_logps/rejected': -317.21881103515625, 'referece_logps/chosen': -382.3419189453125, 'logits/rejected': 0.4290660321712494, 'logits/chosen': 0.5202410221099854, 'epoch': 0.92}

 15%|█▌        | 2475/16104 [11:28:59<44:38:01, 11.79s/it]


 15%|█▌        | 2477/16104 [11:29:23<45:18:59, 11.97s/it]
{'loss': 0.5032, 'learning_rate': 1.9207317251552445e-06, 'rewards/chosen': -0.7923647165298462, 'rewards/rejected': -2.3822433948516846, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5898785591125488, 'policy_logps/rejected': -294.3316955566406, 'policy_logps/chosen': -380.973876953125, 'referece_logps/rejected': -270.50927734375, 'referece_logps/chosen': -373.0502014160156, 'logits/rejected': -0.07209095358848572, 'logits/chosen': -0.017973128706216812, 'epoch': 0.92}

 15%|█▌        | 2478/16104 [11:29:45<55:55:46, 14.78s/it]

 15%|█▌        | 2479/16104 [11:30:06<63:22:51, 16.75s/it]

 15%|█▌        | 2480/16104 [11:30:25<65:37:03, 17.34s/it]

 15%|█▌        | 2481/16104 [11:30:42<66:13:46, 17.50s/it]

 15%|█▌        | 2482/16104 [11:31:00<65:48:53, 17.39s/it]

 15%|█▌        | 2483/16104 [11:31:13<60:47:48, 16.07s/it]

 15%|█▌        | 2484/16104 [11:31:25<56:17:38, 14.88s/it]


 15%|█▌        | 2486/16104 [11:31:55<55:34:11, 14.69s/it]
{'loss': 0.3869, 'learning_rate': 1.920023908644893e-06, 'rewards/chosen': -1.3340224027633667, 'rewards/rejected': -2.8229873180389404, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4889652729034424, 'policy_logps/rejected': -287.8837585449219, 'policy_logps/chosen': -529.8104248046875, 'referece_logps/rejected': -259.65386962890625, 'referece_logps/chosen': -516.47021484375, 'logits/rejected': -1.1752418279647827, 'logits/chosen': -1.2021403312683105, 'epoch': 0.93}

 15%|█▌        | 2487/16104 [11:32:07<51:46:19, 13.69s/it]
[2024-04-06 02:56:40,609] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2488/16104 [11:32:26<58:10:28, 15.38s/it]

 15%|█▌        | 2489/16104 [11:32:40<56:56:09, 15.05s/it]

 15%|█▌        | 2490/16104 [11:33:01<63:09:32, 16.70s/it]

 15%|█▌        | 2491/16104 [11:33:14<58:41:29, 15.52s/it]

 15%|█▌        | 2492/16104 [11:33:33<62:37:37, 16.56s/it]

 15%|█▌        | 2493/16104 [11:33:52<66:20:15, 17.55s/it]

 15%|█▌        | 2494/16104 [11:34:09<65:20:16, 17.28s/it]

 15%|█▌        | 2495/16104 [11:34:20<58:17:46, 15.42s/it]

 15%|█▌        | 2496/16104 [11:34:40<63:35:37, 16.82s/it]

 16%|█▌        | 2497/16104 [11:34:57<63:14:59, 16.73s/it]

 16%|█▌        | 2498/16104 [11:35:08<56:34:52, 14.97s/it]

 16%|█▌        | 2499/16104 [11:35:28<62:43:18, 16.60s/it]

 16%|█▌        | 2500/16104 [11:35:39<56:14:31, 14.88s/it]

 16%|█▌        | 2501/16104 [11:36:11<76:00:12, 20.11s/it]

 16%|█▌        | 2502/16104 [11:36:34<78:58:32, 20.90s/it]

 16%|█▌        | 2503/16104 [11:36:56<80:40:19, 21.35s/it]

 16%|█▌        | 2504/16104 [11:37:14<76:18:54, 20.20s/it]

 16%|█▌        | 2505/16104 [11:37:31<73:07:34, 19.36s/it]

 16%|█▌        | 2506/16104 [11:37:52<74:36:02, 19.75s/it]

 16%|█▌        | 2507/16104 [11:38:11<74:15:42, 19.66s/it]


 16%|█▌        | 2509/16104 [11:38:38<60:53:11, 16.12s/it]
{'loss': 0.5101, 'learning_rate': 1.918201354011167e-06, 'rewards/chosen': -1.5654715299606323, 'rewards/rejected': -2.4181013107299805, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8526297211647034, 'policy_logps/rejected': -413.310546875, 'policy_logps/chosen': -311.7061462402344, 'referece_logps/rejected': -389.1295166015625, 'referece_logps/chosen': -296.0513916015625, 'logits/rejected': -0.9336596727371216, 'logits/chosen': -0.7412891387939453, 'epoch': 0.93}

 16%|█▌        | 2510/16104 [11:38:59<67:12:01, 17.80s/it]

 16%|█▌        | 2511/16104 [11:39:21<71:32:41, 18.95s/it]

 16%|█▌        | 2512/16104 [11:39:39<70:01:52, 18.55s/it]

 16%|█▌        | 2513/16104 [11:39:59<71:31:05, 18.94s/it]

 16%|█▌        | 2514/16104 [11:40:15<68:32:16, 18.16s/it]

 16%|█▌        | 2515/16104 [11:40:32<67:54:37, 17.99s/it]

 16%|█▌        | 2516/16104 [11:40:49<65:47:26, 17.43s/it]

 16%|█▌        | 2517/16104 [11:41:09<68:47:42, 18.23s/it]

 16%|█▌        | 2518/16104 [11:41:29<71:16:52, 18.89s/it]

 16%|█▌        | 2519/16104 [11:41:51<75:07:44, 19.91s/it]

 16%|█▌        | 2520/16104 [11:42:09<72:28:35, 19.21s/it]

 16%|█▌        | 2521/16104 [11:42:21<64:18:21, 17.04s/it]

 16%|█▌        | 2522/16104 [11:42:32<57:00:42, 15.11s/it]

 16%|█▌        | 2523/16104 [11:42:43<52:25:39, 13.90s/it]

 16%|█▌        | 2524/16104 [11:42:56<52:07:28, 13.82s/it]

 16%|█▌        | 2525/16104 [11:43:08<49:51:11, 13.22s/it]

 16%|█▌        | 2526/16104 [11:43:19<47:44:18, 12.66s/it]

 16%|█▌        | 2527/16104 [11:43:30<45:28:26, 12.06s/it]

 16%|█▌        | 2528/16104 [11:43:41<44:36:04, 11.83s/it]
[2024-04-06 03:08:17,772] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2529/16104 [11:44:03<55:48:44, 14.80s/it]

 16%|█▌        | 2530/16104 [11:44:24<62:17:10, 16.52s/it]

 16%|█▌        | 2531/16104 [11:44:41<63:19:21, 16.80s/it]

 16%|█▌        | 2532/16104 [11:45:00<65:58:05, 17.50s/it]

 16%|█▌        | 2533/16104 [11:45:18<66:15:10, 17.57s/it]

 16%|█▌        | 2534/16104 [11:45:29<58:40:35, 15.57s/it]

 16%|█▌        | 2535/16104 [11:45:47<61:43:53, 16.38s/it]

 16%|█▌        | 2536/16104 [11:45:59<56:53:13, 15.09s/it]

 16%|█▌        | 2537/16104 [11:46:12<53:44:43, 14.26s/it]

 16%|█▌        | 2538/16104 [11:46:28<55:52:34, 14.83s/it]

 16%|█▌        | 2539/16104 [11:46:47<60:45:51, 16.13s/it]

 16%|█▌        | 2540/16104 [11:46:58<54:45:24, 14.53s/it]

 16%|█▌        | 2541/16104 [11:47:08<50:23:12, 13.37s/it]

 16%|█▌        | 2542/16104 [11:47:24<52:27:33, 13.93s/it]

 16%|█▌        | 2543/16104 [11:47:39<54:18:12, 14.42s/it]

 16%|█▌        | 2544/16104 [11:47:58<59:51:58, 15.89s/it]

 16%|█▌        | 2545/16104 [11:48:21<67:22:43, 17.89s/it]

 16%|█▌        | 2546/16104 [11:48:41<69:40:14, 18.50s/it]
[2024-04-06 03:13:17,678] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2547/16104 [11:49:03<73:44:09, 19.58s/it]

 16%|█▌        | 2548/16104 [11:49:19<70:02:03, 18.60s/it]

 16%|█▌        | 2549/16104 [11:49:39<71:18:15, 18.94s/it]

 16%|█▌        | 2550/16104 [11:49:51<63:11:58, 16.79s/it]

 16%|█▌        | 2551/16104 [11:50:06<60:53:50, 16.18s/it]

 16%|█▌        | 2552/16104 [11:50:25<64:53:29, 17.24s/it]

 16%|█▌        | 2553/16104 [11:50:46<68:35:22, 18.22s/it]

 16%|█▌        | 2554/16104 [11:51:07<71:57:57, 19.12s/it]

 16%|█▌        | 2555/16104 [11:51:30<75:46:05, 20.13s/it]

 16%|█▌        | 2556/16104 [11:51:49<74:54:02, 19.90s/it]
[2024-04-06 03:16:15,139] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▌        | 2558/16104 [11:52:11<57:14:54, 15.21s/it]
{'loss': 0.5309, 'learning_rate': 1.9142530498472653e-06, 'rewards/chosen': -1.2174502611160278, 'rewards/rejected': -1.591784119606018, 'rewards/accuracies': 0.5, 'rewards/margins': 0.37433376908302307, 'policy_logps/rejected': -385.6164245605469, 'policy_logps/chosen': -442.56854248046875, 'referece_logps/rejected': -369.6985778808594, 'referece_logps/chosen': -430.3940734863281, 'logits/rejected': -1.5719915628433228, 'logits/chosen': -1.3643712997436523, 'epoch': 0.95}

 16%|█▌        | 2559/16104 [11:52:21<52:11:51, 13.87s/it]

 16%|█▌        | 2560/16104 [11:52:33<49:45:08, 13.22s/it]

 16%|█▌        | 2561/16104 [11:52:52<56:34:37, 15.04s/it]


 16%|█▌        | 2563/16104 [11:53:31<64:11:03, 17.06s/it]
{'loss': 0.4146, 'learning_rate': 1.9138451624499006e-06, 'rewards/chosen': -0.9190822839736938, 'rewards/rejected': -2.0957133769989014, 'rewards/accuracies': 0.625, 'rewards/margins': 1.176631212234497, 'policy_logps/rejected': -421.84466552734375, 'policy_logps/chosen': -293.9649658203125, 'referece_logps/rejected': -400.8875427246094, 'referece_logps/chosen': -284.7741394042969, 'logits/rejected': -0.8916928768157959, 'logits/chosen': -0.6981534957885742, 'epoch': 0.95}

 16%|█▌        | 2564/16104 [11:53:45<60:32:41, 16.10s/it]

 16%|█▌        | 2565/16104 [11:54:00<59:50:35, 15.91s/it]

 16%|█▌        | 2566/16104 [11:54:20<64:38:52, 17.19s/it]

 16%|█▌        | 2567/16104 [11:54:39<66:58:39, 17.81s/it]

 16%|█▌        | 2568/16104 [11:55:01<71:01:45, 18.89s/it]

 16%|█▌        | 2569/16104 [11:55:12<62:08:07, 16.53s/it]

 16%|█▌        | 2570/16104 [11:55:27<60:56:17, 16.21s/it]

 16%|█▌        | 2571/16104 [11:55:43<59:45:16, 15.90s/it]

 16%|█▌        | 2572/16104 [11:55:55<56:21:01, 14.99s/it]

 16%|█▌        | 2573/16104 [11:56:15<61:42:20, 16.42s/it]

 16%|█▌        | 2574/16104 [11:56:32<61:45:37, 16.43s/it]

 16%|█▌        | 2575/16104 [11:56:50<63:27:17, 16.89s/it]

 16%|█▌        | 2576/16104 [11:57:11<68:57:19, 18.35s/it]

 16%|█▌        | 2577/16104 [11:57:31<70:32:09, 18.77s/it]

 16%|█▌        | 2578/16104 [11:57:47<67:48:21, 18.05s/it]

 16%|█▌        | 2579/16104 [11:58:07<69:45:15, 18.57s/it]

 16%|█▌        | 2580/16104 [11:58:27<70:36:45, 18.80s/it]

 16%|█▌        | 2581/16104 [11:58:43<67:35:44, 17.99s/it]

 16%|█▌        | 2582/16104 [11:58:56<62:41:40, 16.69s/it]

 16%|█▌        | 2583/16104 [11:59:19<68:54:47, 18.35s/it]

 16%|█▌        | 2584/16104 [11:59:37<68:57:53, 18.36s/it]

 16%|█▌        | 2585/16104 [11:59:58<71:41:25, 19.09s/it]

 16%|█▌        | 2586/16104 [12:00:17<72:08:57, 19.21s/it]

 16%|█▌        | 2587/16104 [12:00:40<75:44:12, 20.17s/it]
[2024-04-06 03:25:15,849] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2588/16104 [12:01:01<77:18:49, 20.59s/it]
[2024-04-06 03:25:30,640] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2589/16104 [12:01:16<70:46:23, 18.85s/it]
[2024-04-06 03:25:51,355] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2590/16104 [12:01:37<72:52:00, 19.41s/it]

 16%|█▌        | 2591/16104 [12:01:49<64:41:25, 17.23s/it]

 16%|█▌        | 2592/16104 [12:02:07<65:42:21, 17.51s/it]


 16%|█▌        | 2594/16104 [12:02:48<72:04:02, 19.20s/it]

 16%|█▌        | 2595/16104 [12:03:05<69:24:09, 18.50s/it]

 16%|█▌        | 2596/16104 [12:03:22<67:56:28, 18.11s/it]

 16%|█▌        | 2597/16104 [12:03:37<64:53:13, 17.29s/it]

 16%|█▌        | 2598/16104 [12:03:51<61:11:13, 16.31s/it]
{'loss': 0.5552, 'learning_rate': 1.9109640972205298e-06, 'rewards/chosen': -1.0470942258834839, 'rewards/rejected': -1.7367132902145386, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6896190643310547, 'policy_logps/rejected': -308.26409912109375, 'policy_logps/chosen': -264.9673156738281, 'referece_logps/rejected': -290.89697265625, 'referece_logps/chosen': -254.4963836669922, 'logits/rejected': -0.48389583826065063, 'logits/chosen': -0.4201139211654663, 'epoch': 0.97}


 16%|█▌        | 2600/16104 [12:04:21<59:17:42, 15.81s/it]
{'loss': 0.5164, 'learning_rate': 1.910798100106599e-06, 'rewards/chosen': -1.3623578548431396, 'rewards/rejected': -1.773338794708252, 'rewards/accuracies': 0.75, 'rewards/margins': 0.41098102927207947, 'policy_logps/rejected': -343.67803955078125, 'policy_logps/chosen': -464.840087890625, 'referece_logps/rejected': -325.94464111328125, 'referece_logps/chosen': -451.21649169921875, 'logits/rejected': -0.5651218891143799, 'logits/chosen': -0.5104414224624634, 'epoch': 0.97}


 16%|█▌        | 2602/16104 [12:04:59<65:38:28, 17.50s/it]

 16%|█▌        | 2603/16104 [12:05:16<66:00:49, 17.60s/it]

 16%|█▌        | 2604/16104 [12:05:38<70:30:19, 18.80s/it]

 16%|█▌        | 2605/16104 [12:05:59<73:20:12, 19.56s/it]
[2024-04-06 03:30:14,032] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2606/16104 [12:06:20<74:40:51, 19.92s/it]
[2024-04-06 03:30:34,791] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2607/16104 [12:06:40<74:55:14, 19.98s/it]

 16%|█▌        | 2608/16104 [12:07:01<75:54:34, 20.25s/it]

 16%|█▌        | 2609/16104 [12:07:16<70:23:12, 18.78s/it]

 16%|█▌        | 2610/16104 [12:07:35<70:05:59, 18.70s/it]

 16%|█▌        | 2611/16104 [12:07:51<66:38:53, 17.78s/it]

 16%|█▌        | 2612/16104 [12:08:04<61:50:01, 16.50s/it]
{'loss': 0.5906, 'learning_rate': 1.9097990235184903e-06, 'rewards/chosen': -0.704598069190979, 'rewards/rejected': -1.4740995168685913, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7695014476776123, 'policy_logps/rejected': -319.79425048828125, 'policy_logps/chosen': -362.9471130371094, 'referece_logps/rejected': -305.0532531738281, 'referece_logps/chosen': -355.901123046875, 'logits/rejected': 0.5496088862419128, 'logits/chosen': 0.5626766085624695, 'epoch': 0.97}


 16%|█▌        | 2614/16104 [12:08:36<59:06:14, 15.77s/it]

 16%|█▌        | 2615/16104 [12:08:53<61:08:21, 16.32s/it]

 16%|█▌        | 2616/16104 [12:09:09<60:40:06, 16.19s/it]

 16%|█▋        | 2617/16104 [12:09:29<64:24:33, 17.19s/it]

 16%|█▋        | 2618/16104 [12:09:46<64:10:35, 17.13s/it]
{'loss': 0.4583, 'learning_rate': 1.90929749749878e-06, 'rewards/chosen': -0.5101940035820007, 'rewards/rejected': -1.773403286933899, 'rewards/accuracies': 0.75, 'rewards/margins': 1.263209342956543, 'policy_logps/rejected': -480.7809143066406, 'policy_logps/chosen': -510.79217529296875, 'referece_logps/rejected': -463.046875, 'referece_logps/chosen': -505.6902770996094, 'logits/rejected': 0.043579280376434326, 'logits/chosen': 0.09358525276184082, 'epoch': 0.98}

 16%|█▋        | 2619/16104 [12:10:00<60:59:41, 16.28s/it]


 16%|█▋        | 2621/16104 [12:10:36<63:52:47, 17.06s/it]
{'loss': 0.5524, 'learning_rate': 1.9090462378767246e-06, 'rewards/chosen': -1.290813684463501, 'rewards/rejected': -1.6955740451812744, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4047603905200958, 'policy_logps/rejected': -303.5820007324219, 'policy_logps/chosen': -341.6773681640625, 'referece_logps/rejected': -286.6262512207031, 'referece_logps/chosen': -328.7692565917969, 'logits/rejected': -0.7034646272659302, 'logits/chosen': -0.6825600862503052, 'epoch': 0.98}


 16%|█▋        | 2623/16104 [12:11:13<68:07:36, 18.19s/it]
[2024-04-06 03:35:27,963] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5425, 'learning_rate': 1.908878547593662e-06, 'rewards/chosen': -0.6717975735664368, 'rewards/rejected': -1.386025309562683, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7142277359962463, 'policy_logps/rejected': -361.5931091308594, 'policy_logps/chosen': -262.9670104980469, 'referece_logps/rejected': -347.73284912109375, 'referece_logps/chosen': -256.2490234375, 'logits/rejected': 1.0282258987426758, 'logits/chosen': 0.8412895202636719, 'epoch': 0.98}
[2024-04-06 03:35:46,571] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▋        | 2625/16104 [12:11:44<61:05:18, 16.32s/it]

 16%|█▋        | 2626/16104 [12:12:03<64:51:15, 17.32s/it]

 16%|█▋        | 2627/16104 [12:12:19<63:12:06, 16.88s/it]

 16%|█▋        | 2628/16104 [12:12:39<66:33:15, 17.78s/it]

 16%|█▋        | 2629/16104 [12:12:50<58:45:05, 15.70s/it]

 16%|█▋        | 2630/16104 [12:13:05<57:45:27, 15.43s/it]

 16%|█▋        | 2631/16104 [12:13:19<56:45:53, 15.17s/it]
{'loss': 0.512, 'learning_rate': 1.908206316102752e-06, 'rewards/chosen': -0.9158336520195007, 'rewards/rejected': -2.6052603721618652, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6894267797470093, 'policy_logps/rejected': -363.562744140625, 'policy_logps/chosen': -340.22052001953125, 'referece_logps/rejected': -337.5101623535156, 'referece_logps/chosen': -331.06219482421875, 'logits/rejected': -0.5832061767578125, 'logits/chosen': -0.46855464577674866, 'epoch': 0.98}
[2024-04-06 03:37:52,813] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2632/16104 [12:13:38<61:03:30, 16.32s/it]


 16%|█▋        | 2634/16104 [12:14:14<63:12:52, 16.89s/it]

 16%|█▋        | 2635/16104 [12:14:26<57:19:44, 15.32s/it]

 16%|█▋        | 2636/16104 [12:14:45<61:28:32, 16.43s/it]
{'loss': 0.4769, 'learning_rate': 1.9077849773070615e-06, 'rewards/chosen': -0.7550156116485596, 'rewards/rejected': -1.1573827266693115, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4023672342300415, 'policy_logps/rejected': -424.10736083984375, 'policy_logps/chosen': -336.81683349609375, 'referece_logps/rejected': -412.53350830078125, 'referece_logps/chosen': -329.2666931152344, 'logits/rejected': -0.017862237989902496, 'logits/chosen': -0.0843174159526825, 'epoch': 0.98}


 16%|█▋        | 2638/16104 [12:15:21<64:36:51, 17.27s/it]

 16%|█▋        | 2639/16104 [12:15:36<62:32:08, 16.72s/it]
{'loss': 0.4975, 'learning_rate': 1.9075317333441065e-06, 'rewards/chosen': -0.9927728176116943, 'rewards/rejected': -1.6822662353515625, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6894935369491577, 'policy_logps/rejected': -501.39508056640625, 'policy_logps/chosen': -446.72265625, 'referece_logps/rejected': -484.57244873046875, 'referece_logps/chosen': -436.794921875, 'logits/rejected': -1.8386173248291016, 'logits/chosen': -1.674065351486206, 'epoch': 0.98}


 16%|█▋        | 2641/16104 [12:16:10<64:15:48, 17.18s/it]

 16%|█▋        | 2642/16104 [12:16:31<69:04:18, 18.47s/it]

 16%|█▋        | 2643/16104 [12:16:44<62:20:13, 16.67s/it]

 16%|█▋        | 2644/16104 [12:17:01<62:46:27, 16.79s/it]

 16%|█▋        | 2645/16104 [12:17:11<55:57:44, 14.97s/it]

 16%|█▋        | 2646/16104 [12:17:22<50:59:19, 13.64s/it]
{'loss': 0.5914, 'learning_rate': 1.9069395460287589e-06, 'rewards/chosen': -0.7473827600479126, 'rewards/rejected': -1.681064486503601, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9336816668510437, 'policy_logps/rejected': -371.22418212890625, 'policy_logps/chosen': -488.5626525878906, 'referece_logps/rejected': -354.41357421875, 'referece_logps/chosen': -481.0888671875, 'logits/rejected': -0.8567120432853699, 'logits/chosen': -0.6797176599502563, 'epoch': 0.99}


 16%|█▋        | 2648/16104 [12:17:43<45:14:04, 12.10s/it]

 16%|█▋        | 2649/16104 [12:18:01<51:56:33, 13.90s/it]
{'loss': 0.4225, 'learning_rate': 1.9066852010867126e-06, 'rewards/chosen': -1.4286787509918213, 'rewards/rejected': -2.281822681427002, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8531438708305359, 'policy_logps/rejected': -289.93194580078125, 'policy_logps/chosen': -289.3208312988281, 'referece_logps/rejected': -267.11370849609375, 'referece_logps/chosen': -275.0340270996094, 'logits/rejected': -1.5043498277664185, 'logits/chosen': -1.6554410457611084, 'epoch': 0.99}
[2024-04-06 03:42:37,097] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▋        | 2651/16104 [12:18:40<61:26:53, 16.44s/it]

 16%|█▋        | 2652/16104 [12:18:59<64:45:45, 17.33s/it]

 16%|█▋        | 2653/16104 [12:19:17<65:44:44, 17.60s/it]
{'loss': 0.3993, 'learning_rate': 1.9063455610348722e-06, 'rewards/chosen': -1.3747254610061646, 'rewards/rejected': -2.76810622215271, 'rewards/accuracies': 1.0, 'rewards/margins': 1.393381118774414, 'policy_logps/rejected': -612.0120239257812, 'policy_logps/chosen': -420.1871643066406, 'referece_logps/rejected': -584.3310546875, 'referece_logps/chosen': -406.43988037109375, 'logits/rejected': 0.16114352643489838, 'logits/chosen': 0.3812127113342285, 'epoch': 0.99}

 16%|█▋        | 2654/16104 [12:19:35<65:35:20, 17.56s/it]
[2024-04-06 03:44:11,048] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▋        | 2656/16104 [12:20:17<72:40:25, 19.45s/it]
[2024-04-06 03:44:32,137] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2657/16104 [12:20:29<64:05:41, 17.16s/it]

 17%|█▋        | 2658/16104 [12:20:49<67:08:46, 17.98s/it]

 17%|█▋        | 2659/16104 [12:21:06<65:54:11, 17.65s/it]
{'loss': 0.5284, 'learning_rate': 1.9058350011271069e-06, 'rewards/chosen': -1.211551308631897, 'rewards/rejected': -1.7089810371398926, 'rewards/accuracies': 0.5, 'rewards/margins': 0.49742984771728516, 'policy_logps/rejected': -487.1074523925781, 'policy_logps/chosen': -372.6896057128906, 'referece_logps/rejected': -470.0176696777344, 'referece_logps/chosen': -360.5740966796875, 'logits/rejected': -0.2769227921962738, 'logits/chosen': -0.26396802067756653, 'epoch': 0.99}

 17%|█▋        | 2660/16104 [12:21:19<60:15:33, 16.14s/it]


 17%|█▋        | 2662/16104 [12:21:47<55:56:52, 14.98s/it]
{'loss': 0.4379, 'learning_rate': 1.905579226451068e-06, 'rewards/chosen': -0.6984055638313293, 'rewards/rejected': -1.5249768495559692, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8265712857246399, 'policy_logps/rejected': -261.5606384277344, 'policy_logps/chosen': -373.1875305175781, 'referece_logps/rejected': -246.3109130859375, 'referece_logps/chosen': -366.20343017578125, 'logits/rejected': -0.16106241941452026, 'logits/chosen': -0.21102586388587952, 'epoch': 0.99}


 17%|█▋        | 2664/16104 [12:22:22<60:18:14, 16.15s/it]

 17%|█▋        | 2665/16104 [12:22:34<56:17:02, 15.08s/it]

 17%|█▋        | 2666/16104 [12:22:54<61:41:41, 16.53s/it]
[2024-04-06 03:47:08,944] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2667/16104 [12:23:11<62:19:45, 16.70s/it]
{'loss': 0.4751, 'learning_rate': 1.9051522027244809e-06, 'rewards/chosen': -0.8067604303359985, 'rewards/rejected': -1.8143951892852783, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0076346397399902, 'policy_logps/rejected': -311.7076110839844, 'policy_logps/chosen': -326.62109375, 'referece_logps/rejected': -293.56365966796875, 'referece_logps/chosen': -318.5534362792969, 'logits/rejected': -0.503093421459198, 'logits/chosen': -0.442393958568573, 'epoch': 0.99}


 17%|█▋        | 2669/16104 [12:23:46<64:41:09, 17.33s/it]
{'loss': 0.5136, 'learning_rate': 1.9049811369044994e-06, 'rewards/chosen': -1.2245486974716187, 'rewards/rejected': -2.3657922744750977, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1412436962127686, 'policy_logps/rejected': -500.7271728515625, 'policy_logps/chosen': -420.87103271484375, 'referece_logps/rejected': -477.0692443847656, 'referece_logps/chosen': -408.62554931640625, 'logits/rejected': -0.7431190013885498, 'logits/chosen': -0.8189160227775574, 'epoch': 0.99}


 17%|█▋        | 2671/16104 [12:24:30<73:56:25, 19.82s/it]
[2024-04-06 03:48:44,574] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4401, 'learning_rate': 1.9048099246521118e-06, 'rewards/chosen': -1.2952284812927246, 'rewards/rejected': -2.0750796794891357, 'rewards/accuracies': 0.625, 'rewards/margins': 0.779850959777832, 'policy_logps/rejected': -402.7131042480469, 'policy_logps/chosen': -404.2268371582031, 'referece_logps/rejected': -381.96234130859375, 'referece_logps/chosen': -391.2745361328125, 'logits/rejected': -0.6472883820533752, 'logits/chosen': -0.44036707282066345, 'epoch': 1.0}
[2024-04-06 03:48:59,707] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2673/16104 [12:25:04<69:08:40, 18.53s/it]
[2024-04-06 03:49:18,525] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2674/16104 [12:25:18<64:35:01, 17.31s/it]

 17%|█▋        | 2675/16104 [12:25:43<72:19:56, 19.39s/it]
[2024-04-06 03:49:57,228] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2676/16104 [12:26:00<69:36:02, 18.66s/it]

 17%|█▋        | 2677/16104 [12:26:22<73:35:50, 19.73s/it]

 17%|█▋        | 2678/16104 [12:26:38<69:55:24, 18.75s/it]
{'loss': 0.522, 'learning_rate': 1.9042095290137372e-06, 'rewards/chosen': -1.1184741258621216, 'rewards/rejected': -2.5618247985839844, 'rewards/accuracies': 0.75, 'rewards/margins': 1.443350911140442, 'policy_logps/rejected': -498.5137023925781, 'policy_logps/chosen': -519.9906005859375, 'referece_logps/rejected': -472.89544677734375, 'referece_logps/chosen': -508.80584716796875, 'logits/rejected': -0.6141742467880249, 'logits/chosen': -0.7300111055374146, 'epoch': 1.0}
[2024-04-06 03:51:05,526] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2680/16104 [12:27:04<58:40:01, 15.73s/it]

 17%|█▋        | 2681/16104 [12:27:24<63:49:49, 17.12s/it]
[2024-04-06 03:51:38,842] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2682/16104 [12:27:36<58:05:58, 15.58s/it]
[2024-04-06 03:51:50,842] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2683/16104 [12:27:57<63:25:06, 17.01s/it]
[2024-04-06 03:52:11,184] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6281, 'learning_rate': 1.9037795776103023e-06, 'rewards/chosen': -0.8452631831169128, 'rewards/rejected': -1.4133342504501343, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5680711269378662, 'policy_logps/rejected': -565.6979370117188, 'policy_logps/chosen': -510.489501953125, 'referece_logps/rejected': -551.5646362304688, 'referece_logps/chosen': -502.0368957519531, 'logits/rejected': -0.5267301201820374, 'logits/chosen': -0.49954089522361755, 'epoch': 1.0}


 17%|█▋        | 2685/16104 [12:28:39<71:47:15, 19.26s/it]

 17%|█▋        | 2686/16104 [12:28:53<66:58:56, 17.97s/it]

 17%|█▋        | 2687/16104 [12:29:15<71:11:27, 19.10s/it]

 17%|█▋        | 2688/16104 [12:29:27<63:11:14, 16.96s/it]

 17%|█▋        | 2689/16104 [12:29:46<65:32:47, 17.59s/it]

 17%|█▋        | 2690/16104 [12:30:00<60:56:09, 16.35s/it]

 17%|█▋        | 2691/16104 [12:30:11<54:44:11, 14.69s/it]

 17%|█▋        | 2692/16104 [12:30:21<50:13:16, 13.48s/it]

 17%|█▋        | 2693/16104 [12:30:39<55:30:13, 14.90s/it]

 17%|█▋        | 2694/16104 [12:30:54<55:10:12, 14.81s/it]

 17%|█▋        | 2695/16104 [12:31:15<61:39:19, 16.55s/it]

 17%|█▋        | 2696/16104 [12:31:26<55:41:51, 14.95s/it]

 17%|█▋        | 2697/16104 [12:31:46<62:01:49, 16.66s/it]
[2024-04-06 03:56:01,111] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5335, 'learning_rate': 1.9025708526594619e-06, 'rewards/chosen': -1.0284994840621948, 'rewards/rejected': -2.1309919357299805, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1024924516677856, 'policy_logps/rejected': -438.21246337890625, 'policy_logps/chosen': -403.2276611328125, 'referece_logps/rejected': -416.9025573730469, 'referece_logps/chosen': -392.9426574707031, 'logits/rejected': -0.2555985748767853, 'logits/chosen': -0.2271345853805542, 'epoch': 1.0}
[2024-04-06 03:56:14,120] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2699/16104 [12:32:17<60:04:42, 16.13s/it]
{'loss': 0.5291, 'learning_rate': 1.9023975932730134e-06, 'rewards/chosen': -1.012811303138733, 'rewards/rejected': -2.1845176219940186, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1717063188552856, 'policy_logps/rejected': -532.9038696289062, 'policy_logps/chosen': -556.762939453125, 'referece_logps/rejected': -511.0586242675781, 'referece_logps/chosen': -546.6348266601562, 'logits/rejected': 0.1255159080028534, 'logits/chosen': 0.0833001658320427, 'epoch': 1.01}


 17%|█▋        | 2701/16104 [12:32:43<54:09:07, 14.55s/it]

 17%|█▋        | 2702/16104 [12:32:55<51:11:42, 13.75s/it]

 17%|█▋        | 2703/16104 [12:33:13<55:53:04, 15.01s/it]
[2024-04-06 03:57:27,938] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4066, 'learning_rate': 1.9020506364850632e-06, 'rewards/chosen': -1.023120403289795, 'rewards/rejected': -1.6747740507125854, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6516537666320801, 'policy_logps/rejected': -415.23101806640625, 'policy_logps/chosen': -390.09930419921875, 'referece_logps/rejected': -398.4833068847656, 'referece_logps/chosen': -379.86810302734375, 'logits/rejected': -0.32866713404655457, 'logits/chosen': -0.3143373727798462, 'epoch': 1.01}


 17%|█▋        | 2705/16104 [12:33:42<56:10:43, 15.09s/it]

 17%|█▋        | 2706/16104 [12:33:55<53:30:17, 14.38s/it]

 17%|█▋        | 2707/16104 [12:34:11<54:48:33, 14.73s/it]

 17%|█▋        | 2708/16104 [12:34:23<52:09:18, 14.02s/it]
{'loss': 0.4083, 'learning_rate': 1.9016161195114648e-06, 'rewards/chosen': -1.071729063987732, 'rewards/rejected': -1.9213768243789673, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8496479392051697, 'policy_logps/rejected': -600.3770141601562, 'policy_logps/chosen': -497.4107666015625, 'referece_logps/rejected': -581.1632690429688, 'referece_logps/chosen': -486.6934509277344, 'logits/rejected': -0.9604523777961731, 'logits/chosen': -0.6756336688995361, 'epoch': 1.01}


 17%|█▋        | 2710/16104 [12:34:45<45:59:44, 12.36s/it]

 17%|█▋        | 2711/16104 [12:34:56<44:36:24, 11.99s/it]

 17%|█▋        | 2712/16104 [12:35:18<55:53:39, 15.03s/it]
{'loss': 0.4709, 'learning_rate': 1.9012678494158587e-06, 'rewards/chosen': -1.0444263219833374, 'rewards/rejected': -1.8703945875167847, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8259682059288025, 'policy_logps/rejected': -290.19683837890625, 'policy_logps/chosen': -439.99566650390625, 'referece_logps/rejected': -271.492919921875, 'referece_logps/chosen': -429.5513916015625, 'logits/rejected': -0.6699156165122986, 'logits/chosen': -0.7461062073707581, 'epoch': 1.01}


 17%|█▋        | 2714/16104 [12:35:47<53:49:48, 14.47s/it]

 17%|█▋        | 2715/16104 [12:36:01<53:06:03, 14.28s/it]

 17%|█▋        | 2716/16104 [12:36:21<59:32:33, 16.01s/it]

 17%|█▋        | 2717/16104 [12:36:39<61:24:16, 16.51s/it]
{'loss': 0.4893, 'learning_rate': 1.9008316915202554e-06, 'rewards/chosen': -0.7120761275291443, 'rewards/rejected': -1.7882548570632935, 'rewards/accuracies': 1.0, 'rewards/margins': 1.076178789138794, 'policy_logps/rejected': -358.01318359375, 'policy_logps/chosen': -460.14593505859375, 'referece_logps/rejected': -340.13067626953125, 'referece_logps/chosen': -453.0252380371094, 'logits/rejected': 0.13004504144191742, 'logits/chosen': 0.18283098936080933, 'epoch': 1.01}


 17%|█▋        | 2719/16104 [12:37:09<59:22:01, 15.97s/it]
{'loss': 0.4336, 'learning_rate': 1.900656973255557e-06, 'rewards/chosen': -0.8503773212432861, 'rewards/rejected': -1.8932617902755737, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0428845882415771, 'policy_logps/rejected': -446.3540954589844, 'policy_logps/chosen': -570.2714233398438, 'referece_logps/rejected': -427.4214172363281, 'referece_logps/chosen': -561.7676391601562, 'logits/rejected': -0.6665228605270386, 'logits/chosen': -0.7292240262031555, 'epoch': 1.01}


 17%|█▋        | 2721/16104 [12:37:42<60:37:46, 16.31s/it]
{'loss': 0.6316, 'learning_rate': 1.900482109258133e-06, 'rewards/chosen': -0.8663967251777649, 'rewards/rejected': -1.410390853881836, 'rewards/accuracies': 0.75, 'rewards/margins': 0.543994128704071, 'policy_logps/rejected': -291.77374267578125, 'policy_logps/chosen': -302.0040588378906, 'referece_logps/rejected': -277.6698303222656, 'referece_logps/chosen': -293.340087890625, 'logits/rejected': -0.43351680040359497, 'logits/chosen': -0.34057602286338806, 'epoch': 1.01}


 17%|█▋        | 2723/16104 [12:38:11<56:45:37, 15.27s/it]

 17%|█▋        | 2724/16104 [12:38:27<57:14:59, 15.40s/it]

 17%|█▋        | 2725/16104 [12:38:39<53:23:15, 14.37s/it]

 17%|█▋        | 2726/16104 [12:38:51<50:50:31, 13.68s/it]
{'loss': 0.5882, 'learning_rate': 1.9000443118696368e-06, 'rewards/chosen': -1.1280031204223633, 'rewards/rejected': -1.4155025482177734, 'rewards/accuracies': 0.5, 'rewards/margins': 0.28749945759773254, 'policy_logps/rejected': -595.5562133789062, 'policy_logps/chosen': -588.0836791992188, 'referece_logps/rejected': -581.4012451171875, 'referece_logps/chosen': -576.8037109375, 'logits/rejected': -0.5949763059616089, 'logits/chosen': -0.5099009275436401, 'epoch': 1.02}

 17%|█▋        | 2727/16104 [12:39:02<48:29:37, 13.05s/it]


 17%|█▋        | 2729/16104 [12:39:37<57:15:29, 15.41s/it]

 17%|█▋        | 2730/16104 [12:39:57<62:38:08, 16.86s/it]
{'loss': 0.4846, 'learning_rate': 1.8996934185864365e-06, 'rewards/chosen': -1.0401380062103271, 'rewards/rejected': -1.642256259918213, 'rewards/accuracies': 0.875, 'rewards/margins': 0.602118194103241, 'policy_logps/rejected': -277.90234375, 'policy_logps/chosen': -269.9638977050781, 'referece_logps/rejected': -261.47979736328125, 'referece_logps/chosen': -259.5625305175781, 'logits/rejected': -0.48370876908302307, 'logits/chosen': -0.4350467324256897, 'epoch': 1.02}

 17%|█▋        | 2731/16104 [12:40:11<58:26:33, 15.73s/it]


 17%|█▋        | 2733/16104 [12:40:36<52:40:14, 14.18s/it]

 17%|█▋        | 2734/16104 [12:40:57<60:48:31, 16.37s/it]
{'loss': 0.4662, 'learning_rate': 1.8993419429959977e-06, 'rewards/chosen': -1.1072790622711182, 'rewards/rejected': -2.623952865600586, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5166733264923096, 'policy_logps/rejected': -436.794677734375, 'policy_logps/chosen': -419.01226806640625, 'referece_logps/rejected': -410.5552062988281, 'referece_logps/chosen': -407.9394226074219, 'logits/rejected': 0.167642280459404, 'logits/chosen': 0.2455013245344162, 'epoch': 1.02}


 17%|█▋        | 2736/16104 [12:41:27<57:46:58, 15.56s/it]

 17%|█▋        | 2737/16104 [12:41:43<58:26:40, 15.74s/it]

 17%|█▋        | 2738/16104 [12:41:59<58:39:37, 15.80s/it]

 17%|█▋        | 2739/16104 [12:42:15<59:23:04, 16.00s/it]
{'loss': 0.4927, 'learning_rate': 1.8989017799849893e-06, 'rewards/chosen': -1.1763641834259033, 'rewards/rejected': -2.1834659576416016, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0071017742156982, 'policy_logps/rejected': -304.4397277832031, 'policy_logps/chosen': -382.47918701171875, 'referece_logps/rejected': -282.6050720214844, 'referece_logps/chosen': -370.715576171875, 'logits/rejected': -0.019759714603424072, 'logits/chosen': -0.12284618616104126, 'epoch': 1.02}


 17%|█▋        | 2741/16104 [12:42:42<54:44:54, 14.75s/it]

 17%|█▋        | 2742/16104 [12:43:02<60:51:34, 16.40s/it]

 17%|█▋        | 2743/16104 [12:43:21<63:46:12, 17.18s/it]

 17%|█▋        | 2744/16104 [12:43:34<58:38:32, 15.80s/it]

 17%|█▋        | 2745/16104 [12:43:46<54:49:15, 14.77s/it]

 17%|█▋        | 2746/16104 [12:44:08<63:15:43, 17.05s/it]

 17%|█▋        | 2747/16104 [12:44:20<57:29:17, 15.49s/it]
{'loss': 0.4437, 'learning_rate': 1.8981956285196326e-06, 'rewards/chosen': -1.0610544681549072, 'rewards/rejected': -1.6904443502426147, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6293898224830627, 'policy_logps/rejected': -340.3210754394531, 'policy_logps/chosen': -314.44683837890625, 'referece_logps/rejected': -323.4166259765625, 'referece_logps/chosen': -303.8363342285156, 'logits/rejected': -1.3161588907241821, 'logits/chosen': -1.1547178030014038, 'epoch': 1.02}


 17%|█▋        | 2749/16104 [12:44:51<58:58:48, 15.90s/it]
{'loss': 0.3401, 'learning_rate': 1.8980187272456653e-06, 'rewards/chosen': -0.9876579642295837, 'rewards/rejected': -2.8046391010284424, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8169809579849243, 'policy_logps/rejected': -302.3265075683594, 'policy_logps/chosen': -402.7706298828125, 'referece_logps/rejected': -274.2801513671875, 'referece_logps/chosen': -392.8940734863281, 'logits/rejected': -0.6795168519020081, 'logits/chosen': -0.7282685041427612, 'epoch': 1.02}


 17%|█▋        | 2751/16104 [12:45:31<66:57:09, 18.05s/it]

 17%|█▋        | 2752/16104 [12:45:44<60:39:12, 16.35s/it]

 17%|█▋        | 2753/16104 [12:46:00<60:44:30, 16.38s/it]
{'loss': 0.5668, 'learning_rate': 1.897664488808863e-06, 'rewards/chosen': -1.3576993942260742, 'rewards/rejected': -2.0468156337738037, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6891164779663086, 'policy_logps/rejected': -232.62713623046875, 'policy_logps/chosen': -509.0048522949219, 'referece_logps/rejected': -212.15896606445312, 'referece_logps/chosen': -495.4278564453125, 'logits/rejected': -0.8563683032989502, 'logits/chosen': -0.7843076586723328, 'epoch': 1.03}


 17%|█▋        | 2755/16104 [12:46:32<59:53:14, 16.15s/it]

 17%|█▋        | 2756/16104 [12:46:47<58:58:36, 15.91s/it]

 17%|█▋        | 2757/16104 [12:47:05<61:08:07, 16.49s/it]

 17%|█▋        | 2758/16104 [12:47:24<63:58:53, 17.26s/it]
{'loss': 0.5385, 'learning_rate': 1.8972208737668702e-06, 'rewards/chosen': -0.9354603290557861, 'rewards/rejected': -1.9534074068069458, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0179471969604492, 'policy_logps/rejected': -399.7733154296875, 'policy_logps/chosen': -347.9691162109375, 'referece_logps/rejected': -380.2392578125, 'referece_logps/chosen': -338.614501953125, 'logits/rejected': -1.1423078775405884, 'logits/chosen': -1.3094507455825806, 'epoch': 1.03}


 17%|█▋        | 2760/16104 [12:47:54<59:03:00, 15.93s/it]
{'loss': 0.4779, 'learning_rate': 1.8970431736656415e-06, 'rewards/chosen': -1.1400121450424194, 'rewards/rejected': -2.0190255641937256, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8790132403373718, 'policy_logps/rejected': -366.57440185546875, 'policy_logps/chosen': -344.4125061035156, 'referece_logps/rejected': -346.3841247558594, 'referece_logps/chosen': -333.01239013671875, 'logits/rejected': -0.7742107510566711, 'logits/chosen': -0.7779366970062256, 'epoch': 1.03}


 17%|█▋        | 2762/16104 [12:48:26<59:01:06, 15.92s/it]

 17%|█▋        | 2763/16104 [12:48:40<56:14:32, 15.18s/it]

 17%|█▋        | 2764/16104 [12:49:00<61:41:43, 16.65s/it]

 17%|█▋        | 2765/16104 [12:49:22<67:25:48, 18.20s/it]

 17%|█▋        | 2766/16104 [12:49:36<63:19:46, 17.09s/it]
{'loss': 0.4229, 'learning_rate': 1.8965092025891636e-06, 'rewards/chosen': -1.0033297538757324, 'rewards/rejected': -1.8369829654693604, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8336532115936279, 'policy_logps/rejected': -253.38742065429688, 'policy_logps/chosen': -231.88668823242188, 'referece_logps/rejected': -235.01760864257812, 'referece_logps/chosen': -221.8533935546875, 'logits/rejected': 0.2414395660161972, 'logits/chosen': 0.160650372505188, 'epoch': 1.03}
[2024-04-06 04:14:11,829] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2768/16104 [12:50:21<73:24:25, 19.82s/it]

 17%|█▋        | 2769/16104 [12:50:40<73:20:05, 19.80s/it]
[2024-04-06 04:14:55,006] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2770/16104 [12:50:52<64:10:39, 17.33s/it]
{'loss': 0.5055, 'learning_rate': 1.8961524965155775e-06, 'rewards/chosen': -1.3681573867797852, 'rewards/rejected': -1.669489860534668, 'rewards/accuracies': 0.375, 'rewards/margins': 0.30133235454559326, 'policy_logps/rejected': -237.56675720214844, 'policy_logps/chosen': -452.8367919921875, 'referece_logps/rejected': -220.87185668945312, 'referece_logps/chosen': -439.15521240234375, 'logits/rejected': -0.6076061129570007, 'logits/chosen': -0.7145260572433472, 'epoch': 1.03}


 17%|█▋        | 2772/16104 [12:51:20<56:49:22, 15.34s/it]
{'loss': 0.4706, 'learning_rate': 1.8959739259585454e-06, 'rewards/chosen': -0.7669355869293213, 'rewards/rejected': -2.1107211112976074, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3437855243682861, 'policy_logps/rejected': -350.90277099609375, 'policy_logps/chosen': -643.7096557617188, 'referece_logps/rejected': -329.7955322265625, 'referece_logps/chosen': -636.040283203125, 'logits/rejected': -0.08057668805122375, 'logits/chosen': -0.10404562950134277, 'epoch': 1.03}


 17%|█▋        | 2774/16104 [12:51:57<64:23:18, 17.39s/it]
{'loss': 0.5123, 'learning_rate': 1.8957952104265384e-06, 'rewards/chosen': -0.9304112792015076, 'rewards/rejected': -1.5012807846069336, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5708696246147156, 'policy_logps/rejected': -256.6746826171875, 'policy_logps/chosen': -320.91485595703125, 'referece_logps/rejected': -241.66189575195312, 'referece_logps/chosen': -311.6107482910156, 'logits/rejected': -0.21544906497001648, 'logits/chosen': -0.17637105286121368, 'epoch': 1.03}


 17%|█▋        | 2776/16104 [12:52:26<60:24:27, 16.32s/it]

 17%|█▋        | 2777/16104 [12:52:39<55:39:03, 15.03s/it]

 17%|█▋        | 2778/16104 [12:52:54<56:31:27, 15.27s/it]

 17%|█▋        | 2779/16104 [12:53:08<54:31:42, 14.73s/it]

 17%|█▋        | 2780/16104 [12:53:29<61:29:15, 16.61s/it]
[2024-04-06 04:17:43,477] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2781/16104 [12:53:46<62:03:43, 16.77s/it]
{'loss': 0.5009, 'learning_rate': 1.8951685648042908e-06, 'rewards/chosen': -1.2904078960418701, 'rewards/rejected': -2.765310764312744, 'rewards/accuracies': 0.875, 'rewards/margins': 1.474902868270874, 'policy_logps/rejected': -460.00518798828125, 'policy_logps/chosen': -389.62652587890625, 'referece_logps/rejected': -432.3520812988281, 'referece_logps/chosen': -376.7224426269531, 'logits/rejected': -0.20965811610221863, 'logits/chosen': -0.1673104614019394, 'epoch': 1.04}


 17%|█▋        | 2783/16104 [12:54:26<68:34:24, 18.53s/it]

 17%|█▋        | 2784/16104 [12:54:42<65:34:24, 17.72s/it]

 17%|█▋        | 2785/16104 [12:54:57<62:37:32, 16.93s/it]

 17%|█▋        | 2786/16104 [12:55:14<63:11:25, 17.08s/it]

 17%|█▋        | 2787/16104 [12:55:29<60:05:32, 16.24s/it]
{'loss': 0.3692, 'learning_rate': 1.8946300277028095e-06, 'rewards/chosen': -0.9059224128723145, 'rewards/rejected': -1.3002246618270874, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3943023085594177, 'policy_logps/rejected': -607.5732421875, 'policy_logps/chosen': -314.4361572265625, 'referece_logps/rejected': -594.5709838867188, 'referece_logps/chosen': -305.376953125, 'logits/rejected': -0.9140648245811462, 'logits/chosen': -0.8556582927703857, 'epoch': 1.04}

 17%|█▋        | 2788/16104 [12:55:41<56:02:31, 15.15s/it]


 17%|█▋        | 2790/16104 [12:56:18<62:10:52, 16.81s/it]

 17%|█▋        | 2791/16104 [12:56:38<65:28:23, 17.70s/it]

 17%|█▋        | 2792/16104 [12:56:55<64:21:35, 17.41s/it]

 17%|█▋        | 2793/16104 [12:57:14<66:35:44, 18.01s/it]
{'loss': 0.4126, 'learning_rate': 1.8940901877837628e-06, 'rewards/chosen': -1.2695103883743286, 'rewards/rejected': -1.990400791168213, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7208904027938843, 'policy_logps/rejected': -299.9327392578125, 'policy_logps/chosen': -528.4953002929688, 'referece_logps/rejected': -280.02874755859375, 'referece_logps/chosen': -515.8001708984375, 'logits/rejected': -0.3585731089115143, 'logits/chosen': -0.4686703681945801, 'epoch': 1.04}

 17%|█▋        | 2794/16104 [12:57:28<61:41:33, 16.69s/it]


 17%|█▋        | 2796/16104 [12:57:55<55:26:32, 15.00s/it]
{'loss': 0.4666, 'learning_rate': 1.8938197795132503e-06, 'rewards/chosen': -0.8640947341918945, 'rewards/rejected': -1.424230933189392, 'rewards/accuracies': 0.75, 'rewards/margins': 0.560136079788208, 'policy_logps/rejected': -341.94091796875, 'policy_logps/chosen': -478.6469421386719, 'referece_logps/rejected': -327.6986083984375, 'referece_logps/chosen': -470.0060119628906, 'logits/rejected': -0.48884230852127075, 'logits/chosen': -0.6212579011917114, 'epoch': 1.04}


 17%|█▋        | 2798/16104 [12:58:28<58:57:51, 15.95s/it]

 17%|█▋        | 2799/16104 [12:58:50<65:39:12, 17.76s/it]
[2024-04-06 04:23:04,837] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2800/16104 [12:59:08<65:55:56, 17.84s/it]
[2024-04-06 04:23:22,858] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2801/16104 [12:59:30<70:32:33, 19.09s/it]
{'loss': 0.5136, 'learning_rate': 1.8933683759789832e-06, 'rewards/chosen': -1.3091763257980347, 'rewards/rejected': -1.559970736503601, 'rewards/accuracies': 0.625, 'rewards/margins': 0.25079435110092163, 'policy_logps/rejected': -281.9705505371094, 'policy_logps/chosen': -267.87646484375, 'referece_logps/rejected': -266.370849609375, 'referece_logps/chosen': -254.78469848632812, 'logits/rejected': -0.7498698234558105, 'logits/chosen': -0.732428789138794, 'epoch': 1.04}


 17%|█▋        | 2803/16104 [13:00:08<70:54:01, 19.19s/it]
{'loss': 0.4595, 'learning_rate': 1.8931875615712865e-06, 'rewards/chosen': -1.2148411273956299, 'rewards/rejected': -1.9842456579208374, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7694046497344971, 'policy_logps/rejected': -435.9359436035156, 'policy_logps/chosen': -520.2279052734375, 'referece_logps/rejected': -416.09344482421875, 'referece_logps/chosen': -508.0794982910156, 'logits/rejected': 0.33764469623565674, 'logits/chosen': 0.24813728034496307, 'epoch': 1.04}


 17%|█▋        | 2805/16104 [13:00:47<71:24:43, 19.33s/it]
{'loss': 0.4679, 'learning_rate': 1.8930066026394687e-06, 'rewards/chosen': -1.0317431688308716, 'rewards/rejected': -1.512839674949646, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4810965657234192, 'policy_logps/rejected': -335.7456359863281, 'policy_logps/chosen': -485.3007507324219, 'referece_logps/rejected': -320.61724853515625, 'referece_logps/chosen': -474.98333740234375, 'logits/rejected': 0.14268210530281067, 'logits/chosen': -0.03040633350610733, 'epoch': 1.05}


 17%|█▋        | 2807/16104 [13:01:23<70:00:59, 18.96s/it]

 17%|█▋        | 2808/16104 [13:01:43<70:32:25, 19.10s/it]

 17%|█▋        | 2809/16104 [13:01:59<67:50:48, 18.37s/it]

 17%|█▋        | 2810/16104 [13:02:15<64:56:59, 17.59s/it]

 17%|█▋        | 2811/16104 [13:02:34<66:45:45, 18.08s/it]

 17%|█▋        | 2812/16104 [13:02:56<70:57:35, 19.22s/it]

 17%|█▋        | 2813/16104 [13:03:09<63:14:34, 17.13s/it]
{'loss': 0.4173, 'learning_rate': 1.8922813222569408e-06, 'rewards/chosen': -1.589982271194458, 'rewards/rejected': -2.0525240898132324, 'rewards/accuracies': 0.75, 'rewards/margins': 0.46254169940948486, 'policy_logps/rejected': -344.6031494140625, 'policy_logps/chosen': -475.1170654296875, 'referece_logps/rejected': -324.0779113769531, 'referece_logps/chosen': -459.21722412109375, 'logits/rejected': -1.1265230178833008, 'logits/chosen': -1.0010180473327637, 'epoch': 1.05}

 17%|█▋        | 2814/16104 [13:03:26<63:17:01, 17.14s/it]

 17%|█▋        | 2815/16104 [13:03:46<66:34:18, 18.03s/it]


 17%|█▋        | 2817/16104 [13:04:22<64:50:26, 17.57s/it]
{'loss': 0.3882, 'learning_rate': 1.8919178156833497e-06, 'rewards/chosen': -1.100935935974121, 'rewards/rejected': -2.701382875442505, 'rewards/accuracies': 0.5, 'rewards/margins': 1.6004469394683838, 'policy_logps/rejected': -572.7611083984375, 'policy_logps/chosen': -430.10333251953125, 'referece_logps/rejected': -545.7472534179688, 'referece_logps/chosen': -419.093994140625, 'logits/rejected': -0.13596758246421814, 'logits/chosen': -0.1614641398191452, 'epoch': 1.05}

 17%|█▋        | 2818/16104 [13:04:38<63:27:51, 17.20s/it]


 18%|█▊        | 2820/16104 [13:05:11<62:11:44, 16.86s/it]
[2024-04-06 04:29:26,045] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3894, 'learning_rate': 1.891644806903789e-06, 'rewards/chosen': -1.028383731842041, 'rewards/rejected': -2.026196002960205, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9978121519088745, 'policy_logps/rejected': -442.31207275390625, 'policy_logps/chosen': -343.65032958984375, 'referece_logps/rejected': -422.0500793457031, 'referece_logps/chosen': -333.36651611328125, 'logits/rejected': 0.3417571783065796, 'logits/chosen': 0.47999486327171326, 'epoch': 1.05}

 18%|█▊        | 2821/16104 [13:05:26<59:57:11, 16.25s/it]

 18%|█▊        | 2822/16104 [13:05:39<55:57:56, 15.17s/it]

 18%|█▊        | 2823/16104 [13:05:53<54:39:18, 14.82s/it]


 18%|█▊        | 2825/16104 [13:06:17<49:09:22, 13.33s/it]

 18%|█▊        | 2826/16104 [13:06:28<46:08:18, 12.51s/it]
{'loss': 0.4351, 'learning_rate': 1.8910978155913683e-06, 'rewards/chosen': -1.020897626876831, 'rewards/rejected': -2.781521797180176, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7606240510940552, 'policy_logps/rejected': -417.7782287597656, 'policy_logps/chosen': -279.9326171875, 'referece_logps/rejected': -389.9630432128906, 'referece_logps/chosen': -269.7236328125, 'logits/rejected': -0.7774244546890259, 'logits/chosen': -0.7327677607536316, 'epoch': 1.05}


 18%|█▊        | 2828/16104 [13:06:49<42:42:02, 11.58s/it]
{'loss': 0.4176, 'learning_rate': 1.8909151967425633e-06, 'rewards/chosen': -0.7074783444404602, 'rewards/rejected': -1.8037694692611694, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0962913036346436, 'policy_logps/rejected': -502.029541015625, 'policy_logps/chosen': -485.14410400390625, 'referece_logps/rejected': -483.9918212890625, 'referece_logps/chosen': -478.0693054199219, 'logits/rejected': 0.04887137562036514, 'logits/chosen': 0.24156419932842255, 'epoch': 1.05}

 18%|█▊        | 2829/16104 [13:07:00<41:54:22, 11.36s/it]


 18%|█▊        | 2831/16104 [13:07:30<49:08:07, 13.33s/it]

 18%|█▊        | 2832/16104 [13:07:43<49:18:38, 13.38s/it]
{'loss': 0.529, 'learning_rate': 1.890549526605216e-06, 'rewards/chosen': -1.199636459350586, 'rewards/rejected': -2.0182180404663086, 'rewards/accuracies': 0.625, 'rewards/margins': 0.818581759929657, 'policy_logps/rejected': -543.5499877929688, 'policy_logps/chosen': -487.4280700683594, 'referece_logps/rejected': -523.3677978515625, 'referece_logps/chosen': -475.43170166015625, 'logits/rejected': -1.0883026123046875, 'logits/chosen': -0.9642038345336914, 'epoch': 1.06}


 18%|█▊        | 2834/16104 [13:08:26<64:35:19, 17.52s/it]
{'loss': 0.5305, 'learning_rate': 1.8903664753758414e-06, 'rewards/chosen': -1.137174129486084, 'rewards/rejected': -2.027254581451416, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8900805115699768, 'policy_logps/rejected': -284.5113525390625, 'policy_logps/chosen': -527.6275024414062, 'referece_logps/rejected': -264.23883056640625, 'referece_logps/chosen': -516.2557373046875, 'logits/rejected': -0.4748871326446533, 'logits/chosen': -0.4860571324825287, 'epoch': 1.06}


 18%|█▊        | 2836/16104 [13:09:02<64:13:04, 17.42s/it]

 18%|█▊        | 2837/16104 [13:09:20<65:22:45, 17.74s/it]

 18%|█▊        | 2838/16104 [13:09:38<65:25:33, 17.75s/it]
{'loss': 0.4105, 'learning_rate': 1.8899999407437859e-06, 'rewards/chosen': -1.9863817691802979, 'rewards/rejected': -3.5181350708007812, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5317531824111938, 'policy_logps/rejected': -471.24072265625, 'policy_logps/chosen': -350.052734375, 'referece_logps/rejected': -436.0593566894531, 'referece_logps/chosen': -330.18896484375, 'logits/rejected': -0.7513267993927002, 'logits/chosen': -0.35677170753479004, 'epoch': 1.06}
[2024-04-06 04:34:09,497] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 18%|█▊        | 2840/16104 [13:10:09<61:27:31, 16.68s/it]
{'loss': 0.5148, 'learning_rate': 1.8898164574004128e-06, 'rewards/chosen': -1.4777278900146484, 'rewards/rejected': -1.7951202392578125, 'rewards/accuracies': 0.625, 'rewards/margins': 0.31739234924316406, 'policy_logps/rejected': -400.9808044433594, 'policy_logps/chosen': -448.57196044921875, 'referece_logps/rejected': -383.02960205078125, 'referece_logps/chosen': -433.7946472167969, 'logits/rejected': 0.34609857201576233, 'logits/chosen': 0.27683717012405396, 'epoch': 1.06}


 18%|█▊        | 2842/16104 [13:10:46<63:12:20, 17.16s/it]

 18%|█▊        | 2843/16104 [13:11:08<68:26:21, 18.58s/it]
{'loss': 0.4488, 'learning_rate': 1.8895409624346628e-06, 'rewards/chosen': -0.7457069158554077, 'rewards/rejected': -2.243875026702881, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4981679916381836, 'policy_logps/rejected': -256.90264892578125, 'policy_logps/chosen': -372.01544189453125, 'referece_logps/rejected': -234.46389770507812, 'referece_logps/chosen': -364.558349609375, 'logits/rejected': -0.7934278249740601, 'logits/chosen': -0.8547788858413696, 'epoch': 1.06}


 18%|█▊        | 2845/16104 [13:11:34<58:50:25, 15.98s/it]
{'loss': 0.6452, 'learning_rate': 1.8893571192003752e-06, 'rewards/chosen': -1.1120209693908691, 'rewards/rejected': -2.5627760887145996, 'rewards/accuracies': 1.0, 'rewards/margins': 1.45075523853302, 'policy_logps/rejected': -326.83941650390625, 'policy_logps/chosen': -271.9560852050781, 'referece_logps/rejected': -301.211669921875, 'referece_logps/chosen': -260.83587646484375, 'logits/rejected': -0.20050692558288574, 'logits/chosen': -0.15225715935230255, 'epoch': 1.06}

 18%|█▊        | 2846/16104 [13:11:56<65:52:00, 17.89s/it]


 18%|█▊        | 2848/16104 [13:12:24<56:51:50, 15.44s/it]
{'loss': 0.644, 'learning_rate': 1.8890810845376299e-06, 'rewards/chosen': -1.1482971906661987, 'rewards/rejected': -1.7041255235671997, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5558283925056458, 'policy_logps/rejected': -292.5181579589844, 'policy_logps/chosen': -252.07183837890625, 'referece_logps/rejected': -275.4769287109375, 'referece_logps/chosen': -240.5888671875, 'logits/rejected': -1.612305760383606, 'logits/chosen': -1.5578713417053223, 'epoch': 1.06}


 18%|█▊        | 2850/16104 [13:13:02<63:02:00, 17.12s/it]

 18%|█▊        | 2851/16104 [13:13:14<58:00:05, 15.76s/it]
{'loss': 0.5066, 'learning_rate': 1.8888047261906457e-06, 'rewards/chosen': -0.7527908682823181, 'rewards/rejected': -1.5956830978393555, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8428922295570374, 'policy_logps/rejected': -424.0823059082031, 'policy_logps/chosen': -374.6242980957031, 'referece_logps/rejected': -408.12542724609375, 'referece_logps/chosen': -367.096435546875, 'logits/rejected': -0.8496754169464111, 'logits/chosen': -0.791812002658844, 'epoch': 1.06}


 18%|█▊        | 2853/16104 [13:13:42<53:53:49, 14.64s/it]

 18%|█▊        | 2854/16104 [13:14:02<60:10:05, 16.35s/it]
{'loss': 0.4852, 'learning_rate': 1.8885280442600345e-06, 'rewards/chosen': -1.1319698095321655, 'rewards/rejected': -1.8181854486465454, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6862155199050903, 'policy_logps/rejected': -312.2692565917969, 'policy_logps/chosen': -322.03466796875, 'referece_logps/rejected': -294.0873718261719, 'referece_logps/chosen': -310.7149963378906, 'logits/rejected': -0.1887860894203186, 'logits/chosen': -0.1584862917661667, 'epoch': 1.06}

 18%|█▊        | 2855/16104 [13:14:13<53:58:23, 14.67s/it]


 18%|█▊        | 2857/16104 [13:14:36<48:40:21, 13.23s/it]
{'loss': 0.4677, 'learning_rate': 1.888251038846528e-06, 'rewards/chosen': -1.1632736921310425, 'rewards/rejected': -2.1620404720306396, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9987665414810181, 'policy_logps/rejected': -261.7787780761719, 'policy_logps/chosen': -319.87158203125, 'referece_logps/rejected': -240.1583709716797, 'referece_logps/chosen': -308.23883056640625, 'logits/rejected': -0.6443950533866882, 'logits/chosen': -0.5910583138465881, 'epoch': 1.06}

 18%|█▊        | 2858/16104 [13:14:53<53:03:03, 14.42s/it]

 18%|█▊        | 2859/16104 [13:15:09<54:05:08, 14.70s/it]


 18%|█▊        | 2861/16104 [13:15:30<46:30:29, 12.64s/it]

 18%|█▊        | 2862/16104 [13:15:46<50:46:05, 13.80s/it]
{'loss': 0.5371, 'learning_rate': 1.8877886445804326e-06, 'rewards/chosen': -1.1412432193756104, 'rewards/rejected': -1.9061670303344727, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7649238109588623, 'policy_logps/rejected': -355.5479736328125, 'policy_logps/chosen': -293.6695251464844, 'referece_logps/rejected': -336.4862976074219, 'referece_logps/chosen': -282.257080078125, 'logits/rejected': -0.45621493458747864, 'logits/chosen': -0.298407644033432, 'epoch': 1.07}


 18%|█▊        | 2864/16104 [13:16:12<48:13:46, 13.11s/it]

 18%|█▊        | 2865/16104 [13:16:34<57:56:23, 15.76s/it]

 18%|█▊        | 2866/16104 [13:16:56<64:27:40, 17.53s/it]
{'loss': 0.4706, 'learning_rate': 1.8874180827177036e-06, 'rewards/chosen': -1.0739086866378784, 'rewards/rejected': -1.3327512741088867, 'rewards/accuracies': 0.5, 'rewards/margins': 0.25884270668029785, 'policy_logps/rejected': -413.53582763671875, 'policy_logps/chosen': -471.8885192871094, 'referece_logps/rejected': -400.208251953125, 'referece_logps/chosen': -461.14947509765625, 'logits/rejected': -0.6163700819015503, 'logits/chosen': -0.6414591670036316, 'epoch': 1.07}


 18%|█▊        | 2868/16104 [13:17:28<62:56:39, 17.12s/it]
{'loss': 0.4585, 'learning_rate': 1.8872325863854755e-06, 'rewards/chosen': -1.2506028413772583, 'rewards/rejected': -2.8691112995147705, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6185086965560913, 'policy_logps/rejected': -508.40289306640625, 'policy_logps/chosen': -396.6665344238281, 'referece_logps/rejected': -479.7117919921875, 'referece_logps/chosen': -384.1605224609375, 'logits/rejected': -1.3486714363098145, 'logits/chosen': -1.176491379737854, 'epoch': 1.07}


 18%|█▊        | 2870/16104 [13:18:02<64:01:24, 17.42s/it]

 18%|█▊        | 2871/16104 [13:18:22<66:40:57, 18.14s/it]

 18%|█▊        | 2872/16104 [13:18:34<60:02:40, 16.34s/it]
{'loss': 0.4478, 'learning_rate': 1.8868611630693647e-06, 'rewards/chosen': -1.5645043849945068, 'rewards/rejected': -2.465555429458618, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9010512232780457, 'policy_logps/rejected': -377.0487060546875, 'policy_logps/chosen': -292.484130859375, 'referece_logps/rejected': -352.39312744140625, 'referece_logps/chosen': -276.83905029296875, 'logits/rejected': -0.8115397691726685, 'logits/chosen': -0.6039379835128784, 'epoch': 1.07}


 18%|█▊        | 2874/16104 [13:19:04<57:41:54, 15.70s/it]
{'loss': 0.3741, 'learning_rate': 1.886675236145581e-06, 'rewards/chosen': -0.9617759585380554, 'rewards/rejected': -2.234304666519165, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2725286483764648, 'policy_logps/rejected': -344.058349609375, 'policy_logps/chosen': -331.5041198730469, 'referece_logps/rejected': -321.7153015136719, 'referece_logps/chosen': -321.88641357421875, 'logits/rejected': -0.7592259645462036, 'logits/chosen': -0.5843444466590881, 'epoch': 1.07}


 18%|█▊        | 2876/16104 [13:19:34<57:29:35, 15.65s/it]
{'loss': 0.3983, 'learning_rate': 1.886489165751417e-06, 'rewards/chosen': -0.7643594741821289, 'rewards/rejected': -2.031325340270996, 'rewards/accuracies': 1.0, 'rewards/margins': 1.266965627670288, 'policy_logps/rejected': -353.4854431152344, 'policy_logps/chosen': -323.43463134765625, 'referece_logps/rejected': -333.17218017578125, 'referece_logps/chosen': -315.7910461425781, 'logits/rejected': -1.419332504272461, 'logits/chosen': -1.3658268451690674, 'epoch': 1.07}

 18%|█▊        | 2877/16104 [13:19:45<52:37:41, 14.32s/it]

 18%|█▊        | 2878/16104 [13:20:01<53:55:37, 14.68s/it]

 18%|█▊        | 2879/16104 [13:20:21<60:39:14, 16.51s/it]
[2024-04-06 04:44:57,377] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 18%|█▊        | 2881/16104 [13:21:02<67:44:59, 18.45s/it]

 18%|█▊        | 2882/16104 [13:21:16<62:54:46, 17.13s/it]
{'loss': 0.4437, 'learning_rate': 1.8859300940478302e-06, 'rewards/chosen': -1.1097699403762817, 'rewards/rejected': -1.9123908281326294, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8026210069656372, 'policy_logps/rejected': -295.21240234375, 'policy_logps/chosen': -369.2620544433594, 'referece_logps/rejected': -276.0885009765625, 'referece_logps/chosen': -358.16436767578125, 'logits/rejected': -1.3193044662475586, 'logits/chosen': -1.171388864517212, 'epoch': 1.07}

 18%|█▊        | 2883/16104 [13:21:34<63:11:00, 17.20s/it]

 18%|█▊        | 2884/16104 [13:21:51<63:07:45, 17.19s/it]
[2024-04-06 04:46:26,116] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2885/16104 [13:22:11<66:45:25, 18.18s/it]

 18%|█▊        | 2886/16104 [13:22:33<70:40:25, 19.25s/it]

 18%|█▊        | 2887/16104 [13:22:55<73:33:47, 20.04s/it]

 18%|█▊        | 2888/16104 [13:23:15<73:25:10, 20.00s/it]

 18%|█▊        | 2889/16104 [13:23:37<76:00:07, 20.70s/it]

 18%|█▊        | 2890/16104 [13:23:55<73:10:09, 19.93s/it]


 18%|█▊        | 2892/16104 [13:24:29<65:53:25, 17.95s/it]
{'loss': 0.4796, 'learning_rate': 1.8849954412821679e-06, 'rewards/chosen': -2.3344919681549072, 'rewards/rejected': -3.5183424949645996, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1838501691818237, 'policy_logps/rejected': -352.655029296875, 'policy_logps/chosen': -317.08673095703125, 'referece_logps/rejected': -317.4716491699219, 'referece_logps/chosen': -293.7418212890625, 'logits/rejected': -0.4700114130973816, 'logits/chosen': -0.41359350085258484, 'epoch': 1.08}


 18%|█▊        | 2894/16104 [13:25:01<61:51:41, 16.86s/it]

 18%|█▊        | 2895/16104 [13:25:20<64:53:54, 17.69s/it]

 18%|█▊        | 2896/16104 [13:25:36<63:01:56, 17.18s/it]

 18%|█▊        | 2897/16104 [13:25:47<55:54:38, 15.24s/it]
{'loss': 0.5289, 'learning_rate': 1.8845267721762341e-06, 'rewards/chosen': -1.6069326400756836, 'rewards/rejected': -3.0421252250671387, 'rewards/accuracies': 0.75, 'rewards/margins': 1.435192584991455, 'policy_logps/rejected': -472.9781494140625, 'policy_logps/chosen': -556.49755859375, 'referece_logps/rejected': -442.556884765625, 'referece_logps/chosen': -540.42822265625, 'logits/rejected': -0.44124341011047363, 'logits/chosen': -0.42818233370780945, 'epoch': 1.08}


 18%|█▊        | 2899/16104 [13:26:13<52:28:48, 14.31s/it]

 18%|█▊        | 2900/16104 [13:26:25<49:33:46, 13.51s/it]

 18%|█▊        | 2901/16104 [13:26:44<56:25:31, 15.39s/it]
{'loss': 0.4681, 'learning_rate': 1.8841511928164043e-06, 'rewards/chosen': -1.4471110105514526, 'rewards/rejected': -2.0672051906585693, 'rewards/accuracies': 0.5, 'rewards/margins': 0.620094358921051, 'policy_logps/rejected': -432.0432434082031, 'policy_logps/chosen': -355.00482177734375, 'referece_logps/rejected': -411.3711242675781, 'referece_logps/chosen': -340.53375244140625, 'logits/rejected': -0.5067759156227112, 'logits/chosen': -0.5114313960075378, 'epoch': 1.08}


 18%|█▊        | 2903/16104 [13:27:25<65:31:33, 17.87s/it]

 18%|█▊        | 2904/16104 [13:27:47<69:44:54, 19.02s/it]
[2024-04-06 04:52:01,457] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4896, 'learning_rate': 1.8838691327455609e-06, 'rewards/chosen': -1.4971327781677246, 'rewards/rejected': -2.866197347640991, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3690643310546875, 'policy_logps/rejected': -398.9662170410156, 'policy_logps/chosen': -422.3010559082031, 'referece_logps/rejected': -370.30426025390625, 'referece_logps/chosen': -407.3297424316406, 'logits/rejected': -0.4578303396701813, 'logits/chosen': -0.3149562180042267, 'epoch': 1.08}

 18%|█▊        | 2905/16104 [13:27:58<60:53:32, 16.61s/it]


 18%|█▊        | 2907/16104 [13:28:28<56:57:09, 15.54s/it]
{'loss': 0.4729, 'learning_rate': 1.8835867508879737e-06, 'rewards/chosen': -0.9026706218719482, 'rewards/rejected': -1.4199796915054321, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5173091292381287, 'policy_logps/rejected': -391.01416015625, 'policy_logps/chosen': -338.4659423828125, 'referece_logps/rejected': -376.8143310546875, 'referece_logps/chosen': -329.4392395019531, 'logits/rejected': -0.7984031438827515, 'logits/chosen': -0.8352934718132019, 'epoch': 1.08}

 18%|█▊        | 2908/16104 [13:28:39<51:49:03, 14.14s/it]


 18%|█▊        | 2910/16104 [13:29:06<50:38:38, 13.82s/it]
{'loss': 0.4336, 'learning_rate': 1.8833040473464475e-06, 'rewards/chosen': -0.6393307447433472, 'rewards/rejected': -1.2341957092285156, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5948649644851685, 'policy_logps/rejected': -344.73004150390625, 'policy_logps/chosen': -267.4757385253906, 'referece_logps/rejected': -332.3880615234375, 'referece_logps/chosen': -261.0824279785156, 'logits/rejected': -0.3212730288505554, 'logits/chosen': -0.2446659505367279, 'epoch': 1.08}
[2024-04-06 04:53:36,808] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2911/16104 [13:29:22<52:40:31, 14.37s/it]

 18%|█▊        | 2912/16104 [13:29:42<58:41:16, 16.02s/it]


 18%|█▊        | 2914/16104 [13:30:07<51:45:50, 14.13s/it]

 18%|█▊        | 2915/16104 [13:30:21<51:45:22, 14.13s/it]

 18%|█▊        | 2916/16104 [13:30:33<48:50:14, 13.33s/it]
{'loss': 0.5836, 'learning_rate': 1.8827376756233868e-06, 'rewards/chosen': -0.5630861520767212, 'rewards/rejected': -1.4941737651824951, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9310876131057739, 'policy_logps/rejected': -363.2718811035156, 'policy_logps/chosen': -325.5020446777344, 'referece_logps/rejected': -348.3301696777344, 'referece_logps/chosen': -319.87115478515625, 'logits/rejected': -0.05425634980201721, 'logits/chosen': -0.0867871642112732, 'epoch': 1.09}


 18%|█▊        | 2918/16104 [13:31:09<56:49:15, 15.51s/it]
{'loss': 0.4493, 'learning_rate': 1.882548599341769e-06, 'rewards/chosen': -1.131295919418335, 'rewards/rejected': -1.9793425798416138, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8480465412139893, 'policy_logps/rejected': -254.6797637939453, 'policy_logps/chosen': -492.2480163574219, 'referece_logps/rejected': -234.8863525390625, 'referece_logps/chosen': -480.93505859375, 'logits/rejected': -0.6057933568954468, 'logits/chosen': -0.6247578859329224, 'epoch': 1.09}

 18%|█▊        | 2919/16104 [13:31:19<51:29:28, 14.06s/it]

 18%|█▊        | 2920/16104 [13:31:40<58:58:24, 16.10s/it]


 18%|█▊        | 2922/16104 [13:32:21<66:46:23, 18.24s/it]
{'loss': 0.4546, 'learning_rate': 1.8821700184011663e-06, 'rewards/chosen': -0.8878142833709717, 'rewards/rejected': -1.5095207691192627, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6217064261436462, 'policy_logps/rejected': -319.1484069824219, 'policy_logps/chosen': -381.12109375, 'referece_logps/rejected': -304.05322265625, 'referece_logps/chosen': -372.2429504394531, 'logits/rejected': -1.6249439716339111, 'logits/chosen': -1.4685896635055542, 'epoch': 1.09}

 18%|█▊        | 2923/16104 [13:32:43<70:39:47, 19.30s/it]


 18%|█▊        | 2925/16104 [13:33:27<75:25:04, 20.60s/it]

 18%|█▊        | 2926/16104 [13:33:43<70:51:10, 19.36s/it]

 18%|█▊        | 2927/16104 [13:34:01<69:38:53, 19.03s/it]

 18%|█▊        | 2928/16104 [13:34:20<68:38:06, 18.75s/it]
{'loss': 0.4662, 'learning_rate': 1.881601076506444e-06, 'rewards/chosen': -1.1022956371307373, 'rewards/rejected': -1.9263229370117188, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8240273594856262, 'policy_logps/rejected': -358.9225769042969, 'policy_logps/chosen': -269.6976623535156, 'referece_logps/rejected': -339.6593322753906, 'referece_logps/chosen': -258.6746826171875, 'logits/rejected': -1.1148654222488403, 'logits/chosen': -0.9615544080734253, 'epoch': 1.09}


 18%|█▊        | 2930/16104 [13:34:51<63:12:11, 17.27s/it]
{'loss': 0.4097, 'learning_rate': 1.8814111438685742e-06, 'rewards/chosen': -1.4108625650405884, 'rewards/rejected': -2.3068625926971436, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8960001468658447, 'policy_logps/rejected': -414.2138977050781, 'policy_logps/chosen': -426.95928955078125, 'referece_logps/rejected': -391.1452331542969, 'referece_logps/chosen': -412.85064697265625, 'logits/rejected': -0.5956677794456482, 'logits/chosen': -0.606691300868988, 'epoch': 1.09}

 18%|█▊        | 2931/16104 [13:35:13<67:46:21, 18.52s/it]


 18%|█▊        | 2933/16104 [13:35:49<66:36:50, 18.21s/it]

 18%|█▊        | 2934/16104 [13:36:01<59:25:38, 16.24s/it]

 18%|█▊        | 2935/16104 [13:36:15<56:58:39, 15.58s/it]

 18%|█▊        | 2936/16104 [13:36:27<53:05:27, 14.51s/it]
{'loss': 0.641, 'learning_rate': 1.8808404903663311e-06, 'rewards/chosen': -0.9432766437530518, 'rewards/rejected': -1.1894406080245972, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24616394937038422, 'policy_logps/rejected': -358.5877685546875, 'policy_logps/chosen': -550.3981323242188, 'referece_logps/rejected': -346.6933288574219, 'referece_logps/chosen': -540.96533203125, 'logits/rejected': -0.40252530574798584, 'logits/chosen': -0.5425260066986084, 'epoch': 1.09}

 18%|█▊        | 2937/16104 [13:36:41<52:43:43, 14.42s/it]

 18%|█▊        | 2938/16104 [13:37:03<60:55:59, 16.66s/it]

 18%|█▊        | 2939/16104 [13:37:19<60:08:11, 16.44s/it]

 18%|█▊        | 2940/16104 [13:37:33<57:00:36, 15.59s/it]

 18%|█▊        | 2941/16104 [13:37:47<55:59:38, 15.31s/it]

 18%|█▊        | 2942/16104 [13:38:07<60:39:50, 16.59s/it]

 18%|█▊        | 2943/16104 [13:38:26<63:55:14, 17.48s/it]

 18%|█▊        | 2944/16104 [13:38:41<61:14:33, 16.75s/it]

 18%|█▊        | 2945/16104 [13:38:53<55:19:22, 15.14s/it]

 18%|█▊        | 2946/16104 [13:39:15<63:07:12, 17.27s/it]

 18%|█▊        | 2947/16104 [13:39:30<60:07:44, 16.45s/it]

 18%|█▊        | 2948/16104 [13:39:51<65:25:10, 17.90s/it]
[2024-04-06 05:04:26,019] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2949/16104 [13:40:11<68:14:46, 18.68s/it]

 18%|█▊        | 2950/16104 [13:40:22<59:33:47, 16.30s/it]
[2024-04-06 05:04:53,258] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2951/16104 [13:40:39<59:45:14, 16.35s/it]


 18%|█▊        | 2953/16104 [13:41:06<55:39:36, 15.24s/it]
{'loss': 0.5715, 'learning_rate': 1.8792166755709707e-06, 'rewards/chosen': -1.007335901260376, 'rewards/rejected': -1.5084426403045654, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5011066794395447, 'policy_logps/rejected': -533.6000366210938, 'policy_logps/chosen': -443.4134521484375, 'referece_logps/rejected': -518.515625, 'referece_logps/chosen': -433.340087890625, 'logits/rejected': -0.35606175661087036, 'logits/chosen': -0.11003292351961136, 'epoch': 1.1}


 18%|█▊        | 2955/16104 [13:41:32<51:24:40, 14.08s/it]
{'loss': 0.536, 'learning_rate': 1.8790249624167917e-06, 'rewards/chosen': -1.146435022354126, 'rewards/rejected': -2.2706358432769775, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1242008209228516, 'policy_logps/rejected': -246.3860321044922, 'policy_logps/chosen': -419.4698486328125, 'referece_logps/rejected': -223.6796875, 'referece_logps/chosen': -408.0054931640625, 'logits/rejected': -0.9672986268997192, 'logits/chosen': -1.0855209827423096, 'epoch': 1.1}

 18%|█▊        | 2956/16104 [13:41:43<48:45:14, 13.35s/it]

 18%|█▊        | 2957/16104 [13:42:05<57:40:02, 15.79s/it]

 18%|█▊        | 2958/16104 [13:42:26<62:59:30, 17.25s/it]

 18%|█▊        | 2959/16104 [13:42:44<63:59:49, 17.53s/it]


 18%|█▊        | 2961/16104 [13:43:24<68:27:21, 18.75s/it]
{'loss': 0.4294, 'learning_rate': 1.8784489696833806e-06, 'rewards/chosen': -1.491273045539856, 'rewards/rejected': -2.814868688583374, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3235957622528076, 'policy_logps/rejected': -491.56317138671875, 'policy_logps/chosen': -351.73516845703125, 'referece_logps/rejected': -463.41455078125, 'referece_logps/chosen': -336.82244873046875, 'logits/rejected': -1.5062156915664673, 'logits/chosen': -1.1234809160232544, 'epoch': 1.1}

 18%|█▊        | 2962/16104 [13:43:44<69:48:54, 19.12s/it]
[2024-04-06 05:08:20,852] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2963/16104 [13:44:06<73:13:59, 20.06s/it]

 18%|█▊        | 2964/16104 [13:44:17<63:01:01, 17.26s/it]
[2024-04-06 05:08:53,749] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2965/16104 [13:44:39<68:22:16, 18.73s/it]
[2024-04-06 05:09:09,203] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2966/16104 [13:44:55<64:46:33, 17.75s/it]


 18%|█▊        | 2968/16104 [13:45:28<63:28:24, 17.40s/it]
{'loss': 0.6305, 'learning_rate': 1.8777753613855666e-06, 'rewards/chosen': -1.1170310974121094, 'rewards/rejected': -1.237382173538208, 'rewards/accuracies': 0.5, 'rewards/margins': 0.12035100162029266, 'policy_logps/rejected': -314.7587890625, 'policy_logps/chosen': -271.5843505859375, 'referece_logps/rejected': -302.3849792480469, 'referece_logps/chosen': -260.4140625, 'logits/rejected': 0.10394655168056488, 'logits/chosen': 0.22047178447246552, 'epoch': 1.11}

 18%|█▊        | 2969/16104 [13:45:47<65:33:16, 17.97s/it]

 18%|█▊        | 2970/16104 [13:46:05<65:11:35, 17.87s/it]


 18%|█▊        | 2972/16104 [13:46:42<67:17:57, 18.45s/it]
{'loss': 0.4257, 'learning_rate': 1.8773896611058354e-06, 'rewards/chosen': -1.159833312034607, 'rewards/rejected': -3.1356372833251953, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9758039712905884, 'policy_logps/rejected': -422.42840576171875, 'policy_logps/chosen': -454.4866638183594, 'referece_logps/rejected': -391.07208251953125, 'referece_logps/chosen': -442.8883056640625, 'logits/rejected': -0.3739748001098633, 'logits/chosen': -0.33972764015197754, 'epoch': 1.11}

 18%|█▊        | 2973/16104 [13:46:54<60:19:36, 16.54s/it]

 18%|█▊        | 2974/16104 [13:47:05<53:58:09, 14.80s/it]
[2024-04-06 05:11:39,679] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2975/16104 [13:47:25<59:31:09, 16.32s/it]

 18%|█▊        | 2976/16104 [13:47:37<54:35:00, 14.97s/it]

 18%|█▊        | 2977/16104 [13:47:57<60:09:06, 16.50s/it]

 18%|█▊        | 2978/16104 [13:48:18<65:13:56, 17.89s/it]

 18%|█▊        | 2979/16104 [13:48:36<65:21:12, 17.93s/it]

 19%|█▊        | 2980/16104 [13:48:50<60:56:23, 16.72s/it]

 19%|█▊        | 2981/16104 [13:49:09<63:07:54, 17.32s/it]

 19%|█▊        | 2982/16104 [13:49:21<57:17:09, 15.72s/it]

 19%|█▊        | 2983/16104 [13:49:37<58:03:15, 15.93s/it]

 19%|█▊        | 2984/16104 [13:49:54<58:33:48, 16.07s/it]

 19%|█▊        | 2985/16104 [13:50:12<61:18:42, 16.82s/it]

 19%|█▊        | 2986/16104 [13:50:26<58:35:07, 16.08s/it]

 19%|█▊        | 2987/16104 [13:50:46<62:27:02, 17.14s/it]

 19%|█▊        | 2988/16104 [13:51:03<62:35:32, 17.18s/it]
[2024-04-06 05:15:40,542] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 19%|█▊        | 2990/16104 [13:51:46<69:27:30, 19.07s/it]

 19%|█▊        | 2991/16104 [13:52:05<69:38:15, 19.12s/it]

 19%|█▊        | 2992/16104 [13:52:26<71:57:14, 19.76s/it]

 19%|█▊        | 2993/16104 [13:52:42<67:52:55, 18.64s/it]

 19%|█▊        | 2994/16104 [13:52:58<65:24:33, 17.96s/it]

 19%|█▊        | 2995/16104 [13:53:09<57:24:31, 15.77s/it]

 19%|█▊        | 2996/16104 [13:53:23<55:45:22, 15.31s/it]

 19%|█▊        | 2997/16104 [13:53:41<57:52:03, 15.89s/it]

 19%|█▊        | 2998/16104 [13:54:01<62:17:36, 17.11s/it]

 19%|█▊        | 2999/16104 [13:54:18<62:39:04, 17.21s/it]

 19%|█▊        | 3000/16104 [13:54:39<66:21:59, 18.23s/it]

 19%|█▊        | 3001/16104 [13:55:15<86:25:04, 23.74s/it]

 19%|█▊        | 3002/16104 [13:55:35<81:51:14, 22.49s/it]

 19%|█▊        | 3003/16104 [13:55:56<80:39:54, 22.17s/it]

 19%|█▊        | 3004/16104 [13:56:10<71:48:26, 19.73s/it]

 19%|█▊        | 3005/16104 [13:56:23<63:44:14, 17.52s/it]

 19%|█▊        | 3006/16104 [13:56:38<61:22:30, 16.87s/it]

 19%|█▊        | 3007/16104 [13:56:56<62:31:11, 17.18s/it]

 19%|█▊        | 3008/16104 [13:57:13<61:57:59, 17.03s/it]

 19%|█▊        | 3009/16104 [13:57:24<55:53:20, 15.36s/it]

 19%|█▊        | 3010/16104 [13:57:37<52:50:09, 14.53s/it]

 19%|█▊        | 3011/16104 [13:57:59<61:00:29, 16.77s/it]

 19%|█▊        | 3012/16104 [13:58:13<58:47:49, 16.17s/it]

 19%|█▊        | 3013/16104 [13:58:29<58:19:01, 16.04s/it]

 19%|█▊        | 3014/16104 [13:58:43<55:28:40, 15.26s/it]
[2024-04-06 05:22:57,194] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▊        | 3015/16104 [13:58:56<53:13:50, 14.64s/it]

 19%|█▊        | 3016/16104 [13:59:16<59:15:10, 16.30s/it]

 19%|█▊        | 3017/16104 [13:59:40<67:49:07, 18.66s/it]

 19%|█▊        | 3018/16104 [13:59:54<62:14:52, 17.12s/it]

 19%|█▊        | 3019/16104 [14:00:14<65:56:51, 18.14s/it]

 19%|█▉        | 3020/16104 [14:00:31<64:48:47, 17.83s/it]

 19%|█▉        | 3021/16104 [14:00:44<59:35:33, 16.40s/it]

 19%|█▉        | 3022/16104 [14:00:57<55:22:51, 15.24s/it]

 19%|█▉        | 3023/16104 [14:01:12<55:29:46, 15.27s/it]

 19%|█▉        | 3024/16104 [14:01:23<50:43:46, 13.96s/it]

 19%|█▉        | 3025/16104 [14:01:35<48:24:35, 13.32s/it]

 19%|█▉        | 3026/16104 [14:01:57<57:48:12, 15.91s/it]

 19%|█▉        | 3027/16104 [14:02:09<53:50:30, 14.82s/it]

 19%|█▉        | 3028/16104 [14:02:31<62:00:33, 17.07s/it]

 19%|█▉        | 3029/16104 [14:02:42<55:06:05, 15.17s/it]

 19%|█▉        | 3030/16104 [14:03:03<61:01:58, 16.81s/it]

 19%|█▉        | 3031/16104 [14:03:25<66:59:34, 18.45s/it]

 19%|█▉        | 3032/16104 [14:03:38<60:53:02, 16.77s/it]

 19%|█▉        | 3033/16104 [14:03:53<58:36:34, 16.14s/it]

 19%|█▉        | 3034/16104 [14:04:04<53:48:27, 14.82s/it]

 19%|█▉        | 3035/16104 [14:04:25<59:58:22, 16.52s/it]
[2024-04-06 05:28:39,516] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▉        | 3036/16104 [14:04:47<66:20:22, 18.28s/it]

 19%|█▉        | 3037/16104 [14:05:00<59:49:06, 16.48s/it]

 19%|█▉        | 3038/16104 [14:05:19<63:15:13, 17.43s/it]

 19%|█▉        | 3039/16104 [14:05:41<67:59:16, 18.73s/it]

 19%|█▉        | 3040/16104 [14:06:00<68:09:24, 18.78s/it]

 19%|█▉        | 3041/16104 [14:06:16<64:59:04, 17.91s/it]

 19%|█▉        | 3042/16104 [14:06:36<67:43:07, 18.66s/it]

 19%|█▉        | 3043/16104 [14:06:53<65:50:35, 18.15s/it]
[2024-04-06 05:31:07,736] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▉        | 3044/16104 [14:07:13<68:04:32, 18.77s/it]

 19%|█▉        | 3045/16104 [14:07:34<70:21:39, 19.40s/it]
[2024-04-06 05:31:48,809] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▉        | 3046/16104 [14:07:50<66:45:43, 18.41s/it]
[2024-04-06 05:32:04,903] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▉        | 3047/16104 [14:08:10<67:51:32, 18.71s/it]

 19%|█▉        | 3048/16104 [14:08:26<65:15:27, 17.99s/it]

 19%|█▉        | 3049/16104 [14:08:43<63:50:36, 17.61s/it]

 19%|█▉        | 3050/16104 [14:08:59<62:31:14, 17.24s/it]

 19%|█▉        | 3051/16104 [14:09:13<59:24:10, 16.38s/it]

 19%|█▉        | 3052/16104 [14:09:24<53:08:15, 14.66s/it]

 19%|█▉        | 3053/16104 [14:09:42<57:01:33, 15.73s/it]

 19%|█▉        | 3054/16104 [14:09:55<53:36:28, 14.79s/it]

 19%|█▉        | 3055/16104 [14:10:11<54:36:33, 15.07s/it]

 19%|█▉        | 3056/16104 [14:10:29<57:51:01, 15.96s/it]
[2024-04-06 05:34:43,335] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▉        | 3057/16104 [14:10:41<53:51:16, 14.86s/it]

 19%|█▉        | 3058/16104 [14:10:52<49:16:25, 13.60s/it]

 19%|█▉        | 3059/16104 [14:11:02<46:03:37, 12.71s/it]

 19%|█▉        | 3060/16104 [14:11:13<43:57:51, 12.13s/it]
{'loss': 0.3754, 'learning_rate': 1.8687610294384986e-06, 'rewards/chosen': -1.3255425691604614, 'rewards/rejected': -2.7191224098205566, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3935800790786743, 'policy_logps/rejected': -405.4437255859375, 'policy_logps/chosen': -607.23876953125, 'referece_logps/rejected': -378.25250244140625, 'referece_logps/chosen': -593.9833374023438, 'logits/rejected': 0.031153827905654907, 'logits/chosen': -0.06559163331985474, 'epoch': 1.14}


 19%|█▉        | 3062/16104 [14:11:53<58:28:46, 16.14s/it]

 19%|█▉        | 3063/16104 [14:12:12<61:39:20, 17.02s/it]
[2024-04-06 05:36:26,479] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4473, 'learning_rate': 1.8684620590688076e-06, 'rewards/chosen': -0.9699554443359375, 'rewards/rejected': -1.8902182579040527, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9202628135681152, 'policy_logps/rejected': -395.5174560546875, 'policy_logps/chosen': -486.47564697265625, 'referece_logps/rejected': -376.61529541015625, 'referece_logps/chosen': -476.776123046875, 'logits/rejected': -0.01524205133318901, 'logits/chosen': 0.024460740387439728, 'epoch': 1.14}

 19%|█▉        | 3064/16104 [14:12:32<65:13:29, 18.01s/it]


 19%|█▉        | 3066/16104 [14:13:13<69:32:54, 19.20s/it]

 19%|█▉        | 3067/16104 [14:13:33<70:21:52, 19.43s/it]

 19%|█▉        | 3068/16104 [14:13:45<63:02:00, 17.41s/it]
{'loss': 0.5059, 'learning_rate': 1.8679630725563431e-06, 'rewards/chosen': -1.4856784343719482, 'rewards/rejected': -1.9325491189956665, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4468705654144287, 'policy_logps/rejected': -388.15447998046875, 'policy_logps/chosen': -422.5102844238281, 'referece_logps/rejected': -368.82904052734375, 'referece_logps/chosen': -407.6534423828125, 'logits/rejected': -0.5939888954162598, 'logits/chosen': -0.5806740522384644, 'epoch': 1.14}
[2024-04-06 05:38:20,841] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▉        | 3069/16104 [14:14:06<66:43:16, 18.43s/it]

 19%|█▉        | 3070/16104 [14:14:24<66:30:41, 18.37s/it]


 19%|█▉        | 3072/16104 [14:15:06<71:51:14, 19.85s/it]

 19%|█▉        | 3073/16104 [14:15:19<64:41:38, 17.87s/it]

 19%|█▉        | 3074/16104 [14:15:33<60:17:32, 16.66s/it]

 19%|█▉        | 3075/16104 [14:15:49<59:27:59, 16.43s/it]

 19%|█▉        | 3076/16104 [14:16:06<60:12:44, 16.64s/it]

 19%|█▉        | 3077/16104 [14:16:24<61:29:08, 16.99s/it]

 19%|█▉        | 3078/16104 [14:16:38<57:56:53, 16.02s/it]

 19%|█▉        | 3079/16104 [14:16:57<61:44:14, 17.06s/it]

 19%|█▉        | 3080/16104 [14:17:08<54:58:08, 15.19s/it]
{'loss': 0.4656, 'learning_rate': 1.8667619246025526e-06, 'rewards/chosen': -1.5966668128967285, 'rewards/rejected': -2.9211678504943848, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3245009183883667, 'policy_logps/rejected': -300.7762756347656, 'policy_logps/chosen': -360.9754638671875, 'referece_logps/rejected': -271.5645751953125, 'referece_logps/chosen': -345.0087890625, 'logits/rejected': -0.9687550663948059, 'logits/chosen': -0.755252480506897, 'epoch': 1.15}


 19%|█▉        | 3082/16104 [14:17:43<60:07:42, 16.62s/it]
{'loss': 0.4392, 'learning_rate': 1.8665612422188395e-06, 'rewards/chosen': -0.8757274746894836, 'rewards/rejected': -2.5338432788848877, 'rewards/accuracies': 0.625, 'rewards/margins': 1.658116102218628, 'policy_logps/rejected': -445.7274169921875, 'policy_logps/chosen': -440.7590026855469, 'referece_logps/rejected': -420.38897705078125, 'referece_logps/chosen': -432.0017395019531, 'logits/rejected': 0.26784807443618774, 'logits/chosen': 0.32414644956588745, 'epoch': 1.15}

 19%|█▉        | 3083/16104 [14:18:04<65:26:01, 18.09s/it]


 19%|█▉        | 3085/16104 [14:18:35<58:48:59, 16.26s/it]
{'loss': 0.463, 'learning_rate': 1.8662599557488114e-06, 'rewards/chosen': -1.539310336112976, 'rewards/rejected': -2.8212950229644775, 'rewards/accuracies': 0.875, 'rewards/margins': 1.281984567642212, 'policy_logps/rejected': -295.3616943359375, 'policy_logps/chosen': -380.977294921875, 'referece_logps/rejected': -267.14874267578125, 'referece_logps/chosen': -365.58416748046875, 'logits/rejected': -0.4494655728340149, 'logits/chosen': -0.0955515205860138, 'epoch': 1.15}


 19%|█▉        | 3087/16104 [14:18:59<50:38:25, 14.01s/it]

 19%|█▉        | 3088/16104 [14:19:11<48:01:54, 13.28s/it]

 19%|█▉        | 3089/16104 [14:19:24<47:48:48, 13.23s/it]
{'loss': 0.4112, 'learning_rate': 1.8658577498897744e-06, 'rewards/chosen': -1.174487590789795, 'rewards/rejected': -2.7501332759857178, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5756458044052124, 'policy_logps/rejected': -375.2130432128906, 'policy_logps/chosen': -586.8662109375, 'referece_logps/rejected': -347.711669921875, 'referece_logps/chosen': -575.1212768554688, 'logits/rejected': -0.5411707758903503, 'logits/chosen': -0.9708388447761536, 'epoch': 1.15}


 19%|█▉        | 3091/16104 [14:19:48<45:45:13, 12.66s/it]
{'loss': 0.3791, 'learning_rate': 1.8656564367910355e-06, 'rewards/chosen': -0.7171763777732849, 'rewards/rejected': -2.72692608833313, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0097498893737793, 'policy_logps/rejected': -278.70599365234375, 'policy_logps/chosen': -308.0804443359375, 'referece_logps/rejected': -251.43673706054688, 'referece_logps/chosen': -300.90869140625, 'logits/rejected': -0.6553919315338135, 'logits/chosen': -0.5826322436332703, 'epoch': 1.15}


 19%|█▉        | 3093/16104 [14:20:11<44:00:13, 12.18s/it]

 19%|█▉        | 3094/16104 [14:20:26<46:40:35, 12.92s/it]

 19%|█▉        | 3095/16104 [14:20:40<48:50:12, 13.51s/it]

 19%|█▉        | 3096/16104 [14:20:54<49:09:39, 13.61s/it]

 19%|█▉        | 3097/16104 [14:21:07<47:40:46, 13.20s/it]
{'loss': 0.5362, 'learning_rate': 1.8650516572088938e-06, 'rewards/chosen': -1.2055045366287231, 'rewards/rejected': -1.7142852544784546, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5087804794311523, 'policy_logps/rejected': -330.318115234375, 'policy_logps/chosen': -414.57550048828125, 'referece_logps/rejected': -313.17523193359375, 'referece_logps/chosen': -402.52044677734375, 'logits/rejected': -0.6142150163650513, 'logits/chosen': -0.7110326290130615, 'epoch': 1.15}


 19%|█▉        | 3099/16104 [14:21:39<51:56:56, 14.38s/it]
{'loss': 0.5074, 'learning_rate': 1.864849784028269e-06, 'rewards/chosen': -0.8295570611953735, 'rewards/rejected': -1.895985722541809, 'rewards/accuracies': 0.75, 'rewards/margins': 1.066428542137146, 'policy_logps/rejected': -383.381591796875, 'policy_logps/chosen': -430.7803039550781, 'referece_logps/rejected': -364.4217529296875, 'referece_logps/chosen': -422.4847412109375, 'logits/rejected': -0.19955861568450928, 'logits/chosen': -0.0754120796918869, 'epoch': 1.15}


 19%|█▉        | 3101/16104 [14:22:15<60:13:59, 16.68s/it]
{'loss': 0.5197, 'learning_rate': 1.864647770908777e-06, 'rewards/chosen': -0.9534908533096313, 'rewards/rejected': -1.7707788944244385, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8172880411148071, 'policy_logps/rejected': -467.6420593261719, 'policy_logps/chosen': -293.443115234375, 'referece_logps/rejected': -449.93426513671875, 'referece_logps/chosen': -283.9082336425781, 'logits/rejected': -1.207588791847229, 'logits/chosen': -1.1023224592208862, 'epoch': 1.16}

 19%|█▉        | 3102/16104 [14:22:35<64:07:46, 17.76s/it]


 19%|█▉        | 3104/16104 [14:23:06<58:42:50, 16.26s/it]

 19%|█▉        | 3105/16104 [14:23:18<53:41:16, 14.87s/it]

 19%|█▉        | 3106/16104 [14:23:39<60:49:27, 16.85s/it]

 19%|█▉        | 3107/16104 [14:23:55<60:00:30, 16.62s/it]

 19%|█▉        | 3108/16104 [14:24:12<60:40:28, 16.81s/it]

 19%|█▉        | 3109/16104 [14:24:28<58:45:35, 16.28s/it]

 19%|█▉        | 3110/16104 [14:24:47<61:52:16, 17.14s/it]

 19%|█▉        | 3111/16104 [14:25:00<57:32:26, 15.94s/it]

 19%|█▉        | 3112/16104 [14:25:15<56:21:25, 15.62s/it]

 19%|█▉        | 3113/16104 [14:25:35<61:12:39, 16.96s/it]

 19%|█▉        | 3114/16104 [14:25:51<60:38:39, 16.81s/it]
{'loss': 0.3238, 'learning_rate': 1.8633312768818055e-06, 'rewards/chosen': -1.352139949798584, 'rewards/rejected': -3.4653289318084717, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1131887435913086, 'policy_logps/rejected': -290.73321533203125, 'policy_logps/chosen': -295.6830749511719, 'referece_logps/rejected': -256.07989501953125, 'referece_logps/chosen': -282.16168212890625, 'logits/rejected': 0.11039949208498001, 'logits/chosen': 0.049802981317043304, 'epoch': 1.16}


 19%|█▉        | 3116/16104 [14:26:24<59:35:31, 16.52s/it]

 19%|█▉        | 3117/16104 [14:26:37<55:02:04, 15.26s/it]

 19%|█▉        | 3118/16104 [14:26:56<59:55:21, 16.61s/it]

 19%|█▉        | 3119/16104 [14:27:16<63:18:26, 17.55s/it]
{'loss': 0.6044, 'learning_rate': 1.8628233609851893e-06, 'rewards/chosen': -1.4271489381790161, 'rewards/rejected': -1.6583932638168335, 'rewards/accuracies': 0.75, 'rewards/margins': 0.23124435544013977, 'policy_logps/rejected': -374.4873962402344, 'policy_logps/chosen': -375.20343017578125, 'referece_logps/rejected': -357.9034423828125, 'referece_logps/chosen': -360.9319763183594, 'logits/rejected': -1.10379958152771, 'logits/chosen': -1.224847435951233, 'epoch': 1.16}


 19%|█▉        | 3121/16104 [14:27:43<56:17:15, 15.61s/it]

 19%|█▉        | 3122/16104 [14:28:05<63:06:45, 17.50s/it]

 19%|█▉        | 3123/16104 [14:28:24<65:31:36, 18.17s/it]

 19%|█▉        | 3124/16104 [14:28:38<60:50:31, 16.87s/it]

 19%|█▉        | 3125/16104 [14:28:54<60:12:55, 16.70s/it]

 19%|█▉        | 3126/16104 [14:29:10<59:22:40, 16.47s/it]

 19%|█▉        | 3127/16104 [14:29:32<65:07:38, 18.07s/it]

 19%|█▉        | 3128/16104 [14:29:55<69:57:34, 19.41s/it]

 19%|█▉        | 3129/16104 [14:30:12<67:54:30, 18.84s/it]
{'loss': 0.3226, 'learning_rate': 1.8618049120008552e-06, 'rewards/chosen': -0.7647610306739807, 'rewards/rejected': -3.225766658782959, 'rewards/accuracies': 0.875, 'rewards/margins': 2.461005687713623, 'policy_logps/rejected': -282.0230407714844, 'policy_logps/chosen': -315.4152526855469, 'referece_logps/rejected': -249.76535034179688, 'referece_logps/chosen': -307.7676086425781, 'logits/rejected': 0.1176811009645462, 'logits/chosen': 0.19957920908927917, 'epoch': 1.17}


 19%|█▉        | 3131/16104 [14:30:52<70:42:37, 19.62s/it]

 19%|█▉        | 3132/16104 [14:31:13<72:18:45, 20.07s/it]

 19%|█▉        | 3133/16104 [14:31:33<71:35:10, 19.87s/it]
{'loss': 0.4393, 'learning_rate': 1.8613965560529602e-06, 'rewards/chosen': -0.7722747921943665, 'rewards/rejected': -1.6142960786819458, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8420213460922241, 'policy_logps/rejected': -353.5686950683594, 'policy_logps/chosen': -440.14825439453125, 'referece_logps/rejected': -337.42572021484375, 'referece_logps/chosen': -432.4255065917969, 'logits/rejected': -1.1127294301986694, 'logits/chosen': -1.189078450202942, 'epoch': 1.17}


 19%|█▉        | 3135/16104 [14:32:14<72:38:28, 20.16s/it]

 19%|█▉        | 3136/16104 [14:32:28<66:08:16, 18.36s/it]

 19%|█▉        | 3137/16104 [14:32:41<59:56:20, 16.64s/it]

 19%|█▉        | 3138/16104 [14:33:03<65:38:55, 18.23s/it]

 19%|█▉        | 3139/16104 [14:33:22<66:59:30, 18.60s/it]

 19%|█▉        | 3140/16104 [14:33:37<62:38:40, 17.40s/it]

 20%|█▉        | 3141/16104 [14:33:51<58:51:24, 16.35s/it]

 20%|█▉        | 3142/16104 [14:34:05<56:39:16, 15.73s/it]

 20%|█▉        | 3143/16104 [14:34:27<62:58:51, 17.49s/it]

 20%|█▉        | 3144/16104 [14:34:46<65:16:49, 18.13s/it]

 20%|█▉        | 3145/16104 [14:35:06<67:04:04, 18.63s/it]

 20%|█▉        | 3146/16104 [14:35:24<66:35:28, 18.50s/it]

 20%|█▉        | 3147/16104 [14:35:44<67:56:18, 18.88s/it]

 20%|█▉        | 3148/16104 [14:36:01<65:39:28, 18.24s/it]

 20%|█▉        | 3149/16104 [14:36:22<68:59:00, 19.17s/it]

 20%|█▉        | 3150/16104 [14:36:38<65:54:45, 18.32s/it]

 20%|█▉        | 3151/16104 [14:36:59<68:23:32, 19.01s/it]

 20%|█▉        | 3152/16104 [14:37:11<60:33:58, 16.83s/it]
{'loss': 0.5678, 'learning_rate': 1.8594492561843276e-06, 'rewards/chosen': -1.6347370147705078, 'rewards/rejected': -2.0957846641540527, 'rewards/accuracies': 0.5, 'rewards/margins': 0.46104755997657776, 'policy_logps/rejected': -441.22283935546875, 'policy_logps/chosen': -455.5643310546875, 'referece_logps/rejected': -420.2649841308594, 'referece_logps/chosen': -439.21697998046875, 'logits/rejected': -0.6005080938339233, 'logits/chosen': -0.7310541868209839, 'epoch': 1.17}


 20%|█▉        | 3154/16104 [14:37:41<59:02:02, 16.41s/it]
{'loss': 0.635, 'learning_rate': 1.8592435466652613e-06, 'rewards/chosen': -0.6888034343719482, 'rewards/rejected': -1.150733470916748, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4619300067424774, 'policy_logps/rejected': -282.7525329589844, 'policy_logps/chosen': -229.45150756835938, 'referece_logps/rejected': -271.2452087402344, 'referece_logps/chosen': -222.56346130371094, 'logits/rejected': -0.5937070846557617, 'logits/chosen': -0.5724465847015381, 'epoch': 1.18}


 20%|█▉        | 3156/16104 [14:38:04<50:14:22, 13.97s/it]

 20%|█▉        | 3157/16104 [14:38:15<46:39:36, 12.97s/it]
{'loss': 0.4639, 'learning_rate': 1.858934721712561e-06, 'rewards/chosen': -0.5825162529945374, 'rewards/rejected': -1.6611024141311646, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0785861015319824, 'policy_logps/rejected': -416.2678527832031, 'policy_logps/chosen': -529.740966796875, 'referece_logps/rejected': -399.6568603515625, 'referece_logps/chosen': -523.9158325195312, 'logits/rejected': 0.5338109731674194, 'logits/chosen': 0.47719135880470276, 'epoch': 1.18}


 20%|█▉        | 3159/16104 [14:38:36<42:32:22, 11.83s/it]

 20%|█▉        | 3160/16104 [14:38:47<41:16:26, 11.48s/it]
{'loss': 0.4587, 'learning_rate': 1.8586255840508888e-06, 'rewards/chosen': -1.0121691226959229, 'rewards/rejected': -2.2394680976867676, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2272989749908447, 'policy_logps/rejected': -318.4528503417969, 'policy_logps/chosen': -425.1889343261719, 'referece_logps/rejected': -296.0581970214844, 'referece_logps/chosen': -415.0672912597656, 'logits/rejected': -0.7482056617736816, 'logits/chosen': -0.7152314186096191, 'epoch': 1.18}


 20%|█▉        | 3162/16104 [14:39:25<54:34:22, 15.18s/it]

 20%|█▉        | 3163/16104 [14:39:44<59:23:48, 16.52s/it]
{'loss': 0.3124, 'learning_rate': 1.8583161337927917e-06, 'rewards/chosen': -0.792976975440979, 'rewards/rejected': -2.446387767791748, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6534109115600586, 'policy_logps/rejected': -507.49853515625, 'policy_logps/chosen': -345.7857360839844, 'referece_logps/rejected': -483.0346374511719, 'referece_logps/chosen': -337.85595703125, 'logits/rejected': 0.1362975537776947, 'logits/chosen': 0.05683351308107376, 'epoch': 1.18}


 20%|█▉        | 3165/16104 [14:40:16<59:22:23, 16.52s/it]

 20%|█▉        | 3166/16104 [14:40:39<65:43:03, 18.29s/it]
{'loss': 0.3107, 'learning_rate': 1.8580063710509293e-06, 'rewards/chosen': -0.9731582999229431, 'rewards/rejected': -2.6038060188293457, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6306477785110474, 'policy_logps/rejected': -202.54396057128906, 'policy_logps/chosen': -346.39178466796875, 'referece_logps/rejected': -176.50592041015625, 'referece_logps/chosen': -336.66021728515625, 'logits/rejected': -0.9001732468605042, 'logits/chosen': -0.8962518572807312, 'epoch': 1.18}

 20%|█▉        | 3167/16104 [14:41:02<70:45:29, 19.69s/it]


 20%|█▉        | 3169/16104 [14:41:31<60:06:36, 16.73s/it]
{'loss': 0.4618, 'learning_rate': 1.8576962959380759e-06, 'rewards/chosen': -0.7386176586151123, 'rewards/rejected': -1.774799108505249, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0361812114715576, 'policy_logps/rejected': -369.1898193359375, 'policy_logps/chosen': -536.197998046875, 'referece_logps/rejected': -351.44183349609375, 'referece_logps/chosen': -528.811767578125, 'logits/rejected': 0.3460463881492615, 'logits/chosen': 0.31150883436203003, 'epoch': 1.18}


 20%|█▉        | 3171/16104 [14:42:01<56:12:41, 15.65s/it]

 20%|█▉        | 3172/16104 [14:42:12<50:53:55, 14.17s/it]
{'loss': 0.4677, 'learning_rate': 1.8573859085671198e-06, 'rewards/chosen': -1.1260688304901123, 'rewards/rejected': -1.9614986181259155, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8354296088218689, 'policy_logps/rejected': -552.075927734375, 'policy_logps/chosen': -453.6268310546875, 'referece_logps/rejected': -532.4609375, 'referece_logps/chosen': -442.36614990234375, 'logits/rejected': -0.5306246280670166, 'logits/chosen': -0.5349840521812439, 'epoch': 1.18}

 20%|█▉        | 3173/16104 [14:42:30<55:32:11, 15.46s/it]

 20%|█▉        | 3174/16104 [14:42:52<62:40:42, 17.45s/it]


 20%|█▉        | 3176/16104 [14:43:23<57:31:33, 16.02s/it]
{'loss': 0.5326, 'learning_rate': 1.8569715731996784e-06, 'rewards/chosen': -0.6086532473564148, 'rewards/rejected': -1.532423973083496, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9237707853317261, 'policy_logps/rejected': -446.2576599121094, 'policy_logps/chosen': -588.6483154296875, 'referece_logps/rejected': -430.9334411621094, 'referece_logps/chosen': -582.5618286132812, 'logits/rejected': -0.261785089969635, 'logits/chosen': -0.28686901926994324, 'epoch': 1.18}


 20%|█▉        | 3178/16104 [14:44:01<62:30:58, 17.41s/it]

 20%|█▉        | 3179/16104 [14:44:20<63:27:19, 17.67s/it]

 20%|█▉        | 3180/16104 [14:44:40<66:07:13, 18.42s/it]
{'loss': 0.3037, 'learning_rate': 1.8565566831757954e-06, 'rewards/chosen': -1.8534704446792603, 'rewards/rejected': -3.2646028995513916, 'rewards/accuracies': 0.75, 'rewards/margins': 1.411132574081421, 'policy_logps/rejected': -279.0815124511719, 'policy_logps/chosen': -281.48486328125, 'referece_logps/rejected': -246.43548583984375, 'referece_logps/chosen': -262.9501647949219, 'logits/rejected': -0.5249571204185486, 'logits/chosen': -0.48503705859184265, 'epoch': 1.18}

 20%|█▉        | 3181/16104 [14:44:51<58:03:54, 16.18s/it]


 20%|█▉        | 3183/16104 [14:45:18<53:37:59, 14.94s/it]

 20%|█▉        | 3184/16104 [14:45:34<54:51:31, 15.29s/it]

 20%|█▉        | 3185/16104 [14:45:52<57:38:07, 16.06s/it]
{'loss': 0.4106, 'learning_rate': 1.85603729106944e-06, 'rewards/chosen': -1.5341064929962158, 'rewards/rejected': -3.0910539627075195, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5569474697113037, 'policy_logps/rejected': -491.2689514160156, 'policy_logps/chosen': -591.7063598632812, 'referece_logps/rejected': -460.3583984375, 'referece_logps/chosen': -576.3652954101562, 'logits/rejected': -0.8282759189605713, 'logits/chosen': -0.8023726344108582, 'epoch': 1.19}


 20%|█▉        | 3187/16104 [14:46:24<56:09:55, 15.65s/it]
{'loss': 0.4602, 'learning_rate': 1.8558292917998216e-06, 'rewards/chosen': -0.9810071587562561, 'rewards/rejected': -2.0034825801849365, 'rewards/accuracies': 0.875, 'rewards/margins': 1.022475242614746, 'policy_logps/rejected': -730.1380004882812, 'policy_logps/chosen': -565.9024658203125, 'referece_logps/rejected': -710.1032104492188, 'referece_logps/chosen': -556.0923461914062, 'logits/rejected': -0.10958566516637802, 'logits/chosen': 0.0774230808019638, 'epoch': 1.19}

 20%|█▉        | 3188/16104 [14:46:35<50:47:58, 14.16s/it]


 20%|█▉        | 3190/16104 [14:47:13<59:32:09, 16.60s/it]
{'loss': 0.483, 'learning_rate': 1.8555170332572542e-06, 'rewards/chosen': -0.7355156540870667, 'rewards/rejected': -2.6497225761413574, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9142065048217773, 'policy_logps/rejected': -289.44024658203125, 'policy_logps/chosen': -338.58905029296875, 'referece_logps/rejected': -262.9430236816406, 'referece_logps/chosen': -331.23388671875, 'logits/rejected': -0.6037655472755432, 'logits/chosen': -0.6300910115242004, 'epoch': 1.19}

 20%|█▉        | 3191/16104 [14:47:28<57:43:28, 16.09s/it]


 20%|█▉        | 3193/16104 [14:48:08<63:16:46, 17.64s/it]
{'loss': 0.4045, 'learning_rate': 1.8552044632499798e-06, 'rewards/chosen': -0.5760126113891602, 'rewards/rejected': -2.609978675842285, 'rewards/accuracies': 0.875, 'rewards/margins': 2.033966064453125, 'policy_logps/rejected': -325.48663330078125, 'policy_logps/chosen': -345.1952819824219, 'referece_logps/rejected': -299.3868713378906, 'referece_logps/chosen': -339.4351501464844, 'logits/rejected': -0.1640261560678482, 'logits/chosen': -0.23040372133255005, 'epoch': 1.19}


 20%|█▉        | 3195/16104 [14:48:39<60:19:48, 16.82s/it]
{'loss': 0.4832, 'learning_rate': 1.854995910265372e-06, 'rewards/chosen': -1.1057058572769165, 'rewards/rejected': -1.8222010135650635, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7164950370788574, 'policy_logps/rejected': -284.2476501464844, 'policy_logps/chosen': -377.9106750488281, 'referece_logps/rejected': -266.0256652832031, 'referece_logps/chosen': -366.8536071777344, 'logits/rejected': -0.7136275172233582, 'logits/chosen': -0.656736433506012, 'epoch': 1.19}


 20%|█▉        | 3197/16104 [14:49:06<52:55:24, 14.76s/it]
{'loss': 0.4748, 'learning_rate': 1.8547872189363249e-06, 'rewards/chosen': -0.6227622628211975, 'rewards/rejected': -1.5100488662719727, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8872866034507751, 'policy_logps/rejected': -381.2735900878906, 'policy_logps/chosen': -389.8604431152344, 'referece_logps/rejected': -366.1731262207031, 'referece_logps/chosen': -383.63287353515625, 'logits/rejected': 0.2931157052516937, 'logits/chosen': 0.2561236619949341, 'epoch': 1.19}

 20%|█▉        | 3198/16104 [14:49:16<48:35:33, 13.55s/it]

 20%|█▉        | 3199/16104 [14:49:27<45:38:21, 12.73s/it]


 20%|█▉        | 3201/16104 [14:50:02<53:18:50, 14.87s/it]
{'loss': 0.3492, 'learning_rate': 1.8543694213800043e-06, 'rewards/chosen': -0.8583818674087524, 'rewards/rejected': -2.188751220703125, 'rewards/accuracies': 0.875, 'rewards/margins': 1.330369472503662, 'policy_logps/rejected': -422.66766357421875, 'policy_logps/chosen': -386.8352355957031, 'referece_logps/rejected': -400.7801513671875, 'referece_logps/chosen': -378.25140380859375, 'logits/rejected': -0.26842886209487915, 'logits/chosen': -0.22825707495212555, 'epoch': 1.19}


 20%|█▉        | 3203/16104 [14:50:35<56:45:13, 15.84s/it]

 20%|█▉        | 3204/16104 [14:50:56<62:08:26, 17.34s/it]

 20%|█▉        | 3205/16104 [14:51:08<55:44:26, 15.56s/it]

 20%|█▉        | 3206/16104 [14:51:24<57:00:03, 15.91s/it]

 20%|█▉        | 3207/16104 [14:51:42<59:02:43, 16.48s/it]

 20%|█▉        | 3208/16104 [14:51:56<56:03:01, 15.65s/it]
{'loss': 0.3725, 'learning_rate': 1.8536369452298246e-06, 'rewards/chosen': -0.8409461975097656, 'rewards/rejected': -2.611201524734497, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7702553272247314, 'policy_logps/rejected': -202.25991821289062, 'policy_logps/chosen': -591.22998046875, 'referece_logps/rejected': -176.1479034423828, 'referece_logps/chosen': -582.8204956054688, 'logits/rejected': -0.022292792797088623, 'logits/chosen': -0.2786651849746704, 'epoch': 1.2}


 20%|█▉        | 3210/16104 [14:52:24<53:53:35, 15.05s/it]

 20%|█▉        | 3211/16104 [14:52:34<48:30:38, 13.55s/it]

 20%|█▉        | 3212/16104 [14:52:46<46:43:36, 13.05s/it]
{'loss': 0.6095, 'learning_rate': 1.8532176276515534e-06, 'rewards/chosen': -1.3476536273956299, 'rewards/rejected': -1.7553167343139648, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4076633155345917, 'policy_logps/rejected': -438.15826416015625, 'policy_logps/chosen': -399.28375244140625, 'referece_logps/rejected': -420.6050720214844, 'referece_logps/chosen': -385.8072509765625, 'logits/rejected': -0.7383152842521667, 'logits/chosen': -0.6536794304847717, 'epoch': 1.2}


 20%|█▉        | 3214/16104 [14:53:24<58:24:02, 16.31s/it]

 20%|█▉        | 3215/16104 [14:53:38<55:49:55, 15.59s/it]
{'loss': 0.608, 'learning_rate': 1.8529027770541691e-06, 'rewards/chosen': -1.0319130420684814, 'rewards/rejected': -1.2446168661117554, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2127039134502411, 'policy_logps/rejected': -375.97705078125, 'policy_logps/chosen': -473.9705810546875, 'referece_logps/rejected': -363.5308837890625, 'referece_logps/chosen': -463.65142822265625, 'logits/rejected': 0.7923477292060852, 'logits/chosen': 0.7681994438171387, 'epoch': 1.2}


 20%|█▉        | 3217/16104 [14:54:16<63:12:25, 17.66s/it]
{'loss': 0.3396, 'learning_rate': 1.8526927041416407e-06, 'rewards/chosen': -1.1041622161865234, 'rewards/rejected': -2.6442463397979736, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5400841236114502, 'policy_logps/rejected': -342.5484924316406, 'policy_logps/chosen': -372.3974609375, 'referece_logps/rejected': -316.10601806640625, 'referece_logps/chosen': -361.3558654785156, 'logits/rejected': -0.5276200771331787, 'logits/chosen': -0.5702486634254456, 'epoch': 1.2}


 20%|█▉        | 3219/16104 [14:54:48<60:06:21, 16.79s/it]

 20%|█▉        | 3220/16104 [14:55:02<57:18:15, 16.01s/it]
{'loss': 0.3952, 'learning_rate': 1.8523773360864179e-06, 'rewards/chosen': -1.3075323104858398, 'rewards/rejected': -2.63373064994812, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3261983394622803, 'policy_logps/rejected': -299.0250244140625, 'policy_logps/chosen': -428.95928955078125, 'referece_logps/rejected': -272.68768310546875, 'referece_logps/chosen': -415.8839416503906, 'logits/rejected': -0.7699957489967346, 'logits/chosen': -0.7583571076393127, 'epoch': 1.2}


 20%|██        | 3222/16104 [14:55:33<54:42:22, 15.29s/it]

 20%|██        | 3223/16104 [14:55:54<61:24:08, 17.16s/it]
{'loss': 0.3781, 'learning_rate': 1.8520616577095444e-06, 'rewards/chosen': -0.7685575485229492, 'rewards/rejected': -2.271556854248047, 'rewards/accuracies': 0.875, 'rewards/margins': 1.502999186515808, 'policy_logps/rejected': -241.65879821777344, 'policy_logps/chosen': -443.1662902832031, 'referece_logps/rejected': -218.9432373046875, 'referece_logps/chosen': -435.4807434082031, 'logits/rejected': -1.4528661966323853, 'logits/chosen': -1.6365330219268799, 'epoch': 1.2}


 20%|██        | 3225/16104 [14:56:32<64:43:36, 18.09s/it]
{'loss': 0.4696, 'learning_rate': 1.8518510331141285e-06, 'rewards/chosen': -1.2413294315338135, 'rewards/rejected': -1.8341784477233887, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5928490161895752, 'policy_logps/rejected': -334.9806213378906, 'policy_logps/chosen': -543.4500732421875, 'referece_logps/rejected': -316.63885498046875, 'referece_logps/chosen': -531.0367431640625, 'logits/rejected': -0.497964084148407, 'logits/chosen': -0.6944350004196167, 'epoch': 1.2}


 20%|██        | 3227/16104 [14:56:56<53:01:51, 14.83s/it]
{'loss': 0.4814, 'learning_rate': 1.8516402706831365e-06, 'rewards/chosen': -1.1267966032028198, 'rewards/rejected': -2.0604896545410156, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9336931705474854, 'policy_logps/rejected': -332.39263916015625, 'policy_logps/chosen': -322.7738342285156, 'referece_logps/rejected': -311.7877502441406, 'referece_logps/chosen': -311.5058898925781, 'logits/rejected': -0.2157382369041443, 'logits/chosen': -0.1276434361934662, 'epoch': 1.2}


 20%|██        | 3229/16104 [14:57:26<52:14:04, 14.61s/it]
{'loss': 0.625, 'learning_rate': 1.8514293704506706e-06, 'rewards/chosen': -0.6195473074913025, 'rewards/rejected': -1.0947304964065552, 'rewards/accuracies': 0.625, 'rewards/margins': 0.47518327832221985, 'policy_logps/rejected': -466.7510070800781, 'policy_logps/chosen': -530.7245483398438, 'referece_logps/rejected': -455.8037109375, 'referece_logps/chosen': -524.529052734375, 'logits/rejected': 0.37838488817214966, 'logits/chosen': 0.2876237630844116, 'epoch': 1.2}

 20%|██        | 3230/16104 [14:57:37<47:59:28, 13.42s/it]


 20%|██        | 3232/16104 [14:57:58<43:02:17, 12.04s/it]
{'loss': 0.5732, 'learning_rate': 1.851112761798865e-06, 'rewards/chosen': -0.9579304456710815, 'rewards/rejected': -1.2782115936279297, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3202812075614929, 'policy_logps/rejected': -469.3174133300781, 'policy_logps/chosen': -586.8761596679688, 'referece_logps/rejected': -456.5352783203125, 'referece_logps/chosen': -577.2967529296875, 'logits/rejected': -0.7654651999473572, 'logits/chosen': -0.8089553117752075, 'epoch': 1.2}

 20%|██        | 3233/16104 [14:58:15<48:13:56, 13.49s/it]

 20%|██        | 3234/16104 [14:58:29<48:29:25, 13.56s/it]


 20%|██        | 3236/16104 [14:58:57<48:53:34, 13.68s/it]

 20%|██        | 3237/16104 [14:59:14<53:00:53, 14.83s/it]
{'loss': 0.4076, 'learning_rate': 1.8505843921889123e-06, 'rewards/chosen': -1.3893715143203735, 'rewards/rejected': -2.5318682193756104, 'rewards/accuracies': 0.75, 'rewards/margins': 1.142496943473816, 'policy_logps/rejected': -211.46884155273438, 'policy_logps/chosen': -297.51727294921875, 'referece_logps/rejected': -186.15016174316406, 'referece_logps/chosen': -283.62359619140625, 'logits/rejected': -0.5881474018096924, 'logits/chosen': -0.3808305263519287, 'epoch': 1.21}


 20%|██        | 3239/16104 [14:59:40<49:21:37, 13.81s/it]

 20%|██        | 3240/16104 [14:59:53<48:14:24, 13.50s/it]

 20%|██        | 3241/16104 [15:00:12<54:15:56, 15.19s/it]

 20%|██        | 3242/16104 [15:00:24<50:54:18, 14.25s/it]

 20%|██        | 3243/16104 [15:00:37<49:17:22, 13.80s/it]

 20%|██        | 3244/16104 [15:00:58<57:29:59, 16.10s/it]

 20%|██        | 3245/16104 [15:01:21<64:25:36, 18.04s/it]
{'loss': 0.5182, 'learning_rate': 1.849737211837604e-06, 'rewards/chosen': -0.8665603995323181, 'rewards/rejected': -1.329193115234375, 'rewards/accuracies': 0.75, 'rewards/margins': 0.46263277530670166, 'policy_logps/rejected': -470.5906982421875, 'policy_logps/chosen': -454.8764343261719, 'referece_logps/rejected': -457.29876708984375, 'referece_logps/chosen': -446.21087646484375, 'logits/rejected': -0.5304350852966309, 'logits/chosen': -0.6267884969711304, 'epoch': 1.21}

 20%|██        | 3246/16104 [15:01:34<59:11:12, 16.57s/it]


 20%|██        | 3248/16104 [15:02:04<55:43:35, 15.60s/it]
{'loss': 0.5775, 'learning_rate': 1.8494189519271208e-06, 'rewards/chosen': -1.0154117345809937, 'rewards/rejected': -1.818631887435913, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8032200932502747, 'policy_logps/rejected': -230.42816162109375, 'policy_logps/chosen': -334.9224548339844, 'referece_logps/rejected': -212.24183654785156, 'referece_logps/chosen': -324.7683410644531, 'logits/rejected': -0.5881476998329163, 'logits/chosen': -0.628879964351654, 'epoch': 1.21}

 20%|██        | 3249/16104 [15:02:22<58:05:24, 16.27s/it]

 20%|██        | 3250/16104 [15:02:42<61:59:47, 17.36s/it]

 20%|██        | 3251/16104 [15:03:04<67:00:30, 18.77s/it]


 20%|██        | 3253/16104 [15:03:43<68:19:21, 19.14s/it]
{'loss': 0.4045, 'learning_rate': 1.8488878315900224e-06, 'rewards/chosen': -0.8828672170639038, 'rewards/rejected': -1.8811616897583008, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9982943534851074, 'policy_logps/rejected': -529.7721557617188, 'policy_logps/chosen': -417.61053466796875, 'referece_logps/rejected': -510.96051025390625, 'referece_logps/chosen': -408.7818298339844, 'logits/rejected': -0.7178988456726074, 'logits/chosen': -0.5784775614738464, 'epoch': 1.21}

 20%|██        | 3254/16104 [15:03:56<62:05:42, 17.40s/it]

 20%|██        | 3255/16104 [15:04:19<68:20:45, 19.15s/it]

 20%|██        | 3256/16104 [15:04:38<67:24:04, 18.89s/it]

 20%|██        | 3257/16104 [15:04:54<64:45:26, 18.15s/it]

 20%|██        | 3258/16104 [15:05:09<61:36:52, 17.27s/it]

 20%|██        | 3259/16104 [15:05:22<56:54:21, 15.95s/it]

 20%|██        | 3260/16104 [15:05:36<54:03:08, 15.15s/it]

 20%|██        | 3261/16104 [15:05:56<59:26:07, 16.66s/it]


 20%|██        | 3263/16104 [15:06:25<55:39:54, 15.61s/it]
{'loss': 0.3161, 'learning_rate': 1.8478230160269504e-06, 'rewards/chosen': -0.9855605363845825, 'rewards/rejected': -3.5306453704833984, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5450849533081055, 'policy_logps/rejected': -357.5396728515625, 'policy_logps/chosen': -296.8717346191406, 'referece_logps/rejected': -322.23321533203125, 'referece_logps/chosen': -287.01611328125, 'logits/rejected': -0.878747820854187, 'logits/chosen': -0.8031677007675171, 'epoch': 1.22}


 20%|██        | 3265/16104 [15:07:01<60:21:44, 16.93s/it]
{'loss': 0.4547, 'learning_rate': 1.8476096412249457e-06, 'rewards/chosen': -0.7590305209159851, 'rewards/rejected': -1.7752169370651245, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0161864757537842, 'policy_logps/rejected': -301.74951171875, 'policy_logps/chosen': -313.6598205566406, 'referece_logps/rejected': -283.997314453125, 'referece_logps/chosen': -306.0694885253906, 'logits/rejected': 0.008666157722473145, 'logits/chosen': -0.07849382609128952, 'epoch': 1.22}

 20%|██        | 3266/16104 [15:07:22<65:13:34, 18.29s/it]


 20%|██        | 3268/16104 [15:07:57<63:14:07, 17.74s/it]

 20%|██        | 3269/16104 [15:08:09<56:58:08, 15.98s/it]

 20%|██        | 3270/16104 [15:08:25<57:37:39, 16.16s/it]
{'loss': 0.4766, 'learning_rate': 1.8470756042673758e-06, 'rewards/chosen': -1.0113834142684937, 'rewards/rejected': -1.586582899093628, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5751994848251343, 'policy_logps/rejected': -353.3747253417969, 'policy_logps/chosen': -431.1853332519531, 'referece_logps/rejected': -337.5089111328125, 'referece_logps/chosen': -421.0715026855469, 'logits/rejected': -0.3042222857475281, 'logits/chosen': -0.26099300384521484, 'epoch': 1.22}

 20%|██        | 3271/16104 [15:08:38<53:50:35, 15.10s/it]

 20%|██        | 3272/16104 [15:08:51<51:02:33, 14.32s/it]


 20%|██        | 3274/16104 [15:09:17<49:31:17, 13.90s/it]

 20%|██        | 3275/16104 [15:09:33<52:15:55, 14.67s/it]

 20%|██        | 3276/16104 [15:09:47<51:36:35, 14.48s/it]

 20%|██        | 3277/16104 [15:10:07<56:48:05, 15.94s/it]
{'loss': 0.519, 'learning_rate': 1.8463265134878037e-06, 'rewards/chosen': -1.4309093952178955, 'rewards/rejected': -3.087132453918457, 'rewards/accuracies': 0.625, 'rewards/margins': 1.656222939491272, 'policy_logps/rejected': -367.999755859375, 'policy_logps/chosen': -401.32476806640625, 'referece_logps/rejected': -337.12841796875, 'referece_logps/chosen': -387.0157470703125, 'logits/rejected': -1.4270014762878418, 'logits/chosen': -1.3862318992614746, 'epoch': 1.22}

 20%|██        | 3278/16104 [15:10:22<55:51:07, 15.68s/it]


 20%|██        | 3280/16104 [15:10:57<59:45:56, 16.78s/it]
{'loss': 0.5484, 'learning_rate': 1.8460049609643948e-06, 'rewards/chosen': -1.1969702243804932, 'rewards/rejected': -1.97770094871521, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7807306051254272, 'policy_logps/rejected': -376.4737854003906, 'policy_logps/chosen': -296.2178649902344, 'referece_logps/rejected': -356.6968078613281, 'referece_logps/chosen': -284.2481689453125, 'logits/rejected': 0.2078135907649994, 'logits/chosen': 0.3167977035045624, 'epoch': 1.22}


 20%|██        | 3282/16104 [15:11:32<59:49:36, 16.80s/it]
{'loss': 0.4067, 'learning_rate': 1.8457904214961776e-06, 'rewards/chosen': -2.2165441513061523, 'rewards/rejected': -2.7537174224853516, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5371733903884888, 'policy_logps/rejected': -333.5771484375, 'policy_logps/chosen': -327.57366943359375, 'referece_logps/rejected': -306.03997802734375, 'referece_logps/chosen': -305.4082336425781, 'logits/rejected': -0.4955478310585022, 'logits/chosen': -0.45584842562675476, 'epoch': 1.22}


 20%|██        | 3284/16104 [15:12:11<65:58:04, 18.52s/it]
{'loss': 0.3256, 'learning_rate': 1.845575745173034e-06, 'rewards/chosen': -1.6294903755187988, 'rewards/rejected': -3.537860155105591, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9083701372146606, 'policy_logps/rejected': -324.41595458984375, 'policy_logps/chosen': -268.45233154296875, 'referece_logps/rejected': -289.037353515625, 'referece_logps/chosen': -252.15740966796875, 'logits/rejected': -0.3360486626625061, 'logits/chosen': -0.43028101325035095, 'epoch': 1.22}

 20%|██        | 3285/16104 [15:12:33<69:01:56, 19.39s/it]

 20%|██        | 3286/16104 [15:12:53<69:24:20, 19.49s/it]

 20%|██        | 3287/16104 [15:13:07<64:16:46, 18.05s/it]

 20%|██        | 3288/16104 [15:13:18<56:28:46, 15.87s/it]

 20%|██        | 3289/16104 [15:13:40<63:12:07, 17.75s/it]

 20%|██        | 3290/16104 [15:13:56<61:20:51, 17.24s/it]

 20%|██        | 3291/16104 [15:14:15<63:13:45, 17.77s/it]


 20%|██        | 3293/16104 [15:14:48<59:29:48, 16.72s/it]
{'loss': 0.4775, 'learning_rate': 1.8446080090710616e-06, 'rewards/chosen': -1.443408727645874, 'rewards/rejected': -2.028994560241699, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5855855941772461, 'policy_logps/rejected': -711.82568359375, 'policy_logps/chosen': -522.3084716796875, 'referece_logps/rejected': -691.5357666015625, 'referece_logps/chosen': -507.8743896484375, 'logits/rejected': -1.663421869277954, 'logits/chosen': -1.4322161674499512, 'epoch': 1.23}

 20%|██        | 3294/16104 [15:15:06<61:32:57, 17.30s/it]

 20%|██        | 3295/16104 [15:15:26<64:13:13, 18.05s/it]

 20%|██        | 3296/16104 [15:15:38<58:04:05, 16.32s/it]


 20%|██        | 3298/16104 [15:16:08<55:48:51, 15.69s/it]
{'loss': 0.5325, 'learning_rate': 1.8440691818937273e-06, 'rewards/chosen': -1.1003398895263672, 'rewards/rejected': -2.5171761512756348, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4168363809585571, 'policy_logps/rejected': -571.7206420898438, 'policy_logps/chosen': -399.830078125, 'referece_logps/rejected': -546.548828125, 'referece_logps/chosen': -388.82666015625, 'logits/rejected': -0.3136395812034607, 'logits/chosen': -0.1759253889322281, 'epoch': 1.23}

 20%|██        | 3299/16104 [15:16:18<50:31:43, 14.21s/it]

 20%|██        | 3300/16104 [15:16:31<48:34:30, 13.66s/it]

 20%|██        | 3301/16104 [15:16:48<52:56:36, 14.89s/it]


 21%|██        | 3303/16104 [15:17:30<63:24:05, 17.83s/it]
{'loss': 0.4461, 'learning_rate': 1.843529501113846e-06, 'rewards/chosen': -2.454469680786133, 'rewards/rejected': -3.2000231742858887, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7455534934997559, 'policy_logps/rejected': -280.12371826171875, 'policy_logps/chosen': -286.0052795410156, 'referece_logps/rejected': -248.12347412109375, 'referece_logps/chosen': -261.4605407714844, 'logits/rejected': -0.7494106292724609, 'logits/chosen': -0.7136297225952148, 'epoch': 1.23}

 21%|██        | 3304/16104 [15:17:50<65:34:50, 18.44s/it]


 21%|██        | 3306/16104 [15:18:26<64:02:50, 18.02s/it]
{'loss': 0.4733, 'learning_rate': 1.8432052831437019e-06, 'rewards/chosen': -1.1049021482467651, 'rewards/rejected': -2.630936622619629, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5260345935821533, 'policy_logps/rejected': -465.78656005859375, 'policy_logps/chosen': -398.99591064453125, 'referece_logps/rejected': -439.4771728515625, 'referece_logps/chosen': -387.9469299316406, 'logits/rejected': -0.1258293241262436, 'logits/chosen': -0.05240560695528984, 'epoch': 1.23}

 21%|██        | 3307/16104 [15:18:39<58:42:36, 16.52s/it]

 21%|██        | 3308/16104 [15:18:59<61:57:56, 17.43s/it]

 21%|██        | 3309/16104 [15:19:15<61:09:31, 17.21s/it]

 21%|██        | 3310/16104 [15:19:33<61:22:44, 17.27s/it]


 21%|██        | 3312/16104 [15:20:12<65:50:02, 18.53s/it]

 21%|██        | 3313/16104 [15:20:24<58:33:34, 16.48s/it]

 21%|██        | 3314/16104 [15:20:42<60:22:44, 16.99s/it]
{'loss': 0.3872, 'learning_rate': 1.8423392014080028e-06, 'rewards/chosen': -0.7167671322822571, 'rewards/rejected': -1.5409049987792969, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8241377472877502, 'policy_logps/rejected': -297.58447265625, 'policy_logps/chosen': -368.9422607421875, 'referece_logps/rejected': -282.1754455566406, 'referece_logps/chosen': -361.7746276855469, 'logits/rejected': -0.5456589460372925, 'logits/chosen': -0.6182726621627808, 'epoch': 1.23}

 21%|██        | 3315/16104 [15:21:00<61:49:25, 17.40s/it]

 21%|██        | 3316/16104 [15:21:18<62:17:51, 17.54s/it]


 21%|██        | 3318/16104 [15:21:46<55:04:45, 15.51s/it]

 21%|██        | 3319/16104 [15:22:00<53:22:29, 15.03s/it]
{'loss': 0.3262, 'learning_rate': 1.8417967927718381e-06, 'rewards/chosen': -1.2315881252288818, 'rewards/rejected': -2.332874298095703, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1012859344482422, 'policy_logps/rejected': -429.6817321777344, 'policy_logps/chosen': -353.16363525390625, 'referece_logps/rejected': -406.35302734375, 'referece_logps/chosen': -340.8477478027344, 'logits/rejected': -0.21895147860050201, 'logits/chosen': -0.029178600758314133, 'epoch': 1.24}

 21%|██        | 3320/16104 [15:22:19<57:36:15, 16.22s/it]

 21%|██        | 3321/16104 [15:22:37<59:14:13, 16.68s/it]

 21%|██        | 3322/16104 [15:22:49<54:01:52, 15.22s/it]

 21%|██        | 3323/16104 [15:23:01<50:26:20, 14.21s/it]

 21%|██        | 3324/16104 [15:23:21<56:44:21, 15.98s/it]

 21%|██        | 3325/16104 [15:23:33<53:02:33, 14.94s/it]

 21%|██        | 3326/16104 [15:23:53<57:59:19, 16.34s/it]

 21%|██        | 3327/16104 [15:24:05<53:52:36, 15.18s/it]


 21%|██        | 3329/16104 [15:24:46<63:43:38, 17.96s/it]
{'loss': 0.4567, 'learning_rate': 1.8407094221354275e-06, 'rewards/chosen': -1.418914794921875, 'rewards/rejected': -1.9832831621170044, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5643683671951294, 'policy_logps/rejected': -229.45277404785156, 'policy_logps/chosen': -227.6398468017578, 'referece_logps/rejected': -209.6199493408203, 'referece_logps/chosen': -213.45071411132812, 'logits/rejected': -1.278106689453125, 'logits/chosen': -1.3148868083953857, 'epoch': 1.24}

 21%|██        | 3330/16104 [15:25:07<66:57:06, 18.87s/it]

 21%|██        | 3331/16104 [15:25:25<66:03:09, 18.62s/it]

 21%|██        | 3332/16104 [15:25:47<69:29:07, 19.59s/it]


 21%|██        | 3334/16104 [15:26:22<66:33:20, 18.76s/it]
{'loss': 0.4336, 'learning_rate': 1.8401644612348339e-06, 'rewards/chosen': -1.1444206237792969, 'rewards/rejected': -2.5633299350738525, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4189093112945557, 'policy_logps/rejected': -380.9563903808594, 'policy_logps/chosen': -464.9468994140625, 'referece_logps/rejected': -355.3230895996094, 'referece_logps/chosen': -453.50274658203125, 'logits/rejected': -0.18080821633338928, 'logits/chosen': -0.2820587158203125, 'epoch': 1.24}

 21%|██        | 3335/16104 [15:26:37<61:55:37, 17.46s/it]

 21%|██        | 3336/16104 [15:26:54<61:33:01, 17.35s/it]


 21%|██        | 3338/16104 [15:27:33<66:01:47, 18.62s/it]
{'loss': 0.5326, 'learning_rate': 1.839727880737195e-06, 'rewards/chosen': -0.8153547644615173, 'rewards/rejected': -1.3064284324645996, 'rewards/accuracies': 0.75, 'rewards/margins': 0.49107372760772705, 'policy_logps/rejected': -305.9327087402344, 'policy_logps/chosen': -440.417236328125, 'referece_logps/rejected': -292.8684387207031, 'referece_logps/chosen': -432.2637023925781, 'logits/rejected': -1.2118324041366577, 'logits/chosen': -1.2631423473358154, 'epoch': 1.24}

 21%|██        | 3339/16104 [15:27:46<60:23:30, 17.03s/it]


 21%|██        | 3341/16104 [15:28:29<68:14:53, 19.25s/it]
{'loss': 0.4258, 'learning_rate': 1.8394000886793592e-06, 'rewards/chosen': -1.160599708557129, 'rewards/rejected': -2.7507073879241943, 'rewards/accuracies': 0.875, 'rewards/margins': 1.590107798576355, 'policy_logps/rejected': -345.12774658203125, 'policy_logps/chosen': -263.39190673828125, 'referece_logps/rejected': -317.62066650390625, 'referece_logps/chosen': -251.7859344482422, 'logits/rejected': -0.29140207171440125, 'logits/chosen': -0.40407800674438477, 'epoch': 1.24}

 21%|██        | 3342/16104 [15:28:48<68:14:42, 19.25s/it]

 21%|██        | 3343/16104 [15:29:08<68:40:59, 19.38s/it]


 21%|██        | 3345/16104 [15:29:30<54:05:04, 15.26s/it]
{'loss': 0.4637, 'learning_rate': 1.8389625572496597e-06, 'rewards/chosen': -0.9373769760131836, 'rewards/rejected': -1.930647850036621, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9932708740234375, 'policy_logps/rejected': -224.23123168945312, 'policy_logps/chosen': -287.13934326171875, 'referece_logps/rejected': -204.92477416992188, 'referece_logps/chosen': -277.7655944824219, 'logits/rejected': -0.5627481341362, 'logits/chosen': -0.5646999478340149, 'epoch': 1.25}

 21%|██        | 3346/16104 [15:29:41<49:12:49, 13.89s/it]

 21%|██        | 3347/16104 [15:29:52<45:38:09, 12.88s/it]

 21%|██        | 3348/16104 [15:30:02<43:16:14, 12.21s/it]


 21%|██        | 3350/16104 [15:30:37<53:03:01, 14.97s/it]
{'loss': 0.3686, 'learning_rate': 1.8384148794013097e-06, 'rewards/chosen': -1.2835276126861572, 'rewards/rejected': -3.110912561416626, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8273850679397583, 'policy_logps/rejected': -449.5415344238281, 'policy_logps/chosen': -369.30389404296875, 'referece_logps/rejected': -418.4324035644531, 'referece_logps/chosen': -356.4686279296875, 'logits/rejected': -0.23573680222034454, 'logits/chosen': -0.10041198879480362, 'epoch': 1.25}

 21%|██        | 3351/16104 [15:30:57<58:31:35, 16.52s/it]

 21%|██        | 3352/16104 [15:31:19<63:50:44, 18.02s/it]


 21%|██        | 3354/16104 [15:32:01<69:54:42, 19.74s/it]
{'loss': 0.3992, 'learning_rate': 1.8379761266192607e-06, 'rewards/chosen': -0.707764208316803, 'rewards/rejected': -2.074312448501587, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3665482997894287, 'policy_logps/rejected': -403.2968444824219, 'policy_logps/chosen': -452.067626953125, 'referece_logps/rejected': -382.5537109375, 'referece_logps/chosen': -444.989990234375, 'logits/rejected': 0.1550256907939911, 'logits/chosen': 0.04599219560623169, 'epoch': 1.25}

 21%|██        | 3355/16104 [15:32:22<70:52:27, 20.01s/it]

 21%|██        | 3356/16104 [15:32:41<70:43:56, 19.97s/it]

 21%|██        | 3357/16104 [15:32:56<65:22:36, 18.46s/it]

 21%|██        | 3358/16104 [15:33:16<66:33:52, 18.80s/it]

 21%|██        | 3359/16104 [15:33:27<57:58:34, 16.38s/it]


 21%|██        | 3361/16104 [15:33:51<50:31:56, 14.28s/it]
{'loss': 0.3958, 'learning_rate': 1.8372070043630239e-06, 'rewards/chosen': -1.4330873489379883, 'rewards/rejected': -1.493599534034729, 'rewards/accuracies': 0.5, 'rewards/margins': 0.06051217019557953, 'policy_logps/rejected': -413.77386474609375, 'policy_logps/chosen': -390.7938537597656, 'referece_logps/rejected': -398.837890625, 'referece_logps/chosen': -376.46295166015625, 'logits/rejected': 0.011962074786424637, 'logits/chosen': 0.04797539860010147, 'epoch': 1.25}

 21%|██        | 3362/16104 [15:34:04<49:04:32, 13.87s/it]

 21%|██        | 3363/16104 [15:34:17<47:47:56, 13.51s/it]

 21%|██        | 3364/16104 [15:34:27<44:59:56, 12.72s/it]


 21%|██        | 3366/16104 [15:34:53<45:05:20, 12.74s/it]
{'loss': 0.5115, 'learning_rate': 1.836656615238477e-06, 'rewards/chosen': -1.410588026046753, 'rewards/rejected': -2.490838050842285, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0802502632141113, 'policy_logps/rejected': -282.41790771484375, 'policy_logps/chosen': -435.38812255859375, 'referece_logps/rejected': -257.5095520019531, 'referece_logps/chosen': -421.2822570800781, 'logits/rejected': -0.35718291997909546, 'logits/chosen': -0.2648731768131256, 'epoch': 1.25}

 21%|██        | 3367/16104 [15:35:10<50:00:33, 14.13s/it]


 21%|██        | 3369/16104 [15:35:37<48:59:45, 13.85s/it]
{'loss': 0.4463, 'learning_rate': 1.8363259755970864e-06, 'rewards/chosen': -1.582383632659912, 'rewards/rejected': -3.4078640937805176, 'rewards/accuracies': 0.75, 'rewards/margins': 1.825480341911316, 'policy_logps/rejected': -675.0526733398438, 'policy_logps/chosen': -616.2965087890625, 'referece_logps/rejected': -640.9739990234375, 'referece_logps/chosen': -600.47265625, 'logits/rejected': -0.3798920810222626, 'logits/chosen': -0.4878499209880829, 'epoch': 1.26}


 21%|██        | 3371/16104 [15:36:11<54:21:03, 15.37s/it]

 21%|██        | 3372/16104 [15:36:32<59:56:58, 16.95s/it]

 21%|██        | 3373/16104 [15:36:48<59:43:20, 16.89s/it]

 21%|██        | 3374/16104 [15:36:59<53:10:02, 15.04s/it]

 21%|██        | 3375/16104 [15:37:19<58:38:36, 16.59s/it]

 21%|██        | 3376/16104 [15:37:30<52:21:28, 14.81s/it]

 21%|██        | 3377/16104 [15:37:50<58:21:19, 16.51s/it]

 21%|██        | 3378/16104 [15:38:10<61:19:31, 17.35s/it]

 21%|██        | 3379/16104 [15:38:29<63:04:51, 17.85s/it]

 21%|██        | 3380/16104 [15:38:50<66:54:45, 18.93s/it]

 21%|██        | 3381/16104 [15:39:06<63:11:23, 17.88s/it]

 21%|██        | 3382/16104 [15:39:26<66:23:58, 18.79s/it]

 21%|██        | 3383/16104 [15:39:47<67:45:37, 19.18s/it]

 21%|██        | 3384/16104 [15:40:07<68:36:38, 19.42s/it]

 21%|██        | 3385/16104 [15:40:26<68:55:05, 19.51s/it]

 21%|██        | 3386/16104 [15:40:44<67:04:46, 18.99s/it]

 21%|██        | 3387/16104 [15:41:01<64:40:22, 18.31s/it]

 21%|██        | 3388/16104 [15:41:11<56:34:37, 16.02s/it]

 21%|██        | 3389/16104 [15:41:31<60:25:33, 17.11s/it]

 21%|██        | 3390/16104 [15:41:46<57:59:25, 16.42s/it]

 21%|██        | 3391/16104 [15:42:06<61:33:59, 17.43s/it]

 21%|██        | 3392/16104 [15:42:18<55:38:43, 15.76s/it]

 21%|██        | 3393/16104 [15:42:28<50:17:12, 14.24s/it]
{'loss': 0.4645, 'learning_rate': 1.8336699073964823e-06, 'rewards/chosen': -1.083654761314392, 'rewards/rejected': -1.5773072242736816, 'rewards/accuracies': 0.625, 'rewards/margins': 0.49365246295928955, 'policy_logps/rejected': -309.16162109375, 'policy_logps/chosen': -335.6812438964844, 'referece_logps/rejected': -293.3885192871094, 'referece_logps/chosen': -324.8446960449219, 'logits/rejected': -0.09321922063827515, 'logits/chosen': -0.10725706815719604, 'epoch': 1.26}


 21%|██        | 3395/16104 [15:42:59<52:15:23, 14.80s/it]

 21%|██        | 3396/16104 [15:43:19<57:32:58, 16.30s/it]

 21%|██        | 3397/16104 [15:43:36<58:28:55, 16.57s/it]

 21%|██        | 3398/16104 [15:43:49<55:08:00, 15.62s/it]

 21%|██        | 3399/16104 [15:44:04<54:33:47, 15.46s/it]
{'loss': 0.5508, 'learning_rate': 1.8330028528156136e-06, 'rewards/chosen': -1.7268202304840088, 'rewards/rejected': -3.3293862342834473, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6025662422180176, 'policy_logps/rejected': -438.7047119140625, 'policy_logps/chosen': -324.938720703125, 'referece_logps/rejected': -405.4108581542969, 'referece_logps/chosen': -307.6705017089844, 'logits/rejected': -0.7971065044403076, 'logits/chosen': -0.748857855796814, 'epoch': 1.27}


 21%|██        | 3401/16104 [15:44:31<51:03:56, 14.47s/it]

 21%|██        | 3402/16104 [15:44:52<57:00:30, 16.16s/it]

 21%|██        | 3403/16104 [15:45:09<58:17:55, 16.52s/it]

 21%|██        | 3404/16104 [15:45:24<56:59:55, 16.16s/it]

 21%|██        | 3405/16104 [15:45:41<57:12:33, 16.22s/it]

 21%|██        | 3406/16104 [15:45:58<58:29:13, 16.58s/it]

 21%|██        | 3407/16104 [15:46:21<65:24:08, 18.54s/it]

 21%|██        | 3408/16104 [15:46:43<69:23:02, 19.67s/it]

 21%|██        | 3409/16104 [15:46:56<61:40:20, 17.49s/it]

 21%|██        | 3410/16104 [15:47:12<59:47:34, 16.96s/it]

 21%|██        | 3411/16104 [15:47:24<54:52:17, 15.56s/it]

 21%|██        | 3412/16104 [15:47:44<59:09:46, 16.78s/it]

 21%|██        | 3413/16104 [15:48:03<62:17:53, 17.67s/it]

 21%|██        | 3414/16104 [15:48:23<64:31:19, 18.30s/it]

 21%|██        | 3415/16104 [15:48:45<68:08:36, 19.33s/it]

 21%|██        | 3416/16104 [15:48:58<61:30:37, 17.45s/it]

 21%|██        | 3417/16104 [15:49:12<57:40:16, 16.36s/it]

 21%|██        | 3418/16104 [15:49:33<62:54:29, 17.85s/it]

 21%|██        | 3419/16104 [15:49:50<61:38:05, 17.49s/it]

 21%|██        | 3420/16104 [15:50:11<65:57:18, 18.72s/it]

 21%|██        | 3421/16104 [15:50:25<60:34:09, 17.19s/it]

 21%|██        | 3422/16104 [15:50:45<63:12:39, 17.94s/it]

 21%|██▏       | 3423/16104 [15:51:04<65:12:49, 18.51s/it]

 21%|██▏       | 3424/16104 [15:51:25<67:15:48, 19.10s/it]

 21%|██▏       | 3425/16104 [15:51:38<61:26:07, 17.44s/it]

 21%|██▏       | 3426/16104 [15:51:59<64:42:02, 18.37s/it]

 21%|██▏       | 3427/16104 [15:52:12<59:15:24, 16.83s/it]

 21%|██▏       | 3428/16104 [15:52:23<52:39:44, 14.96s/it]

 21%|██▏       | 3429/16104 [15:52:34<48:18:47, 13.72s/it]
{'loss': 0.4674, 'learning_rate': 1.8296494033193528e-06, 'rewards/chosen': -1.1446177959442139, 'rewards/rejected': -2.221498727798462, 'rewards/accuracies': 0.625, 'rewards/margins': 1.076880931854248, 'policy_logps/rejected': -364.150634765625, 'policy_logps/chosen': -421.78912353515625, 'referece_logps/rejected': -341.9356384277344, 'referece_logps/chosen': -410.34295654296875, 'logits/rejected': -0.2273014485836029, 'logits/chosen': -0.16814497113227844, 'epoch': 1.28}

 21%|██▏       | 3430/16104 [15:52:44<45:16:46, 12.86s/it]


 21%|██▏       | 3432/16104 [15:53:05<40:54:55, 11.62s/it]

 21%|██▏       | 3433/16104 [15:53:24<48:19:31, 13.73s/it]

 21%|██▏       | 3434/16104 [15:53:42<52:48:49, 15.01s/it]

 21%|██▏       | 3435/16104 [15:54:04<60:09:18, 17.09s/it]
{'loss': 0.5671, 'learning_rate': 1.8289750849386303e-06, 'rewards/chosen': -1.366034984588623, 'rewards/rejected': -2.8317770957946777, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4657419919967651, 'policy_logps/rejected': -358.0874328613281, 'policy_logps/chosen': -395.05511474609375, 'referece_logps/rejected': -329.76971435546875, 'referece_logps/chosen': -381.394775390625, 'logits/rejected': 0.17050941288471222, 'logits/chosen': 0.24311596155166626, 'epoch': 1.28}

 21%|██▏       | 3436/16104 [15:54:14<53:21:49, 15.16s/it]


 21%|██▏       | 3438/16104 [15:54:48<54:03:31, 15.36s/it]

 21%|██▏       | 3439/16104 [15:55:01<51:54:14, 14.75s/it]

 21%|██▏       | 3440/16104 [15:55:18<53:54:37, 15.33s/it]

 21%|██▏       | 3441/16104 [15:55:30<51:10:27, 14.55s/it]

 21%|██▏       | 3442/16104 [15:55:48<54:22:41, 15.46s/it]

 21%|██▏       | 3443/16104 [15:56:07<58:17:55, 16.58s/it]

 21%|██▏       | 3444/16104 [15:56:23<57:32:15, 16.36s/it]

 21%|██▏       | 3445/16104 [15:56:34<52:17:25, 14.87s/it]

 21%|██▏       | 3446/16104 [15:56:46<48:39:07, 13.84s/it]

 21%|██▏       | 3447/16104 [15:57:05<53:56:14, 15.34s/it]

 21%|██▏       | 3448/16104 [15:57:15<49:07:21, 13.97s/it]

 21%|██▏       | 3449/16104 [15:57:35<55:12:12, 15.70s/it]

 21%|██▏       | 3450/16104 [15:57:55<59:55:28, 17.05s/it]

 21%|██▏       | 3451/16104 [15:58:09<56:22:23, 16.04s/it]

 21%|██▏       | 3452/16104 [15:58:24<55:51:02, 15.89s/it]

 21%|██▏       | 3453/16104 [15:58:43<58:41:17, 16.70s/it]

 21%|██▏       | 3454/16104 [15:59:00<59:10:59, 16.84s/it]

 21%|██▏       | 3455/16104 [15:59:16<58:29:17, 16.65s/it]

 21%|██▏       | 3456/16104 [15:59:33<58:49:55, 16.75s/it]

 21%|██▏       | 3457/16104 [15:59:50<58:39:42, 16.70s/it]

 21%|██▏       | 3458/16104 [16:00:10<61:49:53, 17.60s/it]

 21%|██▏       | 3459/16104 [16:00:27<61:00:43, 17.37s/it]
{'loss': 0.3316, 'learning_rate': 1.8262657491956487e-06, 'rewards/chosen': -0.9281103014945984, 'rewards/rejected': -2.3067662715911865, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3786559104919434, 'policy_logps/rejected': -370.5802001953125, 'policy_logps/chosen': -373.987060546875, 'referece_logps/rejected': -347.5124816894531, 'referece_logps/chosen': -364.7059326171875, 'logits/rejected': -0.20744773745536804, 'logits/chosen': -0.26981037855148315, 'epoch': 1.29}


 21%|██▏       | 3461/16104 [16:01:05<64:46:27, 18.44s/it]
{'loss': 0.3756, 'learning_rate': 1.8260391013228109e-06, 'rewards/chosen': -0.9833757281303406, 'rewards/rejected': -2.3266241550445557, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3432484865188599, 'policy_logps/rejected': -258.1996154785156, 'policy_logps/chosen': -245.9866943359375, 'referece_logps/rejected': -234.93338012695312, 'referece_logps/chosen': -236.15292358398438, 'logits/rejected': -0.27597296237945557, 'logits/chosen': -0.20020407438278198, 'epoch': 1.29}


 22%|██▏       | 3463/16104 [16:01:44<66:18:29, 18.88s/it]

 22%|██▏       | 3464/16104 [16:02:05<68:12:48, 19.43s/it]

 22%|██▏       | 3465/16104 [16:02:24<67:30:42, 19.23s/it]
{'loss': 0.4345, 'learning_rate': 1.825585404636766e-06, 'rewards/chosen': -1.096998929977417, 'rewards/rejected': -1.9901695251464844, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8931704759597778, 'policy_logps/rejected': -382.54559326171875, 'policy_logps/chosen': -500.37542724609375, 'referece_logps/rejected': -362.6439208984375, 'referece_logps/chosen': -489.4053955078125, 'logits/rejected': -0.6196380853652954, 'logits/chosen': -0.5959692001342773, 'epoch': 1.29}


 22%|██▏       | 3467/16104 [16:03:04<69:14:27, 19.73s/it]

 22%|██▏       | 3468/16104 [16:03:25<71:02:48, 20.24s/it]

 22%|██▏       | 3469/16104 [16:03:45<69:49:05, 19.89s/it]

 22%|██▏       | 3470/16104 [16:04:02<66:43:57, 19.02s/it]

 22%|██▏       | 3471/16104 [16:04:22<68:10:10, 19.43s/it]

 22%|██▏       | 3472/16104 [16:04:40<66:32:39, 18.96s/it]

 22%|██▏       | 3473/16104 [16:04:57<65:02:04, 18.54s/it]

 22%|██▏       | 3474/16104 [16:05:16<65:01:34, 18.53s/it]

 22%|██▏       | 3475/16104 [16:05:37<67:51:21, 19.34s/it]
{'loss': 0.3724, 'learning_rate': 1.824448825816772e-06, 'rewards/chosen': -1.2903058528900146, 'rewards/rejected': -3.5191867351531982, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2288806438446045, 'policy_logps/rejected': -420.9303283691406, 'policy_logps/chosen': -248.744873046875, 'referece_logps/rejected': -385.73846435546875, 'referece_logps/chosen': -235.84182739257812, 'logits/rejected': 0.2226654291152954, 'logits/chosen': 0.40690720081329346, 'epoch': 1.29}


 22%|██▏       | 3477/16104 [16:06:12<64:29:07, 18.39s/it]
{'loss': 0.5804, 'learning_rate': 1.8242211097004296e-06, 'rewards/chosen': -0.8887026309967041, 'rewards/rejected': -2.0604588985443115, 'rewards/accuracies': 0.625, 'rewards/margins': 1.171756386756897, 'policy_logps/rejected': -497.38037109375, 'policy_logps/chosen': -440.4140625, 'referece_logps/rejected': -476.77581787109375, 'referece_logps/chosen': -431.52703857421875, 'logits/rejected': 0.17292794585227966, 'logits/chosen': 0.16005873680114746, 'epoch': 1.3}


 22%|██▏       | 3479/16104 [16:06:45<61:15:33, 17.47s/it]

 22%|██▏       | 3480/16104 [16:07:05<64:18:59, 18.34s/it]
{'loss': 0.5086, 'learning_rate': 1.8238792854783281e-06, 'rewards/chosen': -0.8603651523590088, 'rewards/rejected': -1.962463617324829, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1020985841751099, 'policy_logps/rejected': -462.57537841796875, 'policy_logps/chosen': -424.14923095703125, 'referece_logps/rejected': -442.95068359375, 'referece_logps/chosen': -415.5455322265625, 'logits/rejected': -0.55094975233078, 'logits/chosen': -0.4676978588104248, 'epoch': 1.3}


 22%|██▏       | 3482/16104 [16:07:46<67:59:02, 19.39s/it]

 22%|██▏       | 3483/16104 [16:08:01<63:22:58, 18.08s/it]

 22%|██▏       | 3484/16104 [16:08:22<66:50:21, 19.07s/it]

 22%|██▏       | 3485/16104 [16:08:33<58:02:48, 16.56s/it]

 22%|██▏       | 3486/16104 [16:08:44<51:59:37, 14.83s/it]

 22%|██▏       | 3487/16104 [16:08:54<47:44:52, 13.62s/it]

 22%|██▏       | 3488/16104 [16:09:07<46:27:16, 13.26s/it]

 22%|██▏       | 3489/16104 [16:09:19<45:26:05, 12.97s/it]
{'loss': 0.4617, 'learning_rate': 1.8228520136314902e-06, 'rewards/chosen': -1.422877550125122, 'rewards/rejected': -2.0531773567199707, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6302996873855591, 'policy_logps/rejected': -269.3553466796875, 'policy_logps/chosen': -278.5870361328125, 'referece_logps/rejected': -248.82357788085938, 'referece_logps/chosen': -264.3582763671875, 'logits/rejected': -1.0671590566635132, 'logits/chosen': -0.9841725826263428, 'epoch': 1.3}


 22%|██▏       | 3491/16104 [16:10:01<59:34:26, 17.00s/it]

 22%|██▏       | 3492/16104 [16:10:13<54:13:39, 15.48s/it]

 22%|██▏       | 3493/16104 [16:10:25<50:09:36, 14.32s/it]

 22%|██▏       | 3494/16104 [16:10:46<57:39:33, 16.46s/it]
{'loss': 0.4464, 'learning_rate': 1.8222801418302648e-06, 'rewards/chosen': -1.1447254419326782, 'rewards/rejected': -1.3210169076919556, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17629146575927734, 'policy_logps/rejected': -295.5357360839844, 'policy_logps/chosen': -328.6341247558594, 'referece_logps/rejected': -282.3255615234375, 'referece_logps/chosen': -317.1868896484375, 'logits/rejected': -0.5822917222976685, 'logits/chosen': -0.7193416357040405, 'epoch': 1.3}


 22%|██▏       | 3496/16104 [16:11:25<63:20:38, 18.09s/it]

 22%|██▏       | 3497/16104 [16:11:37<56:46:24, 16.21s/it]
{'loss': 0.4259, 'learning_rate': 1.8219366195601247e-06, 'rewards/chosen': -1.1455680131912231, 'rewards/rejected': -1.884033441543579, 'rewards/accuracies': 0.625, 'rewards/margins': 0.738465428352356, 'policy_logps/rejected': -240.92965698242188, 'policy_logps/chosen': -389.5059509277344, 'referece_logps/rejected': -222.08934020996094, 'referece_logps/chosen': -378.05029296875, 'logits/rejected': -0.3057459592819214, 'logits/chosen': -0.4094755947589874, 'epoch': 1.3}


 22%|██▏       | 3499/16104 [16:12:17<63:53:24, 18.25s/it]

 22%|██▏       | 3500/16104 [16:12:37<65:46:12, 18.79s/it]

 22%|██▏       | 3501/16104 [16:13:03<73:03:26, 20.87s/it]

 22%|██▏       | 3502/16104 [16:13:17<66:01:59, 18.86s/it]

 22%|██▏       | 3503/16104 [16:13:28<57:34:43, 16.45s/it]

 22%|██▏       | 3504/16104 [16:13:42<54:52:34, 15.68s/it]

 22%|██▏       | 3505/16104 [16:13:52<49:23:48, 14.11s/it]

 22%|██▏       | 3506/16104 [16:14:03<45:49:24, 13.09s/it]

 22%|██▏       | 3507/16104 [16:14:14<43:55:12, 12.55s/it]

 22%|██▏       | 3508/16104 [16:14:25<42:09:57, 12.05s/it]

 22%|██▏       | 3509/16104 [16:14:37<41:21:40, 11.82s/it]

 22%|██▏       | 3510/16104 [16:14:52<45:15:08, 12.94s/it]

 22%|██▏       | 3511/16104 [16:15:10<50:35:05, 14.46s/it]
{'loss': 0.5966, 'learning_rate': 1.8203295610493964e-06, 'rewards/chosen': -0.9124858379364014, 'rewards/rejected': -1.1604087352752686, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2479228973388672, 'policy_logps/rejected': -385.1937255859375, 'policy_logps/chosen': -443.685302734375, 'referece_logps/rejected': -373.589599609375, 'referece_logps/chosen': -434.5604553222656, 'logits/rejected': 0.4353286921977997, 'logits/chosen': 0.3967009484767914, 'epoch': 1.31}


 22%|██▏       | 3513/16104 [16:15:42<51:33:14, 14.74s/it]
{'loss': 0.4931, 'learning_rate': 1.8200994500239588e-06, 'rewards/chosen': -1.261600136756897, 'rewards/rejected': -1.9781073331832886, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7165071964263916, 'policy_logps/rejected': -283.7843017578125, 'policy_logps/chosen': -264.110107421875, 'referece_logps/rejected': -264.00323486328125, 'referece_logps/chosen': -251.49412536621094, 'logits/rejected': -1.0815006494522095, 'logits/chosen': -1.0278184413909912, 'epoch': 1.31}

 22%|██▏       | 3514/16104 [16:16:02<57:53:03, 16.55s/it]

 22%|██▏       | 3515/16104 [16:16:14<52:37:33, 15.05s/it]


 22%|██▏       | 3517/16104 [16:16:48<54:10:20, 15.49s/it]

 22%|██▏       | 3518/16104 [16:17:06<56:58:11, 16.30s/it]

 22%|██▏       | 3519/16104 [16:17:27<61:59:55, 17.74s/it]

 22%|██▏       | 3520/16104 [16:17:41<58:31:36, 16.74s/it]

 22%|██▏       | 3521/16104 [16:17:57<57:10:35, 16.36s/it]
{'loss': 0.2818, 'learning_rate': 1.8191776793154316e-06, 'rewards/chosen': -1.1338216066360474, 'rewards/rejected': -2.745266914367676, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6114450693130493, 'policy_logps/rejected': -374.9931335449219, 'policy_logps/chosen': -464.72906494140625, 'referece_logps/rejected': -347.5404357910156, 'referece_logps/chosen': -453.390869140625, 'logits/rejected': -1.0282819271087646, 'logits/chosen': -0.856535792350769, 'epoch': 1.31}


 22%|██▏       | 3523/16104 [16:18:26<53:07:50, 15.20s/it]

 22%|██▏       | 3524/16104 [16:18:39<51:15:25, 14.67s/it]
{'loss': 0.4039, 'learning_rate': 1.8188314684077173e-06, 'rewards/chosen': -0.7165237069129944, 'rewards/rejected': -2.9409842491149902, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2244603633880615, 'policy_logps/rejected': -302.7682189941406, 'policy_logps/chosen': -350.68218994140625, 'referece_logps/rejected': -273.3583679199219, 'referece_logps/chosen': -343.5169982910156, 'logits/rejected': -0.4817213714122772, 'logits/chosen': -0.38564708828926086, 'epoch': 1.31}

 22%|██▏       | 3525/16104 [16:18:52<49:24:55, 14.14s/it]


 22%|██▏       | 3527/16104 [16:19:29<56:00:59, 16.03s/it]
{'loss': 0.5988, 'learning_rate': 1.8184849593912644e-06, 'rewards/chosen': -2.093172788619995, 'rewards/rejected': -2.6751246452331543, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5819516777992249, 'policy_logps/rejected': -413.42315673828125, 'policy_logps/chosen': -560.6443481445312, 'referece_logps/rejected': -386.6719055175781, 'referece_logps/chosen': -539.712646484375, 'logits/rejected': 0.6480811834335327, 'logits/chosen': 0.6840168237686157, 'epoch': 1.31}

 22%|██▏       | 3528/16104 [16:19:51<61:41:55, 17.66s/it]


 22%|██▏       | 3530/16104 [16:20:36<70:03:18, 20.06s/it]

 22%|██▏       | 3531/16104 [16:20:56<70:10:20, 20.09s/it]
{'loss': 0.4539, 'learning_rate': 1.8180224838626788e-06, 'rewards/chosen': -0.7554508447647095, 'rewards/rejected': -2.5405900478363037, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7851390838623047, 'policy_logps/rejected': -373.1470947265625, 'policy_logps/chosen': -362.4420471191406, 'referece_logps/rejected': -347.7412109375, 'referece_logps/chosen': -354.8875427246094, 'logits/rejected': -0.42372429370880127, 'logits/chosen': -0.48835164308547974, 'epoch': 1.32}

 22%|██▏       | 3532/16104 [16:21:12<66:13:21, 18.96s/it]


 22%|██▏       | 3534/16104 [16:21:49<66:00:25, 18.90s/it]

 22%|██▏       | 3535/16104 [16:22:07<64:59:12, 18.61s/it]
{'loss': 0.4803, 'learning_rate': 1.817559478886612e-06, 'rewards/chosen': -1.3354134559631348, 'rewards/rejected': -2.7666876316070557, 'rewards/accuracies': 1.0, 'rewards/margins': 1.431274175643921, 'policy_logps/rejected': -446.7085266113281, 'policy_logps/chosen': -525.7743530273438, 'referece_logps/rejected': -419.0416564941406, 'referece_logps/chosen': -512.4202880859375, 'logits/rejected': 0.1600022315979004, 'logits/chosen': 0.20037418603897095, 'epoch': 1.32}

 22%|██▏       | 3536/16104 [16:22:24<63:42:32, 18.25s/it]


 22%|██▏       | 3538/16104 [16:22:53<56:14:42, 16.11s/it]
{'loss': 0.4949, 'learning_rate': 1.81721187788491e-06, 'rewards/chosen': -1.0248498916625977, 'rewards/rejected': -1.881354570388794, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8565047383308411, 'policy_logps/rejected': -335.6460266113281, 'policy_logps/chosen': -342.5955505371094, 'referece_logps/rejected': -316.83245849609375, 'referece_logps/chosen': -332.3470458984375, 'logits/rejected': 0.2984921634197235, 'logits/chosen': 0.2692113518714905, 'epoch': 1.32}


 22%|██▏       | 3540/16104 [16:23:21<51:24:48, 14.73s/it]

 22%|██▏       | 3541/16104 [16:23:43<58:57:03, 16.89s/it]

 22%|██▏       | 3542/16104 [16:24:00<58:39:40, 16.81s/it]

 22%|██▏       | 3543/16104 [16:24:18<60:11:46, 17.25s/it]

 22%|██▏       | 3544/16104 [16:24:33<57:58:09, 16.62s/it]

 22%|██▏       | 3545/16104 [16:24:44<51:43:00, 14.82s/it]
{'loss': 0.4256, 'learning_rate': 1.8163996520811442e-06, 'rewards/chosen': -1.4528465270996094, 'rewards/rejected': -2.320279121398926, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8674325942993164, 'policy_logps/rejected': -376.0098571777344, 'policy_logps/chosen': -331.8137512207031, 'referece_logps/rejected': -352.8070983886719, 'referece_logps/chosen': -317.2852783203125, 'logits/rejected': -1.102155327796936, 'logits/chosen': -1.2137527465820312, 'epoch': 1.32}


 22%|██▏       | 3547/16104 [16:25:11<49:39:22, 14.24s/it]

 22%|██▏       | 3548/16104 [16:25:26<50:13:05, 14.40s/it]

 22%|██▏       | 3549/16104 [16:25:42<51:24:46, 14.74s/it]
{'loss': 0.4896, 'learning_rate': 1.8159347964010433e-06, 'rewards/chosen': -1.5351181030273438, 'rewards/rejected': -2.247612237930298, 'rewards/accuracies': 0.375, 'rewards/margins': 0.7124939560890198, 'policy_logps/rejected': -338.1717529296875, 'policy_logps/chosen': -365.583740234375, 'referece_logps/rejected': -315.6956787109375, 'referece_logps/chosen': -350.2325439453125, 'logits/rejected': -0.4922650158405304, 'logits/chosen': -0.5302132368087769, 'epoch': 1.32}

 22%|██▏       | 3550/16104 [16:26:01<56:06:23, 16.09s/it]


 22%|██▏       | 3552/16104 [16:26:44<66:11:05, 18.98s/it]

 22%|██▏       | 3553/16104 [16:27:03<66:36:58, 19.11s/it]

 22%|██▏       | 3554/16104 [16:27:20<64:30:26, 18.50s/it]

 22%|██▏       | 3555/16104 [16:27:37<62:55:16, 18.05s/it]

 22%|██▏       | 3556/16104 [16:27:58<65:04:41, 18.67s/it]

 22%|██▏       | 3557/16104 [16:28:10<58:08:20, 16.68s/it]

 22%|██▏       | 3558/16104 [16:28:26<58:01:46, 16.65s/it]
{'loss': 0.3586, 'learning_rate': 1.8148869407277352e-06, 'rewards/chosen': -1.0827739238739014, 'rewards/rejected': -3.5307822227478027, 'rewards/accuracies': 0.75, 'rewards/margins': 2.4480085372924805, 'policy_logps/rejected': -711.1334838867188, 'policy_logps/chosen': -345.14208984375, 'referece_logps/rejected': -675.8256225585938, 'referece_logps/chosen': -334.3143615722656, 'logits/rejected': -1.4705506563186646, 'logits/chosen': -1.0673874616622925, 'epoch': 1.33}

 22%|██▏       | 3559/16104 [16:28:37<52:12:59, 14.98s/it]

 22%|██▏       | 3560/16104 [16:28:49<49:01:05, 14.07s/it]


 22%|██▏       | 3562/16104 [16:29:26<56:25:33, 16.20s/it]

 22%|██▏       | 3563/16104 [16:29:43<57:11:35, 16.42s/it]
{'loss': 0.481, 'learning_rate': 1.814303644740092e-06, 'rewards/chosen': -1.580811619758606, 'rewards/rejected': -1.8546421527862549, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2738306224346161, 'policy_logps/rejected': -373.6249084472656, 'policy_logps/chosen': -333.09783935546875, 'referece_logps/rejected': -355.0784606933594, 'referece_logps/chosen': -317.2897033691406, 'logits/rejected': -0.6432323455810547, 'logits/chosen': -0.6346717476844788, 'epoch': 1.33}


 22%|██▏       | 3565/16104 [16:30:20<61:14:38, 17.58s/it]

 22%|██▏       | 3566/16104 [16:30:42<65:49:00, 18.90s/it]

 22%|██▏       | 3567/16104 [16:31:04<68:53:42, 19.78s/it]

 22%|██▏       | 3568/16104 [16:31:26<70:37:22, 20.28s/it]

 22%|██▏       | 3569/16104 [16:31:44<68:25:51, 19.65s/it]
{'loss': 0.4556, 'learning_rate': 1.8136026025858042e-06, 'rewards/chosen': -0.7342514991760254, 'rewards/rejected': -2.4561452865600586, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7218940258026123, 'policy_logps/rejected': -276.3242492675781, 'policy_logps/chosen': -315.68426513671875, 'referece_logps/rejected': -251.76278686523438, 'referece_logps/chosen': -308.3417663574219, 'logits/rejected': -0.7451873421669006, 'logits/chosen': -0.6602886319160461, 'epoch': 1.33}

 22%|██▏       | 3570/16104 [16:31:59<63:53:19, 18.35s/it]


 22%|██▏       | 3572/16104 [16:32:42<69:34:02, 19.98s/it]
{'loss': 0.3929, 'learning_rate': 1.8132516371371974e-06, 'rewards/chosen': -1.4158883094787598, 'rewards/rejected': -2.931985855102539, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5160973072052002, 'policy_logps/rejected': -462.96795654296875, 'policy_logps/chosen': -454.3819580078125, 'referece_logps/rejected': -433.6481018066406, 'referece_logps/chosen': -440.22308349609375, 'logits/rejected': 0.2581489682197571, 'logits/chosen': 0.43948888778686523, 'epoch': 1.33}

 22%|██▏       | 3573/16104 [16:33:03<71:09:51, 20.44s/it]


 22%|██▏       | 3575/16104 [16:33:36<62:42:50, 18.02s/it]
{'loss': 0.3345, 'learning_rate': 1.812900375611279e-06, 'rewards/chosen': -1.1800775527954102, 'rewards/rejected': -3.1570897102355957, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9770121574401855, 'policy_logps/rejected': -324.19085693359375, 'policy_logps/chosen': -264.1479797363281, 'referece_logps/rejected': -292.61993408203125, 'referece_logps/chosen': -252.34719848632812, 'logits/rejected': -0.5811509490013123, 'logits/chosen': -0.6704741716384888, 'epoch': 1.33}


 22%|██▏       | 3577/16104 [16:34:06<56:37:27, 16.27s/it]

 22%|██▏       | 3578/16104 [16:34:26<60:16:04, 17.32s/it]

 22%|██▏       | 3579/16104 [16:34:39<55:37:06, 15.99s/it]
{'loss': 0.4797, 'learning_rate': 1.812431566566394e-06, 'rewards/chosen': -1.4951057434082031, 'rewards/rejected': -1.6378159523010254, 'rewards/accuracies': 0.375, 'rewards/margins': 0.14271023869514465, 'policy_logps/rejected': -417.2087707519531, 'policy_logps/chosen': -347.9974670410156, 'referece_logps/rejected': -400.8305969238281, 'referece_logps/chosen': -333.04638671875, 'logits/rejected': 0.676159143447876, 'logits/chosen': 0.6589406132698059, 'epoch': 1.33}

 22%|██▏       | 3580/16104 [16:34:51<51:52:33, 14.91s/it]

 22%|██▏       | 3581/16104 [16:35:10<55:30:30, 15.96s/it]


 22%|██▏       | 3583/16104 [16:35:46<59:29:33, 17.11s/it]
{'loss': 0.4748, 'learning_rate': 1.811962231692629e-06, 'rewards/chosen': -1.8061981201171875, 'rewards/rejected': -2.71632719039917, 'rewards/accuracies': 0.875, 'rewards/margins': 0.910129189491272, 'policy_logps/rejected': -491.81365966796875, 'policy_logps/chosen': -407.5025939941406, 'referece_logps/rejected': -464.650390625, 'referece_logps/chosen': -389.44061279296875, 'logits/rejected': 0.2922663390636444, 'logits/chosen': 0.26142972707748413, 'epoch': 1.33}


 22%|██▏       | 3585/16104 [16:36:20<59:20:04, 17.06s/it]

 22%|██▏       | 3586/16104 [16:36:40<62:23:56, 17.95s/it]

 22%|██▏       | 3587/16104 [16:36:58<62:25:18, 17.95s/it]

 22%|██▏       | 3588/16104 [16:37:18<64:34:27, 18.57s/it]

 22%|██▏       | 3589/16104 [16:37:32<60:22:52, 17.37s/it]

 22%|██▏       | 3590/16104 [16:37:45<55:04:36, 15.84s/it]

 22%|██▏       | 3591/16104 [16:38:05<59:44:33, 17.19s/it]
{'loss': 0.5605, 'learning_rate': 1.8110219856738684e-06, 'rewards/chosen': -1.9835516214370728, 'rewards/rejected': -1.9996079206466675, 'rewards/accuracies': 0.375, 'rewards/margins': 0.016056232154369354, 'policy_logps/rejected': -386.9622497558594, 'policy_logps/chosen': -511.8491516113281, 'referece_logps/rejected': -366.9661865234375, 'referece_logps/chosen': -492.01361083984375, 'logits/rejected': 0.24027180671691895, 'logits/chosen': 0.2713637351989746, 'epoch': 1.34}


 22%|██▏       | 3593/16104 [16:38:43<63:34:00, 18.29s/it]

 22%|██▏       | 3594/16104 [16:38:58<60:36:41, 17.44s/it]
{'loss': 0.4491, 'learning_rate': 1.810668851965802e-06, 'rewards/chosen': -0.7384496331214905, 'rewards/rejected': -2.3794333934783936, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6409838199615479, 'policy_logps/rejected': -284.4466552734375, 'policy_logps/chosen': -445.81146240234375, 'referece_logps/rejected': -260.65234375, 'referece_logps/chosen': -438.427001953125, 'logits/rejected': -1.129897117614746, 'logits/chosen': -1.1993744373321533, 'epoch': 1.34}


 22%|██▏       | 3596/16104 [16:39:29<56:20:23, 16.22s/it]

 22%|██▏       | 3597/16104 [16:39:47<57:41:55, 16.61s/it]

 22%|██▏       | 3598/16104 [16:40:03<57:17:22, 16.49s/it]
{'loss': 0.4667, 'learning_rate': 1.8101975479419387e-06, 'rewards/chosen': -1.2265613079071045, 'rewards/rejected': -1.5872031450271606, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3606416881084442, 'policy_logps/rejected': -430.6716613769531, 'policy_logps/chosen': -453.4967346191406, 'referece_logps/rejected': -414.7995910644531, 'referece_logps/chosen': -441.2311096191406, 'logits/rejected': 0.46790385246276855, 'logits/chosen': 0.4616163671016693, 'epoch': 1.34}


 22%|██▏       | 3600/16104 [16:40:43<63:02:44, 18.15s/it]

 22%|██▏       | 3601/16104 [16:41:01<63:22:50, 18.25s/it]

 22%|██▏       | 3602/16104 [16:41:14<58:06:46, 16.73s/it]
{'loss': 0.3706, 'learning_rate': 1.809725719535116e-06, 'rewards/chosen': -1.1528595685958862, 'rewards/rejected': -3.2314631938934326, 'rewards/accuracies': 1.0, 'rewards/margins': 2.078603744506836, 'policy_logps/rejected': -372.1912841796875, 'policy_logps/chosen': -521.914306640625, 'referece_logps/rejected': -339.8766784667969, 'referece_logps/chosen': -510.38568115234375, 'logits/rejected': -0.12184485793113708, 'logits/chosen': -0.19355912506580353, 'epoch': 1.34}

 22%|██▏       | 3603/16104 [16:41:32<59:03:28, 17.01s/it]


 22%|██▏       | 3605/16104 [16:42:13<65:41:00, 18.92s/it]

 22%|██▏       | 3606/16104 [16:42:26<59:41:08, 17.19s/it]
{'loss': 0.415, 'learning_rate': 1.8092533670507156e-06, 'rewards/chosen': -1.604334831237793, 'rewards/rejected': -2.625903844833374, 'rewards/accuracies': 1.0, 'rewards/margins': 1.021569013595581, 'policy_logps/rejected': -286.6051330566406, 'policy_logps/chosen': -308.0648193359375, 'referece_logps/rejected': -260.3460998535156, 'referece_logps/chosen': -292.021484375, 'logits/rejected': -0.8414639234542847, 'logits/chosen': -0.7029021382331848, 'epoch': 1.34}

 22%|██▏       | 3607/16104 [16:42:46<62:29:27, 18.00s/it]


 22%|██▏       | 3609/16104 [16:43:17<56:46:56, 16.36s/it]

 22%|██▏       | 3610/16104 [16:43:39<62:43:25, 18.07s/it]
{'loss': 0.4257, 'learning_rate': 1.8087804907944562e-06, 'rewards/chosen': -1.360344409942627, 'rewards/rejected': -2.2660531997680664, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9057090282440186, 'policy_logps/rejected': -472.34075927734375, 'policy_logps/chosen': -326.7643737792969, 'referece_logps/rejected': -449.6802062988281, 'referece_logps/chosen': -313.1609191894531, 'logits/rejected': 0.12505638599395752, 'logits/chosen': 0.2468443363904953, 'epoch': 1.35}

 22%|██▏       | 3611/16104 [16:43:58<63:31:39, 18.31s/it]


 22%|██▏       | 3613/16104 [16:44:35<65:04:06, 18.75s/it]

 22%|██▏       | 3614/16104 [16:44:51<61:51:28, 17.83s/it]
{'loss': 0.5357, 'learning_rate': 1.8083070910723977e-06, 'rewards/chosen': -1.4892667531967163, 'rewards/rejected': -1.985478162765503, 'rewards/accuracies': 0.75, 'rewards/margins': 0.49621132016181946, 'policy_logps/rejected': -429.58868408203125, 'policy_logps/chosen': -396.1092529296875, 'referece_logps/rejected': -409.73394775390625, 'referece_logps/chosen': -381.2165832519531, 'logits/rejected': -0.03893309459090233, 'logits/chosen': 0.22956451773643494, 'epoch': 1.35}

 22%|██▏       | 3615/16104 [16:45:10<63:41:11, 18.36s/it]


 22%|██▏       | 3617/16104 [16:45:32<50:42:12, 14.62s/it]

 22%|██▏       | 3618/16104 [16:45:45<48:39:10, 14.03s/it]
{'loss': 0.4316, 'learning_rate': 1.8078331681909377e-06, 'rewards/chosen': -1.0162557363510132, 'rewards/rejected': -2.4257941246032715, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4095385074615479, 'policy_logps/rejected': -369.2804870605469, 'policy_logps/chosen': -411.5562438964844, 'referece_logps/rejected': -345.0225524902344, 'referece_logps/chosen': -401.3936767578125, 'logits/rejected': -0.36264941096305847, 'logits/chosen': -0.24751552939414978, 'epoch': 1.35}


 22%|██▏       | 3620/16104 [16:46:09<45:26:23, 13.10s/it]
{'loss': 0.4893, 'learning_rate': 1.8075960106612737e-06, 'rewards/chosen': -1.2776529788970947, 'rewards/rejected': -1.864776849746704, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5871239900588989, 'policy_logps/rejected': -430.4892578125, 'policy_logps/chosen': -386.2826232910156, 'referece_logps/rejected': -411.8415222167969, 'referece_logps/chosen': -373.5061340332031, 'logits/rejected': -1.0945627689361572, 'logits/chosen': -0.7251603603363037, 'epoch': 1.35}

 22%|██▏       | 3621/16104 [16:46:26<49:44:20, 14.34s/it]


 22%|██▏       | 3623/16104 [16:47:01<54:21:38, 15.68s/it]
{'loss': 0.4287, 'learning_rate': 1.8072400293635299e-06, 'rewards/chosen': -0.9891809821128845, 'rewards/rejected': -2.5199978351593018, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5308167934417725, 'policy_logps/rejected': -275.2977294921875, 'policy_logps/chosen': -537.0387573242188, 'referece_logps/rejected': -250.09774780273438, 'referece_logps/chosen': -527.1469116210938, 'logits/rejected': -0.6097656488418579, 'logits/chosen': -0.6471223831176758, 'epoch': 1.35}

 23%|██▎       | 3624/16104 [16:47:18<55:32:43, 16.02s/it]

 23%|██▎       | 3625/16104 [16:47:33<54:19:35, 15.67s/it]

 23%|██▎       | 3626/16104 [16:47:48<54:08:17, 15.62s/it]

 23%|██▎       | 3627/16104 [16:48:07<56:55:59, 16.43s/it]

 23%|██▎       | 3628/16104 [16:48:29<62:58:51, 18.17s/it]

 23%|██▎       | 3629/16104 [16:48:49<64:32:38, 18.63s/it]

 23%|██▎       | 3630/16104 [16:49:01<57:39:33, 16.64s/it]

 23%|██▎       | 3631/16104 [16:49:14<54:12:48, 15.65s/it]

 23%|██▎       | 3632/16104 [16:49:34<59:15:52, 17.11s/it]

 23%|██▎       | 3633/16104 [16:49:55<62:45:49, 18.12s/it]

 23%|██▎       | 3634/16104 [16:50:14<63:55:08, 18.45s/it]

 23%|██▎       | 3635/16104 [16:50:34<65:33:24, 18.93s/it]


 23%|██▎       | 3637/16104 [16:51:04<57:26:49, 16.59s/it]
{'loss': 0.4723, 'learning_rate': 1.8055748995431252e-06, 'rewards/chosen': -1.1853325366973877, 'rewards/rejected': -2.2045934200286865, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0192607641220093, 'policy_logps/rejected': -317.1870422363281, 'policy_logps/chosen': -305.55718994140625, 'referece_logps/rejected': -295.1410827636719, 'referece_logps/chosen': -293.703857421875, 'logits/rejected': 0.15385456383228302, 'logits/chosen': 0.04988006874918938, 'epoch': 1.36}

 23%|██▎       | 3638/16104 [16:51:15<51:44:36, 14.94s/it]


 23%|██▎       | 3640/16104 [16:51:52<56:53:16, 16.43s/it]
{'loss': 0.5913, 'learning_rate': 1.8052172545928932e-06, 'rewards/chosen': -1.28274667263031, 'rewards/rejected': -1.7315778732299805, 'rewards/accuracies': 0.75, 'rewards/margins': 0.448831170797348, 'policy_logps/rejected': -402.19439697265625, 'policy_logps/chosen': -305.6954040527344, 'referece_logps/rejected': -384.8786315917969, 'referece_logps/chosen': -292.867919921875, 'logits/rejected': -0.17078399658203125, 'logits/chosen': -0.03964786231517792, 'epoch': 1.36}


 23%|██▎       | 3642/16104 [16:52:30<62:12:11, 17.97s/it]

 23%|██▎       | 3643/16104 [16:52:52<66:26:08, 19.19s/it]
{'loss': 0.4212, 'learning_rate': 1.8048593164903957e-06, 'rewards/chosen': -1.154130220413208, 'rewards/rejected': -2.4066970348358154, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2525670528411865, 'policy_logps/rejected': -230.53854370117188, 'policy_logps/chosen': -303.4056701660156, 'referece_logps/rejected': -206.47158813476562, 'referece_logps/chosen': -291.8643798828125, 'logits/rejected': -0.77811598777771, 'logits/chosen': -0.7977362871170044, 'epoch': 1.36}

 23%|██▎       | 3644/16104 [16:53:10<65:49:08, 19.02s/it]

 23%|██▎       | 3645/16104 [16:53:23<58:47:43, 16.99s/it]

 23%|██▎       | 3646/16104 [16:53:36<55:20:47, 15.99s/it]

 23%|██▎       | 3647/16104 [16:53:56<59:20:35, 17.15s/it]


 23%|██▎       | 3649/16104 [16:54:32<60:10:50, 17.39s/it]
{'loss': 0.3822, 'learning_rate': 1.8041425613499626e-06, 'rewards/chosen': -1.4684582948684692, 'rewards/rejected': -2.902202606201172, 'rewards/accuracies': 0.875, 'rewards/margins': 1.433744192123413, 'policy_logps/rejected': -258.2176513671875, 'policy_logps/chosen': -410.88702392578125, 'referece_logps/rejected': -229.19561767578125, 'referece_logps/chosen': -396.20245361328125, 'logits/rejected': -0.12072636187076569, 'logits/chosen': -0.165781170129776, 'epoch': 1.36}


 23%|██▎       | 3651/16104 [16:55:06<60:51:37, 17.59s/it]

 23%|██▎       | 3652/16104 [16:55:22<59:08:41, 17.10s/it]

 23%|██▎       | 3653/16104 [16:55:40<60:14:11, 17.42s/it]

 23%|██▎       | 3654/16104 [16:55:54<56:27:47, 16.33s/it]
{'loss': 0.6689, 'learning_rate': 1.8035443708078157e-06, 'rewards/chosen': -1.3398847579956055, 'rewards/rejected': -1.9435627460479736, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6036780476570129, 'policy_logps/rejected': -339.9639587402344, 'policy_logps/chosen': -453.52001953125, 'referece_logps/rejected': -320.5283203125, 'referece_logps/chosen': -440.1211853027344, 'logits/rejected': 0.022700710222125053, 'logits/chosen': -0.12073332071304321, 'epoch': 1.36}

 23%|██▎       | 3655/16104 [16:56:05<50:55:42, 14.73s/it]

 23%|██▎       | 3656/16104 [16:56:16<47:00:09, 13.59s/it]


 23%|██▎       | 3658/16104 [16:56:38<42:50:23, 12.39s/it]
{'loss': 0.5032, 'learning_rate': 1.803065233258614e-06, 'rewards/chosen': -1.0840187072753906, 'rewards/rejected': -2.072784185409546, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9887655377388, 'policy_logps/rejected': -506.1571350097656, 'policy_logps/chosen': -433.95355224609375, 'referece_logps/rejected': -485.4293212890625, 'referece_logps/chosen': -423.11334228515625, 'logits/rejected': -0.19827547669410706, 'logits/chosen': -0.2605292797088623, 'epoch': 1.36}


 23%|██▎       | 3660/16104 [16:57:00<40:09:47, 11.62s/it]
{'loss': 0.534, 'learning_rate': 1.8028254695520968e-06, 'rewards/chosen': -1.696571946144104, 'rewards/rejected': -2.0260796546936035, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3295077085494995, 'policy_logps/rejected': -375.5318603515625, 'policy_logps/chosen': -441.44384765625, 'referece_logps/rejected': -355.27105712890625, 'referece_logps/chosen': -424.47808837890625, 'logits/rejected': -0.5209928750991821, 'logits/chosen': -0.8484763503074646, 'epoch': 1.36}

 23%|██▎       | 3661/16104 [16:57:11<39:54:32, 11.55s/it]

 23%|██▎       | 3662/16104 [16:57:27<44:47:40, 12.96s/it]

 23%|██▎       | 3663/16104 [16:57:45<49:25:13, 14.30s/it]


 23%|██▎       | 3665/16104 [16:58:12<47:16:40, 13.68s/it]
{'loss': 0.3653, 'learning_rate': 1.802225492045577e-06, 'rewards/chosen': -1.3775441646575928, 'rewards/rejected': -2.5058631896972656, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1283191442489624, 'policy_logps/rejected': -363.69775390625, 'policy_logps/chosen': -543.5264892578125, 'referece_logps/rejected': -338.6391296386719, 'referece_logps/chosen': -529.7510375976562, 'logits/rejected': 0.5038015842437744, 'logits/chosen': 0.3988596200942993, 'epoch': 1.37}

 23%|██▎       | 3666/16104 [16:58:32<53:21:52, 15.45s/it]

 23%|██▎       | 3667/16104 [16:58:43<49:00:49, 14.19s/it]

 23%|██▎       | 3668/16104 [16:59:03<54:48:32, 15.87s/it]

 23%|██▎       | 3669/16104 [16:59:22<58:10:50, 16.84s/it]

 23%|██▎       | 3670/16104 [16:59:41<61:02:55, 17.68s/it]

 23%|██▎       | 3671/16104 [17:00:03<64:44:51, 18.75s/it]

 23%|██▎       | 3672/16104 [17:00:21<64:06:00, 18.56s/it]


 23%|██▎       | 3674/16104 [17:00:48<54:35:29, 15.81s/it]
{'loss': 0.4248, 'learning_rate': 1.8011434885007479e-06, 'rewards/chosen': -1.465864658355713, 'rewards/rejected': -2.253659248352051, 'rewards/accuracies': 0.75, 'rewards/margins': 0.787794828414917, 'policy_logps/rejected': -442.4713439941406, 'policy_logps/chosen': -321.1391906738281, 'referece_logps/rejected': -419.93475341796875, 'referece_logps/chosen': -306.48052978515625, 'logits/rejected': -1.5433142185211182, 'logits/chosen': -1.4396204948425293, 'epoch': 1.37}


 23%|██▎       | 3676/16104 [17:01:20<54:39:55, 15.83s/it]

 23%|██▎       | 3677/16104 [17:01:41<59:26:23, 17.22s/it]
{'loss': 0.3797, 'learning_rate': 1.800782237138998e-06, 'rewards/chosen': -1.3963682651519775, 'rewards/rejected': -3.250645399093628, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8542773723602295, 'policy_logps/rejected': -273.3369140625, 'policy_logps/chosen': -376.0154724121094, 'referece_logps/rejected': -240.8304443359375, 'referece_logps/chosen': -362.0517272949219, 'logits/rejected': -0.6033395528793335, 'logits/chosen': -0.64659184217453, 'epoch': 1.37}

 23%|██▎       | 3678/16104 [17:02:01<63:00:46, 18.26s/it]

 23%|██▎       | 3679/16104 [17:02:17<60:10:53, 17.44s/it]


 23%|██▎       | 3681/16104 [17:02:58<66:38:37, 19.31s/it]

 23%|██▎       | 3682/16104 [17:03:18<67:02:22, 19.43s/it]
{'loss': 0.4507, 'learning_rate': 1.8001795037396849e-06, 'rewards/chosen': -1.0478618144989014, 'rewards/rejected': -2.6710398197174072, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6231776475906372, 'policy_logps/rejected': -331.6203918457031, 'policy_logps/chosen': -331.0647277832031, 'referece_logps/rejected': -304.90997314453125, 'referece_logps/chosen': -320.58612060546875, 'logits/rejected': -1.0240496397018433, 'logits/chosen': -1.0851383209228516, 'epoch': 1.37}

 23%|██▎       | 3683/16104 [17:03:38<67:18:14, 19.51s/it]

 23%|██▎       | 3684/16104 [17:03:56<65:36:55, 19.02s/it]

 23%|██▎       | 3685/16104 [17:04:18<68:46:44, 19.94s/it]

 23%|██▎       | 3686/16104 [17:04:32<62:35:50, 18.15s/it]

 23%|██▎       | 3687/16104 [17:04:51<64:02:20, 18.57s/it]

 23%|██▎       | 3688/16104 [17:05:07<61:13:51, 17.75s/it]

 23%|██▎       | 3689/16104 [17:05:24<59:54:38, 17.37s/it]

 23%|██▎       | 3690/16104 [17:05:42<61:01:47, 17.70s/it]

 23%|██▎       | 3691/16104 [17:06:00<60:54:44, 17.67s/it]

 23%|██▎       | 3692/16104 [17:06:20<63:36:46, 18.45s/it]

 23%|██▎       | 3693/16104 [17:06:36<60:48:22, 17.64s/it]

 23%|██▎       | 3694/16104 [17:06:50<57:10:34, 16.59s/it]


 23%|██▎       | 3696/16104 [17:07:25<57:40:14, 16.73s/it]
{'loss': 0.4268, 'learning_rate': 1.79848754713513e-06, 'rewards/chosen': -2.2213854789733887, 'rewards/rejected': -4.140911102294922, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9195263385772705, 'policy_logps/rejected': -368.34283447265625, 'policy_logps/chosen': -422.2566833496094, 'referece_logps/rejected': -326.9337158203125, 'referece_logps/chosen': -400.0428161621094, 'logits/rejected': -0.4421164393424988, 'logits/chosen': -0.3633444309234619, 'epoch': 1.38}

 23%|██▎       | 3697/16104 [17:07:41<57:20:29, 16.64s/it]

 23%|██▎       | 3698/16104 [17:08:02<61:36:53, 17.88s/it]


 23%|██▎       | 3700/16104 [17:08:31<55:30:55, 16.11s/it]
{'loss': 0.4902, 'learning_rate': 1.7980029675663957e-06, 'rewards/chosen': -1.2893812656402588, 'rewards/rejected': -1.9491708278656006, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6597892642021179, 'policy_logps/rejected': -331.809326171875, 'policy_logps/chosen': -317.3663024902344, 'referece_logps/rejected': -312.317626953125, 'referece_logps/chosen': -304.47247314453125, 'logits/rejected': -0.7770596146583557, 'logits/chosen': -0.6392116546630859, 'epoch': 1.38}

 23%|██▎       | 3701/16104 [17:08:50<59:17:08, 17.21s/it]

 23%|██▎       | 3702/16104 [17:09:02<53:04:18, 15.41s/it]

 23%|██▎       | 3703/16104 [17:09:18<53:42:44, 15.59s/it]

 23%|██▎       | 3704/16104 [17:09:36<57:01:39, 16.56s/it]

 23%|██▎       | 3705/16104 [17:09:55<58:38:41, 17.03s/it]

 23%|██▎       | 3706/16104 [17:10:15<62:25:28, 18.13s/it]


 23%|██▎       | 3708/16104 [17:10:55<65:26:02, 19.00s/it]
{'loss': 0.473, 'learning_rate': 1.7970322592720587e-06, 'rewards/chosen': -1.5511493682861328, 'rewards/rejected': -2.333310127258301, 'rewards/accuracies': 0.625, 'rewards/margins': 0.782160758972168, 'policy_logps/rejected': -279.8741149902344, 'policy_logps/chosen': -306.63885498046875, 'referece_logps/rejected': -256.541015625, 'referece_logps/chosen': -291.12738037109375, 'logits/rejected': -0.504683256149292, 'logits/chosen': -0.4476717710494995, 'epoch': 1.38}


 23%|██▎       | 3710/16104 [17:11:17<51:16:42, 14.89s/it]

 23%|██▎       | 3711/16104 [17:11:39<58:46:47, 17.07s/it]

 23%|██▎       | 3712/16104 [17:11:57<59:19:53, 17.24s/it]

 23%|██▎       | 3713/16104 [17:12:15<60:07:18, 17.47s/it]
{'loss': 0.4099, 'learning_rate': 1.7964245185838175e-06, 'rewards/chosen': -1.0784695148468018, 'rewards/rejected': -2.6413142681121826, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5628447532653809, 'policy_logps/rejected': -264.1346130371094, 'policy_logps/chosen': -282.0663146972656, 'referece_logps/rejected': -237.721435546875, 'referece_logps/chosen': -271.2816467285156, 'logits/rejected': -0.21094028651714325, 'logits/chosen': -0.04044157266616821, 'epoch': 1.38}


 23%|██▎       | 3715/16104 [17:12:51<60:48:15, 17.67s/it]
{'loss': 0.4094, 'learning_rate': 1.7961811967565432e-06, 'rewards/chosen': -1.5145883560180664, 'rewards/rejected': -3.1541078090667725, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6395193338394165, 'policy_logps/rejected': -299.6574401855469, 'policy_logps/chosen': -301.72723388671875, 'referece_logps/rejected': -268.1163635253906, 'referece_logps/chosen': -286.58135986328125, 'logits/rejected': -0.13951750099658966, 'logits/chosen': -0.02101568877696991, 'epoch': 1.38}

 23%|██▎       | 3716/16104 [17:13:10<62:07:18, 18.05s/it]

 23%|██▎       | 3717/16104 [17:13:28<62:10:17, 18.07s/it]

 23%|██▎       | 3718/16104 [17:13:40<55:35:41, 16.16s/it]

 23%|██▎       | 3719/16104 [17:13:58<57:35:36, 16.74s/it]

 23%|██▎       | 3720/16104 [17:14:11<53:37:01, 15.59s/it]

 23%|██▎       | 3721/16104 [17:14:22<49:05:12, 14.27s/it]


 23%|██▎       | 3723/16104 [17:14:43<42:49:09, 12.45s/it]
{'loss': 0.4027, 'learning_rate': 1.7952066215634766e-06, 'rewards/chosen': -1.0493189096450806, 'rewards/rejected': -1.9163851737976074, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8670662641525269, 'policy_logps/rejected': -403.6013488769531, 'policy_logps/chosen': -604.5054931640625, 'referece_logps/rejected': -384.4374694824219, 'referece_logps/chosen': -594.0123291015625, 'logits/rejected': -0.41783198714256287, 'logits/chosen': -0.26084738969802856, 'epoch': 1.39}

 23%|██▎       | 3724/16104 [17:14:54<40:59:06, 11.92s/it]

 23%|██▎       | 3725/16104 [17:15:16<50:54:31, 14.81s/it]

 23%|██▎       | 3726/16104 [17:15:38<58:55:19, 17.14s/it]

 23%|██▎       | 3727/16104 [17:15:56<59:39:37, 17.35s/it]

 23%|██▎       | 3728/16104 [17:16:18<64:40:31, 18.81s/it]

 23%|██▎       | 3729/16104 [17:16:30<57:37:05, 16.76s/it]

 23%|██▎       | 3730/16104 [17:16:43<53:06:49, 15.45s/it]

 23%|██▎       | 3731/16104 [17:17:02<57:40:15, 16.78s/it]

 23%|██▎       | 3732/16104 [17:17:16<54:10:59, 15.77s/it]

 23%|██▎       | 3733/16104 [17:17:36<59:11:52, 17.23s/it]

 23%|██▎       | 3734/16104 [17:17:49<54:05:48, 15.74s/it]

 23%|██▎       | 3735/16104 [17:18:04<53:32:59, 15.59s/it]

 23%|██▎       | 3736/16104 [17:18:26<60:21:57, 17.57s/it]

 23%|██▎       | 3737/16104 [17:18:38<54:01:25, 15.73s/it]

 23%|██▎       | 3738/16104 [17:18:48<48:55:08, 14.24s/it]


 23%|██▎       | 3740/16104 [17:19:20<51:28:47, 14.99s/it]
{'loss': 0.4985, 'learning_rate': 1.793128816828586e-06, 'rewards/chosen': -0.92800372838974, 'rewards/rejected': -1.7480372190475464, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8200335502624512, 'policy_logps/rejected': -379.9533386230469, 'policy_logps/chosen': -456.59027099609375, 'referece_logps/rejected': -362.47296142578125, 'referece_logps/chosen': -447.3101806640625, 'logits/rejected': -0.08097352832555771, 'logits/chosen': -0.18299807608127594, 'epoch': 1.39}

 23%|██▎       | 3741/16104 [17:19:36<52:25:11, 15.26s/it]

 23%|██▎       | 3742/16104 [17:19:47<47:59:18, 13.97s/it]

 23%|██▎       | 3743/16104 [17:20:07<54:35:04, 15.90s/it]

 23%|██▎       | 3744/16104 [17:20:23<54:44:08, 15.94s/it]

 23%|██▎       | 3745/16104 [17:20:35<51:00:55, 14.86s/it]

 23%|██▎       | 3746/16104 [17:20:48<49:06:27, 14.31s/it]

 23%|██▎       | 3747/16104 [17:21:04<50:11:20, 14.62s/it]

 23%|██▎       | 3748/16104 [17:21:24<56:19:22, 16.41s/it]

 23%|██▎       | 3749/16104 [17:21:45<60:51:57, 17.74s/it]

 23%|██▎       | 3750/16104 [17:22:06<64:16:07, 18.73s/it]


 23%|██▎       | 3752/16104 [17:22:44<65:00:11, 18.95s/it]
{'loss': 0.5087, 'learning_rate': 1.7916565471758307e-06, 'rewards/chosen': -0.9313486814498901, 'rewards/rejected': -2.0138487815856934, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0825001001358032, 'policy_logps/rejected': -374.4234313964844, 'policy_logps/chosen': -318.2554016113281, 'referece_logps/rejected': -354.2848815917969, 'referece_logps/chosen': -308.9419250488281, 'logits/rejected': -0.6619758605957031, 'logits/chosen': -0.78554368019104, 'epoch': 1.4}

 23%|██▎       | 3753/16104 [17:23:04<66:30:05, 19.38s/it]

 23%|██▎       | 3754/16104 [17:23:21<64:03:20, 18.67s/it]

 23%|██▎       | 3755/16104 [17:23:39<63:19:37, 18.46s/it]

 23%|██▎       | 3756/16104 [17:23:57<62:38:38, 18.26s/it]

 23%|██▎       | 3757/16104 [17:24:13<60:07:39, 17.53s/it]

 23%|██▎       | 3758/16104 [17:24:35<64:27:22, 18.79s/it]

 23%|██▎       | 3759/16104 [17:24:54<64:37:41, 18.85s/it]

 23%|██▎       | 3760/16104 [17:25:07<58:27:08, 17.05s/it]

 23%|██▎       | 3761/16104 [17:25:28<62:36:41, 18.26s/it]


 23%|██▎       | 3763/16104 [17:25:57<56:07:42, 16.37s/it]

 23%|██▎       | 3764/16104 [17:26:10<52:20:40, 15.27s/it]

 23%|██▎       | 3765/16104 [17:26:23<50:09:42, 14.64s/it]

 23%|██▎       | 3766/16104 [17:26:42<54:33:04, 15.92s/it]

 23%|██▎       | 3767/16104 [17:27:00<56:20:10, 16.44s/it]

 23%|██▎       | 3768/16104 [17:27:18<58:30:08, 17.07s/it]

 23%|██▎       | 3769/16104 [17:27:30<53:04:24, 15.49s/it]

 23%|██▎       | 3770/16104 [17:27:42<49:18:47, 14.39s/it]

 23%|██▎       | 3771/16104 [17:27:55<48:01:32, 14.02s/it]

 23%|██▎       | 3772/16104 [17:28:13<52:38:13, 15.37s/it]

 23%|██▎       | 3773/16104 [17:28:33<57:20:01, 16.74s/it]

 23%|██▎       | 3774/16104 [17:28:52<59:23:44, 17.34s/it]

 23%|██▎       | 3775/16104 [17:29:03<52:51:45, 15.44s/it]

 23%|██▎       | 3776/16104 [17:29:16<50:05:07, 14.63s/it]

 23%|██▎       | 3777/16104 [17:29:35<54:49:56, 16.01s/it]

 23%|██▎       | 3778/16104 [17:29:49<52:34:20, 15.35s/it]

 23%|██▎       | 3779/16104 [17:30:09<57:01:11, 16.65s/it]

 23%|██▎       | 3780/16104 [17:30:31<62:51:00, 18.36s/it]

 23%|██▎       | 3781/16104 [17:30:52<65:36:29, 19.17s/it]

 23%|██▎       | 3782/16104 [17:31:10<64:09:58, 18.75s/it]

 23%|██▎       | 3783/16104 [17:31:22<57:16:12, 16.73s/it]

 23%|██▎       | 3784/16104 [17:31:33<51:29:51, 15.05s/it]

 24%|██▎       | 3785/16104 [17:31:46<49:27:41, 14.45s/it]

 24%|██▎       | 3786/16104 [17:32:04<53:38:03, 15.67s/it]

 24%|██▎       | 3787/16104 [17:32:27<60:31:14, 17.69s/it]

 24%|██▎       | 3788/16104 [17:32:48<64:24:20, 18.83s/it]

 24%|██▎       | 3789/16104 [17:33:05<62:09:30, 18.17s/it]

 24%|██▎       | 3790/16104 [17:33:16<54:38:10, 15.97s/it]

 24%|██▎       | 3791/16104 [17:33:36<59:20:00, 17.35s/it]

 24%|██▎       | 3792/16104 [17:33:47<52:50:36, 15.45s/it]

 24%|██▎       | 3793/16104 [17:33:58<48:21:00, 14.14s/it]

 24%|██▎       | 3794/16104 [17:34:09<45:06:44, 13.19s/it]

 24%|██▎       | 3795/16104 [17:34:21<43:36:07, 12.75s/it]

 24%|██▎       | 3796/16104 [17:34:32<41:46:19, 12.22s/it]

 24%|██▎       | 3797/16104 [17:34:51<48:53:57, 14.30s/it]

 24%|██▎       | 3798/16104 [17:35:03<45:44:04, 13.38s/it]

 24%|██▎       | 3799/16104 [17:35:21<50:54:19, 14.89s/it]

 24%|██▎       | 3800/16104 [17:35:35<49:53:02, 14.60s/it]

 24%|██▎       | 3801/16104 [17:35:55<55:17:29, 16.18s/it]

 24%|██▎       | 3802/16104 [17:36:17<61:02:59, 17.87s/it]

 24%|██▎       | 3803/16104 [17:36:34<60:18:09, 17.65s/it]

 24%|██▎       | 3804/16104 [17:36:47<55:37:01, 16.28s/it]

 24%|██▎       | 3805/16104 [17:37:01<53:35:17, 15.69s/it]

 24%|██▎       | 3806/16104 [17:37:22<59:16:56, 17.35s/it]

 24%|██▎       | 3807/16104 [17:37:41<60:50:22, 17.81s/it]

 24%|██▎       | 3808/16104 [17:38:01<62:45:00, 18.37s/it]

 24%|██▎       | 3809/16104 [17:38:12<54:50:17, 16.06s/it]

 24%|██▎       | 3810/16104 [17:38:31<57:56:13, 16.97s/it]

 24%|██▎       | 3811/16104 [17:38:42<52:05:07, 15.25s/it]

 24%|██▎       | 3812/16104 [17:38:53<47:50:31, 14.01s/it]

 24%|██▎       | 3813/16104 [17:39:05<46:01:38, 13.48s/it]

 24%|██▎       | 3814/16104 [17:39:25<52:36:03, 15.41s/it]

 24%|██▎       | 3815/16104 [17:39:45<56:54:31, 16.67s/it]

 24%|██▎       | 3816/16104 [17:40:03<58:31:52, 17.15s/it]

 24%|██▎       | 3817/16104 [17:40:23<61:20:56, 17.97s/it]

 24%|██▎       | 3818/16104 [17:40:39<59:46:22, 17.51s/it]

 24%|██▎       | 3819/16104 [17:41:01<63:31:39, 18.62s/it]

 24%|██▎       | 3820/16104 [17:41:17<61:11:23, 17.93s/it]

 24%|██▎       | 3821/16104 [17:41:28<53:56:43, 15.81s/it]

 24%|██▎       | 3822/16104 [17:41:46<56:24:10, 16.53s/it]

 24%|██▎       | 3823/16104 [17:42:06<59:33:20, 17.46s/it]

 24%|██▎       | 3824/16104 [17:42:16<52:39:30, 15.44s/it]

 24%|██▍       | 3825/16104 [17:42:31<51:24:47, 15.07s/it]

 24%|██▍       | 3826/16104 [17:42:46<52:13:59, 15.32s/it]

 24%|██▍       | 3827/16104 [17:43:06<56:18:44, 16.51s/it]

 24%|██▍       | 3828/16104 [17:43:25<59:31:52, 17.46s/it]

 24%|██▍       | 3829/16104 [17:43:43<59:30:45, 17.45s/it]

 24%|██▍       | 3830/16104 [17:44:03<62:39:28, 18.38s/it]

 24%|██▍       | 3831/16104 [17:44:20<60:35:36, 17.77s/it]

 24%|██▍       | 3832/16104 [17:44:44<66:49:01, 19.60s/it]

 24%|██▍       | 3833/16104 [17:44:58<61:48:29, 18.13s/it]

 24%|██▍       | 3834/16104 [17:45:18<63:19:35, 18.58s/it]

 24%|██▍       | 3835/16104 [17:45:39<65:31:53, 19.23s/it]

 24%|██▍       | 3836/16104 [17:45:59<66:42:06, 19.57s/it]

 24%|██▍       | 3837/16104 [17:46:15<63:10:21, 18.54s/it]

 24%|██▍       | 3838/16104 [17:46:29<57:56:35, 17.01s/it]

 24%|██▍       | 3839/16104 [17:46:48<60:39:54, 17.81s/it]

 24%|██▍       | 3840/16104 [17:47:08<62:26:13, 18.33s/it]

 24%|██▍       | 3841/16104 [17:47:26<61:53:10, 18.17s/it]

 24%|██▍       | 3842/16104 [17:47:47<64:55:31, 19.06s/it]

 24%|██▍       | 3843/16104 [17:48:06<65:23:45, 19.20s/it]

 24%|██▍       | 3844/16104 [17:48:26<66:05:38, 19.41s/it]

 24%|██▍       | 3845/16104 [17:48:44<64:49:26, 19.04s/it]

 24%|██▍       | 3846/16104 [17:48:59<60:22:53, 17.73s/it]

 24%|██▍       | 3847/16104 [17:49:14<58:01:49, 17.04s/it]

 24%|██▍       | 3848/16104 [17:49:31<57:25:14, 16.87s/it]

 24%|██▍       | 3849/16104 [17:49:51<60:19:38, 17.72s/it]

 24%|██▍       | 3850/16104 [17:50:08<59:35:18, 17.51s/it]

 24%|██▍       | 3851/16104 [17:50:24<58:16:38, 17.12s/it]

 24%|██▍       | 3852/16104 [17:50:46<63:11:37, 18.57s/it]

 24%|██▍       | 3853/16104 [17:51:00<58:56:29, 17.32s/it]

 24%|██▍       | 3854/16104 [17:51:11<52:09:40, 15.33s/it]

 24%|██▍       | 3855/16104 [17:51:22<47:24:28, 13.93s/it]

 24%|██▍       | 3856/16104 [17:51:32<44:05:32, 12.96s/it]

 24%|██▍       | 3857/16104 [17:51:43<42:00:18, 12.35s/it]

 24%|██▍       | 3858/16104 [17:51:59<45:35:55, 13.40s/it]

 24%|██▍       | 3859/16104 [17:52:11<44:16:34, 13.02s/it]

 24%|██▍       | 3860/16104 [17:52:31<51:01:00, 15.00s/it]

 24%|██▍       | 3861/16104 [17:52:48<53:01:03, 15.59s/it]

 24%|██▍       | 3862/16104 [17:53:01<50:54:40, 14.97s/it]

 24%|██▍       | 3863/16104 [17:53:17<51:57:04, 15.28s/it]

 24%|██▍       | 3864/16104 [17:53:33<52:16:32, 15.38s/it]

 24%|██▍       | 3865/16104 [17:53:51<54:43:28, 16.10s/it]

 24%|██▍       | 3866/16104 [17:54:05<53:15:40, 15.67s/it]

 24%|██▍       | 3867/16104 [17:54:20<51:57:03, 15.28s/it]

 24%|██▍       | 3868/16104 [17:54:35<51:45:06, 15.23s/it]
{'loss': 0.4923, 'learning_rate': 1.7771881506689846e-06, 'rewards/chosen': -1.2538163661956787, 'rewards/rejected': -1.7661240100860596, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5123074650764465, 'policy_logps/rejected': -424.0440979003906, 'policy_logps/chosen': -488.9685974121094, 'referece_logps/rejected': -406.3828125, 'referece_logps/chosen': -476.430419921875, 'logits/rejected': 0.24422799050807953, 'logits/chosen': 0.3729105591773987, 'epoch': 1.44}


 24%|██▍       | 3870/16104 [17:55:11<57:25:46, 16.90s/it]

 24%|██▍       | 3871/16104 [17:55:25<54:16:10, 15.97s/it]

 24%|██▍       | 3872/16104 [17:55:43<56:21:12, 16.59s/it]

 24%|██▍       | 3873/16104 [17:56:04<60:36:49, 17.84s/it]

 24%|██▍       | 3874/16104 [17:56:21<60:04:18, 17.68s/it]

 24%|██▍       | 3875/16104 [17:56:37<58:56:42, 17.35s/it]

 24%|██▍       | 3876/16104 [17:56:56<60:13:22, 17.73s/it]

 24%|██▍       | 3877/16104 [17:57:09<55:49:27, 16.44s/it]

 24%|██▍       | 3878/16104 [17:57:29<59:19:36, 17.47s/it]

 24%|██▍       | 3879/16104 [17:57:45<57:25:07, 16.91s/it]
{'loss': 0.4374, 'learning_rate': 1.7757940634073174e-06, 'rewards/chosen': -1.4226183891296387, 'rewards/rejected': -2.1118202209472656, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6892019510269165, 'policy_logps/rejected': -348.7740783691406, 'policy_logps/chosen': -359.2875061035156, 'referece_logps/rejected': -327.6558837890625, 'referece_logps/chosen': -345.0613098144531, 'logits/rejected': -0.6470498442649841, 'logits/chosen': -0.4292547106742859, 'epoch': 1.45}

 24%|██▍       | 3880/16104 [17:58:05<60:17:43, 17.76s/it]


 24%|██▍       | 3882/16104 [17:58:32<53:25:27, 15.74s/it]

 24%|██▍       | 3883/16104 [17:58:50<55:41:33, 16.41s/it]

 24%|██▍       | 3884/16104 [17:59:02<51:10:47, 15.08s/it]
{'loss': 0.4792, 'learning_rate': 1.7751591316788055e-06, 'rewards/chosen': -1.1711463928222656, 'rewards/rejected': -2.35109543800354, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1799488067626953, 'policy_logps/rejected': -301.5943298339844, 'policy_logps/chosen': -358.5663757324219, 'referece_logps/rejected': -278.0833740234375, 'referece_logps/chosen': -346.85491943359375, 'logits/rejected': -0.44164416193962097, 'logits/chosen': -0.5300431251525879, 'epoch': 1.45}


 24%|██▍       | 3886/16104 [17:59:23<43:47:18, 12.90s/it]
{'loss': 0.6064, 'learning_rate': 1.774904939455443e-06, 'rewards/chosen': -0.6061426401138306, 'rewards/rejected': -1.8326359987258911, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2264933586120605, 'policy_logps/rejected': -386.6277160644531, 'policy_logps/chosen': -466.9110107421875, 'referece_logps/rejected': -368.30133056640625, 'referece_logps/chosen': -460.849609375, 'logits/rejected': -0.2374856173992157, 'logits/chosen': 0.03762289881706238, 'epoch': 1.45}


 24%|██▍       | 3888/16104 [17:59:45<40:11:30, 11.84s/it]
{'loss': 0.5732, 'learning_rate': 1.7746506218469316e-06, 'rewards/chosen': -1.2031971216201782, 'rewards/rejected': -1.524474859237671, 'rewards/accuracies': 0.5, 'rewards/margins': 0.32127779722213745, 'policy_logps/rejected': -319.7576599121094, 'policy_logps/chosen': -553.804443359375, 'referece_logps/rejected': -304.5129089355469, 'referece_logps/chosen': -541.7724609375, 'logits/rejected': -0.5350280404090881, 'logits/chosen': -0.6449794769287109, 'epoch': 1.45}


 24%|██▍       | 3890/16104 [18:00:22<52:43:42, 15.54s/it]
{'loss': 0.3953, 'learning_rate': 1.7743961788944209e-06, 'rewards/chosen': -1.1039365530014038, 'rewards/rejected': -1.897469162940979, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7935325503349304, 'policy_logps/rejected': -329.33294677734375, 'policy_logps/chosen': -209.25328063964844, 'referece_logps/rejected': -310.3582763671875, 'referece_logps/chosen': -198.2139129638672, 'logits/rejected': -1.1609219312667847, 'logits/chosen': -0.9725465178489685, 'epoch': 1.45}


 24%|██▍       | 3892/16104 [18:00:51<51:27:44, 15.17s/it]
{'loss': 0.4005, 'learning_rate': 1.7741416106390826e-06, 'rewards/chosen': -0.8583442568778992, 'rewards/rejected': -2.083874225616455, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2255299091339111, 'policy_logps/rejected': -322.0204772949219, 'policy_logps/chosen': -467.80267333984375, 'referece_logps/rejected': -301.1817321777344, 'referece_logps/chosen': -459.21923828125, 'logits/rejected': 0.6218699216842651, 'logits/chosen': 0.5852896571159363, 'epoch': 1.45}

 24%|██▍       | 3893/16104 [18:01:09<54:00:06, 15.92s/it]


 24%|██▍       | 3895/16104 [18:01:46<57:53:04, 17.07s/it]

 24%|██▍       | 3896/16104 [18:02:02<57:06:22, 16.84s/it]

 24%|██▍       | 3897/16104 [18:02:22<60:02:38, 17.71s/it]

 24%|██▍       | 3898/16104 [18:02:44<64:21:41, 18.98s/it]

 24%|██▍       | 3899/16104 [18:03:05<67:05:48, 19.79s/it]

 24%|██▍       | 3900/16104 [18:03:21<63:23:03, 18.70s/it]

 24%|██▍       | 3901/16104 [18:03:38<61:40:49, 18.20s/it]

 24%|██▍       | 3902/16104 [18:04:00<65:15:49, 19.25s/it]

 24%|██▍       | 3903/16104 [18:04:11<56:51:58, 16.78s/it]

 24%|██▍       | 3904/16104 [18:04:29<58:12:44, 17.18s/it]
{'loss': 0.4739, 'learning_rate': 1.7726115720557738e-06, 'rewards/chosen': -0.9169327020645142, 'rewards/rejected': -1.384536623954773, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4676038920879364, 'policy_logps/rejected': -474.2271423339844, 'policy_logps/chosen': -434.75091552734375, 'referece_logps/rejected': -460.3818054199219, 'referece_logps/chosen': -425.58160400390625, 'logits/rejected': 0.8139028549194336, 'logits/chosen': 0.854089081287384, 'epoch': 1.45}


 24%|██▍       | 3906/16104 [18:05:04<57:52:06, 17.08s/it]

 24%|██▍       | 3907/16104 [18:05:20<57:12:22, 16.88s/it]
{'loss': 0.3731, 'learning_rate': 1.772228358857434e-06, 'rewards/chosen': -1.6054558753967285, 'rewards/rejected': -2.5245771408081055, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9191211462020874, 'policy_logps/rejected': -373.65216064453125, 'policy_logps/chosen': -383.1666259765625, 'referece_logps/rejected': -348.40643310546875, 'referece_logps/chosen': -367.1120300292969, 'logits/rejected': 0.13856589794158936, 'logits/chosen': 0.13893400132656097, 'epoch': 1.46}


 24%|██▍       | 3909/16104 [18:05:52<57:35:27, 17.00s/it]

 24%|██▍       | 3910/16104 [18:06:14<62:01:25, 18.31s/it]
{'loss': 0.52, 'learning_rate': 1.7718448645169656e-06, 'rewards/chosen': -1.3543765544891357, 'rewards/rejected': -2.1948843002319336, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8405078649520874, 'policy_logps/rejected': -341.5597229003906, 'policy_logps/chosen': -322.9916687011719, 'referece_logps/rejected': -319.6108703613281, 'referece_logps/chosen': -309.4479064941406, 'logits/rejected': -0.02375347912311554, 'logits/chosen': -0.13079595565795898, 'epoch': 1.46}


 24%|██▍       | 3912/16104 [18:06:44<56:53:32, 16.80s/it]

 24%|██▍       | 3913/16104 [18:07:02<58:00:00, 17.13s/it]

 24%|██▍       | 3914/16104 [18:07:19<57:13:52, 16.90s/it]

 24%|██▍       | 3915/16104 [18:07:40<61:27:25, 18.15s/it]

 24%|██▍       | 3916/16104 [18:08:00<63:06:50, 18.64s/it]
{'loss': 0.5371, 'learning_rate': 1.7710770329682143e-06, 'rewards/chosen': -0.7734741568565369, 'rewards/rejected': -1.6959487199783325, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9224745035171509, 'policy_logps/rejected': -453.27691650390625, 'policy_logps/chosen': -464.91082763671875, 'referece_logps/rejected': -436.31744384765625, 'referece_logps/chosen': -457.17608642578125, 'logits/rejected': 0.017697006464004517, 'logits/chosen': -0.07218414545059204, 'epoch': 1.46}


 24%|██▍       | 3918/16104 [18:08:38<64:33:37, 19.07s/it]

 24%|██▍       | 3919/16104 [18:08:54<61:33:37, 18.19s/it]
{'loss': 0.4626, 'learning_rate': 1.7706926960394724e-06, 'rewards/chosen': -1.3499338626861572, 'rewards/rejected': -1.8359347581863403, 'rewards/accuracies': 0.75, 'rewards/margins': 0.48600104451179504, 'policy_logps/rejected': -365.3137512207031, 'policy_logps/chosen': -356.1015625, 'referece_logps/rejected': -346.9544677734375, 'referece_logps/chosen': -342.60223388671875, 'logits/rejected': -0.016939379274845123, 'logits/chosen': -0.06218767911195755, 'epoch': 1.46}


 24%|██▍       | 3921/16104 [18:09:24<55:27:47, 16.39s/it]

 24%|██▍       | 3922/16104 [18:09:41<55:45:47, 16.48s/it]

 24%|██▍       | 3923/16104 [18:09:52<49:54:27, 14.75s/it]

 24%|██▍       | 3924/16104 [18:10:13<56:29:12, 16.70s/it]

 24%|██▍       | 3925/16104 [18:10:24<51:13:21, 15.14s/it]

 24%|██▍       | 3926/16104 [18:10:38<49:40:29, 14.68s/it]

 24%|██▍       | 3927/16104 [18:10:55<51:47:19, 15.31s/it]

 24%|██▍       | 3928/16104 [18:11:13<54:19:53, 16.06s/it]

 24%|██▍       | 3929/16104 [18:11:28<54:03:27, 15.98s/it]
{'loss': 0.3818, 'learning_rate': 1.7694095472973136e-06, 'rewards/chosen': -0.921768307685852, 'rewards/rejected': -2.068960666656494, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1471924781799316, 'policy_logps/rejected': -484.89874267578125, 'policy_logps/chosen': -375.4834899902344, 'referece_logps/rejected': -464.2091369628906, 'referece_logps/chosen': -366.26580810546875, 'logits/rejected': -1.1552574634552002, 'logits/chosen': -0.9086148738861084, 'epoch': 1.46}


 24%|██▍       | 3931/16104 [18:11:50<45:25:45, 13.44s/it]

 24%|██▍       | 3932/16104 [18:12:02<43:52:08, 12.97s/it]

 24%|██▍       | 3933/16104 [18:12:21<49:24:24, 14.61s/it]

 24%|██▍       | 3934/16104 [18:12:43<57:04:49, 16.88s/it]

 24%|██▍       | 3935/16104 [18:12:58<55:46:18, 16.50s/it]

 24%|██▍       | 3936/16104 [18:13:18<58:51:57, 17.42s/it]
{'loss': 0.3813, 'learning_rate': 1.768509490991719e-06, 'rewards/chosen': -1.1302183866500854, 'rewards/rejected': -2.7135181427001953, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5832996368408203, 'policy_logps/rejected': -310.7901306152344, 'policy_logps/chosen': -302.52752685546875, 'referece_logps/rejected': -283.65496826171875, 'referece_logps/chosen': -291.225341796875, 'logits/rejected': -0.3461443781852722, 'logits/chosen': -0.3753190040588379, 'epoch': 1.47}

 24%|██▍       | 3937/16104 [18:13:33<56:54:53, 16.84s/it]


 24%|██▍       | 3939/16104 [18:13:56<47:22:29, 14.02s/it]

 24%|██▍       | 3940/16104 [18:14:17<54:09:52, 16.03s/it]

 24%|██▍       | 3941/16104 [18:14:32<53:39:49, 15.88s/it]
{'loss': 0.3602, 'learning_rate': 1.7678656608991771e-06, 'rewards/chosen': -1.8205468654632568, 'rewards/rejected': -2.6913349628448486, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8707882165908813, 'policy_logps/rejected': -326.4525146484375, 'policy_logps/chosen': -316.9300537109375, 'referece_logps/rejected': -299.5391845703125, 'referece_logps/chosen': -298.7245788574219, 'logits/rejected': -1.063930869102478, 'logits/chosen': -0.8234607577323914, 'epoch': 1.47}


 24%|██▍       | 3943/16104 [18:14:59<48:31:45, 14.37s/it]
{'loss': 0.2896, 'learning_rate': 1.7676079113949363e-06, 'rewards/chosen': -1.4248501062393188, 'rewards/rejected': -2.6690025329589844, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2441524267196655, 'policy_logps/rejected': -365.3656005859375, 'policy_logps/chosen': -493.4801940917969, 'referece_logps/rejected': -338.67559814453125, 'referece_logps/chosen': -479.231689453125, 'logits/rejected': -0.30315709114074707, 'logits/chosen': -0.34960174560546875, 'epoch': 1.47}


 24%|██▍       | 3945/16104 [18:15:25<46:33:03, 13.78s/it]
{'loss': 0.3909, 'learning_rate': 1.7673500376862571e-06, 'rewards/chosen': -0.9973766207695007, 'rewards/rejected': -2.169370651245117, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1719939708709717, 'policy_logps/rejected': -319.2038269042969, 'policy_logps/chosen': -443.84027099609375, 'referece_logps/rejected': -297.5101318359375, 'referece_logps/chosen': -433.8665466308594, 'logits/rejected': -0.7975656986236572, 'logits/chosen': -0.7296484708786011, 'epoch': 1.47}

 25%|██▍       | 3946/16104 [18:15:41<49:39:12, 14.70s/it]


 25%|██▍       | 3948/16104 [18:16:16<52:54:27, 15.67s/it]
{'loss': 0.5066, 'learning_rate': 1.7669629943311983e-06, 'rewards/chosen': -2.3019111156463623, 'rewards/rejected': -3.319573402404785, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0176622867584229, 'policy_logps/rejected': -321.01812744140625, 'policy_logps/chosen': -312.0631408691406, 'referece_logps/rejected': -287.8223876953125, 'referece_logps/chosen': -289.04400634765625, 'logits/rejected': -0.2424841821193695, 'logits/chosen': -0.3949720561504364, 'epoch': 1.47}


 25%|██▍       | 3950/16104 [18:16:54<58:01:10, 17.19s/it]
{'loss': 0.3838, 'learning_rate': 1.7667048102940187e-06, 'rewards/chosen': -1.8359763622283936, 'rewards/rejected': -3.1045448780059814, 'rewards/accuracies': 0.75, 'rewards/margins': 1.268568515777588, 'policy_logps/rejected': -329.955810546875, 'policy_logps/chosen': -457.7272033691406, 'referece_logps/rejected': -298.91033935546875, 'referece_logps/chosen': -439.3674621582031, 'logits/rejected': -0.5183102488517761, 'logits/chosen': -0.49341633915901184, 'epoch': 1.47}

 25%|██▍       | 3951/16104 [18:17:08<54:20:25, 16.10s/it]

 25%|██▍       | 3952/16104 [18:17:28<57:57:02, 17.17s/it]


 25%|██▍       | 3954/16104 [18:18:07<61:36:09, 18.25s/it]
{'loss': 0.4321, 'learning_rate': 1.7661880700865266e-06, 'rewards/chosen': -1.374829649925232, 'rewards/rejected': -2.3850388526916504, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0102088451385498, 'policy_logps/rejected': -380.21331787109375, 'policy_logps/chosen': -466.1102294921875, 'referece_logps/rejected': -356.36297607421875, 'referece_logps/chosen': -452.3619079589844, 'logits/rejected': -0.27319857478141785, 'logits/chosen': -0.17341738939285278, 'epoch': 1.47}


 25%|██▍       | 3956/16104 [18:18:46<64:21:09, 19.07s/it]

 25%|██▍       | 3957/16104 [18:18:59<58:12:50, 17.25s/it]
{'loss': 0.2376, 'learning_rate': 1.7658001894790372e-06, 'rewards/chosen': -1.4766343832015991, 'rewards/rejected': -4.016479015350342, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5398447513580322, 'policy_logps/rejected': -282.595947265625, 'policy_logps/chosen': -388.52587890625, 'referece_logps/rejected': -242.43116760253906, 'referece_logps/chosen': -373.75958251953125, 'logits/rejected': -0.34328198432922363, 'logits/chosen': -0.3595700263977051, 'epoch': 1.47}


 25%|██▍       | 3959/16104 [18:19:35<59:33:01, 17.65s/it]

 25%|██▍       | 3960/16104 [18:19:53<59:55:09, 17.76s/it]

 25%|██▍       | 3961/16104 [18:20:13<62:13:34, 18.45s/it]

 25%|██▍       | 3962/16104 [18:20:29<60:03:02, 17.80s/it]

 25%|██▍       | 3963/16104 [18:20:51<63:33:08, 18.84s/it]

 25%|██▍       | 3964/16104 [18:21:11<64:37:12, 19.16s/it]
{'loss': 0.4157, 'learning_rate': 1.7648940507430745e-06, 'rewards/chosen': -1.7614023685455322, 'rewards/rejected': -3.0158817768096924, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2544792890548706, 'policy_logps/rejected': -423.58331298828125, 'policy_logps/chosen': -466.10784912109375, 'referece_logps/rejected': -393.42449951171875, 'referece_logps/chosen': -448.49383544921875, 'logits/rejected': -0.06900995969772339, 'logits/chosen': 0.021633565425872803, 'epoch': 1.48}


 25%|██▍       | 3966/16104 [18:21:39<55:27:28, 16.45s/it]
{'loss': 0.576, 'learning_rate': 1.7646348754108309e-06, 'rewards/chosen': -1.7774760723114014, 'rewards/rejected': -2.5256690979003906, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7481931447982788, 'policy_logps/rejected': -633.8693237304688, 'policy_logps/chosen': -531.5133056640625, 'referece_logps/rejected': -608.6126098632812, 'referece_logps/chosen': -513.738525390625, 'logits/rejected': -0.3474167585372925, 'logits/chosen': -0.20316071808338165, 'epoch': 1.48}


 25%|██▍       | 3968/16104 [18:22:15<58:47:07, 17.44s/it]

 25%|██▍       | 3969/16104 [18:22:29<55:25:13, 16.44s/it]
{'loss': 0.4572, 'learning_rate': 1.764245880444239e-06, 'rewards/chosen': -1.4030414819717407, 'rewards/rejected': -2.7362422943115234, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3332008123397827, 'policy_logps/rejected': -342.5788269042969, 'policy_logps/chosen': -345.2882080078125, 'referece_logps/rejected': -315.2164001464844, 'referece_logps/chosen': -331.2577819824219, 'logits/rejected': -0.732486367225647, 'logits/chosen': -0.7428557276725769, 'epoch': 1.48}


 25%|██▍       | 3971/16104 [18:22:59<51:31:34, 15.29s/it]

 25%|██▍       | 3972/16104 [18:23:19<55:46:41, 16.55s/it]
{'loss': 0.4462, 'learning_rate': 1.7638566072416682e-06, 'rewards/chosen': -0.8730447888374329, 'rewards/rejected': -2.2606966495513916, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3876516819000244, 'policy_logps/rejected': -321.382568359375, 'policy_logps/chosen': -458.4104309082031, 'referece_logps/rejected': -298.775634765625, 'referece_logps/chosen': -449.67999267578125, 'logits/rejected': -0.4225464165210724, 'logits/chosen': -0.5168336629867554, 'epoch': 1.48}


 25%|██▍       | 3974/16104 [18:23:47<52:07:18, 15.47s/it]

 25%|██▍       | 3975/16104 [18:24:04<53:01:20, 15.74s/it]

 25%|██▍       | 3976/16104 [18:24:17<50:48:41, 15.08s/it]

 25%|██▍       | 3977/16104 [18:24:33<51:10:37, 15.19s/it]

 25%|██▍       | 3978/16104 [18:24:55<58:41:18, 17.42s/it]

 25%|██▍       | 3979/16104 [18:25:11<57:24:29, 17.04s/it]

 25%|██▍       | 3980/16104 [18:25:31<59:54:05, 17.79s/it]
{'loss': 0.3949, 'learning_rate': 1.7628171861814592e-06, 'rewards/chosen': -1.6821801662445068, 'rewards/rejected': -2.7268407344818115, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0446606874465942, 'policy_logps/rejected': -374.549560546875, 'policy_logps/chosen': -374.18084716796875, 'referece_logps/rejected': -347.2811279296875, 'referece_logps/chosen': -357.3590087890625, 'logits/rejected': -0.5127734541893005, 'logits/chosen': -0.48189646005630493, 'epoch': 1.48}

 25%|██▍       | 3981/16104 [18:25:42<53:22:39, 15.85s/it]

 25%|██▍       | 3982/16104 [18:25:57<51:45:01, 15.37s/it]

 25%|██▍       | 3983/16104 [18:26:16<56:11:02, 16.69s/it]

 25%|██▍       | 3984/16104 [18:26:36<59:25:34, 17.65s/it]

 25%|██▍       | 3985/16104 [18:26:57<62:29:20, 18.56s/it]


 25%|██▍       | 3987/16104 [18:27:30<58:55:31, 17.51s/it]
{'loss': 0.4522, 'learning_rate': 1.761906072652906e-06, 'rewards/chosen': -1.2728080749511719, 'rewards/rejected': -2.148294687271118, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8754866123199463, 'policy_logps/rejected': -401.37945556640625, 'policy_logps/chosen': -371.2259521484375, 'referece_logps/rejected': -379.896484375, 'referece_logps/chosen': -358.49786376953125, 'logits/rejected': -0.7290900349617004, 'logits/chosen': -0.9757083654403687, 'epoch': 1.49}

 25%|██▍       | 3988/16104 [18:27:50<62:18:52, 18.52s/it]


 25%|██▍       | 3990/16104 [18:28:29<64:23:57, 19.14s/it]

 25%|██▍       | 3991/16104 [18:28:50<65:41:43, 19.52s/it]
{'loss': 0.3239, 'learning_rate': 1.7613847581849024e-06, 'rewards/chosen': -0.9542190432548523, 'rewards/rejected': -3.0426039695739746, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0883851051330566, 'policy_logps/rejected': -445.1224365234375, 'policy_logps/chosen': -402.3204345703125, 'referece_logps/rejected': -414.6964111328125, 'referece_logps/chosen': -392.77825927734375, 'logits/rejected': -0.18037766218185425, 'logits/chosen': 0.027119316160678864, 'epoch': 1.49}

 25%|██▍       | 3992/16104 [18:29:09<65:22:34, 19.43s/it]

 25%|██▍       | 3993/16104 [18:29:29<65:32:00, 19.48s/it]

 25%|██▍       | 3994/16104 [18:29:51<68:06:34, 20.25s/it]


 25%|██▍       | 3996/16104 [18:30:32<69:54:41, 20.79s/it]

 25%|██▍       | 3997/16104 [18:30:46<63:01:09, 18.74s/it]

 25%|██▍       | 3998/16104 [18:31:00<57:51:46, 17.21s/it]
{'loss': 0.3693, 'learning_rate': 1.7604712722932814e-06, 'rewards/chosen': -1.583189606666565, 'rewards/rejected': -2.8524270057678223, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2692375183105469, 'policy_logps/rejected': -393.21319580078125, 'policy_logps/chosen': -349.2322998046875, 'referece_logps/rejected': -364.68896484375, 'referece_logps/chosen': -333.4004211425781, 'logits/rejected': -0.15857428312301636, 'logits/chosen': -0.26719430088996887, 'epoch': 1.49}

 25%|██▍       | 3999/16104 [18:31:17<57:39:51, 17.15s/it]

 25%|██▍       | 4000/16104 [18:31:33<56:14:00, 16.73s/it]


 25%|██▍       | 4002/16104 [18:32:28<73:19:12, 21.81s/it]

 25%|██▍       | 4003/16104 [18:32:48<71:13:41, 21.19s/it]
{'loss': 0.4384, 'learning_rate': 1.759817859392548e-06, 'rewards/chosen': -1.6492483615875244, 'rewards/rejected': -3.0931222438812256, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4438738822937012, 'policy_logps/rejected': -378.83673095703125, 'policy_logps/chosen': -414.0522155761719, 'referece_logps/rejected': -347.90557861328125, 'referece_logps/chosen': -397.5596923828125, 'logits/rejected': -0.4112078845500946, 'logits/chosen': -0.5217009782791138, 'epoch': 1.49}

 25%|██▍       | 4004/16104 [18:33:01<62:58:52, 18.74s/it]

 25%|██▍       | 4005/16104 [18:33:17<60:28:20, 17.99s/it]

 25%|██▍       | 4006/16104 [18:33:37<62:30:17, 18.60s/it]


 25%|██▍       | 4008/16104 [18:34:06<56:32:23, 16.83s/it]
{'loss': 0.4726, 'learning_rate': 1.7591636780921692e-06, 'rewards/chosen': -1.9033997058868408, 'rewards/rejected': -2.9839324951171875, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0805330276489258, 'policy_logps/rejected': -351.44329833984375, 'policy_logps/chosen': -461.9244689941406, 'referece_logps/rejected': -321.6039733886719, 'referece_logps/chosen': -442.8904724121094, 'logits/rejected': -0.3759969174861908, 'logits/chosen': -0.5256881713867188, 'epoch': 1.49}


 25%|██▍       | 4010/16104 [18:34:28<46:03:58, 13.71s/it]
{'loss': 0.4744, 'learning_rate': 1.7589017905682826e-06, 'rewards/chosen': -1.1794624328613281, 'rewards/rejected': -2.414494514465332, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2350319623947144, 'policy_logps/rejected': -395.59033203125, 'policy_logps/chosen': -413.4029235839844, 'referece_logps/rejected': -371.44537353515625, 'referece_logps/chosen': -401.60833740234375, 'logits/rejected': -0.7987878322601318, 'logits/chosen': -0.8076390027999878, 'epoch': 1.49}


 25%|██▍       | 4012/16104 [18:34:50<41:38:03, 12.40s/it]

 25%|██▍       | 4013/16104 [18:35:02<40:59:09, 12.20s/it]
{'loss': 0.4077, 'learning_rate': 1.758508729053715e-06, 'rewards/chosen': -1.0476453304290771, 'rewards/rejected': -2.7019684314727783, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6543229818344116, 'policy_logps/rejected': -201.830078125, 'policy_logps/chosen': -347.7950744628906, 'referece_logps/rejected': -174.81039428710938, 'referece_logps/chosen': -337.3186340332031, 'logits/rejected': -0.09128886461257935, 'logits/chosen': -0.24199172854423523, 'epoch': 1.5}

 25%|██▍       | 4014/16104 [18:35:21<48:32:05, 14.45s/it]


 25%|██▍       | 4016/16104 [18:35:50<48:40:24, 14.50s/it]

 25%|██▍       | 4017/16104 [18:36:02<46:49:04, 13.94s/it]
{'loss': 0.3972, 'learning_rate': 1.7579842174966084e-06, 'rewards/chosen': -1.0138028860092163, 'rewards/rejected': -2.930713176727295, 'rewards/accuracies': 0.625, 'rewards/margins': 1.916910171508789, 'policy_logps/rejected': -404.32586669921875, 'policy_logps/chosen': -287.7395324707031, 'referece_logps/rejected': -375.0187072753906, 'referece_logps/chosen': -277.6015319824219, 'logits/rejected': -0.617667555809021, 'logits/chosen': -0.32319873571395874, 'epoch': 1.5}

 25%|██▍       | 4018/16104 [18:36:13<43:44:49, 13.03s/it]


 25%|██▍       | 4020/16104 [18:36:54<56:25:41, 16.81s/it]

 25%|██▍       | 4021/16104 [18:37:14<60:05:36, 17.90s/it]

 25%|██▍       | 4022/16104 [18:37:33<60:14:11, 17.95s/it]
{'loss': 0.4621, 'learning_rate': 1.757327888199253e-06, 'rewards/chosen': -1.2781755924224854, 'rewards/rejected': -2.6174776554107666, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3393020629882812, 'policy_logps/rejected': -289.7729187011719, 'policy_logps/chosen': -370.53289794921875, 'referece_logps/rejected': -263.5981750488281, 'referece_logps/chosen': -357.75115966796875, 'logits/rejected': 0.4829309582710266, 'logits/chosen': 0.4466027021408081, 'epoch': 1.5}

 25%|██▍       | 4023/16104 [18:37:55<64:43:59, 19.29s/it]


 25%|██▍       | 4025/16104 [18:38:32<64:03:14, 19.09s/it]

 25%|██▌       | 4026/16104 [18:38:53<65:07:01, 19.41s/it]

 25%|██▌       | 4027/16104 [18:39:12<65:20:33, 19.48s/it]

 25%|██▌       | 4028/16104 [18:39:33<66:20:06, 19.78s/it]

 25%|██▌       | 4029/16104 [18:39:51<64:32:17, 19.24s/it]
{'loss': 0.4008, 'learning_rate': 1.756407740650775e-06, 'rewards/chosen': -0.8775014877319336, 'rewards/rejected': -2.16082763671875, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2833261489868164, 'policy_logps/rejected': -598.1942138671875, 'policy_logps/chosen': -522.4830322265625, 'referece_logps/rejected': -576.5858764648438, 'referece_logps/chosen': -513.7080078125, 'logits/rejected': -1.1654393672943115, 'logits/chosen': -1.067598819732666, 'epoch': 1.5}

 25%|██▌       | 4030/16104 [18:40:07<61:25:43, 18.32s/it]

 25%|██▌       | 4031/16104 [18:40:17<53:06:19, 15.84s/it]

 25%|██▌       | 4032/16104 [18:40:34<54:19:09, 16.20s/it]

 25%|██▌       | 4033/16104 [18:40:47<51:37:27, 15.40s/it]

 25%|██▌       | 4034/16104 [18:41:07<56:01:32, 16.71s/it]

 25%|██▌       | 4035/16104 [18:41:20<52:04:05, 15.53s/it]

 25%|██▌       | 4036/16104 [18:41:32<48:33:36, 14.49s/it]


 25%|██▌       | 4038/16104 [18:42:02<48:20:40, 14.42s/it]
{'loss': 0.4751, 'learning_rate': 1.7552224909995743e-06, 'rewards/chosen': -1.4315425157546997, 'rewards/rejected': -2.6990160942077637, 'rewards/accuracies': 0.75, 'rewards/margins': 1.267473816871643, 'policy_logps/rejected': -371.48968505859375, 'policy_logps/chosen': -384.023193359375, 'referece_logps/rejected': -344.49951171875, 'referece_logps/chosen': -369.707763671875, 'logits/rejected': -0.5276023745536804, 'logits/chosen': -0.5178652405738831, 'epoch': 1.5}

 25%|██▌       | 4039/16104 [18:42:16<47:23:18, 14.14s/it]


 25%|██▌       | 4041/16104 [18:42:47<48:21:21, 14.43s/it]
{'loss': 0.3687, 'learning_rate': 1.754826857688886e-06, 'rewards/chosen': -1.1838352680206299, 'rewards/rejected': -2.458649158477783, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2748138904571533, 'policy_logps/rejected': -504.46148681640625, 'policy_logps/chosen': -550.0743408203125, 'referece_logps/rejected': -479.875, 'referece_logps/chosen': -538.2359619140625, 'logits/rejected': 0.023557502776384354, 'logits/chosen': 0.004501174204051495, 'epoch': 1.51}


 25%|██▌       | 4043/16104 [18:43:14<48:01:14, 14.33s/it]

 25%|██▌       | 4044/16104 [18:43:29<48:16:49, 14.41s/it]
{'loss': 0.4686, 'learning_rate': 1.754430949571365e-06, 'rewards/chosen': -0.8844583630561829, 'rewards/rejected': -2.2859749794006348, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4015167951583862, 'policy_logps/rejected': -425.54327392578125, 'policy_logps/chosen': -475.22607421875, 'referece_logps/rejected': -402.6835021972656, 'referece_logps/chosen': -466.3814697265625, 'logits/rejected': -0.3034061789512634, 'logits/chosen': -0.3627302348613739, 'epoch': 1.51}


 25%|██▌       | 4046/16104 [18:44:09<57:35:18, 17.19s/it]
{'loss': 0.565, 'learning_rate': 1.7541668582270628e-06, 'rewards/chosen': -2.106612205505371, 'rewards/rejected': -3.3621773719787598, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2555652856826782, 'policy_logps/rejected': -296.072021484375, 'policy_logps/chosen': -222.670166015625, 'referece_logps/rejected': -262.4502258300781, 'referece_logps/chosen': -201.60403442382812, 'logits/rejected': -1.0569559335708618, 'logits/chosen': -1.026553750038147, 'epoch': 1.51}

 25%|██▌       | 4047/16104 [18:44:29<60:55:09, 18.19s/it]

 25%|██▌       | 4048/16104 [18:44:49<62:42:59, 18.73s/it]


 25%|██▌       | 4050/16104 [18:45:17<54:19:46, 16.23s/it]

 25%|██▌       | 4051/16104 [18:45:39<60:18:19, 18.01s/it]

 25%|██▌       | 4052/16104 [18:45:53<56:15:12, 16.80s/it]

 25%|██▌       | 4053/16104 [18:46:12<59:06:57, 17.66s/it]

 25%|██▌       | 4054/16104 [18:46:31<59:50:58, 17.88s/it]

 25%|██▌       | 4055/16104 [18:46:47<57:54:07, 17.30s/it]
{'loss': 0.4332, 'learning_rate': 1.7529769376790586e-06, 'rewards/chosen': -1.369862675666809, 'rewards/rejected': -1.7090258598327637, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3391630947589874, 'policy_logps/rejected': -239.44583129882812, 'policy_logps/chosen': -197.07180786132812, 'referece_logps/rejected': -222.3555908203125, 'referece_logps/chosen': -183.37318420410156, 'logits/rejected': -0.7147990465164185, 'logits/chosen': -0.7374188899993896, 'epoch': 1.51}

 25%|██▌       | 4056/16104 [18:47:06<60:08:32, 17.97s/it]


 25%|██▌       | 4058/16104 [18:47:39<58:51:52, 17.59s/it]

 25%|██▌       | 4059/16104 [18:47:51<53:17:47, 15.93s/it]

 25%|██▌       | 4060/16104 [18:48:11<57:13:23, 17.10s/it]
{'loss': 0.681, 'learning_rate': 1.7523148043841877e-06, 'rewards/chosen': -0.909065306186676, 'rewards/rejected': -0.8605058789253235, 'rewards/accuracies': 0.5, 'rewards/margins': -0.04855938255786896, 'policy_logps/rejected': -429.8563232421875, 'policy_logps/chosen': -373.92718505859375, 'referece_logps/rejected': -421.2512512207031, 'referece_logps/chosen': -364.8365478515625, 'logits/rejected': 0.49040502309799194, 'logits/chosen': 0.6266281008720398, 'epoch': 1.51}

 25%|██▌       | 4061/16104 [18:48:28<57:24:10, 17.16s/it]

 25%|██▌       | 4062/16104 [18:48:49<60:28:21, 18.08s/it]

 25%|██▌       | 4063/16104 [18:49:06<60:00:54, 17.94s/it]


 25%|██▌       | 4065/16104 [18:49:45<62:47:59, 18.78s/it]
{'loss': 0.4889, 'learning_rate': 1.7516519102774706e-06, 'rewards/chosen': -1.722827672958374, 'rewards/rejected': -3.3179235458374023, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5950958728790283, 'policy_logps/rejected': -415.853759765625, 'policy_logps/chosen': -324.1675109863281, 'referece_logps/rejected': -382.67449951171875, 'referece_logps/chosen': -306.939208984375, 'logits/rejected': -0.7923624515533447, 'logits/chosen': -0.6242218613624573, 'epoch': 1.51}


 25%|██▌       | 4067/16104 [18:50:11<52:01:58, 15.56s/it]
{'loss': 0.4411, 'learning_rate': 1.7513865397576058e-06, 'rewards/chosen': -1.1718310117721558, 'rewards/rejected': -1.8845829963684082, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7127519249916077, 'policy_logps/rejected': -362.49627685546875, 'policy_logps/chosen': -359.12591552734375, 'referece_logps/rejected': -343.65045166015625, 'referece_logps/chosen': -347.4076232910156, 'logits/rejected': 0.36770692467689514, 'logits/chosen': 0.4124677777290344, 'epoch': 1.52}

 25%|██▌       | 4068/16104 [18:50:31<56:05:15, 16.78s/it]

 25%|██▌       | 4069/16104 [18:50:46<54:31:39, 16.31s/it]

 25%|██▌       | 4070/16104 [18:51:05<57:03:17, 17.07s/it]

 25%|██▌       | 4071/16104 [18:51:22<57:28:31, 17.20s/it]


 25%|██▌       | 4073/16104 [18:51:57<58:39:41, 17.55s/it]
{'loss': 0.4052, 'learning_rate': 1.7505896988916402e-06, 'rewards/chosen': -1.081519365310669, 'rewards/rejected': -2.3201797008514404, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2386603355407715, 'policy_logps/rejected': -307.0741882324219, 'policy_logps/chosen': -293.5489196777344, 'referece_logps/rejected': -283.8724060058594, 'referece_logps/chosen': -282.7337341308594, 'logits/rejected': -0.1372448205947876, 'logits/chosen': -0.15649251639842987, 'epoch': 1.52}


 25%|██▌       | 4075/16104 [18:52:33<59:24:43, 17.78s/it]
{'loss': 0.526, 'learning_rate': 1.750323842310788e-06, 'rewards/chosen': -2.1110963821411133, 'rewards/rejected': -2.924989700317383, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8138933181762695, 'policy_logps/rejected': -443.8593444824219, 'policy_logps/chosen': -472.3270263671875, 'referece_logps/rejected': -414.6094665527344, 'referece_logps/chosen': -451.2160339355469, 'logits/rejected': 0.17557331919670105, 'logits/chosen': 0.18596899509429932, 'epoch': 1.52}

 25%|██▌       | 4076/16104 [18:52:50<58:30:44, 17.51s/it]

 25%|██▌       | 4077/16104 [18:53:02<53:18:40, 15.96s/it]

 25%|██▌       | 4078/16104 [18:53:24<58:46:20, 17.59s/it]

 25%|██▌       | 4079/16104 [18:53:39<56:00:50, 16.77s/it]

 25%|██▌       | 4080/16104 [18:53:53<53:21:10, 15.97s/it]

 25%|██▌       | 4081/16104 [18:54:10<55:01:12, 16.47s/it]

 25%|██▌       | 4082/16104 [18:54:24<52:38:27, 15.76s/it]

 25%|██▌       | 4083/16104 [18:54:40<52:12:03, 15.63s/it]

 25%|██▌       | 4084/16104 [18:54:52<48:43:50, 14.59s/it]

 25%|██▌       | 4085/16104 [18:55:09<50:48:05, 15.22s/it]

 25%|██▌       | 4086/16104 [18:55:29<55:47:42, 16.71s/it]

 25%|██▌       | 4087/16104 [18:55:42<52:30:38, 15.73s/it]


 25%|██▌       | 4089/16104 [18:56:21<58:21:54, 17.49s/it]

 25%|██▌       | 4090/16104 [18:56:35<54:51:40, 16.44s/it]
{'loss': 0.4725, 'learning_rate': 1.7483260510564124e-06, 'rewards/chosen': -1.6524587869644165, 'rewards/rejected': -2.5522429943084717, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8997840881347656, 'policy_logps/rejected': -328.719970703125, 'policy_logps/chosen': -417.33441162109375, 'referece_logps/rejected': -303.197509765625, 'referece_logps/chosen': -400.809814453125, 'logits/rejected': 0.08930426836013794, 'logits/chosen': -0.01213526725769043, 'epoch': 1.52}

 25%|██▌       | 4091/16104 [18:56:50<53:16:11, 15.96s/it]


 25%|██▌       | 4093/16104 [18:57:14<45:41:22, 13.69s/it]
{'loss': 0.5079, 'learning_rate': 1.7479256749028486e-06, 'rewards/chosen': -0.9742828607559204, 'rewards/rejected': -1.6359843015670776, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6617014408111572, 'policy_logps/rejected': -441.8183898925781, 'policy_logps/chosen': -431.4858093261719, 'referece_logps/rejected': -425.45849609375, 'referece_logps/chosen': -421.74298095703125, 'logits/rejected': -0.5324951410293579, 'logits/chosen': -0.5297210216522217, 'epoch': 1.52}


 25%|██▌       | 4095/16104 [18:57:35<40:43:40, 12.21s/it]
{'loss': 0.4688, 'learning_rate': 1.7476586061835004e-06, 'rewards/chosen': -0.8979721069335938, 'rewards/rejected': -1.5897705554962158, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6917983889579773, 'policy_logps/rejected': -292.3702392578125, 'policy_logps/chosen': -439.1751708984375, 'referece_logps/rejected': -276.4725341796875, 'referece_logps/chosen': -430.1954650878906, 'logits/rejected': -0.18671263754367828, 'logits/chosen': -0.19025015830993652, 'epoch': 1.53}

 25%|██▌       | 4096/16104 [18:57:46<39:46:06, 11.92s/it]

 25%|██▌       | 4097/16104 [18:58:06<47:30:09, 14.24s/it]

 25%|██▌       | 4098/16104 [18:58:22<49:10:06, 14.74s/it]

 25%|██▌       | 4099/16104 [18:58:36<48:34:17, 14.57s/it]

 25%|██▌       | 4100/16104 [18:58:57<54:38:02, 16.38s/it]

 25%|██▌       | 4101/16104 [18:59:09<50:42:52, 15.21s/it]

 25%|██▌       | 4102/16104 [18:59:22<47:43:23, 14.31s/it]

 25%|██▌       | 4103/16104 [18:59:42<53:43:43, 16.12s/it]

 25%|██▌       | 4104/16104 [18:59:53<48:42:17, 14.61s/it]

 25%|██▌       | 4105/16104 [19:00:05<46:31:15, 13.96s/it]


 26%|██▌       | 4107/16104 [19:00:28<41:50:32, 12.56s/it]
{'loss': 0.5576, 'learning_rate': 1.7460536548747999e-06, 'rewards/chosen': -1.346099615097046, 'rewards/rejected': -2.342508316040039, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9964090585708618, 'policy_logps/rejected': -393.861572265625, 'policy_logps/chosen': -287.3759765625, 'referece_logps/rejected': -370.4364929199219, 'referece_logps/chosen': -273.9150085449219, 'logits/rejected': -1.4600768089294434, 'logits/chosen': -1.5380184650421143, 'epoch': 1.53}


 26%|██▌       | 4109/16104 [19:00:54<41:55:14, 12.58s/it]
{'loss': 0.4562, 'learning_rate': 1.7457857402285477e-06, 'rewards/chosen': -1.229527235031128, 'rewards/rejected': -2.4331140518188477, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2035866975784302, 'policy_logps/rejected': -518.5458374023438, 'policy_logps/chosen': -361.09686279296875, 'referece_logps/rejected': -494.2147521972656, 'referece_logps/chosen': -348.8016052246094, 'logits/rejected': -0.4375905394554138, 'logits/chosen': -0.4110182225704193, 'epoch': 1.53}

 26%|██▌       | 4110/16104 [19:01:14<49:33:58, 14.88s/it]

 26%|██▌       | 4111/16104 [19:01:35<55:21:00, 16.61s/it]

 26%|██▌       | 4112/16104 [19:01:53<56:46:54, 17.05s/it]


 26%|██▌       | 4114/16104 [19:02:20<51:24:07, 15.43s/it]

 26%|██▌       | 4115/16104 [19:02:36<51:55:41, 15.59s/it]
{'loss': 0.4352, 'learning_rate': 1.7449812724225602e-06, 'rewards/chosen': -0.6649976968765259, 'rewards/rejected': -2.1338412761688232, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4688435792922974, 'policy_logps/rejected': -237.39312744140625, 'policy_logps/chosen': -297.1545104980469, 'referece_logps/rejected': -216.05471801757812, 'referece_logps/chosen': -290.5045166015625, 'logits/rejected': -0.7718937993049622, 'logits/chosen': -0.5516290664672852, 'epoch': 1.53}

 26%|██▌       | 4116/16104 [19:02:50<49:52:22, 14.98s/it]

 26%|██▌       | 4117/16104 [19:03:10<55:09:30, 16.57s/it]

 26%|██▌       | 4118/16104 [19:03:25<53:33:39, 16.09s/it]

 26%|██▌       | 4119/16104 [19:03:44<56:16:45, 16.90s/it]

 26%|██▌       | 4120/16104 [19:04:05<60:31:09, 18.18s/it]

 26%|██▌       | 4121/16104 [19:04:24<61:00:31, 18.33s/it]

 26%|██▌       | 4122/16104 [19:04:35<53:54:03, 16.19s/it]

 26%|██▌       | 4123/16104 [19:04:46<48:26:36, 14.56s/it]

 26%|██▌       | 4124/16104 [19:05:01<49:25:51, 14.85s/it]

 26%|██▌       | 4125/16104 [19:05:17<50:46:32, 15.26s/it]

 26%|██▌       | 4126/16104 [19:05:37<55:23:51, 16.65s/it]

 26%|██▌       | 4127/16104 [19:05:56<57:43:50, 17.35s/it]

 26%|██▌       | 4128/16104 [19:06:16<59:57:05, 18.02s/it]

 26%|██▌       | 4129/16104 [19:06:33<59:22:22, 17.85s/it]

 26%|██▌       | 4130/16104 [19:06:53<61:20:57, 18.44s/it]

 26%|██▌       | 4131/16104 [19:07:06<55:32:32, 16.70s/it]

 26%|██▌       | 4132/16104 [19:07:24<57:29:02, 17.29s/it]


 26%|██▌       | 4134/16104 [19:07:55<55:06:31, 16.57s/it]

 26%|██▌       | 4135/16104 [19:08:15<58:29:16, 17.59s/it]

 26%|██▌       | 4136/16104 [19:08:37<62:52:15, 18.91s/it]
{'loss': 0.5533, 'learning_rate': 1.7421570992994447e-06, 'rewards/chosen': -1.008540153503418, 'rewards/rejected': -1.3804768323898315, 'rewards/accuracies': 0.5, 'rewards/margins': 0.37193670868873596, 'policy_logps/rejected': -413.3121643066406, 'policy_logps/chosen': -369.0179443359375, 'referece_logps/rejected': -399.50738525390625, 'referece_logps/chosen': -358.93255615234375, 'logits/rejected': -0.07945741713047028, 'logits/chosen': -0.14201106131076813, 'epoch': 1.54}

 26%|██▌       | 4137/16104 [19:08:56<63:46:18, 19.18s/it]

 26%|██▌       | 4138/16104 [19:09:16<64:14:31, 19.33s/it]

 26%|██▌       | 4139/16104 [19:09:35<63:58:21, 19.25s/it]

 26%|██▌       | 4140/16104 [19:09:56<65:15:22, 19.64s/it]

 26%|██▌       | 4141/16104 [19:10:07<56:46:09, 17.08s/it]

 26%|██▌       | 4142/16104 [19:10:18<51:23:03, 15.46s/it]

 26%|██▌       | 4143/16104 [19:10:30<47:01:46, 14.15s/it]

 26%|██▌       | 4144/16104 [19:10:41<44:34:20, 13.42s/it]

 26%|██▌       | 4145/16104 [19:10:59<49:16:33, 14.83s/it]

 26%|██▌       | 4146/16104 [19:11:16<51:03:29, 15.37s/it]

 26%|██▌       | 4147/16104 [19:11:35<54:47:09, 16.49s/it]

 26%|██▌       | 4148/16104 [19:11:54<57:29:16, 17.31s/it]

 26%|██▌       | 4149/16104 [19:12:16<61:31:51, 18.53s/it]

 26%|██▌       | 4150/16104 [19:12:34<61:39:47, 18.57s/it]

 26%|██▌       | 4151/16104 [19:12:53<62:09:46, 18.72s/it]

 26%|██▌       | 4152/16104 [19:13:09<59:12:42, 17.83s/it]

 26%|██▌       | 4153/16104 [19:13:22<53:42:59, 16.18s/it]


 26%|██▌       | 4155/16104 [19:13:57<56:47:25, 17.11s/it]
{'loss': 0.2915, 'learning_rate': 1.7395904854792228e-06, 'rewards/chosen': -1.379437804222107, 'rewards/rejected': -2.971438407897949, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5920006036758423, 'policy_logps/rejected': -254.171875, 'policy_logps/chosen': -247.81982421875, 'referece_logps/rejected': -224.45748901367188, 'referece_logps/chosen': -234.02545166015625, 'logits/rejected': -0.6936802864074707, 'logits/chosen': -0.63215172290802, 'epoch': 1.55}

 26%|██▌       | 4156/16104 [19:14:19<61:23:00, 18.50s/it]

 26%|██▌       | 4157/16104 [19:14:29<53:34:03, 16.14s/it]

 26%|██▌       | 4158/16104 [19:14:48<56:11:05, 16.93s/it]

 26%|██▌       | 4159/16104 [19:15:01<52:37:05, 15.86s/it]

 26%|██▌       | 4160/16104 [19:15:15<50:15:48, 15.15s/it]


 26%|██▌       | 4162/16104 [19:15:40<46:08:23, 13.91s/it]

 26%|██▌       | 4163/16104 [19:15:54<45:35:04, 13.74s/it]

 26%|██▌       | 4164/16104 [19:16:06<44:17:26, 13.35s/it]

 26%|██▌       | 4165/16104 [19:16:21<45:51:46, 13.83s/it]

 26%|██▌       | 4166/16104 [19:16:35<45:51:43, 13.83s/it]

 26%|██▌       | 4167/16104 [19:16:53<50:07:26, 15.12s/it]

 26%|██▌       | 4168/16104 [19:17:05<47:07:54, 14.22s/it]

 26%|██▌       | 4169/16104 [19:17:18<45:46:49, 13.81s/it]

 26%|██▌       | 4170/16104 [19:17:35<49:07:21, 14.82s/it]

 26%|██▌       | 4171/16104 [19:17:55<53:45:36, 16.22s/it]

 26%|██▌       | 4172/16104 [19:18:11<53:20:00, 16.09s/it]

 26%|██▌       | 4173/16104 [19:18:26<52:40:53, 15.90s/it]

 26%|██▌       | 4174/16104 [19:18:46<56:53:05, 17.17s/it]

 26%|██▌       | 4175/16104 [19:19:09<62:30:38, 18.86s/it]

 26%|██▌       | 4176/16104 [19:19:29<63:23:52, 19.13s/it]

 26%|██▌       | 4177/16104 [19:19:48<63:06:52, 19.05s/it]

 26%|██▌       | 4178/16104 [19:19:59<55:49:04, 16.85s/it]

 26%|██▌       | 4179/16104 [19:20:17<56:35:14, 17.08s/it]

 26%|██▌       | 4180/16104 [19:20:37<59:53:04, 18.08s/it]

 26%|██▌       | 4181/16104 [19:20:57<61:01:04, 18.42s/it]

 26%|██▌       | 4182/16104 [19:21:10<55:45:34, 16.84s/it]

 26%|██▌       | 4183/16104 [19:21:29<58:03:32, 17.53s/it]

 26%|██▌       | 4184/16104 [19:21:50<61:45:25, 18.65s/it]

 26%|██▌       | 4185/16104 [19:22:01<54:27:39, 16.45s/it]

 26%|██▌       | 4186/16104 [19:22:23<59:48:43, 18.07s/it]

 26%|██▌       | 4187/16104 [19:22:47<65:23:50, 19.76s/it]

 26%|██▌       | 4188/16104 [19:23:05<63:51:09, 19.29s/it]

 26%|██▌       | 4189/16104 [19:23:26<65:07:56, 19.68s/it]

 26%|██▌       | 4190/16104 [19:23:42<61:25:22, 18.56s/it]

 26%|██▌       | 4191/16104 [19:24:02<62:49:32, 18.99s/it]

 26%|██▌       | 4192/16104 [19:24:24<66:04:22, 19.97s/it]

 26%|██▌       | 4193/16104 [19:24:45<67:16:26, 20.33s/it]

 26%|██▌       | 4194/16104 [19:25:01<62:40:21, 18.94s/it]

 26%|██▌       | 4195/16104 [19:25:20<63:23:19, 19.16s/it]

 26%|██▌       | 4196/16104 [19:25:41<64:29:00, 19.49s/it]

 26%|██▌       | 4197/16104 [19:25:52<56:43:11, 17.15s/it]

 26%|██▌       | 4198/16104 [19:26:04<50:41:54, 15.33s/it]

 26%|██▌       | 4199/16104 [19:26:16<48:07:28, 14.55s/it]

 26%|██▌       | 4200/16104 [19:26:27<44:30:40, 13.46s/it]

 26%|██▌       | 4201/16104 [19:26:46<49:34:39, 14.99s/it]

 26%|██▌       | 4202/16104 [19:27:03<51:56:54, 15.71s/it]

 26%|██▌       | 4203/16104 [19:27:21<54:02:15, 16.35s/it]

 26%|██▌       | 4204/16104 [19:27:39<55:16:55, 16.72s/it]

 26%|██▌       | 4205/16104 [19:27:56<56:27:50, 17.08s/it]

 26%|██▌       | 4206/16104 [19:28:09<52:19:05, 15.83s/it]

 26%|██▌       | 4207/16104 [19:28:23<50:24:29, 15.25s/it]

 26%|██▌       | 4208/16104 [19:28:39<51:08:08, 15.47s/it]

 26%|██▌       | 4209/16104 [19:28:52<48:48:50, 14.77s/it]

 26%|██▌       | 4210/16104 [19:29:13<54:32:40, 16.51s/it]

 26%|██▌       | 4211/16104 [19:29:29<53:44:20, 16.27s/it]

 26%|██▌       | 4212/16104 [19:29:44<53:05:35, 16.07s/it]

 26%|██▌       | 4213/16104 [19:29:55<47:51:36, 14.49s/it]
{'loss': 0.4516, 'learning_rate': 1.7316889122841568e-06, 'rewards/chosen': -0.6718494892120361, 'rewards/rejected': -1.2675830125808716, 'rewards/accuracies': 0.875, 'rewards/margins': 0.595733642578125, 'policy_logps/rejected': -486.2574462890625, 'policy_logps/chosen': -334.6077880859375, 'referece_logps/rejected': -473.5816650390625, 'referece_logps/chosen': -327.8893127441406, 'logits/rejected': -0.4565064311027527, 'logits/chosen': -0.5015228390693665, 'epoch': 1.57}


 26%|██▌       | 4215/16104 [19:30:19<43:28:04, 13.16s/it]

 26%|██▌       | 4216/16104 [19:30:41<51:41:42, 15.65s/it]
{'loss': 0.5555, 'learning_rate': 1.731277492720415e-06, 'rewards/chosen': -0.820356547832489, 'rewards/rejected': -1.3719754219055176, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5516188144683838, 'policy_logps/rejected': -353.7872009277344, 'policy_logps/chosen': -385.6468505859375, 'referece_logps/rejected': -340.0674743652344, 'referece_logps/chosen': -377.44329833984375, 'logits/rejected': 0.02309715747833252, 'logits/chosen': 0.08702926337718964, 'epoch': 1.57}


 26%|██▌       | 4218/16104 [19:31:20<58:22:16, 17.68s/it]

 26%|██▌       | 4219/16104 [19:31:36<56:31:01, 17.12s/it]

 26%|██▌       | 4220/16104 [19:31:48<51:47:39, 15.69s/it]

 26%|██▌       | 4221/16104 [19:31:59<47:14:50, 14.31s/it]

 26%|██▌       | 4222/16104 [19:32:19<52:22:58, 15.87s/it]
{'loss': 0.5172, 'learning_rate': 1.7304538550428872e-06, 'rewards/chosen': -1.7731703519821167, 'rewards/rejected': -2.947183609008789, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1740132570266724, 'policy_logps/rejected': -263.0589904785156, 'policy_logps/chosen': -317.0908203125, 'referece_logps/rejected': -233.58714294433594, 'referece_logps/chosen': -299.359130859375, 'logits/rejected': -1.1187098026275635, 'logits/chosen': -1.0757484436035156, 'epoch': 1.57}


 26%|██▌       | 4224/16104 [19:32:52<54:43:30, 16.58s/it]

 26%|██▌       | 4225/16104 [19:33:11<57:24:18, 17.40s/it]
{'loss': 0.2604, 'learning_rate': 1.7300416372289588e-06, 'rewards/chosen': -1.2550036907196045, 'rewards/rejected': -2.9410948753356934, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6860909461975098, 'policy_logps/rejected': -549.20751953125, 'policy_logps/chosen': -473.06390380859375, 'referece_logps/rejected': -519.7965087890625, 'referece_logps/chosen': -460.5138854980469, 'logits/rejected': -0.08457446098327637, 'logits/chosen': 0.10966158658266068, 'epoch': 1.57}


 26%|██▌       | 4227/16104 [19:33:42<53:14:22, 16.14s/it]

 26%|██▋       | 4228/16104 [19:33:57<52:20:09, 15.86s/it]

 26%|██▋       | 4229/16104 [19:34:17<56:22:49, 17.09s/it]

 26%|██▋       | 4230/16104 [19:34:39<61:26:19, 18.63s/it]

 26%|██▋       | 4231/16104 [19:34:59<62:27:10, 18.94s/it]

 26%|██▋       | 4232/16104 [19:35:18<62:46:51, 19.04s/it]
{'loss': 0.2691, 'learning_rate': 1.7290787623206792e-06, 'rewards/chosen': -1.1796543598175049, 'rewards/rejected': -4.239006996154785, 'rewards/accuracies': 0.875, 'rewards/margins': 3.0593526363372803, 'policy_logps/rejected': -339.00885009765625, 'policy_logps/chosen': -447.6352844238281, 'referece_logps/rejected': -296.6187744140625, 'referece_logps/chosen': -435.8387451171875, 'logits/rejected': -0.06486380100250244, 'logits/chosen': -0.04846050217747688, 'epoch': 1.58}


 26%|██▋       | 4234/16104 [19:35:57<64:07:56, 19.45s/it]
{'loss': 0.4492, 'learning_rate': 1.7288033896877026e-06, 'rewards/chosen': -1.6561319828033447, 'rewards/rejected': -2.6193528175354004, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9632205367088318, 'policy_logps/rejected': -484.0923156738281, 'policy_logps/chosen': -395.8214111328125, 'referece_logps/rejected': -457.8987731933594, 'referece_logps/chosen': -379.2601623535156, 'logits/rejected': -0.22114083170890808, 'logits/chosen': 0.12133687734603882, 'epoch': 1.58}


 26%|██▋       | 4236/16104 [19:36:36<63:52:48, 19.38s/it]

 26%|██▋       | 4237/16104 [19:36:56<64:39:59, 19.62s/it]

 26%|██▋       | 4238/16104 [19:37:10<58:29:09, 17.74s/it]

 26%|██▋       | 4239/16104 [19:37:29<60:23:53, 18.33s/it]

 26%|██▋       | 4240/16104 [19:37:46<58:51:56, 17.86s/it]
{'loss': 0.4326, 'learning_rate': 1.7279765644135593e-06, 'rewards/chosen': -1.361128568649292, 'rewards/rejected': -2.091348171234131, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7302194237709045, 'policy_logps/rejected': -311.0539245605469, 'policy_logps/chosen': -372.2750244140625, 'referece_logps/rejected': -290.14044189453125, 'referece_logps/chosen': -358.66375732421875, 'logits/rejected': -0.5911350250244141, 'logits/chosen': -0.6065872311592102, 'epoch': 1.58}

 26%|██▋       | 4241/16104 [19:38:00<55:33:29, 16.86s/it]


 26%|██▋       | 4243/16104 [19:38:34<55:10:48, 16.75s/it]

 26%|██▋       | 4244/16104 [19:38:48<51:45:26, 15.71s/it]

 26%|██▋       | 4245/16104 [19:38:58<46:53:04, 14.23s/it]
{'loss': 0.5765, 'learning_rate': 1.7272867334820687e-06, 'rewards/chosen': -1.0436363220214844, 'rewards/rejected': -1.6767487525939941, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6331125497817993, 'policy_logps/rejected': -261.1852722167969, 'policy_logps/chosen': -427.88018798828125, 'referece_logps/rejected': -244.41778564453125, 'referece_logps/chosen': -417.44384765625, 'logits/rejected': -0.3900623321533203, 'logits/chosen': -0.5580108165740967, 'epoch': 1.58}


 26%|██▋       | 4247/16104 [19:39:24<43:45:08, 13.28s/it]

 26%|██▋       | 4248/16104 [19:39:37<44:06:31, 13.39s/it]
{'loss': 0.6588, 'learning_rate': 1.7268724818379694e-06, 'rewards/chosen': -1.731151819229126, 'rewards/rejected': -1.9141484498977661, 'rewards/accuracies': 0.375, 'rewards/margins': 0.18299657106399536, 'policy_logps/rejected': -312.66815185546875, 'policy_logps/chosen': -343.5904541015625, 'referece_logps/rejected': -293.5266418457031, 'referece_logps/chosen': -326.2789306640625, 'logits/rejected': -0.06701338291168213, 'logits/chosen': -0.2086162269115448, 'epoch': 1.58}

 26%|██▋       | 4249/16104 [19:39:55<47:55:33, 14.55s/it]


 26%|██▋       | 4251/16104 [19:40:31<54:09:52, 16.45s/it]

 26%|██▋       | 4252/16104 [19:40:42<49:21:40, 14.99s/it]

 26%|██▋       | 4253/16104 [19:41:02<54:27:56, 16.55s/it]

 26%|██▋       | 4254/16104 [19:41:23<58:59:20, 17.92s/it]
{'loss': 0.5129, 'learning_rate': 1.726043184811901e-06, 'rewards/chosen': -1.444739580154419, 'rewards/rejected': -3.209556818008423, 'rewards/accuracies': 0.625, 'rewards/margins': 1.764817476272583, 'policy_logps/rejected': -447.42431640625, 'policy_logps/chosen': -346.69915771484375, 'referece_logps/rejected': -415.3287353515625, 'referece_logps/chosen': -332.2517395019531, 'logits/rejected': -1.1649250984191895, 'logits/chosen': -1.123880386352539, 'epoch': 1.58}


 26%|██▋       | 4256/16104 [19:41:53<52:30:53, 15.96s/it]

 26%|██▋       | 4257/16104 [19:42:14<58:08:22, 17.67s/it]
{'loss': 0.3912, 'learning_rate': 1.7256281397318508e-06, 'rewards/chosen': -1.268897294998169, 'rewards/rejected': -2.4356257915496826, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1667284965515137, 'policy_logps/rejected': -506.26593017578125, 'policy_logps/chosen': -440.575927734375, 'referece_logps/rejected': -481.90972900390625, 'referece_logps/chosen': -427.8869323730469, 'logits/rejected': -0.5341971516609192, 'logits/chosen': -0.6335877776145935, 'epoch': 1.59}


 26%|██▋       | 4259/16104 [19:42:50<58:26:09, 17.76s/it]

 26%|██▋       | 4260/16104 [19:43:11<61:05:13, 18.57s/it]

 26%|██▋       | 4261/16104 [19:43:26<58:07:14, 17.67s/it]

 26%|██▋       | 4262/16104 [19:43:43<57:01:34, 17.34s/it]

 26%|██▋       | 4263/16104 [19:43:57<54:18:00, 16.51s/it]

 26%|██▋       | 4264/16104 [19:44:15<55:03:34, 16.74s/it]

 26%|██▋       | 4265/16104 [19:44:36<59:44:51, 18.17s/it]

 26%|██▋       | 4266/16104 [19:44:56<61:41:59, 18.76s/it]

 26%|██▋       | 4267/16104 [19:45:14<61:02:37, 18.57s/it]
{'loss': 0.3866, 'learning_rate': 1.724242749039295e-06, 'rewards/chosen': -1.4862468242645264, 'rewards/rejected': -2.397719144821167, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9114723205566406, 'policy_logps/rejected': -229.10150146484375, 'policy_logps/chosen': -202.41580200195312, 'referece_logps/rejected': -205.12432861328125, 'referece_logps/chosen': -187.55331420898438, 'logits/rejected': -1.111128568649292, 'logits/chosen': -1.0481271743774414, 'epoch': 1.59}


 27%|██▋       | 4269/16104 [19:45:42<52:26:47, 15.95s/it]

 27%|██▋       | 4270/16104 [19:46:03<56:43:39, 17.26s/it]
{'loss': 0.3413, 'learning_rate': 1.7238265602866435e-06, 'rewards/chosen': -0.8068514466285706, 'rewards/rejected': -2.1626782417297363, 'rewards/accuracies': 0.75, 'rewards/margins': 1.355826735496521, 'policy_logps/rejected': -315.2926025390625, 'policy_logps/chosen': -341.0668640136719, 'referece_logps/rejected': -293.66583251953125, 'referece_logps/chosen': -332.9983215332031, 'logits/rejected': -1.058388113975525, 'logits/chosen': -0.8871556520462036, 'epoch': 1.59}


 27%|██▋       | 4272/16104 [19:46:38<57:25:53, 17.47s/it]

 27%|██▋       | 4273/16104 [19:46:51<52:31:45, 15.98s/it]

 27%|██▋       | 4274/16104 [19:47:02<47:25:30, 14.43s/it]

 27%|██▋       | 4275/16104 [19:47:18<49:08:38, 14.96s/it]

 27%|██▋       | 4276/16104 [19:47:38<54:01:53, 16.45s/it]

 27%|██▋       | 4277/16104 [19:47:49<48:35:31, 14.79s/it]

 27%|██▋       | 4278/16104 [19:48:02<46:52:50, 14.27s/it]

 27%|██▋       | 4279/16104 [19:48:15<45:43:13, 13.92s/it]
{'loss': 0.4857, 'learning_rate': 1.7225764135111866e-06, 'rewards/chosen': -1.3032344579696655, 'rewards/rejected': -2.016482353210449, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7132479548454285, 'policy_logps/rejected': -440.5538330078125, 'policy_logps/chosen': -528.637451171875, 'referece_logps/rejected': -420.3890075683594, 'referece_logps/chosen': -515.6051025390625, 'logits/rejected': -0.24323859810829163, 'logits/chosen': -0.1462021917104721, 'epoch': 1.59}


 27%|██▋       | 4281/16104 [19:48:40<43:50:45, 13.35s/it]

 27%|██▋       | 4282/16104 [19:49:01<51:20:59, 15.64s/it]

 27%|██▋       | 4283/16104 [19:49:14<49:27:31, 15.06s/it]

 27%|██▋       | 4284/16104 [19:49:32<51:38:35, 15.73s/it]

 27%|██▋       | 4285/16104 [19:49:53<57:04:56, 17.39s/it]

 27%|██▋       | 4286/16104 [19:50:11<57:24:28, 17.49s/it]

 27%|██▋       | 4287/16104 [19:50:23<52:07:27, 15.88s/it]

 27%|██▋       | 4288/16104 [19:50:35<48:10:42, 14.68s/it]

 27%|██▋       | 4289/16104 [19:50:47<45:52:53, 13.98s/it]

 27%|██▋       | 4290/16104 [19:51:07<51:52:01, 15.81s/it]

 27%|██▋       | 4291/16104 [19:51:18<47:06:40, 14.36s/it]

 27%|██▋       | 4292/16104 [19:51:29<43:46:50, 13.34s/it]

 27%|██▋       | 4293/16104 [19:51:51<52:21:05, 15.96s/it]

 27%|██▋       | 4294/16104 [19:52:13<58:02:57, 17.69s/it]

 27%|██▋       | 4295/16104 [19:52:37<64:36:31, 19.70s/it]

 27%|██▋       | 4296/16104 [19:52:55<62:19:48, 19.00s/it]

 27%|██▋       | 4297/16104 [19:53:13<62:06:09, 18.94s/it]

 27%|██▋       | 4298/16104 [19:53:26<55:57:00, 17.06s/it]

 27%|██▋       | 4299/16104 [19:53:39<51:44:55, 15.78s/it]

 27%|██▋       | 4300/16104 [19:53:59<55:39:00, 16.97s/it]

 27%|██▋       | 4301/16104 [19:54:14<53:32:04, 16.33s/it]

 27%|██▋       | 4302/16104 [19:54:35<58:09:23, 17.74s/it]
{'loss': 0.4042, 'learning_rate': 1.7193708471892765e-06, 'rewards/chosen': -1.2755382061004639, 'rewards/rejected': -2.938695192337036, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6631569862365723, 'policy_logps/rejected': -317.6145324707031, 'policy_logps/chosen': -356.35009765625, 'referece_logps/rejected': -288.2275695800781, 'referece_logps/chosen': -343.5947265625, 'logits/rejected': -0.22310879826545715, 'logits/chosen': -0.1690540760755539, 'epoch': 1.6}


 27%|██▋       | 4304/16104 [19:55:04<53:54:14, 16.45s/it]

 27%|██▋       | 4305/16104 [19:55:15<48:11:38, 14.70s/it]
{'loss': 0.4456, 'learning_rate': 1.7189515934818182e-06, 'rewards/chosen': -1.4108835458755493, 'rewards/rejected': -2.8476953506469727, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4368118047714233, 'policy_logps/rejected': -347.9828796386719, 'policy_logps/chosen': -540.194580078125, 'referece_logps/rejected': -319.50592041015625, 'referece_logps/chosen': -526.0857543945312, 'logits/rejected': -1.2544944286346436, 'logits/chosen': -1.2763142585754395, 'epoch': 1.6}


 27%|██▋       | 4307/16104 [19:55:39<42:56:05, 13.10s/it]

 27%|██▋       | 4308/16104 [19:55:54<44:48:03, 13.67s/it]

 27%|██▋       | 4309/16104 [19:56:11<48:36:10, 14.83s/it]

 27%|██▋       | 4310/16104 [19:56:23<46:10:55, 14.10s/it]

 27%|██▋       | 4311/16104 [19:56:43<51:42:55, 15.79s/it]

 27%|██▋       | 4312/16104 [19:57:00<52:59:03, 16.18s/it]
{'loss': 0.3857, 'learning_rate': 1.717972317194481e-06, 'rewards/chosen': -1.3083082437515259, 'rewards/rejected': -2.717288017272949, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4089796543121338, 'policy_logps/rejected': -273.9555969238281, 'policy_logps/chosen': -329.2953186035156, 'referece_logps/rejected': -246.78271484375, 'referece_logps/chosen': -316.2122497558594, 'logits/rejected': -0.6705811023712158, 'logits/chosen': -0.7026005387306213, 'epoch': 1.61}


 27%|██▋       | 4314/16104 [19:57:38<56:58:59, 17.40s/it]

 27%|██▋       | 4315/16104 [19:57:51<51:55:37, 15.86s/it]

 27%|██▋       | 4316/16104 [19:58:10<55:52:02, 17.06s/it]
{'loss': 0.4762, 'learning_rate': 1.71741209166831e-06, 'rewards/chosen': -1.2308063507080078, 'rewards/rejected': -2.4991438388824463, 'rewards/accuracies': 0.875, 'rewards/margins': 1.268337368965149, 'policy_logps/rejected': -325.7000427246094, 'policy_logps/chosen': -411.8816223144531, 'referece_logps/rejected': -300.7085876464844, 'referece_logps/chosen': -399.57354736328125, 'logits/rejected': -0.7577759623527527, 'logits/chosen': -0.8354043364524841, 'epoch': 1.61}


 27%|██▋       | 4318/16104 [19:58:44<54:58:30, 16.79s/it]
{'loss': 0.5177, 'learning_rate': 1.7171318047589635e-06, 'rewards/chosen': -1.4809010028839111, 'rewards/rejected': -2.6232540607452393, 'rewards/accuracies': 0.875, 'rewards/margins': 1.142352819442749, 'policy_logps/rejected': -412.5745849609375, 'policy_logps/chosen': -488.2361145019531, 'referece_logps/rejected': -386.342041015625, 'referece_logps/chosen': -473.4270935058594, 'logits/rejected': 0.32000917196273804, 'logits/chosen': 0.3681430518627167, 'epoch': 1.61}


 27%|██▋       | 4320/16104 [19:59:27<62:39:53, 19.14s/it]
{'loss': 0.5717, 'learning_rate': 1.7168514018125731e-06, 'rewards/chosen': -1.6621261835098267, 'rewards/rejected': -2.43839168548584, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7762656807899475, 'policy_logps/rejected': -506.62054443359375, 'policy_logps/chosen': -450.10650634765625, 'referece_logps/rejected': -482.23663330078125, 'referece_logps/chosen': -433.4852294921875, 'logits/rejected': -0.4715651571750641, 'logits/chosen': -0.4433368742465973, 'epoch': 1.61}


 27%|██▋       | 4322/16104 [20:00:02<57:36:53, 17.60s/it]

 27%|██▋       | 4323/16104 [20:00:19<57:01:11, 17.42s/it]

 27%|██▋       | 4324/16104 [20:00:37<57:52:32, 17.69s/it]

 27%|██▋       | 4325/16104 [20:00:57<60:31:28, 18.50s/it]

 27%|██▋       | 4326/16104 [20:01:17<61:43:37, 18.87s/it]

 27%|██▋       | 4327/16104 [20:01:35<61:19:49, 18.75s/it]

 27%|██▋       | 4328/16104 [20:01:53<60:02:49, 18.36s/it]

 27%|██▋       | 4329/16104 [20:02:11<59:20:11, 18.14s/it]

 27%|██▋       | 4330/16104 [20:02:28<58:38:13, 17.93s/it]

 27%|██▋       | 4331/16104 [20:02:46<58:14:46, 17.81s/it]

 27%|██▋       | 4332/16104 [20:03:04<58:42:35, 17.95s/it]

 27%|██▋       | 4333/16104 [20:03:26<62:50:33, 19.22s/it]
{'loss': 0.4551, 'learning_rate': 1.7150259573933267e-06, 'rewards/chosen': -0.9932462573051453, 'rewards/rejected': -2.9121856689453125, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9189393520355225, 'policy_logps/rejected': -391.51763916015625, 'policy_logps/chosen': -418.013427734375, 'referece_logps/rejected': -362.39581298828125, 'referece_logps/chosen': -408.0809631347656, 'logits/rejected': -0.04589322209358215, 'logits/chosen': -0.11806756258010864, 'epoch': 1.61}

 27%|██▋       | 4334/16104 [20:03:46<63:45:58, 19.50s/it]

 27%|██▋       | 4335/16104 [20:04:07<64:59:06, 19.88s/it]


 27%|██▋       | 4337/16104 [20:04:42<60:15:31, 18.44s/it]
{'loss': 0.3342, 'learning_rate': 1.7144632981891045e-06, 'rewards/chosen': -0.7814575433731079, 'rewards/rejected': -2.2095398902893066, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4280824661254883, 'policy_logps/rejected': -320.3426208496094, 'policy_logps/chosen': -269.19927978515625, 'referece_logps/rejected': -298.2472229003906, 'referece_logps/chosen': -261.38470458984375, 'logits/rejected': -0.1682625263929367, 'logits/chosen': -0.28985846042633057, 'epoch': 1.62}

 27%|██▋       | 4338/16104 [20:05:03<63:05:11, 19.30s/it]


 27%|██▋       | 4340/16104 [20:05:30<53:19:37, 16.32s/it]

 27%|██▋       | 4341/16104 [20:05:49<56:21:13, 17.25s/it]
{'loss': 0.6406, 'learning_rate': 1.7139001765638601e-06, 'rewards/chosen': -1.6608600616455078, 'rewards/rejected': -2.6178317070007324, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9569714069366455, 'policy_logps/rejected': -429.0986328125, 'policy_logps/chosen': -408.9660339355469, 'referece_logps/rejected': -402.9202880859375, 'referece_logps/chosen': -392.357421875, 'logits/rejected': -0.35006022453308105, 'logits/chosen': -0.4057307541370392, 'epoch': 1.62}

 27%|██▋       | 4342/16104 [20:06:05<54:30:07, 16.68s/it]

 27%|██▋       | 4343/16104 [20:06:17<50:21:15, 15.41s/it]


 27%|██▋       | 4345/16104 [20:06:44<47:26:40, 14.53s/it]
{'loss': 0.3892, 'learning_rate': 1.7133365928820617e-06, 'rewards/chosen': -1.4244636297225952, 'rewards/rejected': -3.1734237670898438, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7489601373672485, 'policy_logps/rejected': -388.75677490234375, 'policy_logps/chosen': -406.71185302734375, 'referece_logps/rejected': -357.0225524902344, 'referece_logps/chosen': -392.46722412109375, 'logits/rejected': -0.14006146788597107, 'logits/chosen': -0.01377694308757782, 'epoch': 1.62}


 27%|██▋       | 4347/16104 [20:07:12<46:07:56, 14.13s/it]

 27%|██▋       | 4348/16104 [20:07:24<44:19:05, 13.57s/it]
{'loss': 0.4263, 'learning_rate': 1.7129136021155185e-06, 'rewards/chosen': -0.6883586645126343, 'rewards/rejected': -2.5872812271118164, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8989225625991821, 'policy_logps/rejected': -496.5368347167969, 'policy_logps/chosen': -535.722412109375, 'referece_logps/rejected': -470.6640319824219, 'referece_logps/chosen': -528.8388671875, 'logits/rejected': -0.30802014470100403, 'logits/chosen': -0.33839482069015503, 'epoch': 1.62}


 27%|██▋       | 4350/16104 [20:07:46<40:01:21, 12.26s/it]
{'loss': 0.433, 'learning_rate': 1.7126314640685132e-06, 'rewards/chosen': -1.6248317956924438, 'rewards/rejected': -2.8352386951446533, 'rewards/accuracies': 0.5, 'rewards/margins': 1.2104068994522095, 'policy_logps/rejected': -373.517822265625, 'policy_logps/chosen': -373.0927429199219, 'referece_logps/rejected': -345.1654052734375, 'referece_logps/chosen': -356.84442138671875, 'logits/rejected': -0.5714970827102661, 'logits/chosen': -0.4903647303581238, 'epoch': 1.62}


 27%|██▋       | 4352/16104 [20:08:08<37:34:43, 11.51s/it]

 27%|██▋       | 4353/16104 [20:08:18<36:49:03, 11.28s/it]

 27%|██▋       | 4354/16104 [20:08:29<36:37:12, 11.22s/it]

 27%|██▋       | 4355/16104 [20:08:40<36:18:49, 11.13s/it]
{'loss': 0.3243, 'learning_rate': 1.7119256145746632e-06, 'rewards/chosen': -1.2438604831695557, 'rewards/rejected': -3.8801028728485107, 'rewards/accuracies': 0.875, 'rewards/margins': 2.636242628097534, 'policy_logps/rejected': -301.2846984863281, 'policy_logps/chosen': -472.4210205078125, 'referece_logps/rejected': -262.48370361328125, 'referece_logps/chosen': -459.9823913574219, 'logits/rejected': -0.8778790235519409, 'logits/chosen': -1.020532488822937, 'epoch': 1.62}

 27%|██▋       | 4356/16104 [20:08:51<35:51:27, 10.99s/it]

 27%|██▋       | 4357/16104 [20:09:09<42:52:01, 13.14s/it]


 27%|██▋       | 4359/16104 [20:09:50<55:07:16, 16.90s/it]

 27%|██▋       | 4360/16104 [20:10:08<55:45:35, 17.09s/it]

 27%|██▋       | 4361/16104 [20:10:28<58:12:02, 17.84s/it]
{'loss': 0.3392, 'learning_rate': 1.7110776448891568e-06, 'rewards/chosen': -1.7520482540130615, 'rewards/rejected': -2.898613929748535, 'rewards/accuracies': 0.875, 'rewards/margins': 1.146565556526184, 'policy_logps/rejected': -306.65740966796875, 'policy_logps/chosen': -271.42620849609375, 'referece_logps/rejected': -277.6712341308594, 'referece_logps/chosen': -253.90573120117188, 'logits/rejected': -0.3582020103931427, 'logits/chosen': -0.3945791721343994, 'epoch': 1.62}


 27%|██▋       | 4363/16104 [20:11:04<58:02:13, 17.80s/it]

 27%|██▋       | 4364/16104 [20:11:24<60:56:39, 18.69s/it]

 27%|██▋       | 4365/16104 [20:11:42<60:08:21, 18.44s/it]

 27%|██▋       | 4366/16104 [20:12:02<61:13:56, 18.78s/it]

 27%|██▋       | 4367/16104 [20:12:20<60:54:10, 18.68s/it]

 27%|██▋       | 4368/16104 [20:12:42<64:13:08, 19.70s/it]

 27%|██▋       | 4369/16104 [20:13:06<67:59:18, 20.86s/it]

 27%|██▋       | 4370/16104 [20:13:24<65:40:21, 20.15s/it]

 27%|██▋       | 4371/16104 [20:13:42<63:09:51, 19.38s/it]
{'loss': 0.393, 'learning_rate': 1.709662061541973e-06, 'rewards/chosen': -1.4572460651397705, 'rewards/rejected': -2.7648260593414307, 'rewards/accuracies': 1.0, 'rewards/margins': 1.307579517364502, 'policy_logps/rejected': -351.389892578125, 'policy_logps/chosen': -400.5046081542969, 'referece_logps/rejected': -323.7416687011719, 'referece_logps/chosen': -385.93218994140625, 'logits/rejected': -0.46450597047805786, 'logits/chosen': -0.3467167615890503, 'epoch': 1.63}

 27%|██▋       | 4372/16104 [20:13:57<58:42:22, 18.01s/it]

 27%|██▋       | 4373/16104 [20:14:19<62:59:11, 19.33s/it]


 27%|██▋       | 4375/16104 [20:14:59<63:26:15, 19.47s/it]
{'loss': 0.3916, 'learning_rate': 1.709095024083596e-06, 'rewards/chosen': -0.9570888876914978, 'rewards/rejected': -2.1779227256774902, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2208338975906372, 'policy_logps/rejected': -248.50631713867188, 'policy_logps/chosen': -261.7939758300781, 'referece_logps/rejected': -226.72708129882812, 'referece_logps/chosen': -252.22311401367188, 'logits/rejected': -0.5945919752120972, 'logits/chosen': -0.5581239461898804, 'epoch': 1.63}

 27%|██▋       | 4376/16104 [20:15:15<60:52:34, 18.69s/it]

 27%|██▋       | 4377/16104 [20:15:35<61:59:53, 19.03s/it]


 27%|██▋       | 4379/16104 [20:16:10<59:28:38, 18.26s/it]

 27%|██▋       | 4380/16104 [20:16:28<59:42:39, 18.33s/it]

 27%|██▋       | 4381/16104 [20:16:43<55:51:27, 17.15s/it]
{'loss': 0.5539, 'learning_rate': 1.7082436074860702e-06, 'rewards/chosen': -1.3459776639938354, 'rewards/rejected': -2.1223576068878174, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7763800024986267, 'policy_logps/rejected': -373.3184814453125, 'policy_logps/chosen': -493.5661315917969, 'referece_logps/rejected': -352.0948791503906, 'referece_logps/chosen': -480.1063537597656, 'logits/rejected': -0.3689523935317993, 'logits/chosen': -0.42002981901168823, 'epoch': 1.63}

 27%|██▋       | 4382/16104 [20:16:55<51:19:41, 15.76s/it]

 27%|██▋       | 4383/16104 [20:17:15<55:06:54, 16.93s/it]

 27%|██▋       | 4384/16104 [20:17:31<54:15:08, 16.66s/it]

 27%|██▋       | 4385/16104 [20:17:48<54:04:39, 16.61s/it]

 27%|██▋       | 4386/16104 [20:18:04<53:55:53, 16.57s/it]

 27%|██▋       | 4387/16104 [20:18:19<52:39:13, 16.18s/it]

 27%|██▋       | 4388/16104 [20:18:38<54:47:40, 16.84s/it]

 27%|██▋       | 4389/16104 [20:18:57<57:31:30, 17.68s/it]


 27%|██▋       | 4391/16104 [20:19:42<65:39:44, 20.18s/it]

 27%|██▋       | 4392/16104 [20:20:02<65:20:52, 20.09s/it]
{'loss': 0.4522, 'learning_rate': 1.7066799992045327e-06, 'rewards/chosen': -1.0151917934417725, 'rewards/rejected': -2.393242359161377, 'rewards/accuracies': 0.625, 'rewards/margins': 1.378050684928894, 'policy_logps/rejected': -251.8736114501953, 'policy_logps/chosen': -388.64337158203125, 'referece_logps/rejected': -227.9412078857422, 'referece_logps/chosen': -378.491455078125, 'logits/rejected': -0.9780223965644836, 'logits/chosen': -0.6367919445037842, 'epoch': 1.64}

 27%|██▋       | 4393/16104 [20:20:15<58:18:04, 17.92s/it]


 27%|██▋       | 4395/16104 [20:20:57<62:48:29, 19.31s/it]
{'loss': 0.4207, 'learning_rate': 1.7062529599443219e-06, 'rewards/chosen': -1.2606903314590454, 'rewards/rejected': -3.0074892044067383, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7467988729476929, 'policy_logps/rejected': -457.03955078125, 'policy_logps/chosen': -482.54718017578125, 'referece_logps/rejected': -426.96466064453125, 'referece_logps/chosen': -469.94024658203125, 'logits/rejected': -0.1913304626941681, 'logits/chosen': -0.19525665044784546, 'epoch': 1.64}

 27%|██▋       | 4396/16104 [20:21:12<59:06:09, 18.17s/it]

 27%|██▋       | 4397/16104 [20:21:30<58:41:07, 18.05s/it]

 27%|██▋       | 4398/16104 [20:21:42<52:55:36, 16.28s/it]


 27%|██▋       | 4400/16104 [20:22:17<55:43:38, 17.14s/it]
{'loss': 0.5504, 'learning_rate': 1.705540656536953e-06, 'rewards/chosen': -1.5282361507415771, 'rewards/rejected': -2.688115119934082, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1598788499832153, 'policy_logps/rejected': -576.63037109375, 'policy_logps/chosen': -725.4841918945312, 'referece_logps/rejected': -549.7492065429688, 'referece_logps/chosen': -710.2017822265625, 'logits/rejected': 0.25928181409835815, 'logits/chosen': 0.176603302359581, 'epoch': 1.64}

 27%|██▋       | 4401/16104 [20:22:32<54:01:58, 16.62s/it]


 27%|██▋       | 4403/16104 [20:23:09<57:03:12, 17.55s/it]
{'loss': 0.3755, 'learning_rate': 1.705112931961884e-06, 'rewards/chosen': -1.5233359336853027, 'rewards/rejected': -2.8243319988250732, 'rewards/accuracies': 1.0, 'rewards/margins': 1.300995945930481, 'policy_logps/rejected': -464.59417724609375, 'policy_logps/chosen': -454.927978515625, 'referece_logps/rejected': -436.3507995605469, 'referece_logps/chosen': -439.694580078125, 'logits/rejected': -0.6704270243644714, 'logits/chosen': -0.45033174753189087, 'epoch': 1.64}


 27%|██▋       | 4405/16104 [20:23:41<53:48:36, 16.56s/it]

 27%|██▋       | 4406/16104 [20:24:01<57:20:11, 17.65s/it]
{'loss': 0.3663, 'learning_rate': 1.7046849506791345e-06, 'rewards/chosen': -1.1326446533203125, 'rewards/rejected': -2.3204853534698486, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1878407001495361, 'policy_logps/rejected': -400.48260498046875, 'policy_logps/chosen': -423.96636962890625, 'referece_logps/rejected': -377.2777404785156, 'referece_logps/chosen': -412.639892578125, 'logits/rejected': 0.2181624323129654, 'logits/chosen': 0.36442679166793823, 'epoch': 1.64}

 27%|██▋       | 4407/16104 [20:24:18<57:10:30, 17.60s/it]

 27%|██▋       | 4408/16104 [20:24:38<59:11:21, 18.22s/it]


 27%|██▋       | 4410/16104 [20:25:05<51:41:45, 15.91s/it]
{'loss': 0.4017, 'learning_rate': 1.7041139099150646e-06, 'rewards/chosen': -0.8225597143173218, 'rewards/rejected': -2.5034236907958984, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6808640956878662, 'policy_logps/rejected': -272.8841247558594, 'policy_logps/chosen': -343.9990234375, 'referece_logps/rejected': -247.84988403320312, 'referece_logps/chosen': -335.7734069824219, 'logits/rejected': -0.20554926991462708, 'logits/chosen': -0.2485733926296234, 'epoch': 1.64}


 27%|██▋       | 4412/16104 [20:25:27<43:41:26, 13.45s/it]

 27%|██▋       | 4413/16104 [20:25:45<47:53:36, 14.75s/it]
{'loss': 0.3603, 'learning_rate': 1.7036853302538302e-06, 'rewards/chosen': -1.6510684490203857, 'rewards/rejected': -2.696035385131836, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0449669361114502, 'policy_logps/rejected': -358.6044616699219, 'policy_logps/chosen': -454.9872741699219, 'referece_logps/rejected': -331.6441345214844, 'referece_logps/chosen': -438.4765930175781, 'logits/rejected': 0.17700180411338806, 'logits/chosen': 0.23300433158874512, 'epoch': 1.64}


 27%|██▋       | 4415/16104 [20:26:19<51:59:46, 16.01s/it]
{'loss': 0.3743, 'learning_rate': 1.703399468143406e-06, 'rewards/chosen': -1.6017258167266846, 'rewards/rejected': -3.3954825401306152, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7937569618225098, 'policy_logps/rejected': -418.47576904296875, 'policy_logps/chosen': -404.618896484375, 'referece_logps/rejected': -384.52099609375, 'referece_logps/chosen': -388.6016540527344, 'logits/rejected': -0.1352681964635849, 'logits/chosen': -0.20848701894283295, 'epoch': 1.64}

 27%|██▋       | 4416/16104 [20:26:36<52:15:03, 16.09s/it]


 27%|██▋       | 4418/16104 [20:27:12<56:56:39, 17.54s/it]
{'loss': 0.527, 'learning_rate': 1.7029704615890034e-06, 'rewards/chosen': -2.6728456020355225, 'rewards/rejected': -2.4741640090942383, 'rewards/accuracies': 0.375, 'rewards/margins': -0.19868171215057373, 'policy_logps/rejected': -377.3475036621094, 'policy_logps/chosen': -407.788818359375, 'referece_logps/rejected': -352.6058349609375, 'referece_logps/chosen': -381.060302734375, 'logits/rejected': -0.2487586885690689, 'logits/chosen': -0.18887145817279816, 'epoch': 1.65}

 27%|██▋       | 4419/16104 [20:27:34<61:30:16, 18.95s/it]


 27%|██▋       | 4421/16104 [20:28:05<55:23:07, 17.07s/it]
{'loss': 0.3551, 'learning_rate': 1.7025411991069212e-06, 'rewards/chosen': -1.646592378616333, 'rewards/rejected': -2.7565860748291016, 'rewards/accuracies': 0.625, 'rewards/margins': 1.109993577003479, 'policy_logps/rejected': -372.8181457519531, 'policy_logps/chosen': -395.1615295410156, 'referece_logps/rejected': -345.2523193359375, 'referece_logps/chosen': -378.6956481933594, 'logits/rejected': -0.1692701280117035, 'logits/chosen': -0.060567207634449005, 'epoch': 1.65}


 27%|██▋       | 4423/16104 [20:28:37<54:39:28, 16.85s/it]

 27%|██▋       | 4424/16104 [20:28:59<59:18:26, 18.28s/it]
{'loss': 0.4076, 'learning_rate': 1.7021116808534393e-06, 'rewards/chosen': -1.390842080116272, 'rewards/rejected': -2.4841110706329346, 'rewards/accuracies': 0.875, 'rewards/margins': 1.093268871307373, 'policy_logps/rejected': -381.423583984375, 'policy_logps/chosen': -380.0376892089844, 'referece_logps/rejected': -356.58245849609375, 'referece_logps/chosen': -366.1292724609375, 'logits/rejected': -0.6289035677909851, 'logits/chosen': -0.5513852834701538, 'epoch': 1.65}

 27%|██▋       | 4425/16104 [20:29:19<60:32:42, 18.66s/it]


 27%|██▋       | 4427/16104 [20:30:00<63:24:52, 19.55s/it]
{'loss': 0.3586, 'learning_rate': 1.7016819069849307e-06, 'rewards/chosen': -1.0269343852996826, 'rewards/rejected': -3.1292576789855957, 'rewards/accuracies': 0.875, 'rewards/margins': 2.102323055267334, 'policy_logps/rejected': -187.73895263671875, 'policy_logps/chosen': -587.6278076171875, 'referece_logps/rejected': -156.44635009765625, 'referece_logps/chosen': -577.3583984375, 'logits/rejected': -1.5104213953018188, 'logits/chosen': -1.6648415327072144, 'epoch': 1.65}


 28%|██▊       | 4429/16104 [20:30:27<53:11:05, 16.40s/it]
{'loss': 0.5977, 'learning_rate': 1.7013952491415068e-06, 'rewards/chosen': -1.3101203441619873, 'rewards/rejected': -1.784981369972229, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4748609960079193, 'policy_logps/rejected': -433.7233581542969, 'policy_logps/chosen': -468.98052978515625, 'referece_logps/rejected': -415.8735656738281, 'referece_logps/chosen': -455.87933349609375, 'logits/rejected': 0.9862971305847168, 'logits/chosen': 0.9845337271690369, 'epoch': 1.65}


 28%|██▊       | 4431/16104 [20:30:49<43:58:10, 13.56s/it]

 28%|██▊       | 4432/16104 [20:31:00<41:12:38, 12.71s/it]

 28%|██▊       | 4433/16104 [20:31:11<40:08:46, 12.38s/it]
{'loss': 0.3881, 'learning_rate': 1.7008215930287904e-06, 'rewards/chosen': -1.5425876379013062, 'rewards/rejected': -2.379700183868408, 'rewards/accuracies': 0.625, 'rewards/margins': 0.837112545967102, 'policy_logps/rejected': -226.6095428466797, 'policy_logps/chosen': -274.1160583496094, 'referece_logps/rejected': -202.81253051757812, 'referece_logps/chosen': -258.690185546875, 'logits/rejected': -0.6713312268257141, 'logits/chosen': -0.6532047390937805, 'epoch': 1.65}

 28%|██▊       | 4434/16104 [20:31:28<44:16:51, 13.66s/it]

 28%|██▊       | 4435/16104 [20:31:46<48:47:27, 15.05s/it]


 28%|██▊       | 4437/16104 [20:32:09<42:41:46, 13.17s/it]
{'loss': 0.429, 'learning_rate': 1.7002474833243522e-06, 'rewards/chosen': -0.9486271142959595, 'rewards/rejected': -2.699523448944092, 'rewards/accuracies': 0.75, 'rewards/margins': 1.750896692276001, 'policy_logps/rejected': -351.2720642089844, 'policy_logps/chosen': -323.7197570800781, 'referece_logps/rejected': -324.27679443359375, 'referece_logps/chosen': -314.2335205078125, 'logits/rejected': -0.2412586212158203, 'logits/chosen': -0.044509075582027435, 'epoch': 1.65}


 28%|██▊       | 4439/16104 [20:32:31<38:58:42, 12.03s/it]
{'loss': 0.4474, 'learning_rate': 1.699960258491345e-06, 'rewards/chosen': -0.9018909931182861, 'rewards/rejected': -2.588592529296875, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6867015361785889, 'policy_logps/rejected': -320.59039306640625, 'policy_logps/chosen': -594.5806884765625, 'referece_logps/rejected': -294.7044677734375, 'referece_logps/chosen': -585.561767578125, 'logits/rejected': -0.24263423681259155, 'logits/chosen': -0.3919258117675781, 'epoch': 1.65}

 28%|██▊       | 4440/16104 [20:32:42<37:59:46, 11.73s/it]


 28%|██▊       | 4442/16104 [20:33:07<38:56:56, 12.02s/it]
{'loss': 0.3922, 'learning_rate': 1.6995292088965529e-06, 'rewards/chosen': -0.9941295981407166, 'rewards/rejected': -1.9327458143234253, 'rewards/accuracies': 0.75, 'rewards/margins': 0.938616156578064, 'policy_logps/rejected': -303.60833740234375, 'policy_logps/chosen': -407.9328918457031, 'referece_logps/rejected': -284.2808837890625, 'referece_logps/chosen': -397.9915771484375, 'logits/rejected': -1.0886257886886597, 'logits/chosen': -0.9610205292701721, 'epoch': 1.65}


 28%|██▊       | 4444/16104 [20:33:32<38:44:02, 11.96s/it]
{'loss': 0.4651, 'learning_rate': 1.699241701004314e-06, 'rewards/chosen': -1.2889866828918457, 'rewards/rejected': -2.9735848903656006, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6845983266830444, 'policy_logps/rejected': -436.5479736328125, 'policy_logps/chosen': -470.99365234375, 'referece_logps/rejected': -406.8121337890625, 'referece_logps/chosen': -458.103759765625, 'logits/rejected': 0.3555152714252472, 'logits/chosen': 0.42383307218551636, 'epoch': 1.66}

 28%|██▊       | 4445/16104 [20:33:51<46:05:55, 14.23s/it]

 28%|██▊       | 4446/16104 [20:34:09<49:50:42, 15.39s/it]


 28%|██▊       | 4448/16104 [20:34:46<55:09:06, 17.03s/it]

 28%|██▊       | 4449/16104 [20:35:04<56:24:57, 17.43s/it]

 28%|██▊       | 4450/16104 [20:35:22<57:00:41, 17.61s/it]
{'loss': 0.3894, 'learning_rate': 1.6983784986599882e-06, 'rewards/chosen': -1.2914764881134033, 'rewards/rejected': -2.277639865875244, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9861631393432617, 'policy_logps/rejected': -215.26565551757812, 'policy_logps/chosen': -210.1546630859375, 'referece_logps/rejected': -192.4892578125, 'referece_logps/chosen': -197.23988342285156, 'logits/rejected': -0.519658088684082, 'logits/chosen': -0.3377593755722046, 'epoch': 1.66}

 28%|██▊       | 4451/16104 [20:35:42<59:42:05, 18.44s/it]

 28%|██▊       | 4452/16104 [20:35:55<53:40:45, 16.58s/it]

 28%|██▊       | 4453/16104 [20:36:13<55:14:33, 17.07s/it]

 28%|██▊       | 4454/16104 [20:36:27<52:15:18, 16.15s/it]

 28%|██▊       | 4455/16104 [20:36:45<54:16:52, 16.78s/it]

 28%|██▊       | 4456/16104 [20:37:07<58:47:04, 18.17s/it]

 28%|██▊       | 4457/16104 [20:37:21<54:46:30, 16.93s/it]


 28%|██▊       | 4459/16104 [20:37:48<49:47:31, 15.39s/it]
{'loss': 0.3648, 'learning_rate': 1.697081788617643e-06, 'rewards/chosen': -1.12179434299469, 'rewards/rejected': -2.1600341796875, 'rewards/accuracies': 1.0, 'rewards/margins': 1.03823983669281, 'policy_logps/rejected': -428.2862548828125, 'policy_logps/chosen': -398.2638244628906, 'referece_logps/rejected': -406.6859130859375, 'referece_logps/chosen': -387.0459289550781, 'logits/rejected': -0.05421874672174454, 'logits/chosen': -0.015782233327627182, 'epoch': 1.66}

 28%|██▊       | 4460/16104 [20:38:00<46:47:32, 14.47s/it]

 28%|██▊       | 4461/16104 [20:38:17<48:35:24, 15.02s/it]

 28%|██▊       | 4462/16104 [20:38:35<51:27:28, 15.91s/it]


 28%|██▊       | 4464/16104 [20:39:08<53:28:46, 16.54s/it]
{'loss': 0.5646, 'learning_rate': 1.6963604069405684e-06, 'rewards/chosen': -1.5576419830322266, 'rewards/rejected': -1.9937814474105835, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4361395239830017, 'policy_logps/rejected': -463.1977844238281, 'policy_logps/chosen': -454.61773681640625, 'referece_logps/rejected': -443.260009765625, 'referece_logps/chosen': -439.04132080078125, 'logits/rejected': -0.1514551341533661, 'logits/chosen': -0.18805018067359924, 'epoch': 1.66}

 28%|██▊       | 4465/16104 [20:39:24<52:29:51, 16.24s/it]

 28%|██▊       | 4466/16104 [20:39:37<49:06:53, 15.19s/it]


 28%|██▊       | 4468/16104 [20:40:12<54:07:35, 16.75s/it]
{'loss': 0.4324, 'learning_rate': 1.6957827945215283e-06, 'rewards/chosen': -2.519230604171753, 'rewards/rejected': -2.960879325866699, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4416487216949463, 'policy_logps/rejected': -305.2004699707031, 'policy_logps/chosen': -350.2593994140625, 'referece_logps/rejected': -275.5917053222656, 'referece_logps/chosen': -325.06707763671875, 'logits/rejected': -0.5277815461158752, 'logits/chosen': -0.6657425761222839, 'epoch': 1.66}


 28%|██▊       | 4470/16104 [20:40:48<56:42:16, 17.55s/it]
{'loss': 0.3904, 'learning_rate': 1.695493819414706e-06, 'rewards/chosen': -1.2167620658874512, 'rewards/rejected': -4.349087238311768, 'rewards/accuracies': 0.875, 'rewards/margins': 3.1323251724243164, 'policy_logps/rejected': -310.50030517578125, 'policy_logps/chosen': -479.66259765625, 'referece_logps/rejected': -267.00946044921875, 'referece_logps/chosen': -467.49493408203125, 'logits/rejected': -0.9062774181365967, 'logits/chosen': -1.007142424583435, 'epoch': 1.67}

 28%|██▊       | 4471/16104 [20:41:02<52:53:12, 16.37s/it]

 28%|██▊       | 4472/16104 [20:41:19<54:01:31, 16.72s/it]

 28%|██▊       | 4473/16104 [20:41:31<49:23:48, 15.29s/it]


 28%|██▊       | 4475/16104 [20:41:54<43:38:46, 13.51s/it]
{'loss': 0.493, 'learning_rate': 1.6947708894055774e-06, 'rewards/chosen': -1.2313207387924194, 'rewards/rejected': -1.9487230777740479, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7174023389816284, 'policy_logps/rejected': -289.1288757324219, 'policy_logps/chosen': -310.9231872558594, 'referece_logps/rejected': -269.6416320800781, 'referece_logps/chosen': -298.6099548339844, 'logits/rejected': 0.7652133703231812, 'logits/chosen': 0.8341994285583496, 'epoch': 1.67}

 28%|██▊       | 4476/16104 [20:42:08<43:23:44, 13.44s/it]


 28%|██▊       | 4478/16104 [20:42:48<54:36:35, 16.91s/it]

 28%|██▊       | 4479/16104 [20:43:08<57:43:49, 17.88s/it]
{'loss': 0.6178, 'learning_rate': 1.6941920394781976e-06, 'rewards/chosen': -1.6600112915039062, 'rewards/rejected': -2.3546361923217773, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6946251392364502, 'policy_logps/rejected': -407.0460205078125, 'policy_logps/chosen': -299.66339111328125, 'referece_logps/rejected': -383.49969482421875, 'referece_logps/chosen': -283.06329345703125, 'logits/rejected': -0.035296715795993805, 'logits/chosen': 0.03120102733373642, 'epoch': 1.67}

 28%|██▊       | 4480/16104 [20:43:20<51:17:12, 15.88s/it]

 28%|██▊       | 4481/16104 [20:43:38<53:20:50, 16.52s/it]

 28%|██▊       | 4482/16104 [20:43:57<56:32:04, 17.51s/it]

 28%|██▊       | 4483/16104 [20:44:12<53:39:46, 16.62s/it]

 28%|██▊       | 4484/16104 [20:44:31<56:28:03, 17.49s/it]

 28%|██▊       | 4485/16104 [20:44:43<50:26:56, 15.63s/it]

 28%|██▊       | 4486/16104 [20:44:53<45:33:59, 14.12s/it]

 28%|██▊       | 4487/16104 [20:45:11<49:12:03, 15.25s/it]

 28%|██▊       | 4488/16104 [20:45:23<45:58:46, 14.25s/it]


 28%|██▊       | 4490/16104 [20:46:00<52:24:43, 16.25s/it]
{'loss': 0.4459, 'learning_rate': 1.6925978865981216e-06, 'rewards/chosen': -2.0909595489501953, 'rewards/rejected': -3.6045029163360596, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5135436058044434, 'policy_logps/rejected': -515.99072265625, 'policy_logps/chosen': -467.2346496582031, 'referece_logps/rejected': -479.9456787109375, 'referece_logps/chosen': -446.3250732421875, 'logits/rejected': -0.702701210975647, 'logits/chosen': -0.3972965478897095, 'epoch': 1.67}


 28%|██▊       | 4492/16104 [20:46:35<52:48:23, 16.37s/it]
{'loss': 0.4446, 'learning_rate': 1.6923076761725088e-06, 'rewards/chosen': -0.9801269173622131, 'rewards/rejected': -2.33020281791687, 'rewards/accuracies': 0.875, 'rewards/margins': 1.350075602531433, 'policy_logps/rejected': -456.1828308105469, 'policy_logps/chosen': -454.37786865234375, 'referece_logps/rejected': -432.88079833984375, 'referece_logps/chosen': -444.57659912109375, 'logits/rejected': -0.9239268898963928, 'logits/chosen': -0.7453327775001526, 'epoch': 1.67}


 28%|██▊       | 4494/16104 [20:47:11<55:06:40, 17.09s/it]
{'loss': 0.4751, 'learning_rate': 1.6920173537265734e-06, 'rewards/chosen': -1.0763157606124878, 'rewards/rejected': -2.803011417388916, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7266955375671387, 'policy_logps/rejected': -219.33370971679688, 'policy_logps/chosen': -268.53863525390625, 'referece_logps/rejected': -191.30360412597656, 'referece_logps/chosen': -257.77545166015625, 'logits/rejected': -0.0793125182390213, 'logits/chosen': -0.1652165949344635, 'epoch': 1.67}

 28%|██▊       | 4495/16104 [20:47:32<58:53:40, 18.26s/it]


 28%|██▊       | 4497/16104 [20:48:07<56:59:09, 17.67s/it]
{'loss': 0.3715, 'learning_rate': 1.6915816601223312e-06, 'rewards/chosen': -1.1740729808807373, 'rewards/rejected': -3.167506217956543, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9934329986572266, 'policy_logps/rejected': -293.009033203125, 'policy_logps/chosen': -334.819091796875, 'referece_logps/rejected': -261.33392333984375, 'referece_logps/chosen': -323.078369140625, 'logits/rejected': -0.4132396876811981, 'logits/chosen': -0.43640008568763733, 'epoch': 1.68}


 28%|██▊       | 4499/16104 [20:48:47<60:43:05, 18.84s/it]
{'loss': 0.4039, 'learning_rate': 1.69129105783115e-06, 'rewards/chosen': -0.8991243839263916, 'rewards/rejected': -2.1268210411071777, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2276966571807861, 'policy_logps/rejected': -360.0225524902344, 'policy_logps/chosen': -364.5687255859375, 'referece_logps/rejected': -338.75433349609375, 'referece_logps/chosen': -355.5774841308594, 'logits/rejected': -0.7463222742080688, 'logits/chosen': -0.7294365763664246, 'epoch': 1.68}

 28%|██▊       | 4500/16104 [20:49:04<59:11:50, 18.37s/it]


 28%|██▊       | 4502/16104 [20:49:41<57:09:56, 17.74s/it]
{'loss': 0.4047, 'learning_rate': 1.6908549446794032e-06, 'rewards/chosen': -0.635209321975708, 'rewards/rejected': -2.146390438079834, 'rewards/accuracies': 1.0, 'rewards/margins': 1.511181116104126, 'policy_logps/rejected': -423.5590515136719, 'policy_logps/chosen': -475.6947937011719, 'referece_logps/rejected': -402.09515380859375, 'referece_logps/chosen': -469.34271240234375, 'logits/rejected': -0.2374153733253479, 'logits/chosen': -0.14630597829818726, 'epoch': 1.68}

 28%|██▊       | 4503/16104 [20:49:52<50:27:16, 15.66s/it]

 28%|██▊       | 4504/16104 [20:50:02<45:47:07, 14.21s/it]

 28%|██▊       | 4505/16104 [20:50:22<51:12:21, 15.89s/it]

 28%|██▊       | 4506/16104 [20:50:40<52:38:47, 16.34s/it]

 28%|██▊       | 4507/16104 [20:50:56<53:06:11, 16.48s/it]


 28%|██▊       | 4509/16104 [20:51:39<61:13:06, 19.01s/it]
{'loss': 0.3194, 'learning_rate': 1.6898363694789124e-06, 'rewards/chosen': -1.0501042604446411, 'rewards/rejected': -2.1876609325408936, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1375566720962524, 'policy_logps/rejected': -371.22735595703125, 'policy_logps/chosen': -321.1805419921875, 'referece_logps/rejected': -349.3507385253906, 'referece_logps/chosen': -310.67950439453125, 'logits/rejected': 0.04447733238339424, 'logits/chosen': 0.18168243765830994, 'epoch': 1.68}


 28%|██▊       | 4511/16104 [20:52:15<59:50:07, 18.58s/it]

 28%|██▊       | 4512/16104 [20:52:29<55:24:58, 17.21s/it]
{'loss': 0.3738, 'learning_rate': 1.6893994185556965e-06, 'rewards/chosen': -1.3442919254302979, 'rewards/rejected': -2.5861082077026367, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2418162822723389, 'policy_logps/rejected': -339.4598083496094, 'policy_logps/chosen': -374.03582763671875, 'referece_logps/rejected': -313.5987548828125, 'referece_logps/chosen': -360.5928649902344, 'logits/rejected': -0.8130632042884827, 'logits/chosen': -0.7217322587966919, 'epoch': 1.68}

 28%|██▊       | 4513/16104 [20:52:41<50:44:00, 15.76s/it]


 28%|██▊       | 4515/16104 [20:53:17<53:39:56, 16.67s/it]

 28%|██▊       | 4516/16104 [20:53:29<49:22:54, 15.34s/it]
{'loss': 0.4386, 'learning_rate': 1.6888164269281473e-06, 'rewards/chosen': -2.1045753955841064, 'rewards/rejected': -3.5521626472473145, 'rewards/accuracies': 0.625, 'rewards/margins': 1.447587251663208, 'policy_logps/rejected': -465.0255432128906, 'policy_logps/chosen': -301.88006591796875, 'referece_logps/rejected': -429.50396728515625, 'referece_logps/chosen': -280.8343200683594, 'logits/rejected': -0.35040542483329773, 'logits/chosen': -0.07908770442008972, 'epoch': 1.68}

 28%|██▊       | 4517/16104 [20:53:44<48:36:02, 15.10s/it]

 28%|██▊       | 4518/16104 [20:53:54<44:30:31, 13.83s/it]

 28%|██▊       | 4519/16104 [20:54:13<48:37:05, 15.11s/it]

 28%|██▊       | 4520/16104 [20:54:30<51:19:54, 15.95s/it]

 28%|██▊       | 4521/16104 [20:54:50<54:22:54, 16.90s/it]

 28%|██▊       | 4522/16104 [20:55:08<55:53:24, 17.37s/it]


 28%|██▊       | 4524/16104 [20:55:39<52:21:23, 16.28s/it]
{'loss': 0.3951, 'learning_rate': 1.6876491065857584e-06, 'rewards/chosen': -0.9748113751411438, 'rewards/rejected': -2.2006564140319824, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2258449792861938, 'policy_logps/rejected': -287.6685485839844, 'policy_logps/chosen': -497.74188232421875, 'referece_logps/rejected': -265.6619873046875, 'referece_logps/chosen': -487.9938049316406, 'logits/rejected': 0.04217936098575592, 'logits/chosen': -0.01128387451171875, 'epoch': 1.69}

 28%|██▊       | 4525/16104 [20:55:59<55:40:31, 17.31s/it]

 28%|██▊       | 4526/16104 [20:56:20<59:17:37, 18.44s/it]

 28%|██▊       | 4527/16104 [20:56:40<60:47:25, 18.90s/it]

 28%|██▊       | 4528/16104 [20:57:00<61:29:00, 19.12s/it]

 28%|██▊       | 4529/16104 [20:57:15<57:46:31, 17.97s/it]

 28%|██▊       | 4530/16104 [20:57:26<51:04:23, 15.89s/it]

 28%|██▊       | 4531/16104 [20:57:42<51:28:19, 16.01s/it]

 28%|██▊       | 4532/16104 [20:57:53<46:15:50, 14.39s/it]

 28%|██▊       | 4533/16104 [20:58:10<48:43:22, 15.16s/it]

 28%|██▊       | 4534/16104 [20:58:26<49:55:55, 15.54s/it]

 28%|██▊       | 4535/16104 [20:58:38<46:31:11, 14.48s/it]

 28%|██▊       | 4536/16104 [20:58:59<52:18:31, 16.28s/it]

 28%|██▊       | 4537/16104 [20:59:13<50:14:40, 15.64s/it]

 28%|██▊       | 4538/16104 [20:59:26<47:45:19, 14.86s/it]

 28%|██▊       | 4539/16104 [20:59:39<45:44:27, 14.24s/it]


 28%|██▊       | 4541/16104 [21:00:11<50:25:06, 15.70s/it]
{'loss': 0.4682, 'learning_rate': 1.685162643593601e-06, 'rewards/chosen': -0.6884474158287048, 'rewards/rejected': -2.3086414337158203, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6201939582824707, 'policy_logps/rejected': -398.87469482421875, 'policy_logps/chosen': -503.54388427734375, 'referece_logps/rejected': -375.78826904296875, 'referece_logps/chosen': -496.659423828125, 'logits/rejected': 0.05304881930351257, 'logits/chosen': 0.09776930510997772, 'epoch': 1.69}


 28%|██▊       | 4543/16104 [21:00:41<49:41:03, 15.47s/it]
{'loss': 0.4879, 'learning_rate': 1.684869591368197e-06, 'rewards/chosen': -1.2867374420166016, 'rewards/rejected': -2.674365520477295, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3876279592514038, 'policy_logps/rejected': -358.0303955078125, 'policy_logps/chosen': -489.17657470703125, 'referece_logps/rejected': -331.2867431640625, 'referece_logps/chosen': -476.3092041015625, 'logits/rejected': 0.4029720425605774, 'logits/chosen': 0.47761645913124084, 'epoch': 1.69}

 28%|██▊       | 4544/16104 [21:00:52<45:08:18, 14.06s/it]

 28%|██▊       | 4545/16104 [21:01:06<45:11:52, 14.08s/it]

 28%|██▊       | 4546/16104 [21:01:21<46:09:02, 14.37s/it]

 28%|██▊       | 4547/16104 [21:01:35<45:18:06, 14.11s/it]


 28%|██▊       | 4549/16104 [21:02:06<48:36:45, 15.15s/it]
{'loss': 0.3816, 'learning_rate': 1.6839897699810208e-06, 'rewards/chosen': -1.587673306465149, 'rewards/rejected': -4.070516109466553, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4828426837921143, 'policy_logps/rejected': -512.138671875, 'policy_logps/chosen': -297.2430725097656, 'referece_logps/rejected': -471.43359375, 'referece_logps/chosen': -281.3663635253906, 'logits/rejected': -0.804132342338562, 'logits/chosen': -0.6036020517349243, 'epoch': 1.69}

 28%|██▊       | 4550/16104 [21:02:25<52:38:19, 16.40s/it]


 28%|██▊       | 4552/16104 [21:02:56<49:31:15, 15.43s/it]

 28%|██▊       | 4553/16104 [21:03:18<55:48:20, 17.39s/it]
{'loss': 0.5085, 'learning_rate': 1.6834026689383507e-06, 'rewards/chosen': -0.9261586666107178, 'rewards/rejected': -2.399834632873535, 'rewards/accuracies': 1.0, 'rewards/margins': 1.473676085472107, 'policy_logps/rejected': -507.8597412109375, 'policy_logps/chosen': -463.07806396484375, 'referece_logps/rejected': -483.86138916015625, 'referece_logps/chosen': -453.81646728515625, 'logits/rejected': -0.2403959333896637, 'logits/chosen': -0.0419580340385437, 'epoch': 1.7}

 28%|██▊       | 4554/16104 [21:03:32<53:20:32, 16.63s/it]

 28%|██▊       | 4555/16104 [21:03:51<54:54:48, 17.12s/it]

 28%|██▊       | 4556/16104 [21:04:10<57:20:12, 17.87s/it]

 28%|██▊       | 4557/16104 [21:04:30<59:10:58, 18.45s/it]

 28%|██▊       | 4558/16104 [21:04:42<52:19:29, 16.31s/it]

 28%|██▊       | 4559/16104 [21:05:02<56:33:00, 17.63s/it]

 28%|██▊       | 4560/16104 [21:05:21<57:19:42, 17.88s/it]

 28%|██▊       | 4561/16104 [21:05:31<50:25:14, 15.73s/it]

 28%|██▊       | 4562/16104 [21:05:47<50:07:05, 15.63s/it]

 28%|██▊       | 4563/16104 [21:06:01<48:56:35, 15.27s/it]

 28%|██▊       | 4564/16104 [21:06:13<45:18:50, 14.14s/it]

 28%|██▊       | 4565/16104 [21:06:24<42:27:08, 13.24s/it]


 28%|██▊       | 4567/16104 [21:06:54<45:35:43, 14.23s/it]

 28%|██▊       | 4568/16104 [21:07:09<46:28:35, 14.50s/it]

 28%|██▊       | 4569/16104 [21:07:20<42:54:56, 13.39s/it]

 28%|██▊       | 4570/16104 [21:07:30<40:18:36, 12.58s/it]

 28%|██▊       | 4571/16104 [21:07:41<38:50:05, 12.12s/it]
{'loss': 0.5287, 'learning_rate': 1.6807552460576285e-06, 'rewards/chosen': -1.0976231098175049, 'rewards/rejected': -1.2344355583190918, 'rewards/accuracies': 0.625, 'rewards/margins': 0.13681243360042572, 'policy_logps/rejected': -388.51995849609375, 'policy_logps/chosen': -417.2268371582031, 'referece_logps/rejected': -376.17559814453125, 'referece_logps/chosen': -406.2506408691406, 'logits/rejected': 0.10541330277919769, 'logits/chosen': 0.01932375133037567, 'epoch': 1.7}


 28%|██▊       | 4573/16104 [21:08:10<43:22:05, 13.54s/it]

 28%|██▊       | 4574/16104 [21:08:30<49:21:00, 15.41s/it]
{'loss': 0.2654, 'learning_rate': 1.6803131405334284e-06, 'rewards/chosen': -1.0110350847244263, 'rewards/rejected': -1.9990737438201904, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9880385994911194, 'policy_logps/rejected': -297.75286865234375, 'policy_logps/chosen': -416.1815185546875, 'referece_logps/rejected': -277.76214599609375, 'referece_logps/chosen': -406.0711669921875, 'logits/rejected': -0.2774403393268585, 'logits/chosen': -0.361284464597702, 'epoch': 1.7}


 28%|██▊       | 4576/16104 [21:09:00<47:52:51, 14.95s/it]

 28%|██▊       | 4577/16104 [21:09:12<45:01:37, 14.06s/it]

 28%|██▊       | 4578/16104 [21:09:27<45:50:01, 14.32s/it]

 28%|██▊       | 4579/16104 [21:09:46<50:16:55, 15.71s/it]

 28%|██▊       | 4580/16104 [21:10:04<52:56:26, 16.54s/it]

 28%|██▊       | 4581/16104 [21:10:24<55:55:17, 17.47s/it]

 28%|██▊       | 4582/16104 [21:10:43<57:51:55, 18.08s/it]

 28%|██▊       | 4583/16104 [21:11:03<59:39:28, 18.64s/it]

 28%|██▊       | 4584/16104 [21:11:15<53:15:31, 16.64s/it]

 28%|██▊       | 4585/16104 [21:11:35<56:07:30, 17.54s/it]

 28%|██▊       | 4586/16104 [21:11:51<54:54:35, 17.16s/it]
{'loss': 0.394, 'learning_rate': 1.678542243258354e-06, 'rewards/chosen': -2.1308536529541016, 'rewards/rejected': -4.546376705169678, 'rewards/accuracies': 0.875, 'rewards/margins': 2.415523052215576, 'policy_logps/rejected': -253.838623046875, 'policy_logps/chosen': -344.01409912109375, 'referece_logps/rejected': -208.37484741210938, 'referece_logps/chosen': -322.70550537109375, 'logits/rejected': -0.7626932263374329, 'logits/chosen': -0.8073217868804932, 'epoch': 1.71}


 28%|██▊       | 4588/16104 [21:12:32<60:08:37, 18.80s/it]

 28%|██▊       | 4589/16104 [21:12:51<60:09:06, 18.81s/it]

 29%|██▊       | 4590/16104 [21:13:02<52:50:54, 16.52s/it]

 29%|██▊       | 4591/16104 [21:13:18<52:13:12, 16.33s/it]

 29%|██▊       | 4592/16104 [21:13:29<47:12:20, 14.76s/it]

 29%|██▊       | 4593/16104 [21:13:43<46:25:26, 14.52s/it]

 29%|██▊       | 4594/16104 [21:13:56<45:06:05, 14.11s/it]

 29%|██▊       | 4595/16104 [21:14:16<50:34:00, 15.82s/it]

 29%|██▊       | 4596/16104 [21:14:34<52:46:35, 16.51s/it]

 29%|██▊       | 4597/16104 [21:14:55<56:22:50, 17.64s/it]

 29%|██▊       | 4598/16104 [21:15:09<53:44:14, 16.81s/it]

 29%|██▊       | 4599/16104 [21:15:29<56:21:26, 17.63s/it]

 29%|██▊       | 4600/16104 [21:15:41<50:51:41, 15.92s/it]

 29%|██▊       | 4601/16104 [21:16:00<53:46:51, 16.83s/it]

 29%|██▊       | 4602/16104 [21:16:20<56:27:53, 17.67s/it]

 29%|██▊       | 4603/16104 [21:16:38<57:28:22, 17.99s/it]

 29%|██▊       | 4604/16104 [21:16:56<57:19:05, 17.94s/it]

 29%|██▊       | 4605/16104 [21:17:15<58:33:24, 18.33s/it]

 29%|██▊       | 4606/16104 [21:17:32<56:41:54, 17.75s/it]

 29%|██▊       | 4607/16104 [21:17:50<57:01:56, 17.86s/it]

 29%|██▊       | 4608/16104 [21:18:01<50:50:13, 15.92s/it]

 29%|██▊       | 4609/16104 [21:18:23<56:38:50, 17.74s/it]

 29%|██▊       | 4610/16104 [21:18:44<59:07:21, 18.52s/it]

 29%|██▊       | 4611/16104 [21:19:04<60:49:02, 19.05s/it]

 29%|██▊       | 4612/16104 [21:19:23<60:43:41, 19.02s/it]

 29%|██▊       | 4613/16104 [21:19:34<53:11:26, 16.66s/it]

 29%|██▊       | 4614/16104 [21:19:45<47:28:05, 14.87s/it]

 29%|██▊       | 4615/16104 [21:19:56<44:01:03, 13.79s/it]

 29%|██▊       | 4616/16104 [21:20:16<49:43:19, 15.58s/it]

 29%|██▊       | 4617/16104 [21:20:36<54:22:44, 17.04s/it]

 29%|██▊       | 4618/16104 [21:20:51<52:35:56, 16.49s/it]

 29%|██▊       | 4619/16104 [21:21:12<56:19:44, 17.66s/it]

 29%|██▊       | 4620/16104 [21:21:32<58:45:04, 18.42s/it]

 29%|██▊       | 4621/16104 [21:21:48<56:27:25, 17.70s/it]
{'loss': 0.3938, 'learning_rate': 1.6733545877826644e-06, 'rewards/chosen': -1.582442045211792, 'rewards/rejected': -4.056248664855957, 'rewards/accuracies': 1.0, 'rewards/margins': 2.473806381225586, 'policy_logps/rejected': -381.6275329589844, 'policy_logps/chosen': -395.24468994140625, 'referece_logps/rejected': -341.0650329589844, 'referece_logps/chosen': -379.4202575683594, 'logits/rejected': -0.8361761569976807, 'logits/chosen': -0.684634804725647, 'epoch': 1.72}


 29%|██▊       | 4623/16104 [21:22:26<58:04:47, 18.21s/it]

 29%|██▊       | 4624/16104 [21:22:47<60:21:59, 18.93s/it]

 29%|██▊       | 4625/16104 [21:23:02<56:48:36, 17.82s/it]

 29%|██▊       | 4626/16104 [21:23:18<55:03:09, 17.27s/it]

 29%|██▊       | 4627/16104 [21:23:35<54:41:15, 17.15s/it]

 29%|██▊       | 4628/16104 [21:23:48<50:31:22, 15.85s/it]

 29%|██▊       | 4629/16104 [21:24:02<48:42:02, 15.28s/it]

 29%|██▉       | 4630/16104 [21:24:21<52:39:17, 16.52s/it]
{'loss': 0.4033, 'learning_rate': 1.672015215725839e-06, 'rewards/chosen': -1.7589011192321777, 'rewards/rejected': -2.5776896476745605, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8187887072563171, 'policy_logps/rejected': -552.16357421875, 'policy_logps/chosen': -394.61376953125, 'referece_logps/rejected': -526.3866577148438, 'referece_logps/chosen': -377.0247802734375, 'logits/rejected': -1.2379403114318848, 'logits/chosen': -1.1830724477767944, 'epoch': 1.73}


 29%|██▉       | 4632/16104 [21:24:48<47:14:51, 14.83s/it]

 29%|██▉       | 4633/16104 [21:25:09<53:13:41, 16.70s/it]

 29%|██▉       | 4634/16104 [21:25:26<53:34:17, 16.81s/it]
{'loss': 0.4761, 'learning_rate': 1.6714192322056186e-06, 'rewards/chosen': -1.18960440158844, 'rewards/rejected': -2.622978687286377, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4333744049072266, 'policy_logps/rejected': -271.2164611816406, 'policy_logps/chosen': -236.16781616210938, 'referece_logps/rejected': -244.9866943359375, 'referece_logps/chosen': -224.27178955078125, 'logits/rejected': -1.1653422117233276, 'logits/chosen': -1.1527961492538452, 'epoch': 1.73}


 29%|██▉       | 4636/16104 [21:26:03<56:21:31, 17.69s/it]

 29%|██▉       | 4637/16104 [21:26:23<58:21:45, 18.32s/it]
{'loss': 0.392, 'learning_rate': 1.6709719593632484e-06, 'rewards/chosen': -1.525264859199524, 'rewards/rejected': -2.875619411468506, 'rewards/accuracies': 0.875, 'rewards/margins': 1.350354552268982, 'policy_logps/rejected': -362.11474609375, 'policy_logps/chosen': -429.6684875488281, 'referece_logps/rejected': -333.3585205078125, 'referece_logps/chosen': -414.41583251953125, 'logits/rejected': -0.36104220151901245, 'logits/chosen': -0.29515600204467773, 'epoch': 1.73}


 29%|██▉       | 4639/16104 [21:27:01<59:00:14, 18.53s/it]

 29%|██▉       | 4640/16104 [21:27:12<51:36:06, 16.20s/it]

 29%|██▉       | 4641/16104 [21:27:27<50:51:20, 15.97s/it]
{'loss': 0.4584, 'learning_rate': 1.6703752156134057e-06, 'rewards/chosen': -1.025972843170166, 'rewards/rejected': -1.8907991647720337, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8648264408111572, 'policy_logps/rejected': -333.1635437011719, 'policy_logps/chosen': -420.0001220703125, 'referece_logps/rejected': -314.25555419921875, 'referece_logps/chosen': -409.74041748046875, 'logits/rejected': -0.1903601586818695, 'logits/chosen': -0.3677975535392761, 'epoch': 1.73}


 29%|██▉       | 4643/16104 [21:27:58<48:54:58, 15.36s/it]
{'loss': 0.4329, 'learning_rate': 1.6700766810070997e-06, 'rewards/chosen': -1.6258468627929688, 'rewards/rejected': -2.6222636699676514, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9964168071746826, 'policy_logps/rejected': -359.56982421875, 'policy_logps/chosen': -461.201171875, 'referece_logps/rejected': -333.34722900390625, 'referece_logps/chosen': -444.9427185058594, 'logits/rejected': -0.6521158814430237, 'logits/chosen': -0.5936341285705566, 'epoch': 1.73}


 29%|██▉       | 4645/16104 [21:28:39<56:41:01, 17.81s/it]

 29%|██▉       | 4646/16104 [21:28:57<56:29:02, 17.75s/it]

 29%|██▉       | 4647/16104 [21:29:19<60:42:30, 19.08s/it]

 29%|██▉       | 4648/16104 [21:29:40<62:46:46, 19.73s/it]

 29%|██▉       | 4649/16104 [21:30:02<64:28:13, 20.26s/it]
{'loss': 0.2782, 'learning_rate': 1.6691804268423565e-06, 'rewards/chosen': -1.060805082321167, 'rewards/rejected': -2.666295051574707, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6054900884628296, 'policy_logps/rejected': -245.69288635253906, 'policy_logps/chosen': -302.6902160644531, 'referece_logps/rejected': -219.02993774414062, 'referece_logps/chosen': -292.0821533203125, 'logits/rejected': -0.9043366312980652, 'logits/chosen': -0.9568692445755005, 'epoch': 1.73}


 29%|██▉       | 4651/16104 [21:30:35<59:19:41, 18.65s/it]

 29%|██▉       | 4652/16104 [21:30:47<52:57:20, 16.65s/it]

 29%|██▉       | 4653/16104 [21:31:04<53:03:26, 16.68s/it]

 29%|██▉       | 4654/16104 [21:31:17<49:36:20, 15.60s/it]

 29%|██▉       | 4655/16104 [21:31:28<45:19:13, 14.25s/it]

 29%|██▉       | 4656/16104 [21:31:49<51:10:34, 16.09s/it]

 29%|██▉       | 4657/16104 [21:32:09<54:58:51, 17.29s/it]

 29%|██▉       | 4658/16104 [21:32:29<57:21:53, 18.04s/it]

 29%|██▉       | 4659/16104 [21:32:49<59:49:33, 18.82s/it]

 29%|██▉       | 4660/16104 [21:33:10<61:39:37, 19.40s/it]

 29%|██▉       | 4661/16104 [21:33:24<56:41:10, 17.83s/it]

 29%|██▉       | 4662/16104 [21:33:38<52:50:14, 16.62s/it]

 29%|██▉       | 4663/16104 [21:33:54<52:40:42, 16.58s/it]

 29%|██▉       | 4664/16104 [21:34:11<52:55:10, 16.65s/it]

 29%|██▉       | 4665/16104 [21:34:31<55:39:20, 17.52s/it]

 29%|██▉       | 4666/16104 [21:34:52<59:25:53, 18.71s/it]

 29%|██▉       | 4667/16104 [21:35:08<56:13:03, 17.70s/it]

 29%|██▉       | 4668/16104 [21:35:21<51:54:03, 16.34s/it]

 29%|██▉       | 4669/16104 [21:35:38<52:35:11, 16.56s/it]
{'loss': 0.4621, 'learning_rate': 1.6661858822218892e-06, 'rewards/chosen': -1.0105233192443848, 'rewards/rejected': -1.6937617063522339, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6832383871078491, 'policy_logps/rejected': -384.5401306152344, 'policy_logps/chosen': -393.8077392578125, 'referece_logps/rejected': -367.6025695800781, 'referece_logps/chosen': -383.7024841308594, 'logits/rejected': -0.9840032458305359, 'logits/chosen': -1.0548380613327026, 'epoch': 1.74}


 29%|██▉       | 4671/16104 [21:36:07<49:52:10, 15.70s/it]
{'loss': 0.4662, 'learning_rate': 1.6658858340946687e-06, 'rewards/chosen': -1.325158715248108, 'rewards/rejected': -1.7719881534576416, 'rewards/accuracies': 0.625, 'rewards/margins': 0.44682949781417847, 'policy_logps/rejected': -277.8722229003906, 'policy_logps/chosen': -353.5586853027344, 'referece_logps/rejected': -260.15234375, 'referece_logps/chosen': -340.30712890625, 'logits/rejected': -0.08989626169204712, 'logits/chosen': -0.30331340432167053, 'epoch': 1.74}


 29%|██▉       | 4673/16104 [21:36:49<58:14:14, 18.34s/it]
{'loss': 0.3605, 'learning_rate': 1.665585678222368e-06, 'rewards/chosen': -0.7231475114822388, 'rewards/rejected': -3.5528087615966797, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8296608924865723, 'policy_logps/rejected': -490.72723388671875, 'policy_logps/chosen': -414.461181640625, 'referece_logps/rejected': -455.1991271972656, 'referece_logps/chosen': -407.2297058105469, 'logits/rejected': -0.07416778802871704, 'logits/chosen': -0.07709720730781555, 'epoch': 1.74}


 29%|██▉       | 4675/16104 [21:37:23<56:23:51, 17.76s/it]

 29%|██▉       | 4676/16104 [21:37:46<60:29:59, 19.06s/it]

 29%|██▉       | 4677/16104 [21:38:05<61:10:07, 19.27s/it]
{'loss': 0.4323, 'learning_rate': 1.6649850434368138e-06, 'rewards/chosen': -1.5394140481948853, 'rewards/rejected': -2.50557279586792, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9661588072776794, 'policy_logps/rejected': -372.1300354003906, 'policy_logps/chosen': -404.40338134765625, 'referece_logps/rejected': -347.0743408203125, 'referece_logps/chosen': -389.0092468261719, 'logits/rejected': -0.6462966203689575, 'logits/chosen': -0.621883749961853, 'epoch': 1.74}


 29%|██▉       | 4679/16104 [21:38:43<60:23:30, 19.03s/it]

 29%|██▉       | 4680/16104 [21:38:58<56:19:23, 17.75s/it]
{'loss': 0.3453, 'learning_rate': 1.6645342848781595e-06, 'rewards/chosen': -0.957695484161377, 'rewards/rejected': -2.2987442016601562, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3410489559173584, 'policy_logps/rejected': -190.95721435546875, 'policy_logps/chosen': -444.28997802734375, 'referece_logps/rejected': -167.9697723388672, 'referece_logps/chosen': -434.7130126953125, 'logits/rejected': -0.017836663872003555, 'logits/chosen': 0.05541365593671799, 'epoch': 1.74}

 29%|██▉       | 4681/16104 [21:39:13<53:37:12, 16.90s/it]


 29%|██▉       | 4683/16104 [21:39:48<55:54:07, 17.62s/it]

 29%|██▉       | 4684/16104 [21:40:08<58:23:32, 18.41s/it]
{'loss': 0.5362, 'learning_rate': 1.66393289715264e-06, 'rewards/chosen': -1.1058874130249023, 'rewards/rejected': -2.3105273246765137, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2046395540237427, 'policy_logps/rejected': -483.0418701171875, 'policy_logps/chosen': -321.0118408203125, 'referece_logps/rejected': -459.9365539550781, 'referece_logps/chosen': -309.95294189453125, 'logits/rejected': 0.046305835247039795, 'logits/chosen': 0.1837465614080429, 'epoch': 1.75}

 29%|██▉       | 4685/16104 [21:40:21<52:40:48, 16.61s/it]


 29%|██▉       | 4687/16104 [21:40:45<45:29:17, 14.34s/it]

 29%|██▉       | 4688/16104 [21:41:06<51:17:40, 16.18s/it]

 29%|██▉       | 4689/16104 [21:41:19<48:43:47, 15.37s/it]

 29%|██▉       | 4690/16104 [21:41:33<47:12:20, 14.89s/it]

 29%|██▉       | 4691/16104 [21:41:51<50:15:48, 15.85s/it]

 29%|██▉       | 4692/16104 [21:42:12<54:31:07, 17.20s/it]
{'loss': 0.419, 'learning_rate': 1.6627288329421973e-06, 'rewards/chosen': -1.2251683473587036, 'rewards/rejected': -2.1336703300476074, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9085021018981934, 'policy_logps/rejected': -352.4371643066406, 'policy_logps/chosen': -370.57830810546875, 'referece_logps/rejected': -331.1004943847656, 'referece_logps/chosen': -358.32659912109375, 'logits/rejected': -1.0531469583511353, 'logits/chosen': -1.0214293003082275, 'epoch': 1.75}

 29%|██▉       | 4693/16104 [21:42:28<54:11:12, 17.10s/it]


 29%|██▉       | 4695/16104 [21:42:58<49:59:48, 15.78s/it]

 29%|██▉       | 4696/16104 [21:43:21<57:07:19, 18.03s/it]

 29%|██▉       | 4697/16104 [21:43:37<55:17:52, 17.45s/it]

 29%|██▉       | 4698/16104 [21:43:56<56:46:23, 17.92s/it]

 29%|██▉       | 4699/16104 [21:44:09<52:06:09, 16.45s/it]
{'loss': 0.3846, 'learning_rate': 1.6616738692020977e-06, 'rewards/chosen': -1.9048540592193604, 'rewards/rejected': -3.5482935905456543, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6434398889541626, 'policy_logps/rejected': -272.99267578125, 'policy_logps/chosen': -518.105712890625, 'referece_logps/rejected': -237.5097198486328, 'referece_logps/chosen': -499.05718994140625, 'logits/rejected': -0.7591032981872559, 'logits/chosen': -0.8329955339431763, 'epoch': 1.75}

 29%|██▉       | 4700/16104 [21:44:27<53:07:45, 16.77s/it]


 29%|██▉       | 4702/16104 [21:44:52<46:05:34, 14.55s/it]

 29%|██▉       | 4703/16104 [21:45:08<48:18:06, 15.25s/it]

 29%|██▉       | 4704/16104 [21:45:23<48:02:29, 15.17s/it]

 29%|██▉       | 4705/16104 [21:45:40<49:07:49, 15.52s/it]
{'loss': 0.3908, 'learning_rate': 1.6607685706189094e-06, 'rewards/chosen': -1.5273689031600952, 'rewards/rejected': -2.1846511363983154, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6572822332382202, 'policy_logps/rejected': -316.33160400390625, 'policy_logps/chosen': -413.82012939453125, 'referece_logps/rejected': -294.485107421875, 'referece_logps/chosen': -398.5464782714844, 'logits/rejected': 0.13555961847305298, 'logits/chosen': 0.003244195133447647, 'epoch': 1.75}

 29%|██▉       | 4706/16104 [21:45:57<50:42:11, 16.01s/it]


 29%|██▉       | 4708/16104 [21:46:31<52:26:26, 16.57s/it]
{'loss': 0.3631, 'learning_rate': 1.6603155603997908e-06, 'rewards/chosen': -1.4843239784240723, 'rewards/rejected': -3.0275819301605225, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5432579517364502, 'policy_logps/rejected': -372.07745361328125, 'policy_logps/chosen': -330.4993896484375, 'referece_logps/rejected': -341.8016357421875, 'referece_logps/chosen': -315.6561584472656, 'logits/rejected': 0.4509860575199127, 'logits/chosen': 0.44963759183883667, 'epoch': 1.75}


 29%|██▉       | 4710/16104 [21:47:03<52:48:14, 16.68s/it]
{'loss': 0.4733, 'learning_rate': 1.6600134200221505e-06, 'rewards/chosen': -1.009778618812561, 'rewards/rejected': -2.5546560287475586, 'rewards/accuracies': 0.75, 'rewards/margins': 1.544877290725708, 'policy_logps/rejected': -324.4739685058594, 'policy_logps/chosen': -361.6063232421875, 'referece_logps/rejected': -298.9273986816406, 'referece_logps/chosen': -351.508544921875, 'logits/rejected': -0.37378400564193726, 'logits/chosen': -0.35794565081596375, 'epoch': 1.75}

 29%|██▉       | 4711/16104 [21:47:23<55:40:49, 17.59s/it]

 29%|██▉       | 4712/16104 [21:47:43<58:05:07, 18.36s/it]


 29%|██▉       | 4714/16104 [21:48:20<57:58:38, 18.32s/it]

 29%|██▉       | 4715/16104 [21:48:40<59:14:24, 18.73s/it]
{'loss': 0.5186, 'learning_rate': 1.65925760195743e-06, 'rewards/chosen': -1.6534056663513184, 'rewards/rejected': -1.9184428453445435, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2650371789932251, 'policy_logps/rejected': -260.99005126953125, 'policy_logps/chosen': -315.4134216308594, 'referece_logps/rejected': -241.80563354492188, 'referece_logps/chosen': -298.8793640136719, 'logits/rejected': -0.16310463845729828, 'logits/chosen': -0.283290296792984, 'epoch': 1.76}

 29%|██▉       | 4716/16104 [21:48:57<57:39:34, 18.23s/it]


 29%|██▉       | 4718/16104 [21:49:29<52:52:53, 16.72s/it]

 29%|██▉       | 4719/16104 [21:49:40<47:42:11, 15.08s/it]

 29%|██▉       | 4720/16104 [21:49:57<49:23:10, 15.62s/it]

 29%|██▉       | 4721/16104 [21:50:14<51:03:11, 16.15s/it]

 29%|██▉       | 4722/16104 [21:50:26<47:14:07, 14.94s/it]

 29%|██▉       | 4723/16104 [21:50:40<46:19:03, 14.65s/it]
{'loss': 0.4509, 'learning_rate': 1.6580469066285981e-06, 'rewards/chosen': -1.1074005365371704, 'rewards/rejected': -2.620305061340332, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5129047632217407, 'policy_logps/rejected': -491.5274963378906, 'policy_logps/chosen': -532.574951171875, 'referece_logps/rejected': -465.32440185546875, 'referece_logps/chosen': -521.5009155273438, 'logits/rejected': 0.21725843846797943, 'logits/chosen': 0.1602029949426651, 'epoch': 1.76}


 29%|██▉       | 4725/16104 [21:51:10<45:55:11, 14.53s/it]
{'loss': 0.4909, 'learning_rate': 1.6577439664821964e-06, 'rewards/chosen': -1.4602930545806885, 'rewards/rejected': -1.4979475736618042, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03765449672937393, 'policy_logps/rejected': -456.22271728515625, 'policy_logps/chosen': -359.3734130859375, 'referece_logps/rejected': -441.2432556152344, 'referece_logps/chosen': -344.7705078125, 'logits/rejected': -0.3198677897453308, 'logits/chosen': -0.19340750575065613, 'epoch': 1.76}


 29%|██▉       | 4727/16104 [21:51:32<40:35:10, 12.84s/it]
{'loss': 0.4957, 'learning_rate': 1.6574409199081268e-06, 'rewards/chosen': -1.2631667852401733, 'rewards/rejected': -2.2455196380615234, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9823529720306396, 'policy_logps/rejected': -337.90447998046875, 'policy_logps/chosen': -409.8436584472656, 'referece_logps/rejected': -315.44927978515625, 'referece_logps/chosen': -397.2120056152344, 'logits/rejected': 0.014245180413126945, 'logits/chosen': 0.04555341601371765, 'epoch': 1.76}


 29%|██▉       | 4729/16104 [21:51:57<39:49:07, 12.60s/it]

 29%|██▉       | 4730/16104 [21:52:16<46:25:19, 14.69s/it]
{'loss': 0.4427, 'learning_rate': 1.6569861506024148e-06, 'rewards/chosen': -1.0431654453277588, 'rewards/rejected': -2.175204038619995, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1320385932922363, 'policy_logps/rejected': -369.0186767578125, 'policy_logps/chosen': -325.4544372558594, 'referece_logps/rejected': -347.2666320800781, 'referece_logps/chosen': -315.0227966308594, 'logits/rejected': -0.4714790880680084, 'logits/chosen': -0.2868562936782837, 'epoch': 1.76}


 29%|██▉       | 4732/16104 [21:52:40<41:40:27, 13.19s/it]

 29%|██▉       | 4733/16104 [21:52:55<43:13:25, 13.68s/it]

 29%|██▉       | 4734/16104 [21:53:06<40:53:25, 12.95s/it]

 29%|██▉       | 4735/16104 [21:53:18<40:12:34, 12.73s/it]

 29%|██▉       | 4736/16104 [21:53:30<39:20:03, 12.46s/it]

 29%|██▉       | 4737/16104 [21:53:51<47:15:07, 14.97s/it]

 29%|██▉       | 4738/16104 [21:54:10<51:20:17, 16.26s/it]
{'loss': 0.4314, 'learning_rate': 1.6557722635483062e-06, 'rewards/chosen': -1.7684780359268188, 'rewards/rejected': -2.750657796859741, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9821797609329224, 'policy_logps/rejected': -414.85101318359375, 'policy_logps/chosen': -298.7870178222656, 'referece_logps/rejected': -387.344482421875, 'referece_logps/chosen': -281.10223388671875, 'logits/rejected': -0.2611396014690399, 'logits/chosen': -0.4018014371395111, 'epoch': 1.77}


 29%|██▉       | 4740/16104 [21:54:41<49:02:21, 15.54s/it]

 29%|██▉       | 4741/16104 [21:54:58<50:23:20, 15.96s/it]
{'loss': 0.4279, 'learning_rate': 1.655316618036062e-06, 'rewards/chosen': -1.025974154472351, 'rewards/rejected': -1.6765285730361938, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6505544185638428, 'policy_logps/rejected': -420.7877197265625, 'policy_logps/chosen': -418.83203125, 'referece_logps/rejected': -404.02239990234375, 'referece_logps/chosen': -408.5722961425781, 'logits/rejected': -0.2886798679828644, 'logits/chosen': -0.33539465069770813, 'epoch': 1.77}


 29%|██▉       | 4743/16104 [21:55:24<46:04:57, 14.60s/it]

 29%|██▉       | 4744/16104 [21:55:41<47:49:00, 15.15s/it]
{'loss': 0.5196, 'learning_rate': 1.6548607339452852e-06, 'rewards/chosen': -0.9783072471618652, 'rewards/rejected': -2.2688910961151123, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2905839681625366, 'policy_logps/rejected': -466.997802734375, 'policy_logps/chosen': -432.191162109375, 'referece_logps/rejected': -444.3088684082031, 'referece_logps/chosen': -422.4080505371094, 'logits/rejected': 0.40829604864120483, 'logits/chosen': 0.4009329676628113, 'epoch': 1.77}


 29%|██▉       | 4746/16104 [21:56:09<46:52:32, 14.86s/it]

 29%|██▉       | 4747/16104 [21:56:21<44:33:29, 14.12s/it]

 29%|██▉       | 4748/16104 [21:56:37<46:31:43, 14.75s/it]

 29%|██▉       | 4749/16104 [21:56:48<43:07:29, 13.67s/it]

 29%|██▉       | 4750/16104 [21:56:59<40:16:09, 12.77s/it]
{'loss': 0.56, 'learning_rate': 1.653948250692106e-06, 'rewards/chosen': -1.1989964246749878, 'rewards/rejected': -1.286510705947876, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08751437067985535, 'policy_logps/rejected': -284.9271240234375, 'policy_logps/chosen': -354.17578125, 'referece_logps/rejected': -272.0619812011719, 'referece_logps/chosen': -342.18585205078125, 'logits/rejected': -0.20856264233589172, 'logits/chosen': -0.15486657619476318, 'epoch': 1.77}


 30%|██▉       | 4752/16104 [21:57:21<37:16:49, 11.82s/it]
{'loss': 0.6627, 'learning_rate': 1.6536438779150878e-06, 'rewards/chosen': -0.7637178897857666, 'rewards/rejected': -1.7351717948913574, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9714539051055908, 'policy_logps/rejected': -318.6647033691406, 'policy_logps/chosen': -328.63427734375, 'referece_logps/rejected': -301.3129577636719, 'referece_logps/chosen': -320.9971008300781, 'logits/rejected': 0.2120494842529297, 'logits/chosen': 0.18733344972133636, 'epoch': 1.77}


 30%|██▉       | 4754/16104 [21:57:51<42:07:31, 13.36s/it]
{'loss': 0.3883, 'learning_rate': 1.653339399373826e-06, 'rewards/chosen': -1.4223695993423462, 'rewards/rejected': -3.285790205001831, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8634207248687744, 'policy_logps/rejected': -362.3000183105469, 'policy_logps/chosen': -421.3853759765625, 'referece_logps/rejected': -329.442138671875, 'referece_logps/chosen': -407.1616516113281, 'logits/rejected': -0.6876469254493713, 'logits/chosen': -0.7378137111663818, 'epoch': 1.77}


 30%|██▉       | 4756/16104 [21:58:31<52:14:40, 16.57s/it]
{'loss': 0.491, 'learning_rate': 1.653034815117586e-06, 'rewards/chosen': -1.1275662183761597, 'rewards/rejected': -2.2312381267547607, 'rewards/accuracies': 0.875, 'rewards/margins': 1.103671669960022, 'policy_logps/rejected': -435.9682312011719, 'policy_logps/chosen': -396.1051330566406, 'referece_logps/rejected': -413.6558532714844, 'referece_logps/chosen': -384.8294677734375, 'logits/rejected': -0.8938765525817871, 'logits/chosen': -0.9337894916534424, 'epoch': 1.77}


 30%|██▉       | 4758/16104 [21:59:07<54:44:40, 17.37s/it]

 30%|██▉       | 4759/16104 [21:59:23<52:40:44, 16.72s/it]

 30%|██▉       | 4760/16104 [21:59:37<50:33:04, 16.04s/it]

 30%|██▉       | 4761/16104 [21:59:57<54:32:10, 17.31s/it]
{'loss': 0.5005, 'learning_rate': 1.6522728922974297e-06, 'rewards/chosen': -1.034885048866272, 'rewards/rejected': -1.6652475595474243, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6303625106811523, 'policy_logps/rejected': -359.9241027832031, 'policy_logps/chosen': -400.4463806152344, 'referece_logps/rejected': -343.2716369628906, 'referece_logps/chosen': -390.09759521484375, 'logits/rejected': -0.33295369148254395, 'logits/chosen': -0.1595836579799652, 'epoch': 1.77}

 30%|██▉       | 4762/16104 [22:00:14<54:03:21, 17.16s/it]


 30%|██▉       | 4764/16104 [22:00:53<58:05:39, 18.44s/it]
{'loss': 0.4226, 'learning_rate': 1.65181542192879e-06, 'rewards/chosen': -1.467908501625061, 'rewards/rejected': -2.6200380325317383, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1521294116973877, 'policy_logps/rejected': -343.30133056640625, 'policy_logps/chosen': -385.7967529296875, 'referece_logps/rejected': -317.1009521484375, 'referece_logps/chosen': -371.1176452636719, 'logits/rejected': -0.4860689043998718, 'logits/chosen': -0.521250307559967, 'epoch': 1.77}


 30%|██▉       | 4766/16104 [22:01:25<53:26:41, 16.97s/it]

 30%|██▉       | 4767/16104 [22:01:39<50:54:19, 16.16s/it]

 30%|██▉       | 4768/16104 [22:01:51<46:35:32, 14.80s/it]
{'loss': 0.5427, 'learning_rate': 1.6512050923267218e-06, 'rewards/chosen': -1.5385152101516724, 'rewards/rejected': -1.7710504531860352, 'rewards/accuracies': 0.75, 'rewards/margins': 0.23253515362739563, 'policy_logps/rejected': -461.237060546875, 'policy_logps/chosen': -470.8843078613281, 'referece_logps/rejected': -443.52655029296875, 'referece_logps/chosen': -455.4991149902344, 'logits/rejected': -0.7836315631866455, 'logits/chosen': -0.8249925971031189, 'epoch': 1.78}


 30%|██▉       | 4770/16104 [22:02:19<44:19:04, 14.08s/it]

 30%|██▉       | 4771/16104 [22:02:35<46:50:56, 14.88s/it]

 30%|██▉       | 4772/16104 [22:02:47<43:21:47, 13.78s/it]
{'loss': 0.499, 'learning_rate': 1.650594341246146e-06, 'rewards/chosen': -1.058660626411438, 'rewards/rejected': -1.7696086168289185, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7109478712081909, 'policy_logps/rejected': -341.37310791015625, 'policy_logps/chosen': -459.46881103515625, 'referece_logps/rejected': -323.6770324707031, 'referece_logps/chosen': -448.8822021484375, 'logits/rejected': -0.2981278896331787, 'logits/chosen': -0.395187109708786, 'epoch': 1.78}


 30%|██▉       | 4774/16104 [22:03:25<53:00:55, 16.85s/it]

 30%|██▉       | 4775/16104 [22:03:45<55:42:42, 17.70s/it]
{'loss': 0.4483, 'learning_rate': 1.6501360015782282e-06, 'rewards/chosen': -1.476383924484253, 'rewards/rejected': -2.821380138397217, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3449963331222534, 'policy_logps/rejected': -450.071044921875, 'policy_logps/chosen': -576.9421997070312, 'referece_logps/rejected': -421.8572692871094, 'referece_logps/chosen': -562.178466796875, 'logits/rejected': -0.7460110187530518, 'logits/chosen': -0.8103349208831787, 'epoch': 1.78}


 30%|██▉       | 4777/16104 [22:04:22<57:19:30, 18.22s/it]

 30%|██▉       | 4778/16104 [22:04:38<55:11:23, 17.54s/it]

 30%|██▉       | 4779/16104 [22:04:59<58:41:52, 18.66s/it]
{'loss': 0.4888, 'learning_rate': 1.6495245138616078e-06, 'rewards/chosen': -1.0835137367248535, 'rewards/rejected': -2.18491268157959, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1013989448547363, 'policy_logps/rejected': -298.8113098144531, 'policy_logps/chosen': -374.10968017578125, 'referece_logps/rejected': -276.962158203125, 'referece_logps/chosen': -363.2745361328125, 'logits/rejected': -0.40053269267082214, 'logits/chosen': -0.5958306789398193, 'epoch': 1.78}

 30%|██▉       | 4780/16104 [22:05:10<52:02:05, 16.54s/it]

 30%|██▉       | 4781/16104 [22:05:26<51:05:19, 16.24s/it]


 30%|██▉       | 4783/16104 [22:06:08<58:45:14, 18.68s/it]
{'loss': 0.4271, 'learning_rate': 1.6489126057541984e-06, 'rewards/chosen': -1.0844374895095825, 'rewards/rejected': -1.8953635692596436, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8109259009361267, 'policy_logps/rejected': -318.107177734375, 'policy_logps/chosen': -341.0321044921875, 'referece_logps/rejected': -299.1535339355469, 'referece_logps/chosen': -330.187744140625, 'logits/rejected': -0.06509504467248917, 'logits/chosen': -0.06537320464849472, 'epoch': 1.78}


 30%|██▉       | 4785/16104 [22:06:44<58:02:58, 18.46s/it]

 30%|██▉       | 4786/16104 [22:07:05<60:37:38, 19.28s/it]

 30%|██▉       | 4787/16104 [22:07:17<54:01:30, 17.19s/it]
{'loss': 0.4847, 'learning_rate': 1.648300277652044e-06, 'rewards/chosen': -1.5840439796447754, 'rewards/rejected': -1.794352650642395, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21030884981155396, 'policy_logps/rejected': -301.65325927734375, 'policy_logps/chosen': -396.9281005859375, 'referece_logps/rejected': -283.7097473144531, 'referece_logps/chosen': -381.0876770019531, 'logits/rejected': -0.9126492142677307, 'logits/chosen': -0.9934564232826233, 'epoch': 1.78}


 30%|██▉       | 4789/16104 [22:07:53<54:42:44, 17.41s/it]

 30%|██▉       | 4790/16104 [22:08:14<57:23:19, 18.26s/it]
{'loss': 0.5263, 'learning_rate': 1.6478407561922758e-06, 'rewards/chosen': -1.2352042198181152, 'rewards/rejected': -3.3653275966644287, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1301233768463135, 'policy_logps/rejected': -433.594970703125, 'policy_logps/chosen': -401.123779296875, 'referece_logps/rejected': -399.9416809082031, 'referece_logps/chosen': -388.77166748046875, 'logits/rejected': 0.06525912880897522, 'logits/chosen': 0.16746534407138824, 'epoch': 1.78}


 30%|██▉       | 4792/16104 [22:08:52<58:04:03, 18.48s/it]
{'loss': 0.4196, 'learning_rate': 1.6475342775105299e-06, 'rewards/chosen': -0.8732835650444031, 'rewards/rejected': -1.7424391508102417, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8691555261611938, 'policy_logps/rejected': -367.83843994140625, 'policy_logps/chosen': -385.8519287109375, 'referece_logps/rejected': -350.4140625, 'referece_logps/chosen': -377.1191101074219, 'logits/rejected': -0.254733145236969, 'logits/chosen': -0.307029664516449, 'epoch': 1.79}

 30%|██▉       | 4793/16104 [22:09:13<60:05:03, 19.12s/it]


 30%|██▉       | 4795/16104 [22:09:35<47:36:59, 15.16s/it]
{'loss': 0.4552, 'learning_rate': 1.6470743630490374e-06, 'rewards/chosen': -1.035557746887207, 'rewards/rejected': -1.6632534265518188, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6276956796646118, 'policy_logps/rejected': -283.8514099121094, 'policy_logps/chosen': -290.4097900390625, 'referece_logps/rejected': -267.2188415527344, 'referece_logps/chosen': -280.0542297363281, 'logits/rejected': -0.7045078277587891, 'logits/chosen': -0.5521597266197205, 'epoch': 1.79}

 30%|██▉       | 4796/16104 [22:09:48<45:38:16, 14.53s/it]

 30%|██▉       | 4797/16104 [22:10:03<45:41:12, 14.55s/it]


 30%|██▉       | 4799/16104 [22:10:38<50:42:47, 16.15s/it]

 30%|██▉       | 4800/16104 [22:10:56<52:41:36, 16.78s/it]
{'loss': 0.4127, 'learning_rate': 1.6463073155230346e-06, 'rewards/chosen': -1.625113606452942, 'rewards/rejected': -1.9759305715560913, 'rewards/accuracies': 0.625, 'rewards/margins': 0.35081708431243896, 'policy_logps/rejected': -297.97088623046875, 'policy_logps/chosen': -303.38787841796875, 'referece_logps/rejected': -278.2115783691406, 'referece_logps/chosen': -287.1367492675781, 'logits/rejected': -0.479983925819397, 'logits/chosen': -0.3680863082408905, 'epoch': 1.79}

 30%|██▉       | 4801/16104 [22:11:09<49:10:23, 15.66s/it]

 30%|██▉       | 4802/16104 [22:11:21<45:29:23, 14.49s/it]


 30%|██▉       | 4804/16104 [22:11:52<47:32:57, 15.15s/it]
{'loss': 0.3773, 'learning_rate': 1.6456932068678974e-06, 'rewards/chosen': -1.8237377405166626, 'rewards/rejected': -2.440187454223633, 'rewards/accuracies': 0.625, 'rewards/margins': 0.616449773311615, 'policy_logps/rejected': -381.0451965332031, 'policy_logps/chosen': -365.00604248046875, 'referece_logps/rejected': -356.643310546875, 'referece_logps/chosen': -346.7686767578125, 'logits/rejected': -0.6991634368896484, 'logits/chosen': -0.6418834924697876, 'epoch': 1.79}

 30%|██▉       | 4805/16104 [22:12:07<47:59:25, 15.29s/it]

 30%|██▉       | 4806/16104 [22:12:22<47:41:29, 15.20s/it]

 30%|██▉       | 4807/16104 [22:12:35<45:09:24, 14.39s/it]

 30%|██▉       | 4808/16104 [22:12:57<51:59:23, 16.57s/it]


 30%|██▉       | 4810/16104 [22:13:20<44:00:11, 14.03s/it]
{'loss': 0.5113, 'learning_rate': 1.6447712604262416e-06, 'rewards/chosen': -1.1085141897201538, 'rewards/rejected': -2.0757558345794678, 'rewards/accuracies': 0.75, 'rewards/margins': 0.967241644859314, 'policy_logps/rejected': -299.2330017089844, 'policy_logps/chosen': -267.5848693847656, 'referece_logps/rejected': -278.4754638671875, 'referece_logps/chosen': -256.499755859375, 'logits/rejected': -0.8461483716964722, 'logits/chosen': -0.8239931464195251, 'epoch': 1.79}

 30%|██▉       | 4811/16104 [22:13:31<40:46:13, 13.00s/it]

 30%|██▉       | 4812/16104 [22:13:51<47:56:23, 15.28s/it]

 30%|██▉       | 4813/16104 [22:14:10<50:54:04, 16.23s/it]

 30%|██▉       | 4814/16104 [22:14:28<52:34:44, 16.77s/it]

 30%|██▉       | 4815/16104 [22:14:44<51:49:15, 16.53s/it]


 30%|██▉       | 4817/16104 [22:15:20<54:46:59, 17.47s/it]

 30%|██▉       | 4818/16104 [22:15:42<59:11:45, 18.88s/it]
{'loss': 0.5193, 'learning_rate': 1.6435405381361643e-06, 'rewards/chosen': -1.5978056192398071, 'rewards/rejected': -2.0666162967681885, 'rewards/accuracies': 0.75, 'rewards/margins': 0.46881070733070374, 'policy_logps/rejected': -348.455078125, 'policy_logps/chosen': -350.79693603515625, 'referece_logps/rejected': -327.7889099121094, 'referece_logps/chosen': -334.81890869140625, 'logits/rejected': -0.7532488107681274, 'logits/chosen': -0.8904992341995239, 'epoch': 1.8}

 30%|██▉       | 4819/16104 [22:15:55<53:33:42, 17.09s/it]

 30%|██▉       | 4820/16104 [22:16:16<56:56:05, 18.16s/it]


 30%|██▉       | 4822/16104 [22:16:38<45:41:59, 14.58s/it]
{'loss': 0.55, 'learning_rate': 1.6429245520152346e-06, 'rewards/chosen': -1.3078213930130005, 'rewards/rejected': -1.584706425666809, 'rewards/accuracies': 0.5, 'rewards/margins': 0.27688491344451904, 'policy_logps/rejected': -388.8800048828125, 'policy_logps/chosen': -422.155029296875, 'referece_logps/rejected': -373.0329284667969, 'referece_logps/chosen': -409.0768127441406, 'logits/rejected': -0.8393685221672058, 'logits/chosen': -0.7787235975265503, 'epoch': 1.8}


 30%|██▉       | 4824/16104 [22:17:00<40:04:46, 12.79s/it]
{'loss': 0.5502, 'learning_rate': 1.6426164028851765e-06, 'rewards/chosen': -0.8039717674255371, 'rewards/rejected': -1.9339760541915894, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1300042867660522, 'policy_logps/rejected': -473.1787109375, 'policy_logps/chosen': -401.4489440917969, 'referece_logps/rejected': -453.83892822265625, 'referece_logps/chosen': -393.4092712402344, 'logits/rejected': 0.51065993309021, 'logits/chosen': 0.9640496373176575, 'epoch': 1.8}

 30%|██▉       | 4825/16104 [22:17:22<48:04:49, 15.35s/it]

 30%|██▉       | 4826/16104 [22:17:37<48:02:46, 15.34s/it]


 30%|██▉       | 4828/16104 [22:18:02<43:31:57, 13.90s/it]

 30%|██▉       | 4829/16104 [22:18:21<47:55:58, 15.30s/it]
{'loss': 0.4248, 'learning_rate': 1.6418455752569942e-06, 'rewards/chosen': -1.0238319635391235, 'rewards/rejected': -2.985123872756958, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9612916707992554, 'policy_logps/rejected': -351.2109680175781, 'policy_logps/chosen': -300.1583557128906, 'referece_logps/rejected': -321.3597412109375, 'referece_logps/chosen': -289.9200439453125, 'logits/rejected': -0.057575538754463196, 'logits/chosen': -0.024801895022392273, 'epoch': 1.8}

 30%|██▉       | 4830/16104 [22:18:39<51:02:17, 16.30s/it]


 30%|███       | 4832/16104 [22:19:16<54:09:21, 17.30s/it]

 30%|███       | 4833/16104 [22:19:35<54:59:01, 17.56s/it]

 30%|███       | 4834/16104 [22:19:54<56:57:11, 18.19s/it]

 30%|███       | 4835/16104 [22:20:15<59:03:58, 18.87s/it]
{'loss': 0.4306, 'learning_rate': 1.6409197253665265e-06, 'rewards/chosen': -0.8043006658554077, 'rewards/rejected': -2.19126558303833, 'rewards/accuracies': 1.0, 'rewards/margins': 1.386965036392212, 'policy_logps/rejected': -300.1767578125, 'policy_logps/chosen': -283.61004638671875, 'referece_logps/rejected': -278.26409912109375, 'referece_logps/chosen': -275.5670471191406, 'logits/rejected': -0.06694036722183228, 'logits/chosen': -0.009425487369298935, 'epoch': 1.8}

 30%|███       | 4836/16104 [22:20:34<59:17:10, 18.94s/it]

 30%|███       | 4837/16104 [22:20:47<54:01:26, 17.26s/it]

 30%|███       | 4838/16104 [22:21:07<56:24:39, 18.03s/it]

 30%|███       | 4839/16104 [22:21:27<58:10:33, 18.59s/it]


 30%|███       | 4841/16104 [22:22:05<57:40:26, 18.43s/it]
{'loss': 0.4547, 'learning_rate': 1.6399929421276913e-06, 'rewards/chosen': -2.153691291809082, 'rewards/rejected': -2.508354425430298, 'rewards/accuracies': 0.5, 'rewards/margins': 0.35466307401657104, 'policy_logps/rejected': -283.5796813964844, 'policy_logps/chosen': -335.52490234375, 'referece_logps/rejected': -258.49615478515625, 'referece_logps/chosen': -313.98797607421875, 'logits/rejected': -0.5392305254936218, 'logits/chosen': -0.5013296604156494, 'epoch': 1.8}


 30%|███       | 4843/16104 [22:22:38<55:57:19, 17.89s/it]
{'loss': 0.4589, 'learning_rate': 1.6396838072038963e-06, 'rewards/chosen': -1.7669247388839722, 'rewards/rejected': -2.3137807846069336, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5468558669090271, 'policy_logps/rejected': -511.29193115234375, 'policy_logps/chosen': -358.3100891113281, 'referece_logps/rejected': -488.15411376953125, 'referece_logps/chosen': -340.640869140625, 'logits/rejected': -0.8671529293060303, 'logits/chosen': -0.680219292640686, 'epoch': 1.8}

 30%|███       | 4844/16104 [22:22:51<50:52:34, 16.27s/it]

 30%|███       | 4845/16104 [22:23:03<46:57:52, 15.02s/it]

 30%|███       | 4846/16104 [22:23:24<52:43:41, 16.86s/it]


 30%|███       | 4848/16104 [22:23:57<50:48:54, 16.25s/it]

 30%|███       | 4849/16104 [22:24:15<52:19:24, 16.74s/it]
{'loss': 0.3164, 'learning_rate': 1.6387557816002472e-06, 'rewards/chosen': -1.845988154411316, 'rewards/rejected': -3.5385847091674805, 'rewards/accuracies': 0.75, 'rewards/margins': 1.692596435546875, 'policy_logps/rejected': -333.5396728515625, 'policy_logps/chosen': -450.8546447753906, 'referece_logps/rejected': -298.15380859375, 'referece_logps/chosen': -432.394775390625, 'logits/rejected': -0.7176824808120728, 'logits/chosen': -0.5478304028511047, 'epoch': 1.81}


 30%|███       | 4851/16104 [22:24:41<46:57:17, 15.02s/it]
{'loss': 0.3241, 'learning_rate': 1.6384462329551214e-06, 'rewards/chosen': -1.3004294633865356, 'rewards/rejected': -3.297687530517578, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9972585439682007, 'policy_logps/rejected': -407.814697265625, 'policy_logps/chosen': -430.0032958984375, 'referece_logps/rejected': -374.83782958984375, 'referece_logps/chosen': -416.9990234375, 'logits/rejected': -0.22772519290447235, 'logits/chosen': -0.10509170591831207, 'epoch': 1.81}

 30%|███       | 4852/16104 [22:25:01<52:05:24, 16.67s/it]


 30%|███       | 4854/16104 [22:25:43<58:21:28, 18.67s/it]
{'loss': 0.4901, 'learning_rate': 1.6379817163059208e-06, 'rewards/chosen': -1.936759352684021, 'rewards/rejected': -3.11240553855896, 'rewards/accuracies': 0.5, 'rewards/margins': 1.175646185874939, 'policy_logps/rejected': -268.82568359375, 'policy_logps/chosen': -308.4998779296875, 'referece_logps/rejected': -237.7016143798828, 'referece_logps/chosen': -289.1322937011719, 'logits/rejected': -0.2915363907814026, 'logits/chosen': -0.3783915638923645, 'epoch': 1.81}

 30%|███       | 4855/16104 [22:26:02<58:39:11, 18.77s/it]

 30%|███       | 4856/16104 [22:26:17<55:58:28, 17.92s/it]

 30%|███       | 4857/16104 [22:26:32<52:34:55, 16.83s/it]

 30%|███       | 4858/16104 [22:26:54<58:00:26, 18.57s/it]

 30%|███       | 4859/16104 [22:27:08<53:09:09, 17.02s/it]

 30%|███       | 4860/16104 [22:27:27<55:34:57, 17.80s/it]

 30%|███       | 4861/16104 [22:27:47<56:51:48, 18.21s/it]

 30%|███       | 4862/16104 [22:28:06<58:23:10, 18.70s/it]

 30%|███       | 4863/16104 [22:28:28<60:48:28, 19.47s/it]

 30%|███       | 4864/16104 [22:28:42<55:47:10, 17.87s/it]

 30%|███       | 4865/16104 [22:28:58<53:59:35, 17.29s/it]

 30%|███       | 4866/16104 [22:29:15<54:14:59, 17.38s/it]


 30%|███       | 4868/16104 [22:29:55<57:58:26, 18.57s/it]
{'loss': 0.4185, 'learning_rate': 1.6358109035859536e-06, 'rewards/chosen': -1.3285305500030518, 'rewards/rejected': -3.1087749004364014, 'rewards/accuracies': 0.75, 'rewards/margins': 1.78024423122406, 'policy_logps/rejected': -373.1280212402344, 'policy_logps/chosen': -491.3885192871094, 'referece_logps/rejected': -342.040283203125, 'referece_logps/chosen': -478.10321044921875, 'logits/rejected': -0.21072345972061157, 'logits/chosen': -0.2958631217479706, 'epoch': 1.81}


 30%|███       | 4870/16104 [22:30:23<51:42:45, 16.57s/it]

 30%|███       | 4871/16104 [22:30:43<54:32:26, 17.48s/it]
{'loss': 0.389, 'learning_rate': 1.6353450729929001e-06, 'rewards/chosen': -1.0245862007141113, 'rewards/rejected': -3.1850197315216064, 'rewards/accuracies': 1.0, 'rewards/margins': 2.160433292388916, 'policy_logps/rejected': -326.3902893066406, 'policy_logps/chosen': -403.3262634277344, 'referece_logps/rejected': -294.54010009765625, 'referece_logps/chosen': -393.0804138183594, 'logits/rejected': 0.32934412360191345, 'logits/chosen': 0.4090711176395416, 'epoch': 1.81}


 30%|███       | 4873/16104 [22:31:15<53:24:54, 17.12s/it]

 30%|███       | 4874/16104 [22:31:33<54:40:19, 17.53s/it]

 30%|███       | 4875/16104 [22:31:53<56:39:15, 18.16s/it]
{'loss': 0.3448, 'learning_rate': 1.634723605753043e-06, 'rewards/chosen': -0.9102350473403931, 'rewards/rejected': -2.823378086090088, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9131430387496948, 'policy_logps/rejected': -235.11932373046875, 'policy_logps/chosen': -320.8897399902344, 'referece_logps/rejected': -206.88555908203125, 'referece_logps/chosen': -311.78741455078125, 'logits/rejected': 0.11496339738368988, 'logits/chosen': 0.05091431736946106, 'epoch': 1.82}

 30%|███       | 4876/16104 [22:32:13<58:05:04, 18.62s/it]

 30%|███       | 4877/16104 [22:32:26<52:58:30, 16.99s/it]

 30%|███       | 4878/16104 [22:32:37<47:18:08, 15.17s/it]

 30%|███       | 4879/16104 [22:32:52<47:13:34, 15.15s/it]


 30%|███       | 4881/16104 [22:33:21<47:04:52, 15.10s/it]
{'loss': 0.4309, 'learning_rate': 1.6337906347479899e-06, 'rewards/chosen': -1.0178495645523071, 'rewards/rejected': -2.837555408477783, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8197059631347656, 'policy_logps/rejected': -445.60516357421875, 'policy_logps/chosen': -495.2013244628906, 'referece_logps/rejected': -417.2296447753906, 'referece_logps/chosen': -485.02276611328125, 'logits/rejected': -1.0926613807678223, 'logits/chosen': -1.073903203010559, 'epoch': 1.82}

 30%|███       | 4882/16104 [22:33:41<51:03:09, 16.38s/it]

 30%|███       | 4883/16104 [22:34:00<54:02:12, 17.34s/it]

 30%|███       | 4884/16104 [22:34:23<58:40:45, 18.83s/it]

 30%|███       | 4885/16104 [22:34:35<52:35:45, 16.88s/it]

 30%|███       | 4886/16104 [22:34:48<48:49:08, 15.67s/it]


 30%|███       | 4888/16104 [22:35:25<53:30:40, 17.18s/it]
{'loss': 0.4963, 'learning_rate': 1.6327010021437613e-06, 'rewards/chosen': -1.594848871231079, 'rewards/rejected': -2.459990978240967, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8651421070098877, 'policy_logps/rejected': -375.5529479980469, 'policy_logps/chosen': -360.2192077636719, 'referece_logps/rejected': -350.95306396484375, 'referece_logps/chosen': -344.27069091796875, 'logits/rejected': -0.503263533115387, 'logits/chosen': -0.6495541930198669, 'epoch': 1.82}

 30%|███       | 4889/16104 [22:35:45<55:55:05, 17.95s/it]

 30%|███       | 4890/16104 [22:36:04<57:23:51, 18.43s/it]

 30%|███       | 4891/16104 [22:36:24<58:35:35, 18.81s/it]

 30%|███       | 4892/16104 [22:36:43<58:20:59, 18.74s/it]

 30%|███       | 4893/16104 [22:36:58<55:04:08, 17.68s/it]

 30%|███       | 4894/16104 [22:37:10<49:54:43, 16.03s/it]


 30%|███       | 4896/16104 [22:37:42<49:19:02, 15.84s/it]
{'loss': 0.4019, 'learning_rate': 1.6314541722321518e-06, 'rewards/chosen': -1.0404810905456543, 'rewards/rejected': -1.6609166860580444, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6204357147216797, 'policy_logps/rejected': -522.025634765625, 'policy_logps/chosen': -416.9613342285156, 'referece_logps/rejected': -505.4164123535156, 'referece_logps/chosen': -406.5565185546875, 'logits/rejected': -0.1835792362689972, 'logits/chosen': -0.09067116677761078, 'epoch': 1.82}


 30%|███       | 4898/16104 [22:38:04<41:43:18, 13.40s/it]
{'loss': 0.5149, 'learning_rate': 1.6311422091936383e-06, 'rewards/chosen': -1.2562623023986816, 'rewards/rejected': -1.7379895448684692, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4817272424697876, 'policy_logps/rejected': -420.655517578125, 'policy_logps/chosen': -412.9249572753906, 'referece_logps/rejected': -403.2756042480469, 'referece_logps/chosen': -400.36236572265625, 'logits/rejected': 0.6014096736907959, 'logits/chosen': 0.6300572752952576, 'epoch': 1.82}


 30%|███       | 4900/16104 [22:38:26<37:43:33, 12.12s/it]
{'loss': 0.4794, 'learning_rate': 1.6308301440318118e-06, 'rewards/chosen': -0.5605312585830688, 'rewards/rejected': -2.210989236831665, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6504580974578857, 'policy_logps/rejected': -330.49761962890625, 'policy_logps/chosen': -336.1581726074219, 'referece_logps/rejected': -308.3876953125, 'referece_logps/chosen': -330.5528564453125, 'logits/rejected': 0.7101014256477356, 'logits/chosen': 0.9710949659347534, 'epoch': 1.83}

 30%|███       | 4901/16104 [22:38:39<38:26:32, 12.35s/it]


 30%|███       | 4903/16104 [22:39:19<51:15:01, 16.47s/it]
{'loss': 0.4172, 'learning_rate': 1.6303618549183199e-06, 'rewards/chosen': -1.470365047454834, 'rewards/rejected': -3.2363526821136475, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7659876346588135, 'policy_logps/rejected': -436.98590087890625, 'policy_logps/chosen': -410.6208801269531, 'referece_logps/rejected': -404.6224060058594, 'referece_logps/chosen': -395.9172058105469, 'logits/rejected': 0.2909869849681854, 'logits/chosen': 0.376079797744751, 'epoch': 1.83}


 30%|███       | 4905/16104 [22:39:54<51:29:21, 16.55s/it]

 30%|███       | 4906/16104 [22:40:15<56:04:24, 18.03s/it]
{'loss': 0.4149, 'learning_rate': 1.6298933363114767e-06, 'rewards/chosen': -1.0622388124465942, 'rewards/rejected': -2.171940803527832, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1097018718719482, 'policy_logps/rejected': -416.10400390625, 'policy_logps/chosen': -360.0452880859375, 'referece_logps/rejected': -394.3846130371094, 'referece_logps/chosen': -349.42291259765625, 'logits/rejected': -1.6355715990066528, 'logits/chosen': -1.649997591972351, 'epoch': 1.83}

 30%|███       | 4907/16104 [22:40:37<59:03:04, 18.99s/it]

 30%|███       | 4908/16104 [22:40:52<56:06:39, 18.04s/it]

 30%|███       | 4909/16104 [22:41:14<59:41:16, 19.19s/it]

 30%|███       | 4910/16104 [22:41:33<58:54:58, 18.95s/it]

 30%|███       | 4911/16104 [22:41:54<61:07:00, 19.66s/it]

 31%|███       | 4912/16104 [22:42:09<57:11:07, 18.39s/it]

 31%|███       | 4913/16104 [22:42:25<54:20:38, 17.48s/it]

 31%|███       | 4914/16104 [22:42:37<49:44:05, 16.00s/it]

 31%|███       | 4915/16104 [22:42:49<45:17:18, 14.57s/it]


 31%|███       | 4917/16104 [22:43:18<45:43:49, 14.72s/it]
{'loss': 0.5722, 'learning_rate': 1.628173474067361e-06, 'rewards/chosen': -0.9077638387680054, 'rewards/rejected': -1.6679189205169678, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7601551413536072, 'policy_logps/rejected': -291.03741455078125, 'policy_logps/chosen': -408.91314697265625, 'referece_logps/rejected': -274.35821533203125, 'referece_logps/chosen': -399.8354797363281, 'logits/rejected': -0.1621646285057068, 'logits/chosen': -0.06045618653297424, 'epoch': 1.83}

 31%|███       | 4918/16104 [22:43:33<46:08:20, 14.85s/it]

 31%|███       | 4919/16104 [22:43:45<43:03:23, 13.86s/it]

 31%|███       | 4920/16104 [22:43:56<40:50:50, 13.15s/it]

 31%|███       | 4921/16104 [22:44:16<46:48:42, 15.07s/it]

 31%|███       | 4922/16104 [22:44:30<46:04:40, 14.83s/it]

 31%|███       | 4923/16104 [22:44:41<42:23:44, 13.65s/it]

 31%|███       | 4924/16104 [22:44:59<46:11:34, 14.87s/it]


 31%|███       | 4926/16104 [22:45:34<50:18:55, 16.20s/it]
{'loss': 0.4168, 'learning_rate': 1.6267640267039947e-06, 'rewards/chosen': -1.0423249006271362, 'rewards/rejected': -2.5802602767944336, 'rewards/accuracies': 0.75, 'rewards/margins': 1.537935495376587, 'policy_logps/rejected': -365.71661376953125, 'policy_logps/chosen': -245.96517944335938, 'referece_logps/rejected': -339.9139709472656, 'referece_logps/chosen': -235.54193115234375, 'logits/rejected': -1.4896641969680786, 'logits/chosen': -1.4938509464263916, 'epoch': 1.84}

 31%|███       | 4927/16104 [22:45:52<52:04:43, 16.77s/it]

 31%|███       | 4928/16104 [22:46:08<50:55:48, 16.41s/it]

 31%|███       | 4929/16104 [22:46:27<52:58:22, 17.07s/it]

 31%|███       | 4930/16104 [22:46:41<50:15:07, 16.19s/it]

 31%|███       | 4931/16104 [22:47:02<54:44:05, 17.64s/it]

 31%|███       | 4932/16104 [22:47:21<56:13:05, 18.12s/it]

 31%|███       | 4933/16104 [22:47:37<54:09:42, 17.45s/it]

 31%|███       | 4934/16104 [22:47:48<47:55:37, 15.45s/it]

 31%|███       | 4935/16104 [22:48:00<45:11:04, 14.56s/it]

 31%|███       | 4936/16104 [22:48:14<44:28:41, 14.34s/it]

 31%|███       | 4937/16104 [22:48:25<41:36:14, 13.41s/it]

 31%|███       | 4938/16104 [22:48:39<41:59:40, 13.54s/it]

 31%|███       | 4939/16104 [22:48:51<40:19:49, 13.00s/it]

 31%|███       | 4940/16104 [22:49:02<38:19:52, 12.36s/it]

 31%|███       | 4941/16104 [22:49:22<45:31:08, 14.68s/it]

 31%|███       | 4942/16104 [22:49:41<50:09:12, 16.18s/it]

 31%|███       | 4943/16104 [22:49:56<48:16:03, 15.57s/it]

 31%|███       | 4944/16104 [22:50:16<52:31:02, 16.94s/it]

 31%|███       | 4945/16104 [22:50:28<47:56:00, 15.46s/it]

 31%|███       | 4946/16104 [22:50:43<47:19:39, 15.27s/it]

 31%|███       | 4947/16104 [22:50:59<48:13:48, 15.56s/it]

 31%|███       | 4948/16104 [22:51:22<54:56:34, 17.73s/it]

 31%|███       | 4949/16104 [22:51:40<55:12:00, 17.81s/it]

 31%|███       | 4950/16104 [22:51:57<54:27:47, 17.58s/it]

 31%|███       | 4951/16104 [22:52:21<60:25:08, 19.50s/it]

 31%|███       | 4952/16104 [22:52:44<63:40:01, 20.55s/it]

 31%|███       | 4953/16104 [22:53:03<62:48:35, 20.28s/it]

 31%|███       | 4954/16104 [22:53:17<56:42:45, 18.31s/it]

 31%|███       | 4955/16104 [22:53:35<56:22:44, 18.20s/it]

 31%|███       | 4956/16104 [22:53:48<51:36:31, 16.67s/it]

 31%|███       | 4957/16104 [22:54:05<52:25:16, 16.93s/it]

 31%|███       | 4958/16104 [22:54:27<57:00:08, 18.41s/it]

 31%|███       | 4959/16104 [22:54:44<55:01:35, 17.77s/it]

 31%|███       | 4960/16104 [22:55:03<56:47:24, 18.35s/it]

 31%|███       | 4961/16104 [22:55:23<58:13:46, 18.81s/it]

 31%|███       | 4962/16104 [22:55:39<55:38:05, 17.98s/it]

 31%|███       | 4963/16104 [22:55:58<56:24:54, 18.23s/it]

 31%|███       | 4964/16104 [22:56:19<59:11:38, 19.13s/it]

 31%|███       | 4965/16104 [22:56:35<55:57:22, 18.08s/it]

 31%|███       | 4966/16104 [22:56:49<52:23:29, 16.93s/it]


 31%|███       | 4968/16104 [22:57:25<54:02:29, 17.47s/it]

 31%|███       | 4969/16104 [22:57:45<56:25:41, 18.24s/it]
{'loss': 0.37, 'learning_rate': 1.620001735423413e-06, 'rewards/chosen': -1.5166929960250854, 'rewards/rejected': -3.6387295722961426, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1220366954803467, 'policy_logps/rejected': -454.5670166015625, 'policy_logps/chosen': -445.3358459472656, 'referece_logps/rejected': -418.1796875, 'referece_logps/chosen': -430.1689453125, 'logits/rejected': -0.4430563449859619, 'logits/chosen': -0.5408660769462585, 'epoch': 1.85}

 31%|███       | 4970/16104 [22:58:07<59:40:10, 19.29s/it]


 31%|███       | 4972/16104 [22:58:43<58:49:06, 19.02s/it]

 31%|███       | 4973/16104 [22:59:03<59:21:46, 19.20s/it]

 31%|███       | 4974/16104 [22:59:23<60:42:24, 19.64s/it]

 31%|███       | 4975/16104 [22:59:40<57:32:36, 18.61s/it]

 31%|███       | 4976/16104 [22:59:51<50:33:29, 16.36s/it]

 31%|███       | 4977/16104 [23:00:08<51:02:43, 16.52s/it]

 31%|███       | 4978/16104 [23:00:20<47:05:04, 15.23s/it]

 31%|███       | 4979/16104 [23:00:33<45:08:05, 14.61s/it]

 31%|███       | 4980/16104 [23:00:45<42:43:53, 13.83s/it]

 31%|███       | 4981/16104 [23:01:05<48:28:34, 15.69s/it]

 31%|███       | 4982/16104 [23:01:25<52:39:26, 17.04s/it]

 31%|███       | 4983/16104 [23:01:45<55:27:11, 17.95s/it]

 31%|███       | 4984/16104 [23:02:02<54:01:41, 17.49s/it]

 31%|███       | 4985/16104 [23:02:18<53:12:46, 17.23s/it]

 31%|███       | 4986/16104 [23:02:33<50:49:18, 16.46s/it]

 31%|███       | 4987/16104 [23:02:54<55:01:20, 17.82s/it]

 31%|███       | 4988/16104 [23:03:09<52:53:05, 17.13s/it]

 31%|███       | 4989/16104 [23:03:26<51:58:06, 16.83s/it]

 31%|███       | 4990/16104 [23:03:37<46:28:43, 15.06s/it]

 31%|███       | 4991/16104 [23:03:47<42:28:47, 13.76s/it]

 31%|███       | 4992/16104 [23:04:09<49:30:15, 16.04s/it]

 31%|███       | 4993/16104 [23:04:29<53:23:32, 17.30s/it]

 31%|███       | 4994/16104 [23:04:49<55:50:46, 18.10s/it]

 31%|███       | 4995/16104 [23:05:10<58:22:45, 18.92s/it]

 31%|███       | 4996/16104 [23:05:27<57:08:07, 18.52s/it]

 31%|███       | 4997/16104 [23:05:40<52:05:58, 16.89s/it]

 31%|███       | 4998/16104 [23:05:53<48:00:51, 15.56s/it]

 31%|███       | 4999/16104 [23:06:13<52:10:15, 16.91s/it]

 31%|███       | 5000/16104 [23:06:23<46:20:46, 15.03s/it]

 31%|███       | 5001/16104 [23:06:49<56:25:26, 18.29s/it]

 31%|███       | 5002/16104 [23:07:09<57:37:35, 18.69s/it]

 31%|███       | 5003/16104 [23:07:22<52:30:30, 17.03s/it]

 31%|███       | 5004/16104 [23:07:36<49:41:35, 16.12s/it]

 31%|███       | 5005/16104 [23:07:58<54:58:11, 17.83s/it]

 31%|███       | 5006/16104 [23:08:13<52:32:27, 17.04s/it]

 31%|███       | 5007/16104 [23:08:35<57:02:06, 18.50s/it]

 31%|███       | 5008/16104 [23:08:54<57:36:02, 18.69s/it]

 31%|███       | 5009/16104 [23:09:12<56:22:47, 18.29s/it]

 31%|███       | 5010/16104 [23:09:29<55:56:03, 18.15s/it]

 31%|███       | 5011/16104 [23:09:52<60:15:26, 19.56s/it]

 31%|███       | 5012/16104 [23:10:05<54:05:33, 17.56s/it]

 31%|███       | 5013/16104 [23:10:23<54:50:46, 17.80s/it]

 31%|███       | 5014/16104 [23:10:42<55:18:43, 17.96s/it]

 31%|███       | 5015/16104 [23:10:55<50:36:19, 16.43s/it]

 31%|███       | 5016/16104 [23:11:15<53:52:22, 17.49s/it]

 31%|███       | 5017/16104 [23:11:31<52:24:22, 17.02s/it]

 31%|███       | 5018/16104 [23:11:51<55:15:52, 17.95s/it]

 31%|███       | 5019/16104 [23:12:10<56:51:46, 18.47s/it]

 31%|███       | 5020/16104 [23:12:26<54:28:49, 17.69s/it]

 31%|███       | 5021/16104 [23:12:42<53:04:17, 17.24s/it]

 31%|███       | 5022/16104 [23:13:00<53:47:14, 17.47s/it]

 31%|███       | 5023/16104 [23:13:13<49:41:15, 16.14s/it]

 31%|███       | 5024/16104 [23:13:28<48:08:40, 15.64s/it]

 31%|███       | 5025/16104 [23:13:46<50:26:18, 16.39s/it]

 31%|███       | 5026/16104 [23:13:59<46:59:29, 15.27s/it]

 31%|███       | 5027/16104 [23:14:17<49:25:19, 16.06s/it]
{'loss': 0.4222, 'learning_rate': 1.6108071396444234e-06, 'rewards/chosen': -1.7676849365234375, 'rewards/rejected': -2.3923845291137695, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6246994733810425, 'policy_logps/rejected': -417.617431640625, 'policy_logps/chosen': -489.2389831542969, 'referece_logps/rejected': -393.693603515625, 'referece_logps/chosen': -471.5621337890625, 'logits/rejected': -0.047389984130859375, 'logits/chosen': 0.08429396152496338, 'epoch': 1.87}

 31%|███       | 5028/16104 [23:14:38<54:31:28, 17.72s/it]


 31%|███       | 5030/16104 [23:15:20<59:02:46, 19.20s/it]
{'loss': 0.2868, 'learning_rate': 1.6103292855185217e-06, 'rewards/chosen': -0.6421545743942261, 'rewards/rejected': -3.5248167514801025, 'rewards/accuracies': 0.875, 'rewards/margins': 2.882662057876587, 'policy_logps/rejected': -569.217041015625, 'policy_logps/chosen': -375.4168395996094, 'referece_logps/rejected': -533.9688720703125, 'referece_logps/chosen': -368.99530029296875, 'logits/rejected': -0.31250178813934326, 'logits/chosen': -0.1507508009672165, 'epoch': 1.87}


 31%|███       | 5032/16104 [23:15:47<49:41:21, 16.16s/it]

 31%|███▏      | 5033/16104 [23:16:09<55:08:31, 17.93s/it]

 31%|███▏      | 5034/16104 [23:16:27<54:45:02, 17.81s/it]

 31%|███▏      | 5035/16104 [23:16:41<51:15:59, 16.67s/it]
{'loss': 0.3086, 'learning_rate': 1.60953236828314e-06, 'rewards/chosen': -1.5572112798690796, 'rewards/rejected': -2.9049925804138184, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3477811813354492, 'policy_logps/rejected': -369.7402648925781, 'policy_logps/chosen': -311.7044677734375, 'referece_logps/rejected': -340.6903381347656, 'referece_logps/chosen': -296.13232421875, 'logits/rejected': -1.21991765499115, 'logits/chosen': -0.9931339621543884, 'epoch': 1.88}


 31%|███▏      | 5037/16104 [23:17:22<57:49:27, 18.81s/it]
{'loss': 0.423, 'learning_rate': 1.6092134287471445e-06, 'rewards/chosen': -1.874325156211853, 'rewards/rejected': -2.9631524085998535, 'rewards/accuracies': 0.75, 'rewards/margins': 1.08882737159729, 'policy_logps/rejected': -497.7242126464844, 'policy_logps/chosen': -501.0528259277344, 'referece_logps/rejected': -468.09271240234375, 'referece_logps/chosen': -482.3095703125, 'logits/rejected': -0.47188419103622437, 'logits/chosen': -0.34025681018829346, 'epoch': 1.88}


 31%|███▏      | 5039/16104 [23:17:54<53:06:44, 17.28s/it]

 31%|███▏      | 5040/16104 [23:18:07<49:08:06, 15.99s/it]

 31%|███▏      | 5041/16104 [23:18:18<44:44:54, 14.56s/it]
{'loss': 0.5197, 'learning_rate': 1.6085752540015358e-06, 'rewards/chosen': -1.7132906913757324, 'rewards/rejected': -3.0419209003448486, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3286303281784058, 'policy_logps/rejected': -348.56402587890625, 'policy_logps/chosen': -480.7125549316406, 'referece_logps/rejected': -318.1448059082031, 'referece_logps/chosen': -463.57965087890625, 'logits/rejected': -0.20873403549194336, 'logits/chosen': -0.20209866762161255, 'epoch': 1.88}


 31%|███▏      | 5043/16104 [23:18:42<40:06:46, 13.06s/it]
{'loss': 0.3859, 'learning_rate': 1.6082560188951834e-06, 'rewards/chosen': -1.1633119583129883, 'rewards/rejected': -2.844919443130493, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6816074848175049, 'policy_logps/rejected': -511.7958679199219, 'policy_logps/chosen': -496.1041259765625, 'referece_logps/rejected': -483.34661865234375, 'referece_logps/chosen': -484.4710693359375, 'logits/rejected': 0.17749826610088348, 'logits/chosen': 0.19663016498088837, 'epoch': 1.88}


 31%|███▏      | 5045/16104 [23:19:07<39:28:31, 12.85s/it]

 31%|███▏      | 5046/16104 [23:19:18<37:31:42, 12.22s/it]

 31%|███▏      | 5047/16104 [23:19:36<43:14:52, 14.08s/it]

 31%|███▏      | 5048/16104 [23:19:58<49:56:07, 16.26s/it]

 31%|███▏      | 5049/16104 [23:20:19<54:51:23, 17.86s/it]

 31%|███▏      | 5050/16104 [23:20:30<48:19:46, 15.74s/it]

 31%|███▏      | 5051/16104 [23:20:41<44:05:40, 14.36s/it]

 31%|███▏      | 5052/16104 [23:20:52<40:57:27, 13.34s/it]
{'loss': 0.4061, 'learning_rate': 1.6068182437131969e-06, 'rewards/chosen': -1.3926719427108765, 'rewards/rejected': -2.4455924034118652, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0529205799102783, 'policy_logps/rejected': -401.7611083984375, 'policy_logps/chosen': -363.88482666015625, 'referece_logps/rejected': -377.3051452636719, 'referece_logps/chosen': -349.9580993652344, 'logits/rejected': -1.3260467052459717, 'logits/chosen': -1.3786416053771973, 'epoch': 1.88}


 31%|███▏      | 5054/16104 [23:21:17<39:39:00, 12.92s/it]

 31%|███▏      | 5055/16104 [23:21:33<42:27:23, 13.83s/it]

 31%|███▏      | 5056/16104 [23:21:53<48:04:55, 15.67s/it]

 31%|███▏      | 5057/16104 [23:22:06<45:46:24, 14.92s/it]

 31%|███▏      | 5058/16104 [23:22:20<45:11:21, 14.73s/it]

 31%|███▏      | 5059/16104 [23:22:32<42:50:47, 13.97s/it]

 31%|███▏      | 5060/16104 [23:22:50<46:03:32, 15.01s/it]

 31%|███▏      | 5061/16104 [23:23:06<47:41:47, 15.55s/it]

 31%|███▏      | 5062/16104 [23:23:26<51:12:30, 16.70s/it]
{'loss': 0.4592, 'learning_rate': 1.6052183839850222e-06, 'rewards/chosen': -1.2308584451675415, 'rewards/rejected': -3.0058178901672363, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7749593257904053, 'policy_logps/rejected': -494.3224792480469, 'policy_logps/chosen': -518.2767944335938, 'referece_logps/rejected': -464.2643127441406, 'referece_logps/chosen': -505.9682312011719, 'logits/rejected': 0.02428654581308365, 'logits/chosen': -0.02466491609811783, 'epoch': 1.89}


 31%|███▏      | 5064/16104 [23:24:06<56:39:58, 18.48s/it]

 31%|███▏      | 5065/16104 [23:24:26<58:06:59, 18.95s/it]

 31%|███▏      | 5066/16104 [23:24:45<58:27:16, 19.06s/it]

 31%|███▏      | 5067/16104 [23:25:06<60:21:22, 19.69s/it]

 31%|███▏      | 5068/16104 [23:25:18<53:21:38, 17.41s/it]

 31%|███▏      | 5069/16104 [23:25:38<55:42:13, 18.17s/it]

 31%|███▏      | 5070/16104 [23:25:59<57:44:07, 18.84s/it]

 31%|███▏      | 5071/16104 [23:26:20<60:11:26, 19.64s/it]

 31%|███▏      | 5072/16104 [23:26:38<58:03:22, 18.95s/it]

 32%|███▏      | 5073/16104 [23:26:48<50:33:49, 16.50s/it]
{'loss': 0.5964, 'learning_rate': 1.6034557108445302e-06, 'rewards/chosen': -2.1086204051971436, 'rewards/rejected': -3.0483922958374023, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9397717118263245, 'policy_logps/rejected': -468.0917663574219, 'policy_logps/chosen': -451.7066955566406, 'referece_logps/rejected': -437.6078186035156, 'referece_logps/chosen': -430.6204833984375, 'logits/rejected': -0.6547459363937378, 'logits/chosen': -0.5395168662071228, 'epoch': 1.89}

 32%|███▏      | 5074/16104 [23:27:09<54:42:34, 17.86s/it]

 32%|███▏      | 5075/16104 [23:27:31<58:14:55, 19.01s/it]


 32%|███▏      | 5077/16104 [23:28:14<62:03:19, 20.26s/it]

 32%|███▏      | 5078/16104 [23:28:34<61:12:34, 19.99s/it]

 32%|███▏      | 5079/16104 [23:28:55<62:15:45, 20.33s/it]
{'loss': 0.5384, 'learning_rate': 1.6024930072629557e-06, 'rewards/chosen': -1.6387308835983276, 'rewards/rejected': -1.8766101598739624, 'rewards/accuracies': 0.625, 'rewards/margins': 0.23787933588027954, 'policy_logps/rejected': -423.59393310546875, 'policy_logps/chosen': -350.52728271484375, 'referece_logps/rejected': -404.82781982421875, 'referece_logps/chosen': -334.13995361328125, 'logits/rejected': -0.5778392553329468, 'logits/chosen': -0.8185679912567139, 'epoch': 1.89}


 32%|███▏      | 5081/16104 [23:29:26<53:51:56, 17.59s/it]
{'loss': 0.4527, 'learning_rate': 1.602171911024513e-06, 'rewards/chosen': -1.4275158643722534, 'rewards/rejected': -3.49735689163208, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0698413848876953, 'policy_logps/rejected': -498.072509765625, 'policy_logps/chosen': -349.76190185546875, 'referece_logps/rejected': -463.0989685058594, 'referece_logps/chosen': -335.4867858886719, 'logits/rejected': -0.4239066541194916, 'logits/chosen': -0.21154269576072693, 'epoch': 1.89}


 32%|███▏      | 5083/16104 [23:30:00<53:07:01, 17.35s/it]
{'loss': 0.4448, 'learning_rate': 1.6018507173503584e-06, 'rewards/chosen': -1.8064324855804443, 'rewards/rejected': -3.046889305114746, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2404568195343018, 'policy_logps/rejected': -529.4080200195312, 'policy_logps/chosen': -595.1807250976562, 'referece_logps/rejected': -498.93914794921875, 'referece_logps/chosen': -577.1163940429688, 'logits/rejected': -0.7701840400695801, 'logits/chosen': -0.8392616510391235, 'epoch': 1.89}


 32%|███▏      | 5085/16104 [23:30:38<55:27:18, 18.12s/it]

 32%|███▏      | 5086/16104 [23:30:55<54:12:51, 17.71s/it]

 32%|███▏      | 5087/16104 [23:31:14<56:00:07, 18.30s/it]

 32%|███▏      | 5088/16104 [23:31:27<50:44:10, 16.58s/it]
{'loss': 0.4411, 'learning_rate': 1.6010473072248298e-06, 'rewards/chosen': -1.2532423734664917, 'rewards/rejected': -2.410112142562866, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1568700075149536, 'policy_logps/rejected': -323.37054443359375, 'policy_logps/chosen': -312.6838073730469, 'referece_logps/rejected': -299.2694396972656, 'referece_logps/chosen': -300.1513671875, 'logits/rejected': 0.011136144399642944, 'logits/chosen': 0.06424655020236969, 'epoch': 1.9}


 32%|███▏      | 5090/16104 [23:32:09<57:47:12, 18.89s/it]

 32%|███▏      | 5091/16104 [23:32:26<56:24:45, 18.44s/it]

 32%|███▏      | 5092/16104 [23:32:46<57:33:21, 18.82s/it]
{'loss': 0.4968, 'learning_rate': 1.6004041414435721e-06, 'rewards/chosen': -1.5015782117843628, 'rewards/rejected': -2.1173479557037354, 'rewards/accuracies': 0.5, 'rewards/margins': 0.615769624710083, 'policy_logps/rejected': -376.4857177734375, 'policy_logps/chosen': -373.9722595214844, 'referece_logps/rejected': -355.312255859375, 'referece_logps/chosen': -358.95654296875, 'logits/rejected': 0.031133199110627174, 'logits/chosen': 0.0776757076382637, 'epoch': 1.9}

 32%|███▏      | 5093/16104 [23:33:07<59:47:06, 19.55s/it]

 32%|███▏      | 5094/16104 [23:33:28<60:26:31, 19.76s/it]


 32%|███▏      | 5096/16104 [23:34:10<63:28:08, 20.76s/it]

 32%|███▏      | 5097/16104 [23:34:29<61:29:16, 20.11s/it]

 32%|███▏      | 5098/16104 [23:34:43<55:22:51, 18.11s/it]
{'loss': 0.5466, 'learning_rate': 1.5994386642793095e-06, 'rewards/chosen': -1.068591833114624, 'rewards/rejected': -1.410264492034912, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3416725993156433, 'policy_logps/rejected': -253.83203125, 'policy_logps/chosen': -305.5892028808594, 'referece_logps/rejected': -239.7294158935547, 'referece_logps/chosen': -294.9033203125, 'logits/rejected': -0.5279557704925537, 'logits/chosen': -0.4953327178955078, 'epoch': 1.9}


 32%|███▏      | 5100/16104 [23:35:19<55:26:29, 18.14s/it]

 32%|███▏      | 5101/16104 [23:35:31<50:33:53, 16.54s/it]

 32%|███▏      | 5102/16104 [23:35:51<53:10:23, 17.40s/it]

 32%|███▏      | 5103/16104 [23:36:11<55:51:01, 18.28s/it]

 32%|███▏      | 5104/16104 [23:36:29<55:41:15, 18.23s/it]

 32%|███▏      | 5105/16104 [23:36:40<49:04:26, 16.06s/it]

 32%|███▏      | 5106/16104 [23:36:59<51:38:58, 16.91s/it]
{'loss': 0.369, 'learning_rate': 1.598150003728614e-06, 'rewards/chosen': -0.6970769762992859, 'rewards/rejected': -2.0003976821899414, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3033206462860107, 'policy_logps/rejected': -444.71612548828125, 'policy_logps/chosen': -389.1852722167969, 'referece_logps/rejected': -424.7121887207031, 'referece_logps/chosen': -382.2144775390625, 'logits/rejected': 0.9867114424705505, 'logits/chosen': 0.9587736129760742, 'epoch': 1.9}


 32%|███▏      | 5108/16104 [23:37:21<42:35:53, 13.95s/it]

 32%|███▏      | 5109/16104 [23:37:35<42:53:07, 14.04s/it]

 32%|███▏      | 5110/16104 [23:37:53<45:42:09, 14.97s/it]

 32%|███▏      | 5111/16104 [23:38:15<52:03:01, 17.05s/it]

 32%|███▏      | 5112/16104 [23:38:37<57:27:04, 18.82s/it]

 32%|███▏      | 5113/16104 [23:38:49<50:24:12, 16.51s/it]

 32%|███▏      | 5114/16104 [23:38:59<45:15:02, 14.82s/it]

 32%|███▏      | 5115/16104 [23:39:17<47:26:29, 15.54s/it]

 32%|███▏      | 5116/16104 [23:39:35<50:19:28, 16.49s/it]
{'loss': 0.3262, 'learning_rate': 1.5965370007709e-06, 'rewards/chosen': -1.2071956396102905, 'rewards/rejected': -3.218400478363037, 'rewards/accuracies': 0.875, 'rewards/margins': 2.011204957962036, 'policy_logps/rejected': -439.0096435546875, 'policy_logps/chosen': -398.7801818847656, 'referece_logps/rejected': -406.82568359375, 'referece_logps/chosen': -386.7082214355469, 'logits/rejected': -0.27153971791267395, 'logits/chosen': -0.16938360035419464, 'epoch': 1.91}

 32%|███▏      | 5117/16104 [23:39:54<52:25:50, 17.18s/it]


 32%|███▏      | 5119/16104 [23:40:33<56:37:26, 18.56s/it]

 32%|███▏      | 5120/16104 [23:40:51<55:39:08, 18.24s/it]

 32%|███▏      | 5121/16104 [23:41:11<57:08:30, 18.73s/it]

 32%|███▏      | 5122/16104 [23:41:30<57:30:00, 18.85s/it]
{'loss': 0.4586, 'learning_rate': 1.5955680402913219e-06, 'rewards/chosen': -1.72890305519104, 'rewards/rejected': -2.271498441696167, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5425955057144165, 'policy_logps/rejected': -337.5110778808594, 'policy_logps/chosen': -305.3016052246094, 'referece_logps/rejected': -314.79608154296875, 'referece_logps/chosen': -288.0125732421875, 'logits/rejected': -0.8914566040039062, 'logits/chosen': -1.025649070739746, 'epoch': 1.91}

 32%|███▏      | 5123/16104 [23:41:46<55:08:17, 18.08s/it]

 32%|███▏      | 5124/16104 [23:42:06<57:12:10, 18.76s/it]


 32%|███▏      | 5126/16104 [23:42:31<47:09:54, 15.47s/it]

 32%|███▏      | 5127/16104 [23:42:51<51:11:39, 16.79s/it]
{'loss': 0.3247, 'learning_rate': 1.5947599106409384e-06, 'rewards/chosen': -0.9222159385681152, 'rewards/rejected': -3.197859525680542, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2756433486938477, 'policy_logps/rejected': -315.2661437988281, 'policy_logps/chosen': -483.18719482421875, 'referece_logps/rejected': -283.2875671386719, 'referece_logps/chosen': -473.96502685546875, 'logits/rejected': -0.31130778789520264, 'logits/chosen': -0.250669002532959, 'epoch': 1.91}


 32%|███▏      | 5129/16104 [23:43:15<44:31:30, 14.61s/it]

 32%|███▏      | 5130/16104 [23:43:30<44:00:27, 14.44s/it]

 32%|███▏      | 5131/16104 [23:43:44<43:37:49, 14.31s/it]

 32%|███▏      | 5132/16104 [23:43:55<40:41:26, 13.35s/it]
{'loss': 0.3748, 'learning_rate': 1.5939511795131107e-06, 'rewards/chosen': -1.6878321170806885, 'rewards/rejected': -4.875810623168945, 'rewards/accuracies': 0.875, 'rewards/margins': 3.1879782676696777, 'policy_logps/rejected': -355.57012939453125, 'policy_logps/chosen': -387.6290588378906, 'referece_logps/rejected': -306.8120422363281, 'referece_logps/chosen': -370.7507629394531, 'logits/rejected': -1.017444372177124, 'logits/chosen': -1.120269775390625, 'epoch': 1.91}


 32%|███▏      | 5134/16104 [23:44:35<51:25:23, 16.88s/it]

 32%|███▏      | 5135/16104 [23:44:55<54:03:46, 17.74s/it]
{'loss': 0.3965, 'learning_rate': 1.593465652467447e-06, 'rewards/chosen': -2.0802741050720215, 'rewards/rejected': -3.6598236560821533, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5795494318008423, 'policy_logps/rejected': -396.82769775390625, 'policy_logps/chosen': -407.65863037109375, 'referece_logps/rejected': -360.2294921875, 'referece_logps/chosen': -386.8558654785156, 'logits/rejected': -1.0525836944580078, 'logits/chosen': -1.1588691473007202, 'epoch': 1.91}

 32%|███▏      | 5136/16104 [23:45:14<55:31:51, 18.23s/it]

 32%|███▏      | 5137/16104 [23:45:32<55:32:02, 18.23s/it]


 32%|███▏      | 5139/16104 [23:46:07<53:49:22, 17.67s/it]

 32%|███▏      | 5140/16104 [23:46:28<56:40:10, 18.61s/it]

 32%|███▏      | 5141/16104 [23:46:44<54:16:25, 17.82s/it]
{'loss': 0.2921, 'learning_rate': 1.592493950370874e-06, 'rewards/chosen': -1.0897390842437744, 'rewards/rejected': -2.72332501411438, 'rewards/accuracies': 1.0, 'rewards/margins': 1.633586049079895, 'policy_logps/rejected': -208.95407104492188, 'policy_logps/chosen': -345.24700927734375, 'referece_logps/rejected': -181.72084045410156, 'referece_logps/chosen': -334.349609375, 'logits/rejected': -0.8366348147392273, 'logits/chosen': -0.6549151539802551, 'epoch': 1.92}

 32%|███▏      | 5142/16104 [23:47:00<53:09:39, 17.46s/it]

 32%|███▏      | 5143/16104 [23:47:17<52:08:17, 17.12s/it]

 32%|███▏      | 5144/16104 [23:47:31<49:49:45, 16.37s/it]


 32%|███▏      | 5146/16104 [23:48:04<49:14:44, 16.18s/it]

 32%|███▏      | 5147/16104 [23:48:22<51:27:03, 16.90s/it]

 32%|███▏      | 5148/16104 [23:48:36<48:46:44, 16.03s/it]
{'loss': 0.5212, 'learning_rate': 1.5913592075060197e-06, 'rewards/chosen': -1.3065378665924072, 'rewards/rejected': -3.1206650733947754, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8141272068023682, 'policy_logps/rejected': -357.17034912109375, 'policy_logps/chosen': -333.21380615234375, 'referece_logps/rejected': -325.96368408203125, 'referece_logps/chosen': -320.1484375, 'logits/rejected': -0.24239705502986908, 'logits/chosen': -0.21656882762908936, 'epoch': 1.92}


 32%|███▏      | 5150/16104 [23:49:10<49:42:38, 16.34s/it]

 32%|███▏      | 5151/16104 [23:49:24<48:17:45, 15.87s/it]

 32%|███▏      | 5152/16104 [23:49:44<51:34:01, 16.95s/it]
{'loss': 0.4063, 'learning_rate': 1.5907102565937671e-06, 'rewards/chosen': -1.293302297592163, 'rewards/rejected': -2.5972912311553955, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3039889335632324, 'policy_logps/rejected': -327.715087890625, 'policy_logps/chosen': -363.5430908203125, 'referece_logps/rejected': -301.7421569824219, 'referece_logps/chosen': -350.610107421875, 'logits/rejected': 0.013755105435848236, 'logits/chosen': 0.2919676601886749, 'epoch': 1.92}

 32%|███▏      | 5153/16104 [23:49:55<45:53:54, 15.09s/it]


 32%|███▏      | 5155/16104 [23:50:20<41:36:13, 13.68s/it]
{'loss': 0.4202, 'learning_rate': 1.5902232924861294e-06, 'rewards/chosen': -0.8390709161758423, 'rewards/rejected': -2.8349077701568604, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9958367347717285, 'policy_logps/rejected': -315.914794921875, 'policy_logps/chosen': -494.0576171875, 'referece_logps/rejected': -287.5657043457031, 'referece_logps/chosen': -485.6669006347656, 'logits/rejected': -0.7418546676635742, 'logits/chosen': -0.6186885833740234, 'epoch': 1.92}

 32%|███▏      | 5156/16104 [23:50:32<40:40:10, 13.37s/it]


 32%|███▏      | 5158/16104 [23:50:54<36:46:05, 12.09s/it]
{'loss': 0.5227, 'learning_rate': 1.5897361134982284e-06, 'rewards/chosen': -1.1151424646377563, 'rewards/rejected': -2.1769862174987793, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0618438720703125, 'policy_logps/rejected': -544.9991455078125, 'policy_logps/chosen': -474.0542907714844, 'referece_logps/rejected': -523.2291870117188, 'referece_logps/chosen': -462.9028625488281, 'logits/rejected': -0.34656721353530884, 'logits/chosen': -0.08592816442251205, 'epoch': 1.92}


 32%|███▏      | 5160/16104 [23:51:16<35:00:28, 11.52s/it]
{'loss': 0.4911, 'learning_rate': 1.5894112082159553e-06, 'rewards/chosen': -1.7017980813980103, 'rewards/rejected': -2.898564100265503, 'rewards/accuracies': 0.5, 'rewards/margins': 1.1967660188674927, 'policy_logps/rejected': -271.2578125, 'policy_logps/chosen': -421.3214416503906, 'referece_logps/rejected': -242.2721710205078, 'referece_logps/chosen': -404.3034362792969, 'logits/rejected': -0.5638313293457031, 'logits/chosen': -0.685046911239624, 'epoch': 1.92}

 32%|███▏      | 5161/16104 [23:51:39<45:00:34, 14.81s/it]


 32%|███▏      | 5163/16104 [23:52:16<51:58:50, 17.10s/it]

 32%|███▏      | 5164/16104 [23:52:32<50:53:07, 16.74s/it]

 32%|███▏      | 5165/16104 [23:52:46<47:49:30, 15.74s/it]
{'loss': 0.3585, 'learning_rate': 1.58859852787745e-06, 'rewards/chosen': -1.1639220714569092, 'rewards/rejected': -2.4848618507385254, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3209396600723267, 'policy_logps/rejected': -439.1192626953125, 'policy_logps/chosen': -541.4067993164062, 'referece_logps/rejected': -414.2706298828125, 'referece_logps/chosen': -529.7676391601562, 'logits/rejected': -0.7283627986907959, 'logits/chosen': -0.7825704216957092, 'epoch': 1.92}

 32%|███▏      | 5166/16104 [23:53:03<48:54:53, 16.10s/it]

 32%|███▏      | 5167/16104 [23:53:17<47:25:07, 15.61s/it]

 32%|███▏      | 5168/16104 [23:53:33<47:57:21, 15.79s/it]


 32%|███▏      | 5170/16104 [23:54:09<50:35:03, 16.65s/it]
{'loss': 0.2819, 'learning_rate': 1.587785252292473e-06, 'rewards/chosen': -1.4570419788360596, 'rewards/rejected': -3.5956013202667236, 'rewards/accuracies': 0.875, 'rewards/margins': 2.138558864593506, 'policy_logps/rejected': -458.5275573730469, 'policy_logps/chosen': -413.84423828125, 'referece_logps/rejected': -422.57159423828125, 'referece_logps/chosen': -399.2738342285156, 'logits/rejected': 0.21260708570480347, 'logits/chosen': 0.23867085576057434, 'epoch': 1.93}


 32%|███▏      | 5172/16104 [23:54:36<46:14:13, 15.23s/it]

 32%|███▏      | 5173/16104 [23:54:52<47:24:14, 15.61s/it]
{'loss': 0.4768, 'learning_rate': 1.587297001565299e-06, 'rewards/chosen': -1.0735461711883545, 'rewards/rejected': -2.3607547283172607, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2872085571289062, 'policy_logps/rejected': -269.7674865722656, 'policy_logps/chosen': -379.8175048828125, 'referece_logps/rejected': -246.15994262695312, 'referece_logps/chosen': -369.0820617675781, 'logits/rejected': -1.221138596534729, 'logits/chosen': -1.198788046836853, 'epoch': 1.93}

 32%|███▏      | 5174/16104 [23:55:05<44:58:42, 14.81s/it]

 32%|███▏      | 5175/16104 [23:55:19<43:56:50, 14.48s/it]

 32%|███▏      | 5176/16104 [23:55:37<47:29:07, 15.64s/it]

 32%|███▏      | 5177/16104 [23:55:53<47:24:02, 15.62s/it]

 32%|███▏      | 5178/16104 [23:56:13<51:47:37, 17.07s/it]


 32%|███▏      | 5180/16104 [23:56:52<55:06:36, 18.16s/it]
{'loss': 0.3573, 'learning_rate': 1.5861569186735491e-06, 'rewards/chosen': -1.3124998807907104, 'rewards/rejected': -2.9433035850524902, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6308035850524902, 'policy_logps/rejected': -305.3373107910156, 'policy_logps/chosen': -348.9275817871094, 'referece_logps/rejected': -275.904296875, 'referece_logps/chosen': -335.8026123046875, 'logits/rejected': -0.3363531231880188, 'logits/chosen': -0.1772027462720871, 'epoch': 1.93}


 32%|███▏      | 5182/16104 [23:57:24<51:13:19, 16.88s/it]

 32%|███▏      | 5183/16104 [23:57:44<53:49:29, 17.74s/it]

 32%|███▏      | 5184/16104 [23:58:05<56:26:54, 18.61s/it]
{'loss': 0.3652, 'learning_rate': 1.5855049209463983e-06, 'rewards/chosen': -1.2166078090667725, 'rewards/rejected': -3.1209568977355957, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9043489694595337, 'policy_logps/rejected': -518.8199462890625, 'policy_logps/chosen': -364.20977783203125, 'referece_logps/rejected': -487.6103515625, 'referece_logps/chosen': -352.043701171875, 'logits/rejected': -0.552665114402771, 'logits/chosen': -0.45448213815689087, 'epoch': 1.93}


 32%|███▏      | 5186/16104 [23:58:47<60:03:17, 19.80s/it]
{'loss': 0.4026, 'learning_rate': 1.585178779948133e-06, 'rewards/chosen': -1.1246798038482666, 'rewards/rejected': -1.8857260942459106, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7610461115837097, 'policy_logps/rejected': -536.5043334960938, 'policy_logps/chosen': -493.6332702636719, 'referece_logps/rejected': -517.6470947265625, 'referece_logps/chosen': -482.386474609375, 'logits/rejected': -0.6955212354660034, 'logits/chosen': -0.863328218460083, 'epoch': 1.93}

 32%|███▏      | 5187/16104 [23:59:06<59:24:55, 19.59s/it]

 32%|███▏      | 5188/16104 [23:59:21<55:40:34, 18.36s/it]


 32%|███▏      | 5190/16104 [23:59:58<56:30:44, 18.64s/it]
{'loss': 0.3342, 'learning_rate': 1.5845262139460815e-06, 'rewards/chosen': -0.984709620475769, 'rewards/rejected': -4.152196884155273, 'rewards/accuracies': 1.0, 'rewards/margins': 3.167487621307373, 'policy_logps/rejected': -485.13653564453125, 'policy_logps/chosen': -403.7431640625, 'referece_logps/rejected': -443.61456298828125, 'referece_logps/chosen': -393.8960876464844, 'logits/rejected': 0.04327040910720825, 'logits/chosen': -0.08689185976982117, 'epoch': 1.93}

 32%|███▏      | 5191/16104 [24:00:16<55:44:24, 18.39s/it]


 32%|███▏      | 5193/16104 [24:00:55<56:29:51, 18.64s/it]

 32%|███▏      | 5194/16104 [24:01:11<54:14:08, 17.90s/it]
{'loss': 0.5026, 'learning_rate': 1.583873269621994e-06, 'rewards/chosen': -2.006760358810425, 'rewards/rejected': -2.7807934284210205, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7740331888198853, 'policy_logps/rejected': -315.8187255859375, 'policy_logps/chosen': -291.198486328125, 'referece_logps/rejected': -288.0107421875, 'referece_logps/chosen': -271.130859375, 'logits/rejected': -0.28715208172798157, 'logits/chosen': -0.11508038640022278, 'epoch': 1.94}

 32%|███▏      | 5195/16104 [24:01:25<51:10:45, 16.89s/it]

 32%|███▏      | 5196/16104 [24:01:46<54:14:03, 17.90s/it]

 32%|███▏      | 5197/16104 [24:02:01<52:24:05, 17.30s/it]


 32%|███▏      | 5199/16104 [24:02:27<45:18:05, 14.96s/it]
{'loss': 0.3867, 'learning_rate': 1.583056557845356e-06, 'rewards/chosen': -1.7961822748184204, 'rewards/rejected': -3.049966812133789, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2537842988967896, 'policy_logps/rejected': -355.7035827636719, 'policy_logps/chosen': -354.3957214355469, 'referece_logps/rejected': -325.2039489746094, 'referece_logps/chosen': -336.4338684082031, 'logits/rejected': 0.012223668396472931, 'logits/chosen': 0.0003098994493484497, 'epoch': 1.94}

 32%|███▏      | 5200/16104 [24:02:44<47:07:01, 15.56s/it]

 32%|███▏      | 5201/16104 [24:03:00<47:49:21, 15.79s/it]


 32%|███▏      | 5203/16104 [24:03:41<55:23:56, 18.30s/it]

 32%|███▏      | 5204/16104 [24:04:01<56:30:15, 18.66s/it]
{'loss': 0.3186, 'learning_rate': 1.5822392564268103e-06, 'rewards/chosen': -1.5201222896575928, 'rewards/rejected': -2.145787000656128, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6256649494171143, 'policy_logps/rejected': -252.44723510742188, 'policy_logps/chosen': -266.081298828125, 'referece_logps/rejected': -230.98934936523438, 'referece_logps/chosen': -250.8800811767578, 'logits/rejected': -0.4483295679092407, 'logits/chosen': -0.5049161314964294, 'epoch': 1.94}

 32%|███▏      | 5205/16104 [24:04:11<49:15:02, 16.27s/it]

 32%|███▏      | 5206/16104 [24:04:22<44:25:06, 14.67s/it]


 32%|███▏      | 5208/16104 [24:04:47<41:16:01, 13.63s/it]
{'loss': 0.2882, 'learning_rate': 1.58158499130521e-06, 'rewards/chosen': -1.6748573780059814, 'rewards/rejected': -2.6217875480651855, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9469304084777832, 'policy_logps/rejected': -338.9277648925781, 'policy_logps/chosen': -288.1131896972656, 'referece_logps/rejected': -312.70989990234375, 'referece_logps/chosen': -271.3646240234375, 'logits/rejected': 0.3018241226673126, 'logits/chosen': 0.3282620906829834, 'epoch': 1.94}


 32%|███▏      | 5210/16104 [24:05:15<42:22:14, 14.00s/it]
{'loss': 0.5017, 'learning_rate': 1.581257717561037e-06, 'rewards/chosen': -1.3707996606826782, 'rewards/rejected': -2.222867488861084, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8520679473876953, 'policy_logps/rejected': -409.1037902832031, 'policy_logps/chosen': -406.3236389160156, 'referece_logps/rejected': -386.8750915527344, 'referece_logps/chosen': -392.61566162109375, 'logits/rejected': -0.4722524881362915, 'logits/chosen': -0.5281643271446228, 'epoch': 1.94}


 32%|███▏      | 5212/16104 [24:05:45<45:00:02, 14.87s/it]

 32%|███▏      | 5213/16104 [24:06:05<49:47:04, 16.46s/it]

 32%|███▏      | 5214/16104 [24:06:23<51:12:15, 16.93s/it]
{'loss': 0.346, 'learning_rate': 1.5806028879707207e-06, 'rewards/chosen': -2.8944952487945557, 'rewards/rejected': -4.8794660568237305, 'rewards/accuracies': 0.875, 'rewards/margins': 1.984971046447754, 'policy_logps/rejected': -488.0310363769531, 'policy_logps/chosen': -622.7542724609375, 'referece_logps/rejected': -439.23638916015625, 'referece_logps/chosen': -593.809326171875, 'logits/rejected': -0.7762664556503296, 'logits/chosen': -0.867384672164917, 'epoch': 1.94}

 32%|███▏      | 5215/16104 [24:06:38<49:01:53, 16.21s/it]


 32%|███▏      | 5217/16104 [24:07:09<47:53:50, 15.84s/it]

 32%|███▏      | 5218/16104 [24:07:23<46:11:05, 15.27s/it]

 32%|███▏      | 5219/16104 [24:07:40<46:59:32, 15.54s/it]
{'loss': 0.6579, 'learning_rate': 1.5797838225880269e-06, 'rewards/chosen': -1.3371286392211914, 'rewards/rejected': -1.8874952793121338, 'rewards/accuracies': 0.375, 'rewards/margins': 0.5503666400909424, 'policy_logps/rejected': -386.14898681640625, 'policy_logps/chosen': -473.64813232421875, 'referece_logps/rejected': -367.2739562988281, 'referece_logps/chosen': -460.2768859863281, 'logits/rejected': 0.11197744309902191, 'logits/chosen': 0.07921668142080307, 'epoch': 1.94}


 32%|███▏      | 5221/16104 [24:08:13<49:25:34, 16.35s/it]
{'loss': 0.3165, 'learning_rate': 1.5794560322155257e-06, 'rewards/chosen': -1.1012723445892334, 'rewards/rejected': -3.58843731880188, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4871649742126465, 'policy_logps/rejected': -357.8392333984375, 'policy_logps/chosen': -364.07598876953125, 'referece_logps/rejected': -321.954833984375, 'referece_logps/chosen': -353.0632019042969, 'logits/rejected': 0.0975065678358078, 'logits/chosen': -0.0005827844142913818, 'epoch': 1.95}


 32%|███▏      | 5223/16104 [24:08:35<41:18:50, 13.67s/it]
{'loss': 0.4175, 'learning_rate': 1.5791281480829028e-06, 'rewards/chosen': -1.1455271244049072, 'rewards/rejected': -2.5730795860290527, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4275527000427246, 'policy_logps/rejected': -253.00677490234375, 'policy_logps/chosen': -306.7881774902344, 'referece_logps/rejected': -227.2759552001953, 'referece_logps/chosen': -295.3329162597656, 'logits/rejected': -0.25420674681663513, 'logits/chosen': -0.2647467255592346, 'epoch': 1.95}

 32%|███▏      | 5224/16104 [24:08:46<38:38:19, 12.78s/it]


 32%|███▏      | 5226/16104 [24:09:13<39:43:11, 13.15s/it]

 32%|███▏      | 5227/16104 [24:09:26<39:08:34, 12.96s/it]
{'loss': 0.3954, 'learning_rate': 1.578472098749525e-06, 'rewards/chosen': -1.2552107572555542, 'rewards/rejected': -2.212502956390381, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9572921395301819, 'policy_logps/rejected': -460.4618225097656, 'policy_logps/chosen': -596.7847290039062, 'referece_logps/rejected': -438.3367614746094, 'referece_logps/chosen': -584.2326049804688, 'logits/rejected': -0.6952815055847168, 'logits/chosen': -0.7608401775360107, 'epoch': 1.95}

 32%|███▏      | 5228/16104 [24:09:37<37:30:50, 12.42s/it]


 32%|███▏      | 5230/16104 [24:10:11<46:01:00, 15.23s/it]

 32%|███▏      | 5231/16104 [24:10:31<50:20:07, 16.67s/it]
{'loss': 0.4185, 'learning_rate': 1.577815675012507e-06, 'rewards/chosen': -0.8723052740097046, 'rewards/rejected': -1.9902222156524658, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1179170608520508, 'policy_logps/rejected': -463.2408752441406, 'policy_logps/chosen': -547.577392578125, 'referece_logps/rejected': -443.3385925292969, 'referece_logps/chosen': -538.8543701171875, 'logits/rejected': -0.3162025213241577, 'logits/chosen': -0.17123796045780182, 'epoch': 1.95}

 32%|███▏      | 5232/16104 [24:10:52<54:23:13, 18.01s/it]

 32%|███▏      | 5233/16104 [24:11:13<56:12:41, 18.61s/it]

 33%|███▎      | 5234/16104 [24:11:32<57:13:36, 18.95s/it]


 33%|███▎      | 5236/16104 [24:12:03<50:38:15, 16.77s/it]
{'loss': 0.4995, 'learning_rate': 1.5769946194833813e-06, 'rewards/chosen': -1.5299017429351807, 'rewards/rejected': -2.9044530391693115, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3745509386062622, 'policy_logps/rejected': -302.90106201171875, 'policy_logps/chosen': -327.5531311035156, 'referece_logps/rejected': -273.85650634765625, 'referece_logps/chosen': -312.2541198730469, 'logits/rejected': -0.3684876263141632, 'logits/chosen': -0.5445370078086853, 'epoch': 1.95}


 33%|███▎      | 5238/16104 [24:12:37<51:08:53, 16.95s/it]
{'loss': 0.4038, 'learning_rate': 1.576666033841992e-06, 'rewards/chosen': -1.85149085521698, 'rewards/rejected': -3.0150279998779297, 'rewards/accuracies': 0.75, 'rewards/margins': 1.163536787033081, 'policy_logps/rejected': -455.9930725097656, 'policy_logps/chosen': -341.22308349609375, 'referece_logps/rejected': -425.8427734375, 'referece_logps/chosen': -322.70819091796875, 'logits/rejected': -0.7266420722007751, 'logits/chosen': -0.5227482914924622, 'epoch': 1.95}

 33%|███▎      | 5239/16104 [24:12:56<52:37:02, 17.43s/it]


 33%|███▎      | 5241/16104 [24:13:27<48:24:24, 16.04s/it]
{'loss': 0.4578, 'learning_rate': 1.5761729804427529e-06, 'rewards/chosen': -0.9816917181015015, 'rewards/rejected': -2.176482677459717, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1947909593582153, 'policy_logps/rejected': -253.5608367919922, 'policy_logps/chosen': -307.8573913574219, 'referece_logps/rejected': -231.79600524902344, 'referece_logps/chosen': -298.0404968261719, 'logits/rejected': -0.5346551537513733, 'logits/chosen': -0.639156699180603, 'epoch': 1.95}

 33%|███▎      | 5242/16104 [24:13:38<43:54:24, 14.55s/it]


 33%|███▎      | 5244/16104 [24:14:00<38:11:12, 12.66s/it]
{'loss': 0.3458, 'learning_rate': 1.5756797172784922e-06, 'rewards/chosen': -0.7562533617019653, 'rewards/rejected': -2.695734739303589, 'rewards/accuracies': 1.0, 'rewards/margins': 1.939481258392334, 'policy_logps/rejected': -326.1441955566406, 'policy_logps/chosen': -432.8504333496094, 'referece_logps/rejected': -299.1868591308594, 'referece_logps/chosen': -425.2878723144531, 'logits/rejected': 0.17405401170253754, 'logits/chosen': 0.42231714725494385, 'epoch': 1.95}

 33%|███▎      | 5245/16104 [24:14:17<42:00:19, 13.93s/it]


 33%|███▎      | 5247/16104 [24:14:52<47:21:11, 15.70s/it]

 33%|███▎      | 5248/16104 [24:15:12<51:13:23, 16.99s/it]
{'loss': 0.3675, 'learning_rate': 1.5750217070687302e-06, 'rewards/chosen': -1.5343830585479736, 'rewards/rejected': -2.8307077884674072, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2963250875473022, 'policy_logps/rejected': -394.20294189453125, 'policy_logps/chosen': -389.6427917480469, 'referece_logps/rejected': -365.8959045410156, 'referece_logps/chosen': -374.29901123046875, 'logits/rejected': -0.18074819445610046, 'logits/chosen': -0.015342861413955688, 'epoch': 1.96}

 33%|███▎      | 5249/16104 [24:15:28<50:55:43, 16.89s/it]


 33%|███▎      | 5251/16104 [24:16:01<51:10:45, 16.98s/it]
{'loss': 0.451, 'learning_rate': 1.574527955151253e-06, 'rewards/chosen': -2.1321918964385986, 'rewards/rejected': -3.064986228942871, 'rewards/accuracies': 0.875, 'rewards/margins': 0.932794451713562, 'policy_logps/rejected': -369.1175537109375, 'policy_logps/chosen': -333.2841491699219, 'referece_logps/rejected': -338.4676513671875, 'referece_logps/chosen': -311.96221923828125, 'logits/rejected': 0.4164784550666809, 'logits/chosen': 0.30820608139038086, 'epoch': 1.96}


 33%|███▎      | 5253/16104 [24:16:39<54:29:42, 18.08s/it]
{'loss': 0.3949, 'learning_rate': 1.5741986709917665e-06, 'rewards/chosen': -0.9106733202934265, 'rewards/rejected': -2.65617299079895, 'rewards/accuracies': 0.75, 'rewards/margins': 1.745499849319458, 'policy_logps/rejected': -277.3085632324219, 'policy_logps/chosen': -405.24951171875, 'referece_logps/rejected': -250.74684143066406, 'referece_logps/chosen': -396.142822265625, 'logits/rejected': -0.5692616701126099, 'logits/chosen': -0.6013572812080383, 'epoch': 1.96}

 33%|███▎      | 5254/16104 [24:16:51<48:48:56, 16.20s/it]

 33%|███▎      | 5255/16104 [24:17:07<48:03:25, 15.95s/it]

 33%|███▎      | 5256/16104 [24:17:17<43:12:26, 14.34s/it]

 33%|███▎      | 5257/16104 [24:17:32<43:54:30, 14.57s/it]


 33%|███▎      | 5259/16104 [24:18:06<47:20:16, 15.71s/it]
{'loss': 0.3287, 'learning_rate': 1.5732102612698493e-06, 'rewards/chosen': -1.549414873123169, 'rewards/rejected': -2.959693431854248, 'rewards/accuracies': 0.875, 'rewards/margins': 1.410278558731079, 'policy_logps/rejected': -322.51171875, 'policy_logps/chosen': -379.2678527832031, 'referece_logps/rejected': -292.914794921875, 'referece_logps/chosen': -363.773681640625, 'logits/rejected': -0.5216578245162964, 'logits/chosen': -0.41164347529411316, 'epoch': 1.96}

 33%|███▎      | 5260/16104 [24:18:27<52:03:03, 17.28s/it]

 33%|███▎      | 5261/16104 [24:18:39<47:31:21, 15.78s/it]

 33%|███▎      | 5262/16104 [24:18:53<46:04:13, 15.30s/it]


 33%|███▎      | 5264/16104 [24:19:24<46:19:38, 15.39s/it]
{'loss': 0.4963, 'learning_rate': 1.572385948787645e-06, 'rewards/chosen': -1.9522608518600464, 'rewards/rejected': -2.5654637813568115, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6132029294967651, 'policy_logps/rejected': -328.05450439453125, 'policy_logps/chosen': -504.48248291015625, 'referece_logps/rejected': -302.39990234375, 'referece_logps/chosen': -484.9598693847656, 'logits/rejected': -1.3182909488677979, 'logits/chosen': -1.487380027770996, 'epoch': 1.96}

 33%|███▎      | 5265/16104 [24:19:41<47:34:49, 15.80s/it]

 33%|███▎      | 5266/16104 [24:19:58<49:12:14, 16.34s/it]

 33%|███▎      | 5267/16104 [24:20:11<45:48:25, 15.22s/it]

 33%|███▎      | 5268/16104 [24:20:23<42:52:06, 14.24s/it]

 33%|███▎      | 5269/16104 [24:20:39<44:51:36, 14.91s/it]

 33%|███▎      | 5270/16104 [24:20:50<40:56:34, 13.60s/it]

 33%|███▎      | 5271/16104 [24:21:04<41:03:14, 13.64s/it]

 33%|███▎      | 5272/16104 [24:21:21<44:31:14, 14.80s/it]

 33%|███▎      | 5273/16104 [24:21:39<47:12:32, 15.69s/it]


 33%|███▎      | 5275/16104 [24:22:10<47:24:49, 15.76s/it]
{'loss': 0.3968, 'learning_rate': 1.570570424946658e-06, 'rewards/chosen': -1.2750188112258911, 'rewards/rejected': -2.779447555541992, 'rewards/accuracies': 1.0, 'rewards/margins': 1.504428744316101, 'policy_logps/rejected': -329.99908447265625, 'policy_logps/chosen': -359.1598815917969, 'referece_logps/rejected': -302.20465087890625, 'referece_logps/chosen': -346.4096984863281, 'logits/rejected': -1.0047240257263184, 'logits/chosen': -1.08677077293396, 'epoch': 1.97}

 33%|███▎      | 5276/16104 [24:22:29<50:21:43, 16.74s/it]

 33%|███▎      | 5277/16104 [24:22:50<53:48:15, 17.89s/it]

 33%|███▎      | 5278/16104 [24:23:07<53:26:58, 17.77s/it]

 33%|███▎      | 5279/16104 [24:23:26<53:46:24, 17.88s/it]

 33%|███▎      | 5280/16104 [24:23:45<55:11:52, 18.36s/it]

 33%|███▎      | 5281/16104 [24:23:56<48:23:55, 16.10s/it]

 33%|███▎      | 5282/16104 [24:24:10<46:41:34, 15.53s/it]

 33%|███▎      | 5283/16104 [24:24:26<46:52:12, 15.59s/it]

 33%|███▎      | 5284/16104 [24:24:37<43:16:21, 14.40s/it]

 33%|███▎      | 5285/16104 [24:24:55<46:06:38, 15.34s/it]


 33%|███▎      | 5287/16104 [24:25:30<49:18:50, 16.41s/it]

 33%|███▎      | 5288/16104 [24:25:53<54:30:07, 18.14s/it]
{'loss': 0.3428, 'learning_rate': 1.568421205986183e-06, 'rewards/chosen': -1.3417798280715942, 'rewards/rejected': -2.567769765853882, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2259902954101562, 'policy_logps/rejected': -232.66311645507812, 'policy_logps/chosen': -372.9790344238281, 'referece_logps/rejected': -206.9854278564453, 'referece_logps/chosen': -359.5612487792969, 'logits/rejected': -0.26590055227279663, 'logits/chosen': -0.2349017858505249, 'epoch': 1.97}

 33%|███▎      | 5289/16104 [24:26:08<52:17:04, 17.40s/it]

 33%|███▎      | 5290/16104 [24:26:27<53:40:09, 17.87s/it]

 33%|███▎      | 5291/16104 [24:26:41<50:07:18, 16.69s/it]


 33%|███▎      | 5293/16104 [24:27:15<49:02:06, 16.33s/it]

 33%|███▎      | 5294/16104 [24:27:29<46:57:15, 15.64s/it]
{'loss': 0.4353, 'learning_rate': 1.5674279472457766e-06, 'rewards/chosen': -1.0571722984313965, 'rewards/rejected': -2.217139482498169, 'rewards/accuracies': 0.75, 'rewards/margins': 1.159967303276062, 'policy_logps/rejected': -516.5257568359375, 'policy_logps/chosen': -411.6378479003906, 'referece_logps/rejected': -494.3544006347656, 'referece_logps/chosen': -401.0661315917969, 'logits/rejected': -0.5914815664291382, 'logits/chosen': -0.44114950299263, 'epoch': 1.97}

 33%|███▎      | 5295/16104 [24:27:41<44:20:47, 14.77s/it]

 33%|███▎      | 5296/16104 [24:27:55<43:19:59, 14.43s/it]

 33%|███▎      | 5297/16104 [24:28:16<48:48:35, 16.26s/it]

 33%|███▎      | 5298/16104 [24:28:29<46:41:28, 15.56s/it]

 33%|███▎      | 5299/16104 [24:28:46<47:24:06, 15.79s/it]

 33%|███▎      | 5300/16104 [24:29:02<47:23:44, 15.79s/it]

 33%|███▎      | 5301/16104 [24:29:20<49:50:57, 16.61s/it]

 33%|███▎      | 5302/16104 [24:29:40<52:36:22, 17.53s/it]


 33%|███▎      | 5304/16104 [24:30:19<55:42:27, 18.57s/it]
{'loss': 0.3815, 'learning_rate': 1.5657706804489792e-06, 'rewards/chosen': -2.172539710998535, 'rewards/rejected': -2.7785515785217285, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6060115694999695, 'policy_logps/rejected': -322.49554443359375, 'policy_logps/chosen': -349.61944580078125, 'referece_logps/rejected': -294.71002197265625, 'referece_logps/chosen': -327.8940124511719, 'logits/rejected': -0.652229905128479, 'logits/chosen': -0.6370305418968201, 'epoch': 1.98}

 33%|███▎      | 5305/16104 [24:30:38<55:51:55, 18.62s/it]

 33%|███▎      | 5306/16104 [24:30:57<56:40:25, 18.89s/it]

 33%|███▎      | 5307/16104 [24:31:08<49:38:07, 16.55s/it]


 33%|███▎      | 5309/16104 [24:31:49<54:58:14, 18.33s/it]
{'loss': 0.4369, 'learning_rate': 1.5649411883902475e-06, 'rewards/chosen': -1.8304708003997803, 'rewards/rejected': -2.5667638778686523, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7362931966781616, 'policy_logps/rejected': -442.3531799316406, 'policy_logps/chosen': -296.5740661621094, 'referece_logps/rejected': -416.6855163574219, 'referece_logps/chosen': -278.2693786621094, 'logits/rejected': -0.5171380639076233, 'logits/chosen': -0.5898333787918091, 'epoch': 1.98}

 33%|███▎      | 5310/16104 [24:32:04<52:20:11, 17.46s/it]

 33%|███▎      | 5311/16104 [24:32:19<50:11:03, 16.74s/it]

 33%|███▎      | 5312/16104 [24:32:34<48:22:19, 16.14s/it]

 33%|███▎      | 5313/16104 [24:32:45<43:57:10, 14.66s/it]


 33%|███▎      | 5315/16104 [24:33:11<40:44:05, 13.59s/it]
{'loss': 0.4358, 'learning_rate': 1.5639450438486775e-06, 'rewards/chosen': -1.8392679691314697, 'rewards/rejected': -4.021626949310303, 'rewards/accuracies': 1.0, 'rewards/margins': 2.182359218597412, 'policy_logps/rejected': -511.5135498046875, 'policy_logps/chosen': -495.44573974609375, 'referece_logps/rejected': -471.2972412109375, 'referece_logps/chosen': -477.0531005859375, 'logits/rejected': -0.24350078403949738, 'logits/chosen': -0.04086233675479889, 'epoch': 1.98}

 33%|███▎      | 5316/16104 [24:33:22<38:24:44, 12.82s/it]


 33%|███▎      | 5318/16104 [24:33:55<44:55:58, 15.00s/it]
{'loss': 0.4999, 'learning_rate': 1.5634466635173405e-06, 'rewards/chosen': -1.4322415590286255, 'rewards/rejected': -3.4344019889831543, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0021603107452393, 'policy_logps/rejected': -449.05267333984375, 'policy_logps/chosen': -331.1603698730469, 'referece_logps/rejected': -414.7087097167969, 'referece_logps/chosen': -316.8379821777344, 'logits/rejected': -1.188980221748352, 'logits/chosen': -0.9538273811340332, 'epoch': 1.98}

 33%|███▎      | 5319/16104 [24:34:15<49:01:31, 16.36s/it]

 33%|███▎      | 5320/16104 [24:34:29<47:23:50, 15.82s/it]

 33%|███▎      | 5321/16104 [24:34:50<51:28:39, 17.19s/it]

 33%|███▎      | 5322/16104 [24:35:03<47:40:44, 15.92s/it]

 33%|███▎      | 5323/16104 [24:35:23<51:31:03, 17.20s/it]

 33%|███▎      | 5324/16104 [24:35:41<52:28:39, 17.52s/it]

 33%|███▎      | 5325/16104 [24:35:59<52:47:03, 17.63s/it]

 33%|███▎      | 5326/16104 [24:36:19<54:40:29, 18.26s/it]

 33%|███▎      | 5327/16104 [24:36:37<54:40:44, 18.27s/it]

 33%|███▎      | 5328/16104 [24:36:56<55:30:10, 18.54s/it]

 33%|███▎      | 5329/16104 [24:37:07<48:41:36, 16.27s/it]

 33%|███▎      | 5330/16104 [24:37:18<43:52:15, 14.66s/it]


 33%|███▎      | 5332/16104 [24:37:39<37:50:07, 12.64s/it]
{'loss': 0.5495, 'learning_rate': 1.5611181792737297e-06, 'rewards/chosen': -0.9484406113624573, 'rewards/rejected': -1.0858951807022095, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1374545693397522, 'policy_logps/rejected': -427.8936462402344, 'policy_logps/chosen': -431.9007568359375, 'referece_logps/rejected': -417.0346984863281, 'referece_logps/chosen': -422.41632080078125, 'logits/rejected': -0.006852537393569946, 'logits/chosen': 0.008627921342849731, 'epoch': 1.99}

 33%|███▎      | 5333/16104 [24:38:01<45:32:13, 15.22s/it]

 33%|███▎      | 5334/16104 [24:38:19<48:09:41, 16.10s/it]

 33%|███▎      | 5335/16104 [24:38:38<51:18:33, 17.15s/it]

 33%|███▎      | 5336/16104 [24:39:02<57:27:51, 19.21s/it]

 33%|███▎      | 5337/16104 [24:39:23<58:51:35, 19.68s/it]

 33%|███▎      | 5338/16104 [24:39:38<54:49:09, 18.33s/it]

 33%|███▎      | 5339/16104 [24:39:59<56:36:29, 18.93s/it]

 33%|███▎      | 5340/16104 [24:40:18<56:38:32, 18.94s/it]

 33%|███▎      | 5341/16104 [24:40:37<56:53:19, 19.03s/it]

 33%|███▎      | 5342/16104 [24:40:51<52:24:26, 17.53s/it]

 33%|███▎      | 5343/16104 [24:41:04<48:41:12, 16.29s/it]


 33%|███▎      | 5345/16104 [24:41:32<44:40:01, 14.95s/it]
{'loss': 0.3081, 'learning_rate': 1.5589520314020596e-06, 'rewards/chosen': -1.375628113746643, 'rewards/rejected': -2.863316059112549, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4876878261566162, 'policy_logps/rejected': -322.88671875, 'policy_logps/chosen': -308.6119689941406, 'referece_logps/rejected': -294.2535400390625, 'referece_logps/chosen': -294.855712890625, 'logits/rejected': -1.1755090951919556, 'logits/chosen': -1.0292878150939941, 'epoch': 1.99}

 33%|███▎      | 5346/16104 [24:41:49<46:55:56, 15.71s/it]

 33%|███▎      | 5347/16104 [24:42:01<43:28:40, 14.55s/it]

 33%|███▎      | 5348/16104 [24:42:13<41:23:56, 13.86s/it]

 33%|███▎      | 5349/16104 [24:42:33<46:45:00, 15.65s/it]


 33%|███▎      | 5351/16104 [24:43:04<47:22:06, 15.86s/it]
{'loss': 0.437, 'learning_rate': 1.5579509811445882e-06, 'rewards/chosen': -1.2847591638565063, 'rewards/rejected': -3.1925947666168213, 'rewards/accuracies': 0.875, 'rewards/margins': 1.907835841178894, 'policy_logps/rejected': -373.8994140625, 'policy_logps/chosen': -469.7103271484375, 'referece_logps/rejected': -341.97344970703125, 'referece_logps/chosen': -456.86273193359375, 'logits/rejected': -0.22340425848960876, 'logits/chosen': -0.16844485700130463, 'epoch': 1.99}

 33%|███▎      | 5352/16104 [24:43:17<44:38:15, 14.95s/it]


 33%|███▎      | 5354/16104 [24:43:56<51:40:53, 17.31s/it]
{'loss': 0.407, 'learning_rate': 1.5574501512282066e-06, 'rewards/chosen': -1.8503731489181519, 'rewards/rejected': -2.3664486408233643, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5160754919052124, 'policy_logps/rejected': -392.1628112792969, 'policy_logps/chosen': -583.8088989257812, 'referece_logps/rejected': -368.49835205078125, 'referece_logps/chosen': -565.30517578125, 'logits/rejected': -0.9792038202285767, 'logits/chosen': -1.1055444478988647, 'epoch': 1.99}

 33%|███▎      | 5355/16104 [24:44:07<45:56:45, 15.39s/it]

 33%|███▎      | 5356/16104 [24:44:26<49:41:30, 16.64s/it]

 33%|███▎      | 5357/16104 [24:44:45<51:37:04, 17.29s/it]


 33%|███▎      | 5359/16104 [24:45:26<55:52:26, 18.72s/it]
{'loss': 0.2673, 'learning_rate': 1.5566149837939243e-06, 'rewards/chosen': -1.576633334159851, 'rewards/rejected': -3.50422739982605, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9275940656661987, 'policy_logps/rejected': -289.2080993652344, 'policy_logps/chosen': -315.308837890625, 'referece_logps/rejected': -254.16583251953125, 'referece_logps/chosen': -299.54248046875, 'logits/rejected': -1.052722454071045, 'logits/chosen': -1.1981555223464966, 'epoch': 2.0}

 33%|███▎      | 5360/16104 [24:45:42<53:40:56, 17.99s/it]

 33%|███▎      | 5361/16104 [24:45:54<48:15:18, 16.17s/it]

 33%|███▎      | 5362/16104 [24:46:08<46:41:08, 15.65s/it]


 33%|███▎      | 5364/16104 [24:46:50<54:11:46, 18.17s/it]
{'loss': 0.329, 'learning_rate': 1.555779253457953e-06, 'rewards/chosen': -1.6210005283355713, 'rewards/rejected': -3.875713348388672, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2547128200531006, 'policy_logps/rejected': -536.6959838867188, 'policy_logps/chosen': -386.12017822265625, 'referece_logps/rejected': -497.93890380859375, 'referece_logps/chosen': -369.91021728515625, 'logits/rejected': -0.535225510597229, 'logits/chosen': -0.2119099348783493, 'epoch': 2.0}

 33%|███▎      | 5365/16104 [24:47:10<55:55:07, 18.75s/it]


 33%|███▎      | 5367/16104 [24:47:47<54:55:09, 18.41s/it]

 33%|███▎      | 5368/16104 [24:48:06<55:50:11, 18.72s/it]

 33%|███▎      | 5369/16104 [24:48:20<52:00:18, 17.44s/it]

 33%|███▎      | 5370/16104 [24:48:32<46:35:04, 15.62s/it]

 33%|███▎      | 5371/16104 [24:48:52<50:13:04, 16.84s/it]

 33%|███▎      | 5372/16104 [24:49:10<52:02:37, 17.46s/it]

 33%|███▎      | 5373/16104 [24:49:27<51:11:31, 17.17s/it]

 33%|███▎      | 5374/16104 [24:49:39<46:42:32, 15.67s/it]

 33%|███▎      | 5375/16104 [24:49:51<43:26:35, 14.58s/it]

 33%|███▎      | 5376/16104 [24:50:09<46:37:50, 15.65s/it]

 33%|███▎      | 5377/16104 [24:50:21<43:03:13, 14.45s/it]

 33%|███▎      | 5378/16104 [24:50:35<42:43:48, 14.34s/it]

 33%|███▎      | 5379/16104 [24:50:53<46:06:55, 15.48s/it]

 33%|███▎      | 5380/16104 [24:51:13<49:50:42, 16.73s/it]

 33%|███▎      | 5381/16104 [24:51:34<53:31:03, 17.97s/it]

 33%|███▎      | 5382/16104 [24:51:53<54:23:11, 18.26s/it]

 33%|███▎      | 5383/16104 [24:52:14<57:16:55, 19.23s/it]

 33%|███▎      | 5384/16104 [24:52:27<51:55:57, 17.44s/it]

 33%|███▎      | 5385/16104 [24:52:38<45:58:51, 15.44s/it]

 33%|███▎      | 5386/16104 [24:52:49<42:00:13, 14.11s/it]

 33%|███▎      | 5387/16104 [24:53:04<42:43:03, 14.35s/it]

 33%|███▎      | 5388/16104 [24:53:23<47:13:58, 15.87s/it]

 33%|███▎      | 5389/16104 [24:53:44<51:01:54, 17.15s/it]

 33%|███▎      | 5390/16104 [24:53:55<45:50:41, 15.40s/it]

 33%|███▎      | 5391/16104 [24:54:12<47:40:23, 16.02s/it]
{'loss': 0.3979, 'learning_rate': 1.5512566187536571e-06, 'rewards/chosen': -1.1427572965621948, 'rewards/rejected': -2.364830732345581, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2220736742019653, 'policy_logps/rejected': -301.0755920410156, 'policy_logps/chosen': -320.7430725097656, 'referece_logps/rejected': -277.42730712890625, 'referece_logps/chosen': -309.3155212402344, 'logits/rejected': -0.5734719038009644, 'logits/chosen': -0.29299822449684143, 'epoch': 2.01}


 33%|███▎      | 5393/16104 [24:54:45<49:13:13, 16.54s/it]
{'loss': 0.4107, 'learning_rate': 1.5509209604564833e-06, 'rewards/chosen': -0.7776363492012024, 'rewards/rejected': -2.060777187347412, 'rewards/accuracies': 0.875, 'rewards/margins': 1.283140778541565, 'policy_logps/rejected': -486.2619934082031, 'policy_logps/chosen': -522.52734375, 'referece_logps/rejected': -465.6541748046875, 'referece_logps/chosen': -514.7509765625, 'logits/rejected': 0.12327104806900024, 'logits/chosen': 0.1020137220621109, 'epoch': 2.01}


 34%|███▎      | 5395/16104 [24:55:11<43:31:42, 14.63s/it]

 34%|███▎      | 5396/16104 [24:55:26<44:20:52, 14.91s/it]
{'loss': 0.4842, 'learning_rate': 1.5504173058846804e-06, 'rewards/chosen': -1.270127534866333, 'rewards/rejected': -2.2998478412628174, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0297203063964844, 'policy_logps/rejected': -528.5126953125, 'policy_logps/chosen': -442.68316650390625, 'referece_logps/rejected': -505.51422119140625, 'referece_logps/chosen': -429.98193359375, 'logits/rejected': -0.8087896704673767, 'logits/chosen': -0.8409885168075562, 'epoch': 2.01}

 34%|███▎      | 5397/16104 [24:55:47<48:58:42, 16.47s/it]


 34%|███▎      | 5399/16104 [24:56:21<51:14:45, 17.23s/it]

 34%|███▎      | 5400/16104 [24:56:32<45:22:11, 15.26s/it]

 34%|███▎      | 5401/16104 [24:56:51<49:05:17, 16.51s/it]

 34%|███▎      | 5402/16104 [24:57:08<48:58:49, 16.48s/it]

 34%|███▎      | 5403/16104 [24:57:28<52:02:03, 17.51s/it]
{'loss': 0.5214, 'learning_rate': 1.549241332913211e-06, 'rewards/chosen': -1.2069042921066284, 'rewards/rejected': -2.8255019187927246, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6185975074768066, 'policy_logps/rejected': -413.47967529296875, 'policy_logps/chosen': -377.9990539550781, 'referece_logps/rejected': -385.22467041015625, 'referece_logps/chosen': -365.92999267578125, 'logits/rejected': -0.33896857500076294, 'logits/chosen': -0.04751899838447571, 'epoch': 2.01}


 34%|███▎      | 5405/16104 [24:58:03<51:40:41, 17.39s/it]

 34%|███▎      | 5406/16104 [24:58:18<49:34:27, 16.68s/it]

 34%|███▎      | 5407/16104 [24:58:36<49:57:24, 16.81s/it]

 34%|███▎      | 5408/16104 [24:58:57<54:08:43, 18.22s/it]
{'loss': 0.4338, 'learning_rate': 1.5484006855496512e-06, 'rewards/chosen': -1.3055475950241089, 'rewards/rejected': -2.293149948120117, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9876023530960083, 'policy_logps/rejected': -623.3211669921875, 'policy_logps/chosen': -526.7947998046875, 'referece_logps/rejected': -600.3896484375, 'referece_logps/chosen': -513.7392578125, 'logits/rejected': 0.40242019295692444, 'logits/chosen': 0.5294933319091797, 'epoch': 2.01}


 34%|███▎      | 5410/16104 [24:59:24<46:04:29, 15.51s/it]
{'loss': 0.4674, 'learning_rate': 1.5480642712701084e-06, 'rewards/chosen': -1.760773777961731, 'rewards/rejected': -2.503690719604492, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7429169416427612, 'policy_logps/rejected': -399.4765930175781, 'policy_logps/chosen': -457.436279296875, 'referece_logps/rejected': -374.439697265625, 'referece_logps/chosen': -439.8285217285156, 'logits/rejected': 0.020778179168701172, 'logits/chosen': -0.045725613832473755, 'epoch': 2.02}


 34%|███▎      | 5412/16104 [24:59:46<39:43:44, 13.38s/it]

 34%|███▎      | 5413/16104 [25:00:00<39:47:12, 13.40s/it]

 34%|███▎      | 5414/16104 [25:00:19<45:13:27, 15.23s/it]

 34%|███▎      | 5415/16104 [25:00:40<49:48:52, 16.78s/it]

 34%|███▎      | 5416/16104 [25:00:57<50:10:37, 16.90s/it]
{'loss': 0.3864, 'learning_rate': 1.5470544965650274e-06, 'rewards/chosen': -1.1950314044952393, 'rewards/rejected': -2.6411447525024414, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4461132287979126, 'policy_logps/rejected': -311.4990539550781, 'policy_logps/chosen': -279.10211181640625, 'referece_logps/rejected': -285.087646484375, 'referece_logps/chosen': -267.15179443359375, 'logits/rejected': -0.9017677903175354, 'logits/chosen': -0.807090163230896, 'epoch': 2.02}


 34%|███▎      | 5418/16104 [25:01:26<46:09:24, 15.55s/it]

 34%|███▎      | 5419/16104 [25:01:40<44:44:55, 15.08s/it]

 34%|███▎      | 5420/16104 [25:02:00<48:50:53, 16.46s/it]

 34%|███▎      | 5421/16104 [25:02:12<45:12:16, 15.23s/it]

 34%|███▎      | 5422/16104 [25:02:24<42:20:03, 14.27s/it]

 34%|███▎      | 5423/16104 [25:02:36<40:08:23, 13.53s/it]

 34%|███▎      | 5424/16104 [25:02:58<47:59:02, 16.17s/it]

 34%|███▎      | 5425/16104 [25:03:16<49:34:47, 16.71s/it]

 34%|███▎      | 5426/16104 [25:03:33<49:34:51, 16.72s/it]

 34%|███▎      | 5427/16104 [25:03:45<45:20:04, 15.29s/it]

 34%|███▎      | 5428/16104 [25:04:05<49:28:11, 16.68s/it]
{'loss': 0.4004, 'learning_rate': 1.5450325586591015e-06, 'rewards/chosen': -0.4363533854484558, 'rewards/rejected': -2.0474555492401123, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6111022233963013, 'policy_logps/rejected': -398.4905090332031, 'policy_logps/chosen': -382.6683654785156, 'referece_logps/rejected': -378.0159606933594, 'referece_logps/chosen': -378.30487060546875, 'logits/rejected': -1.2205981016159058, 'logits/chosen': -1.2095063924789429, 'epoch': 2.02}


 34%|███▎      | 5430/16104 [25:04:28<41:22:02, 13.95s/it]

 34%|███▎      | 5431/16104 [25:04:38<38:27:33, 12.97s/it]

 34%|███▎      | 5432/16104 [25:04:54<40:57:08, 13.81s/it]

 34%|███▎      | 5433/16104 [25:05:12<44:54:11, 15.15s/it]

 34%|███▎      | 5434/16104 [25:05:32<48:56:06, 16.51s/it]

 34%|███▎      | 5435/16104 [25:05:44<45:02:29, 15.20s/it]

 34%|███▍      | 5436/16104 [25:06:01<46:13:19, 15.60s/it]

 34%|███▍      | 5437/16104 [25:06:18<47:38:33, 16.08s/it]

 34%|███▍      | 5438/16104 [25:06:33<46:36:08, 15.73s/it]

 34%|███▍      | 5439/16104 [25:06:51<48:43:46, 16.45s/it]

 34%|███▍      | 5440/16104 [25:07:04<45:39:25, 15.41s/it]

 34%|███▍      | 5441/16104 [25:07:19<44:52:08, 15.15s/it]

 34%|███▍      | 5442/16104 [25:07:35<46:00:46, 15.54s/it]

 34%|███▍      | 5443/16104 [25:07:46<41:52:29, 14.14s/it]

 34%|███▍      | 5444/16104 [25:08:03<44:45:18, 15.11s/it]

 34%|███▍      | 5445/16104 [25:08:25<50:26:15, 17.03s/it]
{'loss': 0.3696, 'learning_rate': 1.542162714713776e-06, 'rewards/chosen': -2.3945205211639404, 'rewards/rejected': -3.7380104064941406, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3434901237487793, 'policy_logps/rejected': -374.5084533691406, 'policy_logps/chosen': -346.7071228027344, 'referece_logps/rejected': -337.12835693359375, 'referece_logps/chosen': -322.761962890625, 'logits/rejected': -0.871052622795105, 'logits/chosen': -0.9733600616455078, 'epoch': 2.03}


 34%|███▍      | 5447/16104 [25:09:01<51:38:07, 17.44s/it]

 34%|███▍      | 5448/16104 [25:09:21<53:46:30, 18.17s/it]

 34%|███▍      | 5449/16104 [25:09:41<55:30:22, 18.75s/it]

 34%|███▍      | 5450/16104 [25:09:56<52:31:12, 17.75s/it]

 34%|███▍      | 5451/16104 [25:10:17<55:32:19, 18.77s/it]

 34%|███▍      | 5452/16104 [25:10:32<52:12:46, 17.65s/it]

 34%|███▍      | 5453/16104 [25:10:43<46:05:41, 15.58s/it]
{'loss': 0.2359, 'learning_rate': 1.5408100047217257e-06, 'rewards/chosen': -1.5257534980773926, 'rewards/rejected': -4.276113033294678, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7503597736358643, 'policy_logps/rejected': -306.4256896972656, 'policy_logps/chosen': -382.4625244140625, 'referece_logps/rejected': -263.6645812988281, 'referece_logps/chosen': -367.2049865722656, 'logits/rejected': 0.1610971987247467, 'logits/chosen': 0.35387706756591797, 'epoch': 2.03}


 34%|███▍      | 5455/16104 [25:11:21<52:01:18, 17.59s/it]
{'loss': 0.4086, 'learning_rate': 1.5404716083195837e-06, 'rewards/chosen': -1.3301533460617065, 'rewards/rejected': -3.076124429702759, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7459712028503418, 'policy_logps/rejected': -402.7314453125, 'policy_logps/chosen': -375.9530334472656, 'referece_logps/rejected': -371.97021484375, 'referece_logps/chosen': -362.6515197753906, 'logits/rejected': -0.12073558568954468, 'logits/chosen': -0.22876273095607758, 'epoch': 2.03}


 34%|███▍      | 5457/16104 [25:11:50<47:47:38, 16.16s/it]

 34%|███▍      | 5458/16104 [25:12:09<49:51:30, 16.86s/it]

 34%|███▍      | 5459/16104 [25:12:26<50:37:40, 17.12s/it]

 34%|███▍      | 5460/16104 [25:12:45<51:50:38, 17.53s/it]

 34%|███▍      | 5461/16104 [25:13:05<54:10:51, 18.33s/it]

 34%|███▍      | 5462/16104 [25:13:21<52:19:54, 17.70s/it]

 34%|███▍      | 5463/16104 [25:13:37<50:34:23, 17.11s/it]
{'loss': 0.4068, 'learning_rate': 1.5391171487371441e-06, 'rewards/chosen': -1.2961965799331665, 'rewards/rejected': -3.0001320838928223, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7039355039596558, 'policy_logps/rejected': -452.9476013183594, 'policy_logps/chosen': -469.0191650390625, 'referece_logps/rejected': -422.9462890625, 'referece_logps/chosen': -456.05718994140625, 'logits/rejected': -1.2231189012527466, 'logits/chosen': -1.3230371475219727, 'epoch': 2.04}


 34%|███▍      | 5465/16104 [25:14:06<46:38:59, 15.79s/it]
{'loss': 0.4942, 'learning_rate': 1.5387783156220184e-06, 'rewards/chosen': -1.7526978254318237, 'rewards/rejected': -3.1099541187286377, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3572561740875244, 'policy_logps/rejected': -297.20654296875, 'policy_logps/chosen': -362.84356689453125, 'referece_logps/rejected': -266.10699462890625, 'referece_logps/chosen': -345.3166198730469, 'logits/rejected': -0.36750972270965576, 'logits/chosen': -0.1979256272315979, 'epoch': 2.04}


 34%|███▍      | 5467/16104 [25:14:46<53:22:37, 18.07s/it]

 34%|███▍      | 5468/16104 [25:15:08<56:53:40, 19.26s/it]

 34%|███▍      | 5469/16104 [25:15:25<54:24:42, 18.42s/it]

 34%|███▍      | 5470/16104 [25:15:48<58:10:11, 19.69s/it]

 34%|███▍      | 5471/16104 [25:16:08<59:04:35, 20.00s/it]

 34%|███▍      | 5472/16104 [25:16:25<56:23:37, 19.09s/it]

 34%|███▍      | 5473/16104 [25:16:47<58:37:10, 19.85s/it]

 34%|███▍      | 5474/16104 [25:17:07<58:29:17, 19.81s/it]

 34%|███▍      | 5475/16104 [25:17:19<51:40:08, 17.50s/it]

 34%|███▍      | 5476/16104 [25:17:36<51:03:24, 17.29s/it]

 34%|███▍      | 5477/16104 [25:17:51<49:10:45, 16.66s/it]

 34%|███▍      | 5478/16104 [25:18:09<50:14:42, 17.02s/it]

 34%|███▍      | 5479/16104 [25:18:29<52:48:17, 17.89s/it]

 34%|███▍      | 5480/16104 [25:18:49<55:29:36, 18.80s/it]

 34%|███▍      | 5481/16104 [25:19:08<55:14:18, 18.72s/it]

 34%|███▍      | 5482/16104 [25:19:28<56:08:43, 19.03s/it]

 34%|███▍      | 5483/16104 [25:19:45<54:32:55, 18.49s/it]

 34%|███▍      | 5484/16104 [25:19:57<48:36:37, 16.48s/it]
{'loss': 0.4393, 'learning_rate': 1.5355550607700472e-06, 'rewards/chosen': -1.1663402318954468, 'rewards/rejected': -2.682840585708618, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5165002346038818, 'policy_logps/rejected': -375.0891418457031, 'policy_logps/chosen': -456.81622314453125, 'referece_logps/rejected': -348.2607727050781, 'referece_logps/chosen': -445.1528625488281, 'logits/rejected': 0.3490179479122162, 'logits/chosen': 0.24246299266815186, 'epoch': 2.04}

 34%|███▍      | 5485/16104 [25:20:18<53:01:39, 17.98s/it]


 34%|███▍      | 5487/16104 [25:20:51<49:52:05, 16.91s/it]
{'loss': 0.4274, 'learning_rate': 1.535045409667704e-06, 'rewards/chosen': -1.2688138484954834, 'rewards/rejected': -2.88814640045166, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6193325519561768, 'policy_logps/rejected': -367.87249755859375, 'policy_logps/chosen': -499.3341369628906, 'referece_logps/rejected': -338.99102783203125, 'referece_logps/chosen': -486.64599609375, 'logits/rejected': -0.34144172072410583, 'logits/chosen': -0.3507917523384094, 'epoch': 2.04}


 34%|███▍      | 5489/16104 [25:21:29<52:48:40, 17.91s/it]

 34%|███▍      | 5490/16104 [25:21:51<56:39:56, 19.22s/it]
{'loss': 0.4881, 'learning_rate': 1.5345355637734917e-06, 'rewards/chosen': -1.0190035104751587, 'rewards/rejected': -3.3869543075561523, 'rewards/accuracies': 0.75, 'rewards/margins': 2.367950916290283, 'policy_logps/rejected': -382.5248718261719, 'policy_logps/chosen': -487.7536926269531, 'referece_logps/rejected': -348.6553649902344, 'referece_logps/chosen': -477.563720703125, 'logits/rejected': 0.8038021922111511, 'logits/chosen': 0.849897563457489, 'epoch': 2.05}

 34%|███▍      | 5491/16104 [25:22:09<55:10:14, 18.71s/it]


 34%|███▍      | 5493/16104 [25:22:44<52:59:12, 17.98s/it]
{'loss': 0.3359, 'learning_rate': 1.5340255232730277e-06, 'rewards/chosen': -1.1762628555297852, 'rewards/rejected': -2.195528745651245, 'rewards/accuracies': 0.625, 'rewards/margins': 1.01926589012146, 'policy_logps/rejected': -216.53131103515625, 'policy_logps/chosen': -283.2009582519531, 'referece_logps/rejected': -194.57601928710938, 'referece_logps/chosen': -271.4383544921875, 'logits/rejected': -0.32300159335136414, 'logits/chosen': -0.254550039768219, 'epoch': 2.05}


 34%|███▍      | 5495/16104 [25:23:26<57:59:13, 19.68s/it]

 34%|███▍      | 5496/16104 [25:23:46<58:04:00, 19.71s/it]
{'loss': 0.2794, 'learning_rate': 1.5335152883520006e-06, 'rewards/chosen': -1.3903799057006836, 'rewards/rejected': -3.348789691925049, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9584097862243652, 'policy_logps/rejected': -426.1914367675781, 'policy_logps/chosen': -354.9776611328125, 'referece_logps/rejected': -392.7035217285156, 'referece_logps/chosen': -341.0738525390625, 'logits/rejected': -0.6961759924888611, 'logits/chosen': -0.41864079236984253, 'epoch': 2.05}


 34%|███▍      | 5498/16104 [25:24:26<58:32:03, 19.87s/it]
{'loss': 0.2716, 'learning_rate': 1.5331750238182886e-06, 'rewards/chosen': -0.6696937084197998, 'rewards/rejected': -3.639993667602539, 'rewards/accuracies': 0.875, 'rewards/margins': 2.9703001976013184, 'policy_logps/rejected': -452.33258056640625, 'policy_logps/chosen': -605.968505859375, 'referece_logps/rejected': -415.9326477050781, 'referece_logps/chosen': -599.2716064453125, 'logits/rejected': -0.514125645160675, 'logits/chosen': -0.6116750240325928, 'epoch': 2.05}

 34%|███▍      | 5499/16104 [25:24:45<57:40:20, 19.58s/it]


 34%|███▍      | 5501/16104 [25:25:40<72:18:26, 24.55s/it]

 34%|███▍      | 5502/16104 [25:25:56<64:40:19, 21.96s/it]
{'loss': 0.3581, 'learning_rate': 1.5324942359913647e-06, 'rewards/chosen': -1.6647061109542847, 'rewards/rejected': -3.256507396697998, 'rewards/accuracies': 1.0, 'rewards/margins': 1.591801404953003, 'policy_logps/rejected': -317.8138427734375, 'policy_logps/chosen': -376.58929443359375, 'referece_logps/rejected': -285.248779296875, 'referece_logps/chosen': -359.94219970703125, 'logits/rejected': -0.10477090626955032, 'logits/chosen': 0.06155075132846832, 'epoch': 2.05}

 34%|███▍      | 5503/16104 [25:26:19<64:53:49, 22.04s/it]


 34%|███▍      | 5505/16104 [25:26:50<55:07:51, 18.73s/it]

 34%|███▍      | 5506/16104 [25:27:02<48:19:52, 16.42s/it]
{'loss': 0.5546, 'learning_rate': 1.5318131035189848e-06, 'rewards/chosen': -1.3077160120010376, 'rewards/rejected': -2.5612969398498535, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2535808086395264, 'policy_logps/rejected': -343.78814697265625, 'policy_logps/chosen': -441.2159423828125, 'referece_logps/rejected': -318.1751708984375, 'referece_logps/chosen': -428.1387939453125, 'logits/rejected': -0.6554901599884033, 'logits/chosen': -0.6626649498939514, 'epoch': 2.05}

 34%|███▍      | 5507/16104 [25:27:17<47:08:08, 16.01s/it]


 34%|███▍      | 5509/16104 [25:27:48<45:12:20, 15.36s/it]
{'loss': 0.3704, 'learning_rate': 1.531302028256309e-06, 'rewards/chosen': -1.8786712884902954, 'rewards/rejected': -2.601999521255493, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7233286499977112, 'policy_logps/rejected': -420.4164123535156, 'policy_logps/chosen': -287.2119445800781, 'referece_logps/rejected': -394.39642333984375, 'referece_logps/chosen': -268.4252624511719, 'logits/rejected': -1.0459065437316895, 'logits/chosen': -0.8591825366020203, 'epoch': 2.05}


 34%|███▍      | 5511/16104 [25:28:10<38:26:57, 13.07s/it]

 34%|███▍      | 5512/16104 [25:28:21<36:36:47, 12.44s/it]

 34%|███▍      | 5513/16104 [25:28:36<39:07:15, 13.30s/it]

 34%|███▍      | 5514/16104 [25:28:48<38:24:03, 13.05s/it]

 34%|███▍      | 5515/16104 [25:29:08<44:00:23, 14.96s/it]
{'loss': 0.507, 'learning_rate': 1.5302792976299993e-06, 'rewards/chosen': -1.1603676080703735, 'rewards/rejected': -2.566159248352051, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4057917594909668, 'policy_logps/rejected': -407.7138977050781, 'policy_logps/chosen': -348.52716064453125, 'referece_logps/rejected': -382.0523681640625, 'referece_logps/chosen': -336.92352294921875, 'logits/rejected': -0.21532794833183289, 'logits/chosen': -0.20293545722961426, 'epoch': 2.05}


 34%|███▍      | 5517/16104 [25:29:42<46:51:46, 15.94s/it]
{'loss': 0.3608, 'learning_rate': 1.5299382157417177e-06, 'rewards/chosen': -2.5779576301574707, 'rewards/rejected': -4.439812660217285, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8618550300598145, 'policy_logps/rejected': -366.74530029296875, 'policy_logps/chosen': -544.5065307617188, 'referece_logps/rejected': -322.3471374511719, 'referece_logps/chosen': -518.7269287109375, 'logits/rejected': 0.05423398315906525, 'logits/chosen': -0.0550694540143013, 'epoch': 2.06}

 34%|███▍      | 5518/16104 [25:29:57<45:45:21, 15.56s/it]

 34%|███▍      | 5519/16104 [25:30:13<46:18:54, 15.75s/it]

 34%|███▍      | 5520/16104 [25:30:25<42:57:49, 14.61s/it]

 34%|███▍      | 5521/16104 [25:30:45<47:32:47, 16.17s/it]


 34%|███▍      | 5523/16104 [25:31:20<48:33:01, 16.52s/it]

 34%|███▍      | 5524/16104 [25:31:32<44:17:41, 15.07s/it]
{'loss': 0.3756, 'learning_rate': 1.5287437542312296e-06, 'rewards/chosen': -1.4436092376708984, 'rewards/rejected': -3.6124486923217773, 'rewards/accuracies': 0.875, 'rewards/margins': 2.168839693069458, 'policy_logps/rejected': -551.3043212890625, 'policy_logps/chosen': -510.07110595703125, 'referece_logps/rejected': -515.1798095703125, 'referece_logps/chosen': -495.6350402832031, 'logits/rejected': -1.5350316762924194, 'logits/chosen': -1.6015440225601196, 'epoch': 2.06}

 34%|███▍      | 5525/16104 [25:31:43<41:04:07, 13.98s/it]

 34%|███▍      | 5526/16104 [25:32:03<45:55:46, 15.63s/it]


 34%|███▍      | 5528/16104 [25:32:45<53:46:13, 18.30s/it]

 34%|███▍      | 5529/16104 [25:33:02<53:05:29, 18.07s/it]

 34%|███▍      | 5530/16104 [25:33:20<52:53:04, 18.00s/it]

 34%|███▍      | 5531/16104 [25:33:40<54:49:43, 18.67s/it]

 34%|███▍      | 5532/16104 [25:34:02<57:36:41, 19.62s/it]
{'loss': 0.5197, 'learning_rate': 1.5273773721827512e-06, 'rewards/chosen': -1.8142179250717163, 'rewards/rejected': -2.968886613845825, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1546688079833984, 'policy_logps/rejected': -309.42315673828125, 'policy_logps/chosen': -308.2193298339844, 'referece_logps/rejected': -279.7342834472656, 'referece_logps/chosen': -290.0771484375, 'logits/rejected': 0.28511470556259155, 'logits/chosen': 0.15399864315986633, 'epoch': 2.06}


 34%|███▍      | 5534/16104 [25:34:29<47:40:41, 16.24s/it]
{'loss': 0.492, 'learning_rate': 1.5270355631988597e-06, 'rewards/chosen': -1.2296292781829834, 'rewards/rejected': -1.6151492595672607, 'rewards/accuracies': 0.875, 'rewards/margins': 0.38551998138427734, 'policy_logps/rejected': -405.5382080078125, 'policy_logps/chosen': -407.70074462890625, 'referece_logps/rejected': -389.3866882324219, 'referece_logps/chosen': -395.4044189453125, 'logits/rejected': -0.5604748129844666, 'logits/chosen': -0.609936535358429, 'epoch': 2.06}


 34%|███▍      | 5536/16104 [25:34:54<42:05:01, 14.34s/it]
{'loss': 0.6075, 'learning_rate': 1.5266936689368526e-06, 'rewards/chosen': -1.6698448657989502, 'rewards/rejected': -1.585080862045288, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0847640186548233, 'policy_logps/rejected': -305.19219970703125, 'policy_logps/chosen': -305.60052490234375, 'referece_logps/rejected': -289.3414001464844, 'referece_logps/chosen': -288.9020690917969, 'logits/rejected': -0.441220223903656, 'logits/chosen': -0.4332689344882965, 'epoch': 2.06}

 34%|███▍      | 5537/16104 [25:35:08<41:00:29, 13.97s/it]

 34%|███▍      | 5538/16104 [25:35:26<44:35:15, 15.19s/it]


 34%|███▍      | 5540/16104 [25:36:00<47:21:15, 16.14s/it]
{'loss': 0.427, 'learning_rate': 1.5260096247997908e-06, 'rewards/chosen': -0.9328541159629822, 'rewards/rejected': -3.349510908126831, 'rewards/accuracies': 0.75, 'rewards/margins': 2.416656732559204, 'policy_logps/rejected': -497.1820373535156, 'policy_logps/chosen': -346.0574951171875, 'referece_logps/rejected': -463.6868591308594, 'referece_logps/chosen': -336.72894287109375, 'logits/rejected': -0.2894362807273865, 'logits/chosen': -0.2577696144580841, 'epoch': 2.06}

 34%|███▍      | 5541/16104 [25:36:15<46:34:35, 15.87s/it]

 34%|███▍      | 5542/16104 [25:36:28<43:43:00, 14.90s/it]

 34%|███▍      | 5543/16104 [25:36:40<40:56:01, 13.95s/it]


 34%|███▍      | 5545/16104 [25:37:06<39:23:40, 13.43s/it]
{'loss': 0.4326, 'learning_rate': 1.5251540909247621e-06, 'rewards/chosen': -0.9489856958389282, 'rewards/rejected': -1.5442959070205688, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5953103303909302, 'policy_logps/rejected': -348.5764465332031, 'policy_logps/chosen': -412.5965881347656, 'referece_logps/rejected': -333.1335144042969, 'referece_logps/chosen': -403.106689453125, 'logits/rejected': -0.09582126885652542, 'logits/chosen': 0.011781617999076843, 'epoch': 2.07}


 34%|███▍      | 5547/16104 [25:37:33<39:42:53, 13.54s/it]

 34%|███▍      | 5548/16104 [25:37:47<39:46:59, 13.57s/it]
{'loss': 0.4385, 'learning_rate': 1.5246405156233295e-06, 'rewards/chosen': -0.8733385801315308, 'rewards/rejected': -2.856508255004883, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9831697940826416, 'policy_logps/rejected': -419.85003662109375, 'policy_logps/chosen': -401.0804443359375, 'referece_logps/rejected': -391.28497314453125, 'referece_logps/chosen': -392.3470458984375, 'logits/rejected': -1.007356882095337, 'logits/chosen': -0.8796244859695435, 'epoch': 2.07}

 34%|███▍      | 5549/16104 [25:38:01<40:40:58, 13.88s/it]

 34%|███▍      | 5550/16104 [25:38:19<44:24:07, 15.15s/it]

 34%|███▍      | 5551/16104 [25:38:39<48:37:41, 16.59s/it]

 34%|███▍      | 5552/16104 [25:38:58<50:11:08, 17.12s/it]


 34%|███▍      | 5554/16104 [25:39:39<55:26:37, 18.92s/it]

 34%|███▍      | 5555/16104 [25:39:59<56:22:09, 19.24s/it]
{'loss': 0.4333, 'learning_rate': 1.523441430784059e-06, 'rewards/chosen': -1.2523595094680786, 'rewards/rejected': -1.9054149389266968, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6530555486679077, 'policy_logps/rejected': -417.2334899902344, 'policy_logps/chosen': -417.9542236328125, 'referece_logps/rejected': -398.1792907714844, 'referece_logps/chosen': -405.4306640625, 'logits/rejected': -1.0308494567871094, 'logits/chosen': -0.899437665939331, 'epoch': 2.07}

 35%|███▍      | 5556/16104 [25:40:20<58:13:15, 19.87s/it]


 35%|███▍      | 5558/16104 [25:40:49<51:07:23, 17.45s/it]
{'loss': 0.374, 'learning_rate': 1.5229272195308078e-06, 'rewards/chosen': -2.0187079906463623, 'rewards/rejected': -3.741816520690918, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7231085300445557, 'policy_logps/rejected': -359.02978515625, 'policy_logps/chosen': -329.4219055175781, 'referece_logps/rejected': -321.61163330078125, 'referece_logps/chosen': -309.2348327636719, 'logits/rejected': -0.4277159869670868, 'logits/chosen': -0.2897137999534607, 'epoch': 2.07}

 35%|███▍      | 5559/16104 [25:41:06<50:13:12, 17.14s/it]

 35%|███▍      | 5560/16104 [25:41:26<52:51:32, 18.05s/it]

 35%|███▍      | 5561/16104 [25:41:44<52:44:14, 18.01s/it]


 35%|███▍      | 5563/16104 [25:42:23<55:26:22, 18.93s/it]
{'loss': 0.3212, 'learning_rate': 1.522069777801096e-06, 'rewards/chosen': -1.5417542457580566, 'rewards/rejected': -3.1948459148406982, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6530920267105103, 'policy_logps/rejected': -220.810302734375, 'policy_logps/chosen': -387.1375732421875, 'referece_logps/rejected': -188.86184692382812, 'referece_logps/chosen': -371.7200927734375, 'logits/rejected': -1.4866262674331665, 'logits/chosen': -1.5332151651382446, 'epoch': 2.07}


 35%|███▍      | 5565/16104 [25:43:03<56:58:07, 19.46s/it]
{'loss': 0.3615, 'learning_rate': 1.5217266532300675e-06, 'rewards/chosen': -1.7592239379882812, 'rewards/rejected': -3.8078980445861816, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0486741065979004, 'policy_logps/rejected': -536.2645874023438, 'policy_logps/chosen': -633.8712158203125, 'referece_logps/rejected': -498.1855773925781, 'referece_logps/chosen': -616.2789306640625, 'logits/rejected': -0.4639958441257477, 'logits/chosen': -0.6670777201652527, 'epoch': 2.07}


 35%|███▍      | 5567/16104 [25:43:39<53:57:51, 18.44s/it]
{'loss': 0.3641, 'learning_rate': 1.521383444239943e-06, 'rewards/chosen': -1.0142441987991333, 'rewards/rejected': -2.131948947906494, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1177048683166504, 'policy_logps/rejected': -293.63311767578125, 'policy_logps/chosen': -276.0209655761719, 'referece_logps/rejected': -272.31365966796875, 'referece_logps/chosen': -265.87847900390625, 'logits/rejected': -0.6019826531410217, 'logits/chosen': -0.5922738313674927, 'epoch': 2.07}


 35%|███▍      | 5569/16104 [25:44:15<53:18:18, 18.22s/it]

 35%|███▍      | 5570/16104 [25:44:31<50:48:12, 17.36s/it]

 35%|███▍      | 5571/16104 [25:44:52<53:57:23, 18.44s/it]

 35%|███▍      | 5572/16104 [25:45:04<48:18:54, 16.51s/it]
{'loss': 0.2794, 'learning_rate': 1.5205250527955618e-06, 'rewards/chosen': -1.7679930925369263, 'rewards/rejected': -3.95920467376709, 'rewards/accuracies': 0.875, 'rewards/margins': 2.191211700439453, 'policy_logps/rejected': -317.60223388671875, 'policy_logps/chosen': -314.4464416503906, 'referece_logps/rejected': -278.01019287109375, 'referece_logps/chosen': -296.76654052734375, 'logits/rejected': -0.4759010076522827, 'logits/chosen': -0.34502875804901123, 'epoch': 2.08}

 35%|███▍      | 5573/16104 [25:45:20<48:37:44, 16.62s/it]


 35%|███▍      | 5575/16104 [25:45:55<48:56:34, 16.73s/it]

 35%|███▍      | 5576/16104 [25:46:09<46:13:53, 15.81s/it]
{'loss': 0.3428, 'learning_rate': 1.5198379605873903e-06, 'rewards/chosen': -1.3067229986190796, 'rewards/rejected': -3.102185010910034, 'rewards/accuracies': 0.875, 'rewards/margins': 1.795461893081665, 'policy_logps/rejected': -433.1163024902344, 'policy_logps/chosen': -398.4427490234375, 'referece_logps/rejected': -402.094482421875, 'referece_logps/chosen': -385.37554931640625, 'logits/rejected': -0.4586215019226074, 'logits/chosen': -0.5225445628166199, 'epoch': 2.08}

 35%|███▍      | 5577/16104 [25:46:30<51:20:02, 17.56s/it]


 35%|███▍      | 5579/16104 [25:47:06<50:59:41, 17.44s/it]

 35%|███▍      | 5580/16104 [25:47:25<52:50:27, 18.08s/it]
{'loss': 0.3371, 'learning_rate': 1.5191505319252653e-06, 'rewards/chosen': -0.6782273054122925, 'rewards/rejected': -3.139211893081665, 'rewards/accuracies': 0.875, 'rewards/margins': 2.460984706878662, 'policy_logps/rejected': -313.75286865234375, 'policy_logps/chosen': -425.67877197265625, 'referece_logps/rejected': -282.36077880859375, 'referece_logps/chosen': -418.8965148925781, 'logits/rejected': -0.590101957321167, 'logits/chosen': -0.4850911498069763, 'epoch': 2.08}

 35%|███▍      | 5581/16104 [25:47:41<50:20:02, 17.22s/it]


 35%|███▍      | 5583/16104 [25:48:12<46:38:06, 15.96s/it]
{'loss': 0.4368, 'learning_rate': 1.5186347398984062e-06, 'rewards/chosen': -1.8838136196136475, 'rewards/rejected': -2.8291103839874268, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9452967047691345, 'policy_logps/rejected': -310.698486328125, 'policy_logps/chosen': -298.2478332519531, 'referece_logps/rejected': -282.4073486328125, 'referece_logps/chosen': -279.4096984863281, 'logits/rejected': -0.945782482624054, 'logits/chosen': -1.1822823286056519, 'epoch': 2.08}


 35%|███▍      | 5585/16104 [25:48:41<45:10:11, 15.46s/it]

 35%|███▍      | 5586/16104 [25:48:59<47:45:20, 16.35s/it]

 35%|███▍      | 5587/16104 [25:49:17<49:09:35, 16.83s/it]
{'loss': 0.4005, 'learning_rate': 1.517946723512591e-06, 'rewards/chosen': -1.4592738151550293, 'rewards/rejected': -3.3844687938690186, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9251947402954102, 'policy_logps/rejected': -418.1481628417969, 'policy_logps/chosen': -357.84332275390625, 'referece_logps/rejected': -384.303466796875, 'referece_logps/chosen': -343.25054931640625, 'logits/rejected': -0.15608623623847961, 'logits/chosen': -0.19378989934921265, 'epoch': 2.08}

 35%|███▍      | 5588/16104 [25:49:34<49:10:58, 16.84s/it]


 35%|███▍      | 5590/16104 [25:50:01<44:36:22, 15.27s/it]
{'loss': 0.4831, 'learning_rate': 1.5174304912042527e-06, 'rewards/chosen': -1.8099720478057861, 'rewards/rejected': -3.034843921661377, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2248718738555908, 'policy_logps/rejected': -263.203125, 'policy_logps/chosen': -345.8051452636719, 'referece_logps/rejected': -232.85470581054688, 'referece_logps/chosen': -327.7054443359375, 'logits/rejected': -1.2698907852172852, 'logits/chosen': -1.4576650857925415, 'epoch': 2.08}


 35%|███▍      | 5592/16104 [25:50:26<40:20:13, 13.81s/it]
{'loss': 0.3537, 'learning_rate': 1.5170862316654926e-06, 'rewards/chosen': -1.4637460708618164, 'rewards/rejected': -3.2899978160858154, 'rewards/accuracies': 0.625, 'rewards/margins': 1.82625150680542, 'policy_logps/rejected': -563.0745239257812, 'policy_logps/chosen': -564.2581176757812, 'referece_logps/rejected': -530.174560546875, 'referece_logps/chosen': -549.6207275390625, 'logits/rejected': -0.23723334074020386, 'logits/chosen': -0.2559857666492462, 'epoch': 2.08}


 35%|███▍      | 5594/16104 [25:50:59<45:12:03, 15.48s/it]

 35%|███▍      | 5595/16104 [25:51:15<45:51:37, 15.71s/it]
{'loss': 0.3771, 'learning_rate': 1.5165696854968086e-06, 'rewards/chosen': -0.9567946195602417, 'rewards/rejected': -2.3756303787231445, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4188356399536133, 'policy_logps/rejected': -390.9281921386719, 'policy_logps/chosen': -255.4709014892578, 'referece_logps/rejected': -367.1719055175781, 'referece_logps/chosen': -245.9029541015625, 'logits/rejected': -1.0808517932891846, 'logits/chosen': -0.960424542427063, 'epoch': 2.08}


 35%|███▍      | 5597/16104 [25:51:48<46:17:37, 15.86s/it]

 35%|███▍      | 5598/16104 [25:52:00<42:50:50, 14.68s/it]

 35%|███▍      | 5599/16104 [25:52:22<49:30:48, 16.97s/it]
{'loss': 0.5382, 'learning_rate': 1.5158806647581e-06, 'rewards/chosen': -1.2072614431381226, 'rewards/rejected': -2.1699376106262207, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9626762866973877, 'policy_logps/rejected': -491.1712646484375, 'policy_logps/chosen': -359.5960388183594, 'referece_logps/rejected': -469.47186279296875, 'referece_logps/chosen': -347.5234375, 'logits/rejected': -0.65038001537323, 'logits/chosen': -0.6688598394393921, 'epoch': 2.09}

 35%|███▍      | 5600/16104 [25:52:35<45:53:53, 15.73s/it]

 35%|███▍      | 5601/16104 [25:52:55<49:28:18, 16.96s/it]

 35%|███▍      | 5602/16104 [25:53:13<50:56:46, 17.46s/it]



 35%|███▍      | 5605/16104 [25:54:06<51:22:17, 17.61s/it]
{'loss': 0.3984, 'learning_rate': 1.5150189193504154e-06, 'rewards/chosen': -1.9975340366363525, 'rewards/rejected': -3.171536684036255, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1740024089813232, 'policy_logps/rejected': -297.22369384765625, 'policy_logps/chosen': -315.29461669921875, 'referece_logps/rejected': -265.5083312988281, 'referece_logps/chosen': -295.31927490234375, 'logits/rejected': -0.29456841945648193, 'logits/chosen': -0.24669088423252106, 'epoch': 2.09}

 35%|███▍      | 5606/16104 [25:54:26<53:21:19, 18.30s/it]

 35%|███▍      | 5607/16104 [25:54:38<47:54:40, 16.43s/it]
{'loss': 0.4505, 'learning_rate': 1.5145016220488162e-06, 'rewards/chosen': -1.193860411643982, 'rewards/rejected': -3.5352048873901367, 'rewards/accuracies': 0.75, 'rewards/margins': 2.341344118118286, 'policy_logps/rejected': -410.1289367675781, 'policy_logps/chosen': -402.6746520996094, 'referece_logps/rejected': -374.77691650390625, 'referece_logps/chosen': -390.73602294921875, 'logits/rejected': -0.7102758884429932, 'logits/chosen': -0.5848776698112488, 'epoch': 2.09}

 35%|███▍      | 5608/16104 [25:54:57<49:49:51, 17.09s/it]

 35%|███▍      | 5609/16104 [25:55:09<45:50:10, 15.72s/it]


 35%|███▍      | 5611/16104 [25:55:44<49:30:11, 16.98s/it]

 35%|███▍      | 5612/16104 [25:56:00<48:31:46, 16.65s/it]

 35%|███▍      | 5613/16104 [25:56:18<49:59:42, 17.16s/it]

 35%|███▍      | 5614/16104 [25:56:36<50:45:22, 17.42s/it]

 35%|███▍      | 5615/16104 [25:56:58<54:26:26, 18.68s/it]
{'loss': 0.3503, 'learning_rate': 1.5131212473392567e-06, 'rewards/chosen': -1.0899933576583862, 'rewards/rejected': -2.3802530765533447, 'rewards/accuracies': 0.75, 'rewards/margins': 1.290259838104248, 'policy_logps/rejected': -242.94900512695312, 'policy_logps/chosen': -353.73822021484375, 'referece_logps/rejected': -219.146484375, 'referece_logps/chosen': -342.8382873535156, 'logits/rejected': 0.05466526001691818, 'logits/chosen': -0.014681339263916016, 'epoch': 2.09}


 35%|███▍      | 5617/16104 [25:57:28<48:02:31, 16.49s/it]
{'loss': 0.4631, 'learning_rate': 1.5127759459555373e-06, 'rewards/chosen': -1.044323444366455, 'rewards/rejected': -1.8419489860534668, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7976256012916565, 'policy_logps/rejected': -457.7904968261719, 'policy_logps/chosen': -423.70379638671875, 'referece_logps/rejected': -439.3710021972656, 'referece_logps/chosen': -413.26055908203125, 'logits/rejected': -0.48313599824905396, 'logits/chosen': -0.4577779471874237, 'epoch': 2.09}

 35%|███▍      | 5618/16104 [25:57:44<47:13:33, 16.21s/it]


 35%|███▍      | 5620/16104 [25:58:23<51:37:01, 17.72s/it]

 35%|███▍      | 5621/16104 [25:58:42<53:15:02, 18.29s/it]
{'loss': 0.3922, 'learning_rate': 1.5120850943315626e-06, 'rewards/chosen': -0.9207596182823181, 'rewards/rejected': -2.5969419479370117, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6761822700500488, 'policy_logps/rejected': -346.5407409667969, 'policy_logps/chosen': -415.76885986328125, 'referece_logps/rejected': -320.57135009765625, 'referece_logps/chosen': -406.561279296875, 'logits/rejected': -0.7269019484519958, 'logits/chosen': -0.5978420376777649, 'epoch': 2.09}

 35%|███▍      | 5622/16104 [25:58:55<48:54:51, 16.80s/it]


 35%|███▍      | 5624/16104 [25:59:24<44:49:24, 15.40s/it]
{'loss': 0.3998, 'learning_rate': 1.5115667380841948e-06, 'rewards/chosen': -1.6357494592666626, 'rewards/rejected': -3.7438855171203613, 'rewards/accuracies': 0.75, 'rewards/margins': 2.108135938644409, 'policy_logps/rejected': -417.29864501953125, 'policy_logps/chosen': -533.95458984375, 'referece_logps/rejected': -379.85980224609375, 'referece_logps/chosen': -517.5970458984375, 'logits/rejected': -0.08321533352136612, 'logits/chosen': -0.14733850955963135, 'epoch': 2.1}

 35%|███▍      | 5625/16104 [25:59:44<48:34:03, 16.69s/it]

 35%|███▍      | 5626/16104 [26:00:04<51:20:38, 17.64s/it]


 35%|███▍      | 5628/16104 [26:00:36<50:22:48, 17.31s/it]
{'loss': 0.3382, 'learning_rate': 1.5108753067406486e-06, 'rewards/chosen': -1.3867466449737549, 'rewards/rejected': -3.232205390930176, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8454588651657104, 'policy_logps/rejected': -317.3741149902344, 'policy_logps/chosen': -429.69549560546875, 'referece_logps/rejected': -285.0520324707031, 'referece_logps/chosen': -415.82806396484375, 'logits/rejected': -0.09678531438112259, 'logits/chosen': 0.3696501553058624, 'epoch': 2.1}


 35%|███▍      | 5630/16104 [26:01:01<42:57:28, 14.77s/it]
{'loss': 0.2945, 'learning_rate': 1.5105294670459969e-06, 'rewards/chosen': -0.9780833125114441, 'rewards/rejected': -1.6804670095443726, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7023837566375732, 'policy_logps/rejected': -318.0981750488281, 'policy_logps/chosen': -527.0828857421875, 'referece_logps/rejected': -301.29351806640625, 'referece_logps/chosen': -517.302001953125, 'logits/rejected': 0.5987049341201782, 'logits/chosen': 0.37368932366371155, 'epoch': 2.1}

 35%|███▍      | 5631/16104 [26:01:21<47:50:16, 16.44s/it]


 35%|███▍      | 5633/16104 [26:01:50<44:31:26, 15.31s/it]
{'loss': 0.2601, 'learning_rate': 1.5100105526328023e-06, 'rewards/chosen': -1.3728652000427246, 'rewards/rejected': -3.370894193649292, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9980289936065674, 'policy_logps/rejected': -400.74005126953125, 'policy_logps/chosen': -556.659912109375, 'referece_logps/rejected': -367.0311279296875, 'referece_logps/chosen': -542.9312744140625, 'logits/rejected': -0.30742767453193665, 'logits/chosen': -0.3438761532306671, 'epoch': 2.1}

 35%|███▍      | 5634/16104 [26:02:06<44:38:15, 15.35s/it]

 35%|███▍      | 5635/16104 [26:02:27<49:29:43, 17.02s/it]

 35%|███▍      | 5636/16104 [26:02:47<52:15:54, 17.97s/it]

 35%|███▌      | 5637/16104 [26:02:58<45:53:24, 15.78s/it]


 35%|███▌      | 5639/16104 [26:03:27<44:39:44, 15.36s/it]
{'loss': 0.3842, 'learning_rate': 1.5089721669628163e-06, 'rewards/chosen': -1.2199275493621826, 'rewards/rejected': -3.667330503463745, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4474024772644043, 'policy_logps/rejected': -475.24237060546875, 'policy_logps/chosen': -450.145751953125, 'referece_logps/rejected': -438.5691223144531, 'referece_logps/chosen': -437.94647216796875, 'logits/rejected': -0.9046947956085205, 'logits/chosen': -0.7959678173065186, 'epoch': 2.1}

 35%|███▌      | 5640/16104 [26:03:37<40:35:28, 13.96s/it]

 35%|███▌      | 5641/16104 [26:03:57<45:41:51, 15.72s/it]

 35%|███▌      | 5642/16104 [26:04:14<46:24:50, 15.97s/it]

 35%|███▌      | 5643/16104 [26:04:29<45:54:09, 15.80s/it]

 35%|███▌      | 5644/16104 [26:04:47<48:05:43, 16.55s/it]

 35%|███▌      | 5645/16104 [26:05:02<46:18:21, 15.94s/it]

 35%|███▌      | 5646/16104 [26:05:24<51:39:08, 17.78s/it]

 35%|███▌      | 5647/16104 [26:05:36<46:15:21, 15.92s/it]


 35%|███▌      | 5649/16104 [26:06:01<40:54:59, 14.09s/it]

 35%|███▌      | 5650/16104 [26:06:17<42:21:14, 14.59s/it]
{'loss': 0.5015, 'learning_rate': 1.5070665359372703e-06, 'rewards/chosen': -1.0065590143203735, 'rewards/rejected': -2.401134490966797, 'rewards/accuracies': 0.625, 'rewards/margins': 1.394575595855713, 'policy_logps/rejected': -345.1988525390625, 'policy_logps/chosen': -427.47052001953125, 'referece_logps/rejected': -321.1874694824219, 'referece_logps/chosen': -417.40496826171875, 'logits/rejected': -0.46296149492263794, 'logits/chosen': -0.5118218660354614, 'epoch': 2.11}

 35%|███▌      | 5651/16104 [26:06:29<40:25:43, 13.92s/it]

 35%|███▌      | 5652/16104 [26:06:44<41:42:51, 14.37s/it]

 35%|███▌      | 5653/16104 [26:07:00<43:09:13, 14.86s/it]


 35%|███▌      | 5655/16104 [26:07:31<43:50:53, 15.11s/it]

 35%|███▌      | 5656/16104 [26:07:51<47:54:07, 16.51s/it]
{'loss': 0.3611, 'learning_rate': 1.5060260541376324e-06, 'rewards/chosen': -1.0478650331497192, 'rewards/rejected': -3.9106948375701904, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8628299236297607, 'policy_logps/rejected': -446.789306640625, 'policy_logps/chosen': -327.623291015625, 'referece_logps/rejected': -407.6824035644531, 'referece_logps/chosen': -317.14459228515625, 'logits/rejected': -0.4415140151977539, 'logits/chosen': -0.3927907943725586, 'epoch': 2.11}

 35%|███▌      | 5657/16104 [26:08:07<48:00:49, 16.55s/it]

 35%|███▌      | 5658/16104 [26:08:18<42:53:44, 14.78s/it]


 35%|███▌      | 5660/16104 [26:08:43<39:13:15, 13.52s/it]

 35%|███▌      | 5661/16104 [26:09:03<44:47:27, 15.44s/it]
{'loss': 0.5608, 'learning_rate': 1.505158422991434e-06, 'rewards/chosen': -1.213354468345642, 'rewards/rejected': -2.4329721927642822, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2196176052093506, 'policy_logps/rejected': -341.101318359375, 'policy_logps/chosen': -355.2238464355469, 'referece_logps/rejected': -316.7716064453125, 'referece_logps/chosen': -343.09033203125, 'logits/rejected': -0.4328013062477112, 'logits/chosen': -0.41442716121673584, 'epoch': 2.11}


 35%|███▌      | 5663/16104 [26:09:35<44:22:05, 15.30s/it]
{'loss': 0.4033, 'learning_rate': 1.5048112274418951e-06, 'rewards/chosen': -0.6388567686080933, 'rewards/rejected': -1.6110891103744507, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9722324013710022, 'policy_logps/rejected': -319.6498718261719, 'policy_logps/chosen': -351.7642517089844, 'referece_logps/rejected': -303.53900146484375, 'referece_logps/chosen': -345.37567138671875, 'logits/rejected': -1.2180540561676025, 'logits/chosen': -1.2538840770721436, 'epoch': 2.11}

 35%|███▌      | 5664/16104 [26:09:48<42:16:23, 14.58s/it]

 35%|███▌      | 5665/16104 [26:10:08<47:16:00, 16.30s/it]

 35%|███▌      | 5666/16104 [26:10:23<46:07:12, 15.91s/it]

 35%|███▌      | 5667/16104 [26:10:39<46:13:22, 15.94s/it]

 35%|███▌      | 5668/16104 [26:10:56<47:15:50, 16.30s/it]

 35%|███▌      | 5669/16104 [26:11:12<46:57:11, 16.20s/it]

 35%|███▌      | 5670/16104 [26:11:28<46:37:28, 16.09s/it]

 35%|███▌      | 5671/16104 [26:11:46<48:22:08, 16.69s/it]

 35%|███▌      | 5672/16104 [26:12:04<49:18:02, 17.01s/it]

 35%|███▌      | 5673/16104 [26:12:22<49:41:34, 17.15s/it]


 35%|███▌      | 5675/16104 [26:12:59<52:28:24, 18.11s/it]
{'loss': 0.4487, 'learning_rate': 1.5027263407886005e-06, 'rewards/chosen': -0.9109352827072144, 'rewards/rejected': -1.5313498973846436, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6204145550727844, 'policy_logps/rejected': -283.3731384277344, 'policy_logps/chosen': -409.020263671875, 'referece_logps/rejected': -268.0596618652344, 'referece_logps/chosen': -399.91094970703125, 'logits/rejected': -1.0986870527267456, 'logits/chosen': -1.0928205251693726, 'epoch': 2.11}

 35%|███▌      | 5676/16104 [26:13:19<53:45:07, 18.56s/it]

 35%|███▌      | 5677/16104 [26:13:32<49:15:45, 17.01s/it]

 35%|███▌      | 5678/16104 [26:13:44<44:45:56, 15.46s/it]

 35%|███▌      | 5679/16104 [26:14:04<48:32:34, 16.76s/it]

 35%|███▌      | 5680/16104 [26:14:22<49:43:56, 17.18s/it]

 35%|███▌      | 5681/16104 [26:14:34<45:11:08, 15.61s/it]

 35%|███▌      | 5682/16104 [26:14:50<45:23:53, 15.68s/it]


 35%|███▌      | 5684/16104 [26:15:19<43:50:29, 15.15s/it]
{'loss': 0.3252, 'learning_rate': 1.5011607533659745e-06, 'rewards/chosen': -1.3048813343048096, 'rewards/rejected': -3.0229954719543457, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7181140184402466, 'policy_logps/rejected': -290.0063171386719, 'policy_logps/chosen': -416.98162841796875, 'referece_logps/rejected': -259.7763671875, 'referece_logps/chosen': -403.9328308105469, 'logits/rejected': -1.2087817192077637, 'logits/chosen': -1.1783230304718018, 'epoch': 2.12}

 35%|███▌      | 5685/16104 [26:15:38<46:39:27, 16.12s/it]


 35%|███▌      | 5687/16104 [26:16:15<50:20:55, 17.40s/it]
{'loss': 0.4253, 'learning_rate': 1.5006385257271437e-06, 'rewards/chosen': -1.4919965267181396, 'rewards/rejected': -2.470609188079834, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9786127805709839, 'policy_logps/rejected': -361.9004211425781, 'policy_logps/chosen': -327.7491149902344, 'referece_logps/rejected': -337.19427490234375, 'referece_logps/chosen': -312.8291320800781, 'logits/rejected': -0.5822480916976929, 'logits/chosen': -0.6088651418685913, 'epoch': 2.12}

 35%|███▌      | 5688/16104 [26:16:35<52:07:00, 18.01s/it]


 35%|███▌      | 5690/16104 [26:17:10<51:55:03, 17.95s/it]
{'loss': 0.3463, 'learning_rate': 1.500116115822822e-06, 'rewards/chosen': -1.6997246742248535, 'rewards/rejected': -3.4194653034210205, 'rewards/accuracies': 0.875, 'rewards/margins': 1.719740629196167, 'policy_logps/rejected': -496.6622314453125, 'policy_logps/chosen': -493.38555908203125, 'referece_logps/rejected': -462.46759033203125, 'referece_logps/chosen': -476.3883361816406, 'logits/rejected': 0.10369792580604553, 'logits/chosen': 0.03651641309261322, 'epoch': 2.12}

 35%|███▌      | 5691/16104 [26:17:29<52:51:56, 18.28s/it]

 35%|███▌      | 5692/16104 [26:17:41<47:31:34, 16.43s/it]

 35%|███▌      | 5693/16104 [26:18:00<50:21:30, 17.41s/it]

 35%|███▌      | 5694/16104 [26:18:13<45:52:31, 15.86s/it]

 35%|███▌      | 5695/16104 [26:18:24<42:11:17, 14.59s/it]

 35%|███▌      | 5696/16104 [26:18:41<44:09:41, 15.27s/it]

 35%|███▌      | 5697/16104 [26:18:54<41:57:14, 14.51s/it]

 35%|███▌      | 5698/16104 [26:19:14<46:42:06, 16.16s/it]

 35%|███▌      | 5699/16104 [26:19:29<46:02:24, 15.93s/it]


 35%|███▌      | 5701/16104 [26:20:06<49:45:48, 17.22s/it]
{'loss': 0.4179, 'learning_rate': 1.4981990565320825e-06, 'rewards/chosen': -1.1567472219467163, 'rewards/rejected': -3.0099732875823975, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8532260656356812, 'policy_logps/rejected': -468.5648193359375, 'policy_logps/chosen': -482.42047119140625, 'referece_logps/rejected': -438.465087890625, 'referece_logps/chosen': -470.85296630859375, 'logits/rejected': -0.3831079602241516, 'logits/chosen': -0.4829148054122925, 'epoch': 2.12}


 35%|███▌      | 5703/16104 [26:20:42<50:15:43, 17.40s/it]
{'loss': 0.4295, 'learning_rate': 1.497850238032842e-06, 'rewards/chosen': -1.4911952018737793, 'rewards/rejected': -3.537797689437866, 'rewards/accuracies': 0.875, 'rewards/margins': 2.046602964401245, 'policy_logps/rejected': -495.3992004394531, 'policy_logps/chosen': -437.7416687011719, 'referece_logps/rejected': -460.0212707519531, 'referece_logps/chosen': -422.8297119140625, 'logits/rejected': -0.5547458529472351, 'logits/chosen': -0.475109338760376, 'epoch': 2.12}

 35%|███▌      | 5704/16104 [26:21:01<51:43:08, 17.90s/it]

 35%|███▌      | 5705/16104 [26:21:17<50:14:50, 17.39s/it]

 35%|███▌      | 5706/16104 [26:21:37<52:29:18, 18.17s/it]

 35%|███▌      | 5707/16104 [26:21:57<53:47:45, 18.63s/it]

 35%|███▌      | 5708/16104 [26:22:10<48:35:15, 16.83s/it]

 35%|███▌      | 5709/16104 [26:22:28<50:16:32, 17.41s/it]

 35%|███▌      | 5710/16104 [26:22:44<48:54:39, 16.94s/it]

 35%|███▌      | 5711/16104 [26:23:03<50:28:42, 17.49s/it]

 35%|███▌      | 5712/16104 [26:23:20<49:45:53, 17.24s/it]

 35%|███▌      | 5713/16104 [26:23:36<48:55:43, 16.95s/it]

 35%|███▌      | 5714/16104 [26:23:59<53:53:31, 18.67s/it]

 35%|███▌      | 5715/16104 [26:24:11<48:24:28, 16.77s/it]

 35%|███▌      | 5716/16104 [26:24:23<44:34:05, 15.45s/it]

 36%|███▌      | 5717/16104 [26:24:40<45:24:57, 15.74s/it]

 36%|███▌      | 5718/16104 [26:24:59<48:09:04, 16.69s/it]

 36%|███▌      | 5719/16104 [26:25:18<50:50:37, 17.63s/it]

 36%|███▌      | 5720/16104 [26:25:35<50:20:38, 17.45s/it]

 36%|███▌      | 5721/16104 [26:25:55<52:17:36, 18.13s/it]

 36%|███▌      | 5722/16104 [26:26:06<46:14:51, 16.04s/it]

 36%|███▌      | 5723/16104 [26:26:17<41:51:20, 14.51s/it]

 36%|███▌      | 5724/16104 [26:26:28<38:48:30, 13.46s/it]

 36%|███▌      | 5725/16104 [26:26:49<44:44:46, 15.52s/it]

 36%|███▌      | 5726/16104 [26:27:06<46:12:42, 16.03s/it]

 36%|███▌      | 5727/16104 [26:27:25<49:18:09, 17.10s/it]

 36%|███▌      | 5728/16104 [26:27:45<51:43:34, 17.95s/it]

 36%|███▌      | 5729/16104 [26:28:02<50:55:23, 17.67s/it]

 36%|███▌      | 5730/16104 [26:28:24<54:43:47, 18.99s/it]

 36%|███▌      | 5731/16104 [26:28:42<53:45:39, 18.66s/it]

 36%|███▌      | 5732/16104 [26:29:03<55:13:52, 19.17s/it]
[2024-04-06 17:53:40,884] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 36%|███▌      | 5733/16104 [26:29:26<59:03:11, 20.50s/it]

 36%|███▌      | 5734/16104 [26:29:40<53:14:08, 18.48s/it]
[2024-04-06 17:54:13,472] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 36%|███▌      | 5736/16104 [26:30:10<47:00:08, 16.32s/it]

 36%|███▌      | 5737/16104 [26:30:24<44:44:25, 15.54s/it]

 36%|███▌      | 5738/16104 [26:30:39<44:30:10, 15.46s/it]

 36%|███▌      | 5739/16104 [26:31:01<50:02:12, 17.38s/it]
[2024-04-06 17:55:15,358] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 36%|███▌      | 5740/16104 [26:31:20<51:58:46, 18.06s/it]

 36%|███▌      | 5741/16104 [26:31:31<45:46:00, 15.90s/it]

 36%|███▌      | 5742/16104 [26:31:51<49:01:21, 17.03s/it]

 36%|███▌      | 5743/16104 [26:32:11<51:20:49, 17.84s/it]

 36%|███▌      | 5744/16104 [26:32:25<48:38:29, 16.90s/it]

 36%|███▌      | 5745/16104 [26:32:39<45:46:57, 15.91s/it]

 36%|███▌      | 5746/16104 [26:33:00<50:22:34, 17.51s/it]
[2024-04-06 17:57:14,809] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 36%|███▌      | 5747/16104 [26:33:14<47:29:53, 16.51s/it]

 36%|███▌      | 5748/16104 [26:33:34<49:47:17, 17.31s/it]

 36%|███▌      | 5749/16104 [26:33:45<45:09:09, 15.70s/it]

 36%|███▌      | 5750/16104 [26:34:02<45:32:47, 15.84s/it]

 36%|███▌      | 5751/16104 [26:34:17<45:10:44, 15.71s/it]

 36%|███▌      | 5752/16104 [26:34:29<41:52:56, 14.57s/it]
{'loss': 0.3604, 'learning_rate': 1.4892791595270158e-06, 'rewards/chosen': -1.4148732423782349, 'rewards/rejected': -3.0665674209594727, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6516940593719482, 'policy_logps/rejected': -431.25909423828125, 'policy_logps/chosen': -398.6269836425781, 'referece_logps/rejected': -400.59344482421875, 'referece_logps/chosen': -384.4782409667969, 'logits/rejected': -0.3265943229198456, 'logits/chosen': -0.19982020556926727, 'epoch': 2.14}


 36%|███▌      | 5754/16104 [26:35:11<50:43:51, 17.65s/it]

 36%|███▌      | 5755/16104 [26:35:28<50:25:05, 17.54s/it]

 36%|███▌      | 5756/16104 [26:35:45<50:29:38, 17.57s/it]

 36%|███▌      | 5757/16104 [26:36:05<52:02:24, 18.11s/it]

 36%|███▌      | 5758/16104 [26:36:25<53:44:48, 18.70s/it]

 36%|███▌      | 5759/16104 [26:36:39<50:08:26, 17.45s/it]

 36%|███▌      | 5760/16104 [26:37:00<52:52:28, 18.40s/it]

 36%|███▌      | 5761/16104 [26:37:20<54:32:00, 18.98s/it]

 36%|███▌      | 5762/16104 [26:37:33<49:02:11, 17.07s/it]

 36%|███▌      | 5763/16104 [26:37:51<50:09:58, 17.46s/it]

 36%|███▌      | 5764/16104 [26:38:04<45:42:34, 15.91s/it]

 36%|███▌      | 5765/16104 [26:38:21<46:55:30, 16.34s/it]
{'loss': 0.3799, 'learning_rate': 1.4869971893987587e-06, 'rewards/chosen': -1.3729398250579834, 'rewards/rejected': -2.9332990646362305, 'rewards/accuracies': 0.75, 'rewards/margins': 1.560359001159668, 'policy_logps/rejected': -693.5935668945312, 'policy_logps/chosen': -358.7373352050781, 'referece_logps/rejected': -664.2605590820312, 'referece_logps/chosen': -345.0079345703125, 'logits/rejected': -0.43009352684020996, 'logits/chosen': -0.43552660942077637, 'epoch': 2.15}


 36%|███▌      | 5767/16104 [26:38:59<51:17:50, 17.86s/it]

 36%|███▌      | 5768/16104 [26:39:18<52:24:51, 18.26s/it]

 36%|███▌      | 5769/16104 [26:39:32<48:02:09, 16.73s/it]

 36%|███▌      | 5770/16104 [26:39:43<43:40:57, 15.22s/it]

 36%|███▌      | 5771/16104 [26:39:58<42:57:25, 14.97s/it]

 36%|███▌      | 5772/16104 [26:40:12<41:57:42, 14.62s/it]

 36%|███▌      | 5773/16104 [26:40:32<47:22:47, 16.51s/it]

 36%|███▌      | 5774/16104 [26:40:50<48:39:36, 16.96s/it]

 36%|███▌      | 5775/16104 [26:41:08<48:46:07, 17.00s/it]

 36%|███▌      | 5776/16104 [26:41:26<49:39:18, 17.31s/it]

 36%|███▌      | 5777/16104 [26:41:46<52:18:30, 18.23s/it]

 36%|███▌      | 5778/16104 [26:42:05<52:47:37, 18.41s/it]

 36%|███▌      | 5779/16104 [26:42:24<53:27:38, 18.64s/it]

 36%|███▌      | 5780/16104 [26:42:43<54:13:14, 18.91s/it]

 36%|███▌      | 5781/16104 [26:43:02<54:13:46, 18.91s/it]

 36%|███▌      | 5782/16104 [26:43:20<53:03:02, 18.50s/it]

 36%|███▌      | 5783/16104 [26:43:33<48:16:33, 16.84s/it]

 36%|███▌      | 5784/16104 [26:43:50<48:52:18, 17.05s/it]

 36%|███▌      | 5785/16104 [26:44:07<48:27:01, 16.90s/it]

 36%|███▌      | 5786/16104 [26:44:18<43:10:12, 15.06s/it]
{'loss': 0.5855, 'learning_rate': 1.4833039038674046e-06, 'rewards/chosen': -1.8233308792114258, 'rewards/rejected': -2.808619499206543, 'rewards/accuracies': 0.375, 'rewards/margins': 0.9852886199951172, 'policy_logps/rejected': -483.5826416015625, 'policy_logps/chosen': -411.63128662109375, 'referece_logps/rejected': -455.4964599609375, 'referece_logps/chosen': -393.3979797363281, 'logits/rejected': -0.7514577507972717, 'logits/chosen': -0.8338799476623535, 'epoch': 2.16}


 36%|███▌      | 5788/16104 [26:44:47<42:49:59, 14.95s/it]

 36%|███▌      | 5789/16104 [26:45:02<43:23:38, 15.14s/it]

 36%|███▌      | 5790/16104 [26:45:22<47:38:00, 16.63s/it]
{'loss': 0.3332, 'learning_rate': 1.482599441366938e-06, 'rewards/chosen': -2.1947054862976074, 'rewards/rejected': -4.9015607833862305, 'rewards/accuracies': 0.875, 'rewards/margins': 2.706855297088623, 'policy_logps/rejected': -445.4764709472656, 'policy_logps/chosen': -384.59326171875, 'referece_logps/rejected': -396.46087646484375, 'referece_logps/chosen': -362.64617919921875, 'logits/rejected': -1.0235096216201782, 'logits/chosen': -0.9641050100326538, 'epoch': 2.16}


 36%|███▌      | 5792/16104 [26:45:50<43:05:50, 15.05s/it]

 36%|███▌      | 5793/16104 [26:46:04<42:06:32, 14.70s/it]

 36%|███▌      | 5794/16104 [26:46:20<43:02:13, 15.03s/it]

 36%|███▌      | 5795/16104 [26:46:32<41:12:31, 14.39s/it]

 36%|███▌      | 5796/16104 [26:46:44<38:47:41, 13.55s/it]

 36%|███▌      | 5797/16104 [26:47:04<44:19:02, 15.48s/it]

 36%|███▌      | 5798/16104 [26:47:18<42:56:17, 15.00s/it]

 36%|███▌      | 5799/16104 [26:47:35<44:42:01, 15.62s/it]

 36%|███▌      | 5800/16104 [26:47:46<40:59:43, 14.32s/it]

 36%|███▌      | 5801/16104 [26:48:03<43:25:48, 15.17s/it]

 36%|███▌      | 5802/16104 [26:48:14<39:53:56, 13.94s/it]

 36%|███▌      | 5803/16104 [26:48:25<37:02:31, 12.95s/it]

 36%|███▌      | 5804/16104 [26:48:41<39:37:32, 13.85s/it]

 36%|███▌      | 5805/16104 [26:48:56<40:32:50, 14.17s/it]

 36%|███▌      | 5806/16104 [26:49:17<46:29:08, 16.25s/it]

 36%|███▌      | 5807/16104 [26:49:32<44:58:46, 15.73s/it]

 36%|███▌      | 5808/16104 [26:49:51<48:21:36, 16.91s/it]

 36%|███▌      | 5809/16104 [26:50:11<50:38:53, 17.71s/it]

 36%|███▌      | 5810/16104 [26:50:30<52:19:26, 18.30s/it]

 36%|███▌      | 5811/16104 [26:50:41<45:51:02, 16.04s/it]

 36%|███▌      | 5812/16104 [26:51:01<49:08:23, 17.19s/it]

 36%|███▌      | 5813/16104 [26:51:22<52:07:03, 18.23s/it]

 36%|███▌      | 5814/16104 [26:51:41<52:41:04, 18.43s/it]

 36%|███▌      | 5815/16104 [26:51:58<51:25:54, 18.00s/it]

 36%|███▌      | 5816/16104 [26:52:11<47:09:08, 16.50s/it]

 36%|███▌      | 5817/16104 [26:52:25<45:33:49, 15.95s/it]

 36%|███▌      | 5818/16104 [26:52:37<41:40:40, 14.59s/it]

 36%|███▌      | 5819/16104 [26:52:55<45:11:43, 15.82s/it]

 36%|███▌      | 5820/16104 [26:53:16<48:56:42, 17.13s/it]
{'loss': 0.4306, 'learning_rate': 1.4773060479115883e-06, 'rewards/chosen': -1.6239382028579712, 'rewards/rejected': -2.6778273582458496, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0538891553878784, 'policy_logps/rejected': -220.776123046875, 'policy_logps/chosen': -194.04129028320312, 'referece_logps/rejected': -193.99783325195312, 'referece_logps/chosen': -177.80191040039062, 'logits/rejected': -1.2659659385681152, 'logits/chosen': -1.190763235092163, 'epoch': 2.17}


 36%|███▌      | 5822/16104 [26:53:42<42:37:04, 14.92s/it]

 36%|███▌      | 5823/16104 [26:53:54<40:07:51, 14.05s/it]
{'loss': 0.3888, 'learning_rate': 1.4767757496435382e-06, 'rewards/chosen': -1.7166978120803833, 'rewards/rejected': -3.9607033729553223, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2440056800842285, 'policy_logps/rejected': -480.3787841796875, 'policy_logps/chosen': -496.70916748046875, 'referece_logps/rejected': -440.771728515625, 'referece_logps/chosen': -479.54217529296875, 'logits/rejected': -1.0739059448242188, 'logits/chosen': -0.9569209218025208, 'epoch': 2.17}
[2024-04-06 18:18:29,319] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 36%|███▌      | 5824/16104 [26:54:15<46:00:11, 16.11s/it]


 36%|███▌      | 5826/16104 [26:54:39<40:20:25, 14.13s/it]
{'loss': 0.4015, 'learning_rate': 1.476245277797624e-06, 'rewards/chosen': -1.8279552459716797, 'rewards/rejected': -3.864068031311035, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0361130237579346, 'policy_logps/rejected': -309.7379455566406, 'policy_logps/chosen': -390.6818542480469, 'referece_logps/rejected': -271.0972900390625, 'referece_logps/chosen': -372.4023132324219, 'logits/rejected': -0.01976799964904785, 'logits/chosen': 0.005328506231307983, 'epoch': 2.17}


 36%|███▌      | 5828/16104 [26:55:10<43:22:29, 15.20s/it]

 36%|███▌      | 5829/16104 [26:55:31<48:35:48, 17.03s/it]
{'loss': 0.4073, 'learning_rate': 1.4757146325669723e-06, 'rewards/chosen': -2.602473497390747, 'rewards/rejected': -3.6506872177124023, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0482134819030762, 'policy_logps/rejected': -477.8357849121094, 'policy_logps/chosen': -497.4539794921875, 'referece_logps/rejected': -441.32891845703125, 'referece_logps/chosen': -471.4292297363281, 'logits/rejected': 0.3133445978164673, 'logits/chosen': 0.2951749563217163, 'epoch': 2.17}

 36%|███▌      | 5830/16104 [26:55:51<50:43:16, 17.77s/it]


 36%|███▌      | 5832/16104 [26:56:28<51:50:41, 18.17s/it]

 36%|███▌      | 5833/16104 [26:56:47<52:41:44, 18.47s/it]

 36%|███▌      | 5834/16104 [26:57:04<50:50:05, 17.82s/it]
{'loss': 0.5096, 'learning_rate': 1.474829839074545e-06, 'rewards/chosen': -2.0549354553222656, 'rewards/rejected': -2.983497142791748, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9285618662834167, 'policy_logps/rejected': -573.700439453125, 'policy_logps/chosen': -455.3481750488281, 'referece_logps/rejected': -543.8654174804688, 'referece_logps/chosen': -434.798828125, 'logits/rejected': -0.23100103437900543, 'logits/chosen': -0.42599111795425415, 'epoch': 2.17}

 36%|███▌      | 5835/16104 [26:57:23<51:44:03, 18.14s/it]


 36%|███▌      | 5837/16104 [26:58:02<53:25:49, 18.73s/it]

 36%|███▋      | 5838/16104 [26:58:20<53:00:20, 18.59s/it]

 36%|███▋      | 5839/16104 [26:58:40<53:51:17, 18.89s/it]

 36%|███▋      | 5840/16104 [26:59:00<54:46:37, 19.21s/it]
{'loss': 0.4072, 'learning_rate': 1.4737674531078866e-06, 'rewards/chosen': -1.805399775505066, 'rewards/rejected': -3.0990281105041504, 'rewards/accuracies': 0.75, 'rewards/margins': 1.293628215789795, 'policy_logps/rejected': -424.7578430175781, 'policy_logps/chosen': -470.9866943359375, 'referece_logps/rejected': -393.767578125, 'referece_logps/chosen': -452.9327392578125, 'logits/rejected': 0.16999754309654236, 'logits/chosen': 0.24558191001415253, 'epoch': 2.18}


 36%|███▋      | 5842/16104 [26:59:21<42:25:52, 14.89s/it]

 36%|███▋      | 5843/16104 [26:59:32<39:08:06, 13.73s/it]

 36%|███▋      | 5844/16104 [26:59:43<36:47:27, 12.91s/it]

 36%|███▋      | 5845/16104 [27:00:00<40:02:19, 14.05s/it]
{'loss': 0.2813, 'learning_rate': 1.4728816043730594e-06, 'rewards/chosen': -1.2654314041137695, 'rewards/rejected': -3.451892137527466, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1864609718322754, 'policy_logps/rejected': -209.79783630371094, 'policy_logps/chosen': -308.1879577636719, 'referece_logps/rejected': -175.27891540527344, 'referece_logps/chosen': -295.5336608886719, 'logits/rejected': -0.6656028032302856, 'logits/chosen': -0.6242867708206177, 'epoch': 2.18}


 36%|███▋      | 5847/16104 [27:00:38<47:20:11, 16.61s/it]

 36%|███▋      | 5848/16104 [27:00:52<45:00:49, 15.80s/it]

 36%|███▋      | 5849/16104 [27:01:09<46:26:51, 16.31s/it]
{'loss': 0.2338, 'learning_rate': 1.472172581021923e-06, 'rewards/chosen': -1.7917543649673462, 'rewards/rejected': -3.421030282974243, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6292756795883179, 'policy_logps/rejected': -353.95233154296875, 'policy_logps/chosen': -348.295654296875, 'referece_logps/rejected': -319.7420349121094, 'referece_logps/chosen': -330.37811279296875, 'logits/rejected': -0.8065726161003113, 'logits/chosen': -0.6443704962730408, 'epoch': 2.18}

 36%|███▋      | 5850/16104 [27:01:21<42:37:31, 14.97s/it]


 36%|███▋      | 5852/16104 [27:01:56<45:48:17, 16.08s/it]
{'loss': 0.236, 'learning_rate': 1.4716406129311306e-06, 'rewards/chosen': -1.4446654319763184, 'rewards/rejected': -3.570082664489746, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1254169940948486, 'policy_logps/rejected': -221.64036560058594, 'policy_logps/chosen': -270.2362060546875, 'referece_logps/rejected': -185.93954467773438, 'referece_logps/chosen': -255.78955078125, 'logits/rejected': -0.13381405174732208, 'logits/chosen': -0.15756170451641083, 'epoch': 2.18}


 36%|███▋      | 5854/16104 [27:02:34<51:03:27, 17.93s/it]
{'loss': 0.4242, 'learning_rate': 1.4712858721317915e-06, 'rewards/chosen': -1.2213932275772095, 'rewards/rejected': -3.357032060623169, 'rewards/accuracies': 0.75, 'rewards/margins': 2.135639190673828, 'policy_logps/rejected': -232.198486328125, 'policy_logps/chosen': -466.4504089355469, 'referece_logps/rejected': -198.6281280517578, 'referece_logps/chosen': -454.2364807128906, 'logits/rejected': -0.7111271023750305, 'logits/chosen': -0.6665818095207214, 'epoch': 2.18}

 36%|███▋      | 5855/16104 [27:02:47<46:10:09, 16.22s/it]


 36%|███▋      | 5857/16104 [27:03:11<40:06:23, 14.09s/it]

 36%|███▋      | 5858/16104 [27:03:32<45:32:51, 16.00s/it]
{'loss': 0.5457, 'learning_rate': 1.470576161818274e-06, 'rewards/chosen': -1.2673335075378418, 'rewards/rejected': -3.138054609298706, 'rewards/accuracies': 0.625, 'rewards/margins': 1.8707211017608643, 'policy_logps/rejected': -453.48211669921875, 'policy_logps/chosen': -502.4766845703125, 'referece_logps/rejected': -422.1015625, 'referece_logps/chosen': -489.8033447265625, 'logits/rejected': -0.5377313494682312, 'logits/chosen': -0.7103737592697144, 'epoch': 2.18}


 36%|███▋      | 5860/16104 [27:03:58<42:08:06, 14.81s/it]

 36%|███▋      | 5861/16104 [27:04:18<45:45:13, 16.08s/it]
{'loss': 0.2744, 'learning_rate': 1.4700436791837401e-06, 'rewards/chosen': -2.962026596069336, 'rewards/rejected': -4.4162750244140625, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4542484283447266, 'policy_logps/rejected': -425.35687255859375, 'policy_logps/chosen': -410.72174072265625, 'referece_logps/rejected': -381.194091796875, 'referece_logps/chosen': -381.1014404296875, 'logits/rejected': -0.2855832576751709, 'logits/chosen': -0.3587997853755951, 'epoch': 2.18}

 36%|███▋      | 5862/16104 [27:04:37<48:50:51, 17.17s/it]


 36%|███▋      | 5864/16104 [27:05:17<52:26:43, 18.44s/it]
{'loss': 0.2867, 'learning_rate': 1.4695110254222605e-06, 'rewards/chosen': -1.3100876808166504, 'rewards/rejected': -3.825272560119629, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5151844024658203, 'policy_logps/rejected': -465.0953369140625, 'policy_logps/chosen': -381.47979736328125, 'referece_logps/rejected': -426.8426208496094, 'referece_logps/chosen': -368.37896728515625, 'logits/rejected': -0.5289555788040161, 'logits/chosen': -0.304841011762619, 'epoch': 2.18}


 36%|███▋      | 5866/16104 [27:05:48<48:12:13, 16.95s/it]
{'loss': 0.4517, 'learning_rate': 1.469155827939843e-06, 'rewards/chosen': -1.6158013343811035, 'rewards/rejected': -2.9225223064422607, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3067212104797363, 'policy_logps/rejected': -259.07354736328125, 'policy_logps/chosen': -271.3714294433594, 'referece_logps/rejected': -229.8483123779297, 'referece_logps/chosen': -255.21340942382812, 'logits/rejected': -0.23698875308036804, 'logits/chosen': -0.0830206573009491, 'epoch': 2.19}


 36%|███▋      | 5868/16104 [27:06:20<46:33:18, 16.37s/it]

 36%|███▋      | 5869/16104 [27:06:32<43:00:55, 15.13s/it]
{'loss': 0.4138, 'learning_rate': 1.4686228893977537e-06, 'rewards/chosen': -2.471543312072754, 'rewards/rejected': -3.2800326347351074, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8084889054298401, 'policy_logps/rejected': -415.3204345703125, 'policy_logps/chosen': -479.3650817871094, 'referece_logps/rejected': -382.5201110839844, 'referece_logps/chosen': -454.64959716796875, 'logits/rejected': -0.11354157328605652, 'logits/chosen': -0.11634773015975952, 'epoch': 2.19}


 36%|███▋      | 5871/16104 [27:07:00<42:09:55, 14.83s/it]
{'loss': 0.3705, 'learning_rate': 1.4682675022412232e-06, 'rewards/chosen': -1.7130963802337646, 'rewards/rejected': -3.778048276901245, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0649518966674805, 'policy_logps/rejected': -387.2693176269531, 'policy_logps/chosen': -393.600830078125, 'referece_logps/rejected': -349.4888610839844, 'referece_logps/chosen': -376.4698791503906, 'logits/rejected': -0.9237817525863647, 'logits/chosen': -0.7710584402084351, 'epoch': 2.19}


 36%|███▋      | 5873/16104 [27:07:29<41:34:11, 14.63s/it]

 36%|███▋      | 5874/16104 [27:07:49<46:09:17, 16.24s/it]

 36%|███▋      | 5875/16104 [27:08:08<49:06:11, 17.28s/it]

 36%|███▋      | 5876/16104 [27:08:30<52:33:54, 18.50s/it]
{'loss': 0.4508, 'learning_rate': 1.4673787029862394e-06, 'rewards/chosen': -1.6142864227294922, 'rewards/rejected': -2.3882646560668945, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7739779949188232, 'policy_logps/rejected': -337.5393981933594, 'policy_logps/chosen': -399.160400390625, 'referece_logps/rejected': -313.6567077636719, 'referece_logps/chosen': -383.0175476074219, 'logits/rejected': -0.2885962724685669, 'logits/chosen': -0.2670706808567047, 'epoch': 2.19}


 37%|███▋      | 5878/16104 [27:08:53<42:35:00, 14.99s/it]
{'loss': 0.302, 'learning_rate': 1.4670230508897879e-06, 'rewards/chosen': -1.867821455001831, 'rewards/rejected': -3.5047693252563477, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6369476318359375, 'policy_logps/rejected': -342.9145202636719, 'policy_logps/chosen': -537.9947509765625, 'referece_logps/rejected': -307.8668212890625, 'referece_logps/chosen': -519.316650390625, 'logits/rejected': -0.8795175552368164, 'logits/chosen': -0.790065348148346, 'epoch': 2.19}


 37%|███▋      | 5880/16104 [27:09:33<49:42:36, 17.50s/it]

 37%|███▋      | 5881/16104 [27:09:44<44:09:47, 15.55s/it]

 37%|███▋      | 5882/16104 [27:09:59<43:41:02, 15.38s/it]

 37%|███▋      | 5883/16104 [27:10:10<40:03:50, 14.11s/it]

 37%|███▋      | 5884/16104 [27:10:21<37:19:38, 13.15s/it]

 37%|███▋      | 5885/16104 [27:10:39<41:08:26, 14.49s/it]

 37%|███▋      | 5886/16104 [27:10:55<42:33:20, 14.99s/it]
{'loss': 0.4129, 'learning_rate': 1.46559968740301e-06, 'rewards/chosen': -1.6206996440887451, 'rewards/rejected': -3.7723424434661865, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1516427993774414, 'policy_logps/rejected': -339.7952880859375, 'policy_logps/chosen': -406.003173828125, 'referece_logps/rejected': -302.07183837890625, 'referece_logps/chosen': -389.79620361328125, 'logits/rejected': -0.016942337155342102, 'logits/chosen': 0.09568240493535995, 'epoch': 2.19}


 37%|███▋      | 5888/16104 [27:11:28<45:26:41, 16.01s/it]

 37%|███▋      | 5889/16104 [27:11:41<42:26:39, 14.96s/it]

 37%|███▋      | 5890/16104 [27:11:55<42:05:13, 14.83s/it]

 37%|███▋      | 5891/16104 [27:12:07<39:23:12, 13.88s/it]
{'loss': 0.3288, 'learning_rate': 1.4647094728738733e-06, 'rewards/chosen': -1.5658276081085205, 'rewards/rejected': -4.008289813995361, 'rewards/accuracies': 0.875, 'rewards/margins': 2.442462205886841, 'policy_logps/rejected': -371.00897216796875, 'policy_logps/chosen': -507.2537841796875, 'referece_logps/rejected': -330.9260559082031, 'referece_logps/chosen': -491.5954284667969, 'logits/rejected': -0.8797048926353455, 'logits/chosen': -0.9309320449829102, 'epoch': 2.19}


 37%|███▋      | 5893/16104 [27:12:32<37:28:14, 13.21s/it]

 37%|███▋      | 5894/16104 [27:12:44<36:20:25, 12.81s/it]

 37%|███▋      | 5895/16104 [27:12:56<35:37:15, 12.56s/it]

 37%|███▋      | 5896/16104 [27:13:09<35:37:54, 12.57s/it]

 37%|███▋      | 5897/16104 [27:13:23<36:30:08, 12.87s/it]

 37%|███▋      | 5898/16104 [27:13:40<40:37:21, 14.33s/it]
{'loss': 0.4283, 'learning_rate': 1.4634623832051434e-06, 'rewards/chosen': -2.0729541778564453, 'rewards/rejected': -2.9549264907836914, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8819725513458252, 'policy_logps/rejected': -418.4333801269531, 'policy_logps/chosen': -433.5867614746094, 'referece_logps/rejected': -388.8840637207031, 'referece_logps/chosen': -412.85723876953125, 'logits/rejected': -0.3897041976451874, 'logits/chosen': -0.6412996053695679, 'epoch': 2.2}

 37%|███▋      | 5899/16104 [27:14:00<45:00:30, 15.88s/it]

 37%|███▋      | 5900/16104 [27:14:16<45:17:58, 15.98s/it]

 37%|███▋      | 5901/16104 [27:14:36<48:19:10, 17.05s/it]

 37%|███▋      | 5902/16104 [27:14:54<49:09:54, 17.35s/it]


 37%|███▋      | 5904/16104 [27:15:25<46:21:33, 16.36s/it]

 37%|███▋      | 5905/16104 [27:15:35<41:32:45, 14.66s/it]

 37%|███▋      | 5906/16104 [27:15:47<39:16:44, 13.87s/it]

 37%|███▋      | 5907/16104 [27:15:59<37:27:54, 13.23s/it]
{'loss': 0.4545, 'learning_rate': 1.4618576327014485e-06, 'rewards/chosen': -1.0653573274612427, 'rewards/rejected': -1.4344769716262817, 'rewards/accuracies': 0.75, 'rewards/margins': 0.36911964416503906, 'policy_logps/rejected': -525.5131225585938, 'policy_logps/chosen': -530.3335571289062, 'referece_logps/rejected': -511.16839599609375, 'referece_logps/chosen': -519.6799926757812, 'logits/rejected': -0.04304301738739014, 'logits/chosen': 0.09026741981506348, 'epoch': 2.2}

 37%|███▋      | 5908/16104 [27:16:12<37:10:48, 13.13s/it]

 37%|███▋      | 5909/16104 [27:16:26<37:38:31, 13.29s/it]


 37%|███▋      | 5911/16104 [27:16:56<39:29:14, 13.95s/it]

 37%|███▋      | 5912/16104 [27:17:10<39:21:16, 13.90s/it]
{'loss': 0.4402, 'learning_rate': 1.4609654504034275e-06, 'rewards/chosen': -0.8739770650863647, 'rewards/rejected': -2.4622790813446045, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5883021354675293, 'policy_logps/rejected': -323.9490661621094, 'policy_logps/chosen': -444.1065673828125, 'referece_logps/rejected': -299.3263244628906, 'referece_logps/chosen': -435.3668212890625, 'logits/rejected': -0.8893409967422485, 'logits/chosen': -0.9024944305419922, 'epoch': 2.2}


 37%|███▋      | 5914/16104 [27:17:33<35:25:43, 12.52s/it]
{'loss': 0.4844, 'learning_rate': 1.460608446905562e-06, 'rewards/chosen': -1.007578730583191, 'rewards/rejected': -1.702666163444519, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6950874924659729, 'policy_logps/rejected': -481.8717956542969, 'policy_logps/chosen': -490.49884033203125, 'referece_logps/rejected': -464.8451232910156, 'referece_logps/chosen': -480.4230651855469, 'logits/rejected': -0.9377316236495972, 'logits/chosen': -0.95747971534729, 'epoch': 2.2}


 37%|███▋      | 5916/16104 [27:17:55<33:22:29, 11.79s/it]

 37%|███▋      | 5917/16104 [27:18:15<40:09:34, 14.19s/it]

 37%|███▋      | 5918/16104 [27:18:33<43:30:54, 15.38s/it]

 37%|███▋      | 5919/16104 [27:18:47<42:28:57, 15.02s/it]
{'loss': 0.4842, 'learning_rate': 1.459715612219705e-06, 'rewards/chosen': -1.412283182144165, 'rewards/rejected': -1.7376259565353394, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3253428637981415, 'policy_logps/rejected': -378.9968566894531, 'policy_logps/chosen': -360.8608703613281, 'referece_logps/rejected': -361.6205749511719, 'referece_logps/chosen': -346.738037109375, 'logits/rejected': 0.06163415685296059, 'logits/chosen': 0.05727125704288483, 'epoch': 2.21}

 37%|███▋      | 5920/16104 [27:19:04<44:26:22, 15.71s/it]


 37%|███▋      | 5922/16104 [27:19:30<40:46:09, 14.41s/it]

 37%|███▋      | 5923/16104 [27:19:44<39:48:59, 14.08s/it]
{'loss': 0.383, 'learning_rate': 1.4590010096939867e-06, 'rewards/chosen': -1.8795998096466064, 'rewards/rejected': -3.2307116985321045, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3511114120483398, 'policy_logps/rejected': -395.6729431152344, 'policy_logps/chosen': -405.436767578125, 'referece_logps/rejected': -363.3658447265625, 'referece_logps/chosen': -386.64080810546875, 'logits/rejected': -1.011860966682434, 'logits/chosen': -0.8410909175872803, 'epoch': 2.21}


 37%|███▋      | 5925/16104 [27:20:10<38:22:31, 13.57s/it]
{'loss': 0.424, 'learning_rate': 1.4586435969977596e-06, 'rewards/chosen': -1.5057092905044556, 'rewards/rejected': -2.7678234577178955, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2621142864227295, 'policy_logps/rejected': -241.94686889648438, 'policy_logps/chosen': -296.0569763183594, 'referece_logps/rejected': -214.26861572265625, 'referece_logps/chosen': -280.9998779296875, 'logits/rejected': -0.30978819727897644, 'logits/chosen': -0.18476764857769012, 'epoch': 2.21}


 37%|███▋      | 5927/16104 [27:20:36<37:09:07, 13.14s/it]

 37%|███▋      | 5928/16104 [27:20:47<35:18:24, 12.49s/it]
{'loss': 0.4475, 'learning_rate': 1.4581073388243558e-06, 'rewards/chosen': -0.8412308096885681, 'rewards/rejected': -2.777317523956299, 'rewards/accuracies': 0.875, 'rewards/margins': 1.936086893081665, 'policy_logps/rejected': -454.75408935546875, 'policy_logps/chosen': -388.6695556640625, 'referece_logps/rejected': -426.98089599609375, 'referece_logps/chosen': -380.2572326660156, 'logits/rejected': -0.5642638802528381, 'logits/chosen': -0.57039475440979, 'epoch': 2.21}


 37%|███▋      | 5930/16104 [27:21:17<38:08:51, 13.50s/it]

 37%|███▋      | 5931/16104 [27:21:35<41:30:48, 14.69s/it]
{'loss': 0.4387, 'learning_rate': 1.4575709138696225e-06, 'rewards/chosen': -1.7183308601379395, 'rewards/rejected': -2.412332057952881, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6940010190010071, 'policy_logps/rejected': -308.69207763671875, 'policy_logps/chosen': -320.06866455078125, 'referece_logps/rejected': -284.56878662109375, 'referece_logps/chosen': -302.88531494140625, 'logits/rejected': -0.8113644123077393, 'logits/chosen': -0.7584054470062256, 'epoch': 2.21}
[2024-04-06 18:46:10,972] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 37%|███▋      | 5932/16104 [27:21:56<47:28:29, 16.80s/it]
[2024-04-06 18:46:28,599] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 37%|███▋      | 5934/16104 [27:22:27<44:30:01, 15.75s/it]
{'loss': 0.434, 'learning_rate': 1.4570343223288537e-06, 'rewards/chosen': -1.5221703052520752, 'rewards/rejected': -2.62429141998291, 'rewards/accuracies': 0.875, 'rewards/margins': 1.102121114730835, 'policy_logps/rejected': -322.1499328613281, 'policy_logps/chosen': -392.0111083984375, 'referece_logps/rejected': -295.9070129394531, 'referece_logps/chosen': -376.7893981933594, 'logits/rejected': -0.6495504975318909, 'logits/chosen': -0.5280343890190125, 'epoch': 2.21}

 37%|███▋      | 5935/16104 [27:22:40<42:44:45, 15.13s/it]


 37%|███▋      | 5937/16104 [27:23:13<45:07:05, 15.98s/it]

 37%|███▋      | 5938/16104 [27:23:29<45:07:13, 15.98s/it]
{'loss': 0.4949, 'learning_rate': 1.4563186081449882e-06, 'rewards/chosen': -1.0739096403121948, 'rewards/rejected': -1.791301965713501, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7173923254013062, 'policy_logps/rejected': -438.0640869140625, 'policy_logps/chosen': -413.6260986328125, 'referece_logps/rejected': -420.1510925292969, 'referece_logps/chosen': -402.886962890625, 'logits/rejected': -0.5082905888557434, 'logits/chosen': -0.5657476186752319, 'epoch': 2.21}

 37%|███▋      | 5939/16104 [27:23:50<49:20:25, 17.47s/it]
[2024-04-06 18:48:23,280] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 37%|███▋      | 5941/16104 [27:24:20<44:33:47, 15.79s/it]
{'loss': 0.6413, 'learning_rate': 1.455781628663288e-06, 'rewards/chosen': -1.018485426902771, 'rewards/rejected': -2.0290884971618652, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0106030702590942, 'policy_logps/rejected': -404.62469482421875, 'policy_logps/chosen': -453.6861877441406, 'referece_logps/rejected': -384.33380126953125, 'referece_logps/chosen': -443.50128173828125, 'logits/rejected': 0.6725094318389893, 'logits/chosen': 0.8019955158233643, 'epoch': 2.21}


 37%|███▋      | 5943/16104 [27:24:45<39:48:51, 14.11s/it]
{'loss': 0.5017, 'learning_rate': 1.4554235501441857e-06, 'rewards/chosen': -0.8720304369926453, 'rewards/rejected': -1.5091100931167603, 'rewards/accuracies': 0.625, 'rewards/margins': 0.637079656124115, 'policy_logps/rejected': -360.1972351074219, 'policy_logps/chosen': -426.7255859375, 'referece_logps/rejected': -345.1061706542969, 'referece_logps/chosen': -418.0052795410156, 'logits/rejected': -0.7555762529373169, 'logits/chosen': -0.7359974384307861, 'epoch': 2.21}

 37%|███▋      | 5944/16104 [27:24:59<39:04:33, 13.85s/it]
[2024-04-06 18:49:37,333] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 37%|███▋      | 5946/16104 [27:25:44<51:01:16, 18.08s/it]
{'loss': 0.2236, 'learning_rate': 1.4548862942134278e-06, 'rewards/chosen': -1.3107291460037231, 'rewards/rejected': -3.558218479156494, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2474894523620605, 'policy_logps/rejected': -289.12542724609375, 'policy_logps/chosen': -325.75164794921875, 'referece_logps/rejected': -253.54322814941406, 'referece_logps/chosen': -312.6443786621094, 'logits/rejected': -0.1629951000213623, 'logits/chosen': -0.15639296174049377, 'epoch': 2.22}

 37%|███▋      | 5947/16104 [27:26:05<53:44:04, 19.05s/it]
[2024-04-06 18:50:37,936] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 37%|███▋      | 5949/16104 [27:26:36<48:01:40, 17.03s/it]
{'loss': 0.5083, 'learning_rate': 1.4543488726740138e-06, 'rewards/chosen': -1.8310000896453857, 'rewards/rejected': -2.0656118392944336, 'rewards/accuracies': 0.75, 'rewards/margins': 0.23461169004440308, 'policy_logps/rejected': -318.2605895996094, 'policy_logps/chosen': -395.0938720703125, 'referece_logps/rejected': -297.6044616699219, 'referece_logps/chosen': -376.7838134765625, 'logits/rejected': -0.159410297870636, 'logits/chosen': -0.16787010431289673, 'epoch': 2.22}
[2024-04-06 18:51:13,328] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 37%|███▋      | 5950/16104 [27:26:59<52:47:29, 18.72s/it]
[2024-04-06 18:51:33,473] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 37%|███▋      | 5952/16104 [27:27:38<53:50:53, 19.10s/it]
{'loss': 0.4083, 'learning_rate': 1.4538112857216e-06, 'rewards/chosen': -0.5804599523544312, 'rewards/rejected': -3.154235601425171, 'rewards/accuracies': 1.0, 'rewards/margins': 2.57377552986145, 'policy_logps/rejected': -475.17864990234375, 'policy_logps/chosen': -483.852783203125, 'referece_logps/rejected': -443.6363220214844, 'referece_logps/chosen': -478.0482482910156, 'logits/rejected': -0.6926354169845581, 'logits/chosen': -0.7672393918037415, 'epoch': 2.22}


 37%|███▋      | 5954/16104 [27:28:04<45:26:05, 16.11s/it]

 37%|███▋      | 5955/16104 [27:28:18<43:37:23, 15.47s/it]
{'loss': 0.4688, 'learning_rate': 1.4532735335519037e-06, 'rewards/chosen': -0.9981006979942322, 'rewards/rejected': -3.8794121742248535, 'rewards/accuracies': 0.875, 'rewards/margins': 2.8813114166259766, 'policy_logps/rejected': -456.0376281738281, 'policy_logps/chosen': -434.00634765625, 'referece_logps/rejected': -417.2435607910156, 'referece_logps/chosen': -424.02532958984375, 'logits/rejected': 0.3846089839935303, 'logits/chosen': 0.366748571395874, 'epoch': 2.22}

 37%|███▋      | 5956/16104 [27:28:31<41:37:17, 14.77s/it]

 37%|███▋      | 5957/16104 [27:28:43<39:52:38, 14.15s/it]

 37%|███▋      | 5958/16104 [27:29:03<44:49:55, 15.91s/it]


 37%|███▋      | 5960/16104 [27:29:36<45:47:11, 16.25s/it]

 37%|███▋      | 5961/16104 [27:29:52<45:38:55, 16.20s/it]
{'loss': 0.4475, 'learning_rate': 1.452197534343833e-06, 'rewards/chosen': -1.4498376846313477, 'rewards/rejected': -3.0720269680023193, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6221892833709717, 'policy_logps/rejected': -363.67095947265625, 'policy_logps/chosen': -360.4021301269531, 'referece_logps/rejected': -332.9507141113281, 'referece_logps/chosen': -345.9037780761719, 'logits/rejected': -1.1020140647888184, 'logits/chosen': -1.040067434310913, 'epoch': 2.22}

 37%|███▋      | 5962/16104 [27:30:11<48:31:55, 17.23s/it]

 37%|███▋      | 5963/16104 [27:30:27<47:19:44, 16.80s/it]

 37%|███▋      | 5964/16104 [27:30:43<46:08:48, 16.38s/it]

 37%|███▋      | 5965/16104 [27:31:03<49:42:46, 17.65s/it]

 37%|███▋      | 5966/16104 [27:31:21<50:10:43, 17.82s/it]


 37%|███▋      | 5968/16104 [27:32:02<53:38:26, 19.05s/it]
{'loss': 0.3078, 'learning_rate': 1.4509413697496197e-06, 'rewards/chosen': -2.3678929805755615, 'rewards/rejected': -4.231759548187256, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8638666868209839, 'policy_logps/rejected': -489.75, 'policy_logps/chosen': -492.0229797363281, 'referece_logps/rejected': -447.43243408203125, 'referece_logps/chosen': -468.3440246582031, 'logits/rejected': -0.2185995876789093, 'logits/chosen': -0.24257464706897736, 'epoch': 2.22}

 37%|███▋      | 5969/16104 [27:32:22<54:38:52, 19.41s/it]


 37%|███▋      | 5971/16104 [27:32:54<50:18:07, 17.87s/it]
{'loss': 0.3191, 'learning_rate': 1.4504027397290089e-06, 'rewards/chosen': -1.3143901824951172, 'rewards/rejected': -3.2587826251983643, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9443926811218262, 'policy_logps/rejected': -236.14010620117188, 'policy_logps/chosen': -387.9249572753906, 'referece_logps/rejected': -203.5522918701172, 'referece_logps/chosen': -374.7810363769531, 'logits/rejected': -0.15452471375465393, 'logits/chosen': -0.3966960608959198, 'epoch': 2.22}

 37%|███▋      | 5972/16104 [27:33:07<45:44:02, 16.25s/it]

 37%|███▋      | 5973/16104 [27:33:25<47:48:49, 16.99s/it]

 37%|███▋      | 5974/16104 [27:33:37<43:30:50, 15.46s/it]

 37%|███▋      | 5975/16104 [27:33:55<45:14:44, 16.08s/it]


 37%|███▋      | 5977/16104 [27:34:29<46:27:57, 16.52s/it]
{'loss': 0.5063, 'learning_rate': 1.4493249879549034e-06, 'rewards/chosen': -2.8750407695770264, 'rewards/rejected': -3.1008052825927734, 'rewards/accuracies': 0.625, 'rewards/margins': 0.22576439380645752, 'policy_logps/rejected': -322.7944030761719, 'policy_logps/chosen': -432.8017578125, 'referece_logps/rejected': -291.786376953125, 'referece_logps/chosen': -404.0513610839844, 'logits/rejected': 0.07924731075763702, 'logits/chosen': -0.14446812868118286, 'epoch': 2.23}

 37%|███▋      | 5978/16104 [27:34:45<46:14:01, 16.44s/it]


 37%|███▋      | 5980/16104 [27:35:16<45:09:46, 16.06s/it]
{'loss': 0.4402, 'learning_rate': 1.4487858665937824e-06, 'rewards/chosen': -0.7821952104568481, 'rewards/rejected': -2.6209969520568848, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8388017416000366, 'policy_logps/rejected': -373.4903564453125, 'policy_logps/chosen': -463.9331359863281, 'referece_logps/rejected': -347.28033447265625, 'referece_logps/chosen': -456.1112060546875, 'logits/rejected': -0.47908613085746765, 'logits/chosen': -0.6477529406547546, 'epoch': 2.23}


 37%|███▋      | 5982/16104 [27:35:41<39:50:29, 14.17s/it]
{'loss': 0.3078, 'learning_rate': 1.448426361569973e-06, 'rewards/chosen': -1.757825255393982, 'rewards/rejected': -3.404484748840332, 'rewards/accuracies': 1.0, 'rewards/margins': 1.64665949344635, 'policy_logps/rejected': -359.75665283203125, 'policy_logps/chosen': -518.5521240234375, 'referece_logps/rejected': -325.7117614746094, 'referece_logps/chosen': -500.973876953125, 'logits/rejected': -0.7011920213699341, 'logits/chosen': -0.833185076713562, 'epoch': 2.23}

 37%|███▋      | 5983/16104 [27:35:51<36:51:04, 13.11s/it]


 37%|███▋      | 5985/16104 [27:36:14<34:43:47, 12.36s/it]
{'loss': 0.3717, 'learning_rate': 1.447886968005093e-06, 'rewards/chosen': -1.7225350141525269, 'rewards/rejected': -3.14825439453125, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4257194995880127, 'policy_logps/rejected': -384.80426025390625, 'policy_logps/chosen': -461.86419677734375, 'referece_logps/rejected': -353.32171630859375, 'referece_logps/chosen': -444.6388854980469, 'logits/rejected': -1.1869665384292603, 'logits/chosen': -1.078348994255066, 'epoch': 2.23}
[2024-04-06 19:00:51,711] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 37%|███▋      | 5986/16104 [27:36:37<43:38:35, 15.53s/it]

 37%|███▋      | 5987/16104 [27:36:50<41:18:26, 14.70s/it]

 37%|███▋      | 5988/16104 [27:37:07<43:45:56, 15.57s/it]

 37%|███▋      | 5989/16104 [27:37:28<47:32:28, 16.92s/it]

 37%|███▋      | 5990/16104 [27:37:40<43:30:14, 15.48s/it]

 37%|███▋      | 5991/16104 [27:38:01<48:35:16, 17.30s/it]

 37%|███▋      | 5992/16104 [27:38:14<44:37:01, 15.88s/it]

 37%|███▋      | 5993/16104 [27:38:33<47:44:09, 17.00s/it]


 37%|███▋      | 5995/16104 [27:39:13<51:28:15, 18.33s/it]
{'loss': 0.3683, 'learning_rate': 1.4460878129003012e-06, 'rewards/chosen': -1.8453329801559448, 'rewards/rejected': -2.628079652786255, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7827467918395996, 'policy_logps/rejected': -527.7495727539062, 'policy_logps/chosen': -498.32550048828125, 'referece_logps/rejected': -501.46881103515625, 'referece_logps/chosen': -479.8721923828125, 'logits/rejected': -0.31601428985595703, 'logits/chosen': -0.24210092425346375, 'epoch': 2.23}

 37%|███▋      | 5996/16104 [27:39:34<54:06:24, 19.27s/it]

 37%|███▋      | 5997/16104 [27:39:51<52:23:43, 18.66s/it]

 37%|███▋      | 5998/16104 [27:40:10<52:38:39, 18.75s/it]

 37%|███▋      | 5999/16104 [27:40:32<54:45:08, 19.51s/it]

 37%|███▋      | 6000/16104 [27:40:50<53:48:39, 19.17s/it]

 37%|███▋      | 6001/16104 [27:41:24<66:22:30, 23.65s/it]

 37%|███▋      | 6002/16104 [27:41:42<61:42:34, 21.99s/it]

 37%|███▋      | 6003/16104 [27:41:57<56:01:49, 19.97s/it]

 37%|███▋      | 6004/16104 [27:42:20<57:52:33, 20.63s/it]

 37%|███▋      | 6005/16104 [27:42:38<55:53:51, 19.93s/it]

 37%|███▋      | 6006/16104 [27:42:54<52:52:05, 18.85s/it]


 37%|███▋      | 6008/16104 [27:43:33<53:13:00, 18.98s/it]
{'loss': 0.4269, 'learning_rate': 1.443746214619232e-06, 'rewards/chosen': -0.9946764707565308, 'rewards/rejected': -1.1925958395004272, 'rewards/accuracies': 0.625, 'rewards/margins': 0.19791941344738007, 'policy_logps/rejected': -378.79840087890625, 'policy_logps/chosen': -315.4586181640625, 'referece_logps/rejected': -366.8724060058594, 'referece_logps/chosen': -305.5118713378906, 'logits/rejected': 0.03864291310310364, 'logits/chosen': 0.04553450644016266, 'epoch': 2.24}


 37%|███▋      | 6010/16104 [27:44:05<50:07:32, 17.88s/it]

 37%|███▋      | 6011/16104 [27:44:27<53:31:42, 19.09s/it]
{'loss': 0.4488, 'learning_rate': 1.4432054143942281e-06, 'rewards/chosen': -1.6794252395629883, 'rewards/rejected': -2.5367019176483154, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8572765588760376, 'policy_logps/rejected': -381.85125732421875, 'policy_logps/chosen': -246.6975860595703, 'referece_logps/rejected': -356.4842529296875, 'referece_logps/chosen': -229.90333557128906, 'logits/rejected': -0.4848553240299225, 'logits/chosen': -0.44880110025405884, 'epoch': 2.24}

 37%|███▋      | 6012/16104 [27:44:42<49:50:02, 17.78s/it]

 37%|███▋      | 6013/16104 [27:45:02<51:53:07, 18.51s/it]

 37%|███▋      | 6014/16104 [27:45:16<47:50:34, 17.07s/it]

 37%|███▋      | 6015/16104 [27:45:37<51:48:40, 18.49s/it]

 37%|███▋      | 6016/16104 [27:45:58<53:35:01, 19.12s/it]


 37%|███▋      | 6018/16104 [27:46:31<50:46:09, 18.12s/it]

 37%|███▋      | 6019/16104 [27:46:49<50:52:40, 18.16s/it]

 37%|███▋      | 6020/16104 [27:47:11<53:57:08, 19.26s/it]
[2024-04-06 19:11:25,728] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3537, 'learning_rate': 1.4415820463707895e-06, 'rewards/chosen': -0.633863091468811, 'rewards/rejected': -2.6360878944396973, 'rewards/accuracies': 0.875, 'rewards/margins': 2.002224922180176, 'policy_logps/rejected': -608.0150756835938, 'policy_logps/chosen': -538.7235717773438, 'referece_logps/rejected': -581.6542358398438, 'referece_logps/chosen': -532.3848876953125, 'logits/rejected': 0.9633263349533081, 'logits/chosen': 0.9678602814674377, 'epoch': 2.24}
[2024-04-06 19:11:45,408] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 37%|███▋      | 6021/16104 [27:47:31<54:18:20, 19.39s/it]

 37%|███▋      | 6022/16104 [27:47:52<56:02:27, 20.01s/it]


 37%|███▋      | 6024/16104 [27:48:27<53:02:52, 18.95s/it]

 37%|███▋      | 6025/16104 [27:48:43<50:17:13, 17.96s/it]

 37%|███▋      | 6026/16104 [27:49:01<50:29:51, 18.04s/it]

 37%|███▋      | 6027/16104 [27:49:21<52:03:12, 18.60s/it]
{'loss': 0.4143, 'learning_rate': 1.4403184262089242e-06, 'rewards/chosen': -1.1649479866027832, 'rewards/rejected': -3.17641019821167, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0114619731903076, 'policy_logps/rejected': -563.4971923828125, 'policy_logps/chosen': -424.01934814453125, 'referece_logps/rejected': -531.733154296875, 'referece_logps/chosen': -412.369873046875, 'logits/rejected': -0.1099431961774826, 'logits/chosen': 0.042757466435432434, 'epoch': 2.25}


 37%|███▋      | 6029/16104 [27:49:51<47:28:51, 16.97s/it]

 37%|███▋      | 6030/16104 [27:50:03<43:25:49, 15.52s/it]
{'loss': 0.4214, 'learning_rate': 1.439776607389928e-06, 'rewards/chosen': -1.3320508003234863, 'rewards/rejected': -2.723527669906616, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3914767503738403, 'policy_logps/rejected': -434.510986328125, 'policy_logps/chosen': -484.01025390625, 'referece_logps/rejected': -407.27569580078125, 'referece_logps/chosen': -470.68975830078125, 'logits/rejected': -0.06676621735095978, 'logits/chosen': -0.05934992432594299, 'epoch': 2.25}


 37%|███▋      | 6032/16104 [27:50:25<36:57:46, 13.21s/it]

 37%|███▋      | 6033/16104 [27:50:45<42:46:07, 15.29s/it]
{'loss': 0.4024, 'learning_rate': 1.4392346284631989e-06, 'rewards/chosen': -1.1976535320281982, 'rewards/rejected': -2.256863594055176, 'rewards/accuracies': 0.75, 'rewards/margins': 1.059209942817688, 'policy_logps/rejected': -251.913330078125, 'policy_logps/chosen': -190.43142700195312, 'referece_logps/rejected': -229.34466552734375, 'referece_logps/chosen': -178.45492553710938, 'logits/rejected': -0.7211257219314575, 'logits/chosen': -0.6599266529083252, 'epoch': 2.25}
[2024-04-06 19:15:22,293] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 37%|███▋      | 6035/16104 [27:51:19<43:48:02, 15.66s/it]

 37%|███▋      | 6036/16104 [27:51:39<47:11:52, 16.88s/it]
{'loss': 0.3562, 'learning_rate': 1.4386924896260535e-06, 'rewards/chosen': -1.9213896989822388, 'rewards/rejected': -3.8639607429504395, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9425712823867798, 'policy_logps/rejected': -354.5058288574219, 'policy_logps/chosen': -337.5218811035156, 'referece_logps/rejected': -315.8662109375, 'referece_logps/chosen': -318.3079833984375, 'logits/rejected': -0.5771148204803467, 'logits/chosen': -0.5557876229286194, 'epoch': 2.25}


 37%|███▋      | 6038/16104 [27:52:19<51:46:21, 18.52s/it]

 38%|███▊      | 6039/16104 [27:52:31<46:21:22, 16.58s/it]
{'loss': 0.2409, 'learning_rate': 1.438150191075866e-06, 'rewards/chosen': -2.2190685272216797, 'rewards/rejected': -3.6076302528381348, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3885618448257446, 'policy_logps/rejected': -530.2911987304688, 'policy_logps/chosen': -366.6269836425781, 'referece_logps/rejected': -494.21490478515625, 'referece_logps/chosen': -344.436279296875, 'logits/rejected': -0.18306036293506622, 'logits/chosen': 0.11428218334913254, 'epoch': 2.25}

 38%|███▊      | 6040/16104 [27:52:51<48:49:51, 17.47s/it]

 38%|███▊      | 6041/16104 [27:53:03<44:31:30, 15.93s/it]


 38%|███▊      | 6043/16104 [27:53:39<47:24:58, 16.97s/it]
{'loss': 0.5175, 'learning_rate': 1.4374268782410225e-06, 'rewards/chosen': -1.460853934288025, 'rewards/rejected': -3.289705753326416, 'rewards/accuracies': 0.75, 'rewards/margins': 1.828851580619812, 'policy_logps/rejected': -384.0567321777344, 'policy_logps/chosen': -455.3445739746094, 'referece_logps/rejected': -351.15966796875, 'referece_logps/chosen': -440.736083984375, 'logits/rejected': -1.0071417093276978, 'logits/chosen': -1.0247087478637695, 'epoch': 2.25}


 38%|███▊      | 6045/16104 [27:54:08<43:48:57, 15.68s/it]
{'loss': 0.3252, 'learning_rate': 1.4370651156261525e-06, 'rewards/chosen': -1.6358057260513306, 'rewards/rejected': -3.8358302116394043, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2000248432159424, 'policy_logps/rejected': -233.2030029296875, 'policy_logps/chosen': -378.21917724609375, 'referece_logps/rejected': -194.84471130371094, 'referece_logps/chosen': -361.8610534667969, 'logits/rejected': -1.111968755722046, 'logits/chosen': -1.2094508409500122, 'epoch': 2.25}

 38%|███▊      | 6046/16104 [27:54:23<43:25:29, 15.54s/it]

 38%|███▊      | 6047/16104 [27:54:45<48:35:13, 17.39s/it]

 38%|███▊      | 6048/16104 [27:55:03<49:11:52, 17.61s/it]
[2024-04-06 19:19:38,865] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6049/16104 [27:55:24<52:21:44, 18.75s/it]

 38%|███▊      | 6050/16104 [27:55:37<47:20:10, 16.95s/it]

 38%|███▊      | 6051/16104 [27:55:48<42:20:51, 15.16s/it]
[2024-04-06 19:20:19,006] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6052/16104 [27:56:04<43:21:58, 15.53s/it]

 38%|███▊      | 6053/16104 [27:56:26<48:44:32, 17.46s/it]

 38%|███▊      | 6054/16104 [27:56:43<47:56:18, 17.17s/it]

 38%|███▊      | 6055/16104 [27:57:03<50:40:18, 18.15s/it]

 38%|███▊      | 6056/16104 [27:57:21<50:41:59, 18.16s/it]

 38%|███▊      | 6057/16104 [27:57:40<50:38:35, 18.15s/it]

 38%|███▊      | 6058/16104 [27:57:50<44:29:12, 15.94s/it]

 38%|███▊      | 6059/16104 [27:58:02<40:32:29, 14.53s/it]

 38%|███▊      | 6060/16104 [27:58:12<37:27:45, 13.43s/it]
[2024-04-06 19:22:49,036] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6061/16104 [27:58:34<44:35:17, 15.98s/it]

 38%|███▊      | 6062/16104 [27:58:56<49:05:36, 17.60s/it]

 38%|███▊      | 6063/16104 [27:59:08<44:13:35, 15.86s/it]

 38%|███▊      | 6064/16104 [27:59:26<46:36:47, 16.71s/it]

 38%|███▊      | 6065/16104 [27:59:41<45:12:10, 16.21s/it]


 38%|███▊      | 6067/16104 [28:00:16<47:01:20, 16.87s/it]
{'loss': 0.3193, 'learning_rate': 1.4330810722118114e-06, 'rewards/chosen': -1.5549259185791016, 'rewards/rejected': -3.8618156909942627, 'rewards/accuracies': 0.875, 'rewards/margins': 2.306889772415161, 'policy_logps/rejected': -274.33209228515625, 'policy_logps/chosen': -423.69232177734375, 'referece_logps/rejected': -235.71395874023438, 'referece_logps/chosen': -408.1430358886719, 'logits/rejected': -0.03262844681739807, 'logits/chosen': -0.026258468627929688, 'epoch': 2.26}

 38%|███▊      | 6068/16104 [28:00:29<43:30:16, 15.61s/it]

 38%|███▊      | 6069/16104 [28:00:44<42:50:57, 15.37s/it]

 38%|███▊      | 6070/16104 [28:01:02<45:43:12, 16.40s/it]

 38%|███▊      | 6071/16104 [28:01:14<41:43:07, 14.97s/it]

 38%|███▊      | 6072/16104 [28:01:27<39:49:55, 14.29s/it]

 38%|███▊      | 6073/16104 [28:01:48<45:31:12, 16.34s/it]

 38%|███▊      | 6074/16104 [28:02:06<47:21:55, 17.00s/it]

 38%|███▊      | 6075/16104 [28:02:20<44:08:08, 15.84s/it]

 38%|███▊      | 6076/16104 [28:02:31<40:04:23, 14.39s/it]

 38%|███▊      | 6077/16104 [28:02:53<46:35:54, 16.73s/it]

 38%|███▊      | 6078/16104 [28:03:08<45:04:26, 16.18s/it]

 38%|███▊      | 6079/16104 [28:03:24<44:54:08, 16.12s/it]

 38%|███▊      | 6080/16104 [28:03:43<47:54:34, 17.21s/it]

 38%|███▊      | 6081/16104 [28:03:56<44:11:28, 15.87s/it]

 38%|███▊      | 6082/16104 [28:04:18<49:10:58, 17.67s/it]

 38%|███▊      | 6083/16104 [28:04:38<51:09:46, 18.38s/it]

 38%|███▊      | 6084/16104 [28:04:50<45:25:30, 16.32s/it]

 38%|███▊      | 6085/16104 [28:05:00<40:44:45, 14.64s/it]

 38%|███▊      | 6086/16104 [28:05:17<42:38:44, 15.32s/it]
[2024-04-06 19:29:51,790] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6087/16104 [28:05:37<46:27:19, 16.70s/it]

 38%|███▊      | 6088/16104 [28:05:53<45:34:06, 16.38s/it]

 38%|███▊      | 6089/16104 [28:06:05<41:45:40, 15.01s/it]

 38%|███▊      | 6090/16104 [28:06:24<45:34:38, 16.38s/it]
[2024-04-06 19:31:03,169] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6091/16104 [28:06:49<52:12:06, 18.77s/it]

 38%|███▊      | 6092/16104 [28:07:10<54:36:37, 19.64s/it]
[2024-04-06 19:31:39,681] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6093/16104 [28:07:25<50:36:50, 18.20s/it]

 38%|███▊      | 6094/16104 [28:07:45<51:57:54, 18.69s/it]

 38%|███▊      | 6095/16104 [28:08:04<52:39:02, 18.94s/it]

 38%|███▊      | 6096/16104 [28:08:16<46:11:05, 16.61s/it]
[2024-04-06 19:32:51,100] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6097/16104 [28:08:36<49:44:24, 17.89s/it]
[2024-04-06 19:33:10,523] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6098/16104 [28:08:56<51:00:39, 18.35s/it]
[2024-04-06 19:33:31,248] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6099/16104 [28:09:17<52:58:59, 19.06s/it]

 38%|███▊      | 6100/16104 [28:09:36<53:02:22, 19.09s/it]

 38%|███▊      | 6101/16104 [28:09:50<49:24:34, 17.78s/it]

 38%|███▊      | 6102/16104 [28:10:12<52:10:56, 18.78s/it]

 38%|███▊      | 6103/16104 [28:10:30<51:42:51, 18.62s/it]

 38%|███▊      | 6104/16104 [28:10:50<52:38:01, 18.95s/it]
[2024-04-06 19:35:23,743] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6105/16104 [28:11:09<53:08:04, 19.13s/it]

 38%|███▊      | 6106/16104 [28:11:27<52:20:51, 18.85s/it]

 38%|███▊      | 6107/16104 [28:11:49<54:28:52, 19.62s/it]
[2024-04-06 19:36:24,029] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6108/16104 [28:12:09<55:21:15, 19.94s/it]

 38%|███▊      | 6109/16104 [28:12:23<50:21:40, 18.14s/it]

 38%|███▊      | 6110/16104 [28:12:39<48:27:44, 17.46s/it]

 38%|███▊      | 6111/16104 [28:12:59<50:15:44, 18.11s/it]

 38%|███▊      | 6112/16104 [28:13:10<44:33:46, 16.06s/it]

 38%|███▊      | 6113/16104 [28:13:21<40:06:51, 14.45s/it]

 38%|███▊      | 6114/16104 [28:13:40<44:24:30, 16.00s/it]

 38%|███▊      | 6115/16104 [28:14:02<48:56:34, 17.64s/it]

 38%|███▊      | 6116/16104 [28:14:14<44:33:49, 16.06s/it]

 38%|███▊      | 6117/16104 [28:14:25<40:30:09, 14.60s/it]

 38%|███▊      | 6118/16104 [28:14:36<37:28:11, 13.51s/it]

 38%|███▊      | 6119/16104 [28:14:49<36:38:19, 13.21s/it]

 38%|███▊      | 6120/16104 [28:15:08<41:27:58, 14.95s/it]

 38%|███▊      | 6121/16104 [28:15:28<45:32:36, 16.42s/it]

 38%|███▊      | 6122/16104 [28:15:40<41:48:34, 15.08s/it]

 38%|███▊      | 6123/16104 [28:16:00<46:09:09, 16.65s/it]

 38%|███▊      | 6124/16104 [28:16:20<49:10:16, 17.74s/it]

 38%|███▊      | 6125/16104 [28:16:33<45:17:01, 16.34s/it]

 38%|███▊      | 6126/16104 [28:16:46<42:17:47, 15.26s/it]


 38%|███▊      | 6128/16104 [28:17:18<43:55:12, 15.85s/it]

 38%|███▊      | 6129/16104 [28:17:34<43:52:52, 15.84s/it]

 38%|███▊      | 6130/16104 [28:17:56<48:53:58, 17.65s/it]

 38%|███▊      | 6131/16104 [28:18:13<48:56:47, 17.67s/it]

 38%|███▊      | 6132/16104 [28:18:31<49:14:26, 17.78s/it]

 38%|███▊      | 6133/16104 [28:18:43<44:20:47, 16.01s/it]

 38%|███▊      | 6134/16104 [28:19:01<46:02:14, 16.62s/it]

 38%|███▊      | 6135/16104 [28:19:25<51:45:18, 18.69s/it]
[2024-04-06 19:43:39,449] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6136/16104 [28:19:37<46:35:32, 16.83s/it]

 38%|███▊      | 6137/16104 [28:19:59<50:48:36, 18.35s/it]

 38%|███▊      | 6138/16104 [28:20:19<51:56:41, 18.76s/it]

 38%|███▊      | 6139/16104 [28:20:38<52:19:15, 18.90s/it]

 38%|███▊      | 6140/16104 [28:20:57<52:21:43, 18.92s/it]

 38%|███▊      | 6141/16104 [28:21:09<46:30:50, 16.81s/it]

 38%|███▊      | 6142/16104 [28:21:24<44:57:36, 16.25s/it]

 38%|███▊      | 6143/16104 [28:21:41<45:31:52, 16.46s/it]
[2024-04-06 19:45:55,510] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6144/16104 [28:21:54<43:07:18, 15.59s/it]

 38%|███▊      | 6145/16104 [28:22:10<43:08:21, 15.59s/it]

 38%|███▊      | 6146/16104 [28:22:28<44:58:52, 16.26s/it]

 38%|███▊      | 6147/16104 [28:22:48<48:12:00, 17.43s/it]

 38%|███▊      | 6148/16104 [28:23:04<47:19:42, 17.11s/it]

 38%|███▊      | 6149/16104 [28:23:23<48:09:36, 17.42s/it]

 38%|███▊      | 6150/16104 [28:23:44<51:27:12, 18.61s/it]
[2024-04-06 19:47:58,543] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6151/16104 [28:24:03<51:50:20, 18.75s/it]
[2024-04-06 19:48:17,623] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6152/16104 [28:24:20<50:41:15, 18.34s/it]

 38%|███▊      | 6153/16104 [28:24:38<50:12:37, 18.16s/it]

 38%|███▊      | 6154/16104 [28:24:54<48:21:27, 17.50s/it]

 38%|███▊      | 6155/16104 [28:25:16<51:42:21, 18.71s/it]

 38%|███▊      | 6156/16104 [28:25:35<52:27:32, 18.98s/it]

 38%|███▊      | 6157/16104 [28:25:50<48:47:56, 17.66s/it]

 38%|███▊      | 6158/16104 [28:26:03<45:01:50, 16.30s/it]

 38%|███▊      | 6159/16104 [28:26:17<43:03:29, 15.59s/it]

 38%|███▊      | 6160/16104 [28:26:37<46:59:31, 17.01s/it]
[2024-04-06 19:50:51,818] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6161/16104 [28:26:56<48:50:01, 17.68s/it]
{'loss': 0.414, 'learning_rate': 1.4159637900754666e-06, 'rewards/chosen': -1.767383098602295, 'rewards/rejected': -2.3190393447875977, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5516563653945923, 'policy_logps/rejected': -352.2923583984375, 'policy_logps/chosen': -321.4119567871094, 'referece_logps/rejected': -329.1019287109375, 'referece_logps/chosen': -303.7381591796875, 'logits/rejected': -0.304749995470047, 'logits/chosen': -0.3030897378921509, 'epoch': 2.3}


 38%|███▊      | 6163/16104 [28:27:23<42:05:50, 15.24s/it]

 38%|███▊      | 6164/16104 [28:27:43<46:15:32, 16.75s/it]

 38%|███▊      | 6165/16104 [28:28:01<47:00:32, 17.03s/it]
{'loss': 0.4261, 'learning_rate': 1.4152320536922687e-06, 'rewards/chosen': -1.462398648262024, 'rewards/rejected': -2.521435499191284, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0590368509292603, 'policy_logps/rejected': -280.2131042480469, 'policy_logps/chosen': -250.29501342773438, 'referece_logps/rejected': -254.99876403808594, 'referece_logps/chosen': -235.6710205078125, 'logits/rejected': -1.6084859371185303, 'logits/chosen': -1.7096192836761475, 'epoch': 2.3}


 38%|███▊      | 6167/16104 [28:28:34<45:59:49, 16.66s/it]

 38%|███▊      | 6168/16104 [28:28:49<44:38:53, 16.18s/it]
{'loss': 0.4235, 'learning_rate': 1.4146830750117586e-06, 'rewards/chosen': -1.5505869388580322, 'rewards/rejected': -2.389759063720703, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8391724228858948, 'policy_logps/rejected': -474.0408935546875, 'policy_logps/chosen': -438.5327453613281, 'referece_logps/rejected': -450.143310546875, 'referece_logps/chosen': -423.0268859863281, 'logits/rejected': -0.6841180324554443, 'logits/chosen': -0.592807412147522, 'epoch': 2.3}


 38%|███▊      | 6170/16104 [28:29:26<48:02:33, 17.41s/it]
{'loss': 0.4622, 'learning_rate': 1.4143170053390628e-06, 'rewards/chosen': -1.520883560180664, 'rewards/rejected': -3.0826008319854736, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5617173910140991, 'policy_logps/rejected': -396.3121337890625, 'policy_logps/chosen': -426.1358642578125, 'referece_logps/rejected': -365.4861145019531, 'referece_logps/chosen': -410.927001953125, 'logits/rejected': -0.3800133168697357, 'logits/chosen': -0.24513649940490723, 'epoch': 2.3}


 38%|███▊      | 6172/16104 [28:29:51<41:59:23, 15.22s/it]

 38%|███▊      | 6173/16104 [28:30:08<42:47:30, 15.51s/it]
{'loss': 0.4596, 'learning_rate': 1.4137677751495663e-06, 'rewards/chosen': -1.5300359725952148, 'rewards/rejected': -2.527865171432495, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9978291988372803, 'policy_logps/rejected': -304.8561706542969, 'policy_logps/chosen': -358.25921630859375, 'referece_logps/rejected': -279.5774841308594, 'referece_logps/chosen': -342.9588928222656, 'logits/rejected': -0.28070738911628723, 'logits/chosen': -0.23387394845485687, 'epoch': 2.3}


 38%|███▊      | 6175/16104 [28:30:38<42:28:35, 15.40s/it]

 38%|███▊      | 6176/16104 [28:30:55<43:35:50, 15.81s/it]

 38%|███▊      | 6177/16104 [28:31:10<42:47:31, 15.52s/it]

 38%|███▊      | 6178/16104 [28:31:31<47:29:03, 17.22s/it]

 38%|███▊      | 6179/16104 [28:31:44<43:50:42, 15.90s/it]

 38%|███▊      | 6180/16104 [28:32:01<44:56:44, 16.30s/it]

 38%|███▊      | 6181/16104 [28:32:13<41:38:22, 15.11s/it]

 38%|███▊      | 6182/16104 [28:32:33<45:18:54, 16.44s/it]

 38%|███▊      | 6183/16104 [28:32:46<42:45:23, 15.51s/it]
{'loss': 0.4069, 'learning_rate': 1.411935921027979e-06, 'rewards/chosen': -0.9793665409088135, 'rewards/rejected': -2.8287081718444824, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8493417501449585, 'policy_logps/rejected': -281.6800537109375, 'policy_logps/chosen': -400.26824951171875, 'referece_logps/rejected': -253.39297485351562, 'referece_logps/chosen': -390.4745788574219, 'logits/rejected': -0.4454748034477234, 'logits/chosen': -0.3851585388183594, 'epoch': 2.3}


 38%|███▊      | 6185/16104 [28:33:26<49:38:36, 18.02s/it]

 38%|███▊      | 6186/16104 [28:33:37<43:39:11, 15.85s/it]

 38%|███▊      | 6187/16104 [28:33:58<48:01:24, 17.43s/it]
{'loss': 0.4854, 'learning_rate': 1.4112027123850966e-06, 'rewards/chosen': -1.3481297492980957, 'rewards/rejected': -2.335531711578369, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9874017834663391, 'policy_logps/rejected': -483.7763366699219, 'policy_logps/chosen': -407.28265380859375, 'referece_logps/rejected': -460.4209899902344, 'referece_logps/chosen': -393.80133056640625, 'logits/rejected': 0.15901586413383484, 'logits/chosen': 0.20118308067321777, 'epoch': 2.31}


 38%|███▊      | 6189/16104 [28:34:35<49:53:30, 18.12s/it]

 38%|███▊      | 6190/16104 [28:34:46<43:53:49, 15.94s/it]
{'loss': 0.4698, 'learning_rate': 1.4106526312212079e-06, 'rewards/chosen': -1.711527943611145, 'rewards/rejected': -2.7297518253326416, 'rewards/accuracies': 0.75, 'rewards/margins': 1.018223762512207, 'policy_logps/rejected': -334.4214782714844, 'policy_logps/chosen': -505.4234619140625, 'referece_logps/rejected': -307.1239318847656, 'referece_logps/chosen': -488.30816650390625, 'logits/rejected': -0.5057193636894226, 'logits/chosen': -0.45510154962539673, 'epoch': 2.31}

 38%|███▊      | 6191/16104 [28:34:57<39:35:25, 14.38s/it]


 38%|███▊      | 6193/16104 [28:35:38<47:52:42, 17.39s/it]

 38%|███▊      | 6194/16104 [28:35:50<44:02:56, 16.00s/it]

 38%|███▊      | 6195/16104 [28:36:06<43:37:21, 15.85s/it]

 38%|███▊      | 6196/16104 [28:36:22<44:09:47, 16.05s/it]

 38%|███▊      | 6197/16104 [28:36:33<39:52:51, 14.49s/it]

 38%|███▊      | 6198/16104 [28:36:49<40:59:00, 14.89s/it]

 38%|███▊      | 6199/16104 [28:37:04<41:15:13, 14.99s/it]

 38%|███▊      | 6200/16104 [28:37:18<40:20:38, 14.66s/it]
{'loss': 0.5107, 'learning_rate': 1.4088179487109032e-06, 'rewards/chosen': -2.3654897212982178, 'rewards/rejected': -2.601351022720337, 'rewards/accuracies': 0.5, 'rewards/margins': 0.23586125671863556, 'policy_logps/rejected': -483.2834167480469, 'policy_logps/chosen': -543.4288940429688, 'referece_logps/rejected': -457.2698974609375, 'referece_logps/chosen': -519.7739868164062, 'logits/rejected': -0.9059839844703674, 'logits/chosen': -0.85239177942276, 'epoch': 2.31}


 39%|███▊      | 6202/16104 [28:37:40<34:43:02, 12.62s/it]

 39%|███▊      | 6203/16104 [28:37:50<33:05:39, 12.03s/it]

 39%|███▊      | 6204/16104 [28:38:03<34:05:02, 12.39s/it]
{'loss': 0.3804, 'learning_rate': 1.4080836122434648e-06, 'rewards/chosen': -1.3922057151794434, 'rewards/rejected': -3.89688777923584, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5046818256378174, 'policy_logps/rejected': -514.2459716796875, 'policy_logps/chosen': -492.033935546875, 'referece_logps/rejected': -475.27703857421875, 'referece_logps/chosen': -478.11187744140625, 'logits/rejected': 0.027223072946071625, 'logits/chosen': -0.01264234259724617, 'epoch': 2.31}


 39%|███▊      | 6206/16104 [28:38:41<42:40:34, 15.52s/it]
{'loss': 0.3135, 'learning_rate': 1.4077163449337768e-06, 'rewards/chosen': -1.4636056423187256, 'rewards/rejected': -4.6012492179870605, 'rewards/accuracies': 0.75, 'rewards/margins': 3.1376430988311768, 'policy_logps/rejected': -400.4946594238281, 'policy_logps/chosen': -366.37255859375, 'referece_logps/rejected': -354.482177734375, 'referece_logps/chosen': -351.73651123046875, 'logits/rejected': 0.10127684473991394, 'logits/chosen': 0.3252268433570862, 'epoch': 2.31}


 39%|███▊      | 6208/16104 [28:39:06<37:41:02, 13.71s/it]

 39%|███▊      | 6209/16104 [28:39:28<44:18:45, 16.12s/it]

 39%|███▊      | 6210/16104 [28:39:45<45:41:40, 16.63s/it]

 39%|███▊      | 6211/16104 [28:40:00<44:06:16, 16.05s/it]

 39%|███▊      | 6212/16104 [28:40:18<45:37:08, 16.60s/it]

 39%|███▊      | 6213/16104 [28:40:34<45:00:35, 16.38s/it]

 39%|███▊      | 6214/16104 [28:40:48<42:53:43, 15.61s/it]

 39%|███▊      | 6215/16104 [28:41:05<44:00:58, 16.02s/it]

 39%|███▊      | 6216/16104 [28:41:16<40:02:29, 14.58s/it]
{'loss': 0.428, 'learning_rate': 1.4058790200030257e-06, 'rewards/chosen': -1.6625442504882812, 'rewards/rejected': -2.8767571449279785, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2142127752304077, 'policy_logps/rejected': -497.9579162597656, 'policy_logps/chosen': -468.59979248046875, 'referece_logps/rejected': -469.1903381347656, 'referece_logps/chosen': -451.974365234375, 'logits/rejected': -0.9271236062049866, 'logits/chosen': -0.8032848834991455, 'epoch': 2.32}

 39%|███▊      | 6217/16104 [28:41:37<45:33:23, 16.59s/it]


 39%|███▊      | 6219/16104 [28:42:15<48:26:06, 17.64s/it]

 39%|███▊      | 6220/16104 [28:42:28<45:02:01, 16.40s/it]

 39%|███▊      | 6221/16104 [28:42:41<42:22:35, 15.44s/it]

 39%|███▊      | 6222/16104 [28:42:54<39:47:49, 14.50s/it]

 39%|███▊      | 6223/16104 [28:43:05<36:40:12, 13.36s/it]

 39%|███▊      | 6224/16104 [28:43:22<40:06:27, 14.61s/it]

 39%|███▊      | 6225/16104 [28:43:38<41:35:04, 15.15s/it]

 39%|███▊      | 6226/16104 [28:43:58<45:28:09, 16.57s/it]
{'loss': 0.4456, 'learning_rate': 1.404040053219758e-06, 'rewards/chosen': -1.3844900131225586, 'rewards/rejected': -2.2553870677948, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8708972930908203, 'policy_logps/rejected': -240.08636474609375, 'policy_logps/chosen': -270.3472900390625, 'referece_logps/rejected': -217.532470703125, 'referece_logps/chosen': -256.50238037109375, 'logits/rejected': -0.3417907655239105, 'logits/chosen': -0.3969554305076599, 'epoch': 2.32}


 39%|███▊      | 6228/16104 [28:44:30<43:49:38, 15.98s/it]

 39%|███▊      | 6229/16104 [28:44:47<44:48:13, 16.33s/it]

 39%|███▊      | 6230/16104 [28:45:00<42:17:40, 15.42s/it]

 39%|███▊      | 6231/16104 [28:45:13<40:11:34, 14.66s/it]

 39%|███▊      | 6232/16104 [28:45:30<42:26:51, 15.48s/it]

 39%|███▊      | 6233/16104 [28:45:50<46:07:22, 16.82s/it]

 39%|███▊      | 6234/16104 [28:46:08<46:35:59, 17.00s/it]

 39%|███▊      | 6235/16104 [28:46:22<44:07:04, 16.09s/it]

 39%|███▊      | 6236/16104 [28:46:35<41:55:25, 15.29s/it]

 39%|███▊      | 6237/16104 [28:46:49<40:23:46, 14.74s/it]
{'loss': 0.3179, 'learning_rate': 1.4020153022970865e-06, 'rewards/chosen': -1.6687335968017578, 'rewards/rejected': -3.0808496475219727, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4121164083480835, 'policy_logps/rejected': -441.8698425292969, 'policy_logps/chosen': -289.9151306152344, 'referece_logps/rejected': -411.0613098144531, 'referece_logps/chosen': -273.227783203125, 'logits/rejected': -0.7368482351303101, 'logits/chosen': -0.5433836579322815, 'epoch': 2.32}


 39%|███▊      | 6239/16104 [28:47:22<43:13:40, 15.78s/it]

 39%|███▊      | 6240/16104 [28:47:35<40:36:34, 14.82s/it]
{'loss': 0.2993, 'learning_rate': 1.4014627555759686e-06, 'rewards/chosen': -1.387428879737854, 'rewards/rejected': -2.728817939758301, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3413891792297363, 'policy_logps/rejected': -353.2181701660156, 'policy_logps/chosen': -416.11505126953125, 'referece_logps/rejected': -325.92999267578125, 'referece_logps/chosen': -402.2408142089844, 'logits/rejected': -0.23342439532279968, 'logits/chosen': -0.5218446850776672, 'epoch': 2.32}

 39%|███▉      | 6241/16104 [28:47:51<42:10:28, 15.39s/it]

 39%|███▉      | 6242/16104 [28:48:11<45:48:10, 16.72s/it]

 39%|███▉      | 6243/16104 [28:48:28<45:30:04, 16.61s/it]

 39%|███▉      | 6244/16104 [28:48:48<48:19:26, 17.64s/it]

 39%|███▉      | 6245/16104 [28:49:08<50:13:05, 18.34s/it]

 39%|███▉      | 6246/16104 [28:49:27<51:24:19, 18.77s/it]


 39%|███▉      | 6248/16104 [28:50:05<51:18:47, 18.74s/it]
{'loss': 0.4482, 'learning_rate': 1.3999885836446104e-06, 'rewards/chosen': -2.5167782306671143, 'rewards/rejected': -3.5930051803588867, 'rewards/accuracies': 0.5, 'rewards/margins': 1.0762267112731934, 'policy_logps/rejected': -394.79522705078125, 'policy_logps/chosen': -382.031982421875, 'referece_logps/rejected': -358.86517333984375, 'referece_logps/chosen': -356.8641662597656, 'logits/rejected': -0.4019366204738617, 'logits/chosen': -0.4524625539779663, 'epoch': 2.33}


 39%|███▉      | 6250/16104 [28:50:45<52:58:25, 19.35s/it]

 39%|███▉      | 6251/16104 [28:51:01<50:14:13, 18.36s/it]

 39%|███▉      | 6252/16104 [28:51:22<52:14:14, 19.09s/it]
{'loss': 0.2452, 'learning_rate': 1.39925110911433e-06, 'rewards/chosen': -1.9098317623138428, 'rewards/rejected': -4.4914751052856445, 'rewards/accuracies': 0.75, 'rewards/margins': 2.581643581390381, 'policy_logps/rejected': -248.34951782226562, 'policy_logps/chosen': -315.14483642578125, 'referece_logps/rejected': -203.43475341796875, 'referece_logps/chosen': -296.0464782714844, 'logits/rejected': -0.196909561753273, 'logits/chosen': -0.19220110774040222, 'epoch': 2.33}


 39%|███▉      | 6254/16104 [28:52:05<55:29:15, 20.28s/it]
[2024-04-06 20:16:19,595] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4251, 'learning_rate': 1.3988822749168366e-06, 'rewards/chosen': -1.5972282886505127, 'rewards/rejected': -4.1251020431518555, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5278735160827637, 'policy_logps/rejected': -562.54443359375, 'policy_logps/chosen': -478.108642578125, 'referece_logps/rejected': -521.2933959960938, 'referece_logps/chosen': -462.1363830566406, 'logits/rejected': 1.117100477218628, 'logits/chosen': 1.0736247301101685, 'epoch': 2.33}


 39%|███▉      | 6256/16104 [28:52:37<48:28:24, 17.72s/it]
[2024-04-06 20:16:51,153] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 39%|███▉      | 6257/16104 [28:52:55<49:02:20, 17.93s/it]
{'loss': 0.338, 'learning_rate': 1.3983289026230032e-06, 'rewards/chosen': -1.8294247388839722, 'rewards/rejected': -3.8586606979370117, 'rewards/accuracies': 0.875, 'rewards/margins': 2.02923583984375, 'policy_logps/rejected': -437.0311279296875, 'policy_logps/chosen': -351.4557800292969, 'referece_logps/rejected': -398.44451904296875, 'referece_logps/chosen': -333.1615295410156, 'logits/rejected': -0.25355732440948486, 'logits/chosen': -0.11993981152772903, 'epoch': 2.33}


 39%|███▉      | 6259/16104 [28:53:29<48:04:31, 17.58s/it]

 39%|███▉      | 6260/16104 [28:53:45<46:51:04, 17.13s/it]

 39%|███▉      | 6261/16104 [28:54:05<49:41:41, 18.18s/it]
[2024-04-06 20:18:20,038] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5462, 'learning_rate': 1.3975908473491164e-06, 'rewards/chosen': -1.6666326522827148, 'rewards/rejected': -3.239190101623535, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5725576877593994, 'policy_logps/rejected': -432.22900390625, 'policy_logps/chosen': -413.7247619628906, 'referece_logps/rejected': -399.83709716796875, 'referece_logps/chosen': -397.05841064453125, 'logits/rejected': 0.2463512420654297, 'logits/chosen': 0.04435873031616211, 'epoch': 2.33}

 39%|███▉      | 6262/16104 [28:54:16<43:35:13, 15.94s/it]


 39%|███▉      | 6264/16104 [28:54:53<47:31:07, 17.38s/it]

 39%|███▉      | 6265/16104 [28:55:06<44:04:39, 16.13s/it]
{'loss': 0.3625, 'learning_rate': 1.3968525347430947e-06, 'rewards/chosen': -1.379351019859314, 'rewards/rejected': -3.1240758895874023, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7447251081466675, 'policy_logps/rejected': -490.10626220703125, 'policy_logps/chosen': -433.1365051269531, 'referece_logps/rejected': -458.865478515625, 'referece_logps/chosen': -419.34295654296875, 'logits/rejected': 0.07713586837053299, 'logits/chosen': 0.16759130358695984, 'epoch': 2.33}

 39%|███▉      | 6266/16104 [28:55:26<46:57:53, 17.19s/it]


 39%|███▉      | 6268/16104 [28:56:01<46:39:02, 17.07s/it]

 39%|███▉      | 6269/16104 [28:56:22<50:08:28, 18.35s/it]
{'loss': 0.6301, 'learning_rate': 1.3961139652827947e-06, 'rewards/chosen': -1.6705012321472168, 'rewards/rejected': -3.3116228580474854, 'rewards/accuracies': 0.625, 'rewards/margins': 1.6411216259002686, 'policy_logps/rejected': -434.0173034667969, 'policy_logps/chosen': -419.1888427734375, 'referece_logps/rejected': -400.9010925292969, 'referece_logps/chosen': -402.48382568359375, 'logits/rejected': 0.3842959403991699, 'logits/chosen': 0.36591005325317383, 'epoch': 2.34}


 39%|███▉      | 6271/16104 [28:56:53<45:33:12, 16.68s/it]

 39%|███▉      | 6272/16104 [28:57:10<45:51:09, 16.79s/it]

 39%|███▉      | 6273/16104 [28:57:28<46:44:10, 17.11s/it]
{'loss': 0.4078, 'learning_rate': 1.3953751394462393e-06, 'rewards/chosen': -1.2090970277786255, 'rewards/rejected': -2.544459581375122, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3353625535964966, 'policy_logps/rejected': -463.66973876953125, 'policy_logps/chosen': -383.84100341796875, 'referece_logps/rejected': -438.2251281738281, 'referece_logps/chosen': -371.7500305175781, 'logits/rejected': -0.9427968859672546, 'logits/chosen': -0.7239540815353394, 'epoch': 2.34}


 39%|███▉      | 6275/16104 [28:58:06<49:33:41, 18.15s/it]
{'loss': 0.4975, 'learning_rate': 1.3950056305362937e-06, 'rewards/chosen': -1.8145769834518433, 'rewards/rejected': -2.599972724914551, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7853957414627075, 'policy_logps/rejected': -406.749755859375, 'policy_logps/chosen': -326.9397888183594, 'referece_logps/rejected': -380.75006103515625, 'referece_logps/chosen': -308.7940368652344, 'logits/rejected': -0.057693615555763245, 'logits/chosen': -0.04757644236087799, 'epoch': 2.34}


 39%|███▉      | 6277/16104 [28:58:43<50:34:05, 18.52s/it]

 39%|███▉      | 6278/16104 [28:58:59<48:29:37, 17.77s/it]

 39%|███▉      | 6279/16104 [28:59:15<47:08:15, 17.27s/it]
{'loss': 0.3922, 'learning_rate': 1.3942664210320123e-06, 'rewards/chosen': -1.1397758722305298, 'rewards/rejected': -2.4140429496765137, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2742669582366943, 'policy_logps/rejected': -426.1081237792969, 'policy_logps/chosen': -372.7332458496094, 'referece_logps/rejected': -401.96771240234375, 'referece_logps/chosen': -361.33544921875, 'logits/rejected': -0.26521235704421997, 'logits/chosen': -0.07318544387817383, 'epoch': 2.34}


 39%|███▉      | 6281/16104 [28:59:54<49:48:43, 18.26s/it]

 39%|███▉      | 6282/16104 [29:00:10<47:56:19, 17.57s/it]

 39%|███▉      | 6283/16104 [29:00:29<49:35:09, 18.18s/it]
{'loss': 0.4717, 'learning_rate': 1.3935269563472588e-06, 'rewards/chosen': -1.3482197523117065, 'rewards/rejected': -1.982201099395752, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6339814066886902, 'policy_logps/rejected': -408.64678955078125, 'policy_logps/chosen': -324.06475830078125, 'referece_logps/rejected': -388.8247375488281, 'referece_logps/chosen': -310.58258056640625, 'logits/rejected': -0.6084377765655518, 'logits/chosen': -0.4235685467720032, 'epoch': 2.34}


 39%|███▉      | 6285/16104 [29:00:56<42:29:36, 15.58s/it]
{'loss': 0.3769, 'learning_rate': 1.393157128461762e-06, 'rewards/chosen': -1.0204296112060547, 'rewards/rejected': -2.244361639022827, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2239317893981934, 'policy_logps/rejected': -407.15032958984375, 'policy_logps/chosen': -501.5566711425781, 'referece_logps/rejected': -384.70672607421875, 'referece_logps/chosen': -491.3524169921875, 'logits/rejected': -0.17532917857170105, 'logits/chosen': -0.17827051877975464, 'epoch': 2.34}
[2024-04-06 20:25:30,713] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 39%|███▉      | 6286/16104 [29:01:16<46:28:19, 17.04s/it]

 39%|███▉      | 6287/16104 [29:01:36<49:03:52, 17.99s/it]

 39%|███▉      | 6288/16104 [29:01:53<47:48:12, 17.53s/it]

 39%|███▉      | 6289/16104 [29:02:11<48:14:52, 17.70s/it]


 39%|███▉      | 6291/16104 [29:02:48<49:11:12, 18.04s/it]

 39%|███▉      | 6292/16104 [29:03:08<50:57:03, 18.69s/it]

 39%|███▉      | 6293/16104 [29:03:24<48:32:35, 17.81s/it]

 39%|███▉      | 6294/16104 [29:03:43<49:59:17, 18.34s/it]

 39%|███▉      | 6295/16104 [29:03:55<44:48:32, 16.45s/it]

 39%|███▉      | 6296/16104 [29:04:12<44:55:15, 16.49s/it]
{'loss': 0.2946, 'learning_rate': 1.3911219395671582e-06, 'rewards/chosen': -1.7462208271026611, 'rewards/rejected': -3.0486295223236084, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3024089336395264, 'policy_logps/rejected': -331.72454833984375, 'policy_logps/chosen': -316.58245849609375, 'referece_logps/rejected': -301.2382507324219, 'referece_logps/chosen': -299.1202087402344, 'logits/rejected': -0.9493755102157593, 'logits/chosen': -0.9343394041061401, 'epoch': 2.35}


 39%|███▉      | 6298/16104 [29:04:46<45:44:38, 16.79s/it]
{'loss': 0.4161, 'learning_rate': 1.390751699250186e-06, 'rewards/chosen': -0.7260658144950867, 'rewards/rejected': -2.707338809967041, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9812731742858887, 'policy_logps/rejected': -370.036865234375, 'policy_logps/chosen': -420.216552734375, 'referece_logps/rejected': -342.96343994140625, 'referece_logps/chosen': -412.9559326171875, 'logits/rejected': -0.0121842622756958, 'logits/chosen': -0.019962675869464874, 'epoch': 2.35}


 39%|███▉      | 6300/16104 [29:05:10<39:14:54, 14.41s/it]
{'loss': 0.4733, 'learning_rate': 1.3903813957068005e-06, 'rewards/chosen': -1.129964828491211, 'rewards/rejected': -3.058403253555298, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9284385442733765, 'policy_logps/rejected': -533.4225463867188, 'policy_logps/chosen': -566.0023803710938, 'referece_logps/rejected': -502.83843994140625, 'referece_logps/chosen': -554.7027587890625, 'logits/rejected': 0.16103453934192657, 'logits/chosen': 0.379263699054718, 'epoch': 2.35}

 39%|███▉      | 6301/16104 [29:05:25<39:37:02, 14.55s/it]

 39%|███▉      | 6302/16104 [29:05:46<45:16:15, 16.63s/it]

 39%|███▉      | 6303/16104 [29:05:59<41:43:08, 15.32s/it]

 39%|███▉      | 6304/16104 [29:06:13<41:02:11, 15.07s/it]

 39%|███▉      | 6305/16104 [29:06:31<43:12:45, 15.88s/it]

 39%|███▉      | 6306/16104 [29:06:49<44:53:41, 16.50s/it]

 39%|███▉      | 6307/16104 [29:07:09<47:38:26, 17.51s/it]

 39%|███▉      | 6308/16104 [29:07:21<43:40:20, 16.05s/it]


 39%|███▉      | 6310/16104 [29:07:58<46:07:35, 16.95s/it]
{'loss': 0.4166, 'learning_rate': 1.3885289316911492e-06, 'rewards/chosen': -1.9690479040145874, 'rewards/rejected': -3.363050699234009, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3940030336380005, 'policy_logps/rejected': -279.72674560546875, 'policy_logps/chosen': -234.773193359375, 'referece_logps/rejected': -246.09625244140625, 'referece_logps/chosen': -215.0827178955078, 'logits/rejected': -0.9362874627113342, 'logits/chosen': -0.7752530574798584, 'epoch': 2.35}


 39%|███▉      | 6312/16104 [29:08:28<43:49:54, 16.11s/it]
{'loss': 0.4934, 'learning_rate': 1.3881582500479131e-06, 'rewards/chosen': -1.432012677192688, 'rewards/rejected': -3.1803340911865234, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7483211755752563, 'policy_logps/rejected': -337.1062927246094, 'policy_logps/chosen': -404.83050537109375, 'referece_logps/rejected': -305.3029479980469, 'referece_logps/chosen': -390.5103454589844, 'logits/rejected': 0.5651987791061401, 'logits/chosen': 0.42440706491470337, 'epoch': 2.35}

 39%|███▉      | 6313/16104 [29:08:43<42:38:08, 15.68s/it]

 39%|███▉      | 6314/16104 [29:08:57<41:38:32, 15.31s/it]

 39%|███▉      | 6315/16104 [29:09:15<43:28:46, 15.99s/it]

 39%|███▉      | 6316/16104 [29:09:28<40:36:02, 14.93s/it]

 39%|███▉      | 6317/16104 [29:09:47<44:25:59, 16.34s/it]


 39%|███▉      | 6319/16104 [29:10:26<49:09:30, 18.09s/it]
{'loss': 0.2792, 'learning_rate': 1.3868603700869378e-06, 'rewards/chosen': -1.5262911319732666, 'rewards/rejected': -3.715181350708008, 'rewards/accuracies': 0.875, 'rewards/margins': 2.188889980316162, 'policy_logps/rejected': -227.30848693847656, 'policy_logps/chosen': -433.2422790527344, 'referece_logps/rejected': -190.1566925048828, 'referece_logps/chosen': -417.9794006347656, 'logits/rejected': -0.4063223898410797, 'logits/chosen': -0.40771713852882385, 'epoch': 2.35}

 39%|███▉      | 6320/16104 [29:10:45<50:06:19, 18.44s/it]

 39%|███▉      | 6321/16104 [29:11:01<47:38:18, 17.53s/it]


 39%|███▉      | 6323/16104 [29:11:31<42:58:01, 15.81s/it]
{'loss': 0.4214, 'learning_rate': 1.386118379947709e-06, 'rewards/chosen': -1.4222540855407715, 'rewards/rejected': -2.931973934173584, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5097200870513916, 'policy_logps/rejected': -400.3924560546875, 'policy_logps/chosen': -372.6867370605469, 'referece_logps/rejected': -371.0727233886719, 'referece_logps/chosen': -358.4641418457031, 'logits/rejected': -0.750273585319519, 'logits/chosen': -0.8809152841567993, 'epoch': 2.36}

 39%|███▉      | 6324/16104 [29:11:46<42:29:18, 15.64s/it]

 39%|███▉      | 6325/16104 [29:12:07<47:12:06, 17.38s/it]

 39%|███▉      | 6326/16104 [29:12:29<51:01:51, 18.79s/it]


 39%|███▉      | 6328/16104 [29:13:05<49:53:13, 18.37s/it]
{'loss': 0.4678, 'learning_rate': 1.3851905408984903e-06, 'rewards/chosen': -1.907531499862671, 'rewards/rejected': -1.9885469675064087, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08101539313793182, 'policy_logps/rejected': -351.20892333984375, 'policy_logps/chosen': -382.9377136230469, 'referece_logps/rejected': -331.3234558105469, 'referece_logps/chosen': -363.8623962402344, 'logits/rejected': -0.4178920090198517, 'logits/chosen': -0.5219259262084961, 'epoch': 2.36}


 39%|███▉      | 6330/16104 [29:13:38<46:49:05, 17.24s/it]
{'loss': 0.3376, 'learning_rate': 1.3848192961547393e-06, 'rewards/chosen': -1.3403327465057373, 'rewards/rejected': -3.542609691619873, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2022767066955566, 'policy_logps/rejected': -184.74468994140625, 'policy_logps/chosen': -292.9036865234375, 'referece_logps/rejected': -149.31858825683594, 'referece_logps/chosen': -279.5003356933594, 'logits/rejected': -0.38082849979400635, 'logits/chosen': -0.2952536940574646, 'epoch': 2.36}


 39%|███▉      | 6332/16104 [29:14:10<44:44:47, 16.48s/it]
{'loss': 0.2322, 'learning_rate': 1.38444798914448e-06, 'rewards/chosen': -1.0006027221679688, 'rewards/rejected': -3.1037564277648926, 'rewards/accuracies': 1.0, 'rewards/margins': 2.103153705596924, 'policy_logps/rejected': -405.0029602050781, 'policy_logps/chosen': -398.1081848144531, 'referece_logps/rejected': -373.96539306640625, 'referece_logps/chosen': -388.1021423339844, 'logits/rejected': -0.6864797472953796, 'logits/chosen': -0.5741856098175049, 'epoch': 2.36}

 39%|███▉      | 6333/16104 [29:14:22<40:39:45, 14.98s/it]

 39%|███▉      | 6334/16104 [29:14:36<39:55:47, 14.71s/it]

 39%|███▉      | 6335/16104 [29:14:50<39:09:36, 14.43s/it]

 39%|███▉      | 6336/16104 [29:15:07<41:51:57, 15.43s/it]

 39%|███▉      | 6337/16104 [29:15:23<42:14:00, 15.57s/it]


 39%|███▉      | 6339/16104 [29:15:51<39:32:00, 14.57s/it]

 39%|███▉      | 6340/16104 [29:16:05<39:07:27, 14.43s/it]
{'loss': 0.4582, 'learning_rate': 1.3829621396401133e-06, 'rewards/chosen': -2.10312557220459, 'rewards/rejected': -2.4738104343414307, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3706846237182617, 'policy_logps/rejected': -414.1766662597656, 'policy_logps/chosen': -329.892578125, 'referece_logps/rejected': -389.4385681152344, 'referece_logps/chosen': -308.861328125, 'logits/rejected': -0.3553348481655121, 'logits/chosen': -0.4313432574272156, 'epoch': 2.36}


 39%|███▉      | 6342/16104 [29:16:26<34:03:28, 12.56s/it]
{'loss': 0.4361, 'learning_rate': 1.3825905221987152e-06, 'rewards/chosen': -0.9632829427719116, 'rewards/rejected': -3.3771092891693115, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4138259887695312, 'policy_logps/rejected': -369.5697937011719, 'policy_logps/chosen': -495.18414306640625, 'referece_logps/rejected': -335.7987365722656, 'referece_logps/chosen': -485.55133056640625, 'logits/rejected': -0.4777980446815491, 'logits/chosen': -0.43334734439849854, 'epoch': 2.36}

 39%|███▉      | 6343/16104 [29:16:37<32:33:18, 12.01s/it]

 39%|███▉      | 6344/16104 [29:16:48<31:27:57, 11.61s/it]


 39%|███▉      | 6346/16104 [29:17:12<32:06:16, 11.84s/it]

 39%|███▉      | 6347/16104 [29:17:33<39:03:18, 14.41s/it]

 39%|███▉      | 6348/16104 [29:17:47<38:26:20, 14.18s/it]
{'loss': 0.4107, 'learning_rate': 1.3814752986798327e-06, 'rewards/chosen': -1.6988301277160645, 'rewards/rejected': -1.954557180404663, 'rewards/accuracies': 0.5, 'rewards/margins': 0.25572699308395386, 'policy_logps/rejected': -520.47412109375, 'policy_logps/chosen': -486.45416259765625, 'referece_logps/rejected': -500.9285583496094, 'referece_logps/chosen': -469.4658508300781, 'logits/rejected': -0.1343604177236557, 'logits/chosen': 0.03391468524932861, 'epoch': 2.37}


 39%|███▉      | 6350/16104 [29:18:20<41:39:03, 15.37s/it]
{'loss': 0.3712, 'learning_rate': 1.3811034339758098e-06, 'rewards/chosen': -1.3824962377548218, 'rewards/rejected': -3.4181251525878906, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0356292724609375, 'policy_logps/rejected': -412.47821044921875, 'policy_logps/chosen': -471.0435791015625, 'referece_logps/rejected': -378.2969970703125, 'referece_logps/chosen': -457.2185974121094, 'logits/rejected': -0.18973806500434875, 'logits/chosen': -0.10243798792362213, 'epoch': 2.37}

 39%|███▉      | 6351/16104 [29:18:32<38:16:57, 14.13s/it]

 39%|███▉      | 6352/16104 [29:18:48<39:44:59, 14.67s/it]


 39%|███▉      | 6354/16104 [29:19:25<45:27:35, 16.79s/it]

 39%|███▉      | 6355/16104 [29:19:43<46:41:31, 17.24s/it]
{'loss': 0.3438, 'learning_rate': 1.3801735025619083e-06, 'rewards/chosen': -1.232997179031372, 'rewards/rejected': -3.495659828186035, 'rewards/accuracies': 0.875, 'rewards/margins': 2.262662649154663, 'policy_logps/rejected': -341.3016357421875, 'policy_logps/chosen': -414.45867919921875, 'referece_logps/rejected': -306.34503173828125, 'referece_logps/chosen': -402.1286926269531, 'logits/rejected': -0.7271264791488647, 'logits/chosen': -0.7197848558425903, 'epoch': 2.37}


 39%|███▉      | 6357/16104 [29:20:13<43:22:52, 16.02s/it]
{'loss': 0.2844, 'learning_rate': 1.379801422292803e-06, 'rewards/chosen': -1.453087568283081, 'rewards/rejected': -3.956608772277832, 'rewards/accuracies': 1.0, 'rewards/margins': 2.503520965576172, 'policy_logps/rejected': -239.3488311767578, 'policy_logps/chosen': -406.30682373046875, 'referece_logps/rejected': -199.78274536132812, 'referece_logps/chosen': -391.7759704589844, 'logits/rejected': -0.9437450170516968, 'logits/chosen': -0.8842607140541077, 'epoch': 2.37}

 39%|███▉      | 6358/16104 [29:20:26<40:51:53, 15.09s/it]


 39%|███▉      | 6360/16104 [29:20:55<41:06:37, 15.19s/it]

 39%|███▉      | 6361/16104 [29:21:15<44:35:21, 16.48s/it]

 40%|███▉      | 6362/16104 [29:21:29<42:53:33, 15.85s/it]

 40%|███▉      | 6363/16104 [29:21:43<41:00:26, 15.16s/it]

 40%|███▉      | 6364/16104 [29:21:59<42:02:59, 15.54s/it]

 40%|███▉      | 6365/16104 [29:22:19<45:31:43, 16.83s/it]

 40%|███▉      | 6366/16104 [29:22:39<47:57:46, 17.73s/it]
{'loss': 0.3004, 'learning_rate': 1.3781263014508411e-06, 'rewards/chosen': -1.8171366453170776, 'rewards/rejected': -3.2249162197113037, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4077792167663574, 'policy_logps/rejected': -240.36582946777344, 'policy_logps/chosen': -265.3519592285156, 'referece_logps/rejected': -208.11668395996094, 'referece_logps/chosen': -247.1805877685547, 'logits/rejected': -0.7074559330940247, 'logits/chosen': -0.6832969188690186, 'epoch': 2.37}

 40%|███▉      | 6367/16104 [29:22:58<48:51:43, 18.07s/it]

 40%|███▉      | 6368/16104 [29:23:18<50:23:11, 18.63s/it]

 40%|███▉      | 6369/16104 [29:23:34<48:41:55, 18.01s/it]

 40%|███▉      | 6370/16104 [29:23:54<49:53:01, 18.45s/it]

 40%|███▉      | 6371/16104 [29:24:15<52:02:18, 19.25s/it]

 40%|███▉      | 6372/16104 [29:24:34<52:24:00, 19.38s/it]


 40%|███▉      | 6374/16104 [29:25:03<45:50:49, 16.96s/it]
{'loss': 0.2135, 'learning_rate': 1.3766362648563166e-06, 'rewards/chosen': -2.1629555225372314, 'rewards/rejected': -5.208709239959717, 'rewards/accuracies': 1.0, 'rewards/margins': 3.0457537174224854, 'policy_logps/rejected': -328.61419677734375, 'policy_logps/chosen': -365.66802978515625, 'referece_logps/rejected': -276.5270690917969, 'referece_logps/chosen': -344.0384826660156, 'logits/rejected': -0.25008735060691833, 'logits/chosen': -0.21799802780151367, 'epoch': 2.37}


 40%|███▉      | 6376/16104 [29:25:33<43:53:28, 16.24s/it]
{'loss': 0.1606, 'learning_rate': 1.3762636032008854e-06, 'rewards/chosen': -1.2133452892303467, 'rewards/rejected': -3.3173673152923584, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1040220260620117, 'policy_logps/rejected': -331.5672912597656, 'policy_logps/chosen': -308.40142822265625, 'referece_logps/rejected': -298.39361572265625, 'referece_logps/chosen': -296.2679443359375, 'logits/rejected': -0.5530463457107544, 'logits/chosen': -0.3681575059890747, 'epoch': 2.38}
[2024-04-06 20:50:09,361] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 40%|███▉      | 6377/16104 [29:25:55<48:00:33, 17.77s/it]

 40%|███▉      | 6378/16104 [29:26:13<48:17:45, 17.88s/it]

 40%|███▉      | 6379/16104 [29:26:29<47:01:09, 17.41s/it]
{'loss': 0.321, 'learning_rate': 1.3757044965825798e-06, 'rewards/chosen': -1.7074191570281982, 'rewards/rejected': -3.1240806579589844, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4166616201400757, 'policy_logps/rejected': -339.1763916015625, 'policy_logps/chosen': -309.8658142089844, 'referece_logps/rejected': -307.935546875, 'referece_logps/chosen': -292.7916259765625, 'logits/rejected': -0.6330242156982422, 'logits/chosen': -0.5299700498580933, 'epoch': 2.38}

 40%|███▉      | 6380/16104 [29:26:42<43:04:29, 15.95s/it]


 40%|███▉      | 6382/16104 [29:27:14<41:43:09, 15.45s/it]

 40%|███▉      | 6383/16104 [29:27:33<45:03:58, 16.69s/it]
{'loss': 0.3689, 'learning_rate': 1.3749588083558579e-06, 'rewards/chosen': -0.8939037322998047, 'rewards/rejected': -2.253516912460327, 'rewards/accuracies': 0.75, 'rewards/margins': 1.359613060951233, 'policy_logps/rejected': -222.98046875, 'policy_logps/chosen': -333.123046875, 'referece_logps/rejected': -200.44532775878906, 'referece_logps/chosen': -324.1840515136719, 'logits/rejected': -0.11958005279302597, 'logits/chosen': -0.05583158880472183, 'epoch': 2.38}


 40%|███▉      | 6385/16104 [29:28:09<47:45:08, 17.69s/it]
[2024-04-06 20:52:23,943] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.2908, 'learning_rate': 1.3745858732058136e-06, 'rewards/chosen': -1.9523719549179077, 'rewards/rejected': -4.8062520027160645, 'rewards/accuracies': 0.875, 'rewards/margins': 2.853879928588867, 'policy_logps/rejected': -546.2354736328125, 'policy_logps/chosen': -601.63330078125, 'referece_logps/rejected': -498.1728820800781, 'referece_logps/chosen': -582.109619140625, 'logits/rejected': 0.22899764776229858, 'logits/chosen': 0.2995270788669586, 'epoch': 2.38}
[2024-04-06 20:52:45,486] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 40%|███▉      | 6386/16104 [29:28:31<50:52:07, 18.84s/it]


 40%|███▉      | 6388/16104 [29:29:09<51:25:51, 19.06s/it]
{'loss': 0.1464, 'learning_rate': 1.3740263568546054e-06, 'rewards/chosen': -2.230588674545288, 'rewards/rejected': -4.906723499298096, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6761350631713867, 'policy_logps/rejected': -259.4367980957031, 'policy_logps/chosen': -330.9106140136719, 'referece_logps/rejected': -210.3695526123047, 'referece_logps/chosen': -308.60467529296875, 'logits/rejected': -0.32749220728874207, 'logits/chosen': -0.5471996068954468, 'epoch': 2.38}

 40%|███▉      | 6389/16104 [29:29:29<51:30:50, 19.09s/it]

 40%|███▉      | 6390/16104 [29:29:48<52:02:08, 19.28s/it]
[2024-04-06 20:54:23,434] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 40%|███▉      | 6391/16104 [29:30:09<52:55:24, 19.62s/it]


 40%|███▉      | 6393/16104 [29:30:43<49:02:00, 18.18s/it]
{'loss': 0.4293, 'learning_rate': 1.3730935271025437e-06, 'rewards/chosen': -1.6872509717941284, 'rewards/rejected': -2.703605890274048, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0163549184799194, 'policy_logps/rejected': -546.2625732421875, 'policy_logps/chosen': -404.75982666015625, 'referece_logps/rejected': -519.2265625, 'referece_logps/chosen': -387.8872985839844, 'logits/rejected': -0.31466400623321533, 'logits/chosen': -0.20393629372119904, 'epoch': 2.38}


 40%|███▉      | 6395/16104 [29:31:12<44:32:05, 16.51s/it]
{'loss': 0.3744, 'learning_rate': 1.3727202895027941e-06, 'rewards/chosen': -2.054213047027588, 'rewards/rejected': -3.5433645248413086, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4891514778137207, 'policy_logps/rejected': -358.6476135253906, 'policy_logps/chosen': -521.5382080078125, 'referece_logps/rejected': -323.21392822265625, 'referece_logps/chosen': -500.9960632324219, 'logits/rejected': -0.9098937511444092, 'logits/chosen': -0.9123083353042603, 'epoch': 2.38}


 40%|███▉      | 6397/16104 [29:31:46<46:02:53, 17.08s/it]
{'loss': 0.3524, 'learning_rate': 1.3723469915942411e-06, 'rewards/chosen': -2.1320343017578125, 'rewards/rejected': -5.2728376388549805, 'rewards/accuracies': 1.0, 'rewards/margins': 3.140803098678589, 'policy_logps/rejected': -386.1417236328125, 'policy_logps/chosen': -361.0464172363281, 'referece_logps/rejected': -333.4133605957031, 'referece_logps/chosen': -339.7261047363281, 'logits/rejected': 0.685112714767456, 'logits/chosen': 0.8973619341850281, 'epoch': 2.38}


 40%|███▉      | 6399/16104 [29:32:17<44:40:53, 16.57s/it]
{'loss': 0.3804, 'learning_rate': 1.371973633437288e-06, 'rewards/chosen': -1.452895998954773, 'rewards/rejected': -3.93990159034729, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4870052337646484, 'policy_logps/rejected': -349.1848449707031, 'policy_logps/chosen': -444.07440185546875, 'referece_logps/rejected': -309.78582763671875, 'referece_logps/chosen': -429.54541015625, 'logits/rejected': -0.4237171709537506, 'logits/chosen': -0.43348070979118347, 'epoch': 2.38}

 40%|███▉      | 6400/16104 [29:32:37<47:05:31, 17.47s/it]


 40%|███▉      | 6402/16104 [29:33:06<42:09:27, 15.64s/it]

 40%|███▉      | 6403/16104 [29:33:22<42:39:28, 15.83s/it]
{'loss': 0.3803, 'learning_rate': 1.3712267366198385e-06, 'rewards/chosen': -1.0815556049346924, 'rewards/rejected': -2.767303466796875, 'rewards/accuracies': 0.875, 'rewards/margins': 1.685747742652893, 'policy_logps/rejected': -320.8269958496094, 'policy_logps/chosen': -445.11712646484375, 'referece_logps/rejected': -293.1539306640625, 'referece_logps/chosen': -434.30157470703125, 'logits/rejected': -0.3428787887096405, 'logits/chosen': -0.49716949462890625, 'epoch': 2.39}

 40%|███▉      | 6404/16104 [29:33:38<42:51:29, 15.91s/it]

 40%|███▉      | 6405/16104 [29:33:49<38:40:01, 14.35s/it]

 40%|███▉      | 6406/16104 [29:34:00<35:40:43, 13.24s/it]

 40%|███▉      | 6407/16104 [29:34:10<33:36:55, 12.48s/it]

 40%|███▉      | 6408/16104 [29:34:20<31:37:31, 11.74s/it]
[2024-04-06 20:58:56,190] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 40%|███▉      | 6409/16104 [29:34:42<39:20:49, 14.61s/it]
[2024-04-06 20:59:16,987] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 40%|███▉      | 6410/16104 [29:35:02<44:20:25, 16.47s/it]

 40%|███▉      | 6411/16104 [29:35:20<45:01:20, 16.72s/it]


 40%|███▉      | 6413/16104 [29:35:56<47:30:37, 17.65s/it]
[2024-04-06 21:00:10,859] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5309, 'learning_rate': 1.3693584444592394e-06, 'rewards/chosen': -1.8695522546768188, 'rewards/rejected': -2.4012346267700195, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5316823720932007, 'policy_logps/rejected': -450.8722839355469, 'policy_logps/chosen': -468.1339111328125, 'referece_logps/rejected': -426.8599853515625, 'referece_logps/chosen': -449.43841552734375, 'logits/rejected': -0.0184963196516037, 'logits/chosen': -0.03799411654472351, 'epoch': 2.39}

 40%|███▉      | 6414/16104 [29:36:16<49:05:24, 18.24s/it]

 40%|███▉      | 6415/16104 [29:36:35<50:13:06, 18.66s/it]

 40%|███▉      | 6416/16104 [29:36:57<52:36:48, 19.55s/it]

 40%|███▉      | 6417/16104 [29:37:14<50:19:13, 18.70s/it]

 40%|███▉      | 6418/16104 [29:37:32<49:54:19, 18.55s/it]

 40%|███▉      | 6419/16104 [29:37:50<49:14:44, 18.31s/it]
[2024-04-06 21:02:24,112] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 40%|███▉      | 6420/16104 [29:38:09<50:22:58, 18.73s/it]

 40%|███▉      | 6421/16104 [29:38:25<47:52:11, 17.80s/it]

 40%|███▉      | 6422/16104 [29:38:41<46:07:34, 17.15s/it]

 40%|███▉      | 6423/16104 [29:39:00<47:39:00, 17.72s/it]

 40%|███▉      | 6424/16104 [29:39:15<45:57:11, 17.09s/it]

 40%|███▉      | 6425/16104 [29:39:35<48:07:14, 17.90s/it]

 40%|███▉      | 6426/16104 [29:39:48<43:50:29, 16.31s/it]

 40%|███▉      | 6427/16104 [29:40:02<41:49:40, 15.56s/it]

 40%|███▉      | 6428/16104 [29:40:21<45:08:59, 16.80s/it]

 40%|███▉      | 6429/16104 [29:40:34<41:57:08, 15.61s/it]

 40%|███▉      | 6430/16104 [29:40:45<38:03:24, 14.16s/it]

 40%|███▉      | 6431/16104 [29:41:05<42:57:33, 15.99s/it]

 40%|███▉      | 6432/16104 [29:41:17<39:43:04, 14.78s/it]

 40%|███▉      | 6433/16104 [29:41:37<43:43:08, 16.27s/it]

 40%|███▉      | 6434/16104 [29:41:53<43:50:37, 16.32s/it]

 40%|███▉      | 6435/16104 [29:42:12<45:47:47, 17.05s/it]

 40%|███▉      | 6436/16104 [29:42:28<44:46:18, 16.67s/it]

 40%|███▉      | 6437/16104 [29:42:48<47:13:41, 17.59s/it]

 40%|███▉      | 6438/16104 [29:43:05<47:21:24, 17.64s/it]

 40%|███▉      | 6439/16104 [29:43:26<50:01:20, 18.63s/it]

 40%|███▉      | 6440/16104 [29:43:45<50:28:39, 18.80s/it]

 40%|███▉      | 6441/16104 [29:44:04<49:55:50, 18.60s/it]

 40%|████      | 6442/16104 [29:44:22<49:43:45, 18.53s/it]

 40%|████      | 6443/16104 [29:44:40<49:27:41, 18.43s/it]

 40%|████      | 6444/16104 [29:44:59<50:08:47, 18.69s/it]

 40%|████      | 6445/16104 [29:45:18<50:12:20, 18.71s/it]

 40%|████      | 6446/16104 [29:45:30<44:28:31, 16.58s/it]

 40%|████      | 6447/16104 [29:45:43<41:56:36, 15.64s/it]

 40%|████      | 6448/16104 [29:46:02<44:25:02, 16.56s/it]

 40%|████      | 6449/16104 [29:46:13<39:40:15, 14.79s/it]

 40%|████      | 6450/16104 [29:46:30<41:54:27, 15.63s/it]


 40%|████      | 6452/16104 [29:47:07<45:51:35, 17.10s/it]
{'loss': 0.2909, 'learning_rate': 1.3620578986009409e-06, 'rewards/chosen': -0.8510482907295227, 'rewards/rejected': -3.705933094024658, 'rewards/accuracies': 1.0, 'rewards/margins': 2.854884624481201, 'policy_logps/rejected': -571.0580444335938, 'policy_logps/chosen': -413.6355285644531, 'referece_logps/rejected': -533.9986572265625, 'referece_logps/chosen': -405.12506103515625, 'logits/rejected': -0.4052869379520416, 'logits/chosen': -0.2363564372062683, 'epoch': 2.4}

 40%|████      | 6453/16104 [29:47:27<48:04:10, 17.93s/it]

 40%|████      | 6454/16104 [29:47:41<45:33:43, 17.00s/it]

 40%|████      | 6455/16104 [29:47:59<45:38:31, 17.03s/it]

 40%|████      | 6456/16104 [29:48:18<47:32:32, 17.74s/it]

 40%|████      | 6457/16104 [29:48:37<48:55:01, 18.25s/it]

 40%|████      | 6458/16104 [29:48:48<42:58:55, 16.04s/it]

 40%|████      | 6459/16104 [29:49:01<39:58:47, 14.92s/it]


 40%|████      | 6461/16104 [29:49:41<47:14:58, 17.64s/it]
{'loss': 0.4307, 'learning_rate': 1.3603699773692697e-06, 'rewards/chosen': -2.359574794769287, 'rewards/rejected': -3.6896653175354004, 'rewards/accuracies': 0.5, 'rewards/margins': 1.3300902843475342, 'policy_logps/rejected': -464.91497802734375, 'policy_logps/chosen': -273.1997985839844, 'referece_logps/rejected': -428.01837158203125, 'referece_logps/chosen': -249.60401916503906, 'logits/rejected': -1.9017488956451416, 'logits/chosen': -1.6758791208267212, 'epoch': 2.41}
[2024-04-06 21:14:17,898] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 40%|████      | 6463/16104 [29:50:23<51:37:32, 19.28s/it]
[2024-04-06 21:14:37,761] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.333, 'learning_rate': 1.3599947232137807e-06, 'rewards/chosen': -1.6287918090820312, 'rewards/rejected': -3.402444362640381, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7736525535583496, 'policy_logps/rejected': -348.9112243652344, 'policy_logps/chosen': -421.8272399902344, 'referece_logps/rejected': -314.8867492675781, 'referece_logps/chosen': -405.5393371582031, 'logits/rejected': 0.4520612061023712, 'logits/chosen': 0.4807758331298828, 'epoch': 2.41}

 40%|████      | 6464/16104 [29:50:38<48:24:34, 18.08s/it]

 40%|████      | 6465/16104 [29:50:50<43:13:48, 16.15s/it]

 40%|████      | 6466/16104 [29:51:01<38:47:02, 14.49s/it]

 40%|████      | 6467/16104 [29:51:14<37:55:21, 14.17s/it]

 40%|████      | 6468/16104 [29:51:29<38:32:01, 14.40s/it]

 40%|████      | 6469/16104 [29:51:44<39:09:31, 14.63s/it]

 40%|████      | 6470/16104 [29:52:00<39:47:41, 14.87s/it]

 40%|████      | 6471/16104 [29:52:19<43:10:36, 16.14s/it]

 40%|████      | 6472/16104 [29:52:36<44:19:06, 16.56s/it]

 40%|████      | 6473/16104 [29:52:57<47:27:30, 17.74s/it]

 40%|████      | 6474/16104 [29:53:08<42:00:35, 15.70s/it]

 40%|████      | 6475/16104 [29:53:22<41:11:32, 15.40s/it]

 40%|████      | 6476/16104 [29:53:33<37:26:32, 14.00s/it]

 40%|████      | 6477/16104 [29:53:48<38:00:11, 14.21s/it]

 40%|████      | 6478/16104 [29:54:02<37:43:37, 14.11s/it]

 40%|████      | 6479/16104 [29:54:13<35:20:28, 13.22s/it]

 40%|████      | 6480/16104 [29:54:31<39:15:50, 14.69s/it]

 40%|████      | 6481/16104 [29:54:43<36:54:43, 13.81s/it]

 40%|████      | 6482/16104 [29:54:55<35:39:37, 13.34s/it]

 40%|████      | 6483/16104 [29:55:15<40:50:34, 15.28s/it]

 40%|████      | 6484/16104 [29:55:36<45:36:09, 17.07s/it]

 40%|████      | 6485/16104 [29:55:55<46:47:30, 17.51s/it]

 40%|████      | 6486/16104 [29:56:07<42:53:24, 16.05s/it]

 40%|████      | 6487/16104 [29:56:20<40:27:17, 15.14s/it]

 40%|████      | 6488/16104 [29:56:36<40:58:39, 15.34s/it]

 40%|████      | 6489/16104 [29:56:48<37:58:34, 14.22s/it]


 40%|████      | 6491/16104 [29:57:17<38:26:41, 14.40s/it]
{'loss': 0.344, 'learning_rate': 1.354735076461003e-06, 'rewards/chosen': -0.9199941754341125, 'rewards/rejected': -2.948935031890869, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0289409160614014, 'policy_logps/rejected': -323.0802001953125, 'policy_logps/chosen': -316.7833557128906, 'referece_logps/rejected': -293.5908203125, 'referece_logps/chosen': -307.58343505859375, 'logits/rejected': -0.848655641078949, 'logits/chosen': -0.8108729124069214, 'epoch': 2.42}

 40%|████      | 6492/16104 [29:57:37<42:48:48, 16.04s/it]

 40%|████      | 6493/16104 [29:57:58<46:52:51, 17.56s/it]

 40%|████      | 6494/16104 [29:58:09<41:28:40, 15.54s/it]

 40%|████      | 6495/16104 [29:58:31<46:23:02, 17.38s/it]

 40%|████      | 6496/16104 [29:58:45<43:27:27, 16.28s/it]

 40%|████      | 6497/16104 [29:59:03<45:02:41, 16.88s/it]

 40%|████      | 6498/16104 [29:59:23<47:56:55, 17.97s/it]

 40%|████      | 6499/16104 [29:59:41<47:18:21, 17.73s/it]

 40%|████      | 6500/16104 [29:59:55<44:31:39, 16.69s/it]


 40%|████      | 6502/16104 [30:00:52<58:46:09, 22.03s/it]
[2024-04-06 21:25:06,303] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 40%|████      | 6503/16104 [30:01:10<55:37:34, 20.86s/it]
[2024-04-06 21:25:24,417] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3361, 'learning_rate': 1.3524774884884954e-06, 'rewards/chosen': -1.5290085077285767, 'rewards/rejected': -2.267259120941162, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7382507920265198, 'policy_logps/rejected': -324.58709716796875, 'policy_logps/chosen': -378.3305358886719, 'referece_logps/rejected': -301.91448974609375, 'referece_logps/chosen': -363.0404357910156, 'logits/rejected': -0.6660274267196655, 'logits/chosen': -0.7818537354469299, 'epoch': 2.42}

 40%|████      | 6504/16104 [30:01:30<54:47:56, 20.55s/it]

 40%|████      | 6505/16104 [30:01:42<48:25:19, 18.16s/it]

 40%|████      | 6506/16104 [30:01:53<42:28:18, 15.93s/it]

 40%|████      | 6507/16104 [30:02:08<42:10:10, 15.82s/it]

 40%|████      | 6508/16104 [30:02:20<38:53:46, 14.59s/it]


 40%|████      | 6510/16104 [30:02:52<41:33:29, 15.59s/it]

 40%|████      | 6511/16104 [30:03:07<41:05:56, 15.42s/it]

 40%|████      | 6512/16104 [30:03:26<44:08:18, 16.57s/it]

 40%|████      | 6513/16104 [30:03:41<42:31:20, 15.96s/it]
{'loss': 0.4455, 'learning_rate': 1.3505945962026064e-06, 'rewards/chosen': -1.249476671218872, 'rewards/rejected': -3.2326862812042236, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9832096099853516, 'policy_logps/rejected': -366.5789794921875, 'policy_logps/chosen': -383.0451354980469, 'referece_logps/rejected': -334.2520751953125, 'referece_logps/chosen': -370.55035400390625, 'logits/rejected': -0.007115982472896576, 'logits/chosen': -0.09242729842662811, 'epoch': 2.43}

 40%|████      | 6514/16104 [30:03:58<43:37:21, 16.38s/it]


 40%|████      | 6516/16104 [30:04:35<46:06:45, 17.31s/it]

 40%|████      | 6517/16104 [30:04:53<46:52:38, 17.60s/it]
{'loss': 0.3326, 'learning_rate': 1.3498410417607013e-06, 'rewards/chosen': -1.7668828964233398, 'rewards/rejected': -3.510636568069458, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7437537908554077, 'policy_logps/rejected': -251.9506378173828, 'policy_logps/chosen': -452.1708984375, 'referece_logps/rejected': -216.84425354003906, 'referece_logps/chosen': -434.5020751953125, 'logits/rejected': -0.31586408615112305, 'logits/chosen': -0.3024698495864868, 'epoch': 2.43}


 40%|████      | 6519/16104 [30:05:23<43:05:19, 16.18s/it]
{'loss': 0.314, 'learning_rate': 1.3494641795990985e-06, 'rewards/chosen': -1.659206748008728, 'rewards/rejected': -4.204935550689697, 'rewards/accuracies': 1.0, 'rewards/margins': 2.545729160308838, 'policy_logps/rejected': -435.5546569824219, 'policy_logps/chosen': -406.9105224609375, 'referece_logps/rejected': -393.50531005859375, 'referece_logps/chosen': -390.3184814453125, 'logits/rejected': -1.1790320873260498, 'logits/chosen': -1.2210270166397095, 'epoch': 2.43}
[2024-04-06 21:29:58,955] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 40%|████      | 6521/16104 [30:06:06<50:01:59, 18.80s/it]

 40%|████      | 6522/16104 [30:06:26<51:03:48, 19.18s/it]

 41%|████      | 6523/16104 [30:06:45<51:26:18, 19.33s/it]

 41%|████      | 6524/16104 [30:07:05<51:36:17, 19.39s/it]

 41%|████      | 6525/16104 [30:07:22<49:41:34, 18.68s/it]

 41%|████      | 6526/16104 [30:07:38<47:09:57, 17.73s/it]

 41%|████      | 6527/16104 [30:07:57<48:13:33, 18.13s/it]

 41%|████      | 6528/16104 [30:08:13<46:48:06, 17.59s/it]

 41%|████      | 6529/16104 [30:08:30<46:16:09, 17.40s/it]

 41%|████      | 6530/16104 [30:08:48<46:29:58, 17.48s/it]

 41%|████      | 6531/16104 [30:09:08<49:04:36, 18.46s/it]

 41%|████      | 6532/16104 [30:09:21<44:16:59, 16.65s/it]

 41%|████      | 6533/16104 [30:09:36<43:07:10, 16.22s/it]

 41%|████      | 6534/16104 [30:09:57<47:04:11, 17.71s/it]

 41%|████      | 6535/16104 [30:10:17<48:41:53, 18.32s/it]

 41%|████      | 6536/16104 [30:10:32<46:00:26, 17.31s/it]

 41%|████      | 6537/16104 [30:10:46<43:33:21, 16.39s/it]

 41%|████      | 6538/16104 [30:11:06<46:05:13, 17.34s/it]

 41%|████      | 6539/16104 [30:11:16<40:47:56, 15.36s/it]

 41%|████      | 6540/16104 [30:11:29<38:56:46, 14.66s/it]

 41%|████      | 6541/16104 [30:11:42<37:10:23, 13.99s/it]

 41%|████      | 6542/16104 [30:11:57<38:11:54, 14.38s/it]

 41%|████      | 6543/16104 [30:12:17<42:11:02, 15.88s/it]

 41%|████      | 6544/16104 [30:12:27<38:02:25, 14.32s/it]

 41%|████      | 6545/16104 [30:12:39<36:04:37, 13.59s/it]
{'loss': 0.3607, 'learning_rate': 1.3445598480394373e-06, 'rewards/chosen': -1.37086021900177, 'rewards/rejected': -2.4794700145721436, 'rewards/accuracies': 0.875, 'rewards/margins': 1.108609914779663, 'policy_logps/rejected': -347.29388427734375, 'policy_logps/chosen': -339.1341857910156, 'referece_logps/rejected': -322.49920654296875, 'referece_logps/chosen': -325.4255676269531, 'logits/rejected': -0.9061885476112366, 'logits/chosen': -0.9771167635917664, 'epoch': 2.44}


 41%|████      | 6547/16104 [30:13:17<43:37:24, 16.43s/it]

 41%|████      | 6548/16104 [30:13:38<46:35:38, 17.55s/it]

 41%|████      | 6549/16104 [30:13:57<48:07:41, 18.13s/it]

 41%|████      | 6550/16104 [30:14:10<44:09:31, 16.64s/it]

 41%|████      | 6551/16104 [30:14:23<40:36:59, 15.31s/it]

 41%|████      | 6552/16104 [30:14:40<42:03:35, 15.85s/it]

 41%|████      | 6553/16104 [30:14:56<42:15:39, 15.93s/it]

 41%|████      | 6554/16104 [30:15:15<45:13:26, 17.05s/it]

 41%|████      | 6555/16104 [30:15:36<47:59:04, 18.09s/it]
{'loss': 0.3254, 'learning_rate': 1.3426710504915742e-06, 'rewards/chosen': -0.9386162757873535, 'rewards/rejected': -2.166407823562622, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2277915477752686, 'policy_logps/rejected': -250.29571533203125, 'policy_logps/chosen': -333.3597412109375, 'referece_logps/rejected': -228.63165283203125, 'referece_logps/chosen': -323.9736022949219, 'logits/rejected': -0.2924231290817261, 'logits/chosen': -0.27129971981048584, 'epoch': 2.44}


 41%|████      | 6557/16104 [30:16:11<47:41:44, 17.99s/it]

 41%|████      | 6558/16104 [30:16:28<46:15:38, 17.45s/it]

 41%|████      | 6559/16104 [30:16:46<46:34:42, 17.57s/it]

 41%|████      | 6560/16104 [30:17:05<47:51:32, 18.05s/it]

 41%|████      | 6561/16104 [30:17:18<44:25:04, 16.76s/it]
{'loss': 0.3654, 'learning_rate': 1.341537106114388e-06, 'rewards/chosen': -1.7225010395050049, 'rewards/rejected': -2.899191379547119, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1766902208328247, 'policy_logps/rejected': -330.8937072753906, 'policy_logps/chosen': -388.8135070800781, 'referece_logps/rejected': -301.9017333984375, 'referece_logps/chosen': -371.5885009765625, 'logits/rejected': -0.24589405953884125, 'logits/chosen': -0.26234835386276245, 'epoch': 2.44}

 41%|████      | 6562/16104 [30:17:29<39:30:28, 14.91s/it]


 41%|████      | 6564/16104 [30:18:11<47:50:13, 18.05s/it]

 41%|████      | 6565/16104 [30:18:24<43:51:51, 16.55s/it]

 41%|████      | 6566/16104 [30:18:38<41:31:21, 15.67s/it]

 41%|████      | 6567/16104 [30:18:50<38:32:56, 14.55s/it]
{'loss': 0.399, 'learning_rate': 1.3404026643689856e-06, 'rewards/chosen': -1.3828266859054565, 'rewards/rejected': -3.1717445850372314, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7889177799224854, 'policy_logps/rejected': -321.7015380859375, 'policy_logps/chosen': -402.5445556640625, 'referece_logps/rejected': -289.98406982421875, 'referece_logps/chosen': -388.7162780761719, 'logits/rejected': 0.21057891845703125, 'logits/chosen': 0.22699058055877686, 'epoch': 2.45}


 41%|████      | 6569/16104 [30:19:18<36:52:26, 13.92s/it]

 41%|████      | 6570/16104 [30:19:28<34:18:30, 12.95s/it]
{'loss': 0.4804, 'learning_rate': 1.3398352574994396e-06, 'rewards/chosen': -1.5405917167663574, 'rewards/rejected': -2.7010645866394043, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1604726314544678, 'policy_logps/rejected': -359.4597473144531, 'policy_logps/chosen': -372.57403564453125, 'referece_logps/rejected': -332.4490661621094, 'referece_logps/chosen': -357.1680908203125, 'logits/rejected': -0.3571012318134308, 'logits/chosen': -0.25325629115104675, 'epoch': 2.45}


 41%|████      | 6572/16104 [30:19:50<31:17:04, 11.82s/it]

 41%|████      | 6573/16104 [30:20:08<36:15:14, 13.69s/it]

 41%|████      | 6574/16104 [30:20:30<42:58:11, 16.23s/it]

 41%|████      | 6575/16104 [30:20:50<45:47:22, 17.30s/it]

 41%|████      | 6576/16104 [30:21:04<43:30:58, 16.44s/it]
{'loss': 0.2875, 'learning_rate': 1.3387000727995263e-06, 'rewards/chosen': -1.4607088565826416, 'rewards/rejected': -4.666506290435791, 'rewards/accuracies': 1.0, 'rewards/margins': 3.2057971954345703, 'policy_logps/rejected': -498.6898193359375, 'policy_logps/chosen': -507.93218994140625, 'referece_logps/rejected': -452.0247802734375, 'referece_logps/chosen': -493.32513427734375, 'logits/rejected': -0.014412632212042809, 'logits/chosen': 0.048313215374946594, 'epoch': 2.45}


 41%|████      | 6578/16104 [30:21:39<44:50:57, 16.95s/it]

 41%|████      | 6579/16104 [30:21:56<45:09:50, 17.07s/it]

 41%|████      | 6580/16104 [30:22:13<44:20:30, 16.76s/it]

 41%|████      | 6581/16104 [30:22:31<45:44:04, 17.29s/it]

 41%|████      | 6582/16104 [30:22:52<48:38:47, 18.39s/it]
[2024-04-06 21:47:06,640] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████      | 6583/16104 [30:23:08<46:41:41, 17.66s/it]
[2024-04-06 21:47:22,578] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████      | 6584/16104 [30:23:19<41:07:19, 15.55s/it]
{'loss': 0.4492, 'learning_rate': 1.3371857262283103e-06, 'rewards/chosen': -1.784217357635498, 'rewards/rejected': -3.6426215171813965, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8584040403366089, 'policy_logps/rejected': -487.9139709472656, 'policy_logps/chosen': -469.52288818359375, 'referece_logps/rejected': -451.48779296875, 'referece_logps/chosen': -451.6807556152344, 'logits/rejected': 0.05945921316742897, 'logits/chosen': 0.16422350704669952, 'epoch': 2.45}


 41%|████      | 6586/16104 [30:23:42<36:31:39, 13.82s/it]

 41%|████      | 6587/16104 [30:23:59<38:34:42, 14.59s/it]

 41%|████      | 6588/16104 [30:24:16<40:53:47, 15.47s/it]

 41%|████      | 6589/16104 [30:24:28<38:07:27, 14.42s/it]
{'loss': 0.3887, 'learning_rate': 1.336238816080099e-06, 'rewards/chosen': -1.5568957328796387, 'rewards/rejected': -3.6209583282470703, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0640621185302734, 'policy_logps/rejected': -476.19427490234375, 'policy_logps/chosen': -473.9712829589844, 'referece_logps/rejected': -439.9847106933594, 'referece_logps/chosen': -458.40234375, 'logits/rejected': -0.13125833868980408, 'logits/chosen': -0.11304817348718643, 'epoch': 2.45}
[2024-04-06 21:49:04,055] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 41%|████      | 6591/16104 [30:25:11<47:26:45, 17.95s/it]
[2024-04-06 21:49:25,601] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████      | 6592/16104 [30:25:29<47:12:04, 17.86s/it]
[2024-04-06 21:49:43,253] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████      | 6593/16104 [30:25:48<48:35:25, 18.39s/it]

 41%|████      | 6594/16104 [30:26:08<49:49:18, 18.86s/it]

 41%|████      | 6595/16104 [30:26:29<51:12:19, 19.39s/it]

 41%|████      | 6596/16104 [30:26:48<51:19:22, 19.43s/it]

 41%|████      | 6597/16104 [30:27:01<45:44:32, 17.32s/it]

 41%|████      | 6598/16104 [30:27:19<46:34:46, 17.64s/it]

 41%|████      | 6599/16104 [30:27:40<49:14:44, 18.65s/it]
[2024-04-06 21:51:54,774] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5099, 'learning_rate': 1.334343976632198e-06, 'rewards/chosen': -1.8499324321746826, 'rewards/rejected': -2.8561956882476807, 'rewards/accuracies': 0.875, 'rewards/margins': 1.006263256072998, 'policy_logps/rejected': -475.5053405761719, 'policy_logps/chosen': -477.22198486328125, 'referece_logps/rejected': -446.9433898925781, 'referece_logps/chosen': -458.7226867675781, 'logits/rejected': -0.26348641514778137, 'logits/chosen': -0.29138126969337463, 'epoch': 2.46}
[2024-04-06 21:52:14,268] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 41%|████      | 6601/16104 [30:28:19<50:37:25, 19.18s/it]

 41%|████      | 6602/16104 [30:28:39<51:01:45, 19.33s/it]

 41%|████      | 6603/16104 [30:29:00<52:29:44, 19.89s/it]

 41%|████      | 6604/16104 [30:29:20<52:25:21, 19.87s/it]

 41%|████      | 6605/16104 [30:29:36<49:29:39, 18.76s/it]

 41%|████      | 6606/16104 [30:29:57<51:00:08, 19.33s/it]
[2024-04-06 21:54:11,621] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████      | 6607/16104 [30:30:19<53:11:36, 20.16s/it]
[2024-04-06 21:54:33,728] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████      | 6608/16104 [30:30:39<52:40:59, 19.97s/it]

 41%|████      | 6609/16104 [30:30:50<46:10:47, 17.51s/it]
[2024-04-06 21:55:05,015] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5505, 'learning_rate': 1.3324477847036994e-06, 'rewards/chosen': -1.1709860563278198, 'rewards/rejected': -1.5674595832824707, 'rewards/accuracies': 0.625, 'rewards/margins': 0.39647337794303894, 'policy_logps/rejected': -344.6415710449219, 'policy_logps/chosen': -385.3199462890625, 'referece_logps/rejected': -328.96697998046875, 'referece_logps/chosen': -373.6100769042969, 'logits/rejected': -0.12769274413585663, 'logits/chosen': -0.15993764996528625, 'epoch': 2.46}

 41%|████      | 6610/16104 [30:31:08<46:20:26, 17.57s/it]

 41%|████      | 6611/16104 [30:31:22<43:22:31, 16.45s/it]

 41%|████      | 6612/16104 [30:31:42<46:18:35, 17.56s/it]

 41%|████      | 6613/16104 [30:31:54<41:44:51, 15.84s/it]


 41%|████      | 6615/16104 [30:32:19<36:40:17, 13.91s/it]

 41%|████      | 6616/16104 [30:32:29<34:10:02, 12.96s/it]

 41%|████      | 6617/16104 [30:32:44<35:46:04, 13.57s/it]

 41%|████      | 6618/16104 [30:33:00<37:40:22, 14.30s/it]

 41%|████      | 6619/16104 [30:33:21<42:54:03, 16.28s/it]
[2024-04-06 21:57:35,902] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████      | 6620/16104 [30:33:37<42:19:36, 16.07s/it]

 41%|████      | 6621/16104 [30:33:48<38:09:45, 14.49s/it]

 41%|████      | 6622/16104 [30:34:01<37:30:45, 14.24s/it]

 41%|████      | 6623/16104 [30:34:20<40:53:05, 15.52s/it]

 41%|████      | 6624/16104 [30:34:41<45:02:11, 17.10s/it]

 41%|████      | 6625/16104 [30:34:51<39:56:31, 15.17s/it]

 41%|████      | 6626/16104 [30:35:02<36:20:56, 13.81s/it]

 41%|████      | 6627/16104 [30:35:13<33:56:55, 12.90s/it]

 41%|████      | 6628/16104 [30:35:25<33:32:04, 12.74s/it]

 41%|████      | 6629/16104 [30:35:41<36:05:15, 13.71s/it]

 41%|████      | 6630/16104 [30:36:01<41:20:52, 15.71s/it]

 41%|████      | 6631/16104 [30:36:21<44:36:56, 16.96s/it]
{'loss': 0.3579, 'learning_rate': 1.3282714395372301e-06, 'rewards/chosen': -2.3904342651367188, 'rewards/rejected': -3.6758315563201904, 'rewards/accuracies': 0.75, 'rewards/margins': 1.285396933555603, 'policy_logps/rejected': -416.14666748046875, 'policy_logps/chosen': -480.8947448730469, 'referece_logps/rejected': -379.38836669921875, 'referece_logps/chosen': -456.99041748046875, 'logits/rejected': -0.5160560607910156, 'logits/chosen': -0.5468342304229736, 'epoch': 2.47}


 41%|████      | 6633/16104 [30:36:50<41:28:50, 15.77s/it]
{'loss': 0.3806, 'learning_rate': 1.32789145186572e-06, 'rewards/chosen': -1.188647985458374, 'rewards/rejected': -2.3468964099884033, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1582486629486084, 'policy_logps/rejected': -184.80999755859375, 'policy_logps/chosen': -313.6752624511719, 'referece_logps/rejected': -161.34103393554688, 'referece_logps/chosen': -301.788818359375, 'logits/rejected': -0.3388543128967285, 'logits/chosen': -0.3424053192138672, 'epoch': 2.47}


 41%|████      | 6635/16104 [30:37:28<45:55:11, 17.46s/it]

 41%|████      | 6636/16104 [30:37:41<42:36:48, 16.20s/it]
{'loss': 0.3639, 'learning_rate': 1.3273213708992142e-06, 'rewards/chosen': -1.6935375928878784, 'rewards/rejected': -3.4900450706481934, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7965073585510254, 'policy_logps/rejected': -420.0387268066406, 'policy_logps/chosen': -379.13299560546875, 'referece_logps/rejected': -385.1383056640625, 'referece_logps/chosen': -362.1976318359375, 'logits/rejected': -0.8307508230209351, 'logits/chosen': -0.8726094365119934, 'epoch': 2.47}


 41%|████      | 6638/16104 [30:38:13<42:07:11, 16.02s/it]

 41%|████      | 6639/16104 [30:38:26<39:17:24, 14.94s/it]
{'loss': 0.3581, 'learning_rate': 1.3267511707661098e-06, 'rewards/chosen': -1.788124918937683, 'rewards/rejected': -3.473917245864868, 'rewards/accuracies': 0.75, 'rewards/margins': 1.685792326927185, 'policy_logps/rejected': -406.5885925292969, 'policy_logps/chosen': -401.9822998046875, 'referece_logps/rejected': -371.8493957519531, 'referece_logps/chosen': -384.1009826660156, 'logits/rejected': 0.1372232586145401, 'logits/chosen': 0.20289799571037292, 'epoch': 2.47}


 41%|████      | 6641/16104 [30:38:58<40:42:22, 15.49s/it]

 41%|████      | 6642/16104 [30:39:15<42:22:23, 16.12s/it]
{'loss': 0.2624, 'learning_rate': 1.326180851673997e-06, 'rewards/chosen': -0.8232455253601074, 'rewards/rejected': -3.5317578315734863, 'rewards/accuracies': 1.0, 'rewards/margins': 2.708512306213379, 'policy_logps/rejected': -340.8315734863281, 'policy_logps/chosen': -369.71337890625, 'referece_logps/rejected': -305.5140075683594, 'referece_logps/chosen': -361.48095703125, 'logits/rejected': -0.39960354566574097, 'logits/chosen': -0.25948649644851685, 'epoch': 2.47}

 41%|████▏     | 6643/16104 [30:39:33<43:19:14, 16.48s/it]

 41%|████▏     | 6644/16104 [30:39:45<39:58:45, 15.21s/it]

 41%|████▏     | 6645/16104 [30:40:07<45:31:44, 17.33s/it]


 41%|████▏     | 6647/16104 [30:40:30<37:48:40, 14.39s/it]

 41%|████▏     | 6648/16104 [30:40:48<40:32:33, 15.44s/it]

 41%|████▏     | 6649/16104 [30:41:01<38:53:08, 14.81s/it]
{'loss': 0.5506, 'learning_rate': 1.3248496456737878e-06, 'rewards/chosen': -1.5845551490783691, 'rewards/rejected': -2.838435173034668, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2538800239562988, 'policy_logps/rejected': -519.76416015625, 'policy_logps/chosen': -539.3843994140625, 'referece_logps/rejected': -491.3798828125, 'referece_logps/chosen': -523.5388793945312, 'logits/rejected': -0.07175394892692566, 'logits/chosen': 0.07697063684463501, 'epoch': 2.48}

 41%|████▏     | 6650/16104 [30:41:21<42:34:38, 16.21s/it]

 41%|████▏     | 6651/16104 [30:41:35<40:58:50, 15.61s/it]


 41%|████▏     | 6653/16104 [30:42:04<38:23:12, 14.62s/it]

 41%|████▏     | 6654/16104 [30:42:21<40:58:43, 15.61s/it]
{'loss': 0.4748, 'learning_rate': 1.323898389868788e-06, 'rewards/chosen': -1.6488006114959717, 'rewards/rejected': -2.2281060218811035, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5793052315711975, 'policy_logps/rejected': -435.7814025878906, 'policy_logps/chosen': -411.5465087890625, 'referece_logps/rejected': -413.50030517578125, 'referece_logps/chosen': -395.0585021972656, 'logits/rejected': -0.04856817051768303, 'logits/chosen': 0.05217813700437546, 'epoch': 2.48}

 41%|████▏     | 6655/16104 [30:42:41<44:11:23, 16.84s/it]

 41%|████▏     | 6656/16104 [30:42:59<44:59:58, 17.15s/it]


 41%|████▏     | 6658/16104 [30:43:30<41:52:35, 15.96s/it]

 41%|████▏     | 6659/16104 [30:43:42<38:29:16, 14.67s/it]

 41%|████▏     | 6660/16104 [30:43:52<35:21:55, 13.48s/it]

 41%|████▏     | 6661/16104 [30:44:08<36:40:23, 13.98s/it]
{'loss': 0.3788, 'learning_rate': 1.322566081662134e-06, 'rewards/chosen': -2.334059715270996, 'rewards/rejected': -4.147705554962158, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8136460781097412, 'policy_logps/rejected': -292.5987854003906, 'policy_logps/chosen': -395.91064453125, 'referece_logps/rejected': -251.12173461914062, 'referece_logps/chosen': -372.5700378417969, 'logits/rejected': -0.7050341367721558, 'logits/chosen': -0.8434845805168152, 'epoch': 2.48}


 41%|████▏     | 6663/16104 [30:44:46<43:16:40, 16.50s/it]

 41%|████▏     | 6664/16104 [30:45:02<43:30:19, 16.59s/it]

 41%|████▏     | 6665/16104 [30:45:16<41:05:22, 15.67s/it]
{'loss': 0.2854, 'learning_rate': 1.3218044754532956e-06, 'rewards/chosen': -1.870218276977539, 'rewards/rejected': -3.4129152297973633, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5426968336105347, 'policy_logps/rejected': -321.72064208984375, 'policy_logps/chosen': -382.66888427734375, 'referece_logps/rejected': -287.5915222167969, 'referece_logps/chosen': -363.9667053222656, 'logits/rejected': -0.2903900742530823, 'logits/chosen': -0.2269512116909027, 'epoch': 2.48}

 41%|████▏     | 6666/16104 [30:45:27<37:39:30, 14.36s/it]


 41%|████▏     | 6668/16104 [30:45:54<36:25:18, 13.90s/it]

 41%|████▏     | 6669/16104 [30:46:13<39:51:15, 15.21s/it]

 41%|████▏     | 6670/16104 [30:46:24<36:48:26, 14.05s/it]
{'loss': 0.3444, 'learning_rate': 1.3208521748548215e-06, 'rewards/chosen': -1.6623625755310059, 'rewards/rejected': -4.141487121582031, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4791245460510254, 'policy_logps/rejected': -601.6343383789062, 'policy_logps/chosen': -292.93048095703125, 'referece_logps/rejected': -560.219482421875, 'referece_logps/chosen': -276.3068542480469, 'logits/rejected': -0.7083660960197449, 'logits/chosen': -0.46779894828796387, 'epoch': 2.49}

 41%|████▏     | 6671/16104 [30:46:35<34:31:33, 13.18s/it]

 41%|████▏     | 6672/16104 [30:46:50<35:40:05, 13.61s/it]

 41%|████▏     | 6673/16104 [30:47:03<35:20:34, 13.49s/it]

 41%|████▏     | 6674/16104 [30:47:16<34:42:34, 13.25s/it]

 41%|████▏     | 6675/16104 [30:47:35<39:45:01, 15.18s/it]

 41%|████▏     | 6676/16104 [30:47:55<43:19:53, 16.55s/it]


 41%|████▏     | 6678/16104 [30:48:26<41:41:35, 15.92s/it]
{'loss': 0.459, 'learning_rate': 1.3193278193878354e-06, 'rewards/chosen': -1.4905422925949097, 'rewards/rejected': -4.337390899658203, 'rewards/accuracies': 0.75, 'rewards/margins': 2.846848964691162, 'policy_logps/rejected': -356.75665283203125, 'policy_logps/chosen': -469.92413330078125, 'referece_logps/rejected': -313.3827209472656, 'referece_logps/chosen': -455.0186767578125, 'logits/rejected': -0.49982181191444397, 'logits/chosen': -0.6013779044151306, 'epoch': 2.49}


 41%|████▏     | 6680/16104 [30:49:00<42:42:11, 16.31s/it]
{'loss': 0.3194, 'learning_rate': 1.3189466011931105e-06, 'rewards/chosen': -0.9197385311126709, 'rewards/rejected': -3.8972620964050293, 'rewards/accuracies': 0.875, 'rewards/margins': 2.9775235652923584, 'policy_logps/rejected': -476.05902099609375, 'policy_logps/chosen': -335.16607666015625, 'referece_logps/rejected': -437.08636474609375, 'referece_logps/chosen': -325.96868896484375, 'logits/rejected': 0.236631840467453, 'logits/chosen': 0.40187472105026245, 'epoch': 2.49}

 41%|████▏     | 6681/16104 [30:49:18<43:34:00, 16.64s/it]


 41%|████▏     | 6683/16104 [30:49:52<44:27:36, 16.99s/it]
{'loss': 0.376, 'learning_rate': 1.318374677155609e-06, 'rewards/chosen': -2.1902894973754883, 'rewards/rejected': -3.9465677738189697, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7562777996063232, 'policy_logps/rejected': -362.6793518066406, 'policy_logps/chosen': -415.82568359375, 'referece_logps/rejected': -323.21368408203125, 'referece_logps/chosen': -393.9228515625, 'logits/rejected': -0.8378573656082153, 'logits/chosen': -0.5854803919792175, 'epoch': 2.49}


 42%|████▏     | 6685/16104 [30:50:31<47:34:18, 18.18s/it]
{'loss': 0.3243, 'learning_rate': 1.317993330056969e-06, 'rewards/chosen': -1.5167847871780396, 'rewards/rejected': -2.6337363719940186, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1169513463974, 'policy_logps/rejected': -377.5404357910156, 'policy_logps/chosen': -541.4321899414062, 'referece_logps/rejected': -351.20306396484375, 'referece_logps/chosen': -526.2643432617188, 'logits/rejected': -0.0925644189119339, 'logits/chosen': -0.4526987671852112, 'epoch': 2.49}

 42%|████▏     | 6686/16104 [30:50:47<46:19:28, 17.71s/it]
[2024-04-06 22:15:24,022] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 42%|████▏     | 6688/16104 [30:51:26<48:06:22, 18.39s/it]
{'loss': 0.3996, 'learning_rate': 1.317421212952813e-06, 'rewards/chosen': -1.2414382696151733, 'rewards/rejected': -3.729641914367676, 'rewards/accuracies': 1.0, 'rewards/margins': 2.488203287124634, 'policy_logps/rejected': -295.51806640625, 'policy_logps/chosen': -307.4897766113281, 'referece_logps/rejected': -258.2216796875, 'referece_logps/chosen': -295.0754089355469, 'logits/rejected': -0.4414711594581604, 'logits/chosen': -0.3265451490879059, 'epoch': 2.49}

 42%|████▏     | 6689/16104 [30:51:46<49:06:33, 18.78s/it]

 42%|████▏     | 6690/16104 [30:52:01<46:10:12, 17.66s/it]


 42%|████▏     | 6692/16104 [30:52:37<46:41:22, 17.86s/it]
{'loss': 0.4758, 'learning_rate': 1.3166582104197195e-06, 'rewards/chosen': -1.8527023792266846, 'rewards/rejected': -3.258600950241089, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4058986902236938, 'policy_logps/rejected': -210.24147033691406, 'policy_logps/chosen': -347.4174499511719, 'referece_logps/rejected': -177.65548706054688, 'referece_logps/chosen': -328.8904724121094, 'logits/rejected': -0.7331526875495911, 'logits/chosen': -0.8892716765403748, 'epoch': 2.49}

 42%|████▏     | 6693/16104 [30:52:47<40:58:36, 15.67s/it]


 42%|████▏     | 6695/16104 [30:53:09<34:20:37, 13.14s/it]
{'loss': 0.5356, 'learning_rate': 1.316085823994303e-06, 'rewards/chosen': -1.6949654817581177, 'rewards/rejected': -3.361619472503662, 'rewards/accuracies': 0.75, 'rewards/margins': 1.666654109954834, 'policy_logps/rejected': -403.6357116699219, 'policy_logps/chosen': -247.67581176757812, 'referece_logps/rejected': -370.01953125, 'referece_logps/chosen': -230.72616577148438, 'logits/rejected': -1.3996844291687012, 'logits/chosen': -1.1574627161026, 'epoch': 2.49}


 42%|████▏     | 6697/16104 [30:53:40<39:17:39, 15.04s/it]
{'loss': 0.2763, 'learning_rate': 1.3157041690999837e-06, 'rewards/chosen': -1.2986193895339966, 'rewards/rejected': -3.598536729812622, 'rewards/accuracies': 0.875, 'rewards/margins': 2.299917459487915, 'policy_logps/rejected': -360.3787841796875, 'policy_logps/chosen': -459.626953125, 'referece_logps/rejected': -324.3934326171875, 'referece_logps/chosen': -446.64080810546875, 'logits/rejected': -0.16719071567058563, 'logits/chosen': -0.30477720499038696, 'epoch': 2.5}


 42%|████▏     | 6699/16104 [30:54:13<41:42:00, 15.96s/it]
{'loss': 0.2927, 'learning_rate': 1.3153224631224771e-06, 'rewards/chosen': -1.2816071510314941, 'rewards/rejected': -2.551021099090576, 'rewards/accuracies': 0.875, 'rewards/margins': 1.269413709640503, 'policy_logps/rejected': -402.90789794921875, 'policy_logps/chosen': -365.23040771484375, 'referece_logps/rejected': -377.3976745605469, 'referece_logps/chosen': -352.4143371582031, 'logits/rejected': -0.38415274024009705, 'logits/chosen': -0.20592251420021057, 'epoch': 2.5}


 42%|████▏     | 6701/16104 [30:54:38<36:57:28, 14.15s/it]

 42%|████▏     | 6702/16104 [30:54:49<34:16:02, 13.12s/it]
{'loss': 0.3293, 'learning_rate': 1.3147498085103487e-06, 'rewards/chosen': -1.0830163955688477, 'rewards/rejected': -2.8499839305877686, 'rewards/accuracies': 1.0, 'rewards/margins': 1.766967535018921, 'policy_logps/rejected': -298.4588623046875, 'policy_logps/chosen': -325.27435302734375, 'referece_logps/rejected': -269.958984375, 'referece_logps/chosen': -314.44415283203125, 'logits/rejected': 0.16992667317390442, 'logits/chosen': 0.29369914531707764, 'epoch': 2.5}


 42%|████▏     | 6704/16104 [30:55:24<40:51:26, 15.65s/it]
{'loss': 0.1997, 'learning_rate': 1.3143679750951034e-06, 'rewards/chosen': -1.416167140007019, 'rewards/rejected': -4.1235833168029785, 'rewards/accuracies': 0.875, 'rewards/margins': 2.707416296005249, 'policy_logps/rejected': -336.23297119140625, 'policy_logps/chosen': -506.8385314941406, 'referece_logps/rejected': -294.99713134765625, 'referece_logps/chosen': -492.67681884765625, 'logits/rejected': -0.16311733424663544, 'logits/chosen': 0.004178464412689209, 'epoch': 2.5}


 42%|████▏     | 6706/16104 [30:55:58<42:01:03, 16.10s/it]

 42%|████▏     | 6707/16104 [30:56:19<45:18:50, 17.36s/it]
{'loss': 0.5146, 'learning_rate': 1.3137951296159535e-06, 'rewards/chosen': -1.682084083557129, 'rewards/rejected': -2.8079729080200195, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1258890628814697, 'policy_logps/rejected': -242.71353149414062, 'policy_logps/chosen': -308.3131103515625, 'referece_logps/rejected': -214.6337890625, 'referece_logps/chosen': -291.4922790527344, 'logits/rejected': -0.2876485586166382, 'logits/chosen': -0.2576601803302765, 'epoch': 2.5}
[2024-04-06 22:20:54,905] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 42%|████▏     | 6709/16104 [30:57:01<50:01:29, 19.17s/it]
{'loss': 0.4324, 'learning_rate': 1.3134131691491155e-06, 'rewards/chosen': -1.1084336042404175, 'rewards/rejected': -2.644399404525757, 'rewards/accuracies': 0.75, 'rewards/margins': 1.535965919494629, 'policy_logps/rejected': -227.3280029296875, 'policy_logps/chosen': -354.7747802734375, 'referece_logps/rejected': -200.8839874267578, 'referece_logps/chosen': -343.6904602050781, 'logits/rejected': -0.7583528757095337, 'logits/chosen': -0.7154104709625244, 'epoch': 2.5}


 42%|████▏     | 6711/16104 [30:57:29<43:36:55, 16.72s/it]
{'loss': 0.3926, 'learning_rate': 1.3130311579697898e-06, 'rewards/chosen': -1.402307152748108, 'rewards/rejected': -3.0393433570861816, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6370360851287842, 'policy_logps/rejected': -313.1441650390625, 'policy_logps/chosen': -262.583984375, 'referece_logps/rejected': -282.750732421875, 'referece_logps/chosen': -248.56094360351562, 'logits/rejected': -0.6576507687568665, 'logits/chosen': -0.44097793102264404, 'epoch': 2.5}


 42%|████▏     | 6713/16104 [30:58:11<48:55:48, 18.76s/it]
{'loss': 0.3727, 'learning_rate': 1.3126490961397892e-06, 'rewards/chosen': -1.4389441013336182, 'rewards/rejected': -2.7722175121307373, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3332734107971191, 'policy_logps/rejected': -390.5824890136719, 'policy_logps/chosen': -352.7486572265625, 'referece_logps/rejected': -362.86029052734375, 'referece_logps/chosen': -338.3592224121094, 'logits/rejected': -0.05654621124267578, 'logits/chosen': 0.06929762661457062, 'epoch': 2.5}

 42%|████▏     | 6714/16104 [30:58:26<46:16:10, 17.74s/it]

 42%|████▏     | 6715/16104 [30:58:44<46:30:02, 17.83s/it]

 42%|████▏     | 6716/16104 [30:59:00<45:09:24, 17.32s/it]

 42%|████▏     | 6717/16104 [30:59:12<41:08:33, 15.78s/it]

 42%|████▏     | 6718/16104 [30:59:24<38:15:39, 14.68s/it]


 42%|████▏     | 6720/16104 [30:59:47<33:46:48, 12.96s/it]

 42%|████▏     | 6721/16104 [31:00:01<34:17:05, 13.15s/it]

 42%|████▏     | 6722/16104 [31:00:13<33:49:38, 12.98s/it]

 42%|████▏     | 6723/16104 [31:00:29<35:47:26, 13.73s/it]

 42%|████▏     | 6724/16104 [31:00:47<39:25:47, 15.13s/it]

 42%|████▏     | 6725/16104 [31:00:59<36:59:44, 14.20s/it]
{'loss': 0.3248, 'learning_rate': 1.3103556649581148e-06, 'rewards/chosen': -1.8244349956512451, 'rewards/rejected': -4.197090148925781, 'rewards/accuracies': 1.0, 'rewards/margins': 2.372654676437378, 'policy_logps/rejected': -548.576171875, 'policy_logps/chosen': -337.357666015625, 'referece_logps/rejected': -506.6053466796875, 'referece_logps/chosen': -319.11328125, 'logits/rejected': 0.13234014809131622, 'logits/chosen': 0.05144982784986496, 'epoch': 2.51}


 42%|████▏     | 6727/16104 [31:01:23<34:09:00, 13.11s/it]
{'loss': 0.3626, 'learning_rate': 1.3099732503048147e-06, 'rewards/chosen': -1.4143236875534058, 'rewards/rejected': -2.4749443531036377, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0606205463409424, 'policy_logps/rejected': -381.6538391113281, 'policy_logps/chosen': -302.5945739746094, 'referece_logps/rejected': -356.9043884277344, 'referece_logps/chosen': -288.45135498046875, 'logits/rejected': -0.524955689907074, 'logits/chosen': -0.5511480569839478, 'epoch': 2.51}


 42%|████▏     | 6729/16104 [31:01:59<40:31:36, 15.56s/it]
{'loss': 0.444, 'learning_rate': 1.30959078549563e-06, 'rewards/chosen': -1.797644853591919, 'rewards/rejected': -3.9056396484375, 'rewards/accuracies': 0.875, 'rewards/margins': 2.107994556427002, 'policy_logps/rejected': -268.4410400390625, 'policy_logps/chosen': -306.1683654785156, 'referece_logps/rejected': -229.38462829589844, 'referece_logps/chosen': -288.19195556640625, 'logits/rejected': -0.6499656438827515, 'logits/chosen': -0.8184349536895752, 'epoch': 2.51}

 42%|████▏     | 6730/16104 [31:02:20<44:41:48, 17.17s/it]


 42%|████▏     | 6732/16104 [31:02:58<47:04:31, 18.08s/it]

 42%|████▏     | 6733/16104 [31:03:21<51:19:25, 19.72s/it]
[2024-04-06 22:27:35,780] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 42%|████▏     | 6734/16104 [31:03:39<50:13:36, 19.30s/it]
{'loss': 0.2764, 'learning_rate': 1.3086344044468198e-06, 'rewards/chosen': -1.5823324918746948, 'rewards/rejected': -3.8636398315429688, 'rewards/accuracies': 0.75, 'rewards/margins': 2.2813074588775635, 'policy_logps/rejected': -311.6607971191406, 'policy_logps/chosen': -343.666748046875, 'referece_logps/rejected': -273.0244140625, 'referece_logps/chosen': -327.8434143066406, 'logits/rejected': -0.2843048572540283, 'logits/chosen': -0.2632814347743988, 'epoch': 2.51}
[2024-04-06 22:28:13,216] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 42%|████▏     | 6735/16104 [31:03:59<50:04:51, 19.24s/it]

 42%|████▏     | 6736/16104 [31:04:12<45:31:55, 17.50s/it]
[2024-04-06 22:28:46,947] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 42%|████▏     | 6738/16104 [31:04:50<47:02:33, 18.08s/it]

 42%|████▏     | 6739/16104 [31:05:09<47:55:56, 18.43s/it]
{'loss': 0.377, 'learning_rate': 1.3076777112777247e-06, 'rewards/chosen': -2.9615230560302734, 'rewards/rejected': -4.628055572509766, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6665326356887817, 'policy_logps/rejected': -255.7928466796875, 'policy_logps/chosen': -271.4182434082031, 'referece_logps/rejected': -209.51231384277344, 'referece_logps/chosen': -241.80300903320312, 'logits/rejected': -0.7645611763000488, 'logits/chosen': -0.7709931135177612, 'epoch': 2.51}


 42%|████▏     | 6741/16104 [31:05:43<45:46:56, 17.60s/it]

 42%|████▏     | 6742/16104 [31:06:02<46:26:14, 17.86s/it]

 42%|████▏     | 6743/16104 [31:06:21<47:32:39, 18.28s/it]
{'loss': 0.5769, 'learning_rate': 1.3069121326659918e-06, 'rewards/chosen': -1.3379937410354614, 'rewards/rejected': -2.254464864730835, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9164709448814392, 'policy_logps/rejected': -407.94207763671875, 'policy_logps/chosen': -404.801025390625, 'referece_logps/rejected': -385.3973693847656, 'referece_logps/chosen': -391.421142578125, 'logits/rejected': -0.6839250922203064, 'logits/chosen': -0.7149521112442017, 'epoch': 2.51}

 42%|████▏     | 6744/16104 [31:06:42<49:42:30, 19.12s/it]


 42%|████▏     | 6746/16104 [31:07:19<48:38:17, 18.71s/it]
{'loss': 0.2809, 'learning_rate': 1.3063378183210897e-06, 'rewards/chosen': -2.2909395694732666, 'rewards/rejected': -4.452674388885498, 'rewards/accuracies': 0.625, 'rewards/margins': 2.1617350578308105, 'policy_logps/rejected': -383.5312805175781, 'policy_logps/chosen': -364.8586730957031, 'referece_logps/rejected': -339.0045166015625, 'referece_logps/chosen': -341.94927978515625, 'logits/rejected': -0.9854576587677002, 'logits/chosen': -0.7049193382263184, 'epoch': 2.51}


 42%|████▏     | 6748/16104 [31:08:00<50:33:10, 19.45s/it]
[2024-04-06 22:32:14,679] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.2875, 'learning_rate': 1.3059548801186912e-06, 'rewards/chosen': -1.558442234992981, 'rewards/rejected': -2.7944700717926025, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2360279560089111, 'policy_logps/rejected': -269.621826171875, 'policy_logps/chosen': -311.3674621582031, 'referece_logps/rejected': -241.67715454101562, 'referece_logps/chosen': -295.7830505371094, 'logits/rejected': 0.1834784895181656, 'logits/chosen': 0.23200947046279907, 'epoch': 2.51}


 42%|████▏     | 6750/16104 [31:08:23<40:06:26, 15.44s/it]

 42%|████▏     | 6751/16104 [31:08:42<42:38:52, 16.42s/it]

 42%|████▏     | 6752/16104 [31:09:00<43:51:41, 16.88s/it]

 42%|████▏     | 6753/16104 [31:09:20<46:19:03, 17.83s/it]
[2024-04-06 22:33:34,704] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 42%|████▏     | 6754/16104 [31:09:35<44:26:00, 17.11s/it]
{'loss': 0.333, 'learning_rate': 1.3048057687252865e-06, 'rewards/chosen': -0.8221672177314758, 'rewards/rejected': -2.9362637996673584, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1140966415405273, 'policy_logps/rejected': -457.86138916015625, 'policy_logps/chosen': -580.9129028320312, 'referece_logps/rejected': -428.498779296875, 'referece_logps/chosen': -572.6912231445312, 'logits/rejected': -0.038659609854221344, 'logits/chosen': -0.2875952422618866, 'epoch': 2.52}

 42%|████▏     | 6755/16104 [31:09:55<46:29:18, 17.90s/it]

 42%|████▏     | 6756/16104 [31:10:13<46:44:36, 18.00s/it]

 42%|████▏     | 6757/16104 [31:10:30<45:54:28, 17.68s/it]

 42%|████▏     | 6758/16104 [31:10:49<46:44:39, 18.01s/it]
[2024-04-06 22:35:25,188] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 42%|████▏     | 6759/16104 [31:11:11<49:22:03, 19.02s/it]
[2024-04-06 22:35:43,758] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 42%|████▏     | 6760/16104 [31:11:29<49:00:48, 18.88s/it]

 42%|████▏     | 6761/16104 [31:11:47<48:18:06, 18.61s/it]

 42%|████▏     | 6762/16104 [31:12:02<45:05:42, 17.38s/it]
[2024-04-06 22:36:36,214] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 42%|████▏     | 6764/16104 [31:12:40<47:22:09, 18.26s/it]
{'loss': 0.4494, 'learning_rate': 1.3028895975014148e-06, 'rewards/chosen': -1.672254204750061, 'rewards/rejected': -3.188443899154663, 'rewards/accuracies': 0.875, 'rewards/margins': 1.516189694404602, 'policy_logps/rejected': -280.5794982910156, 'policy_logps/chosen': -370.738525390625, 'referece_logps/rejected': -248.69503784179688, 'referece_logps/chosen': -354.0160217285156, 'logits/rejected': -0.23980243504047394, 'logits/chosen': -0.31033390760421753, 'epoch': 2.52}

 42%|████▏     | 6765/16104 [31:12:52<42:20:09, 16.32s/it]


 42%|████▏     | 6767/16104 [31:13:26<43:41:30, 16.85s/it]
{'loss': 0.2863, 'learning_rate': 1.3023145068592392e-06, 'rewards/chosen': -1.2622498273849487, 'rewards/rejected': -2.967763900756836, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7055139541625977, 'policy_logps/rejected': -302.9266357421875, 'policy_logps/chosen': -484.2239990234375, 'referece_logps/rejected': -273.2489929199219, 'referece_logps/chosen': -471.6015319824219, 'logits/rejected': -0.09256475418806076, 'logits/chosen': -0.19485875964164734, 'epoch': 2.52}

 42%|████▏     | 6768/16104 [31:13:47<47:05:57, 18.16s/it]
[2024-04-06 22:38:23,810] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 42%|████▏     | 6769/16104 [31:14:09<50:00:57, 19.29s/it]

 42%|████▏     | 6770/16104 [31:14:22<44:49:19, 17.29s/it]

 42%|████▏     | 6771/16104 [31:14:40<45:29:48, 17.55s/it]

 42%|████▏     | 6772/16104 [31:15:00<47:08:13, 18.18s/it]

 42%|████▏     | 6773/16104 [31:15:19<48:16:01, 18.62s/it]


 42%|████▏     | 6775/16104 [31:16:00<50:30:09, 19.49s/it]
{'loss': 0.3174, 'learning_rate': 1.300780394299144e-06, 'rewards/chosen': -1.6191942691802979, 'rewards/rejected': -4.408677101135254, 'rewards/accuracies': 1.0, 'rewards/margins': 2.789482831954956, 'policy_logps/rejected': -296.2138671875, 'policy_logps/chosen': -306.98162841796875, 'referece_logps/rejected': -252.1271209716797, 'referece_logps/chosen': -290.7896728515625, 'logits/rejected': -1.0941367149353027, 'logits/chosen': -1.0185359716415405, 'epoch': 2.52}

 42%|████▏     | 6776/16104 [31:16:13<44:59:25, 17.36s/it]

 42%|████▏     | 6777/16104 [31:16:23<39:44:41, 15.34s/it]

 42%|████▏     | 6778/16104 [31:16:34<36:08:21, 13.95s/it]

 42%|████▏     | 6779/16104 [31:16:45<33:35:02, 12.97s/it]

 42%|████▏     | 6780/16104 [31:16:55<31:49:13, 12.29s/it]

 42%|████▏     | 6781/16104 [31:17:18<39:29:49, 15.25s/it]

 42%|████▏     | 6782/16104 [31:17:33<39:39:27, 15.32s/it]

 42%|████▏     | 6783/16104 [31:17:47<38:40:20, 14.94s/it]


 42%|████▏     | 6785/16104 [31:18:19<39:14:03, 15.16s/it]

 42%|████▏     | 6786/16104 [31:18:39<43:00:32, 16.62s/it]

 42%|████▏     | 6787/16104 [31:18:59<45:30:07, 17.58s/it]
{'loss': 0.2696, 'learning_rate': 1.298477766648572e-06, 'rewards/chosen': -1.5565673112869263, 'rewards/rejected': -3.721534013748169, 'rewards/accuracies': 0.75, 'rewards/margins': 2.164966344833374, 'policy_logps/rejected': -367.7973327636719, 'policy_logps/chosen': -411.13421630859375, 'referece_logps/rejected': -330.5820007324219, 'referece_logps/chosen': -395.5684814453125, 'logits/rejected': 0.41473114490509033, 'logits/chosen': 0.7519190907478333, 'epoch': 2.53}

 42%|████▏     | 6788/16104 [31:19:13<43:25:39, 16.78s/it]

 42%|████▏     | 6789/16104 [31:19:25<39:35:36, 15.30s/it]

 42%|████▏     | 6790/16104 [31:19:36<35:59:58, 13.91s/it]

 42%|████▏     | 6791/16104 [31:19:47<33:50:32, 13.08s/it]

 42%|████▏     | 6792/16104 [31:20:04<36:36:10, 14.15s/it]


 42%|████▏     | 6794/16104 [31:20:36<38:44:30, 14.98s/it]
{'loss': 0.3832, 'learning_rate': 1.2971337634071774e-06, 'rewards/chosen': -1.51506769657135, 'rewards/rejected': -2.672517776489258, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1574501991271973, 'policy_logps/rejected': -400.7248840332031, 'policy_logps/chosen': -340.7188720703125, 'referece_logps/rejected': -373.9997253417969, 'referece_logps/chosen': -325.5681457519531, 'logits/rejected': -0.12447715550661087, 'logits/chosen': 0.031554147601127625, 'epoch': 2.53}

 42%|████▏     | 6795/16104 [31:20:56<42:08:38, 16.30s/it]


 42%|████▏     | 6797/16104 [31:21:21<37:25:16, 14.47s/it]

 42%|████▏     | 6798/16104 [31:21:37<38:40:33, 14.96s/it]
{'loss': 0.3914, 'learning_rate': 1.296365496953077e-06, 'rewards/chosen': -1.1668846607208252, 'rewards/rejected': -2.9433507919311523, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7764662504196167, 'policy_logps/rejected': -297.33587646484375, 'policy_logps/chosen': -291.34088134765625, 'referece_logps/rejected': -267.90234375, 'referece_logps/chosen': -279.67205810546875, 'logits/rejected': -0.6248769164085388, 'logits/chosen': -0.48759889602661133, 'epoch': 2.53}

 42%|████▏     | 6799/16104 [31:21:56<42:14:54, 16.35s/it]

 42%|████▏     | 6800/16104 [31:22:07<38:10:23, 14.77s/it]

 42%|████▏     | 6801/16104 [31:22:30<44:00:48, 17.03s/it]

 42%|████▏     | 6802/16104 [31:22:50<46:21:55, 17.94s/it]


 42%|████▏     | 6804/16104 [31:23:29<48:21:35, 18.72s/it]
{'loss': 0.2864, 'learning_rate': 1.2952127377719706e-06, 'rewards/chosen': -1.8181573152542114, 'rewards/rejected': -3.3816041946411133, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5634468793869019, 'policy_logps/rejected': -377.035400390625, 'policy_logps/chosen': -283.4624938964844, 'referece_logps/rejected': -343.2193603515625, 'referece_logps/chosen': -265.2809143066406, 'logits/rejected': -1.3591089248657227, 'logits/chosen': -1.3448126316070557, 'epoch': 2.54}

 42%|████▏     | 6805/16104 [31:23:39<42:02:16, 16.27s/it]

 42%|████▏     | 6806/16104 [31:23:50<37:43:07, 14.60s/it]
[2024-04-06 22:48:18,749] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 42%|████▏     | 6807/16104 [31:24:04<37:20:05, 14.46s/it]

 42%|████▏     | 6808/16104 [31:24:20<38:08:29, 14.77s/it]

 42%|████▏     | 6809/16104 [31:24:34<37:54:46, 14.68s/it]
[2024-04-06 22:49:10,574] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 42%|████▏     | 6810/16104 [31:24:56<43:27:07, 16.83s/it]

 42%|████▏     | 6811/16104 [31:25:16<45:37:07, 17.67s/it]
[2024-04-06 22:49:52,818] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 42%|████▏     | 6812/16104 [31:25:38<49:26:10, 19.15s/it]

 42%|████▏     | 6813/16104 [31:25:56<48:35:52, 18.83s/it]


 42%|████▏     | 6815/16104 [31:26:25<42:34:21, 16.50s/it]
{'loss': 0.4118, 'learning_rate': 1.2930982305856501e-06, 'rewards/chosen': -1.5380812883377075, 'rewards/rejected': -2.8833136558532715, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3452324867248535, 'policy_logps/rejected': -298.5570068359375, 'policy_logps/chosen': -278.4067077636719, 'referece_logps/rejected': -269.7238464355469, 'referece_logps/chosen': -263.02587890625, 'logits/rejected': -0.16851860284805298, 'logits/chosen': -0.2956908047199249, 'epoch': 2.54}

 42%|████▏     | 6816/16104 [31:26:43<43:30:14, 16.86s/it]

 42%|████▏     | 6817/16104 [31:26:56<40:59:01, 15.89s/it]

 42%|████▏     | 6818/16104 [31:27:16<43:48:53, 16.99s/it]

 42%|████▏     | 6819/16104 [31:27:28<39:54:35, 15.47s/it]

 42%|████▏     | 6820/16104 [31:27:48<43:36:59, 16.91s/it]

 42%|████▏     | 6821/16104 [31:28:07<45:39:50, 17.71s/it]

 42%|████▏     | 6822/16104 [31:28:22<43:19:10, 16.80s/it]


 42%|████▏     | 6824/16104 [31:28:59<45:16:51, 17.57s/it]
{'loss': 0.3385, 'learning_rate': 1.2913671117138572e-06, 'rewards/chosen': -1.7193591594696045, 'rewards/rejected': -4.050705432891846, 'rewards/accuracies': 0.875, 'rewards/margins': 2.331346273422241, 'policy_logps/rejected': -543.550537109375, 'policy_logps/chosen': -419.78271484375, 'referece_logps/rejected': -503.0435485839844, 'referece_logps/chosen': -402.589111328125, 'logits/rejected': 0.05494413897395134, 'logits/chosen': -0.009702300652861595, 'epoch': 2.54}


 42%|████▏     | 6826/16104 [31:29:41<49:58:04, 19.39s/it]

 42%|████▏     | 6827/16104 [31:29:57<47:14:56, 18.34s/it]
{'loss': 0.4284, 'learning_rate': 1.2907898596560329e-06, 'rewards/chosen': -1.175185203552246, 'rewards/rejected': -2.351379156112671, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1761939525604248, 'policy_logps/rejected': -265.55902099609375, 'policy_logps/chosen': -351.3813781738281, 'referece_logps/rejected': -242.04522705078125, 'referece_logps/chosen': -339.6295166015625, 'logits/rejected': -0.6731075644493103, 'logits/chosen': -0.7673847675323486, 'epoch': 2.54}

 42%|████▏     | 6828/16104 [31:30:14<45:44:23, 17.75s/it]

 42%|████▏     | 6829/16104 [31:30:31<45:13:34, 17.55s/it]

 42%|████▏     | 6830/16104 [31:30:48<44:56:25, 17.45s/it]


 42%|████▏     | 6832/16104 [31:31:24<45:09:17, 17.53s/it]
{'loss': 0.382, 'learning_rate': 1.2898275377374232e-06, 'rewards/chosen': -2.231049060821533, 'rewards/rejected': -3.8779211044311523, 'rewards/accuracies': 0.625, 'rewards/margins': 1.6468721628189087, 'policy_logps/rejected': -455.0604248046875, 'policy_logps/chosen': -523.3436279296875, 'referece_logps/rejected': -416.2812194824219, 'referece_logps/chosen': -501.0331115722656, 'logits/rejected': -0.17614403367042542, 'logits/chosen': -0.09525077044963837, 'epoch': 2.55}

 42%|████▏     | 6833/16104 [31:31:44<47:08:50, 18.31s/it]

 42%|████▏     | 6834/16104 [31:32:04<48:33:26, 18.86s/it]


 42%|████▏     | 6836/16104 [31:32:43<49:22:16, 19.18s/it]

 42%|████▏     | 6837/16104 [31:32:57<45:23:29, 17.63s/it]
{'loss': 0.3606, 'learning_rate': 1.28886492271781e-06, 'rewards/chosen': -1.654365062713623, 'rewards/rejected': -3.635317087173462, 'rewards/accuracies': 1.0, 'rewards/margins': 1.980952501296997, 'policy_logps/rejected': -351.00701904296875, 'policy_logps/chosen': -342.6957092285156, 'referece_logps/rejected': -314.65386962890625, 'referece_logps/chosen': -326.15203857421875, 'logits/rejected': -0.8549062609672546, 'logits/chosen': -0.9387027621269226, 'epoch': 2.55}

 42%|████▏     | 6838/16104 [31:33:16<45:59:57, 17.87s/it]


 42%|████▏     | 6840/16104 [31:33:52<45:59:58, 17.88s/it]
{'loss': 0.3367, 'learning_rate': 1.2882872134225184e-06, 'rewards/chosen': -1.6202844381332397, 'rewards/rejected': -2.958218812942505, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3379340171813965, 'policy_logps/rejected': -260.0633850097656, 'policy_logps/chosen': -283.588623046875, 'referece_logps/rejected': -230.481201171875, 'referece_logps/chosen': -267.3857727050781, 'logits/rejected': -0.14500069618225098, 'logits/chosen': -0.25720056891441345, 'epoch': 2.55}

 42%|████▏     | 6841/16104 [31:34:02<40:26:57, 15.72s/it]

 42%|████▏     | 6842/16104 [31:34:22<43:30:56, 16.91s/it]

 42%|████▏     | 6843/16104 [31:34:42<46:04:15, 17.91s/it]

 42%|████▏     | 6844/16104 [31:34:57<43:17:02, 16.83s/it]

 43%|████▎     | 6845/16104 [31:35:14<43:52:45, 17.06s/it]

 43%|████▎     | 6846/16104 [31:35:35<46:44:12, 18.17s/it]

 43%|████▎     | 6847/16104 [31:35:53<46:50:58, 18.22s/it]

 43%|████▎     | 6848/16104 [31:36:08<44:15:42, 17.22s/it]


 43%|████▎     | 6850/16104 [31:36:44<45:16:50, 17.62s/it]

 43%|████▎     | 6851/16104 [31:37:02<45:36:15, 17.74s/it]
{'loss': 0.3996, 'learning_rate': 1.2861680496530077e-06, 'rewards/chosen': -1.287179708480835, 'rewards/rejected': -2.6528332233428955, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3656532764434814, 'policy_logps/rejected': -290.073974609375, 'policy_logps/chosen': -319.38702392578125, 'referece_logps/rejected': -263.5456848144531, 'referece_logps/chosen': -306.5152282714844, 'logits/rejected': 0.10685990750789642, 'logits/chosen': 0.18391864001750946, 'epoch': 2.55}

 43%|████▎     | 6852/16104 [31:37:21<46:53:04, 18.24s/it]


 43%|████▎     | 6854/16104 [31:37:52<41:53:56, 16.31s/it]
{'loss': 0.4713, 'learning_rate': 1.2855898523650342e-06, 'rewards/chosen': -1.8555479049682617, 'rewards/rejected': -2.9185433387756348, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0629953145980835, 'policy_logps/rejected': -337.42816162109375, 'policy_logps/chosen': -380.2330322265625, 'referece_logps/rejected': -308.24273681640625, 'referece_logps/chosen': -361.67755126953125, 'logits/rejected': -0.9845935702323914, 'logits/chosen': -0.9552246928215027, 'epoch': 2.55}

 43%|████▎     | 6855/16104 [31:38:11<43:52:15, 17.08s/it]

 43%|████▎     | 6856/16104 [31:38:23<40:19:27, 15.70s/it]

 43%|████▎     | 6857/16104 [31:38:43<43:34:09, 16.96s/it]

 43%|████▎     | 6858/16104 [31:39:03<45:48:45, 17.84s/it]

 43%|████▎     | 6859/16104 [31:39:15<41:15:45, 16.07s/it]

 43%|████▎     | 6860/16104 [31:39:31<41:10:34, 16.04s/it]

 43%|████▎     | 6861/16104 [31:39:46<40:23:32, 15.73s/it]

 43%|████▎     | 6862/16104 [31:40:02<40:39:50, 15.84s/it]

 43%|████▎     | 6863/16104 [31:40:14<37:41:28, 14.68s/it]

 43%|████▎     | 6864/16104 [31:40:30<38:43:00, 15.08s/it]

 43%|████▎     | 6865/16104 [31:40:45<38:59:13, 15.19s/it]

 43%|████▎     | 6866/16104 [31:40:58<37:02:36, 14.44s/it]

 43%|████▎     | 6867/16104 [31:41:15<38:56:23, 15.18s/it]

 43%|████▎     | 6868/16104 [31:41:35<42:22:45, 16.52s/it]

 43%|████▎     | 6869/16104 [31:41:54<44:12:34, 17.23s/it]

 43%|████▎     | 6870/16104 [31:42:05<39:36:53, 15.44s/it]

 43%|████▎     | 6871/16104 [31:42:22<41:14:05, 16.08s/it]

 43%|████▎     | 6872/16104 [31:42:33<37:18:20, 14.55s/it]

 43%|████▎     | 6873/16104 [31:42:44<34:38:38, 13.51s/it]

 43%|████▎     | 6874/16104 [31:42:55<32:25:36, 12.65s/it]

 43%|████▎     | 6875/16104 [31:43:07<32:07:47, 12.53s/it]

 43%|████▎     | 6876/16104 [31:43:27<37:39:24, 14.69s/it]

 43%|████▎     | 6877/16104 [31:43:48<42:47:05, 16.69s/it]

 43%|████▎     | 6878/16104 [31:44:08<45:02:12, 17.57s/it]

 43%|████▎     | 6879/16104 [31:44:30<48:06:48, 18.78s/it]

 43%|████▎     | 6880/16104 [31:44:45<45:07:11, 17.61s/it]

 43%|████▎     | 6881/16104 [31:45:02<44:47:40, 17.48s/it]

 43%|████▎     | 6882/16104 [31:45:19<44:24:08, 17.33s/it]

 43%|████▎     | 6883/16104 [31:45:31<40:24:46, 15.78s/it]

 43%|████▎     | 6884/16104 [31:45:43<37:57:20, 14.82s/it]

 43%|████▎     | 6885/16104 [31:45:58<37:34:47, 14.67s/it]

 43%|████▎     | 6886/16104 [31:46:09<35:18:52, 13.79s/it]

 43%|████▎     | 6887/16104 [31:46:24<35:53:35, 14.02s/it]

 43%|████▎     | 6888/16104 [31:46:37<34:58:33, 13.66s/it]

 43%|████▎     | 6889/16104 [31:46:52<36:06:28, 14.11s/it]

 43%|████▎     | 6890/16104 [31:47:07<36:48:33, 14.38s/it]

 43%|████▎     | 6891/16104 [31:47:28<42:01:00, 16.42s/it]

 43%|████▎     | 6892/16104 [31:47:39<38:03:53, 14.88s/it]

 43%|████▎     | 6893/16104 [31:47:57<40:22:03, 15.78s/it]

 43%|████▎     | 6894/16104 [31:48:15<41:26:46, 16.20s/it]

 43%|████▎     | 6895/16104 [31:48:30<41:09:19, 16.09s/it]

 43%|████▎     | 6896/16104 [31:48:50<43:58:06, 17.19s/it]

 43%|████▎     | 6897/16104 [31:49:02<40:10:10, 15.71s/it]

 43%|████▎     | 6898/16104 [31:49:14<36:49:01, 14.40s/it]


 43%|████▎     | 6900/16104 [31:49:40<35:13:05, 13.78s/it]

 43%|████▎     | 6901/16104 [31:50:00<40:30:52, 15.85s/it]

 43%|████▎     | 6902/16104 [31:50:15<39:58:31, 15.64s/it]

 43%|████▎     | 6903/16104 [31:50:36<44:04:59, 17.25s/it]

 43%|████▎     | 6904/16104 [31:50:56<46:04:01, 18.03s/it]

 43%|████▎     | 6905/16104 [31:51:09<42:19:42, 16.57s/it]

 43%|████▎     | 6906/16104 [31:51:21<38:21:01, 15.01s/it]

 43%|████▎     | 6907/16104 [31:51:34<36:54:15, 14.45s/it]

 43%|████▎     | 6908/16104 [31:51:54<41:23:27, 16.20s/it]

 43%|████▎     | 6909/16104 [31:52:06<38:04:56, 14.91s/it]

 43%|████▎     | 6910/16104 [31:52:17<34:49:35, 13.64s/it]

 43%|████▎     | 6911/16104 [31:52:36<38:54:20, 15.24s/it]

 43%|████▎     | 6912/16104 [31:52:50<38:26:53, 15.06s/it]

 43%|████▎     | 6913/16104 [31:53:08<40:48:53, 15.99s/it]
{'loss': 0.2523, 'learning_rate': 1.2741977757309105e-06, 'rewards/chosen': -1.4690881967544556, 'rewards/rejected': -3.529878616333008, 'rewards/accuracies': 0.875, 'rewards/margins': 2.060790538787842, 'policy_logps/rejected': -255.39352416992188, 'policy_logps/chosen': -416.2582092285156, 'referece_logps/rejected': -220.09475708007812, 'referece_logps/chosen': -401.5673522949219, 'logits/rejected': -1.6996567249298096, 'logits/chosen': -1.8120101690292358, 'epoch': 2.58}

 43%|████▎     | 6914/16104 [31:53:21<38:11:16, 14.96s/it]


 43%|████▎     | 6916/16104 [31:54:02<45:15:23, 17.73s/it]

 43%|████▎     | 6917/16104 [31:54:22<46:49:39, 18.35s/it]

 43%|████▎     | 6918/16104 [31:54:34<42:41:02, 16.73s/it]

 43%|████▎     | 6919/16104 [31:54:57<46:52:59, 18.38s/it]

 43%|████▎     | 6920/16104 [31:55:13<45:03:59, 17.67s/it]

 43%|████▎     | 6921/16104 [31:55:35<48:27:04, 18.99s/it]
[2024-04-06 23:19:49,427] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 43%|████▎     | 6922/16104 [31:55:57<51:14:24, 20.09s/it]
[2024-04-06 23:20:12,074] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 43%|████▎     | 6923/16104 [31:56:17<50:50:53, 19.94s/it]

 43%|████▎     | 6924/16104 [31:56:33<47:49:47, 18.76s/it]

 43%|████▎     | 6925/16104 [31:56:54<49:49:53, 19.54s/it]

 43%|████▎     | 6926/16104 [31:57:07<44:15:56, 17.36s/it]

 43%|████▎     | 6927/16104 [31:57:26<45:57:03, 18.03s/it]

 43%|████▎     | 6928/16104 [31:57:39<41:35:33, 16.32s/it]
{'loss': 0.4534, 'learning_rate': 1.271295265489005e-06, 'rewards/chosen': -1.0692816972732544, 'rewards/rejected': -2.5619804859161377, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4926986694335938, 'policy_logps/rejected': -395.6418762207031, 'policy_logps/chosen': -467.0172119140625, 'referece_logps/rejected': -370.02203369140625, 'referece_logps/chosen': -456.32440185546875, 'logits/rejected': -0.6127309203147888, 'logits/chosen': -0.5811557769775391, 'epoch': 2.58}


 43%|████▎     | 6930/16104 [31:58:11<42:15:21, 16.58s/it]

 43%|████▎     | 6931/16104 [31:58:22<37:45:11, 14.82s/it]

 43%|████▎     | 6932/16104 [31:58:34<35:34:33, 13.96s/it]

 43%|████▎     | 6933/16104 [31:58:53<39:32:10, 15.52s/it]

 43%|████▎     | 6934/16104 [31:59:11<41:34:48, 16.32s/it]

 43%|████▎     | 6935/16104 [31:59:32<45:22:21, 17.81s/it]

 43%|████▎     | 6936/16104 [31:59:50<45:27:08, 17.85s/it]

 43%|████▎     | 6937/16104 [32:00:11<47:50:29, 18.79s/it]

 43%|████▎     | 6938/16104 [32:00:29<47:11:15, 18.53s/it]

 43%|████▎     | 6939/16104 [32:00:49<48:07:40, 18.90s/it]
[2024-04-06 23:25:03,594] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 43%|████▎     | 6940/16104 [32:01:09<49:01:22, 19.26s/it]

 43%|████▎     | 6941/16104 [32:01:26<47:37:02, 18.71s/it]

 43%|████▎     | 6942/16104 [32:01:48<49:43:34, 19.54s/it]
[2024-04-06 23:26:02,578] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 43%|████▎     | 6943/16104 [32:02:07<49:00:50, 19.26s/it]
[2024-04-06 23:26:21,192] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 43%|████▎     | 6944/16104 [32:02:23<47:14:13, 18.56s/it]
{'loss': 0.3425, 'learning_rate': 1.2681965335682041e-06, 'rewards/chosen': -1.0955560207366943, 'rewards/rejected': -2.113182544708252, 'rewards/accuracies': 0.875, 'rewards/margins': 1.017626404762268, 'policy_logps/rejected': -241.4498291015625, 'policy_logps/chosen': -268.95751953125, 'referece_logps/rejected': -220.3179931640625, 'referece_logps/chosen': -258.0019836425781, 'logits/rejected': -0.3104698657989502, 'logits/chosen': -0.4087003469467163, 'epoch': 2.59}


 43%|████▎     | 6946/16104 [32:02:52<41:32:45, 16.33s/it]

 43%|████▎     | 6947/16104 [32:03:10<42:04:58, 16.54s/it]

 43%|████▎     | 6948/16104 [32:03:28<43:27:06, 17.08s/it]

 43%|████▎     | 6949/16104 [32:03:48<45:43:53, 17.98s/it]
[2024-04-06 23:28:02,584] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 43%|████▎     | 6950/16104 [32:04:10<49:07:14, 19.32s/it]

 43%|████▎     | 6951/16104 [32:04:29<48:35:44, 19.11s/it]

 43%|████▎     | 6952/16104 [32:04:47<48:00:47, 18.89s/it]

 43%|████▎     | 6953/16104 [32:05:02<44:53:12, 17.66s/it]

 43%|████▎     | 6954/16104 [32:05:20<45:04:27, 17.73s/it]

 43%|████▎     | 6955/16104 [32:05:37<44:16:45, 17.42s/it]

 43%|████▎     | 6956/16104 [32:05:58<47:21:57, 18.64s/it]

 43%|████▎     | 6957/16104 [32:06:10<42:07:24, 16.58s/it]
{'loss': 0.4686, 'learning_rate': 1.2656767673647596e-06, 'rewards/chosen': -1.2394192218780518, 'rewards/rejected': -1.6136072874069214, 'rewards/accuracies': 0.5, 'rewards/margins': 0.37418824434280396, 'policy_logps/rejected': -391.1895751953125, 'policy_logps/chosen': -301.83172607421875, 'referece_logps/rejected': -375.0534973144531, 'referece_logps/chosen': -289.43756103515625, 'logits/rejected': -0.10465846955776215, 'logits/chosen': -0.20136135816574097, 'epoch': 2.59}


 43%|████▎     | 6959/16104 [32:06:35<36:15:44, 14.27s/it]

 43%|████▎     | 6960/16104 [32:06:48<35:44:11, 14.07s/it]

 43%|████▎     | 6961/16104 [32:07:06<38:37:26, 15.21s/it]

 43%|████▎     | 6962/16104 [32:07:18<36:17:12, 14.29s/it]

 43%|████▎     | 6963/16104 [32:07:34<37:12:37, 14.65s/it]

 43%|████▎     | 6964/16104 [32:07:49<37:56:26, 14.94s/it]

 43%|████▎     | 6965/16104 [32:08:08<40:28:02, 15.94s/it]

 43%|████▎     | 6966/16104 [32:08:26<42:22:14, 16.69s/it]
{'loss': 0.4003, 'learning_rate': 1.2639312488415915e-06, 'rewards/chosen': -1.9084669351577759, 'rewards/rejected': -3.2122647762298584, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3037978410720825, 'policy_logps/rejected': -538.0758056640625, 'policy_logps/chosen': -522.2057495117188, 'referece_logps/rejected': -505.95318603515625, 'referece_logps/chosen': -503.12109375, 'logits/rejected': -0.08624053001403809, 'logits/chosen': -0.15505123138427734, 'epoch': 2.6}


 43%|████▎     | 6968/16104 [32:09:05<45:39:31, 17.99s/it]

 43%|████▎     | 6969/16104 [32:09:22<45:12:22, 17.82s/it]

 43%|████▎     | 6970/16104 [32:09:39<44:24:16, 17.50s/it]

 43%|████▎     | 6971/16104 [32:09:55<42:57:19, 16.93s/it]

 43%|████▎     | 6972/16104 [32:10:11<42:21:39, 16.70s/it]

 43%|████▎     | 6973/16104 [32:10:24<40:03:02, 15.79s/it]

 43%|████▎     | 6974/16104 [32:10:35<36:08:09, 14.25s/it]
{'loss': 0.4132, 'learning_rate': 1.262378950641979e-06, 'rewards/chosen': -2.1077158451080322, 'rewards/rejected': -4.212986469268799, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1052703857421875, 'policy_logps/rejected': -424.9425354003906, 'policy_logps/chosen': -536.1429443359375, 'referece_logps/rejected': -382.81268310546875, 'referece_logps/chosen': -515.0657958984375, 'logits/rejected': 0.22287389636039734, 'logits/chosen': 0.16655662655830383, 'epoch': 2.6}


 43%|████▎     | 6976/16104 [32:11:00<34:28:20, 13.60s/it]

 43%|████▎     | 6977/16104 [32:11:21<39:29:32, 15.58s/it]
{'loss': 0.2468, 'learning_rate': 1.261796663475257e-06, 'rewards/chosen': -1.5658113956451416, 'rewards/rejected': -4.925438404083252, 'rewards/accuracies': 1.0, 'rewards/margins': 3.3596270084381104, 'policy_logps/rejected': -437.2576599121094, 'policy_logps/chosen': -283.21710205078125, 'referece_logps/rejected': -388.0032653808594, 'referece_logps/chosen': -267.5589904785156, 'logits/rejected': 0.22371278703212738, 'logits/chosen': 0.2111670821905136, 'epoch': 2.6}

 43%|████▎     | 6978/16104 [32:11:40<42:33:32, 16.79s/it]


 43%|████▎     | 6980/16104 [32:12:13<41:56:16, 16.55s/it]
{'loss': 0.2591, 'learning_rate': 1.2612142809972576e-06, 'rewards/chosen': -1.6976979970932007, 'rewards/rejected': -3.7366697788238525, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0389719009399414, 'policy_logps/rejected': -460.163818359375, 'policy_logps/chosen': -569.048583984375, 'referece_logps/rejected': -422.797119140625, 'referece_logps/chosen': -552.071533203125, 'logits/rejected': -1.5462546348571777, 'logits/chosen': -1.479300618171692, 'epoch': 2.6}

 43%|████▎     | 6981/16104 [32:12:33<43:58:19, 17.35s/it]


 43%|████▎     | 6983/16104 [32:13:11<46:06:49, 18.20s/it]

 43%|████▎     | 6984/16104 [32:13:28<45:07:58, 17.82s/it]

 43%|████▎     | 6985/16104 [32:13:41<41:43:49, 16.47s/it]

 43%|████▎     | 6986/16104 [32:13:56<40:18:26, 15.91s/it]

 43%|████▎     | 6987/16104 [32:14:15<43:11:43, 17.06s/it]

 43%|████▎     | 6988/16104 [32:14:32<42:28:06, 16.77s/it]

 43%|████▎     | 6989/16104 [32:14:48<42:13:50, 16.68s/it]

 43%|████▎     | 6990/16104 [32:15:08<44:22:36, 17.53s/it]

 43%|████▎     | 6991/16104 [32:15:27<46:04:56, 18.20s/it]
{'loss': 0.3938, 'learning_rate': 1.2590780665638112e-06, 'rewards/chosen': -2.6074981689453125, 'rewards/rejected': -4.563237190246582, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9557386636734009, 'policy_logps/rejected': -479.600830078125, 'policy_logps/chosen': -438.5094299316406, 'referece_logps/rejected': -433.968505859375, 'referece_logps/chosen': -412.4344482421875, 'logits/rejected': -0.45407432317733765, 'logits/chosen': -0.44136691093444824, 'epoch': 2.6}


 43%|████▎     | 6993/16104 [32:16:00<44:14:43, 17.48s/it]

 43%|████▎     | 6994/16104 [32:16:18<44:45:49, 17.69s/it]

 43%|████▎     | 6995/16104 [32:16:36<44:48:21, 17.71s/it]
{'loss': 0.3039, 'learning_rate': 1.2583009463602104e-06, 'rewards/chosen': -2.9920706748962402, 'rewards/rejected': -4.585790634155273, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5937196016311646, 'policy_logps/rejected': -501.1163330078125, 'policy_logps/chosen': -406.1221923828125, 'referece_logps/rejected': -455.25848388671875, 'referece_logps/chosen': -376.20147705078125, 'logits/rejected': -0.833321750164032, 'logits/chosen': -0.6963497400283813, 'epoch': 2.61}

 43%|████▎     | 6996/16104 [32:16:55<45:53:30, 18.14s/it]

 43%|████▎     | 6997/16104 [32:17:07<41:14:39, 16.30s/it]


 43%|████▎     | 6999/16104 [32:17:47<46:46:54, 18.50s/it]

 43%|████▎     | 7000/16104 [32:18:05<46:25:59, 18.36s/it]
{'loss': 0.543, 'learning_rate': 1.257329311068154e-06, 'rewards/chosen': -0.8428972363471985, 'rewards/rejected': -2.6661558151245117, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8232582807540894, 'policy_logps/rejected': -255.64141845703125, 'policy_logps/chosen': -335.1552734375, 'referece_logps/rejected': -228.9798583984375, 'referece_logps/chosen': -326.726318359375, 'logits/rejected': -0.1928246021270752, 'logits/chosen': -0.12751176953315735, 'epoch': 2.61}


 43%|████▎     | 7002/16104 [32:18:57<54:05:14, 21.39s/it]
{'loss': 0.5459, 'learning_rate': 1.2569405840302933e-06, 'rewards/chosen': -2.189452648162842, 'rewards/rejected': -3.420322895050049, 'rewards/accuracies': 0.75, 'rewards/margins': 1.230870246887207, 'policy_logps/rejected': -319.0718994140625, 'policy_logps/chosen': -359.4547119140625, 'referece_logps/rejected': -284.86871337890625, 'referece_logps/chosen': -337.5601806640625, 'logits/rejected': -0.4272191524505615, 'logits/chosen': -0.514238178730011, 'epoch': 2.61}

 43%|████▎     | 7003/16104 [32:19:09<46:39:04, 18.45s/it]

 43%|████▎     | 7004/16104 [32:19:29<47:42:13, 18.87s/it]


 44%|████▎     | 7006/16104 [32:20:04<45:20:37, 17.94s/it]
{'loss': 0.328, 'learning_rate': 1.2561630052930176e-06, 'rewards/chosen': -2.3220314979553223, 'rewards/rejected': -3.395205497741699, 'rewards/accuracies': 0.875, 'rewards/margins': 1.073174238204956, 'policy_logps/rejected': -259.4407958984375, 'policy_logps/chosen': -385.9483642578125, 'referece_logps/rejected': -225.48873901367188, 'referece_logps/chosen': -362.72808837890625, 'logits/rejected': -0.9301614761352539, 'logits/chosen': -1.16242516040802, 'epoch': 2.61}

 44%|████▎     | 7007/16104 [32:20:19<43:21:35, 17.16s/it]

 44%|████▎     | 7008/16104 [32:20:33<40:50:48, 16.17s/it]

 44%|████▎     | 7009/16104 [32:20:49<40:41:37, 16.11s/it]


 44%|████▎     | 7011/16104 [32:21:20<40:57:01, 16.21s/it]

 44%|████▎     | 7012/16104 [32:21:39<42:29:14, 16.82s/it]
{'loss': 0.4739, 'learning_rate': 1.254996326476901e-06, 'rewards/chosen': -2.4291138648986816, 'rewards/rejected': -4.023000717163086, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5938867330551147, 'policy_logps/rejected': -335.79412841796875, 'policy_logps/chosen': -287.82501220703125, 'referece_logps/rejected': -295.56414794921875, 'referece_logps/chosen': -263.53387451171875, 'logits/rejected': -1.1706526279449463, 'logits/chosen': -1.1415764093399048, 'epoch': 2.61}

 44%|████▎     | 7013/16104 [32:21:57<43:42:49, 17.31s/it]


 44%|████▎     | 7015/16104 [32:22:30<41:35:59, 16.48s/it]
{'loss': 0.2911, 'learning_rate': 1.254412847709389e-06, 'rewards/chosen': -2.7537176609039307, 'rewards/rejected': -4.337952613830566, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5842347145080566, 'policy_logps/rejected': -348.0005187988281, 'policy_logps/chosen': -483.06475830078125, 'referece_logps/rejected': -304.6209716796875, 'referece_logps/chosen': -455.5275573730469, 'logits/rejected': -0.5378693342208862, 'logits/chosen': -0.6739692091941833, 'epoch': 2.61}


 44%|████▎     | 7017/16104 [32:23:04<41:37:41, 16.49s/it]

 44%|████▎     | 7018/16104 [32:23:15<37:17:48, 14.78s/it]
{'loss': 0.4122, 'learning_rate': 1.253829276318796e-06, 'rewards/chosen': -1.3032679557800293, 'rewards/rejected': -2.6224842071533203, 'rewards/accuracies': 0.75, 'rewards/margins': 1.319216251373291, 'policy_logps/rejected': -325.8503112792969, 'policy_logps/chosen': -429.4292907714844, 'referece_logps/rejected': -299.6254577636719, 'referece_logps/chosen': -416.3965759277344, 'logits/rejected': 0.5048292875289917, 'logits/chosen': 0.4350056052207947, 'epoch': 2.61}


 44%|████▎     | 7020/16104 [32:23:47<38:53:16, 15.41s/it]

 44%|████▎     | 7021/16104 [32:24:06<41:59:34, 16.64s/it]

 44%|████▎     | 7022/16104 [32:24:26<44:05:36, 17.48s/it]

 44%|████▎     | 7023/16104 [32:24:46<46:11:20, 18.31s/it]

 44%|████▎     | 7024/16104 [32:25:03<44:51:40, 17.79s/it]
{'loss': 0.3396, 'learning_rate': 1.252661856518236e-06, 'rewards/chosen': -1.1171306371688843, 'rewards/rejected': -2.54294490814209, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4258143901824951, 'policy_logps/rejected': -245.8814239501953, 'policy_logps/chosen': -401.0303955078125, 'referece_logps/rejected': -220.45196533203125, 'referece_logps/chosen': -389.8591003417969, 'logits/rejected': -0.4239950478076935, 'logits/chosen': -0.46980971097946167, 'epoch': 2.62}


 44%|████▎     | 7026/16104 [32:25:32<40:10:51, 15.93s/it]
{'loss': 0.4596, 'learning_rate': 1.2522726347357723e-06, 'rewards/chosen': -1.1261274814605713, 'rewards/rejected': -1.729920744895935, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6037932634353638, 'policy_logps/rejected': -451.1898193359375, 'policy_logps/chosen': -400.234619140625, 'referece_logps/rejected': -433.890625, 'referece_logps/chosen': -388.9733581542969, 'logits/rejected': -0.05296115577220917, 'logits/chosen': -0.09987463057041168, 'epoch': 2.62}


 44%|████▎     | 7028/16104 [32:26:02<39:32:44, 15.69s/it]

 44%|████▎     | 7029/16104 [32:26:15<36:57:11, 14.66s/it]
{'loss': 0.3852, 'learning_rate': 1.2516887255451734e-06, 'rewards/chosen': -1.5386358499526978, 'rewards/rejected': -2.829533815383911, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2908982038497925, 'policy_logps/rejected': -297.91522216796875, 'policy_logps/chosen': -387.0411071777344, 'referece_logps/rejected': -269.6199035644531, 'referece_logps/chosen': -371.6547546386719, 'logits/rejected': -0.1019735336303711, 'logits/chosen': -0.08137211203575134, 'epoch': 2.62}


 44%|████▎     | 7031/16104 [32:26:39<33:54:30, 13.45s/it]
{'loss': 0.3261, 'learning_rate': 1.251299401832028e-06, 'rewards/chosen': -1.8940995931625366, 'rewards/rejected': -3.569876194000244, 'rewards/accuracies': 0.625, 'rewards/margins': 1.675776481628418, 'policy_logps/rejected': -474.03802490234375, 'policy_logps/chosen': -554.0608520507812, 'referece_logps/rejected': -438.33929443359375, 'referece_logps/chosen': -535.119873046875, 'logits/rejected': -0.8321387767791748, 'logits/chosen': -0.8407483100891113, 'epoch': 2.62}


 44%|████▎     | 7033/16104 [32:27:08<34:43:31, 13.78s/it]

 44%|████▎     | 7034/16104 [32:27:19<32:18:42, 12.82s/it]
{'loss': 0.4439, 'learning_rate': 1.2507153400406793e-06, 'rewards/chosen': -1.1364387273788452, 'rewards/rejected': -2.723386287689209, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5869474411010742, 'policy_logps/rejected': -579.4249267578125, 'policy_logps/chosen': -648.2947998046875, 'referece_logps/rejected': -552.1910400390625, 'referece_logps/chosen': -636.930419921875, 'logits/rejected': -0.02333270013332367, 'logits/chosen': 0.022602587938308716, 'epoch': 2.62}


 44%|████▎     | 7036/16104 [32:27:40<29:35:55, 11.75s/it]

 44%|████▎     | 7037/16104 [32:27:51<28:44:59, 11.41s/it]
{'loss': 0.2868, 'learning_rate': 1.250131186972387e-06, 'rewards/chosen': -1.5335203409194946, 'rewards/rejected': -4.342327117919922, 'rewards/accuracies': 0.875, 'rewards/margins': 2.8088066577911377, 'policy_logps/rejected': -556.900390625, 'policy_logps/chosen': -620.114990234375, 'referece_logps/rejected': -513.47705078125, 'referece_logps/chosen': -604.7797241210938, 'logits/rejected': -1.2824876308441162, 'logits/chosen': -1.1462669372558594, 'epoch': 2.62}


 44%|████▎     | 7039/16104 [32:28:12<27:45:30, 11.02s/it]

 44%|████▎     | 7040/16104 [32:28:23<27:30:34, 10.93s/it]

 44%|████▎     | 7041/16104 [32:28:41<32:58:15, 13.10s/it]

 44%|████▎     | 7042/16104 [32:29:01<38:09:03, 15.16s/it]
{'loss': 0.2605, 'learning_rate': 1.249157396265218e-06, 'rewards/chosen': -1.598647952079773, 'rewards/rejected': -3.8882787227630615, 'rewards/accuracies': 0.875, 'rewards/margins': 2.289630651473999, 'policy_logps/rejected': -363.7457275390625, 'policy_logps/chosen': -403.2422790527344, 'referece_logps/rejected': -324.86297607421875, 'referece_logps/chosen': -387.2558288574219, 'logits/rejected': 0.8252130746841431, 'logits/chosen': 0.5991531014442444, 'epoch': 2.62}

 44%|████▎     | 7043/16104 [32:29:18<39:05:17, 15.53s/it]


 44%|████▎     | 7045/16104 [32:29:45<36:49:16, 14.63s/it]
{'loss': 0.5065, 'learning_rate': 1.248573000831554e-06, 'rewards/chosen': -2.184176445007324, 'rewards/rejected': -3.1739511489868164, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9897745847702026, 'policy_logps/rejected': -370.96435546875, 'policy_logps/chosen': -332.88690185546875, 'referece_logps/rejected': -339.224853515625, 'referece_logps/chosen': -311.04510498046875, 'logits/rejected': 0.4912148118019104, 'logits/chosen': 0.5303026437759399, 'epoch': 2.62}


 44%|████▍     | 7047/16104 [32:30:18<39:22:08, 15.65s/it]
{'loss': 0.4043, 'learning_rate': 1.2481833535865373e-06, 'rewards/chosen': -1.6689902544021606, 'rewards/rejected': -3.112365484237671, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4433749914169312, 'policy_logps/rejected': -367.6438293457031, 'policy_logps/chosen': -314.6273498535156, 'referece_logps/rejected': -336.5201416015625, 'referece_logps/chosen': -297.93743896484375, 'logits/rejected': 0.2571626901626587, 'logits/chosen': 0.19244582951068878, 'epoch': 2.63}

 44%|████▍     | 7048/16104 [32:30:40<43:35:46, 17.33s/it]


 44%|████▍     | 7050/16104 [32:31:14<42:51:30, 17.04s/it]

 44%|████▍     | 7051/16104 [32:31:34<45:21:20, 18.04s/it]

 44%|████▍     | 7052/16104 [32:31:53<45:26:11, 18.07s/it]
{'loss': 0.4203, 'learning_rate': 1.2472090599213885e-06, 'rewards/chosen': -1.5716183185577393, 'rewards/rejected': -3.410496950149536, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8388786315917969, 'policy_logps/rejected': -403.90618896484375, 'policy_logps/chosen': -442.4251403808594, 'referece_logps/rejected': -369.80120849609375, 'referece_logps/chosen': -426.70892333984375, 'logits/rejected': -0.4872991442680359, 'logits/chosen': -0.42225655913352966, 'epoch': 2.63}


 44%|████▍     | 7054/16104 [32:32:31<46:13:55, 18.39s/it]

 44%|████▍     | 7055/16104 [32:32:50<47:10:31, 18.77s/it]
{'loss': 0.3469, 'learning_rate': 1.246624363658668e-06, 'rewards/chosen': -2.2386178970336914, 'rewards/rejected': -4.286662578582764, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0480446815490723, 'policy_logps/rejected': -330.86798095703125, 'policy_logps/chosen': -485.9029235839844, 'referece_logps/rejected': -288.0013732910156, 'referece_logps/chosen': -463.5167236328125, 'logits/rejected': 0.3440505564212799, 'logits/chosen': 0.19642579555511475, 'epoch': 2.63}

 44%|████▍     | 7056/16104 [32:33:10<48:01:20, 19.11s/it]
[2024-04-06 23:57:46,545] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 44%|████▍     | 7057/16104 [32:33:32<49:58:26, 19.89s/it]
[2024-04-06 23:58:06,513] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 44%|████▍     | 7059/16104 [32:34:05<44:49:02, 17.84s/it]

 44%|████▍     | 7060/16104 [32:34:25<46:18:00, 18.43s/it]
{'loss': 0.4382, 'learning_rate': 1.2456496704646951e-06, 'rewards/chosen': -1.2634810209274292, 'rewards/rejected': -2.849761962890625, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5862808227539062, 'policy_logps/rejected': -324.6732482910156, 'policy_logps/chosen': -423.77313232421875, 'referece_logps/rejected': -296.17559814453125, 'referece_logps/chosen': -411.13836669921875, 'logits/rejected': -0.06847228109836578, 'logits/chosen': -0.24660679697990417, 'epoch': 2.63}


 44%|████▍     | 7062/16104 [32:34:57<42:04:58, 16.76s/it]
{'loss': 0.5537, 'learning_rate': 1.245259723573131e-06, 'rewards/chosen': -1.7016736268997192, 'rewards/rejected': -2.3888652324676514, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6871916055679321, 'policy_logps/rejected': -469.52545166015625, 'policy_logps/chosen': -442.1005859375, 'referece_logps/rejected': -445.63677978515625, 'referece_logps/chosen': -425.0838623046875, 'logits/rejected': -0.8498217463493347, 'logits/chosen': -0.9555765390396118, 'epoch': 2.63}

 44%|████▍     | 7063/16104 [32:35:16<43:56:21, 17.50s/it]
[2024-04-06 23:59:50,974] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 44%|████▍     | 7064/16104 [32:35:36<45:59:53, 18.32s/it]


 44%|████▍     | 7066/16104 [32:36:09<43:56:49, 17.50s/it]

 44%|████▍     | 7067/16104 [32:36:25<42:27:09, 16.91s/it]

 44%|████▍     | 7068/16104 [32:36:37<38:42:44, 15.42s/it]

 44%|████▍     | 7069/16104 [32:36:55<40:44:34, 16.23s/it]

 44%|████▍     | 7070/16104 [32:37:14<43:05:59, 17.18s/it]
{'loss': 0.3704, 'learning_rate': 1.243699539790198e-06, 'rewards/chosen': -2.1598665714263916, 'rewards/rejected': -3.205784797668457, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0459184646606445, 'policy_logps/rejected': -349.0115051269531, 'policy_logps/chosen': -331.820068359375, 'referece_logps/rejected': -316.95367431640625, 'referece_logps/chosen': -310.2214050292969, 'logits/rejected': 0.326307088136673, 'logits/chosen': 0.27570652961730957, 'epoch': 2.63}


 44%|████▍     | 7072/16104 [32:37:51<43:55:11, 17.51s/it]
{'loss': 0.3401, 'learning_rate': 1.2433093951058566e-06, 'rewards/chosen': -1.2664504051208496, 'rewards/rejected': -3.099485397338867, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8330353498458862, 'policy_logps/rejected': -353.0187683105469, 'policy_logps/chosen': -418.92132568359375, 'referece_logps/rejected': -322.02392578125, 'referece_logps/chosen': -406.2568359375, 'logits/rejected': -0.1555441915988922, 'logits/chosen': -0.22040626406669617, 'epoch': 2.63}


 44%|████▍     | 7074/16104 [32:38:31<47:36:04, 18.98s/it]

 44%|████▍     | 7075/16104 [32:38:47<45:18:22, 18.06s/it]

 44%|████▍     | 7076/16104 [32:39:05<45:22:04, 18.09s/it]

 44%|████▍     | 7077/16104 [32:39:18<40:58:55, 16.34s/it]

 44%|████▍     | 7078/16104 [32:39:33<40:26:05, 16.13s/it]

 44%|████▍     | 7079/16104 [32:39:53<43:27:47, 17.34s/it]
{'loss': 0.3516, 'learning_rate': 1.2419435790925755e-06, 'rewards/chosen': -1.6678733825683594, 'rewards/rejected': -2.6217525005340576, 'rewards/accuracies': 0.75, 'rewards/margins': 0.953879177570343, 'policy_logps/rejected': -418.20391845703125, 'policy_logps/chosen': -435.86627197265625, 'referece_logps/rejected': -391.98638916015625, 'referece_logps/chosen': -419.1875915527344, 'logits/rejected': 0.5749585032463074, 'logits/chosen': 0.6924347877502441, 'epoch': 2.64}


 44%|████▍     | 7081/16104 [32:40:15<35:12:33, 14.05s/it]
{'loss': 0.3721, 'learning_rate': 1.2415532577440766e-06, 'rewards/chosen': -1.162232518196106, 'rewards/rejected': -3.035508394241333, 'rewards/accuracies': 0.875, 'rewards/margins': 1.873275637626648, 'policy_logps/rejected': -302.5918273925781, 'policy_logps/chosen': -421.33563232421875, 'referece_logps/rejected': -272.2367248535156, 'referece_logps/chosen': -409.7133483886719, 'logits/rejected': -1.0852957963943481, 'logits/chosen': -1.1794819831848145, 'epoch': 2.64}


 44%|████▍     | 7083/16104 [32:40:47<37:39:30, 15.03s/it]
{'loss': 0.4249, 'learning_rate': 1.2411628973105365e-06, 'rewards/chosen': -1.9868178367614746, 'rewards/rejected': -4.034282684326172, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0474650859832764, 'policy_logps/rejected': -506.48345947265625, 'policy_logps/chosen': -593.8321533203125, 'referece_logps/rejected': -466.1405944824219, 'referece_logps/chosen': -573.9639282226562, 'logits/rejected': -0.2039187252521515, 'logits/chosen': -0.325086772441864, 'epoch': 2.64}

 44%|████▍     | 7084/16104 [32:41:06<40:59:11, 16.36s/it]

 44%|████▍     | 7085/16104 [32:41:21<39:25:53, 15.74s/it]

 44%|████▍     | 7086/16104 [32:41:40<42:19:18, 16.89s/it]


 44%|████▍     | 7088/16104 [32:42:12<41:21:41, 16.52s/it]
{'loss': 0.2894, 'learning_rate': 1.2401868256441558e-06, 'rewards/chosen': -1.5239129066467285, 'rewards/rejected': -3.097161054611206, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5732483863830566, 'policy_logps/rejected': -428.133056640625, 'policy_logps/chosen': -503.9981689453125, 'referece_logps/rejected': -397.16143798828125, 'referece_logps/chosen': -488.7590026855469, 'logits/rejected': -0.13445836305618286, 'logits/chosen': -0.13228201866149902, 'epoch': 2.64}


 44%|████▍     | 7090/16104 [32:42:42<40:32:56, 16.19s/it]
{'loss': 0.2593, 'learning_rate': 1.2397963289104234e-06, 'rewards/chosen': -1.179789662361145, 'rewards/rejected': -2.8834939002990723, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7037041187286377, 'policy_logps/rejected': -384.3935852050781, 'policy_logps/chosen': -560.28857421875, 'referece_logps/rejected': -355.55859375, 'referece_logps/chosen': -548.4906616210938, 'logits/rejected': -0.6997557282447815, 'logits/chosen': -0.8011375665664673, 'epoch': 2.64}


 44%|████▍     | 7092/16104 [32:43:16<41:13:25, 16.47s/it]
{'loss': 0.2719, 'learning_rate': 1.239405793375934e-06, 'rewards/chosen': -1.6819324493408203, 'rewards/rejected': -3.172212839126587, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4902803897857666, 'policy_logps/rejected': -403.3656005859375, 'policy_logps/chosen': -331.7140197753906, 'referece_logps/rejected': -371.64349365234375, 'referece_logps/chosen': -314.89471435546875, 'logits/rejected': 0.018058136105537415, 'logits/chosen': 0.09330718219280243, 'epoch': 2.64}


 44%|████▍     | 7094/16104 [32:43:44<38:25:26, 15.35s/it]
{'loss': 0.2459, 'learning_rate': 1.2390152191038784e-06, 'rewards/chosen': -1.829327940940857, 'rewards/rejected': -3.9245762825012207, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0952486991882324, 'policy_logps/rejected': -427.1331787109375, 'policy_logps/chosen': -373.0718688964844, 'referece_logps/rejected': -387.8874206542969, 'referece_logps/chosen': -354.77862548828125, 'logits/rejected': -0.4093043804168701, 'logits/chosen': -0.20301054418087006, 'epoch': 2.64}


 44%|████▍     | 7096/16104 [32:44:24<43:32:08, 17.40s/it]
{'loss': 0.3496, 'learning_rate': 1.2386246061574547e-06, 'rewards/chosen': -1.6196218729019165, 'rewards/rejected': -2.8986799716949463, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2790583372116089, 'policy_logps/rejected': -412.1058044433594, 'policy_logps/chosen': -484.3800354003906, 'referece_logps/rejected': -383.1189880371094, 'referece_logps/chosen': -468.18377685546875, 'logits/rejected': -0.12054941803216934, 'logits/chosen': -0.03985269367694855, 'epoch': 2.64}

 44%|████▍     | 7097/16104 [32:44:41<43:39:48, 17.45s/it]

 44%|████▍     | 7098/16104 [32:45:01<45:19:16, 18.12s/it]

 44%|████▍     | 7099/16104 [32:45:21<46:56:13, 18.76s/it]


 44%|████▍     | 7101/16104 [32:45:54<43:08:25, 17.25s/it]

 44%|████▍     | 7102/16104 [32:46:06<39:00:11, 15.60s/it]
{'loss': 0.4475, 'learning_rate': 1.2374525359040458e-06, 'rewards/chosen': -1.953138828277588, 'rewards/rejected': -4.650265693664551, 'rewards/accuracies': 0.75, 'rewards/margins': 2.697126865386963, 'policy_logps/rejected': -303.9486083984375, 'policy_logps/chosen': -407.4768981933594, 'referece_logps/rejected': -257.4459533691406, 'referece_logps/chosen': -387.9455261230469, 'logits/rejected': -1.0325469970703125, 'logits/chosen': -1.3015598058700562, 'epoch': 2.65}

 44%|████▍     | 7103/16104 [32:46:25<42:00:49, 16.80s/it]

 44%|████▍     | 7104/16104 [32:46:45<44:06:03, 17.64s/it]

 44%|████▍     | 7105/16104 [32:46:57<39:59:06, 16.00s/it]

 44%|████▍     | 7106/16104 [32:47:17<43:10:33, 17.27s/it]


 44%|████▍     | 7108/16104 [32:47:56<45:50:03, 18.34s/it]

 44%|████▍     | 7109/16104 [32:48:10<42:36:47, 17.05s/it]
{'loss': 0.2918, 'learning_rate': 1.2360846836835938e-06, 'rewards/chosen': -1.9144667387008667, 'rewards/rejected': -3.8397934436798096, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9253267049789429, 'policy_logps/rejected': -299.2327575683594, 'policy_logps/chosen': -312.2713623046875, 'referece_logps/rejected': -260.8348083496094, 'referece_logps/chosen': -293.1266784667969, 'logits/rejected': -0.5548654794692993, 'logits/chosen': -0.4262771010398865, 'epoch': 2.65}

 44%|████▍     | 7110/16104 [32:48:25<41:20:05, 16.54s/it]

 44%|████▍     | 7111/16104 [32:48:45<43:46:46, 17.53s/it]


 44%|████▍     | 7113/16104 [32:49:16<39:59:51, 16.02s/it]
{'loss': 0.5716, 'learning_rate': 1.235302843568402e-06, 'rewards/chosen': -1.7590916156768799, 'rewards/rejected': -2.237947940826416, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4788564443588257, 'policy_logps/rejected': -454.3683166503906, 'policy_logps/chosen': -389.4459228515625, 'referece_logps/rejected': -431.9888610839844, 'referece_logps/chosen': -371.8550109863281, 'logits/rejected': -0.22421514987945557, 'logits/chosen': -0.11075064539909363, 'epoch': 2.65}

 44%|████▍     | 7114/16104 [32:49:27<35:56:49, 14.39s/it]


 44%|████▍     | 7116/16104 [32:49:48<31:11:19, 12.49s/it]
{'loss': 0.5166, 'learning_rate': 1.234716363510927e-06, 'rewards/chosen': -1.039997935295105, 'rewards/rejected': -2.4096970558166504, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3696990013122559, 'policy_logps/rejected': -526.399658203125, 'policy_logps/chosen': -535.4125366210938, 'referece_logps/rejected': -502.30267333984375, 'referece_logps/chosen': -525.0125122070312, 'logits/rejected': -0.02811010181903839, 'logits/chosen': -0.15865987539291382, 'epoch': 2.65}

 44%|████▍     | 7117/16104 [32:50:05<34:21:53, 13.77s/it]

 44%|████▍     | 7118/16104 [32:50:16<32:07:24, 12.87s/it]

 44%|████▍     | 7119/16104 [32:50:33<35:20:52, 14.16s/it]

 44%|████▍     | 7120/16104 [32:50:51<38:24:06, 15.39s/it]


 44%|████▍     | 7122/16104 [32:51:12<32:30:32, 13.03s/it]
{'loss': 0.4546, 'learning_rate': 1.2335431472527468e-06, 'rewards/chosen': -1.7966557741165161, 'rewards/rejected': -3.970729112625122, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1740736961364746, 'policy_logps/rejected': -253.30958557128906, 'policy_logps/chosen': -426.8652038574219, 'referece_logps/rejected': -213.602294921875, 'referece_logps/chosen': -408.898681640625, 'logits/rejected': -0.30657875537872314, 'logits/chosen': -0.3926198184490204, 'epoch': 2.65}

 44%|████▍     | 7123/16104 [32:51:23<30:44:21, 12.32s/it]


 44%|████▍     | 7125/16104 [32:51:45<28:41:27, 11.50s/it]

 44%|████▍     | 7126/16104 [32:52:04<34:51:43, 13.98s/it]
{'loss': 0.3726, 'learning_rate': 1.2327608140304238e-06, 'rewards/chosen': -1.8839219808578491, 'rewards/rejected': -3.570070505142212, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6861488819122314, 'policy_logps/rejected': -395.9875793457031, 'policy_logps/chosen': -302.87933349609375, 'referece_logps/rejected': -360.28692626953125, 'referece_logps/chosen': -284.0401306152344, 'logits/rejected': -1.594208002090454, 'logits/chosen': -1.3851265907287598, 'epoch': 2.65}

 44%|████▍     | 7127/16104 [32:52:17<33:42:51, 13.52s/it]


 44%|████▍     | 7129/16104 [32:52:44<34:15:29, 13.74s/it]
{'loss': 0.4481, 'learning_rate': 1.232173965222294e-06, 'rewards/chosen': -1.6113461256027222, 'rewards/rejected': -3.733077049255371, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1217310428619385, 'policy_logps/rejected': -393.00579833984375, 'policy_logps/chosen': -520.5505981445312, 'referece_logps/rejected': -355.6750183105469, 'referece_logps/chosen': -504.4371643066406, 'logits/rejected': -0.2834996283054352, 'logits/chosen': -0.11924444884061813, 'epoch': 2.66}

 44%|████▍     | 7130/16104 [32:52:59<35:17:15, 14.16s/it]

 44%|████▍     | 7131/16104 [32:53:17<38:10:17, 15.31s/it]

 44%|████▍     | 7132/16104 [32:53:37<41:06:50, 16.50s/it]


 44%|████▍     | 7134/16104 [32:54:12<42:12:27, 16.94s/it]
{'loss': 0.3018, 'learning_rate': 1.2311956961439124e-06, 'rewards/chosen': -1.4369498491287231, 'rewards/rejected': -3.3509280681610107, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9139782190322876, 'policy_logps/rejected': -275.8658142089844, 'policy_logps/chosen': -258.5141296386719, 'referece_logps/rejected': -242.35653686523438, 'referece_logps/chosen': -244.14462280273438, 'logits/rejected': -0.7993319630622864, 'logits/chosen': -0.768281102180481, 'epoch': 2.66}


 44%|████▍     | 7136/16104 [32:54:48<43:17:48, 17.38s/it]

 44%|████▍     | 7137/16104 [32:55:00<39:08:28, 15.71s/it]
{'loss': 0.2806, 'learning_rate': 1.2306086224062248e-06, 'rewards/chosen': -1.7420170307159424, 'rewards/rejected': -4.24773645401001, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5057196617126465, 'policy_logps/rejected': -502.2423095703125, 'policy_logps/chosen': -370.7532043457031, 'referece_logps/rejected': -459.76495361328125, 'referece_logps/chosen': -353.3330383300781, 'logits/rejected': -0.7234312295913696, 'logits/chosen': -0.43457967042922974, 'epoch': 2.66}

 44%|████▍     | 7138/16104 [32:55:14<37:18:01, 14.98s/it]


 44%|████▍     | 7140/16104 [32:55:49<41:15:26, 16.57s/it]
[2024-04-07 00:20:03,252] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 44%|████▍     | 7141/16104 [32:56:07<42:25:35, 17.04s/it]
[2024-04-07 00:20:21,393] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3218, 'learning_rate': 1.2298257268601668e-06, 'rewards/chosen': -2.033604860305786, 'rewards/rejected': -4.518879413604736, 'rewards/accuracies': 1.0, 'rewards/margins': 2.48527455329895, 'policy_logps/rejected': -332.1026611328125, 'policy_logps/chosen': -333.6074523925781, 'referece_logps/rejected': -286.9138488769531, 'referece_logps/chosen': -313.2713928222656, 'logits/rejected': -0.8009583353996277, 'logits/chosen': -0.6965357065200806, 'epoch': 2.66}

 44%|████▍     | 7142/16104 [32:56:24<42:40:58, 17.15s/it]

 44%|████▍     | 7143/16104 [32:56:40<41:57:45, 16.86s/it]

 44%|████▍     | 7144/16104 [32:57:00<44:01:27, 17.69s/it]

 44%|████▍     | 7145/16104 [32:57:16<42:30:13, 17.08s/it]

 44%|████▍     | 7146/16104 [32:57:36<44:46:32, 17.99s/it]


 44%|████▍     | 7148/16104 [32:58:16<47:44:56, 19.19s/it]
{'loss': 0.5689, 'learning_rate': 1.2284553020303168e-06, 'rewards/chosen': -2.0023458003997803, 'rewards/rejected': -2.6417391300201416, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6393935680389404, 'policy_logps/rejected': -477.153076171875, 'policy_logps/chosen': -383.5760498046875, 'referece_logps/rejected': -450.7356872558594, 'referece_logps/chosen': -363.5526123046875, 'logits/rejected': 0.040547385811805725, 'logits/chosen': -0.04402855038642883, 'epoch': 2.66}
[2024-04-07 00:22:50,724] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 44%|████▍     | 7149/16104 [32:58:36<48:03:23, 19.32s/it]

 44%|████▍     | 7150/16104 [32:58:58<50:03:06, 20.12s/it]

 44%|████▍     | 7151/16104 [32:59:15<47:55:33, 19.27s/it]

 44%|████▍     | 7152/16104 [32:59:30<44:19:05, 17.82s/it]


 44%|████▍     | 7154/16104 [33:00:11<47:45:19, 19.21s/it]
[2024-04-07 00:24:25,283] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 44%|████▍     | 7155/16104 [33:00:27<45:31:16, 18.31s/it]
{'loss': 0.3015, 'learning_rate': 1.2270844243707325e-06, 'rewards/chosen': -1.920334815979004, 'rewards/rejected': -3.8693532943725586, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9490184783935547, 'policy_logps/rejected': -480.4161682128906, 'policy_logps/chosen': -477.7386474609375, 'referece_logps/rejected': -441.72265625, 'referece_logps/chosen': -458.5353088378906, 'logits/rejected': -0.8633313179016113, 'logits/chosen': -0.608784019947052, 'epoch': 2.67}

 44%|████▍     | 7156/16104 [33:00:44<44:40:03, 17.97s/it]

 44%|████▍     | 7157/16104 [33:01:00<43:07:37, 17.35s/it]

 44%|████▍     | 7158/16104 [33:01:16<42:01:47, 16.91s/it]


 44%|████▍     | 7160/16104 [33:01:57<46:23:57, 18.68s/it]
{'loss': 0.5073, 'learning_rate': 1.2261049503049204e-06, 'rewards/chosen': -1.5540144443511963, 'rewards/rejected': -2.448289155960083, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8942745923995972, 'policy_logps/rejected': -292.4197692871094, 'policy_logps/chosen': -249.15670776367188, 'referece_logps/rejected': -267.9368896484375, 'referece_logps/chosen': -233.6165771484375, 'logits/rejected': -0.8425933718681335, 'logits/chosen': -0.793954610824585, 'epoch': 2.67}


 44%|████▍     | 7162/16104 [33:02:27<42:11:52, 16.99s/it]
{'loss': 0.3737, 'learning_rate': 1.2257130965986814e-06, 'rewards/chosen': -1.5108582973480225, 'rewards/rejected': -3.21307373046875, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7022159099578857, 'policy_logps/rejected': -479.1587219238281, 'policy_logps/chosen': -494.9169921875, 'referece_logps/rejected': -447.02801513671875, 'referece_logps/chosen': -479.80841064453125, 'logits/rejected': 1.0784273147583008, 'logits/chosen': 1.1278718709945679, 'epoch': 2.67}

 44%|████▍     | 7163/16104 [33:02:45<42:41:07, 17.19s/it]

 44%|████▍     | 7164/16104 [33:03:04<44:38:23, 17.98s/it]

 44%|████▍     | 7165/16104 [33:03:25<46:21:18, 18.67s/it]

 44%|████▍     | 7166/16104 [33:03:42<45:02:45, 18.14s/it]

 45%|████▍     | 7167/16104 [33:04:01<46:17:23, 18.65s/it]


 45%|████▍     | 7169/16104 [33:04:41<47:44:32, 19.24s/it]
{'loss': 0.3196, 'learning_rate': 1.2243413214323236e-06, 'rewards/chosen': -1.0752676725387573, 'rewards/rejected': -3.9994726181030273, 'rewards/accuracies': 1.0, 'rewards/margins': 2.9242045879364014, 'policy_logps/rejected': -262.37103271484375, 'policy_logps/chosen': -425.1646728515625, 'referece_logps/rejected': -222.3763427734375, 'referece_logps/chosen': -414.4119567871094, 'logits/rejected': -0.2934936285018921, 'logits/chosen': -0.33188366889953613, 'epoch': 2.67}


 45%|████▍     | 7171/16104 [33:05:13<43:08:15, 17.38s/it]
{'loss': 0.418, 'learning_rate': 1.2239493038765282e-06, 'rewards/chosen': -1.6810814142227173, 'rewards/rejected': -2.458752393722534, 'rewards/accuracies': 0.625, 'rewards/margins': 0.777671217918396, 'policy_logps/rejected': -387.5435791015625, 'policy_logps/chosen': -378.8184509277344, 'referece_logps/rejected': -362.9560241699219, 'referece_logps/chosen': -362.00762939453125, 'logits/rejected': -0.9865214228630066, 'logits/chosen': -1.0610404014587402, 'epoch': 2.67}


 45%|████▍     | 7173/16104 [33:05:51<45:18:22, 18.26s/it]

 45%|████▍     | 7174/16104 [33:06:11<46:27:43, 18.73s/it]

 45%|████▍     | 7175/16104 [33:06:25<43:10:04, 17.40s/it]

 45%|████▍     | 7176/16104 [33:06:41<42:08:43, 16.99s/it]

 45%|████▍     | 7177/16104 [33:07:00<42:57:18, 17.32s/it]
{'loss': 0.4704, 'learning_rate': 1.2227730340433234e-06, 'rewards/chosen': -0.2654387950897217, 'rewards/rejected': -2.532827377319336, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2673885822296143, 'policy_logps/rejected': -294.45281982421875, 'policy_logps/chosen': -296.243408203125, 'referece_logps/rejected': -269.12451171875, 'referece_logps/chosen': -293.5890197753906, 'logits/rejected': -0.6276971697807312, 'logits/chosen': -0.6561247110366821, 'epoch': 2.67}

 45%|████▍     | 7178/16104 [33:07:18<43:40:01, 17.61s/it]


 45%|████▍     | 7180/16104 [33:07:51<42:56:00, 17.32s/it]
{'loss': 0.368, 'learning_rate': 1.2221847773635057e-06, 'rewards/chosen': -1.4431486129760742, 'rewards/rejected': -4.085039138793945, 'rewards/accuracies': 0.75, 'rewards/margins': 2.641890525817871, 'policy_logps/rejected': -380.45111083984375, 'policy_logps/chosen': -359.3289794921875, 'referece_logps/rejected': -339.6007385253906, 'referece_logps/chosen': -344.89752197265625, 'logits/rejected': 0.13719354569911957, 'logits/chosen': 0.03405164182186127, 'epoch': 2.68}

 45%|████▍     | 7181/16104 [33:08:10<43:48:58, 17.68s/it]

 45%|████▍     | 7182/16104 [33:08:30<45:52:49, 18.51s/it]

 45%|████▍     | 7183/16104 [33:08:48<45:26:21, 18.34s/it]

 45%|████▍     | 7184/16104 [33:09:06<45:14:55, 18.26s/it]

 45%|████▍     | 7185/16104 [33:09:26<46:41:50, 18.85s/it]

 45%|████▍     | 7186/16104 [33:09:37<40:37:18, 16.40s/it]

 45%|████▍     | 7187/16104 [33:09:49<37:21:59, 15.09s/it]

 45%|████▍     | 7188/16104 [33:10:00<34:25:34, 13.90s/it]


 45%|████▍     | 7190/16104 [33:10:33<37:54:17, 15.31s/it]

 45%|████▍     | 7191/16104 [33:10:46<35:36:47, 14.38s/it]

 45%|████▍     | 7192/16104 [33:11:08<41:17:38, 16.68s/it]
{'loss': 0.2434, 'learning_rate': 1.2198309438869746e-06, 'rewards/chosen': -1.501451015472412, 'rewards/rejected': -3.8575873374938965, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3561363220214844, 'policy_logps/rejected': -361.754150390625, 'policy_logps/chosen': -413.03668212890625, 'referece_logps/rejected': -323.17828369140625, 'referece_logps/chosen': -398.02215576171875, 'logits/rejected': -0.21142339706420898, 'logits/chosen': -0.31292805075645447, 'epoch': 2.68}

 45%|████▍     | 7193/16104 [33:11:23<40:29:10, 16.36s/it]

 45%|████▍     | 7194/16104 [33:11:34<36:28:25, 14.74s/it]

 45%|████▍     | 7195/16104 [33:11:48<35:46:25, 14.46s/it]

 45%|████▍     | 7196/16104 [33:12:02<35:37:28, 14.40s/it]

 45%|████▍     | 7197/16104 [33:12:21<38:44:11, 15.66s/it]

 45%|████▍     | 7198/16104 [33:12:40<41:25:35, 16.75s/it]
[2024-04-07 00:37:16,679] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 45%|████▍     | 7199/16104 [33:13:02<45:14:31, 18.29s/it]

 45%|████▍     | 7200/16104 [33:13:20<45:04:30, 18.22s/it]

 45%|████▍     | 7201/16104 [33:13:33<40:57:08, 16.56s/it]

 45%|████▍     | 7202/16104 [33:13:44<37:04:21, 14.99s/it]


 45%|████▍     | 7204/16104 [33:14:12<34:55:22, 14.13s/it]
{'loss': 0.396, 'learning_rate': 1.2174758298832899e-06, 'rewards/chosen': -2.1123125553131104, 'rewards/rejected': -4.533981800079346, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4216692447662354, 'policy_logps/rejected': -409.99359130859375, 'policy_logps/chosen': -470.1241149902344, 'referece_logps/rejected': -364.6537780761719, 'referece_logps/chosen': -449.0009765625, 'logits/rejected': -0.5306915044784546, 'logits/chosen': -0.8024908304214478, 'epoch': 2.68}

 45%|████▍     | 7205/16104 [33:14:31<39:03:14, 15.80s/it]

 45%|████▍     | 7206/16104 [33:14:45<37:27:13, 15.15s/it]


 45%|████▍     | 7208/16104 [33:15:22<40:55:43, 16.56s/it]
{'loss': 0.4195, 'learning_rate': 1.216690509691386e-06, 'rewards/chosen': -2.0495662689208984, 'rewards/rejected': -3.352048873901367, 'rewards/accuracies': 0.5, 'rewards/margins': 1.3024826049804688, 'policy_logps/rejected': -405.9878845214844, 'policy_logps/chosen': -417.33477783203125, 'referece_logps/rejected': -372.4673767089844, 'referece_logps/chosen': -396.839111328125, 'logits/rejected': -1.2356699705123901, 'logits/chosen': -1.2576568126678467, 'epoch': 2.69}

 45%|████▍     | 7209/16104 [33:15:36<39:35:07, 16.02s/it]

 45%|████▍     | 7210/16104 [33:15:57<42:54:30, 17.37s/it]

 45%|████▍     | 7211/16104 [33:16:12<41:09:02, 16.66s/it]


 45%|████▍     | 7213/16104 [33:16:34<34:02:41, 13.78s/it]
{'loss': 0.4936, 'learning_rate': 1.2157086622869385e-06, 'rewards/chosen': -1.6602150201797485, 'rewards/rejected': -2.54491925239563, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8847041130065918, 'policy_logps/rejected': -368.2793273925781, 'policy_logps/chosen': -348.4307861328125, 'referece_logps/rejected': -342.8301696777344, 'referece_logps/chosen': -331.82867431640625, 'logits/rejected': 0.3459695875644684, 'logits/chosen': 0.32169198989868164, 'epoch': 2.69}

 45%|████▍     | 7214/16104 [33:16:45<31:58:23, 12.95s/it]

 45%|████▍     | 7215/16104 [33:16:57<31:27:14, 12.74s/it]

 45%|████▍     | 7216/16104 [33:17:08<29:48:54, 12.08s/it]

 45%|████▍     | 7217/16104 [33:17:25<33:10:49, 13.44s/it]

 45%|████▍     | 7218/16104 [33:17:42<36:15:35, 14.69s/it]

 45%|████▍     | 7219/16104 [33:17:57<36:06:03, 14.63s/it]

 45%|████▍     | 7220/16104 [33:18:11<36:10:09, 14.66s/it]

 45%|████▍     | 7221/16104 [33:18:25<35:03:09, 14.21s/it]

 45%|████▍     | 7222/16104 [33:18:36<32:41:48, 13.25s/it]

 45%|████▍     | 7223/16104 [33:18:57<38:40:45, 15.68s/it]

 45%|████▍     | 7224/16104 [33:19:16<41:01:50, 16.63s/it]

 45%|████▍     | 7225/16104 [33:19:34<42:05:29, 17.07s/it]

 45%|████▍     | 7226/16104 [33:19:46<38:42:13, 15.69s/it]

 45%|████▍     | 7227/16104 [33:19:57<35:18:16, 14.32s/it]

 45%|████▍     | 7228/16104 [33:20:13<36:08:32, 14.66s/it]

 45%|████▍     | 7229/16104 [33:20:29<37:28:17, 15.20s/it]

 45%|████▍     | 7230/16104 [33:20:49<40:59:09, 16.63s/it]

 45%|████▍     | 7231/16104 [33:21:01<37:23:02, 15.17s/it]

 45%|████▍     | 7232/16104 [33:21:16<37:28:41, 15.21s/it]

 45%|████▍     | 7233/16104 [33:21:30<36:23:23, 14.77s/it]

 45%|████▍     | 7234/16104 [33:21:41<33:24:57, 13.56s/it]

 45%|████▍     | 7235/16104 [33:21:58<35:49:19, 14.54s/it]

 45%|████▍     | 7236/16104 [33:22:16<38:34:52, 15.66s/it]

 45%|████▍     | 7237/16104 [33:22:28<35:57:39, 14.60s/it]

 45%|████▍     | 7238/16104 [33:22:47<38:50:15, 15.77s/it]

 45%|████▍     | 7239/16104 [33:22:57<35:04:41, 14.24s/it]

 45%|████▍     | 7240/16104 [33:23:08<32:45:31, 13.30s/it]

 45%|████▍     | 7241/16104 [33:23:28<37:25:14, 15.20s/it]

 45%|████▍     | 7242/16104 [33:23:43<37:02:24, 15.05s/it]

 45%|████▍     | 7243/16104 [33:24:02<40:20:39, 16.39s/it]

 45%|████▍     | 7244/16104 [33:24:22<43:00:54, 17.48s/it]

 45%|████▍     | 7245/16104 [33:24:37<41:20:58, 16.80s/it]


 45%|████▌     | 7247/16104 [33:25:15<44:27:34, 18.07s/it]
{'loss': 0.3941, 'learning_rate': 1.2090263656661893e-06, 'rewards/chosen': -1.323432445526123, 'rewards/rejected': -2.3899810314178467, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0665485858917236, 'policy_logps/rejected': -384.6547546386719, 'policy_logps/chosen': -387.9267578125, 'referece_logps/rejected': -360.75494384765625, 'referece_logps/chosen': -374.6924743652344, 'logits/rejected': -0.5639176964759827, 'logits/chosen': -0.5696009397506714, 'epoch': 2.7}

 45%|████▌     | 7248/16104 [33:25:34<45:42:29, 18.58s/it]

 45%|████▌     | 7249/16104 [33:25:54<46:36:28, 18.95s/it]

 45%|████▌     | 7250/16104 [33:26:14<47:10:05, 19.18s/it]

 45%|████▌     | 7251/16104 [33:26:26<41:32:51, 16.90s/it]

 45%|████▌     | 7252/16104 [33:26:42<40:58:45, 16.67s/it]

 45%|████▌     | 7253/16104 [33:26:52<36:34:15, 14.87s/it]

 45%|████▌     | 7254/16104 [33:27:03<33:29:51, 13.63s/it]

 45%|████▌     | 7255/16104 [33:27:14<31:19:39, 12.74s/it]

 45%|████▌     | 7256/16104 [33:27:24<29:46:02, 12.11s/it]

 45%|████▌     | 7257/16104 [33:27:42<33:53:12, 13.79s/it]

 45%|████▌     | 7258/16104 [33:27:55<33:15:05, 13.53s/it]

 45%|████▌     | 7259/16104 [33:28:14<37:24:49, 15.23s/it]

 45%|████▌     | 7260/16104 [33:28:35<41:29:55, 16.89s/it]

 45%|████▌     | 7261/16104 [33:28:52<41:24:49, 16.86s/it]

 45%|████▌     | 7262/16104 [33:29:06<39:29:48, 16.08s/it]

 45%|████▌     | 7263/16104 [33:29:21<38:44:48, 15.78s/it]

 45%|████▌     | 7264/16104 [33:29:34<36:54:25, 15.03s/it]

 45%|████▌     | 7265/16104 [33:29:53<39:36:34, 16.13s/it]
[2024-04-07 00:54:29,111] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 45%|████▌     | 7266/16104 [33:30:14<43:27:05, 17.70s/it]

 45%|████▌     | 7267/16104 [33:30:33<43:42:10, 17.80s/it]

 45%|████▌     | 7268/16104 [33:30:46<40:45:49, 16.61s/it]

 45%|████▌     | 7269/16104 [33:30:59<37:43:19, 15.37s/it]

 45%|████▌     | 7270/16104 [33:31:13<36:40:22, 14.94s/it]

 45%|████▌     | 7271/16104 [33:31:32<40:03:25, 16.33s/it]

 45%|████▌     | 7272/16104 [33:31:52<42:34:04, 17.35s/it]

 45%|████▌     | 7273/16104 [33:32:06<40:11:02, 16.38s/it]

 45%|████▌     | 7274/16104 [33:32:19<37:25:21, 15.26s/it]

 45%|████▌     | 7275/16104 [33:32:30<34:05:06, 13.90s/it]

 45%|████▌     | 7276/16104 [33:32:42<33:03:28, 13.48s/it]

 45%|████▌     | 7277/16104 [33:32:55<33:01:56, 13.47s/it]

 45%|████▌     | 7278/16104 [33:33:15<37:23:07, 15.25s/it]

 45%|████▌     | 7279/16104 [33:33:33<39:24:07, 16.07s/it]

 45%|████▌     | 7280/16104 [33:33:53<42:06:01, 17.18s/it]

 45%|████▌     | 7281/16104 [33:34:08<41:00:06, 16.73s/it]

 45%|████▌     | 7282/16104 [33:34:27<42:26:21, 17.32s/it]

 45%|████▌     | 7283/16104 [33:34:45<43:10:34, 17.62s/it]

 45%|████▌     | 7284/16104 [33:34:56<38:20:12, 15.65s/it]


 45%|████▌     | 7286/16104 [33:35:35<42:56:27, 17.53s/it]

 45%|████▌     | 7287/16104 [33:35:54<44:05:47, 18.00s/it]

 45%|████▌     | 7288/16104 [33:36:11<43:11:45, 17.64s/it]

 45%|████▌     | 7289/16104 [33:36:30<44:00:59, 17.98s/it]

 45%|████▌     | 7290/16104 [33:36:46<43:04:30, 17.59s/it]

 45%|████▌     | 7291/16104 [33:37:06<44:38:12, 18.23s/it]

 45%|████▌     | 7292/16104 [33:37:26<45:35:57, 18.63s/it]

 45%|████▌     | 7293/16104 [33:37:45<46:16:34, 18.91s/it]

 45%|████▌     | 7294/16104 [33:38:04<46:14:46, 18.90s/it]

 45%|████▌     | 7295/16104 [33:38:23<46:07:50, 18.85s/it]

 45%|████▌     | 7296/16104 [33:38:41<45:47:39, 18.72s/it]

 45%|████▌     | 7297/16104 [33:38:52<40:09:15, 16.41s/it]

 45%|████▌     | 7298/16104 [33:39:03<36:21:59, 14.87s/it]

 45%|████▌     | 7299/16104 [33:39:23<39:47:10, 16.27s/it]

 45%|████▌     | 7300/16104 [33:39:34<36:10:30, 14.79s/it]

 45%|████▌     | 7301/16104 [33:39:51<37:49:08, 15.47s/it]

 45%|████▌     | 7302/16104 [33:40:09<39:42:42, 16.24s/it]

 45%|████▌     | 7303/16104 [33:40:24<38:40:49, 15.82s/it]

 45%|████▌     | 7304/16104 [33:40:41<39:41:17, 16.24s/it]

 45%|████▌     | 7305/16104 [33:40:57<39:22:54, 16.11s/it]

 45%|████▌     | 7306/16104 [33:41:17<42:04:14, 17.21s/it]

 45%|████▌     | 7307/16104 [33:41:37<43:51:38, 17.95s/it]

 45%|████▌     | 7308/16104 [33:41:56<45:09:55, 18.49s/it]

 45%|████▌     | 7309/16104 [33:42:17<46:49:49, 19.17s/it]

 45%|████▌     | 7310/16104 [33:42:32<43:17:15, 17.72s/it]

 45%|████▌     | 7311/16104 [33:42:51<44:14:34, 18.11s/it]

 45%|████▌     | 7312/16104 [33:43:08<43:24:05, 17.77s/it]

 45%|████▌     | 7313/16104 [33:43:24<42:30:32, 17.41s/it]

 45%|████▌     | 7314/16104 [33:43:41<41:47:49, 17.12s/it]

 45%|████▌     | 7315/16104 [33:43:53<38:10:44, 15.64s/it]

 45%|████▌     | 7316/16104 [33:44:10<39:17:11, 16.09s/it]

 45%|████▌     | 7317/16104 [33:44:20<35:12:04, 14.42s/it]

 45%|████▌     | 7318/16104 [33:44:33<33:40:16, 13.80s/it]

 45%|████▌     | 7319/16104 [33:44:44<31:40:42, 12.98s/it]
{'loss': 0.3843, 'learning_rate': 1.1948437387220797e-06, 'rewards/chosen': -1.1363130807876587, 'rewards/rejected': -2.274155855178833, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1378428936004639, 'policy_logps/rejected': -336.73541259765625, 'policy_logps/chosen': -420.64312744140625, 'referece_logps/rejected': -313.99383544921875, 'referece_logps/chosen': -409.27996826171875, 'logits/rejected': -0.48140740394592285, 'logits/chosen': -0.4381040036678314, 'epoch': 2.73}


 45%|████▌     | 7321/16104 [33:45:20<38:15:16, 15.68s/it]

 45%|████▌     | 7322/16104 [33:45:34<36:53:31, 15.12s/it]

 45%|████▌     | 7323/16104 [33:45:51<38:45:43, 15.89s/it]

 45%|████▌     | 7324/16104 [33:46:02<34:50:42, 14.29s/it]

 45%|████▌     | 7325/16104 [33:46:20<37:52:16, 15.53s/it]

 45%|████▌     | 7326/16104 [33:46:38<39:20:04, 16.13s/it]

 45%|████▌     | 7327/16104 [33:46:52<37:43:16, 15.47s/it]
{'loss': 0.3133, 'learning_rate': 1.1932653146788101e-06, 'rewards/chosen': -1.3004008531570435, 'rewards/rejected': -2.9496212005615234, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6492204666137695, 'policy_logps/rejected': -346.8698425292969, 'policy_logps/chosen': -300.8719482421875, 'referece_logps/rejected': -317.3736572265625, 'referece_logps/chosen': -287.86798095703125, 'logits/rejected': -0.09988078474998474, 'logits/chosen': -0.09086339175701141, 'epoch': 2.73}

 46%|████▌     | 7328/16104 [33:47:09<38:43:03, 15.88s/it]

 46%|████▌     | 7329/16104 [33:47:26<39:58:16, 16.40s/it]


 46%|████▌     | 7331/16104 [33:48:06<44:14:51, 18.16s/it]
{'loss': 0.2539, 'learning_rate': 1.1924759147715199e-06, 'rewards/chosen': -2.8935039043426514, 'rewards/rejected': -3.984362840652466, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0908589363098145, 'policy_logps/rejected': -354.16864013671875, 'policy_logps/chosen': -431.13250732421875, 'referece_logps/rejected': -314.3250427246094, 'referece_logps/chosen': -402.1974792480469, 'logits/rejected': 0.07146953046321869, 'logits/chosen': 0.11982489377260208, 'epoch': 2.73}


 46%|████▌     | 7333/16104 [33:48:41<43:14:36, 17.75s/it]

 46%|████▌     | 7334/16104 [33:49:00<43:54:43, 18.03s/it]

 46%|████▌     | 7335/16104 [33:49:15<42:04:18, 17.27s/it]

 46%|████▌     | 7336/16104 [33:49:37<45:43:14, 18.77s/it]

 46%|████▌     | 7337/16104 [33:49:49<40:36:50, 16.68s/it]
{'loss': 0.4653, 'learning_rate': 1.191291581490454e-06, 'rewards/chosen': -1.670820713043213, 'rewards/rejected': -2.682175874710083, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0113552808761597, 'policy_logps/rejected': -473.3323669433594, 'policy_logps/chosen': -724.7631225585938, 'referece_logps/rejected': -446.5105895996094, 'referece_logps/chosen': -708.054931640625, 'logits/rejected': -0.31414905190467834, 'logits/chosen': -0.46241456270217896, 'epoch': 2.73}


 46%|████▌     | 7339/16104 [33:50:14<35:08:14, 14.43s/it]

 46%|████▌     | 7340/16104 [33:50:33<38:19:34, 15.74s/it]

 46%|████▌     | 7341/16104 [33:50:53<41:25:19, 17.02s/it]
{'loss': 0.3149, 'learning_rate': 1.1905018711015658e-06, 'rewards/chosen': -1.9805290699005127, 'rewards/rejected': -4.006740093231201, 'rewards/accuracies': 0.625, 'rewards/margins': 2.0262105464935303, 'policy_logps/rejected': -333.1189880371094, 'policy_logps/chosen': -387.7735595703125, 'referece_logps/rejected': -293.05157470703125, 'referece_logps/chosen': -367.9682922363281, 'logits/rejected': 0.09747719019651413, 'logits/chosen': 0.1965283453464508, 'epoch': 2.74}


 46%|████▌     | 7343/16104 [33:51:30<43:43:42, 17.97s/it]

 46%|████▌     | 7344/16104 [33:51:50<45:02:21, 18.51s/it]

 46%|████▌     | 7345/16104 [33:52:10<45:57:50, 18.89s/it]

 46%|████▌     | 7346/16104 [33:52:24<42:20:39, 17.41s/it]

 46%|████▌     | 7347/16104 [33:52:46<46:00:09, 18.91s/it]

 46%|████▌     | 7348/16104 [33:53:00<41:54:16, 17.23s/it]

 46%|████▌     | 7349/16104 [33:53:19<43:36:23, 17.93s/it]

 46%|████▌     | 7350/16104 [33:53:34<41:13:55, 16.96s/it]

 46%|████▌     | 7351/16104 [33:53:48<39:27:29, 16.23s/it]
{'loss': 0.5166, 'learning_rate': 1.1885270568178057e-06, 'rewards/chosen': -1.693024754524231, 'rewards/rejected': -1.9186506271362305, 'rewards/accuracies': 0.5, 'rewards/margins': 0.22562581300735474, 'policy_logps/rejected': -361.437255859375, 'policy_logps/chosen': -468.70037841796875, 'referece_logps/rejected': -342.250732421875, 'referece_logps/chosen': -451.77008056640625, 'logits/rejected': -0.4712027609348297, 'logits/chosen': -0.7856260538101196, 'epoch': 2.74}


 46%|████▌     | 7353/16104 [33:54:19<37:49:10, 15.56s/it]

 46%|████▌     | 7354/16104 [33:54:32<36:06:44, 14.86s/it]

 46%|████▌     | 7355/16104 [33:54:46<35:26:23, 14.58s/it]

 46%|████▌     | 7356/16104 [33:55:04<37:47:39, 15.55s/it]

 46%|████▌     | 7357/16104 [33:55:24<40:52:55, 16.83s/it]

 46%|████▌     | 7358/16104 [33:55:37<38:19:35, 15.78s/it]
{'loss': 0.2911, 'learning_rate': 1.1871442325816624e-06, 'rewards/chosen': -1.1973168849945068, 'rewards/rejected': -3.101567029953003, 'rewards/accuracies': 0.875, 'rewards/margins': 1.904249906539917, 'policy_logps/rejected': -319.0401611328125, 'policy_logps/chosen': -412.7334899902344, 'referece_logps/rejected': -288.0245056152344, 'referece_logps/chosen': -400.76031494140625, 'logits/rejected': -0.4339408278465271, 'logits/chosen': -0.5732811689376831, 'epoch': 2.74}

 46%|████▌     | 7359/16104 [33:55:57<41:04:02, 16.91s/it]


 46%|████▌     | 7361/16104 [33:56:30<40:18:41, 16.60s/it]

 46%|████▌     | 7362/16104 [33:56:50<42:27:03, 17.48s/it]
{'loss': 0.3934, 'learning_rate': 1.1863538805810584e-06, 'rewards/chosen': -1.2818044424057007, 'rewards/rejected': -3.3657546043395996, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0839500427246094, 'policy_logps/rejected': -378.1294250488281, 'policy_logps/chosen': -383.2007751464844, 'referece_logps/rejected': -344.47186279296875, 'referece_logps/chosen': -370.3827209472656, 'logits/rejected': -0.5379794836044312, 'logits/chosen': -0.5455319285392761, 'epoch': 2.74}

 46%|████▌     | 7363/16104 [33:57:09<43:53:34, 18.08s/it]


 46%|████▌     | 7365/16104 [33:57:46<43:47:04, 18.04s/it]

 46%|████▌     | 7366/16104 [33:58:02<42:11:06, 17.38s/it]
{'loss': 0.3885, 'learning_rate': 1.1855634079669087e-06, 'rewards/chosen': -2.113593339920044, 'rewards/rejected': -3.814877510070801, 'rewards/accuracies': 0.75, 'rewards/margins': 1.701284408569336, 'policy_logps/rejected': -277.0799560546875, 'policy_logps/chosen': -386.200439453125, 'referece_logps/rejected': -238.93121337890625, 'referece_logps/chosen': -365.06451416015625, 'logits/rejected': -0.4472464621067047, 'logits/chosen': -0.59096759557724, 'epoch': 2.74}

 46%|████▌     | 7367/16104 [33:58:21<43:49:15, 18.06s/it]


 46%|████▌     | 7369/16104 [33:58:53<40:56:28, 16.87s/it]
{'loss': 0.595, 'learning_rate': 1.1849704746614234e-06, 'rewards/chosen': -1.6471110582351685, 'rewards/rejected': -2.242034435272217, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5949233770370483, 'policy_logps/rejected': -491.8391418457031, 'policy_logps/chosen': -411.2813720703125, 'referece_logps/rejected': -469.41876220703125, 'referece_logps/chosen': -394.810302734375, 'logits/rejected': -0.4687146544456482, 'logits/chosen': -0.4579322338104248, 'epoch': 2.75}

 46%|████▌     | 7370/16104 [33:59:09<40:40:36, 16.77s/it]


 46%|████▌     | 7372/16104 [33:59:50<45:31:59, 18.77s/it]
{'loss': 0.5485, 'learning_rate': 1.1843774740144672e-06, 'rewards/chosen': -1.6901568174362183, 'rewards/rejected': -2.349287986755371, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6591313481330872, 'policy_logps/rejected': -524.7749633789062, 'policy_logps/chosen': -508.2922668457031, 'referece_logps/rejected': -501.2820739746094, 'referece_logps/chosen': -491.39068603515625, 'logits/rejected': -0.7070618867874146, 'logits/chosen': -0.7591812014579773, 'epoch': 2.75}

 46%|████▌     | 7373/16104 [34:00:09<45:27:02, 18.74s/it]


 46%|████▌     | 7375/16104 [34:00:38<39:42:08, 16.37s/it]

 46%|████▌     | 7376/16104 [34:00:50<36:16:45, 14.96s/it]

 46%|████▌     | 7377/16104 [34:01:10<39:37:52, 16.35s/it]

 46%|████▌     | 7378/16104 [34:01:25<38:31:29, 15.89s/it]
{'loss': 0.4344, 'learning_rate': 1.183191271559735e-06, 'rewards/chosen': -1.3327738046646118, 'rewards/rejected': -2.5370235443115234, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2042498588562012, 'policy_logps/rejected': -293.2856140136719, 'policy_logps/chosen': -318.1829833984375, 'referece_logps/rejected': -267.91534423828125, 'referece_logps/chosen': -304.8552551269531, 'logits/rejected': -1.203620195388794, 'logits/chosen': -1.3432788848876953, 'epoch': 2.75}

 46%|████▌     | 7379/16104 [34:01:41<39:02:49, 16.11s/it]

 46%|████▌     | 7380/16104 [34:01:55<37:41:12, 15.55s/it]

 46%|████▌     | 7381/16104 [34:02:15<40:43:45, 16.81s/it]

 46%|████▌     | 7382/16104 [34:02:29<38:37:40, 15.94s/it]

 46%|████▌     | 7383/16104 [34:02:43<37:17:03, 15.39s/it]

 46%|████▌     | 7384/16104 [34:03:01<39:11:39, 16.18s/it]

 46%|████▌     | 7385/16104 [34:03:17<39:09:42, 16.17s/it]


 46%|████▌     | 7387/16104 [34:03:54<41:21:00, 17.08s/it]

 46%|████▌     | 7388/16104 [34:04:05<36:42:35, 15.16s/it]
{'loss': 0.3966, 'learning_rate': 1.1812136754887026e-06, 'rewards/chosen': -1.820294737815857, 'rewards/rejected': -3.622684955596924, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8023900985717773, 'policy_logps/rejected': -491.53326416015625, 'policy_logps/chosen': -434.9112548828125, 'referece_logps/rejected': -455.3063659667969, 'referece_logps/chosen': -416.7082824707031, 'logits/rejected': -0.5506000518798828, 'logits/chosen': -0.3378211557865143, 'epoch': 2.75}


 46%|████▌     | 7390/16104 [34:04:33<34:23:58, 14.21s/it]
{'loss': 0.4076, 'learning_rate': 1.1808180680534834e-06, 'rewards/chosen': -2.031519651412964, 'rewards/rejected': -4.053302764892578, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0217833518981934, 'policy_logps/rejected': -415.56597900390625, 'policy_logps/chosen': -478.3841857910156, 'referece_logps/rejected': -375.032958984375, 'referece_logps/chosen': -458.0689697265625, 'logits/rejected': -0.6118205785751343, 'logits/chosen': -0.6063798069953918, 'epoch': 2.75}


 46%|████▌     | 7392/16104 [34:05:11<40:56:42, 16.92s/it]

 46%|████▌     | 7393/16104 [34:05:31<42:58:26, 17.76s/it]
{'loss': 0.448, 'learning_rate': 1.1802246020625585e-06, 'rewards/chosen': -1.2251272201538086, 'rewards/rejected': -2.471170425415039, 'rewards/accuracies': 0.5, 'rewards/margins': 1.2460432052612305, 'policy_logps/rejected': -369.9174499511719, 'policy_logps/chosen': -336.1379699707031, 'referece_logps/rejected': -345.2056884765625, 'referece_logps/chosen': -323.8866882324219, 'logits/rejected': -1.189570665359497, 'logits/chosen': -1.2364007234573364, 'epoch': 2.75}


 46%|████▌     | 7395/16104 [34:06:11<46:06:54, 19.06s/it]

 46%|████▌     | 7396/16104 [34:06:25<42:20:53, 17.51s/it]
{'loss': 0.3541, 'learning_rate': 1.1796310704579746e-06, 'rewards/chosen': -1.2793090343475342, 'rewards/rejected': -2.585921049118042, 'rewards/accuracies': 1.0, 'rewards/margins': 1.306612253189087, 'policy_logps/rejected': -565.6217041015625, 'policy_logps/chosen': -485.3389892578125, 'referece_logps/rejected': -539.762451171875, 'referece_logps/chosen': -472.5458679199219, 'logits/rejected': -0.5373290181159973, 'logits/chosen': -0.4315306544303894, 'epoch': 2.76}

 46%|████▌     | 7397/16104 [34:06:39<40:18:27, 16.67s/it]

 46%|████▌     | 7398/16104 [34:06:58<41:20:14, 17.09s/it]


 46%|████▌     | 7400/16104 [34:07:32<41:56:17, 17.35s/it]

 46%|████▌     | 7401/16104 [34:07:46<39:25:42, 16.31s/it]

 46%|████▌     | 7402/16104 [34:07:57<35:36:25, 14.73s/it]

 46%|████▌     | 7403/16104 [34:08:09<33:31:52, 13.87s/it]
{'loss': 0.387, 'learning_rate': 1.1782459094302362e-06, 'rewards/chosen': -1.7567309141159058, 'rewards/rejected': -3.0001046657562256, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2433737516403198, 'policy_logps/rejected': -371.9158020019531, 'policy_logps/chosen': -332.2305908203125, 'referece_logps/rejected': -341.9147644042969, 'referece_logps/chosen': -314.6632385253906, 'logits/rejected': -0.7320147752761841, 'logits/chosen': -0.7453827261924744, 'epoch': 2.76}


 46%|████▌     | 7405/16104 [34:08:48<40:33:09, 16.78s/it]
{'loss': 0.4338, 'learning_rate': 1.1778500841232344e-06, 'rewards/chosen': -0.6215444803237915, 'rewards/rejected': -2.193479537963867, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5719349384307861, 'policy_logps/rejected': -317.1624755859375, 'policy_logps/chosen': -350.20074462890625, 'referece_logps/rejected': -295.2276611328125, 'referece_logps/chosen': -343.98529052734375, 'logits/rejected': 0.49975496530532837, 'logits/chosen': 0.4867081046104431, 'epoch': 2.76}


 46%|████▌     | 7407/16104 [34:09:15<36:38:27, 15.17s/it]

 46%|████▌     | 7408/16104 [34:09:32<38:28:16, 15.93s/it]

 46%|████▌     | 7409/16104 [34:09:43<34:42:00, 14.37s/it]
{'loss': 0.4298, 'learning_rate': 1.1770583472410447e-06, 'rewards/chosen': -1.365061640739441, 'rewards/rejected': -3.3301286697387695, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9650671482086182, 'policy_logps/rejected': -200.50233459472656, 'policy_logps/chosen': -274.1349182128906, 'referece_logps/rejected': -167.2010498046875, 'referece_logps/chosen': -260.48431396484375, 'logits/rejected': -0.795783519744873, 'logits/chosen': -0.6800326108932495, 'epoch': 2.76}


 46%|████▌     | 7411/16104 [34:10:10<33:02:56, 13.69s/it]

 46%|████▌     | 7412/16104 [34:10:23<32:25:24, 13.43s/it]

 46%|████▌     | 7413/16104 [34:10:43<37:09:06, 15.39s/it]

 46%|████▌     | 7414/16104 [34:11:05<41:32:37, 17.21s/it]

 46%|████▌     | 7415/16104 [34:11:15<36:48:57, 15.25s/it]

 46%|████▌     | 7416/16104 [34:11:28<34:44:14, 14.39s/it]

 46%|████▌     | 7417/16104 [34:11:38<32:03:32, 13.29s/it]

 46%|████▌     | 7418/16104 [34:11:59<37:45:47, 15.65s/it]

 46%|████▌     | 7419/16104 [34:12:14<37:13:12, 15.43s/it]

 46%|████▌     | 7420/16104 [34:12:29<36:25:01, 15.10s/it]

 46%|████▌     | 7421/16104 [34:12:47<38:31:32, 15.97s/it]
{'loss': 0.3325, 'learning_rate': 1.174682451061313e-06, 'rewards/chosen': -2.0202906131744385, 'rewards/rejected': -3.387821912765503, 'rewards/accuracies': 0.875, 'rewards/margins': 1.367531418800354, 'policy_logps/rejected': -342.7822265625, 'policy_logps/chosen': -361.8343505859375, 'referece_logps/rejected': -308.90399169921875, 'referece_logps/chosen': -341.6314392089844, 'logits/rejected': -0.23688583076000214, 'logits/chosen': -0.19143402576446533, 'epoch': 2.76}


 46%|████▌     | 7423/16104 [34:13:17<37:04:37, 15.38s/it]

 46%|████▌     | 7424/16104 [34:13:33<38:09:21, 15.83s/it]

 46%|████▌     | 7425/16104 [34:13:53<41:00:17, 17.01s/it]

 46%|████▌     | 7426/16104 [34:14:13<43:01:05, 17.85s/it]

 46%|████▌     | 7427/16104 [34:14:29<41:23:26, 17.17s/it]
{'loss': 0.3505, 'learning_rate': 1.1734941205307057e-06, 'rewards/chosen': -1.6296409368515015, 'rewards/rejected': -4.31657075881958, 'rewards/accuracies': 0.625, 'rewards/margins': 2.686929702758789, 'policy_logps/rejected': -560.7571411132812, 'policy_logps/chosen': -549.5907592773438, 'referece_logps/rejected': -517.5914916992188, 'referece_logps/chosen': -533.2943725585938, 'logits/rejected': -0.15489462018013, 'logits/chosen': -0.07574320584535599, 'epoch': 2.77}

 46%|████▌     | 7428/16104 [34:14:40<37:26:52, 15.54s/it]


 46%|████▌     | 7430/16104 [34:15:13<39:14:33, 16.29s/it]

 46%|████▌     | 7431/16104 [34:15:33<41:25:42, 17.20s/it]
{'loss': 0.3603, 'learning_rate': 1.1727017597072106e-06, 'rewards/chosen': -1.2425953149795532, 'rewards/rejected': -2.808499574661255, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5659044981002808, 'policy_logps/rejected': -416.6936340332031, 'policy_logps/chosen': -406.119140625, 'referece_logps/rejected': -388.60858154296875, 'referece_logps/chosen': -393.69317626953125, 'logits/rejected': -0.4859168529510498, 'logits/chosen': -0.4666076898574829, 'epoch': 2.77}


 46%|████▌     | 7433/16104 [34:16:03<37:56:20, 15.75s/it]

 46%|████▌     | 7434/16104 [34:16:14<34:15:53, 14.23s/it]
{'loss': 0.4376, 'learning_rate': 1.1721074157075534e-06, 'rewards/chosen': -1.1336009502410889, 'rewards/rejected': -1.948472261428833, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8148711919784546, 'policy_logps/rejected': -357.9841613769531, 'policy_logps/chosen': -304.26239013671875, 'referece_logps/rejected': -338.4994201660156, 'referece_logps/chosen': -292.9263916015625, 'logits/rejected': -0.6504945755004883, 'logits/chosen': -0.5924674868583679, 'epoch': 2.77}


 46%|████▌     | 7436/16104 [34:16:35<29:50:25, 12.39s/it]

 46%|████▌     | 7437/16104 [34:16:55<35:39:30, 14.81s/it]

 46%|████▌     | 7438/16104 [34:17:16<39:43:08, 16.50s/it]

 46%|████▌     | 7439/16104 [34:17:35<41:30:11, 17.24s/it]

 46%|████▌     | 7440/16104 [34:17:55<43:45:55, 18.19s/it]
{'loss': 0.527, 'learning_rate': 1.1709185399492418e-06, 'rewards/chosen': -1.2705504894256592, 'rewards/rejected': -2.5092666149139404, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2387158870697021, 'policy_logps/rejected': -438.77777099609375, 'policy_logps/chosen': -433.5701904296875, 'referece_logps/rejected': -413.6850891113281, 'referece_logps/chosen': -420.86468505859375, 'logits/rejected': 0.5690485239028931, 'logits/chosen': 0.5470402240753174, 'epoch': 2.77}


 46%|████▌     | 7442/16104 [34:18:36<46:10:51, 19.19s/it]

 46%|████▌     | 7443/16104 [34:18:55<46:33:54, 19.36s/it]

 46%|████▌     | 7444/16104 [34:19:13<45:38:37, 18.97s/it]

 46%|████▌     | 7445/16104 [34:19:25<40:30:58, 16.84s/it]
{'loss': 0.3257, 'learning_rate': 1.1699276199432872e-06, 'rewards/chosen': -1.478476881980896, 'rewards/rejected': -3.9194960594177246, 'rewards/accuracies': 0.875, 'rewards/margins': 2.441019058227539, 'policy_logps/rejected': -308.3611755371094, 'policy_logps/chosen': -295.3385009765625, 'referece_logps/rejected': -269.1662292480469, 'referece_logps/chosen': -280.5537109375, 'logits/rejected': -0.18787726759910583, 'logits/chosen': -0.17444860935211182, 'epoch': 2.77}

 46%|████▌     | 7446/16104 [34:19:45<42:40:39, 17.75s/it]

 46%|████▌     | 7447/16104 [34:19:59<39:36:46, 16.47s/it]


 46%|████▋     | 7449/16104 [34:20:26<35:21:49, 14.71s/it]
{'loss': 0.4684, 'learning_rate': 1.1691347601606684e-06, 'rewards/chosen': -1.1417160034179688, 'rewards/rejected': -2.3142638206481934, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1725478172302246, 'policy_logps/rejected': -436.9736328125, 'policy_logps/chosen': -435.35919189453125, 'referece_logps/rejected': -413.8309631347656, 'referece_logps/chosen': -423.9420471191406, 'logits/rejected': -0.40694284439086914, 'logits/chosen': -0.3451593816280365, 'epoch': 2.78}

 46%|████▋     | 7450/16104 [34:20:36<32:28:39, 13.51s/it]


 46%|████▋     | 7452/16104 [34:21:02<31:29:19, 13.10s/it]
{'loss': 0.4678, 'learning_rate': 1.1685400434567117e-06, 'rewards/chosen': -1.231242299079895, 'rewards/rejected': -3.047856569290161, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8166142702102661, 'policy_logps/rejected': -505.9422607421875, 'policy_logps/chosen': -415.5985412597656, 'referece_logps/rejected': -475.46368408203125, 'referece_logps/chosen': -403.2861328125, 'logits/rejected': -0.4713961184024811, 'logits/chosen': -0.37373554706573486, 'epoch': 2.78}

 46%|████▋     | 7453/16104 [34:21:13<29:52:08, 12.43s/it]

 46%|████▋     | 7454/16104 [34:21:23<28:37:55, 11.92s/it]

 46%|████▋     | 7455/16104 [34:21:41<32:31:40, 13.54s/it]


 46%|████▋     | 7457/16104 [34:22:14<35:58:34, 14.98s/it]
{'loss': 0.4022, 'learning_rate': 1.1675487127021422e-06, 'rewards/chosen': -1.9473848342895508, 'rewards/rejected': -2.239020347595215, 'rewards/accuracies': 0.625, 'rewards/margins': 0.29163533449172974, 'policy_logps/rejected': -365.9394226074219, 'policy_logps/chosen': -338.5805358886719, 'referece_logps/rejected': -343.5492248535156, 'referece_logps/chosen': -319.1067199707031, 'logits/rejected': -0.45115068554878235, 'logits/chosen': -0.2136860191822052, 'epoch': 2.78}


 46%|████▋     | 7459/16104 [34:22:54<42:37:43, 17.75s/it]

 46%|████▋     | 7460/16104 [34:23:14<43:56:57, 18.30s/it]

 46%|████▋     | 7461/16104 [34:23:32<43:39:07, 18.18s/it]

 46%|████▋     | 7462/16104 [34:23:46<40:35:44, 16.91s/it]

 46%|████▋     | 7463/16104 [34:24:06<42:56:43, 17.89s/it]

 46%|████▋     | 7464/16104 [34:24:26<44:23:32, 18.50s/it]
{'loss': 0.3781, 'learning_rate': 1.1661605652093005e-06, 'rewards/chosen': -1.168358325958252, 'rewards/rejected': -2.6122210025787354, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4438626766204834, 'policy_logps/rejected': -296.0938720703125, 'policy_logps/chosen': -225.9723358154297, 'referece_logps/rejected': -269.9716796875, 'referece_logps/chosen': -214.28875732421875, 'logits/rejected': -0.2020188271999359, 'logits/chosen': -0.32412800192832947, 'epoch': 2.78}


 46%|████▋     | 7466/16104 [34:24:48<35:14:16, 14.69s/it]
{'loss': 0.3839, 'learning_rate': 1.1657638910261603e-06, 'rewards/chosen': -0.9529614448547363, 'rewards/rejected': -2.629218339920044, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6762568950653076, 'policy_logps/rejected': -379.4437255859375, 'policy_logps/chosen': -314.2765197753906, 'referece_logps/rejected': -353.1515808105469, 'referece_logps/chosen': -304.7469177246094, 'logits/rejected': 0.02593555487692356, 'logits/chosen': 0.058743178844451904, 'epoch': 2.78}


 46%|████▋     | 7468/16104 [34:25:24<39:08:15, 16.31s/it]
{'loss': 0.3967, 'learning_rate': 1.1653671900212399e-06, 'rewards/chosen': -1.5238386392593384, 'rewards/rejected': -2.461409568786621, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9375709295272827, 'policy_logps/rejected': -354.85211181640625, 'policy_logps/chosen': -359.4414978027344, 'referece_logps/rejected': -330.2380065917969, 'referece_logps/chosen': -344.203125, 'logits/rejected': -0.03902745246887207, 'logits/chosen': 0.011302858591079712, 'epoch': 2.78}


 46%|████▋     | 7470/16104 [34:26:00<41:44:39, 17.41s/it]
{'loss': 0.4043, 'learning_rate': 1.1649704622587276e-06, 'rewards/chosen': -1.2047011852264404, 'rewards/rejected': -2.9682600498199463, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7635585069656372, 'policy_logps/rejected': -377.9808654785156, 'policy_logps/chosen': -343.45074462890625, 'referece_logps/rejected': -348.2982177734375, 'referece_logps/chosen': -331.40374755859375, 'logits/rejected': 0.15312154591083527, 'logits/chosen': 0.1489751636981964, 'epoch': 2.78}

 46%|████▋     | 7471/16104 [34:26:15<40:09:37, 16.75s/it]

 46%|████▋     | 7472/16104 [34:26:35<42:22:19, 17.67s/it]

 46%|████▋     | 7473/16104 [34:26:54<42:55:52, 17.91s/it]

 46%|████▋     | 7474/16104 [34:27:07<39:48:41, 16.61s/it]


 46%|████▋     | 7476/16104 [34:27:42<40:31:20, 16.91s/it]
{'loss': 0.3721, 'learning_rate': 1.163780119067598e-06, 'rewards/chosen': -1.6509721279144287, 'rewards/rejected': -3.3064823150634766, 'rewards/accuracies': 1.0, 'rewards/margins': 1.655510425567627, 'policy_logps/rejected': -394.226318359375, 'policy_logps/chosen': -339.891357421875, 'referece_logps/rejected': -361.1614685058594, 'referece_logps/chosen': -323.3816833496094, 'logits/rejected': -0.5577271580696106, 'logits/chosen': -0.5945041179656982, 'epoch': 2.79}

 46%|████▋     | 7477/16104 [34:27:58<39:24:22, 16.44s/it]

 46%|████▋     | 7478/16104 [34:28:13<38:39:48, 16.14s/it]

 46%|████▋     | 7479/16104 [34:28:35<42:43:32, 17.83s/it]


 46%|████▋     | 7481/16104 [34:29:04<38:38:54, 16.14s/it]
{'loss': 0.3602, 'learning_rate': 1.1627879841418225e-06, 'rewards/chosen': -0.8399555683135986, 'rewards/rejected': -3.008434534072876, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1684789657592773, 'policy_logps/rejected': -433.5801696777344, 'policy_logps/chosen': -602.631591796875, 'referece_logps/rejected': -403.495849609375, 'referece_logps/chosen': -594.2320556640625, 'logits/rejected': -0.443172425031662, 'logits/chosen': -0.39557626843452454, 'epoch': 2.79}


 46%|████▋     | 7483/16104 [34:29:38<39:32:24, 16.51s/it]
{'loss': 0.3704, 'learning_rate': 1.1623910840198717e-06, 'rewards/chosen': -1.0297831296920776, 'rewards/rejected': -3.1100685596466064, 'rewards/accuracies': 0.625, 'rewards/margins': 2.08028507232666, 'policy_logps/rejected': -286.3069763183594, 'policy_logps/chosen': -445.35760498046875, 'referece_logps/rejected': -255.206298828125, 'referece_logps/chosen': -435.05975341796875, 'logits/rejected': 0.5363068580627441, 'logits/chosen': 0.4006868898868561, 'epoch': 2.79}

 46%|████▋     | 7484/16104 [34:29:57<41:20:31, 17.27s/it]

 46%|████▋     | 7485/16104 [34:30:17<43:21:02, 18.11s/it]

 46%|████▋     | 7486/16104 [34:30:32<40:46:01, 17.03s/it]

 46%|████▋     | 7487/16104 [34:30:45<38:20:52, 16.02s/it]

 46%|████▋     | 7488/16104 [34:31:06<41:35:53, 17.38s/it]


 47%|████▋     | 7490/16104 [34:31:40<41:19:17, 17.27s/it]
{'loss': 0.3862, 'learning_rate': 1.1610017270907507e-06, 'rewards/chosen': -1.6537073850631714, 'rewards/rejected': -1.8179931640625, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1642857789993286, 'policy_logps/rejected': -339.931884765625, 'policy_logps/chosen': -321.177001953125, 'referece_logps/rejected': -321.751953125, 'referece_logps/chosen': -304.639892578125, 'logits/rejected': -0.01114441454410553, 'logits/chosen': 0.14112445712089539, 'epoch': 2.79}


 47%|████▋     | 7492/16104 [34:32:15<40:44:01, 17.03s/it]

 47%|████▋     | 7493/16104 [34:32:27<37:04:07, 15.50s/it]

 47%|████▋     | 7494/16104 [34:32:45<39:02:01, 16.32s/it]
{'loss': 0.5085, 'learning_rate': 1.1602076653871426e-06, 'rewards/chosen': -1.5542412996292114, 'rewards/rejected': -3.0509514808654785, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4967100620269775, 'policy_logps/rejected': -354.5019226074219, 'policy_logps/chosen': -434.3482360839844, 'referece_logps/rejected': -323.9924011230469, 'referece_logps/chosen': -418.8058776855469, 'logits/rejected': -0.3921738266944885, 'logits/chosen': -0.44308778643608093, 'epoch': 2.79}

 47%|████▋     | 7495/16104 [34:33:06<42:19:05, 17.70s/it]

 47%|████▋     | 7496/16104 [34:33:20<39:51:24, 16.67s/it]


 47%|████▋     | 7498/16104 [34:33:53<40:26:49, 16.92s/it]
{'loss': 0.4378, 'learning_rate': 1.159413499992565e-06, 'rewards/chosen': -2.166008234024048, 'rewards/rejected': -3.283525228500366, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1175167560577393, 'policy_logps/rejected': -388.2590637207031, 'policy_logps/chosen': -389.74468994140625, 'referece_logps/rejected': -355.4237976074219, 'referece_logps/chosen': -368.0845642089844, 'logits/rejected': -0.34842708706855774, 'logits/chosen': -0.3283006548881531, 'epoch': 2.79}


 47%|████▋     | 7500/16104 [34:34:33<44:09:50, 18.48s/it]

 47%|████▋     | 7501/16104 [34:34:59<49:43:09, 20.81s/it]

 47%|████▋     | 7502/16104 [34:35:19<49:12:14, 20.59s/it]

 47%|████▋     | 7503/16104 [34:35:37<47:16:42, 19.79s/it]
{'loss': 0.3899, 'learning_rate': 1.1584206482169797e-06, 'rewards/chosen': -1.8300673961639404, 'rewards/rejected': -4.0633440017700195, 'rewards/accuracies': 0.875, 'rewards/margins': 2.233276605606079, 'policy_logps/rejected': -475.56982421875, 'policy_logps/chosen': -489.5169677734375, 'referece_logps/rejected': -434.9364013671875, 'referece_logps/chosen': -471.2162170410156, 'logits/rejected': -1.268073558807373, 'logits/chosen': -1.1843847036361694, 'epoch': 2.8}

 47%|████▋     | 7504/16104 [34:35:57<47:48:42, 20.01s/it]


 47%|████▋     | 7506/16104 [34:36:19<36:30:53, 15.29s/it]
{'loss': 0.4991, 'learning_rate': 1.1578248601865926e-06, 'rewards/chosen': -1.7455518245697021, 'rewards/rejected': -2.1774487495422363, 'rewards/accuracies': 0.75, 'rewards/margins': 0.43189680576324463, 'policy_logps/rejected': -526.7537841796875, 'policy_logps/chosen': -382.7670593261719, 'referece_logps/rejected': -504.9793395996094, 'referece_logps/chosen': -365.31158447265625, 'logits/rejected': -0.16865652799606323, 'logits/chosen': 0.15632349252700806, 'epoch': 2.8}

 47%|████▋     | 7507/16104 [34:36:30<33:16:44, 13.94s/it]

 47%|████▋     | 7508/16104 [34:36:40<30:57:43, 12.97s/it]

 47%|████▋     | 7509/16104 [34:37:00<35:36:41, 14.92s/it]

 47%|████▋     | 7510/16104 [34:37:20<39:15:34, 16.45s/it]

 47%|████▋     | 7511/16104 [34:37:42<43:24:54, 18.19s/it]


 47%|████▋     | 7513/16104 [34:38:17<42:36:02, 17.85s/it]
{'loss': 0.2494, 'learning_rate': 1.156434465040231e-06, 'rewards/chosen': -0.9824866652488708, 'rewards/rejected': -2.486673593521118, 'rewards/accuracies': 0.875, 'rewards/margins': 1.504186987876892, 'policy_logps/rejected': -356.03912353515625, 'policy_logps/chosen': -354.6009521484375, 'referece_logps/rejected': -331.17236328125, 'referece_logps/chosen': -344.7760925292969, 'logits/rejected': 0.1273525357246399, 'logits/chosen': 0.11034402251243591, 'epoch': 2.8}

 47%|████▋     | 7514/16104 [34:38:36<43:01:31, 18.03s/it]

 47%|████▋     | 7515/16104 [34:38:56<44:58:16, 18.85s/it]

 47%|████▋     | 7516/16104 [34:39:18<46:50:02, 19.63s/it]

 47%|████▋     | 7517/16104 [34:39:36<46:04:55, 19.32s/it]

 47%|████▋     | 7518/16104 [34:39:56<46:27:23, 19.48s/it]

 47%|████▋     | 7519/16104 [34:40:16<46:32:05, 19.51s/it]

 47%|████▋     | 7520/16104 [34:40:36<46:44:02, 19.60s/it]


 47%|████▋     | 7522/16104 [34:41:05<40:42:16, 17.07s/it]

 47%|████▋     | 7523/16104 [34:41:23<41:24:09, 17.37s/it]
{'loss': 0.2752, 'learning_rate': 1.1544476490583668e-06, 'rewards/chosen': -1.965338945388794, 'rewards/rejected': -3.8422434329986572, 'rewards/accuracies': 0.875, 'rewards/margins': 1.876904845237732, 'policy_logps/rejected': -513.7353515625, 'policy_logps/chosen': -465.91424560546875, 'referece_logps/rejected': -475.3128967285156, 'referece_logps/chosen': -446.2608642578125, 'logits/rejected': 0.2608376741409302, 'logits/chosen': 0.2560955286026001, 'epoch': 2.8}

 47%|████▋     | 7524/16104 [34:41:41<41:35:05, 17.45s/it]


 47%|████▋     | 7526/16104 [34:42:15<40:57:12, 17.19s/it]

 47%|████▋     | 7527/16104 [34:42:35<42:42:36, 17.93s/it]
{'loss': 0.4163, 'learning_rate': 1.1536527472803964e-06, 'rewards/chosen': -1.6716268062591553, 'rewards/rejected': -3.1119771003723145, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4403505325317383, 'policy_logps/rejected': -328.1219787597656, 'policy_logps/chosen': -417.9930114746094, 'referece_logps/rejected': -297.002197265625, 'referece_logps/chosen': -401.2767333984375, 'logits/rejected': -0.058664530515670776, 'logits/chosen': -0.17696639895439148, 'epoch': 2.8}


 47%|████▋     | 7529/16104 [34:42:57<34:24:15, 14.44s/it]
{'loss': 0.426, 'learning_rate': 1.1532552590660887e-06, 'rewards/chosen': -1.6216542720794678, 'rewards/rejected': -1.68436598777771, 'rewards/accuracies': 0.625, 'rewards/margins': 0.06271164119243622, 'policy_logps/rejected': -412.02862548828125, 'policy_logps/chosen': -448.65411376953125, 'referece_logps/rejected': -395.1849670410156, 'referece_logps/chosen': -432.4375305175781, 'logits/rejected': -0.1640177071094513, 'logits/chosen': -0.037272579967975616, 'epoch': 2.81}

 47%|████▋     | 7530/16104 [34:43:14<36:25:08, 15.29s/it]

 47%|████▋     | 7531/16104 [34:43:32<38:13:28, 16.05s/it]

 47%|████▋     | 7532/16104 [34:43:45<35:39:43, 14.98s/it]


 47%|████▋     | 7534/16104 [34:44:12<34:13:51, 14.38s/it]
{'loss': 0.3715, 'learning_rate': 1.1522614301806696e-06, 'rewards/chosen': -1.2690157890319824, 'rewards/rejected': -2.9769415855407715, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7079259157180786, 'policy_logps/rejected': -341.8798522949219, 'policy_logps/chosen': -349.2351989746094, 'referece_logps/rejected': -312.1104431152344, 'referece_logps/chosen': -336.5450134277344, 'logits/rejected': -0.8416163325309753, 'logits/chosen': -0.7516500949859619, 'epoch': 2.81}

 47%|████▋     | 7535/16104 [34:44:30<37:11:43, 15.63s/it]

 47%|████▋     | 7536/16104 [34:44:42<34:45:38, 14.61s/it]

 47%|████▋     | 7537/16104 [34:45:02<38:28:26, 16.17s/it]

 47%|████▋     | 7538/16104 [34:45:22<40:57:40, 17.21s/it]

 47%|████▋     | 7539/16104 [34:45:41<42:09:07, 17.72s/it]


 47%|████▋     | 7541/16104 [34:46:19<44:28:18, 18.70s/it]

 47%|████▋     | 7542/16104 [34:46:39<45:17:14, 19.04s/it]
{'loss': 0.3939, 'learning_rate': 1.150670984101365e-06, 'rewards/chosen': -1.8563133478164673, 'rewards/rejected': -3.956949234008789, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1006362438201904, 'policy_logps/rejected': -400.7186584472656, 'policy_logps/chosen': -322.1382751464844, 'referece_logps/rejected': -361.149169921875, 'referece_logps/chosen': -303.57513427734375, 'logits/rejected': -0.007653623819351196, 'logits/chosen': 0.04997760057449341, 'epoch': 2.81}

 47%|████▋     | 7543/16104 [34:46:55<43:17:01, 18.20s/it]


 47%|████▋     | 7545/16104 [34:47:24<37:57:38, 15.97s/it]
{'loss': 0.3501, 'learning_rate': 1.1500744660344403e-06, 'rewards/chosen': -1.0612081289291382, 'rewards/rejected': -1.9663922786712646, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9051841497421265, 'policy_logps/rejected': -315.47900390625, 'policy_logps/chosen': -468.88555908203125, 'referece_logps/rejected': -295.8150939941406, 'referece_logps/chosen': -458.2734375, 'logits/rejected': -0.8548048138618469, 'logits/chosen': -0.7358178496360779, 'epoch': 2.81}

 47%|████▋     | 7546/16104 [34:47:43<40:07:37, 16.88s/it]

 47%|████▋     | 7547/16104 [34:48:02<41:48:02, 17.59s/it]

 47%|████▋     | 7548/16104 [34:48:22<43:43:47, 18.40s/it]

 47%|████▋     | 7549/16104 [34:48:43<44:57:48, 18.92s/it]

 47%|████▋     | 7550/16104 [34:48:55<40:12:08, 16.92s/it]

 47%|████▋     | 7551/16104 [34:49:13<41:18:39, 17.39s/it]

 47%|████▋     | 7552/16104 [34:49:31<41:36:34, 17.52s/it]


 47%|████▋     | 7554/16104 [34:50:02<39:55:42, 16.81s/it]
{'loss': 0.3339, 'learning_rate': 1.1482845848803453e-06, 'rewards/chosen': -1.6830296516418457, 'rewards/rejected': -3.3092100620269775, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6261805295944214, 'policy_logps/rejected': -323.1297302246094, 'policy_logps/chosen': -483.0828857421875, 'referece_logps/rejected': -290.0376281738281, 'referece_logps/chosen': -466.2525634765625, 'logits/rejected': -0.2841307818889618, 'logits/chosen': -0.38906508684158325, 'epoch': 2.81}

 47%|████▋     | 7555/16104 [34:50:22<41:59:01, 17.68s/it]


 47%|████▋     | 7557/16104 [34:50:58<43:08:10, 18.17s/it]
{'loss': 0.3277, 'learning_rate': 1.1476878495685788e-06, 'rewards/chosen': -1.325602412223816, 'rewards/rejected': -4.0309882164001465, 'rewards/accuracies': 1.0, 'rewards/margins': 2.705386161804199, 'policy_logps/rejected': -370.3401794433594, 'policy_logps/chosen': -320.63995361328125, 'referece_logps/rejected': -330.0303039550781, 'referece_logps/chosen': -307.3839111328125, 'logits/rejected': 0.5130512714385986, 'logits/chosen': 0.4028812646865845, 'epoch': 2.82}


 47%|████▋     | 7559/16104 [34:51:36<43:50:54, 18.47s/it]
{'loss': 0.3746, 'learning_rate': 1.1472899961428052e-06, 'rewards/chosen': -1.2895128726959229, 'rewards/rejected': -4.544870853424072, 'rewards/accuracies': 1.0, 'rewards/margins': 3.255357503890991, 'policy_logps/rejected': -311.18853759765625, 'policy_logps/chosen': -299.5362243652344, 'referece_logps/rejected': -265.73980712890625, 'referece_logps/chosen': -286.6410827636719, 'logits/rejected': -0.32417356967926025, 'logits/chosen': -0.32638630270957947, 'epoch': 2.82}

 47%|████▋     | 7560/16104 [34:51:56<44:39:53, 18.82s/it]


 47%|████▋     | 7562/16104 [34:52:20<36:51:09, 15.53s/it]
{'loss': 0.4303, 'learning_rate': 1.1466931713381898e-06, 'rewards/chosen': -1.4173201322555542, 'rewards/rejected': -2.6071746349334717, 'rewards/accuracies': 0.75, 'rewards/margins': 1.189854383468628, 'policy_logps/rejected': -300.3540344238281, 'policy_logps/chosen': -298.36859130859375, 'referece_logps/rejected': -274.28228759765625, 'referece_logps/chosen': -284.19537353515625, 'logits/rejected': -0.8327420353889465, 'logits/chosen': -0.6355103254318237, 'epoch': 2.82}

 47%|████▋     | 7563/16104 [34:52:32<33:57:30, 14.31s/it]

 47%|████▋     | 7564/16104 [34:52:45<33:34:26, 14.15s/it]

 47%|████▋     | 7565/16104 [34:53:05<37:36:49, 15.86s/it]

 47%|████▋     | 7566/16104 [34:53:22<38:18:54, 16.16s/it]

 47%|████▋     | 7567/16104 [34:53:35<35:53:18, 15.13s/it]

 47%|████▋     | 7568/16104 [34:53:57<40:43:20, 17.17s/it]

 47%|████▋     | 7569/16104 [34:54:17<42:36:39, 17.97s/it]

 47%|████▋     | 7570/16104 [34:54:37<44:04:41, 18.59s/it]

 47%|████▋     | 7571/16104 [34:54:58<46:03:24, 19.43s/it]

 47%|████▋     | 7572/16104 [34:55:19<47:29:51, 20.04s/it]

 47%|████▋     | 7573/16104 [34:55:39<46:59:20, 19.83s/it]

 47%|████▋     | 7574/16104 [34:55:59<47:10:59, 19.91s/it]

 47%|████▋     | 7575/16104 [34:56:19<47:08:55, 19.90s/it]


 47%|████▋     | 7577/16104 [34:56:50<41:29:15, 17.52s/it]
{'loss': 0.4262, 'learning_rate': 1.143708250571411e-06, 'rewards/chosen': -1.513359546661377, 'rewards/rejected': -3.2946693897247314, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7813096046447754, 'policy_logps/rejected': -350.604248046875, 'policy_logps/chosen': -339.7574768066406, 'referece_logps/rejected': -317.6575622558594, 'referece_logps/chosen': -324.6239013671875, 'logits/rejected': -0.16388541460037231, 'logits/chosen': -0.1429918259382248, 'epoch': 2.82}

 47%|████▋     | 7578/16104 [34:57:10<43:05:48, 18.20s/it]


 47%|████▋     | 7580/16104 [34:57:44<41:46:09, 17.64s/it]
{'loss': 0.4064, 'learning_rate': 1.1431111085907068e-06, 'rewards/chosen': -1.8247383832931519, 'rewards/rejected': -3.405585765838623, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5808476209640503, 'policy_logps/rejected': -324.4815979003906, 'policy_logps/chosen': -340.1783142089844, 'referece_logps/rejected': -290.4257507324219, 'referece_logps/chosen': -321.9309387207031, 'logits/rejected': 0.23232871294021606, 'logits/chosen': 0.43724721670150757, 'epoch': 2.82}

 47%|████▋     | 7581/16104 [34:57:55<36:50:47, 15.56s/it]


 47%|████▋     | 7583/16104 [34:58:16<30:58:18, 13.09s/it]
{'loss': 0.419, 'learning_rate': 1.1425139145081064e-06, 'rewards/chosen': -1.5989998579025269, 'rewards/rejected': -2.638594627380371, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0395948886871338, 'policy_logps/rejected': -393.1202697753906, 'policy_logps/chosen': -469.8565673828125, 'referece_logps/rejected': -366.73431396484375, 'referece_logps/chosen': -453.8665771484375, 'logits/rejected': 0.3147866129875183, 'logits/chosen': 0.21764439344406128, 'epoch': 2.83}

 47%|████▋     | 7584/16104 [34:58:27<29:14:19, 12.35s/it]

 47%|████▋     | 7585/16104 [34:58:43<31:59:32, 13.52s/it]


 47%|████▋     | 7587/16104 [34:59:14<34:46:17, 14.70s/it]
{'loss': 0.4105, 'learning_rate': 1.1417175750596992e-06, 'rewards/chosen': -2.0648155212402344, 'rewards/rejected': -3.5546791553497314, 'rewards/accuracies': 0.75, 'rewards/margins': 1.489863634109497, 'policy_logps/rejected': -416.1668701171875, 'policy_logps/chosen': -302.102783203125, 'referece_logps/rejected': -380.6201171875, 'referece_logps/chosen': -281.45458984375, 'logits/rejected': -0.5866466760635376, 'logits/chosen': -0.4793769121170044, 'epoch': 2.83}

 47%|████▋     | 7588/16104 [34:59:34<38:13:37, 16.16s/it]

 47%|████▋     | 7589/16104 [34:59:54<40:51:44, 17.28s/it]

 47%|████▋     | 7590/16104 [35:00:10<40:05:13, 16.95s/it]

 47%|████▋     | 7591/16104 [35:00:30<42:16:35, 17.88s/it]

 47%|████▋     | 7592/16104 [35:00:51<44:19:47, 18.75s/it]

 47%|████▋     | 7593/16104 [35:01:07<42:40:28, 18.05s/it]

 47%|████▋     | 7594/16104 [35:01:23<40:48:42, 17.26s/it]

 47%|████▋     | 7595/16104 [35:01:38<39:34:46, 16.75s/it]

 47%|████▋     | 7596/16104 [35:01:58<41:36:02, 17.60s/it]

 47%|████▋     | 7597/16104 [35:02:10<37:24:29, 15.83s/it]

 47%|████▋     | 7598/16104 [35:02:26<37:52:41, 16.03s/it]

 47%|████▋     | 7599/16104 [35:02:44<38:57:58, 16.49s/it]

 47%|████▋     | 7600/16104 [35:02:55<35:27:36, 15.01s/it]

 47%|████▋     | 7601/16104 [35:03:06<32:30:04, 13.76s/it]

 47%|████▋     | 7602/16104 [35:03:20<32:19:21, 13.69s/it]

 47%|████▋     | 7603/16104 [35:03:30<30:11:59, 12.79s/it]

 47%|████▋     | 7604/16104 [35:03:48<33:51:51, 14.34s/it]

 47%|████▋     | 7605/16104 [35:04:06<36:13:53, 15.35s/it]

 47%|████▋     | 7606/16104 [35:04:27<40:17:51, 17.07s/it]

 47%|████▋     | 7607/16104 [35:04:43<39:33:40, 16.76s/it]

 47%|████▋     | 7608/16104 [35:04:56<36:32:45, 15.49s/it]

 47%|████▋     | 7609/16104 [35:05:15<39:35:36, 16.78s/it]

 47%|████▋     | 7610/16104 [35:05:32<39:47:27, 16.86s/it]

 47%|████▋     | 7611/16104 [35:05:52<41:27:18, 17.57s/it]

 47%|████▋     | 7612/16104 [35:06:08<40:12:58, 17.05s/it]

 47%|████▋     | 7613/16104 [35:06:28<42:42:39, 18.11s/it]

 47%|████▋     | 7614/16104 [35:06:44<41:22:08, 17.54s/it]

 47%|████▋     | 7615/16104 [35:07:04<42:46:16, 18.14s/it]

 47%|████▋     | 7616/16104 [35:07:23<43:49:02, 18.58s/it]

 47%|████▋     | 7617/16104 [35:07:42<43:29:38, 18.45s/it]

 47%|████▋     | 7618/16104 [35:07:58<41:42:51, 17.70s/it]


 47%|████▋     | 7620/16104 [35:08:27<37:52:35, 16.07s/it]
{'loss': 0.3688, 'learning_rate': 1.1351443223202812e-06, 'rewards/chosen': -2.33115291595459, 'rewards/rejected': -4.177229404449463, 'rewards/accuracies': 0.75, 'rewards/margins': 1.846076250076294, 'policy_logps/rejected': -418.234375, 'policy_logps/chosen': -337.42169189453125, 'referece_logps/rejected': -376.4620666503906, 'referece_logps/chosen': -314.11016845703125, 'logits/rejected': -0.5234304070472717, 'logits/chosen': -0.6074106693267822, 'epoch': 2.84}

 47%|████▋     | 7621/16104 [35:08:38<34:03:48, 14.46s/it]


 47%|████▋     | 7623/16104 [35:09:01<30:31:12, 12.96s/it]
{'loss': 0.4203, 'learning_rate': 1.134546454328572e-06, 'rewards/chosen': -0.9277846813201904, 'rewards/rejected': -3.134840488433838, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2070555686950684, 'policy_logps/rejected': -506.1806640625, 'policy_logps/chosen': -387.88970947265625, 'referece_logps/rejected': -474.832275390625, 'referece_logps/chosen': -378.61187744140625, 'logits/rejected': -0.7448760271072388, 'logits/chosen': -0.2803175747394562, 'epoch': 2.84}

 47%|████▋     | 7624/16104 [35:09:12<29:06:07, 12.35s/it]

 47%|████▋     | 7625/16104 [35:09:30<33:09:14, 14.08s/it]

 47%|████▋     | 7626/16104 [35:09:50<37:06:22, 15.76s/it]

 47%|████▋     | 7627/16104 [35:10:08<38:34:33, 16.38s/it]


 47%|████▋     | 7629/16104 [35:10:41<39:37:36, 16.83s/it]
{'loss': 0.5057, 'learning_rate': 1.1333505716114453e-06, 'rewards/chosen': -2.247063398361206, 'rewards/rejected': -1.9144494533538818, 'rewards/accuracies': 0.375, 'rewards/margins': -0.332614004611969, 'policy_logps/rejected': -414.4312438964844, 'policy_logps/chosen': -452.52880859375, 'referece_logps/rejected': -395.2867431640625, 'referece_logps/chosen': -430.0581970214844, 'logits/rejected': -0.5093656182289124, 'logits/chosen': -0.49772870540618896, 'epoch': 2.84}

 47%|████▋     | 7630/16104 [35:11:02<42:26:38, 18.03s/it]

 47%|████▋     | 7631/16104 [35:11:21<42:56:04, 18.24s/it]


 47%|████▋     | 7633/16104 [35:11:59<44:22:40, 18.86s/it]
{'loss': 0.2654, 'learning_rate': 1.1325532084738225e-06, 'rewards/chosen': -2.235893726348877, 'rewards/rejected': -4.271091461181641, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0351977348327637, 'policy_logps/rejected': -224.76779174804688, 'policy_logps/chosen': -289.08270263671875, 'referece_logps/rejected': -182.05686950683594, 'referece_logps/chosen': -266.7237243652344, 'logits/rejected': 0.10276876389980316, 'logits/chosen': 0.1443067193031311, 'epoch': 2.84}

 47%|████▋     | 7634/16104 [35:12:20<45:20:35, 19.27s/it]

 47%|████▋     | 7635/16104 [35:12:39<45:30:15, 19.34s/it]

 47%|████▋     | 7636/16104 [35:12:59<45:35:39, 19.38s/it]

 47%|████▋     | 7637/16104 [35:13:20<47:15:59, 20.10s/it]


 47%|████▋     | 7639/16104 [35:13:49<40:39:37, 17.29s/it]

 47%|████▋     | 7640/16104 [35:14:09<42:33:15, 18.10s/it]
{'loss': 0.322, 'learning_rate': 1.131157616855944e-06, 'rewards/chosen': -1.4860631227493286, 'rewards/rejected': -2.629563808441162, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1435009241104126, 'policy_logps/rejected': -272.3333740234375, 'policy_logps/chosen': -400.73675537109375, 'referece_logps/rejected': -246.03775024414062, 'referece_logps/chosen': -385.8761291503906, 'logits/rejected': -0.7905802726745605, 'logits/chosen': -0.7512637376785278, 'epoch': 2.85}

 47%|████▋     | 7641/16104 [35:14:29<43:41:30, 18.59s/it]

 47%|████▋     | 7642/16104 [35:14:46<42:35:17, 18.12s/it]

 47%|████▋     | 7643/16104 [35:15:04<42:41:48, 18.17s/it]

 47%|████▋     | 7644/16104 [35:15:22<42:31:46, 18.10s/it]

 47%|████▋     | 7645/16104 [35:15:38<40:51:48, 17.39s/it]


 47%|████▋     | 7647/16104 [35:16:10<39:47:40, 16.94s/it]
{'loss': 0.2925, 'learning_rate': 1.1297617652656849e-06, 'rewards/chosen': -1.5311665534973145, 'rewards/rejected': -3.5767626762390137, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0455963611602783, 'policy_logps/rejected': -477.23236083984375, 'policy_logps/chosen': -491.9447937011719, 'referece_logps/rejected': -441.46478271484375, 'referece_logps/chosen': -476.6331481933594, 'logits/rejected': -0.8260417580604553, 'logits/chosen': -0.7877874374389648, 'epoch': 2.85}

 47%|████▋     | 7648/16104 [35:16:25<38:21:58, 16.33s/it]

 47%|████▋     | 7649/16104 [35:16:39<36:48:24, 15.67s/it]

 48%|████▊     | 7650/16104 [35:16:52<35:23:00, 15.07s/it]

 48%|████▊     | 7651/16104 [35:17:04<32:52:24, 14.00s/it]

 48%|████▊     | 7652/16104 [35:17:19<33:19:47, 14.20s/it]

 48%|████▊     | 7653/16104 [35:17:37<36:00:38, 15.34s/it]

 48%|████▊     | 7654/16104 [35:17:53<36:42:53, 15.64s/it]

 48%|████▊     | 7655/16104 [35:18:13<39:39:40, 16.90s/it]

 48%|████▊     | 7656/16104 [35:18:30<40:13:15, 17.14s/it]

 48%|████▊     | 7657/16104 [35:18:49<40:51:37, 17.41s/it]

 48%|████▊     | 7658/16104 [35:19:02<37:59:34, 16.19s/it]

 48%|████▊     | 7659/16104 [35:19:21<40:22:35, 17.21s/it]

 48%|████▊     | 7660/16104 [35:19:41<42:07:15, 17.96s/it]

 48%|████▊     | 7661/16104 [35:19:52<37:03:52, 15.80s/it]

 48%|████▊     | 7662/16104 [35:20:06<35:31:36, 15.15s/it]

 48%|████▊     | 7663/16104 [35:20:19<34:14:52, 14.61s/it]

 48%|████▊     | 7664/16104 [35:20:34<34:31:59, 14.73s/it]

 48%|████▊     | 7665/16104 [35:20:49<34:42:13, 14.80s/it]

 48%|████▊     | 7666/16104 [35:21:04<34:41:29, 14.80s/it]

 48%|████▊     | 7667/16104 [35:21:17<33:46:43, 14.41s/it]

 48%|████▊     | 7668/16104 [35:21:28<31:06:23, 13.27s/it]

 48%|████▊     | 7669/16104 [35:21:48<36:01:01, 15.37s/it]

 48%|████▊     | 7670/16104 [35:22:00<33:32:15, 14.32s/it]


 48%|████▊     | 7672/16104 [35:22:24<30:40:57, 13.10s/it]

 48%|████▊     | 7673/16104 [35:22:37<30:25:44, 12.99s/it]

 48%|████▊     | 7674/16104 [35:22:48<29:09:21, 12.45s/it]

 48%|████▊     | 7675/16104 [35:23:00<29:01:22, 12.40s/it]

 48%|████▊     | 7676/16104 [35:23:21<35:18:51, 15.08s/it]

 48%|████▊     | 7677/16104 [35:23:35<34:10:05, 14.60s/it]

 48%|████▊     | 7678/16104 [35:23:46<31:43:36, 13.56s/it]

 48%|████▊     | 7679/16104 [35:24:03<33:58:26, 14.52s/it]
{'loss': 0.3118, 'learning_rate': 1.1233774959475896e-06, 'rewards/chosen': -2.4289960861206055, 'rewards/rejected': -3.5580153465270996, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1290192604064941, 'policy_logps/rejected': -345.27001953125, 'policy_logps/chosen': -306.4887390136719, 'referece_logps/rejected': -309.6898193359375, 'referece_logps/chosen': -282.1988220214844, 'logits/rejected': -0.5368859171867371, 'logits/chosen': -0.4774858355522156, 'epoch': 2.86}


 48%|████▊     | 7681/16104 [35:24:27<30:45:46, 13.15s/it]

 48%|████▊     | 7682/16104 [35:24:43<32:43:56, 13.99s/it]

 48%|████▊     | 7683/16104 [35:25:04<37:40:33, 16.11s/it]

 48%|████▊     | 7684/16104 [35:25:15<33:55:10, 14.50s/it]

 48%|████▊     | 7685/16104 [35:25:35<38:03:45, 16.28s/it]

 48%|████▊     | 7686/16104 [35:25:48<35:32:53, 15.20s/it]

 48%|████▊     | 7687/16104 [35:26:00<33:34:56, 14.36s/it]

 48%|████▊     | 7688/16104 [35:26:20<37:13:32, 15.92s/it]
{'loss': 0.3973, 'learning_rate': 1.1215809879741465e-06, 'rewards/chosen': -1.4808986186981201, 'rewards/rejected': -2.2252912521362305, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7443927526473999, 'policy_logps/rejected': -460.36370849609375, 'policy_logps/chosen': -443.99835205078125, 'referece_logps/rejected': -438.1108093261719, 'referece_logps/chosen': -429.189453125, 'logits/rejected': -0.4699941873550415, 'logits/chosen': -0.4969791769981384, 'epoch': 2.86}


 48%|████▊     | 7690/16104 [35:26:56<40:13:31, 17.21s/it]

 48%|████▊     | 7691/16104 [35:27:11<38:43:14, 16.57s/it]

 48%|████▊     | 7692/16104 [35:27:29<39:43:55, 17.00s/it]

 48%|████▊     | 7693/16104 [35:27:41<36:02:09, 15.42s/it]

 48%|████▊     | 7694/16104 [35:27:52<33:14:02, 14.23s/it]

 48%|████▊     | 7695/16104 [35:28:10<35:40:28, 15.27s/it]

 48%|████▊     | 7696/16104 [35:28:21<32:31:44, 13.93s/it]

 48%|████▊     | 7697/16104 [35:28:38<34:51:25, 14.93s/it]
{'loss': 0.3789, 'learning_rate': 1.1197840816292091e-06, 'rewards/chosen': -1.4069263935089111, 'rewards/rejected': -2.0308332443237305, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6239069104194641, 'policy_logps/rejected': -177.07357788085938, 'policy_logps/chosen': -176.00454711914062, 'referece_logps/rejected': -156.7652587890625, 'referece_logps/chosen': -161.935302734375, 'logits/rejected': -0.601345956325531, 'logits/chosen': -0.6198614835739136, 'epoch': 2.87}


 48%|████▊     | 7699/16104 [35:29:15<39:35:08, 16.96s/it]

 48%|████▊     | 7700/16104 [35:29:31<38:54:24, 16.67s/it]

 48%|████▊     | 7701/16104 [35:29:52<41:53:28, 17.95s/it]

 48%|████▊     | 7702/16104 [35:30:09<41:15:11, 17.68s/it]
{'loss': 0.4358, 'learning_rate': 1.118785630357763e-06, 'rewards/chosen': -1.5839099884033203, 'rewards/rejected': -2.872133731842041, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2882237434387207, 'policy_logps/rejected': -438.6860046386719, 'policy_logps/chosen': -446.6688232421875, 'referece_logps/rejected': -409.96466064453125, 'referece_logps/chosen': -430.8297424316406, 'logits/rejected': 0.2963789999485016, 'logits/chosen': 0.456014484167099, 'epoch': 2.87}


 48%|████▊     | 7704/16104 [35:30:48<42:59:06, 18.42s/it]

 48%|████▊     | 7705/16104 [35:31:07<43:43:31, 18.74s/it]

 48%|████▊     | 7706/16104 [35:31:18<38:34:31, 16.54s/it]

 48%|████▊     | 7707/16104 [35:31:38<40:42:19, 17.45s/it]

 48%|████▊     | 7708/16104 [35:32:00<43:32:44, 18.67s/it]

 48%|████▊     | 7709/16104 [35:32:12<39:03:41, 16.75s/it]

 48%|████▊     | 7710/16104 [35:32:28<38:17:02, 16.42s/it]

 48%|████▊     | 7711/16104 [35:32:48<41:17:06, 17.71s/it]

 48%|████▊     | 7712/16104 [35:33:04<40:03:08, 17.18s/it]

 48%|████▊     | 7713/16104 [35:33:19<38:10:39, 16.38s/it]

 48%|████▊     | 7714/16104 [35:33:34<37:44:50, 16.20s/it]

 48%|████▊     | 7715/16104 [35:33:53<39:08:31, 16.80s/it]

 48%|████▊     | 7716/16104 [35:34:12<41:06:54, 17.65s/it]
{'loss': 0.2645, 'learning_rate': 1.1159893309442177e-06, 'rewards/chosen': -2.9399566650390625, 'rewards/rejected': -6.030982494354248, 'rewards/accuracies': 1.0, 'rewards/margins': 3.091026782989502, 'policy_logps/rejected': -562.702392578125, 'policy_logps/chosen': -532.7493896484375, 'referece_logps/rejected': -502.392578125, 'referece_logps/chosen': -503.3498229980469, 'logits/rejected': 0.1501532644033432, 'logits/chosen': 0.10324663668870926, 'epoch': 2.87}


 48%|████▊     | 7718/16104 [35:34:44<39:28:02, 16.94s/it]

 48%|████▊     | 7719/16104 [35:34:56<36:21:16, 15.61s/it]

 48%|████▊     | 7720/16104 [35:35:15<38:20:13, 16.46s/it]
{'loss': 0.2942, 'learning_rate': 1.115190218373886e-06, 'rewards/chosen': -1.365862250328064, 'rewards/rejected': -4.833235263824463, 'rewards/accuracies': 0.75, 'rewards/margins': 3.4673728942871094, 'policy_logps/rejected': -381.37847900390625, 'policy_logps/chosen': -366.132568359375, 'referece_logps/rejected': -333.046142578125, 'referece_logps/chosen': -352.4739685058594, 'logits/rejected': -0.7427811026573181, 'logits/chosen': -0.644300639629364, 'epoch': 2.88}


 48%|████▊     | 7722/16104 [35:35:45<36:00:57, 15.47s/it]

 48%|████▊     | 7723/16104 [35:36:02<37:07:00, 15.94s/it]

 48%|████▊     | 7724/16104 [35:36:15<35:02:18, 15.05s/it]

 48%|████▊     | 7725/16104 [35:36:35<38:14:14, 16.43s/it]

 48%|████▊     | 7726/16104 [35:36:47<35:23:31, 15.21s/it]

 48%|████▊     | 7727/16104 [35:36:58<32:15:43, 13.86s/it]

 48%|████▊     | 7728/16104 [35:37:12<32:23:53, 13.92s/it]

 48%|████▊     | 7729/16104 [35:37:34<37:58:01, 16.32s/it]

 48%|████▊     | 7730/16104 [35:37:55<41:08:59, 17.69s/it]

 48%|████▊     | 7731/16104 [35:38:15<42:48:27, 18.41s/it]
{'loss': 0.3269, 'learning_rate': 1.112992275940217e-06, 'rewards/chosen': -1.5152686834335327, 'rewards/rejected': -3.3407480716705322, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8254796266555786, 'policy_logps/rejected': -538.0107421875, 'policy_logps/chosen': -444.692138671875, 'referece_logps/rejected': -504.6032409667969, 'referece_logps/chosen': -429.5394287109375, 'logits/rejected': 0.5238115787506104, 'logits/chosen': 0.5631498694419861, 'epoch': 2.88}


 48%|████▊     | 7733/16104 [35:38:38<35:21:04, 15.20s/it]

 48%|████▊     | 7734/16104 [35:38:49<32:12:01, 13.85s/it]

 48%|████▊     | 7735/16104 [35:39:00<30:07:19, 12.96s/it]

 48%|████▊     | 7736/16104 [35:39:11<28:28:14, 12.25s/it]

 48%|████▊     | 7737/16104 [35:39:24<29:16:15, 12.59s/it]

 48%|████▊     | 7738/16104 [35:39:39<30:42:26, 13.21s/it]

 48%|████▊     | 7739/16104 [35:39:56<33:39:41, 14.49s/it]

 48%|████▊     | 7740/16104 [35:40:18<39:08:52, 16.85s/it]

 48%|████▊     | 7741/16104 [35:40:32<36:36:07, 15.76s/it]

 48%|████▊     | 7742/16104 [35:40:45<34:37:42, 14.91s/it]
{'loss': 0.3365, 'learning_rate': 1.1107937804473288e-06, 'rewards/chosen': -1.4115839004516602, 'rewards/rejected': -3.0085837841033936, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5969996452331543, 'policy_logps/rejected': -357.75347900390625, 'policy_logps/chosen': -312.6416015625, 'referece_logps/rejected': -327.66766357421875, 'referece_logps/chosen': -298.5257568359375, 'logits/rejected': -0.623115599155426, 'logits/chosen': -0.5137656331062317, 'epoch': 2.88}


 48%|████▊     | 7744/16104 [35:41:22<39:19:34, 16.93s/it]

 48%|████▊     | 7745/16104 [35:41:39<38:55:53, 16.77s/it]

 48%|████▊     | 7746/16104 [35:41:54<37:52:20, 16.31s/it]

 48%|████▊     | 7747/16104 [35:42:17<42:12:35, 18.18s/it]

 48%|████▊     | 7748/16104 [35:42:29<38:14:57, 16.48s/it]

 48%|████▊     | 7749/16104 [35:42:42<36:02:56, 15.53s/it]

 48%|████▊     | 7750/16104 [35:43:02<38:53:28, 16.76s/it]

 48%|████▊     | 7751/16104 [35:43:19<38:44:32, 16.70s/it]
{'loss': 0.2502, 'learning_rate': 1.108994607560131e-06, 'rewards/chosen': -1.1192586421966553, 'rewards/rejected': -3.8220953941345215, 'rewards/accuracies': 0.875, 'rewards/margins': 2.7028369903564453, 'policy_logps/rejected': -429.1617126464844, 'policy_logps/chosen': -496.9936218261719, 'referece_logps/rejected': -390.94073486328125, 'referece_logps/chosen': -485.8010559082031, 'logits/rejected': -0.7814453840255737, 'logits/chosen': -0.5867964029312134, 'epoch': 2.89}


 48%|████▊     | 7753/16104 [35:43:49<38:07:55, 16.44s/it]

 48%|████▊     | 7754/16104 [35:44:09<40:16:43, 17.37s/it]

 48%|████▊     | 7755/16104 [35:44:27<40:33:03, 17.49s/it]

 48%|████▊     | 7756/16104 [35:44:47<42:12:41, 18.20s/it]

 48%|████▊     | 7757/16104 [35:45:01<39:28:22, 17.02s/it]

 48%|████▊     | 7758/16104 [35:45:20<41:15:06, 17.79s/it]

 48%|████▊     | 7759/16104 [35:45:33<37:26:22, 16.15s/it]

 48%|████▊     | 7760/16104 [35:45:44<33:39:27, 14.52s/it]

 48%|████▊     | 7761/16104 [35:46:00<35:02:26, 15.12s/it]

 48%|████▊     | 7762/16104 [35:46:12<32:31:31, 14.04s/it]
{'loss': 0.413, 'learning_rate': 1.106795134076122e-06, 'rewards/chosen': -1.3755435943603516, 'rewards/rejected': -2.415053367614746, 'rewards/accuracies': 0.5, 'rewards/margins': 1.039509654045105, 'policy_logps/rejected': -327.49871826171875, 'policy_logps/chosen': -415.13232421875, 'referece_logps/rejected': -303.34820556640625, 'referece_logps/chosen': -401.3768615722656, 'logits/rejected': -0.5155948400497437, 'logits/chosen': -0.46256008744239807, 'epoch': 2.89}

 48%|████▊     | 7763/16104 [35:46:32<37:04:28, 16.00s/it]


 48%|████▊     | 7765/16104 [35:47:01<34:42:15, 14.98s/it]

 48%|████▊     | 7766/16104 [35:47:17<35:25:40, 15.30s/it]
{'loss': 0.3808, 'learning_rate': 1.1059951953686534e-06, 'rewards/chosen': -1.457499384880066, 'rewards/rejected': -2.67698073387146, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2194812297821045, 'policy_logps/rejected': -542.3001098632812, 'policy_logps/chosen': -416.8449401855469, 'referece_logps/rejected': -515.5302734375, 'referece_logps/chosen': -402.2699279785156, 'logits/rejected': -0.554865300655365, 'logits/chosen': -0.48000603914260864, 'epoch': 2.89}


 48%|████▊     | 7768/16104 [35:47:47<34:21:36, 14.84s/it]

 48%|████▊     | 7769/16104 [35:48:01<33:38:12, 14.53s/it]
{'loss': 0.3587, 'learning_rate': 1.1053951962889428e-06, 'rewards/chosen': -2.2147912979125977, 'rewards/rejected': -3.19974422454834, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9849528670310974, 'policy_logps/rejected': -326.99755859375, 'policy_logps/chosen': -412.88275146484375, 'referece_logps/rejected': -295.0000915527344, 'referece_logps/chosen': -390.7348327636719, 'logits/rejected': -0.5867617726325989, 'logits/chosen': -0.5467509031295776, 'epoch': 2.89}


 48%|████▊     | 7771/16104 [35:48:33<35:01:13, 15.13s/it]

 48%|████▊     | 7772/16104 [35:48:49<35:57:22, 15.54s/it]

 48%|████▊     | 7773/16104 [35:49:09<38:46:36, 16.76s/it]
{'loss': 0.3981, 'learning_rate': 1.1045951378658214e-06, 'rewards/chosen': -2.066465139389038, 'rewards/rejected': -3.370006561279297, 'rewards/accuracies': 0.75, 'rewards/margins': 1.303541660308838, 'policy_logps/rejected': -373.17059326171875, 'policy_logps/chosen': -491.8155517578125, 'referece_logps/rejected': -339.47052001953125, 'referece_logps/chosen': -471.15087890625, 'logits/rejected': -0.6030125021934509, 'logits/chosen': -0.8925735950469971, 'epoch': 2.9}

 48%|████▊     | 7774/16104 [35:49:30<41:58:16, 18.14s/it]

 48%|████▊     | 7775/16104 [35:49:50<43:04:20, 18.62s/it]

 48%|████▊     | 7776/16104 [35:50:04<39:50:57, 17.23s/it]

 48%|████▊     | 7777/16104 [35:50:16<36:15:18, 15.67s/it]

 48%|████▊     | 7778/16104 [35:50:36<39:09:14, 16.93s/it]

 48%|████▊     | 7779/16104 [35:50:54<39:56:14, 17.27s/it]

 48%|████▊     | 7780/16104 [35:51:09<38:11:15, 16.52s/it]


 48%|████▊     | 7782/16104 [35:51:41<37:09:37, 16.08s/it]
{'loss': 0.3885, 'learning_rate': 1.10279475968574e-06, 'rewards/chosen': -1.0425362586975098, 'rewards/rejected': -2.0350170135498047, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9924808144569397, 'policy_logps/rejected': -408.1129150390625, 'policy_logps/chosen': -411.775146484375, 'referece_logps/rejected': -387.76275634765625, 'referece_logps/chosen': -401.3497619628906, 'logits/rejected': -1.0759973526000977, 'logits/chosen': -1.0963923931121826, 'epoch': 2.9}


 48%|████▊     | 7784/16104 [35:52:09<34:36:11, 14.97s/it]
{'loss': 0.4588, 'learning_rate': 1.1023946296974706e-06, 'rewards/chosen': -1.1180973052978516, 'rewards/rejected': -2.1959710121154785, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0778735876083374, 'policy_logps/rejected': -391.02313232421875, 'policy_logps/chosen': -389.71136474609375, 'referece_logps/rejected': -369.06341552734375, 'referece_logps/chosen': -378.5303955078125, 'logits/rejected': -0.048293620347976685, 'logits/chosen': -0.04005441069602966, 'epoch': 2.9}

 48%|████▊     | 7785/16104 [35:52:30<38:27:14, 16.64s/it]


 48%|████▊     | 7787/16104 [35:52:56<34:06:02, 14.76s/it]
{'loss': 0.4952, 'learning_rate': 1.1017944036699583e-06, 'rewards/chosen': -1.4686830043792725, 'rewards/rejected': -2.951584577560425, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4829013347625732, 'policy_logps/rejected': -251.18698120117188, 'policy_logps/chosen': -360.07501220703125, 'referece_logps/rejected': -221.67112731933594, 'referece_logps/chosen': -345.3881530761719, 'logits/rejected': -0.5815118551254272, 'logits/chosen': -0.5125036835670471, 'epoch': 2.9}


 48%|████▊     | 7789/16104 [35:53:25<33:16:05, 14.40s/it]

 48%|████▊     | 7790/16104 [35:53:38<31:55:46, 13.83s/it]
{'loss': 0.4104, 'learning_rate': 1.1011941405825597e-06, 'rewards/chosen': -1.456068515777588, 'rewards/rejected': -2.480147361755371, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0240790843963623, 'policy_logps/rejected': -294.2781982421875, 'policy_logps/chosen': -394.21478271484375, 'referece_logps/rejected': -269.47674560546875, 'referece_logps/chosen': -379.6540832519531, 'logits/rejected': 0.5240370035171509, 'logits/chosen': 0.33779630064964294, 'epoch': 2.9}

 48%|████▊     | 7791/16104 [35:53:50<30:55:16, 13.39s/it]


 48%|████▊     | 7793/16104 [35:54:17<31:24:49, 13.61s/it]
{'loss': 0.3047, 'learning_rate': 1.1005938406538103e-06, 'rewards/chosen': -1.6201826333999634, 'rewards/rejected': -3.4089009761810303, 'rewards/accuracies': 0.875, 'rewards/margins': 1.788718342781067, 'policy_logps/rejected': -448.35491943359375, 'policy_logps/chosen': -382.8083801269531, 'referece_logps/rejected': -414.26593017578125, 'referece_logps/chosen': -366.6065673828125, 'logits/rejected': -0.3900183439254761, 'logits/chosen': -0.3260909914970398, 'epoch': 2.9}


 48%|████▊     | 7795/16104 [35:54:56<38:26:23, 16.65s/it]
{'loss': 0.374, 'learning_rate': 1.1001936203418178e-06, 'rewards/chosen': -1.3829741477966309, 'rewards/rejected': -3.1148977279663086, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7319238185882568, 'policy_logps/rejected': -217.17062377929688, 'policy_logps/chosen': -352.7337341308594, 'referece_logps/rejected': -186.02163696289062, 'referece_logps/chosen': -338.90399169921875, 'logits/rejected': -0.5611250996589661, 'logits/chosen': -0.4344399571418762, 'epoch': 2.9}


 48%|████▊     | 7797/16104 [35:55:24<34:35:51, 14.99s/it]
{'loss': 0.3565, 'learning_rate': 1.0997933838177826e-06, 'rewards/chosen': -1.7317211627960205, 'rewards/rejected': -3.2716727256774902, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5399515628814697, 'policy_logps/rejected': -291.3668212890625, 'policy_logps/chosen': -393.24127197265625, 'referece_logps/rejected': -258.65008544921875, 'referece_logps/chosen': -375.924072265625, 'logits/rejected': -1.0076987743377686, 'logits/chosen': -0.9351696372032166, 'epoch': 2.9}

 48%|████▊     | 7798/16104 [35:55:42<37:06:51, 16.09s/it]


 48%|████▊     | 7800/16104 [35:56:06<32:07:31, 13.93s/it]

 48%|████▊     | 7801/16104 [35:56:26<36:10:44, 15.69s/it]
{'loss': 0.3618, 'learning_rate': 1.0989928623926312e-06, 'rewards/chosen': -1.032570481300354, 'rewards/rejected': -2.406399965286255, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3738294839859009, 'policy_logps/rejected': -459.2068176269531, 'policy_logps/chosen': -450.8627014160156, 'referece_logps/rejected': -435.14276123046875, 'referece_logps/chosen': -440.5369567871094, 'logits/rejected': -1.4639055728912354, 'logits/chosen': -1.4516125917434692, 'epoch': 2.91}


 48%|████▊     | 7803/16104 [35:56:56<36:29:43, 15.83s/it]

 48%|████▊     | 7804/16104 [35:57:14<37:48:06, 16.40s/it]
{'loss': 0.4639, 'learning_rate': 1.098392429248835e-06, 'rewards/chosen': -1.385172724723816, 'rewards/rejected': -3.316183567047119, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9310109615325928, 'policy_logps/rejected': -318.3978271484375, 'policy_logps/chosen': -432.31256103515625, 'referece_logps/rejected': -285.23602294921875, 'referece_logps/chosen': -418.4608459472656, 'logits/rejected': -0.42511454224586487, 'logits/chosen': -0.585448145866394, 'epoch': 2.91}

 48%|████▊     | 7805/16104 [35:57:28<36:38:27, 15.89s/it]


 48%|████▊     | 7807/16104 [35:58:08<41:12:51, 17.88s/it]

 48%|████▊     | 7808/16104 [35:58:30<43:58:48, 19.08s/it]
{'loss': 0.4321, 'learning_rate': 1.0975917960394687e-06, 'rewards/chosen': -2.528836250305176, 'rewards/rejected': -3.7800681591033936, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2512320280075073, 'policy_logps/rejected': -431.9689025878906, 'policy_logps/chosen': -379.4500732421875, 'referece_logps/rejected': -394.1682434082031, 'referece_logps/chosen': -354.1617431640625, 'logits/rejected': 0.20911559462547302, 'logits/chosen': 0.19941192865371704, 'epoch': 2.91}

 48%|████▊     | 7809/16104 [35:58:49<43:58:38, 19.09s/it]


 49%|████▊     | 7811/16104 [35:59:16<37:34:54, 16.31s/it]

 49%|████▊     | 7812/16104 [35:59:32<37:38:29, 16.34s/it]
{'loss': 0.2774, 'learning_rate': 1.0967910996659087e-06, 'rewards/chosen': -2.6339235305786133, 'rewards/rejected': -5.19854736328125, 'rewards/accuracies': 0.875, 'rewards/margins': 2.564624309539795, 'policy_logps/rejected': -314.05841064453125, 'policy_logps/chosen': -309.5671691894531, 'referece_logps/rejected': -262.07293701171875, 'referece_logps/chosen': -283.2279357910156, 'logits/rejected': 0.19001638889312744, 'logits/chosen': 0.17223605513572693, 'epoch': 2.91}

 49%|████▊     | 7813/16104 [35:59:43<33:43:38, 14.64s/it]


 49%|████▊     | 7815/16104 [36:00:14<34:03:12, 14.79s/it]

 49%|████▊     | 7816/16104 [36:00:24<31:16:26, 13.58s/it]

 49%|████▊     | 7817/16104 [36:00:42<33:49:25, 14.69s/it]

 49%|████▊     | 7818/16104 [36:00:56<33:46:26, 14.67s/it]
{'loss': 0.2509, 'learning_rate': 1.0955899378063522e-06, 'rewards/chosen': -1.570050835609436, 'rewards/rejected': -4.3371710777282715, 'rewards/accuracies': 1.0, 'rewards/margins': 2.767120122909546, 'policy_logps/rejected': -333.3870849609375, 'policy_logps/chosen': -273.079833984375, 'referece_logps/rejected': -290.015380859375, 'referece_logps/chosen': -257.37933349609375, 'logits/rejected': 0.04932357370853424, 'logits/chosen': 0.05503304302692413, 'epoch': 2.91}


 49%|████▊     | 7820/16104 [36:01:32<37:48:03, 16.43s/it]
{'loss': 0.3307, 'learning_rate': 1.095189519499182e-06, 'rewards/chosen': -2.253099203109741, 'rewards/rejected': -3.7071757316589355, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4540762901306152, 'policy_logps/rejected': -372.7949523925781, 'policy_logps/chosen': -619.2543334960938, 'referece_logps/rejected': -335.7231750488281, 'referece_logps/chosen': -596.7232666015625, 'logits/rejected': 0.46731898188591003, 'logits/chosen': 0.39718860387802124, 'epoch': 2.91}


 49%|████▊     | 7822/16104 [36:01:59<34:33:22, 15.02s/it]

 49%|████▊     | 7823/16104 [36:02:18<37:44:47, 16.41s/it]

 49%|████▊     | 7824/16104 [36:02:35<37:44:41, 16.41s/it]
{'loss': 0.4095, 'learning_rate': 1.094388636742604e-06, 'rewards/chosen': -2.943178176879883, 'rewards/rejected': -5.0249457359313965, 'rewards/accuracies': 0.625, 'rewards/margins': 2.081768035888672, 'policy_logps/rejected': -395.73480224609375, 'policy_logps/chosen': -397.2176208496094, 'referece_logps/rejected': -345.4853210449219, 'referece_logps/chosen': -367.78582763671875, 'logits/rejected': -0.7261853218078613, 'logits/chosen': -0.6441696286201477, 'epoch': 2.92}


 49%|████▊     | 7826/16104 [36:03:10<39:49:17, 17.32s/it]

 49%|████▊     | 7827/16104 [36:03:28<40:26:56, 17.59s/it]

 49%|████▊     | 7828/16104 [36:03:46<40:31:55, 17.63s/it]

 49%|████▊     | 7829/16104 [36:04:06<42:17:32, 18.40s/it]

 49%|████▊     | 7830/16104 [36:04:22<40:38:15, 17.68s/it]
{'loss': 0.252, 'learning_rate': 1.0931871982240755e-06, 'rewards/chosen': -1.5339984893798828, 'rewards/rejected': -4.06777811050415, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5337793827056885, 'policy_logps/rejected': -280.828857421875, 'policy_logps/chosen': -339.465087890625, 'referece_logps/rejected': -240.15106201171875, 'referece_logps/chosen': -324.1251220703125, 'logits/rejected': 0.05058518052101135, 'logits/chosen': -0.06929133832454681, 'epoch': 2.92}

 49%|████▊     | 7831/16104 [36:04:37<39:00:50, 16.98s/it]


 49%|████▊     | 7833/16104 [36:05:07<36:00:15, 15.67s/it]

 49%|████▊     | 7834/16104 [36:05:24<37:28:09, 16.31s/it]

 49%|████▊     | 7835/16104 [36:05:44<39:56:22, 17.39s/it]

 49%|████▊     | 7836/16104 [36:05:58<37:25:35, 16.30s/it]

 49%|████▊     | 7837/16104 [36:06:11<34:57:22, 15.22s/it]
{'loss': 0.3003, 'learning_rate': 1.0917853485590658e-06, 'rewards/chosen': -2.0713648796081543, 'rewards/rejected': -4.214064598083496, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1426994800567627, 'policy_logps/rejected': -391.8930358886719, 'policy_logps/chosen': -511.50335693359375, 'referece_logps/rejected': -349.7524108886719, 'referece_logps/chosen': -490.78973388671875, 'logits/rejected': 0.36650875210762024, 'logits/chosen': 0.3593734800815582, 'epoch': 2.92}


 49%|████▊     | 7839/16104 [36:06:32<29:45:02, 12.96s/it]

 49%|████▊     | 7840/16104 [36:06:49<32:03:03, 13.96s/it]
{'loss': 0.3342, 'learning_rate': 1.0911844999902489e-06, 'rewards/chosen': -1.6272478103637695, 'rewards/rejected': -3.5802431106567383, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9529950618743896, 'policy_logps/rejected': -308.0613098144531, 'policy_logps/chosen': -275.9414978027344, 'referece_logps/rejected': -272.2588806152344, 'referece_logps/chosen': -259.66900634765625, 'logits/rejected': -0.9352554082870483, 'logits/chosen': -0.8822498321533203, 'epoch': 2.92}

 49%|████▊     | 7841/16104 [36:06:59<29:45:17, 12.96s/it]


 49%|████▊     | 7843/16104 [36:07:20<27:01:52, 11.78s/it]
{'loss': 0.4444, 'learning_rate': 1.0905836182242508e-06, 'rewards/chosen': -1.9826250076293945, 'rewards/rejected': -2.2375588417053223, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2549339532852173, 'policy_logps/rejected': -479.5659484863281, 'policy_logps/chosen': -431.2969970703125, 'referece_logps/rejected': -457.19036865234375, 'referece_logps/chosen': -411.47076416015625, 'logits/rejected': -0.9072593450546265, 'logits/chosen': -0.9949826598167419, 'epoch': 2.92}


 49%|████▊     | 7845/16104 [36:07:50<31:21:52, 13.67s/it]

 49%|████▊     | 7846/16104 [36:08:07<33:27:58, 14.59s/it]

 49%|████▊     | 7847/16104 [36:08:27<37:05:21, 16.17s/it]
{'loss': 0.5318, 'learning_rate': 1.089782391274301e-06, 'rewards/chosen': -2.583479642868042, 'rewards/rejected': -4.208898067474365, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6254184246063232, 'policy_logps/rejected': -693.0217895507812, 'policy_logps/chosen': -553.2230224609375, 'referece_logps/rejected': -650.932861328125, 'referece_logps/chosen': -527.38818359375, 'logits/rejected': -0.9620546102523804, 'logits/chosen': -0.8909808397293091, 'epoch': 2.92}


 49%|████▊     | 7849/16104 [36:09:02<38:57:07, 16.99s/it]

 49%|████▊     | 7850/16104 [36:09:16<36:44:39, 16.03s/it]
{'loss': 0.4135, 'learning_rate': 1.089181432898971e-06, 'rewards/chosen': -1.7135118246078491, 'rewards/rejected': -4.857764720916748, 'rewards/accuracies': 0.875, 'rewards/margins': 3.1442527770996094, 'policy_logps/rejected': -437.4791259765625, 'policy_logps/chosen': -356.55242919921875, 'referece_logps/rejected': -388.90142822265625, 'referece_logps/chosen': -339.41729736328125, 'logits/rejected': -0.749014139175415, 'logits/chosen': -0.7847837209701538, 'epoch': 2.92}

 49%|████▉     | 7851/16104 [36:09:36<39:13:51, 17.11s/it]


 49%|████▉     | 7853/16104 [36:10:11<39:35:23, 17.27s/it]

 49%|████▉     | 7854/16104 [36:10:27<38:32:56, 16.82s/it]
{'loss': 0.3445, 'learning_rate': 1.0883801045973423e-06, 'rewards/chosen': -2.2554311752319336, 'rewards/rejected': -4.455358505249023, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1999270915985107, 'policy_logps/rejected': -530.1074829101562, 'policy_logps/chosen': -431.6450500488281, 'referece_logps/rejected': -485.55389404296875, 'referece_logps/chosen': -409.09075927734375, 'logits/rejected': -0.8049167394638062, 'logits/chosen': -0.716284990310669, 'epoch': 2.93}


 49%|████▉     | 7856/16104 [36:10:55<36:10:14, 15.79s/it]

 49%|████▉     | 7857/16104 [36:11:14<38:33:39, 16.83s/it]
{'loss': 0.3907, 'learning_rate': 1.0877790708038625e-06, 'rewards/chosen': -2.043487787246704, 'rewards/rejected': -3.3505711555480957, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3070828914642334, 'policy_logps/rejected': -395.241943359375, 'policy_logps/chosen': -349.48712158203125, 'referece_logps/rejected': -361.7362060546875, 'referece_logps/chosen': -329.05224609375, 'logits/rejected': -0.4890761375427246, 'logits/chosen': -0.5701173543930054, 'epoch': 2.93}

 49%|████▉     | 7858/16104 [36:11:34<40:34:28, 17.71s/it]

 49%|████▉     | 7859/16104 [36:11:54<41:58:06, 18.32s/it]


 49%|████▉     | 7861/16104 [36:12:27<39:19:02, 17.17s/it]

 49%|████▉     | 7862/16104 [36:12:41<37:36:54, 16.43s/it]
{'loss': 0.4623, 'learning_rate': 1.0867772769063924e-06, 'rewards/chosen': -3.549755334854126, 'rewards/rejected': -4.207460403442383, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6577051877975464, 'policy_logps/rejected': -423.2249755859375, 'policy_logps/chosen': -494.5393981933594, 'referece_logps/rejected': -381.1503601074219, 'referece_logps/chosen': -459.0418701171875, 'logits/rejected': -0.5017541646957397, 'logits/chosen': -0.5332928895950317, 'epoch': 2.93}


 49%|████▉     | 7864/16104 [36:13:13<37:00:24, 16.17s/it]

 49%|████▉     | 7865/16104 [36:13:28<36:20:38, 15.88s/it]
{'loss': 0.4251, 'learning_rate': 1.086176158379523e-06, 'rewards/chosen': -2.1327152252197266, 'rewards/rejected': -2.2321529388427734, 'rewards/accuracies': 0.5, 'rewards/margins': 0.09943754971027374, 'policy_logps/rejected': -358.6928405761719, 'policy_logps/chosen': -398.2732849121094, 'referece_logps/rejected': -336.371337890625, 'referece_logps/chosen': -376.9461364746094, 'logits/rejected': -0.6157044172286987, 'logits/chosen': -0.5309886932373047, 'epoch': 2.93}

 49%|████▉     | 7866/16104 [36:13:43<35:46:44, 15.64s/it]

 49%|████▉     | 7867/16104 [36:13:54<32:18:02, 14.12s/it]

 49%|████▉     | 7868/16104 [36:14:14<36:13:34, 15.83s/it]


 49%|████▉     | 7870/16104 [36:14:45<35:52:55, 15.69s/it]

 49%|████▉     | 7871/16104 [36:15:01<36:11:00, 15.82s/it]

 49%|████▉     | 7872/16104 [36:15:19<37:23:50, 16.35s/it]

 49%|████▉     | 7873/16104 [36:15:37<38:31:14, 16.85s/it]

 49%|████▉     | 7874/16104 [36:15:57<40:28:01, 17.70s/it]
{'loss': 0.5049, 'learning_rate': 1.0843726154314767e-06, 'rewards/chosen': -1.602413535118103, 'rewards/rejected': -3.521763801574707, 'rewards/accuracies': 0.875, 'rewards/margins': 1.919350266456604, 'policy_logps/rejected': -365.1398620605469, 'policy_logps/chosen': -404.7762451171875, 'referece_logps/rejected': -329.9222412109375, 'referece_logps/chosen': -388.7521057128906, 'logits/rejected': -0.3997243046760559, 'logits/chosen': -0.39758211374282837, 'epoch': 2.93}


 49%|████▉     | 7876/16104 [36:16:27<37:46:18, 16.53s/it]
{'loss': 0.4323, 'learning_rate': 1.0839717903583683e-06, 'rewards/chosen': -1.957643985748291, 'rewards/rejected': -3.972808361053467, 'rewards/accuracies': 0.875, 'rewards/margins': 2.015164613723755, 'policy_logps/rejected': -267.953369140625, 'policy_logps/chosen': -321.9983215332031, 'referece_logps/rejected': -228.2252655029297, 'referece_logps/chosen': -302.421875, 'logits/rejected': -1.4674291610717773, 'logits/chosen': -1.3313547372817993, 'epoch': 2.93}

 49%|████▉     | 7877/16104 [36:16:40<34:50:31, 15.25s/it]

 49%|████▉     | 7878/16104 [36:16:58<36:55:23, 16.16s/it]

 49%|████▉     | 7879/16104 [36:17:14<36:52:02, 16.14s/it]

 49%|████▉     | 7880/16104 [36:17:30<36:59:06, 16.19s/it]

 49%|████▉     | 7881/16104 [36:17:47<37:04:15, 16.23s/it]

 49%|████▉     | 7882/16104 [36:18:02<36:45:00, 16.09s/it]

 49%|████▉     | 7883/16104 [36:18:22<39:25:46, 17.27s/it]

 49%|████▉     | 7884/16104 [36:18:39<38:51:43, 17.02s/it]

 49%|████▉     | 7885/16104 [36:18:59<40:45:03, 17.85s/it]

 49%|████▉     | 7886/16104 [36:19:18<42:05:38, 18.44s/it]

 49%|████▉     | 7887/16104 [36:19:38<42:59:45, 18.84s/it]

 49%|████▉     | 7888/16104 [36:19:55<41:37:31, 18.24s/it]

 49%|████▉     | 7889/16104 [36:20:07<37:26:34, 16.41s/it]


 49%|████▉     | 7891/16104 [36:20:35<35:34:28, 15.59s/it]
{'loss': 0.3054, 'learning_rate': 1.080965173696443e-06, 'rewards/chosen': -1.4785733222961426, 'rewards/rejected': -3.654831647872925, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1762583255767822, 'policy_logps/rejected': -366.33709716796875, 'policy_logps/chosen': -380.89556884765625, 'referece_logps/rejected': -329.7887878417969, 'referece_logps/chosen': -366.1098327636719, 'logits/rejected': -0.062452495098114014, 'logits/chosen': 0.06742118299007416, 'epoch': 2.94}

 49%|████▉     | 7892/16104 [36:20:47<32:44:20, 14.35s/it]

 49%|████▉     | 7893/16104 [36:21:00<31:55:24, 14.00s/it]

 49%|████▉     | 7894/16104 [36:21:18<34:51:25, 15.28s/it]

 49%|████▉     | 7895/16104 [36:21:31<32:44:08, 14.36s/it]

 49%|████▉     | 7896/16104 [36:21:44<32:09:12, 14.10s/it]

 49%|████▉     | 7897/16104 [36:22:06<37:43:24, 16.55s/it]

 49%|████▉     | 7898/16104 [36:22:25<39:06:36, 17.16s/it]

 49%|████▉     | 7899/16104 [36:22:47<42:33:24, 18.67s/it]

 49%|████▉     | 7900/16104 [36:23:01<38:55:54, 17.08s/it]

 49%|████▉     | 7901/16104 [36:23:11<34:36:20, 15.19s/it]

 49%|████▉     | 7902/16104 [36:23:24<33:08:44, 14.55s/it]


 49%|████▉     | 7904/16104 [36:24:04<39:23:57, 17.30s/it]
{'loss': 0.4535, 'learning_rate': 1.0783588421887815e-06, 'rewards/chosen': -0.981518030166626, 'rewards/rejected': -2.5884666442871094, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6069486141204834, 'policy_logps/rejected': -390.3655700683594, 'policy_logps/chosen': -365.2130126953125, 'referece_logps/rejected': -364.48089599609375, 'referece_logps/chosen': -355.3978271484375, 'logits/rejected': -0.7485699653625488, 'logits/chosen': -0.8218089938163757, 'epoch': 2.94}

 49%|████▉     | 7905/16104 [36:24:23<40:58:39, 17.99s/it]

 49%|████▉     | 7906/16104 [36:24:45<43:50:18, 19.25s/it]


 49%|████▉     | 7908/16104 [36:25:18<41:03:30, 18.03s/it]

 49%|████▉     | 7909/16104 [36:25:34<39:35:01, 17.39s/it]

 49%|████▉     | 7910/16104 [36:25:52<40:07:34, 17.63s/it]
{'loss': 0.4607, 'learning_rate': 1.0771557381997687e-06, 'rewards/chosen': -1.2288854122161865, 'rewards/rejected': -4.539608955383301, 'rewards/accuracies': 0.75, 'rewards/margins': 3.3107235431671143, 'policy_logps/rejected': -543.6270751953125, 'policy_logps/chosen': -409.5285949707031, 'referece_logps/rejected': -498.23095703125, 'referece_logps/chosen': -397.23974609375, 'logits/rejected': -0.16242168843746185, 'logits/chosen': 0.09682668000459671, 'epoch': 2.95}


 49%|████▉     | 7912/16104 [36:26:14<32:12:40, 14.16s/it]
{'loss': 0.3715, 'learning_rate': 1.076754678481544e-06, 'rewards/chosen': -1.663552165031433, 'rewards/rejected': -3.454707622528076, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7911556959152222, 'policy_logps/rejected': -398.4072570800781, 'policy_logps/chosen': -369.849609375, 'referece_logps/rejected': -363.86016845703125, 'referece_logps/chosen': -353.2140808105469, 'logits/rejected': -0.9224932193756104, 'logits/chosen': -0.9244118332862854, 'epoch': 2.95}

 49%|████▉     | 7913/16104 [36:26:33<35:41:35, 15.69s/it]

 49%|████▉     | 7914/16104 [36:26:55<39:45:38, 17.48s/it]


 49%|████▉     | 7916/16104 [36:27:28<38:14:49, 16.82s/it]
{'loss': 0.373, 'learning_rate': 1.0759525218516266e-06, 'rewards/chosen': -1.0739144086837769, 'rewards/rejected': -3.4953324794769287, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4214179515838623, 'policy_logps/rejected': -234.7358856201172, 'policy_logps/chosen': -450.5791931152344, 'referece_logps/rejected': -199.7825469970703, 'referece_logps/chosen': -439.84002685546875, 'logits/rejected': -0.738739013671875, 'logits/chosen': -0.8323056101799011, 'epoch': 2.95}

 49%|████▉     | 7917/16104 [36:27:41<35:47:55, 15.74s/it]


 49%|████▉     | 7919/16104 [36:28:12<35:17:02, 15.52s/it]

 49%|████▉     | 7920/16104 [36:28:32<38:36:08, 16.98s/it]
{'loss': 0.5237, 'learning_rate': 1.0751503160630708e-06, 'rewards/chosen': -1.4755504131317139, 'rewards/rejected': -3.4478750228881836, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9723248481750488, 'policy_logps/rejected': -466.11065673828125, 'policy_logps/chosen': -422.5855712890625, 'referece_logps/rejected': -431.63189697265625, 'referece_logps/chosen': -407.830078125, 'logits/rejected': 0.21916767954826355, 'logits/chosen': 0.24625597894191742, 'epoch': 2.95}

 49%|████▉     | 7921/16104 [36:28:53<41:03:25, 18.06s/it]


 49%|████▉     | 7923/16104 [36:29:30<41:02:45, 18.06s/it]

 49%|████▉     | 7924/16104 [36:29:50<42:20:26, 18.63s/it]
{'loss': 0.3696, 'learning_rate': 1.0743480616350873e-06, 'rewards/chosen': -1.059782862663269, 'rewards/rejected': -3.1335952281951904, 'rewards/accuracies': 0.625, 'rewards/margins': 2.073812246322632, 'policy_logps/rejected': -398.9735107421875, 'policy_logps/chosen': -361.04833984375, 'referece_logps/rejected': -367.63751220703125, 'referece_logps/chosen': -350.45050048828125, 'logits/rejected': -0.22406113147735596, 'logits/chosen': -0.2002807855606079, 'epoch': 2.95}

 49%|████▉     | 7925/16104 [36:30:01<36:56:57, 16.26s/it]


 49%|████▉     | 7927/16104 [36:30:22<30:30:11, 13.43s/it]
{'loss': 0.3843, 'learning_rate': 1.0737463392068309e-06, 'rewards/chosen': -1.1160948276519775, 'rewards/rejected': -1.543217420578003, 'rewards/accuracies': 0.5, 'rewards/margins': 0.42712271213531494, 'policy_logps/rejected': -499.11444091796875, 'policy_logps/chosen': -370.04681396484375, 'referece_logps/rejected': -483.68218994140625, 'referece_logps/chosen': -358.8858642578125, 'logits/rejected': -0.6229961514472961, 'logits/chosen': -0.6820588707923889, 'epoch': 2.95}

 49%|████▉     | 7928/16104 [36:30:33<28:37:01, 12.60s/it]

 49%|████▉     | 7929/16104 [36:30:53<33:46:34, 14.87s/it]

 49%|████▉     | 7930/16104 [36:31:09<34:45:41, 15.31s/it]

 49%|████▉     | 7931/16104 [36:31:27<36:11:19, 15.94s/it]

 49%|████▉     | 7932/16104 [36:31:42<35:27:59, 15.62s/it]

 49%|████▉     | 7933/16104 [36:32:03<39:30:05, 17.40s/it]

 49%|████▉     | 7934/16104 [36:32:17<37:14:24, 16.41s/it]

 49%|████▉     | 7935/16104 [36:32:36<38:31:25, 16.98s/it]

 49%|████▉     | 7936/16104 [36:32:53<38:59:55, 17.19s/it]


 49%|████▉     | 7938/16104 [36:33:18<33:43:03, 14.86s/it]
{'loss': 0.334, 'learning_rate': 1.0715397955984875e-06, 'rewards/chosen': -1.3115568161010742, 'rewards/rejected': -3.365380048751831, 'rewards/accuracies': 0.875, 'rewards/margins': 2.053823232650757, 'policy_logps/rejected': -275.965576171875, 'policy_logps/chosen': -521.2130126953125, 'referece_logps/rejected': -242.31178283691406, 'referece_logps/chosen': -508.097412109375, 'logits/rejected': 0.8351865410804749, 'logits/chosen': 0.6666668057441711, 'epoch': 2.96}

 49%|████▉     | 7939/16104 [36:33:35<34:36:33, 15.26s/it]

 49%|████▉     | 7940/16104 [36:33:51<35:11:29, 15.52s/it]


 49%|████▉     | 7942/16104 [36:34:24<36:11:57, 15.97s/it]

 49%|████▉     | 7943/16104 [36:34:41<36:29:39, 16.10s/it]
{'loss': 0.4339, 'learning_rate': 1.0705367048253926e-06, 'rewards/chosen': -1.5788317918777466, 'rewards/rejected': -3.709866762161255, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1310343742370605, 'policy_logps/rejected': -438.2333679199219, 'policy_logps/chosen': -289.5950622558594, 'referece_logps/rejected': -401.13470458984375, 'referece_logps/chosen': -273.8067321777344, 'logits/rejected': -1.4161161184310913, 'logits/chosen': -1.2652003765106201, 'epoch': 2.96}

 49%|████▉     | 7944/16104 [36:34:55<35:34:44, 15.70s/it]

 49%|████▉     | 7945/16104 [36:35:11<35:40:59, 15.74s/it]


 49%|████▉     | 7947/16104 [36:35:39<33:09:39, 14.64s/it]
{'loss': 0.3896, 'learning_rate': 1.0697341807981856e-06, 'rewards/chosen': -1.131568193435669, 'rewards/rejected': -3.508065938949585, 'rewards/accuracies': 0.75, 'rewards/margins': 2.376497983932495, 'policy_logps/rejected': -575.245361328125, 'policy_logps/chosen': -406.24468994140625, 'referece_logps/rejected': -540.1646728515625, 'referece_logps/chosen': -394.92901611328125, 'logits/rejected': -0.6410647630691528, 'logits/chosen': -0.6619858741760254, 'epoch': 2.96}

 49%|████▉     | 7948/16104 [36:35:49<30:27:53, 13.45s/it]

 49%|████▉     | 7949/16104 [36:36:02<30:09:44, 13.32s/it]

 49%|████▉     | 7950/16104 [36:36:13<28:21:53, 12.52s/it]


 49%|████▉     | 7951/16104 [36:36:31<32:00:23, 14.13s/it]
{'loss': 0.2868, 'learning_rate': 1.068730962355431e-06, 'rewards/chosen': -1.2328153848648071, 'rewards/rejected': -2.2066502571105957, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9738349914550781, 'policy_logps/rejected': -313.42578125, 'policy_logps/chosen': -306.2751159667969, 'referece_logps/rejected': -291.35931396484375, 'referece_logps/chosen': -293.94696044921875, 'logits/rejected': 0.46359044313430786, 'logits/chosen': 0.43651068210601807, 'epoch': 2.96}
 49%|████▉     | 7952/16104 [36:36:47<33:15:54, 14.69s/it]


 49%|████▉     | 7954/16104 [36:37:26<39:30:35, 17.45s/it]
{'loss': 0.2928, 'learning_rate': 1.068329655459483e-06, 'rewards/chosen': -2.19650936126709, 'rewards/rejected': -3.334841728210449, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1383326053619385, 'policy_logps/rejected': -338.1285705566406, 'policy_logps/chosen': -453.7296447753906, 'referece_logps/rejected': -304.7801818847656, 'referece_logps/chosen': -431.76458740234375, 'logits/rejected': 0.47374439239501953, 'logits/chosen': 0.49090999364852905, 'epoch': 2.96}


 49%|████▉     | 7956/16104 [36:38:04<41:23:39, 18.29s/it]
{'loss': 0.2966, 'learning_rate': 1.0679283375073094e-06, 'rewards/chosen': -1.5000604391098022, 'rewards/rejected': -3.3660905361175537, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8660297393798828, 'policy_logps/rejected': -291.076904296875, 'policy_logps/chosen': -349.1071472167969, 'referece_logps/rejected': -257.4159851074219, 'referece_logps/chosen': -334.1065673828125, 'logits/rejected': -0.44451186060905457, 'logits/chosen': -0.3185799717903137, 'epoch': 2.96}

 49%|████▉     | 7957/16104 [36:38:21<40:17:33, 17.80s/it]

 49%|████▉     | 7958/16104 [36:38:41<41:51:17, 18.50s/it]

 49%|████▉     | 7959/16104 [36:39:01<42:42:49, 18.88s/it]


 49%|████▉     | 7961/16104 [36:39:35<40:58:47, 18.12s/it]
{'loss': 0.3448, 'learning_rate': 1.066924994682034e-06, 'rewards/chosen': -1.8600538969039917, 'rewards/rejected': -3.67000150680542, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8099476099014282, 'policy_logps/rejected': -426.9084167480469, 'policy_logps/chosen': -505.05596923828125, 'referece_logps/rejected': -390.2084045410156, 'referece_logps/chosen': -486.4554748535156, 'logits/rejected': -0.3030374050140381, 'logits/chosen': -0.26260489225387573, 'epoch': 2.97}


 49%|████▉     | 7963/16104 [36:40:09<40:25:15, 17.87s/it]
{'loss': 0.2584, 'learning_rate': 1.0665236385444531e-06, 'rewards/chosen': -2.15203595161438, 'rewards/rejected': -4.991329669952393, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8392937183380127, 'policy_logps/rejected': -642.5972900390625, 'policy_logps/chosen': -514.6837158203125, 'referece_logps/rejected': -592.6839599609375, 'referece_logps/chosen': -493.16339111328125, 'logits/rejected': 0.5698516368865967, 'logits/chosen': 0.5904743671417236, 'epoch': 2.97}


 49%|████▉     | 7965/16104 [36:40:47<41:43:15, 18.45s/it]
{'loss': 0.3395, 'learning_rate': 1.0661222716428729e-06, 'rewards/chosen': -1.4949612617492676, 'rewards/rejected': -3.5230026245117188, 'rewards/accuracies': 0.75, 'rewards/margins': 2.028041124343872, 'policy_logps/rejected': -354.3525085449219, 'policy_logps/chosen': -352.5308837890625, 'referece_logps/rejected': -319.12249755859375, 'referece_logps/chosen': -337.581298828125, 'logits/rejected': -0.506254255771637, 'logits/chosen': -0.550310492515564, 'epoch': 2.97}

 49%|████▉     | 7966/16104 [36:40:58<36:25:39, 16.11s/it]

 49%|████▉     | 7967/16104 [36:41:14<36:49:31, 16.29s/it]

 49%|████▉     | 7968/16104 [36:41:32<38:06:28, 16.86s/it]

 49%|████▉     | 7969/16104 [36:41:50<38:19:23, 16.96s/it]

 49%|████▉     | 7970/16104 [36:42:09<40:15:15, 17.82s/it]


 50%|████▉     | 7972/16104 [36:42:37<35:07:19, 15.55s/it]
{'loss': 0.3027, 'learning_rate': 1.064717403658491e-06, 'rewards/chosen': -1.3759567737579346, 'rewards/rejected': -3.6484687328338623, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2725119590759277, 'policy_logps/rejected': -251.17782592773438, 'policy_logps/chosen': -433.4478454589844, 'referece_logps/rejected': -214.6931610107422, 'referece_logps/chosen': -419.6882629394531, 'logits/rejected': -0.3609244227409363, 'logits/chosen': -0.4855508804321289, 'epoch': 2.97}

 50%|████▉     | 7973/16104 [36:42:58<39:09:54, 17.34s/it]

 50%|████▉     | 7974/16104 [36:43:18<40:26:18, 17.91s/it]

 50%|████▉     | 7975/16104 [36:43:34<39:26:05, 17.46s/it]

 50%|████▉     | 7976/16104 [36:43:51<39:26:40, 17.47s/it]


 50%|████▉     | 7978/16104 [36:44:19<35:57:40, 15.93s/it]

 50%|████▉     | 7979/16104 [36:44:33<34:38:50, 15.35s/it]

 50%|████▉     | 7980/16104 [36:44:49<34:56:55, 15.49s/it]
{'loss': 0.5707, 'learning_rate': 1.0631116833341077e-06, 'rewards/chosen': -1.7967660427093506, 'rewards/rejected': -1.8660391569137573, 'rewards/accuracies': 0.5, 'rewards/margins': 0.06927317380905151, 'policy_logps/rejected': -514.3820190429688, 'policy_logps/chosen': -536.41796875, 'referece_logps/rejected': -495.72161865234375, 'referece_logps/chosen': -518.4503173828125, 'logits/rejected': -0.2637942135334015, 'logits/chosen': -0.33810365200042725, 'epoch': 2.97}


 50%|████▉     | 7982/16104 [36:45:29<40:12:37, 17.82s/it]
{'loss': 0.2467, 'learning_rate': 1.0627102275608205e-06, 'rewards/chosen': -1.4104934930801392, 'rewards/rejected': -5.284938335418701, 'rewards/accuracies': 0.875, 'rewards/margins': 3.8744454383850098, 'policy_logps/rejected': -345.9862365722656, 'policy_logps/chosen': -352.9373779296875, 'referece_logps/rejected': -293.1368408203125, 'referece_logps/chosen': -338.8324279785156, 'logits/rejected': 0.6854040622711182, 'logits/chosen': 0.6538270711898804, 'epoch': 2.97}


 50%|████▉     | 7984/16104 [36:46:03<39:22:43, 17.46s/it]

 50%|████▉     | 7985/16104 [36:46:17<37:13:57, 16.51s/it]
{'loss': 0.3703, 'learning_rate': 1.0621080248956347e-06, 'rewards/chosen': -2.0115103721618652, 'rewards/rejected': -3.4990720748901367, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4875617027282715, 'policy_logps/rejected': -347.00921630859375, 'policy_logps/chosen': -360.599853515625, 'referece_logps/rejected': -312.0185241699219, 'referece_logps/chosen': -340.4847412109375, 'logits/rejected': -0.2583599388599396, 'logits/chosen': -0.3705715239048004, 'epoch': 2.98}


 50%|████▉     | 7987/16104 [36:46:43<33:29:27, 14.85s/it]

 50%|████▉     | 7988/16104 [36:46:57<32:31:23, 14.43s/it]

 50%|████▉     | 7989/16104 [36:47:13<34:02:43, 15.10s/it]
{'loss': 0.3754, 'learning_rate': 1.0613050528732901e-06, 'rewards/chosen': -0.6532443761825562, 'rewards/rejected': -2.8468923568725586, 'rewards/accuracies': 1.0, 'rewards/margins': 2.193647623062134, 'policy_logps/rejected': -434.95733642578125, 'policy_logps/chosen': -344.7394714355469, 'referece_logps/rejected': -406.4884033203125, 'referece_logps/chosen': -338.20703125, 'logits/rejected': -0.587373673915863, 'logits/chosen': -0.46397665143013, 'epoch': 2.98}

 50%|████▉     | 7990/16104 [36:47:30<34:51:15, 15.46s/it]

 50%|████▉     | 7991/16104 [36:47:49<37:17:07, 16.54s/it]

 50%|████▉     | 7992/16104 [36:48:02<35:01:15, 15.54s/it]

 50%|████▉     | 7993/16104 [36:48:20<36:46:45, 16.32s/it]

 50%|████▉     | 7994/16104 [36:48:35<35:38:03, 15.82s/it]

 50%|████▉     | 7995/16104 [36:48:56<39:21:55, 17.48s/it]

 50%|████▉     | 7996/16104 [36:49:07<34:47:33, 15.45s/it]


 50%|████▉     | 7998/16104 [36:49:39<35:09:04, 15.61s/it]
{'loss': 0.4484, 'learning_rate': 1.0594982215407246e-06, 'rewards/chosen': -1.2601956129074097, 'rewards/rejected': -3.309159994125366, 'rewards/accuracies': 1.0, 'rewards/margins': 2.048964262008667, 'policy_logps/rejected': -561.8358154296875, 'policy_logps/chosen': -528.9884033203125, 'referece_logps/rejected': -528.7442626953125, 'referece_logps/chosen': -516.3864135742188, 'logits/rejected': -1.8379366397857666, 'logits/chosen': -1.625693678855896, 'epoch': 2.98}

 50%|████▉     | 7999/16104 [36:49:50<31:57:51, 14.20s/it]

 50%|████▉     | 8000/16104 [36:50:03<31:01:13, 13.78s/it]

 50%|████▉     | 8001/16104 [36:50:35<43:08:12, 19.16s/it]

 50%|████▉     | 8002/16104 [36:50:48<38:51:52, 17.27s/it]

 50%|████▉     | 8003/16104 [36:51:02<36:39:59, 16.29s/it]

 50%|████▉     | 8004/16104 [36:51:22<39:10:55, 17.41s/it]

 50%|████▉     | 8005/16104 [36:51:40<39:57:56, 17.76s/it]

 50%|████▉     | 8006/16104 [36:52:00<41:04:27, 18.26s/it]

 50%|████▉     | 8007/16104 [36:52:12<36:53:30, 16.40s/it]

 50%|████▉     | 8008/16104 [36:52:30<38:03:58, 16.93s/it]

 50%|████▉     | 8009/16104 [36:52:45<37:07:28, 16.51s/it]

 50%|████▉     | 8010/16104 [36:53:06<39:50:26, 17.72s/it]

 50%|████▉     | 8011/16104 [36:53:25<40:51:14, 18.17s/it]

 50%|████▉     | 8012/16104 [36:53:45<41:52:55, 18.63s/it]

 50%|████▉     | 8013/16104 [36:53:56<36:30:18, 16.24s/it]

 50%|████▉     | 8014/16104 [36:54:06<32:44:40, 14.57s/it]

 50%|████▉     | 8015/16104 [36:54:17<30:08:01, 13.41s/it]

 50%|████▉     | 8016/16104 [36:54:28<28:17:59, 12.60s/it]

 50%|████▉     | 8017/16104 [36:54:48<33:30:08, 14.91s/it]

 50%|████▉     | 8018/16104 [36:55:07<36:16:29, 16.15s/it]

 50%|████▉     | 8019/16104 [36:55:27<38:58:55, 17.36s/it]

 50%|████▉     | 8020/16104 [36:55:49<41:39:39, 18.55s/it]

 50%|████▉     | 8021/16104 [36:56:09<42:38:26, 18.99s/it]

 50%|████▉     | 8022/16104 [36:56:28<42:54:54, 19.12s/it]

 50%|████▉     | 8023/16104 [36:56:48<43:21:46, 19.32s/it]

 50%|████▉     | 8024/16104 [36:57:07<43:24:39, 19.34s/it]

 50%|████▉     | 8025/16104 [36:57:27<43:56:46, 19.58s/it]

 50%|████▉     | 8026/16104 [36:57:48<44:57:05, 20.03s/it]

 50%|████▉     | 8027/16104 [36:58:06<43:14:49, 19.28s/it]

 50%|████▉     | 8028/16104 [36:58:26<43:41:04, 19.47s/it]

 50%|████▉     | 8029/16104 [36:58:36<37:41:53, 16.81s/it]

 50%|████▉     | 8030/16104 [36:58:53<37:46:18, 16.84s/it]

 50%|████▉     | 8031/16104 [36:59:05<34:35:48, 15.43s/it]

 50%|████▉     | 8032/16104 [36:59:19<33:27:02, 14.92s/it]

 50%|████▉     | 8033/16104 [36:59:35<34:16:01, 15.28s/it]

 50%|████▉     | 8034/16104 [36:59:55<37:19:46, 16.65s/it]

 50%|████▉     | 8035/16104 [37:00:16<40:18:29, 17.98s/it]

 50%|████▉     | 8036/16104 [37:00:32<39:06:46, 17.45s/it]

 50%|████▉     | 8037/16104 [37:00:44<35:00:20, 15.62s/it]

 50%|████▉     | 8038/16104 [37:01:00<35:43:40, 15.95s/it]

 50%|████▉     | 8039/16104 [37:01:14<34:08:23, 15.24s/it]

 50%|████▉     | 8040/16104 [37:01:28<33:21:42, 14.89s/it]

 50%|████▉     | 8041/16104 [37:01:49<37:37:23, 16.80s/it]

 50%|████▉     | 8042/16104 [37:02:06<37:37:36, 16.80s/it]

 50%|████▉     | 8043/16104 [37:02:26<39:38:54, 17.71s/it]

 50%|████▉     | 8044/16104 [37:02:48<42:25:20, 18.95s/it]

 50%|████▉     | 8045/16104 [37:03:07<42:37:22, 19.04s/it]

 50%|████▉     | 8046/16104 [37:03:23<40:11:32, 17.96s/it]

 50%|████▉     | 8047/16104 [37:03:40<39:57:21, 17.85s/it]

 50%|████▉     | 8048/16104 [37:03:56<38:18:15, 17.12s/it]

 50%|████▉     | 8049/16104 [37:04:15<40:07:01, 17.93s/it]

 50%|████▉     | 8050/16104 [37:04:35<41:17:56, 18.46s/it]

 50%|████▉     | 8051/16104 [37:04:55<42:32:22, 19.02s/it]

 50%|█████     | 8052/16104 [37:05:14<42:09:37, 18.85s/it]

 50%|█████     | 8053/16104 [37:05:32<41:33:54, 18.59s/it]

 50%|█████     | 8054/16104 [37:05:52<42:18:36, 18.92s/it]

 50%|█████     | 8055/16104 [37:06:11<42:47:29, 19.14s/it]

 50%|█████     | 8056/16104 [37:06:27<40:34:49, 18.15s/it]

 50%|█████     | 8057/16104 [37:06:39<36:22:22, 16.27s/it]

 50%|█████     | 8058/16104 [37:06:50<32:38:44, 14.61s/it]

 50%|█████     | 8059/16104 [37:07:02<31:13:10, 13.97s/it]

 50%|█████     | 8060/16104 [37:07:18<32:15:38, 14.44s/it]

 50%|█████     | 8061/16104 [37:07:37<35:41:22, 15.97s/it]

 50%|█████     | 8062/16104 [37:07:54<36:23:02, 16.29s/it]

 50%|█████     | 8063/16104 [37:08:07<34:18:41, 15.36s/it]

 50%|█████     | 8064/16104 [37:08:20<32:26:35, 14.53s/it]


 50%|█████     | 8066/16104 [37:08:43<28:56:31, 12.96s/it]

 50%|█████     | 8067/16104 [37:09:01<32:08:28, 14.40s/it]

 50%|█████     | 8068/16104 [37:09:18<33:58:55, 15.22s/it]

 50%|█████     | 8069/16104 [37:09:30<32:01:03, 14.35s/it]

 50%|█████     | 8070/16104 [37:09:41<29:37:31, 13.27s/it]

 50%|█████     | 8071/16104 [37:10:00<33:31:51, 15.03s/it]

 50%|█████     | 8072/16104 [37:10:18<35:36:50, 15.96s/it]

 50%|█████     | 8073/16104 [37:10:39<38:25:39, 17.23s/it]

 50%|█████     | 8074/16104 [37:10:49<34:04:07, 15.27s/it]

 50%|█████     | 8075/16104 [37:11:04<33:51:47, 15.18s/it]

 50%|█████     | 8076/16104 [37:11:20<34:11:27, 15.33s/it]

 50%|█████     | 8077/16104 [37:11:36<34:23:42, 15.43s/it]

 50%|█████     | 8078/16104 [37:11:46<31:14:10, 14.01s/it]

 50%|█████     | 8079/16104 [37:12:02<32:23:25, 14.53s/it]

 50%|█████     | 8080/16104 [37:12:19<33:40:07, 15.11s/it]

 50%|█████     | 8081/16104 [37:12:31<31:38:51, 14.20s/it]

 50%|█████     | 8082/16104 [37:12:45<31:54:15, 14.32s/it]

 50%|█████     | 8083/16104 [37:13:01<33:04:28, 14.84s/it]

 50%|█████     | 8084/16104 [37:13:12<30:17:21, 13.60s/it]

 50%|█████     | 8085/16104 [37:13:26<30:21:53, 13.63s/it]

 50%|█████     | 8086/16104 [37:13:37<28:40:58, 12.88s/it]

 50%|█████     | 8087/16104 [37:13:51<29:22:06, 13.19s/it]

 50%|█████     | 8088/16104 [37:14:09<32:55:11, 14.78s/it]

 50%|█████     | 8089/16104 [37:14:26<34:10:40, 15.35s/it]

 50%|█████     | 8090/16104 [37:14:43<35:26:40, 15.92s/it]

 50%|█████     | 8091/16104 [37:15:03<37:49:21, 16.99s/it]

 50%|█████     | 8092/16104 [37:15:14<33:50:46, 15.21s/it]

 50%|█████     | 8093/16104 [37:15:25<31:22:21, 14.10s/it]

 50%|█████     | 8094/16104 [37:15:37<29:59:56, 13.48s/it]

 50%|█████     | 8095/16104 [37:15:56<33:38:20, 15.12s/it]

 50%|█████     | 8096/16104 [37:16:08<31:12:52, 14.03s/it]

 50%|█████     | 8097/16104 [37:16:28<35:09:25, 15.81s/it]

 50%|█████     | 8098/16104 [37:16:48<38:20:08, 17.24s/it]

 50%|█████     | 8099/16104 [37:17:09<40:56:55, 18.42s/it]

 50%|█████     | 8100/16104 [37:17:24<38:14:09, 17.20s/it]

 50%|█████     | 8101/16104 [37:17:41<37:57:37, 17.08s/it]

 50%|█████     | 8102/16104 [37:17:54<35:37:29, 16.03s/it]

 50%|█████     | 8103/16104 [37:18:14<38:13:59, 17.20s/it]

 50%|█████     | 8104/16104 [37:18:25<34:21:27, 15.46s/it]

 50%|█████     | 8105/16104 [37:18:46<37:25:57, 16.85s/it]

 50%|█████     | 8106/16104 [37:19:03<37:35:20, 16.92s/it]

 50%|█████     | 8107/16104 [37:19:19<37:22:49, 16.83s/it]

 50%|█████     | 8108/16104 [37:19:39<39:24:19, 17.74s/it]

 50%|█████     | 8109/16104 [37:19:55<38:06:38, 17.16s/it]

 50%|█████     | 8110/16104 [37:20:07<34:31:42, 15.55s/it]

 50%|█████     | 8111/16104 [37:20:22<34:33:20, 15.56s/it]

 50%|█████     | 8112/16104 [37:20:39<35:31:43, 16.00s/it]

 50%|█████     | 8113/16104 [37:20:59<37:49:22, 17.04s/it]
{'loss': 0.311, 'learning_rate': 1.0363958184195488e-06, 'rewards/chosen': -2.270214796066284, 'rewards/rejected': -4.331508636474609, 'rewards/accuracies': 0.875, 'rewards/margins': 2.061293601989746, 'policy_logps/rejected': -434.42431640625, 'policy_logps/chosen': -434.9179992675781, 'referece_logps/rejected': -391.1092834472656, 'referece_logps/chosen': -412.21588134765625, 'logits/rejected': 0.36399078369140625, 'logits/chosen': 0.3334915041923523, 'epoch': 3.02}

 50%|█████     | 8114/16104 [37:21:12<35:24:07, 15.95s/it]


 50%|█████     | 8116/16104 [37:21:36<30:42:18, 13.84s/it]

 50%|█████     | 8117/16104 [37:21:48<29:47:46, 13.43s/it]

 50%|█████     | 8118/16104 [37:22:04<31:14:50, 14.09s/it]

 50%|█████     | 8119/16104 [37:22:22<33:46:58, 15.23s/it]

 50%|█████     | 8120/16104 [37:22:32<30:41:38, 13.84s/it]

 50%|█████     | 8121/16104 [37:22:50<33:09:57, 14.96s/it]

 50%|█████     | 8122/16104 [37:23:02<31:06:11, 14.03s/it]
{'loss': 0.3328, 'learning_rate': 1.0345868224691655e-06, 'rewards/chosen': -1.9673895835876465, 'rewards/rejected': -3.4598894119262695, 'rewards/accuracies': 1.0, 'rewards/margins': 1.492499828338623, 'policy_logps/rejected': -467.117431640625, 'policy_logps/chosen': -413.3752746582031, 'referece_logps/rejected': -432.51849365234375, 'referece_logps/chosen': -393.701416015625, 'logits/rejected': -0.2666163146495819, 'logits/chosen': -0.28165769577026367, 'epoch': 3.03}


 50%|█████     | 8124/16104 [37:23:37<35:09:32, 15.86s/it]

 50%|█████     | 8125/16104 [37:23:47<31:42:07, 14.30s/it]

 50%|█████     | 8126/16104 [37:23:58<29:20:24, 13.24s/it]

 50%|█████     | 8127/16104 [37:24:09<27:43:04, 12.51s/it]

 50%|█████     | 8128/16104 [37:24:26<30:45:45, 13.88s/it]

 50%|█████     | 8129/16104 [37:24:46<34:37:27, 15.63s/it]
{'loss': 0.2559, 'learning_rate': 1.033179746965799e-06, 'rewards/chosen': -1.0544767379760742, 'rewards/rejected': -3.7154791355133057, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6610023975372314, 'policy_logps/rejected': -307.587158203125, 'policy_logps/chosen': -407.0069580078125, 'referece_logps/rejected': -270.432373046875, 'referece_logps/chosen': -396.4621887207031, 'logits/rejected': -0.2971705198287964, 'logits/chosen': -0.3444744944572449, 'epoch': 3.03}


 50%|█████     | 8131/16104 [37:25:22<37:53:37, 17.11s/it]

 50%|█████     | 8132/16104 [37:25:42<40:08:30, 18.13s/it]
{'loss': 0.3461, 'learning_rate': 1.0325766943118877e-06, 'rewards/chosen': -1.9105896949768066, 'rewards/rejected': -4.6933159828186035, 'rewards/accuracies': 0.875, 'rewards/margins': 2.782726287841797, 'policy_logps/rejected': -317.61968994140625, 'policy_logps/chosen': -464.5864562988281, 'referece_logps/rejected': -270.6865234375, 'referece_logps/chosen': -445.4805908203125, 'logits/rejected': -0.14241337776184082, 'logits/chosen': -0.26225051283836365, 'epoch': 3.03}


 51%|█████     | 8134/16104 [37:26:20<41:19:58, 18.67s/it]

 51%|█████     | 8135/16104 [37:26:41<43:13:00, 19.52s/it]

 51%|█████     | 8136/16104 [37:27:03<44:48:42, 20.25s/it]

 51%|█████     | 8137/16104 [37:27:23<44:44:37, 20.22s/it]

 51%|█████     | 8138/16104 [37:27:34<38:24:50, 17.36s/it]

 51%|█████     | 8139/16104 [37:27:53<39:43:59, 17.96s/it]

 51%|█████     | 8140/16104 [37:28:05<35:41:39, 16.14s/it]

 51%|█████     | 8141/16104 [37:28:19<34:21:46, 15.54s/it]

 51%|█████     | 8142/16104 [37:28:39<37:09:17, 16.80s/it]

 51%|█████     | 8143/16104 [37:28:56<37:24:25, 16.92s/it]

 51%|█████     | 8144/16104 [37:29:14<38:12:34, 17.28s/it]

 51%|█████     | 8145/16104 [37:29:31<37:35:15, 17.00s/it]

 51%|█████     | 8146/16104 [37:29:43<34:07:28, 15.44s/it]

 51%|█████     | 8147/16104 [37:30:05<38:38:43, 17.48s/it]

 51%|█████     | 8148/16104 [37:30:27<41:42:36, 18.87s/it]

 51%|█████     | 8149/16104 [37:30:47<42:28:55, 19.23s/it]

 51%|█████     | 8150/16104 [37:31:03<40:28:18, 18.32s/it]

 51%|█████     | 8151/16104 [37:31:25<42:27:45, 19.22s/it]

 51%|█████     | 8152/16104 [37:31:44<42:25:48, 19.21s/it]

 51%|█████     | 8153/16104 [37:31:57<38:47:44, 17.57s/it]

 51%|█████     | 8154/16104 [37:32:18<40:55:51, 18.53s/it]

 51%|█████     | 8155/16104 [37:32:31<37:10:44, 16.84s/it]

 51%|█████     | 8156/16104 [37:32:46<36:10:31, 16.39s/it]

 51%|█████     | 8157/16104 [37:33:06<38:08:27, 17.28s/it]

 51%|█████     | 8158/16104 [37:33:26<39:48:27, 18.04s/it]
{'loss': 0.2987, 'learning_rate': 1.0273497646769e-06, 'rewards/chosen': -2.3995678424835205, 'rewards/rejected': -4.186867713928223, 'rewards/accuracies': 0.75, 'rewards/margins': 1.787299394607544, 'policy_logps/rejected': -403.897705078125, 'policy_logps/chosen': -389.6537170410156, 'referece_logps/rejected': -362.0290222167969, 'referece_logps/chosen': -365.6580505371094, 'logits/rejected': 0.4594457149505615, 'logits/chosen': 0.5402059555053711, 'epoch': 3.04}

 51%|█████     | 8159/16104 [37:33:45<40:45:44, 18.47s/it]

 51%|█████     | 8160/16104 [37:34:05<41:43:32, 18.91s/it]


 51%|█████     | 8162/16104 [37:34:39<39:27:05, 17.88s/it]

 51%|█████     | 8163/16104 [37:34:49<34:43:31, 15.74s/it]

 51%|█████     | 8164/16104 [37:35:03<33:31:17, 15.20s/it]
{'loss': 0.2881, 'learning_rate': 1.0261434387316247e-06, 'rewards/chosen': -1.335583209991455, 'rewards/rejected': -3.7515945434570312, 'rewards/accuracies': 0.875, 'rewards/margins': 2.416010856628418, 'policy_logps/rejected': -488.6101379394531, 'policy_logps/chosen': -339.2315979003906, 'referece_logps/rejected': -451.0941467285156, 'referece_logps/chosen': -325.87579345703125, 'logits/rejected': -0.9009851217269897, 'logits/chosen': -0.8102924823760986, 'epoch': 3.04}


 51%|█████     | 8166/16104 [37:35:35<34:54:10, 15.83s/it]

 51%|█████     | 8167/16104 [37:35:53<36:09:31, 16.40s/it]

 51%|█████     | 8168/16104 [37:36:11<37:28:48, 17.00s/it]

 51%|█████     | 8169/16104 [37:36:24<34:50:23, 15.81s/it]
{'loss': 0.4031, 'learning_rate': 1.0251381379534204e-06, 'rewards/chosen': -1.1077674627304077, 'rewards/rejected': -3.4623019695281982, 'rewards/accuracies': 1.0, 'rewards/margins': 2.35453462600708, 'policy_logps/rejected': -549.5984497070312, 'policy_logps/chosen': -475.1295166015625, 'referece_logps/rejected': -514.9754638671875, 'referece_logps/chosen': -464.0518798828125, 'logits/rejected': 0.5553199648857117, 'logits/chosen': 0.4862437844276428, 'epoch': 3.04}


 51%|█████     | 8171/16104 [37:37:05<39:53:00, 18.10s/it]

 51%|█████     | 8172/16104 [37:37:20<38:04:40, 17.28s/it]

 51%|█████     | 8173/16104 [37:37:35<36:40:49, 16.65s/it]

 51%|█████     | 8174/16104 [37:37:50<35:22:56, 16.06s/it]

 51%|█████     | 8175/16104 [37:38:05<34:36:53, 15.72s/it]
{'loss': 0.4111, 'learning_rate': 1.0239317435519215e-06, 'rewards/chosen': -2.31974196434021, 'rewards/rejected': -3.631880044937134, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3121378421783447, 'policy_logps/rejected': -365.29254150390625, 'policy_logps/chosen': -355.3385009765625, 'referece_logps/rejected': -328.9737548828125, 'referece_logps/chosen': -332.1411437988281, 'logits/rejected': -1.2666443586349487, 'logits/chosen': -1.280620813369751, 'epoch': 3.05}


 51%|█████     | 8177/16104 [37:38:46<39:44:57, 18.05s/it]

 51%|█████     | 8178/16104 [37:39:02<38:30:32, 17.49s/it]

 51%|█████     | 8179/16104 [37:39:23<41:03:19, 18.65s/it]

 51%|█████     | 8180/16104 [37:39:43<41:34:34, 18.89s/it]

 51%|█████     | 8181/16104 [37:39:57<38:37:49, 17.55s/it]

 51%|█████     | 8182/16104 [37:40:16<39:36:59, 18.00s/it]

 51%|█████     | 8183/16104 [37:40:37<41:31:24, 18.87s/it]

 51%|█████     | 8184/16104 [37:40:53<39:54:12, 18.14s/it]
{'loss': 0.3866, 'learning_rate': 1.0221220871531869e-06, 'rewards/chosen': -1.8143301010131836, 'rewards/rejected': -4.51449728012085, 'rewards/accuracies': 0.75, 'rewards/margins': 2.700167179107666, 'policy_logps/rejected': -226.17239379882812, 'policy_logps/chosen': -394.86029052734375, 'referece_logps/rejected': -181.0274200439453, 'referece_logps/chosen': -376.7169494628906, 'logits/rejected': -0.7784772515296936, 'logits/chosen': -0.9548945426940918, 'epoch': 3.05}

 51%|█████     | 8185/16104 [37:41:06<35:58:18, 16.35s/it]

 51%|█████     | 8186/16104 [37:41:17<33:03:49, 15.03s/it]


 51%|█████     | 8188/16104 [37:41:56<37:33:00, 17.08s/it]

 51%|█████     | 8189/16104 [37:42:07<33:19:46, 15.16s/it]

 51%|█████     | 8190/16104 [37:42:19<30:58:41, 14.09s/it]

 51%|█████     | 8191/16104 [37:42:36<32:55:26, 14.98s/it]
{'loss': 0.3733, 'learning_rate': 1.0207145262040197e-06, 'rewards/chosen': -1.6055383682250977, 'rewards/rejected': -2.5258073806762695, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9202691316604614, 'policy_logps/rejected': -422.506103515625, 'policy_logps/chosen': -445.4356384277344, 'referece_logps/rejected': -397.24798583984375, 'referece_logps/chosen': -429.3802795410156, 'logits/rejected': -0.5243983268737793, 'logits/chosen': -0.586784839630127, 'epoch': 3.05}


 51%|█████     | 8193/16104 [37:43:06<32:16:34, 14.69s/it]

 51%|█████     | 8194/16104 [37:43:17<29:41:36, 13.51s/it]
{'loss': 0.2436, 'learning_rate': 1.0201112730654588e-06, 'rewards/chosen': -0.9658135175704956, 'rewards/rejected': -4.639716148376465, 'rewards/accuracies': 1.0, 'rewards/margins': 3.673902750015259, 'policy_logps/rejected': -428.27178955078125, 'policy_logps/chosen': -397.29571533203125, 'referece_logps/rejected': -381.8746337890625, 'referece_logps/chosen': -387.6375427246094, 'logits/rejected': -1.4061667919158936, 'logits/chosen': -1.3559330701828003, 'epoch': 3.05}


 51%|█████     | 8196/16104 [37:43:38<26:29:06, 12.06s/it]

 51%|█████     | 8197/16104 [37:43:56<30:18:00, 13.80s/it]

 51%|█████     | 8198/16104 [37:44:11<30:57:50, 14.10s/it]
{'loss': 0.3832, 'learning_rate': 1.0193069241958216e-06, 'rewards/chosen': -1.3080393075942993, 'rewards/rejected': -3.610783338546753, 'rewards/accuracies': 0.75, 'rewards/margins': 2.302743911743164, 'policy_logps/rejected': -462.41864013671875, 'policy_logps/chosen': -499.998291015625, 'referece_logps/rejected': -426.3108215332031, 'referece_logps/chosen': -486.9178771972656, 'logits/rejected': -0.2477593570947647, 'logits/chosen': -0.28738313913345337, 'epoch': 3.05}


 51%|█████     | 8200/16104 [37:44:39<30:33:29, 13.92s/it]

 51%|█████     | 8201/16104 [37:44:51<29:44:15, 13.55s/it]

 51%|█████     | 8202/16104 [37:45:11<33:41:03, 15.35s/it]
{'loss': 0.2572, 'learning_rate': 1.0185025628301923e-06, 'rewards/chosen': -1.3242223262786865, 'rewards/rejected': -3.7246510982513428, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4004287719726562, 'policy_logps/rejected': -450.766845703125, 'policy_logps/chosen': -357.07904052734375, 'referece_logps/rejected': -413.52032470703125, 'referece_logps/chosen': -343.8367919921875, 'logits/rejected': -0.8362493515014648, 'logits/chosen': -0.8014042377471924, 'epoch': 3.06}


 51%|█████     | 8204/16104 [37:45:45<35:39:45, 16.25s/it]

 51%|█████     | 8205/16104 [37:46:06<38:45:52, 17.67s/it]

 51%|█████     | 8206/16104 [37:46:25<40:00:14, 18.23s/it]

 51%|█████     | 8207/16104 [37:46:39<37:19:31, 17.02s/it]
{'loss': 0.3562, 'learning_rate': 1.017497094343778e-06, 'rewards/chosen': -2.369701385498047, 'rewards/rejected': -3.9385130405426025, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5688118934631348, 'policy_logps/rejected': -484.4258728027344, 'policy_logps/chosen': -531.1893310546875, 'referece_logps/rejected': -445.040771484375, 'referece_logps/chosen': -507.4923095703125, 'logits/rejected': -0.07842183113098145, 'logits/chosen': 0.06019569933414459, 'epoch': 3.06}


 51%|█████     | 8209/16104 [37:47:12<36:36:55, 16.70s/it]

 51%|█████     | 8210/16104 [37:47:31<37:48:34, 17.24s/it]

 51%|█████     | 8211/16104 [37:47:50<39:31:08, 18.02s/it]

 51%|█████     | 8212/16104 [37:48:09<39:33:24, 18.04s/it]

 51%|█████     | 8213/16104 [37:48:27<39:40:59, 18.10s/it]

 51%|█████     | 8214/16104 [37:48:47<40:48:23, 18.62s/it]

 51%|█████     | 8215/16104 [37:49:03<39:12:27, 17.89s/it]

 51%|█████     | 8216/16104 [37:49:20<38:54:59, 17.76s/it]

 51%|█████     | 8217/16104 [37:49:38<39:12:48, 17.90s/it]

 51%|█████     | 8218/16104 [37:49:49<34:25:40, 15.72s/it]

 51%|█████     | 8219/16104 [37:50:02<32:24:54, 14.80s/it]

 51%|█████     | 8220/16104 [37:50:14<30:57:54, 14.14s/it]

 51%|█████     | 8221/16104 [37:50:31<32:45:36, 14.96s/it]

 51%|█████     | 8222/16104 [37:50:50<35:01:54, 16.00s/it]

 51%|█████     | 8223/16104 [37:51:09<37:18:06, 17.04s/it]

 51%|█████     | 8224/16104 [37:51:27<38:09:06, 17.43s/it]

 51%|█████     | 8225/16104 [37:51:39<34:35:45, 15.81s/it]

 51%|█████     | 8226/16104 [37:51:58<36:17:53, 16.59s/it]
{'loss': 0.3244, 'learning_rate': 1.0136761613750242e-06, 'rewards/chosen': -1.9620164632797241, 'rewards/rejected': -2.890188217163086, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9281716346740723, 'policy_logps/rejected': -363.03094482421875, 'policy_logps/chosen': -523.2047729492188, 'referece_logps/rejected': -334.12908935546875, 'referece_logps/chosen': -503.5845947265625, 'logits/rejected': -0.4864859879016876, 'logits/chosen': -0.43824252486228943, 'epoch': 3.06}


 51%|█████     | 8228/16104 [37:52:34<38:07:44, 17.43s/it]

 51%|█████     | 8229/16104 [37:52:44<33:39:59, 15.39s/it]

 51%|█████     | 8230/16104 [37:52:55<30:28:35, 13.93s/it]

 51%|█████     | 8231/16104 [37:53:06<28:21:22, 12.97s/it]

 51%|█████     | 8232/16104 [37:53:19<28:19:43, 12.96s/it]

 51%|█████     | 8233/16104 [37:53:32<28:40:23, 13.11s/it]
{'loss': 0.4406, 'learning_rate': 1.012268395924006e-06, 'rewards/chosen': -1.793172001838684, 'rewards/rejected': -2.965012550354004, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1718403100967407, 'policy_logps/rejected': -357.306396484375, 'policy_logps/chosen': -325.10577392578125, 'referece_logps/rejected': -327.6562805175781, 'referece_logps/chosen': -307.174072265625, 'logits/rejected': -0.6448696851730347, 'logits/chosen': -0.6413166522979736, 'epoch': 3.07}


 51%|█████     | 8235/16104 [37:54:03<31:21:16, 14.34s/it]
{'loss': 0.3708, 'learning_rate': 1.0118661726351797e-06, 'rewards/chosen': -1.5475753545761108, 'rewards/rejected': -2.7398605346679688, 'rewards/accuracies': 0.625, 'rewards/margins': 1.192285180091858, 'policy_logps/rejected': -379.7454833984375, 'policy_logps/chosen': -273.73150634765625, 'referece_logps/rejected': -352.3468933105469, 'referece_logps/chosen': -258.2557678222656, 'logits/rejected': -0.6120622158050537, 'logits/chosen': -0.6871054768562317, 'epoch': 3.07}

 51%|█████     | 8236/16104 [37:54:19<31:59:41, 14.64s/it]

 51%|█████     | 8237/16104 [37:54:41<36:45:37, 16.82s/it]

 51%|█████     | 8238/16104 [37:55:00<38:34:32, 17.65s/it]


 51%|█████     | 8240/16104 [37:55:38<39:07:16, 17.91s/it]
{'loss': 0.2985, 'learning_rate': 1.0108606061553456e-06, 'rewards/chosen': -2.1369168758392334, 'rewards/rejected': -3.9728527069091797, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8359359502792358, 'policy_logps/rejected': -464.8526611328125, 'policy_logps/chosen': -436.3653564453125, 'referece_logps/rejected': -425.1241455078125, 'referece_logps/chosen': -414.9962463378906, 'logits/rejected': -1.1807971000671387, 'logits/chosen': -1.0590871572494507, 'epoch': 3.07}


 51%|█████     | 8242/16104 [37:56:08<34:58:15, 16.01s/it]

 51%|█████     | 8243/16104 [37:56:18<31:16:15, 14.32s/it]

 51%|█████     | 8244/16104 [37:56:38<34:44:17, 15.91s/it]

 51%|█████     | 8245/16104 [37:56:50<32:30:33, 14.89s/it]

 51%|█████     | 8246/16104 [37:57:10<35:55:57, 16.46s/it]
{'loss': 0.2627, 'learning_rate': 1.0096539119711157e-06, 'rewards/chosen': -2.5092618465423584, 'rewards/rejected': -3.866884231567383, 'rewards/accuracies': 0.625, 'rewards/margins': 1.357622742652893, 'policy_logps/rejected': -348.2614440917969, 'policy_logps/chosen': -360.4687805175781, 'referece_logps/rejected': -309.59259033203125, 'referece_logps/chosen': -335.3761901855469, 'logits/rejected': 0.34016260504722595, 'logits/chosen': 0.3137578070163727, 'epoch': 3.07}


 51%|█████     | 8248/16104 [37:57:48<38:53:51, 17.82s/it]

 51%|█████     | 8249/16104 [37:58:06<38:50:56, 17.80s/it]

 51%|█████     | 8250/16104 [37:58:25<39:49:55, 18.26s/it]

 51%|█████     | 8251/16104 [37:58:40<37:34:58, 17.23s/it]
{'loss': 0.3461, 'learning_rate': 1.008648322670439e-06, 'rewards/chosen': -1.8439785242080688, 'rewards/rejected': -3.266592502593994, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4226137399673462, 'policy_logps/rejected': -285.5040283203125, 'policy_logps/chosen': -329.63201904296875, 'referece_logps/rejected': -252.83810424804688, 'referece_logps/chosen': -311.19219970703125, 'logits/rejected': -1.257234811782837, 'logits/chosen': -1.129682183265686, 'epoch': 3.07}


 51%|█████     | 8253/16104 [37:59:16<37:59:36, 17.42s/it]

 51%|█████▏    | 8254/16104 [37:59:34<37:55:26, 17.39s/it]

 51%|█████▏    | 8255/16104 [37:59:50<37:21:15, 17.13s/it]

 51%|█████▏    | 8256/16104 [38:00:06<36:37:51, 16.80s/it]

 51%|█████▏    | 8257/16104 [38:00:18<33:26:48, 15.34s/it]
{'loss': 0.4513, 'learning_rate': 1.0074416040543967e-06, 'rewards/chosen': -2.172991991043091, 'rewards/rejected': -4.651543617248535, 'rewards/accuracies': 0.75, 'rewards/margins': 2.4785518646240234, 'policy_logps/rejected': -453.039794921875, 'policy_logps/chosen': -438.0303039550781, 'referece_logps/rejected': -406.5244140625, 'referece_logps/chosen': -416.3004150390625, 'logits/rejected': -1.0629262924194336, 'logits/chosen': -0.8456332087516785, 'epoch': 3.08}


 51%|█████▏    | 8259/16104 [38:00:46<31:53:20, 14.63s/it]

 51%|█████▏    | 8260/16104 [38:01:06<35:15:45, 16.18s/it]

 51%|█████▏    | 8261/16104 [38:01:24<36:34:17, 16.79s/it]

 51%|█████▏    | 8262/16104 [38:01:42<37:25:59, 17.18s/it]

 51%|█████▏    | 8263/16104 [38:01:58<36:54:16, 16.94s/it]

 51%|█████▏    | 8264/16104 [38:02:10<33:37:47, 15.44s/it]

 51%|█████▏    | 8265/16104 [38:02:26<33:34:19, 15.42s/it]

 51%|█████▏    | 8266/16104 [38:02:46<36:55:04, 16.96s/it]
{'loss': 0.4256, 'learning_rate': 1.005631506360231e-06, 'rewards/chosen': -1.4182980060577393, 'rewards/rejected': -3.6383371353149414, 'rewards/accuracies': 1.0, 'rewards/margins': 2.220038890838623, 'policy_logps/rejected': -414.49822998046875, 'policy_logps/chosen': -453.8294677734375, 'referece_logps/rejected': -378.1148376464844, 'referece_logps/chosen': -439.64642333984375, 'logits/rejected': -0.40828725695610046, 'logits/chosen': -0.3979419469833374, 'epoch': 3.08}


 51%|█████▏    | 8268/16104 [38:03:14<34:22:22, 15.79s/it]

 51%|█████▏    | 8269/16104 [38:03:36<38:01:42, 17.47s/it]
{'loss': 0.326, 'learning_rate': 1.0050281360688076e-06, 'rewards/chosen': -1.7302520275115967, 'rewards/rejected': -3.422663688659668, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6924116611480713, 'policy_logps/rejected': -450.139404296875, 'policy_logps/chosen': -556.9324340820312, 'referece_logps/rejected': -415.9127197265625, 'referece_logps/chosen': -539.6299438476562, 'logits/rejected': -0.5917580723762512, 'logits/chosen': -0.6099475026130676, 'epoch': 3.08}

 51%|█████▏    | 8270/16104 [38:03:56<39:26:48, 18.13s/it]

 51%|█████▏    | 8271/16104 [38:04:13<39:18:15, 18.06s/it]


 51%|█████▏    | 8273/16104 [38:04:40<33:22:20, 15.34s/it]

 51%|█████▏    | 8274/16104 [38:04:52<31:15:36, 14.37s/it]

 51%|█████▏    | 8275/16104 [38:05:02<28:26:09, 13.08s/it]
{'loss': 0.3914, 'learning_rate': 1.0038213902139073e-06, 'rewards/chosen': -1.3278764486312866, 'rewards/rejected': -3.7649154663085938, 'rewards/accuracies': 0.75, 'rewards/margins': 2.4370388984680176, 'policy_logps/rejected': -335.7483215332031, 'policy_logps/chosen': -333.76129150390625, 'referece_logps/rejected': -298.0991516113281, 'referece_logps/chosen': -320.4825439453125, 'logits/rejected': -0.13579577207565308, 'logits/chosen': -0.2839711904525757, 'epoch': 3.08}

 51%|█████▏    | 8276/16104 [38:05:21<32:36:13, 14.99s/it]

 51%|█████▏    | 8277/16104 [38:05:39<34:35:18, 15.91s/it]

 51%|█████▏    | 8278/16104 [38:05:59<37:02:09, 17.04s/it]


 51%|█████▏    | 8280/16104 [38:06:42<41:44:21, 19.21s/it]
{'loss': 0.4112, 'learning_rate': 1.0028157643425719e-06, 'rewards/chosen': -1.3493373394012451, 'rewards/rejected': -2.840341567993164, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4910041093826294, 'policy_logps/rejected': -447.99420166015625, 'policy_logps/chosen': -406.2281494140625, 'referece_logps/rejected': -419.5907897949219, 'referece_logps/chosen': -392.73480224609375, 'logits/rejected': 0.2221212089061737, 'logits/chosen': 0.13543951511383057, 'epoch': 3.08}

 51%|█████▏    | 8281/16104 [38:06:57<38:58:39, 17.94s/it]

 51%|█████▏    | 8282/16104 [38:07:18<40:46:46, 18.77s/it]

 51%|█████▏    | 8283/16104 [38:07:34<39:03:04, 17.98s/it]

 51%|█████▏    | 8284/16104 [38:07:48<36:17:15, 16.71s/it]


 51%|█████▏    | 8286/16104 [38:08:14<32:14:22, 14.85s/it]

 51%|█████▏    | 8287/16104 [38:08:35<35:56:52, 16.56s/it]
{'loss': 0.2959, 'learning_rate': 1.0014078835665953e-06, 'rewards/chosen': -3.416520833969116, 'rewards/rejected': -4.702632427215576, 'rewards/accuracies': 0.75, 'rewards/margins': 1.286111831665039, 'policy_logps/rejected': -348.60687255859375, 'policy_logps/chosen': -384.8499755859375, 'referece_logps/rejected': -301.5805358886719, 'referece_logps/chosen': -350.68475341796875, 'logits/rejected': -0.056196823716163635, 'logits/chosen': 0.03929000347852707, 'epoch': 3.09}

 51%|█████▏    | 8288/16104 [38:08:56<39:00:56, 17.97s/it]


 51%|█████▏    | 8290/16104 [38:09:33<39:15:55, 18.09s/it]
{'loss': 0.3757, 'learning_rate': 1.0008045050741873e-06, 'rewards/chosen': -1.947769284248352, 'rewards/rejected': -3.34724497795105, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3994758129119873, 'policy_logps/rejected': -455.5673828125, 'policy_logps/chosen': -426.1829528808594, 'referece_logps/rejected': -422.0949401855469, 'referece_logps/chosen': -406.70526123046875, 'logits/rejected': -0.32565417885780334, 'logits/chosen': -0.3840496838092804, 'epoch': 3.09}


 51%|█████▏    | 8292/16104 [38:10:02<35:34:26, 16.39s/it]

 51%|█████▏    | 8293/16104 [38:10:15<33:09:15, 15.28s/it]

 52%|█████▏    | 8294/16104 [38:10:35<36:14:07, 16.70s/it]

 52%|█████▏    | 8295/16104 [38:10:52<36:44:09, 16.94s/it]

 52%|█████▏    | 8296/16104 [38:11:05<33:43:24, 15.55s/it]
{'loss': 0.4189, 'learning_rate': 9.995977474303627e-07, 'rewards/chosen': -1.5625319480895996, 'rewards/rejected': -3.1526873111724854, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5901553630828857, 'policy_logps/rejected': -422.8887023925781, 'policy_logps/chosen': -398.0611877441406, 'referece_logps/rejected': -391.36181640625, 'referece_logps/chosen': -382.4358825683594, 'logits/rejected': -0.5451829433441162, 'logits/chosen': -0.4866819679737091, 'epoch': 3.09}

 52%|█████▏    | 8297/16104 [38:11:19<33:09:59, 15.29s/it]


 52%|█████▏    | 8299/16104 [38:11:55<36:23:06, 16.78s/it]

 52%|█████▏    | 8300/16104 [38:12:17<39:34:49, 18.26s/it]

 52%|█████▏    | 8301/16104 [38:12:29<35:40:54, 16.46s/it]
{'loss': 0.5227, 'learning_rate': 9.98592116433405e-07, 'rewards/chosen': -1.4001230001449585, 'rewards/rejected': -2.0215537548065186, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6214306354522705, 'policy_logps/rejected': -386.66253662109375, 'policy_logps/chosen': -318.38427734375, 'referece_logps/rejected': -366.4469909667969, 'referece_logps/chosen': -304.3830261230469, 'logits/rejected': 0.036392971873283386, 'logits/chosen': 0.12616294622421265, 'epoch': 3.09}

 52%|█████▏    | 8302/16104 [38:12:39<31:48:04, 14.67s/it]


 52%|█████▏    | 8304/16104 [38:13:04<29:21:26, 13.55s/it]

 52%|█████▏    | 8305/16104 [38:13:21<31:03:00, 14.33s/it]

 52%|█████▏    | 8306/16104 [38:13:39<33:29:27, 15.46s/it]

 52%|█████▏    | 8307/16104 [38:13:49<30:25:07, 14.04s/it]

 52%|█████▏    | 8308/16104 [38:14:01<28:57:40, 13.37s/it]

 52%|█████▏    | 8309/16104 [38:14:20<32:43:01, 15.11s/it]
{'loss': 0.2272, 'learning_rate': 9.96983110222812e-07, 'rewards/chosen': -1.9123367071151733, 'rewards/rejected': -3.3949832916259766, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4826465845108032, 'policy_logps/rejected': -449.5741271972656, 'policy_logps/chosen': -427.25006103515625, 'referece_logps/rejected': -415.6242980957031, 'referece_logps/chosen': -408.1266784667969, 'logits/rejected': -0.6861920952796936, 'logits/chosen': -0.37820154428482056, 'epoch': 3.1}


 52%|█████▏    | 8311/16104 [38:14:51<31:50:01, 14.71s/it]
{'loss': 0.3007, 'learning_rate': 9.965808597278317e-07, 'rewards/chosen': -1.371090054512024, 'rewards/rejected': -3.9062552452087402, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5351650714874268, 'policy_logps/rejected': -249.65756225585938, 'policy_logps/chosen': -268.61773681640625, 'referece_logps/rejected': -210.594970703125, 'referece_logps/chosen': -254.90682983398438, 'logits/rejected': -0.7329422235488892, 'logits/chosen': -0.5342679619789124, 'epoch': 3.1}

 52%|█████▏    | 8312/16104 [38:15:12<35:59:06, 16.63s/it]

 52%|█████▏    | 8313/16104 [38:15:28<35:43:06, 16.50s/it]


 52%|█████▏    | 8315/16104 [38:15:55<32:34:53, 15.06s/it]

 52%|█████▏    | 8316/16104 [38:16:11<33:33:48, 15.51s/it]
{'loss': 0.2565, 'learning_rate': 9.955752360531894e-07, 'rewards/chosen': -1.7294760942459106, 'rewards/rejected': -3.061516284942627, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3320403099060059, 'policy_logps/rejected': -373.18157958984375, 'policy_logps/chosen': -431.0425720214844, 'referece_logps/rejected': -342.5664367675781, 'referece_logps/chosen': -413.7478332519531, 'logits/rejected': -0.6737272143363953, 'logits/chosen': -1.021498441696167, 'epoch': 3.1}


 52%|█████▏    | 8318/16104 [38:16:41<33:08:17, 15.32s/it]

 52%|█████▏    | 8319/16104 [38:16:59<34:21:48, 15.89s/it]
{'loss': 0.3741, 'learning_rate': 9.949718639311926e-07, 'rewards/chosen': -1.982603669166565, 'rewards/rejected': -3.8906192779541016, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9080156087875366, 'policy_logps/rejected': -234.9489288330078, 'policy_logps/chosen': -330.64349365234375, 'referece_logps/rejected': -196.042724609375, 'referece_logps/chosen': -310.8174743652344, 'logits/rejected': -1.1862579584121704, 'logits/chosen': -1.0590978860855103, 'epoch': 3.1}


 52%|█████▏    | 8321/16104 [38:17:25<31:27:00, 14.55s/it]

 52%|█████▏    | 8322/16104 [38:17:35<28:56:46, 13.39s/it]

 52%|█████▏    | 8323/16104 [38:17:49<29:00:32, 13.42s/it]

 52%|█████▏    | 8324/16104 [38:18:05<30:37:21, 14.17s/it]

 52%|█████▏    | 8325/16104 [38:18:19<30:41:00, 14.20s/it]

 52%|█████▏    | 8326/16104 [38:18:36<32:11:17, 14.90s/it]

 52%|█████▏    | 8327/16104 [38:18:55<35:15:19, 16.32s/it]

 52%|█████▏    | 8328/16104 [38:19:09<33:31:36, 15.52s/it]

 52%|█████▏    | 8329/16104 [38:19:21<31:11:22, 14.44s/it]

 52%|█████▏    | 8330/16104 [38:19:35<30:52:45, 14.30s/it]
{'loss': 0.4523, 'learning_rate': 9.927595168159934e-07, 'rewards/chosen': -1.618013858795166, 'rewards/rejected': -3.2074460983276367, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5894323587417603, 'policy_logps/rejected': -362.5238037109375, 'policy_logps/chosen': -308.2279968261719, 'referece_logps/rejected': -330.4493713378906, 'referece_logps/chosen': -292.0478515625, 'logits/rejected': -1.145388126373291, 'logits/chosen': -1.1326634883880615, 'epoch': 3.1}


 52%|█████▏    | 8332/16104 [38:20:13<35:55:09, 16.64s/it]
{'loss': 0.4204, 'learning_rate': 9.923572753762395e-07, 'rewards/chosen': -2.026297092437744, 'rewards/rejected': -3.3858587741851807, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3595614433288574, 'policy_logps/rejected': -519.6378173828125, 'policy_logps/chosen': -382.10906982421875, 'referece_logps/rejected': -485.77923583984375, 'referece_logps/chosen': -361.8460693359375, 'logits/rejected': -0.7325012683868408, 'logits/chosen': -0.6179881691932678, 'epoch': 3.1}


 52%|█████▏    | 8334/16104 [38:20:42<33:02:53, 15.31s/it]

 52%|█████▏    | 8335/16104 [38:20:53<30:26:05, 14.10s/it]

 52%|█████▏    | 8336/16104 [38:21:09<31:41:25, 14.69s/it]

 52%|█████▏    | 8337/16104 [38:21:27<33:47:57, 15.67s/it]

 52%|█████▏    | 8338/16104 [38:21:41<32:41:08, 15.15s/it]
{'loss': 0.2967, 'learning_rate': 9.911505587372032e-07, 'rewards/chosen': -1.915178656578064, 'rewards/rejected': -5.045736312866211, 'rewards/accuracies': 1.0, 'rewards/margins': 3.130557060241699, 'policy_logps/rejected': -414.546142578125, 'policy_logps/chosen': -324.6792907714844, 'referece_logps/rejected': -364.0887451171875, 'referece_logps/chosen': -305.5274963378906, 'logits/rejected': -0.07161858677864075, 'logits/chosen': 0.08504664897918701, 'epoch': 3.11}


 52%|█████▏    | 8340/16104 [38:22:11<33:16:59, 15.43s/it]
{'loss': 0.3491, 'learning_rate': 9.907483226345501e-07, 'rewards/chosen': -2.1402177810668945, 'rewards/rejected': -3.550807237625122, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4105894565582275, 'policy_logps/rejected': -416.1077880859375, 'policy_logps/chosen': -311.5677490234375, 'referece_logps/rejected': -380.5997009277344, 'referece_logps/chosen': -290.1655578613281, 'logits/rejected': 0.10908183455467224, 'logits/chosen': -0.058974988758563995, 'epoch': 3.11}

 52%|█████▏    | 8341/16104 [38:22:28<34:30:23, 16.00s/it]


 52%|█████▏    | 8343/16104 [38:23:00<34:00:05, 15.77s/it]
{'loss': 0.3372, 'learning_rate': 9.901449713077608e-07, 'rewards/chosen': -1.3190107345581055, 'rewards/rejected': -3.3278369903564453, 'rewards/accuracies': 1.0, 'rewards/margins': 2.00882625579834, 'policy_logps/rejected': -341.1994934082031, 'policy_logps/chosen': -324.5350646972656, 'referece_logps/rejected': -307.921142578125, 'referece_logps/chosen': -311.344970703125, 'logits/rejected': -0.0994294285774231, 'logits/chosen': -0.17925149202346802, 'epoch': 3.11}


 52%|█████▏    | 8345/16104 [38:23:27<31:21:02, 14.55s/it]

 52%|█████▏    | 8346/16104 [38:23:38<28:52:12, 13.40s/it]
{'loss': 0.4325, 'learning_rate': 9.895416235688524e-07, 'rewards/chosen': -0.9731419086456299, 'rewards/rejected': -2.833144187927246, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8600023984909058, 'policy_logps/rejected': -558.06201171875, 'policy_logps/chosen': -404.57427978515625, 'referece_logps/rejected': -529.7305908203125, 'referece_logps/chosen': -394.8428955078125, 'logits/rejected': -0.9164041876792908, 'logits/chosen': -0.7143669724464417, 'epoch': 3.11}


 52%|█████▏    | 8348/16104 [38:23:59<25:54:28, 12.03s/it]
{'loss': 0.4357, 'learning_rate': 9.891393938446547e-07, 'rewards/chosen': -1.3246691226959229, 'rewards/rejected': -2.4737250804901123, 'rewards/accuracies': 0.875, 'rewards/margins': 1.149056077003479, 'policy_logps/rejected': -494.89874267578125, 'policy_logps/chosen': -438.39447021484375, 'referece_logps/rejected': -470.1615295410156, 'referece_logps/chosen': -425.14776611328125, 'logits/rejected': -0.3483150601387024, 'logits/chosen': -0.44353750348091125, 'epoch': 3.11}

 52%|█████▏    | 8349/16104 [38:24:18<30:21:26, 14.09s/it]

 52%|█████▏    | 8350/16104 [38:24:37<33:40:57, 15.64s/it]

 52%|█████▏    | 8351/16104 [38:24:57<36:22:15, 16.89s/it]

 52%|█████▏    | 8352/16104 [38:25:19<39:18:01, 18.25s/it]


 52%|█████▏    | 8354/16104 [38:26:00<41:44:31, 19.39s/it]

 52%|█████▏    | 8355/16104 [38:26:12<36:55:15, 17.15s/it]
{'loss': 0.4296, 'learning_rate': 9.877316040759939e-07, 'rewards/chosen': -2.0727758407592773, 'rewards/rejected': -3.8920116424560547, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8192358016967773, 'policy_logps/rejected': -276.7232360839844, 'policy_logps/chosen': -283.3880920410156, 'referece_logps/rejected': -237.8031463623047, 'referece_logps/chosen': -262.66033935546875, 'logits/rejected': -0.2862022817134857, 'logits/chosen': -0.14592699706554413, 'epoch': 3.11}

 52%|█████▏    | 8356/16104 [38:26:30<37:44:59, 17.54s/it]

 52%|█████▏    | 8357/16104 [38:26:47<36:53:19, 17.14s/it]


 52%|█████▏    | 8359/16104 [38:27:18<36:05:44, 16.78s/it]
{'loss': 0.2997, 'learning_rate': 9.869271635187657e-07, 'rewards/chosen': -1.160832405090332, 'rewards/rejected': -3.728616952896118, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5677847862243652, 'policy_logps/rejected': -446.29254150390625, 'policy_logps/chosen': -433.16314697265625, 'referece_logps/rejected': -409.0063781738281, 'referece_logps/chosen': -421.5548400878906, 'logits/rejected': 0.3363659083843231, 'logits/chosen': 0.3719467222690582, 'epoch': 3.11}

 52%|█████▏    | 8360/16104 [38:27:31<33:35:37, 15.62s/it]


 52%|█████▏    | 8362/16104 [38:28:10<37:55:20, 17.63s/it]

 52%|█████▏    | 8363/16104 [38:28:30<39:11:40, 18.23s/it]
{'loss': 0.3132, 'learning_rate': 9.861227314226495e-07, 'rewards/chosen': -0.724450945854187, 'rewards/rejected': -3.0698750019073486, 'rewards/accuracies': 0.875, 'rewards/margins': 2.345424175262451, 'policy_logps/rejected': -728.6845092773438, 'policy_logps/chosen': -646.0123901367188, 'referece_logps/rejected': -697.9857177734375, 'referece_logps/chosen': -638.7679443359375, 'logits/rejected': 0.00026963651180267334, 'logits/chosen': 0.17745469510555267, 'epoch': 3.12}

 52%|█████▏    | 8364/16104 [38:28:49<40:02:48, 18.63s/it]

 52%|█████▏    | 8365/16104 [38:29:09<40:31:46, 18.85s/it]

 52%|█████▏    | 8366/16104 [38:29:22<37:11:28, 17.30s/it]

 52%|█████▏    | 8367/16104 [38:29:39<36:47:03, 17.12s/it]


 52%|█████▏    | 8369/16104 [38:30:14<37:24:13, 17.41s/it]

 52%|█████▏    | 8370/16104 [38:30:30<36:32:10, 17.01s/it]

 52%|█████▏    | 8371/16104 [38:30:48<37:08:52, 17.29s/it]
{'loss': 0.3977, 'learning_rate': 9.845138946963556e-07, 'rewards/chosen': -2.5222535133361816, 'rewards/rejected': -3.8231041431427, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3008506298065186, 'policy_logps/rejected': -415.0692443847656, 'policy_logps/chosen': -317.97833251953125, 'referece_logps/rejected': -376.8382263183594, 'referece_logps/chosen': -292.75579833984375, 'logits/rejected': -0.06986872851848602, 'logits/chosen': 0.1293523758649826, 'epoch': 3.12}


 52%|█████▏    | 8373/16104 [38:31:16<33:30:42, 15.61s/it]
{'loss': 0.2773, 'learning_rate': 9.841116916164881e-07, 'rewards/chosen': -1.1041394472122192, 'rewards/rejected': -3.3720080852508545, 'rewards/accuracies': 1.0, 'rewards/margins': 2.267868757247925, 'policy_logps/rejected': -311.2530517578125, 'policy_logps/chosen': -334.74884033203125, 'referece_logps/rejected': -277.5329895019531, 'referece_logps/chosen': -323.70745849609375, 'logits/rejected': -0.13763979077339172, 'logits/chosen': -0.2734007239341736, 'epoch': 3.12}

 52%|█████▏    | 8374/16104 [38:31:33<34:20:31, 15.99s/it]


 52%|█████▏    | 8376/16104 [38:32:12<38:12:52, 17.80s/it]
{'loss': 0.4247, 'learning_rate': 9.835083918373522e-07, 'rewards/chosen': -1.5250895023345947, 'rewards/rejected': -3.2077925205230713, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6827033758163452, 'policy_logps/rejected': -356.6500549316406, 'policy_logps/chosen': -380.3602600097656, 'referece_logps/rejected': -324.5721130371094, 'referece_logps/chosen': -365.1093444824219, 'logits/rejected': 0.18347984552383423, 'logits/chosen': 0.11031714081764221, 'epoch': 3.12}


 52%|█████▏    | 8378/16104 [38:32:40<34:16:24, 15.97s/it]

 52%|█████▏    | 8379/16104 [38:33:00<36:52:05, 17.18s/it]

 52%|█████▏    | 8380/16104 [38:33:14<34:40:10, 16.16s/it]

 52%|█████▏    | 8381/16104 [38:33:29<33:33:44, 15.64s/it]

 52%|█████▏    | 8382/16104 [38:33:43<32:29:10, 15.15s/it]
{'loss': 0.3632, 'learning_rate': 9.823018105108232e-07, 'rewards/chosen': -2.196592330932617, 'rewards/rejected': -4.225828170776367, 'rewards/accuracies': 1.0, 'rewards/margins': 2.029236078262329, 'policy_logps/rejected': -451.6576843261719, 'policy_logps/chosen': -547.1265869140625, 'referece_logps/rejected': -409.3994140625, 'referece_logps/chosen': -525.16064453125, 'logits/rejected': -0.9000965356826782, 'logits/chosen': -0.9944055080413818, 'epoch': 3.12}

 52%|█████▏    | 8383/16104 [38:33:59<33:21:56, 15.56s/it]


 52%|█████▏    | 8385/16104 [38:34:29<32:12:35, 15.02s/it]
{'loss': 0.4128, 'learning_rate': 9.816985294027052e-07, 'rewards/chosen': -0.7515476942062378, 'rewards/rejected': -2.654562473297119, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9030144214630127, 'policy_logps/rejected': -329.3474426269531, 'policy_logps/chosen': -311.4948425292969, 'referece_logps/rejected': -302.80181884765625, 'referece_logps/chosen': -303.9793701171875, 'logits/rejected': -0.8261713981628418, 'logits/chosen': -0.8238986730575562, 'epoch': 3.12}

 52%|█████▏    | 8386/16104 [38:34:47<34:29:14, 16.09s/it]

 52%|█████▏    | 8387/16104 [38:35:05<35:54:06, 16.75s/it]

 52%|█████▏    | 8388/16104 [38:35:23<36:39:36, 17.10s/it]

 52%|█████▏    | 8389/16104 [38:35:43<38:28:46, 17.96s/it]

 52%|█████▏    | 8390/16104 [38:36:02<38:49:27, 18.12s/it]


 52%|█████▏    | 8392/16104 [38:36:37<38:16:54, 17.87s/it]
{'loss': 0.2969, 'learning_rate': 9.802908997748235e-07, 'rewards/chosen': -1.6492100954055786, 'rewards/rejected': -3.0055651664733887, 'rewards/accuracies': 1.0, 'rewards/margins': 1.35635507106781, 'policy_logps/rejected': -378.98760986328125, 'policy_logps/chosen': -367.0890197753906, 'referece_logps/rejected': -348.93194580078125, 'referece_logps/chosen': -350.596923828125, 'logits/rejected': -0.28159382939338684, 'logits/chosen': -0.44041842222213745, 'epoch': 3.13}

 52%|█████▏    | 8393/16104 [38:36:51<36:15:09, 16.93s/it]


 52%|█████▏    | 8395/16104 [38:37:23<34:26:10, 16.08s/it]

 52%|█████▏    | 8396/16104 [38:37:42<36:49:03, 17.20s/it]

 52%|█████▏    | 8397/16104 [38:38:02<38:34:00, 18.01s/it]

 52%|█████▏    | 8398/16104 [38:38:16<36:03:27, 16.84s/it]
{'loss': 0.2174, 'learning_rate': 9.790843910814934e-07, 'rewards/chosen': -1.859541893005371, 'rewards/rejected': -4.237957000732422, 'rewards/accuracies': 1.0, 'rewards/margins': 2.378415107727051, 'policy_logps/rejected': -377.65447998046875, 'policy_logps/chosen': -448.9178771972656, 'referece_logps/rejected': -335.27490234375, 'referece_logps/chosen': -430.3224792480469, 'logits/rejected': 0.1117311418056488, 'logits/chosen': 0.11005417257547379, 'epoch': 3.13}

 52%|█████▏    | 8399/16104 [38:38:36<37:51:18, 17.69s/it]


 52%|█████▏    | 8401/16104 [38:39:02<32:26:10, 15.16s/it]
{'loss': 0.401, 'learning_rate': 9.784811480470114e-07, 'rewards/chosen': -1.5658824443817139, 'rewards/rejected': -4.160825252532959, 'rewards/accuracies': 1.0, 'rewards/margins': 2.594942808151245, 'policy_logps/rejected': -319.4951171875, 'policy_logps/chosen': -349.6507568359375, 'referece_logps/rejected': -277.8868408203125, 'referece_logps/chosen': -333.9919128417969, 'logits/rejected': 0.34399932622909546, 'logits/chosen': 0.4928283095359802, 'epoch': 3.13}

 52%|█████▏    | 8402/16104 [38:39:16<31:14:32, 14.60s/it]

 52%|█████▏    | 8403/16104 [38:39:26<28:40:10, 13.40s/it]

 52%|█████▏    | 8404/16104 [38:39:44<31:05:49, 14.54s/it]

 52%|█████▏    | 8405/16104 [38:39:54<28:37:03, 13.38s/it]

 52%|█████▏    | 8406/16104 [38:40:12<31:26:38, 14.70s/it]

 52%|█████▏    | 8407/16104 [38:40:25<30:27:37, 14.25s/it]

 52%|█████▏    | 8408/16104 [38:40:36<28:32:15, 13.35s/it]

 52%|█████▏    | 8409/16104 [38:40:55<32:07:55, 15.03s/it]


 52%|█████▏    | 8411/16104 [38:41:37<38:42:51, 18.12s/it]
{'loss': 0.2868, 'learning_rate': 9.764703957466561e-07, 'rewards/chosen': -0.9791109561920166, 'rewards/rejected': -3.9202725887298584, 'rewards/accuracies': 1.0, 'rewards/margins': 2.941161870956421, 'policy_logps/rejected': -521.9213256835938, 'policy_logps/chosen': -538.17626953125, 'referece_logps/rejected': -482.7186584472656, 'referece_logps/chosen': -528.3851318359375, 'logits/rejected': -0.1773931086063385, 'logits/chosen': -0.19563716650009155, 'epoch': 3.13}


 52%|█████▏    | 8413/16104 [38:42:09<36:13:19, 16.95s/it]

 52%|█████▏    | 8414/16104 [38:42:31<39:31:06, 18.50s/it]
{'loss': 0.3543, 'learning_rate': 9.758671882468456e-07, 'rewards/chosen': -2.3627727031707764, 'rewards/rejected': -3.3968710899353027, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0340983867645264, 'policy_logps/rejected': -225.27017211914062, 'policy_logps/chosen': -345.1841125488281, 'referece_logps/rejected': -191.30148315429688, 'referece_logps/chosen': -321.556396484375, 'logits/rejected': -0.26766252517700195, 'logits/chosen': -0.34993642568588257, 'epoch': 3.13}

 52%|█████▏    | 8415/16104 [38:42:45<36:27:45, 17.07s/it]

 52%|█████▏    | 8416/16104 [38:43:05<38:15:44, 17.92s/it]


 52%|█████▏    | 8418/16104 [38:43:39<37:56:43, 17.77s/it]
{'loss': 0.3309, 'learning_rate': 9.750629252854013e-07, 'rewards/chosen': -1.586218237876892, 'rewards/rejected': -3.706116199493408, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1198980808258057, 'policy_logps/rejected': -254.994140625, 'policy_logps/chosen': -330.3476257324219, 'referece_logps/rejected': -217.93292236328125, 'referece_logps/chosen': -314.4854431152344, 'logits/rejected': -0.03238007426261902, 'logits/chosen': -0.044449739158153534, 'epoch': 3.14}

 52%|█████▏    | 8419/16104 [38:43:55<37:01:22, 17.34s/it]

 52%|█████▏    | 8420/16104 [38:44:14<37:45:23, 17.69s/it]


 52%|█████▏    | 8422/16104 [38:44:45<35:44:23, 16.75s/it]
{'loss': 0.4216, 'learning_rate': 9.74258678463943e-07, 'rewards/chosen': -1.7387254238128662, 'rewards/rejected': -3.4720964431762695, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7333712577819824, 'policy_logps/rejected': -377.17730712890625, 'policy_logps/chosen': -455.24945068359375, 'referece_logps/rejected': -342.4563293457031, 'referece_logps/chosen': -437.8621826171875, 'logits/rejected': -0.1747206598520279, 'logits/chosen': -0.3684409558773041, 'epoch': 3.14}

 52%|█████▏    | 8423/16104 [38:44:59<33:54:00, 15.89s/it]

 52%|█████▏    | 8424/16104 [38:45:15<33:55:29, 15.90s/it]

 52%|█████▏    | 8425/16104 [38:45:26<30:40:08, 14.38s/it]


 52%|█████▏    | 8427/16104 [38:45:49<27:59:52, 13.13s/it]
{'loss': 0.2904, 'learning_rate': 9.732533934269716e-07, 'rewards/chosen': -1.7379690408706665, 'rewards/rejected': -4.127294063568115, 'rewards/accuracies': 0.875, 'rewards/margins': 2.389324903488159, 'policy_logps/rejected': -328.1270751953125, 'policy_logps/chosen': -438.69525146484375, 'referece_logps/rejected': -286.8541259765625, 'referece_logps/chosen': -421.3155517578125, 'logits/rejected': -0.06419134885072708, 'logits/chosen': -0.09351116418838501, 'epoch': 3.14}

 52%|█████▏    | 8428/16104 [38:46:00<26:25:51, 12.40s/it]

 52%|█████▏    | 8429/16104 [38:46:21<31:49:56, 14.93s/it]

 52%|█████▏    | 8430/16104 [38:46:34<30:33:59, 14.34s/it]

 52%|█████▏    | 8431/16104 [38:46:47<29:35:50, 13.89s/it]

 52%|█████▏    | 8432/16104 [38:47:06<33:17:27, 15.62s/it]

 52%|█████▏    | 8433/16104 [38:47:20<32:18:08, 15.16s/it]

 52%|█████▏    | 8434/16104 [38:47:35<31:52:55, 14.96s/it]

 52%|█████▏    | 8435/16104 [38:47:48<30:26:05, 14.29s/it]

 52%|█████▏    | 8436/16104 [38:48:06<33:09:09, 15.56s/it]


 52%|█████▏    | 8438/16104 [38:48:37<33:12:18, 15.59s/it]
{'loss': 0.2586, 'learning_rate': 9.710418629884355e-07, 'rewards/chosen': -1.7815290689468384, 'rewards/rejected': -3.89642333984375, 'rewards/accuracies': 1.0, 'rewards/margins': 2.114894151687622, 'policy_logps/rejected': -408.7038879394531, 'policy_logps/chosen': -482.356201171875, 'referece_logps/rejected': -369.7396545410156, 'referece_logps/chosen': -464.5408935546875, 'logits/rejected': -1.069421648979187, 'logits/chosen': -1.151013731956482, 'epoch': 3.14}


 52%|█████▏    | 8440/16104 [38:49:13<35:54:14, 16.87s/it]

 52%|█████▏    | 8441/16104 [38:49:25<32:53:34, 15.45s/it]
{'loss': 0.3447, 'learning_rate': 9.704387424675268e-07, 'rewards/chosen': -1.7800648212432861, 'rewards/rejected': -3.910111904144287, 'rewards/accuracies': 0.625, 'rewards/margins': 2.130046844482422, 'policy_logps/rejected': -339.5225524902344, 'policy_logps/chosen': -358.12823486328125, 'referece_logps/rejected': -300.42144775390625, 'referece_logps/chosen': -340.32757568359375, 'logits/rejected': -0.5742501616477966, 'logits/chosen': -0.6595816016197205, 'epoch': 3.14}

 52%|█████▏    | 8442/16104 [38:49:46<36:16:41, 17.05s/it]

 52%|█████▏    | 8443/16104 [38:50:07<38:27:59, 18.08s/it]

 52%|█████▏    | 8444/16104 [38:50:28<40:39:16, 19.11s/it]

 52%|█████▏    | 8445/16104 [38:50:45<39:06:36, 18.38s/it]

 52%|█████▏    | 8446/16104 [38:50:57<35:11:16, 16.54s/it]


 52%|█████▏    | 8448/16104 [38:51:32<35:32:36, 16.71s/it]
{'loss': 0.3852, 'learning_rate': 9.690315034847747e-07, 'rewards/chosen': -2.052122116088867, 'rewards/rejected': -4.354348182678223, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3022258281707764, 'policy_logps/rejected': -495.60443115234375, 'policy_logps/chosen': -470.46258544921875, 'referece_logps/rejected': -452.06097412109375, 'referece_logps/chosen': -449.94134521484375, 'logits/rejected': -0.6197487711906433, 'logits/chosen': -0.6961342692375183, 'epoch': 3.15}

 52%|█████▏    | 8449/16104 [38:51:52<37:46:55, 17.77s/it]

 52%|█████▏    | 8450/16104 [38:52:11<38:39:17, 18.18s/it]

 52%|█████▏    | 8451/16104 [38:52:29<38:42:58, 18.21s/it]


 52%|█████▏    | 8453/16104 [38:53:00<35:18:02, 16.61s/it]
{'loss': 0.4314, 'learning_rate': 9.680263702020924e-07, 'rewards/chosen': -1.6461706161499023, 'rewards/rejected': -4.082588195800781, 'rewards/accuracies': 1.0, 'rewards/margins': 2.436417818069458, 'policy_logps/rejected': -303.8952331542969, 'policy_logps/chosen': -430.0714111328125, 'referece_logps/rejected': -263.0693664550781, 'referece_logps/chosen': -413.6097106933594, 'logits/rejected': -0.3115716576576233, 'logits/chosen': -0.16090013086795807, 'epoch': 3.15}

 52%|█████▏    | 8454/16104 [38:53:15<34:21:23, 16.17s/it]

 53%|█████▎    | 8455/16104 [38:53:25<30:52:31, 14.53s/it]

 53%|█████▎    | 8456/16104 [38:53:39<30:03:24, 14.15s/it]

 53%|█████▎    | 8457/16104 [38:53:52<29:30:30, 13.89s/it]


 53%|█████▎    | 8459/16104 [38:54:26<33:10:35, 15.62s/it]
{'loss': 0.3175, 'learning_rate': 9.66820253034201e-07, 'rewards/chosen': -1.3906712532043457, 'rewards/rejected': -4.149942874908447, 'rewards/accuracies': 0.875, 'rewards/margins': 2.7592716217041016, 'policy_logps/rejected': -234.92633056640625, 'policy_logps/chosen': -295.1149597167969, 'referece_logps/rejected': -193.42691040039062, 'referece_logps/chosen': -281.2082214355469, 'logits/rejected': -0.4495857059955597, 'logits/chosen': -0.5261968374252319, 'epoch': 3.15}

 53%|█████▎    | 8460/16104 [38:54:38<31:21:00, 14.76s/it]

 53%|█████▎    | 8461/16104 [38:54:57<34:02:52, 16.04s/it]

 53%|█████▎    | 8462/16104 [38:55:13<33:36:44, 15.83s/it]

 53%|█████▎    | 8463/16104 [38:55:34<37:06:24, 17.48s/it]

 53%|█████▎    | 8464/16104 [38:55:53<38:02:34, 17.93s/it]

 53%|█████▎    | 8465/16104 [38:56:12<38:36:41, 18.20s/it]

 53%|█████▎    | 8466/16104 [38:56:26<35:51:40, 16.90s/it]


 53%|█████▎    | 8468/16104 [38:56:50<30:17:25, 14.28s/it]

 53%|█████▎    | 8469/16104 [38:57:05<30:56:21, 14.59s/it]

 53%|█████▎    | 8470/16104 [38:57:25<34:08:09, 16.10s/it]

 53%|█████▎    | 8471/16104 [38:57:35<30:48:25, 14.53s/it]

 53%|█████▎    | 8472/16104 [38:57:54<33:20:38, 15.73s/it]

 53%|█████▎    | 8473/16104 [38:58:09<33:03:05, 15.59s/it]

 53%|█████▎    | 8474/16104 [38:58:30<36:07:08, 17.04s/it]

 53%|█████▎    | 8475/16104 [38:58:41<32:16:30, 15.23s/it]

 53%|█████▎    | 8476/16104 [38:58:54<31:08:39, 14.70s/it]

 53%|█████▎    | 8477/16104 [38:59:07<29:48:50, 14.07s/it]

 53%|█████▎    | 8478/16104 [38:59:22<30:42:38, 14.50s/it]

 53%|█████▎    | 8479/16104 [38:59:35<29:45:27, 14.05s/it]

 53%|█████▎    | 8480/16104 [38:59:46<27:35:55, 13.03s/it]

 53%|█████▎    | 8481/16104 [39:00:03<30:28:01, 14.39s/it]

 53%|█████▎    | 8482/16104 [39:00:19<30:58:00, 14.63s/it]

 53%|█████▎    | 8483/16104 [39:00:38<34:14:43, 16.18s/it]

 53%|█████▎    | 8484/16104 [39:00:57<35:49:48, 16.93s/it]

 53%|█████▎    | 8485/16104 [39:01:15<36:35:02, 17.29s/it]

 53%|█████▎    | 8486/16104 [39:01:26<32:27:55, 15.34s/it]

 53%|█████▎    | 8487/16104 [39:01:44<33:51:59, 16.01s/it]

 53%|█████▎    | 8488/16104 [39:02:00<34:06:15, 16.12s/it]

 53%|█████▎    | 8489/16104 [39:02:12<31:35:35, 14.94s/it]

 53%|█████▎    | 8490/16104 [39:02:32<34:33:01, 16.34s/it]

 53%|█████▎    | 8491/16104 [39:02:43<31:35:29, 14.94s/it]

 53%|█████▎    | 8492/16104 [39:02:55<29:09:36, 13.79s/it]

 53%|█████▎    | 8493/16104 [39:03:12<31:31:40, 14.91s/it]

 53%|█████▎    | 8494/16104 [39:03:24<29:54:18, 14.15s/it]

 53%|█████▎    | 8495/16104 [39:03:46<34:53:55, 16.51s/it]

 53%|█████▎    | 8496/16104 [39:04:00<32:55:22, 15.58s/it]

 53%|█████▎    | 8497/16104 [39:04:19<35:08:49, 16.63s/it]

 53%|█████▎    | 8498/16104 [39:04:31<32:08:48, 15.22s/it]

 53%|█████▎    | 8499/16104 [39:04:43<29:52:32, 14.14s/it]

 53%|█████▎    | 8500/16104 [39:05:03<33:35:51, 15.91s/it]

 53%|█████▎    | 8501/16104 [39:05:38<45:43:16, 21.65s/it]

 53%|█████▎    | 8502/16104 [39:05:55<42:47:03, 20.26s/it]

 53%|█████▎    | 8503/16104 [39:06:14<42:22:58, 20.07s/it]

 53%|█████▎    | 8504/16104 [39:06:28<38:24:00, 18.19s/it]

 53%|█████▎    | 8505/16104 [39:06:42<35:52:04, 16.99s/it]

 53%|█████▎    | 8506/16104 [39:07:02<37:47:36, 17.91s/it]

 53%|█████▎    | 8507/16104 [39:07:22<38:45:08, 18.36s/it]

 53%|█████▎    | 8508/16104 [39:07:42<39:45:15, 18.84s/it]
{'loss': 0.3673, 'learning_rate': 9.569722617887134e-07, 'rewards/chosen': -1.2945082187652588, 'rewards/rejected': -2.609908103942871, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3153998851776123, 'policy_logps/rejected': -264.0423889160156, 'policy_logps/chosen': -304.33404541015625, 'referece_logps/rejected': -237.94329833984375, 'referece_logps/chosen': -291.3889465332031, 'logits/rejected': -0.36240535974502563, 'logits/chosen': -0.5045040249824524, 'epoch': 3.17}


 53%|█████▎    | 8510/16104 [39:08:13<37:06:58, 17.60s/it]

 53%|█████▎    | 8511/16104 [39:08:26<33:40:43, 15.97s/it]

 53%|█████▎    | 8512/16104 [39:08:47<36:44:25, 17.42s/it]

 53%|█████▎    | 8513/16104 [39:09:07<38:27:09, 18.24s/it]

 53%|█████▎    | 8514/16104 [39:09:27<39:40:56, 18.82s/it]

 53%|█████▎    | 8515/16104 [39:09:45<39:35:38, 18.78s/it]

 53%|█████▎    | 8516/16104 [39:10:05<40:15:55, 19.10s/it]

 53%|█████▎    | 8517/16104 [39:10:27<41:54:52, 19.89s/it]

 53%|█████▎    | 8518/16104 [39:10:46<41:34:02, 19.73s/it]

 53%|█████▎    | 8519/16104 [39:11:06<41:38:22, 19.76s/it]

 53%|█████▎    | 8520/16104 [39:11:24<40:22:22, 19.16s/it]

 53%|█████▎    | 8521/16104 [39:11:35<35:03:51, 16.65s/it]

 53%|█████▎    | 8522/16104 [39:11:49<33:40:29, 15.99s/it]

 53%|█████▎    | 8523/16104 [39:12:00<30:14:55, 14.36s/it]

 53%|█████▎    | 8524/16104 [39:12:11<27:56:30, 13.27s/it]

 53%|█████▎    | 8525/16104 [39:12:21<26:16:56, 12.48s/it]

 53%|█████▎    | 8526/16104 [39:12:32<25:16:14, 12.01s/it]

 53%|█████▎    | 8527/16104 [39:12:43<24:27:07, 11.62s/it]

 53%|█████▎    | 8528/16104 [39:12:53<23:51:31, 11.34s/it]

 53%|█████▎    | 8529/16104 [39:13:08<25:57:56, 12.34s/it]

 53%|█████▎    | 8530/16104 [39:13:28<30:59:33, 14.73s/it]

 53%|█████▎    | 8531/16104 [39:13:46<32:56:17, 15.66s/it]

 53%|█████▎    | 8532/16104 [39:14:06<35:45:18, 17.00s/it]

 53%|█████▎    | 8533/16104 [39:14:26<37:30:29, 17.84s/it]

 53%|█████▎    | 8534/16104 [39:14:38<33:39:08, 16.00s/it]

 53%|█████▎    | 8535/16104 [39:14:59<36:53:23, 17.55s/it]

 53%|█████▎    | 8536/16104 [39:15:17<37:12:33, 17.70s/it]

 53%|█████▎    | 8537/16104 [39:15:30<34:04:46, 16.21s/it]

 53%|█████▎    | 8538/16104 [39:15:41<30:36:31, 14.56s/it]

 53%|█████▎    | 8539/16104 [39:15:51<28:09:13, 13.40s/it]

 53%|█████▎    | 8540/16104 [39:16:02<26:25:39, 12.58s/it]

 53%|█████▎    | 8541/16104 [39:16:13<25:27:24, 12.12s/it]

 53%|█████▎    | 8542/16104 [39:16:24<24:39:02, 11.74s/it]

 53%|█████▎    | 8543/16104 [39:16:44<29:51:30, 14.22s/it]

 53%|█████▎    | 8544/16104 [39:16:56<28:24:37, 13.53s/it]

 53%|█████▎    | 8545/16104 [39:17:15<31:44:48, 15.12s/it]

 53%|█████▎    | 8546/16104 [39:17:28<30:50:53, 14.69s/it]

 53%|█████▎    | 8547/16104 [39:17:50<35:03:22, 16.70s/it]

 53%|█████▎    | 8548/16104 [39:18:09<36:27:38, 17.37s/it]

 53%|█████▎    | 8549/16104 [39:18:24<35:16:46, 16.81s/it]

 53%|█████▎    | 8550/16104 [39:18:39<34:18:12, 16.35s/it]

 53%|█████▎    | 8551/16104 [39:18:56<34:42:36, 16.54s/it]

 53%|█████▎    | 8552/16104 [39:19:15<36:03:15, 17.19s/it]

 53%|█████▎    | 8553/16104 [39:19:26<31:53:57, 15.21s/it]

 53%|█████▎    | 8554/16104 [39:19:43<33:15:17, 15.86s/it]

 53%|█████▎    | 8555/16104 [39:19:54<30:21:21, 14.48s/it]

 53%|█████▎    | 8556/16104 [39:20:05<28:06:36, 13.41s/it]

 53%|█████▎    | 8557/16104 [39:20:27<33:32:53, 16.00s/it]

 53%|█████▎    | 8558/16104 [39:20:45<34:28:19, 16.45s/it]

 53%|█████▎    | 8559/16104 [39:20:58<32:23:20, 15.45s/it]

 53%|█████▎    | 8560/16104 [39:21:20<36:39:39, 17.49s/it]

 53%|█████▎    | 8561/16104 [39:21:35<35:04:14, 16.74s/it]

 53%|█████▎    | 8562/16104 [39:21:49<33:00:01, 15.75s/it]

 53%|█████▎    | 8563/16104 [39:22:02<31:41:03, 15.13s/it]

 53%|█████▎    | 8564/16104 [39:22:21<33:41:44, 16.09s/it]

 53%|█████▎    | 8565/16104 [39:22:39<35:04:42, 16.75s/it]

 53%|█████▎    | 8566/16104 [39:22:59<37:02:28, 17.69s/it]

 53%|█████▎    | 8567/16104 [39:23:12<34:15:38, 16.36s/it]

 53%|█████▎    | 8568/16104 [39:23:25<31:50:09, 15.21s/it]

 53%|█████▎    | 8569/16104 [39:23:44<34:13:46, 16.35s/it]

 53%|█████▎    | 8570/16104 [39:24:03<35:59:55, 17.20s/it]

 53%|█████▎    | 8571/16104 [39:24:16<33:37:49, 16.07s/it]

 53%|█████▎    | 8572/16104 [39:24:33<33:52:49, 16.19s/it]
{'loss': 0.3306, 'learning_rate': 9.441160200580018e-07, 'rewards/chosen': -2.5368149280548096, 'rewards/rejected': -4.257453441619873, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7206385135650635, 'policy_logps/rejected': -462.0958251953125, 'policy_logps/chosen': -432.20257568359375, 'referece_logps/rejected': -419.5213317871094, 'referece_logps/chosen': -406.83441162109375, 'logits/rejected': 0.959064245223999, 'logits/chosen': 0.8844839334487915, 'epoch': 3.19}


 53%|█████▎    | 8574/16104 [39:25:08<34:52:44, 16.68s/it]
{'loss': 0.3408, 'learning_rate': 9.437144006220058e-07, 'rewards/chosen': -1.813366413116455, 'rewards/rejected': -3.3076648712158203, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4942985773086548, 'policy_logps/rejected': -243.2215576171875, 'policy_logps/chosen': -371.5195007324219, 'referece_logps/rejected': -210.14491271972656, 'referece_logps/chosen': -353.38580322265625, 'logits/rejected': -1.2272088527679443, 'logits/chosen': -0.8779614567756653, 'epoch': 3.19}


 53%|█████▎    | 8576/16104 [39:25:43<35:27:44, 16.96s/it]

 53%|█████▎    | 8577/16104 [39:25:54<31:36:31, 15.12s/it]

 53%|█████▎    | 8578/16104 [39:26:13<34:15:09, 16.38s/it]

 53%|█████▎    | 8579/16104 [39:26:24<30:41:35, 14.68s/it]

 53%|█████▎    | 8580/16104 [39:26:44<34:04:27, 16.30s/it]

 53%|█████▎    | 8581/16104 [39:27:04<36:13:42, 17.34s/it]

 53%|█████▎    | 8582/16104 [39:27:23<37:26:31, 17.92s/it]

 53%|█████▎    | 8583/16104 [39:27:39<36:18:36, 17.38s/it]

 53%|█████▎    | 8584/16104 [39:27:55<35:24:55, 16.95s/it]
{'loss': 0.4662, 'learning_rate': 9.417064413528463e-07, 'rewards/chosen': -2.0530643463134766, 'rewards/rejected': -3.5213186740875244, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4682540893554688, 'policy_logps/rejected': -480.17138671875, 'policy_logps/chosen': -663.4935302734375, 'referece_logps/rejected': -444.9582214355469, 'referece_logps/chosen': -642.9629516601562, 'logits/rejected': -0.8568280339241028, 'logits/chosen': -1.0543831586837769, 'epoch': 3.2}

 53%|█████▎    | 8585/16104 [39:28:16<38:05:48, 18.24s/it]


 53%|█████▎    | 8587/16104 [39:28:54<38:46:28, 18.57s/it]

 53%|█████▎    | 8588/16104 [39:29:06<34:39:52, 16.60s/it]

 53%|█████▎    | 8589/16104 [39:29:19<32:37:30, 15.63s/it]

 53%|█████▎    | 8590/16104 [39:29:39<35:04:34, 16.81s/it]
{'loss': 0.3782, 'learning_rate': 9.405017784592755e-07, 'rewards/chosen': -2.216641426086426, 'rewards/rejected': -5.222102642059326, 'rewards/accuracies': 0.875, 'rewards/margins': 3.0054612159729004, 'policy_logps/rejected': -392.73162841796875, 'policy_logps/chosen': -321.3414306640625, 'referece_logps/rejected': -340.5105895996094, 'referece_logps/chosen': -299.17498779296875, 'logits/rejected': 0.10936948657035828, 'logits/chosen': 0.30726513266563416, 'epoch': 3.2}


 53%|█████▎    | 8592/16104 [39:30:10<34:35:35, 16.58s/it]

 53%|█████▎    | 8593/16104 [39:30:28<35:17:33, 16.92s/it]

 53%|█████▎    | 8594/16104 [39:30:40<32:02:41, 15.36s/it]

 53%|█████▎    | 8595/16104 [39:31:02<36:26:57, 17.47s/it]

 53%|█████▎    | 8596/16104 [39:31:20<36:51:42, 17.67s/it]
{'loss': 0.3132, 'learning_rate': 9.39297202210827e-07, 'rewards/chosen': -1.7245644330978394, 'rewards/rejected': -2.756429433822632, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0318646430969238, 'policy_logps/rejected': -448.1317138671875, 'policy_logps/chosen': -328.84222412109375, 'referece_logps/rejected': -420.5674133300781, 'referece_logps/chosen': -311.5965576171875, 'logits/rejected': -0.7050220966339111, 'logits/chosen': -0.5740395188331604, 'epoch': 3.2}


 53%|█████▎    | 8598/16104 [39:31:42<29:26:27, 14.12s/it]

 53%|█████▎    | 8599/16104 [39:31:52<27:15:32, 13.08s/it]
{'loss': 0.5882, 'learning_rate': 9.386949471267103e-07, 'rewards/chosen': -1.829080581665039, 'rewards/rejected': -2.0022976398468018, 'rewards/accuracies': 0.5, 'rewards/margins': 0.17321717739105225, 'policy_logps/rejected': -345.9226989746094, 'policy_logps/chosen': -473.2734680175781, 'referece_logps/rejected': -325.8997497558594, 'referece_logps/chosen': -454.982666015625, 'logits/rejected': -0.2586881220340729, 'logits/chosen': -0.42938297986984253, 'epoch': 3.2}


 53%|█████▎    | 8601/16104 [39:32:14<24:43:01, 11.86s/it]
{'loss': 0.4222, 'learning_rate': 9.382934561232582e-07, 'rewards/chosen': -1.4464161396026611, 'rewards/rejected': -2.5533385276794434, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1069223880767822, 'policy_logps/rejected': -304.655517578125, 'policy_logps/chosen': -285.0389404296875, 'referece_logps/rejected': -279.12213134765625, 'referece_logps/chosen': -270.5747985839844, 'logits/rejected': -0.5433167219161987, 'logits/chosen': -0.49967995285987854, 'epoch': 3.2}


 53%|█████▎    | 8603/16104 [39:32:46<29:44:11, 14.27s/it]

 53%|█████▎    | 8604/16104 [39:32:59<29:18:03, 14.06s/it]
{'loss': 0.4821, 'learning_rate': 9.376912383594294e-07, 'rewards/chosen': -2.3241000175476074, 'rewards/rejected': -3.9920475482940674, 'rewards/accuracies': 1.0, 'rewards/margins': 1.66794753074646, 'policy_logps/rejected': -357.8707275390625, 'policy_logps/chosen': -450.5650329589844, 'referece_logps/rejected': -317.9502868652344, 'referece_logps/chosen': -427.32403564453125, 'logits/rejected': -0.5288034081459045, 'logits/chosen': -0.48766523599624634, 'epoch': 3.21}

 53%|█████▎    | 8605/16104 [39:33:19<32:49:53, 15.76s/it]


 53%|█████▎    | 8607/16104 [39:33:56<36:03:03, 17.31s/it]

 53%|█████▎    | 8608/16104 [39:34:16<37:32:03, 18.03s/it]

 53%|█████▎    | 8609/16104 [39:34:32<36:26:41, 17.51s/it]

 53%|█████▎    | 8610/16104 [39:34:52<37:40:49, 18.10s/it]

 53%|█████▎    | 8611/16104 [39:35:04<34:17:13, 16.47s/it]

 53%|█████▎    | 8612/16104 [39:35:22<34:56:54, 16.79s/it]

 53%|█████▎    | 8613/16104 [39:35:37<33:37:19, 16.16s/it]

 53%|█████▎    | 8614/16104 [39:35:52<32:58:20, 15.85s/it]

 53%|█████▎    | 8615/16104 [39:36:03<30:19:44, 14.58s/it]

 54%|█████▎    | 8616/16104 [39:36:19<31:12:08, 15.00s/it]
{'loss': 0.3909, 'learning_rate': 9.352825963415091e-07, 'rewards/chosen': -1.5224242210388184, 'rewards/rejected': -3.141981363296509, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6195571422576904, 'policy_logps/rejected': -224.16934204101562, 'policy_logps/chosen': -358.30419921875, 'referece_logps/rejected': -192.74952697753906, 'referece_logps/chosen': -343.0799560546875, 'logits/rejected': -0.727638304233551, 'logits/chosen': -0.7516356706619263, 'epoch': 3.21}


 54%|█████▎    | 8618/16104 [39:36:59<36:09:26, 17.39s/it]

 54%|█████▎    | 8619/16104 [39:37:20<38:50:24, 18.68s/it]

 54%|█████▎    | 8620/16104 [39:37:40<39:26:11, 18.97s/it]

 54%|█████▎    | 8621/16104 [39:37:56<37:55:57, 18.25s/it]
{'loss': 0.4416, 'learning_rate': 9.342791059577631e-07, 'rewards/chosen': -1.6479402780532837, 'rewards/rejected': -2.641674280166626, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9937338829040527, 'policy_logps/rejected': -395.58514404296875, 'policy_logps/chosen': -387.2592468261719, 'referece_logps/rejected': -369.16839599609375, 'referece_logps/chosen': -370.77984619140625, 'logits/rejected': -0.542145848274231, 'logits/chosen': -0.5714672803878784, 'epoch': 3.21}

 54%|█████▎    | 8622/16104 [39:38:15<38:04:50, 18.32s/it]


 54%|█████▎    | 8624/16104 [39:38:44<33:34:31, 16.16s/it]
{'loss': 0.5052, 'learning_rate': 9.336770435648963e-07, 'rewards/chosen': -1.9377400875091553, 'rewards/rejected': -2.970289707183838, 'rewards/accuracies': 0.75, 'rewards/margins': 1.032549500465393, 'policy_logps/rejected': -430.0641784667969, 'policy_logps/chosen': -446.89508056640625, 'referece_logps/rejected': -400.3612976074219, 'referece_logps/chosen': -427.5177001953125, 'logits/rejected': -0.16795052587985992, 'logits/chosen': -0.05808153748512268, 'epoch': 3.21}


 54%|█████▎    | 8626/16104 [39:39:11<30:32:38, 14.70s/it]
{'loss': 0.5411, 'learning_rate': 9.332756820371974e-07, 'rewards/chosen': -1.531764030456543, 'rewards/rejected': -1.8800175189971924, 'rewards/accuracies': 0.75, 'rewards/margins': 0.34825342893600464, 'policy_logps/rejected': -426.7328186035156, 'policy_logps/chosen': -378.47271728515625, 'referece_logps/rejected': -407.9326477050781, 'referece_logps/chosen': -363.15509033203125, 'logits/rejected': 0.16661259531974792, 'logits/chosen': 0.2913551330566406, 'epoch': 3.21}


 54%|█████▎    | 8628/16104 [39:39:44<31:22:11, 15.11s/it]

 54%|█████▎    | 8629/16104 [39:40:06<35:40:47, 17.18s/it]
{'loss': 0.3264, 'learning_rate': 9.326736600093269e-07, 'rewards/chosen': -2.241393804550171, 'rewards/rejected': -3.0086312294006348, 'rewards/accuracies': 0.75, 'rewards/margins': 0.767237663269043, 'policy_logps/rejected': -261.38580322265625, 'policy_logps/chosen': -280.2518310546875, 'referece_logps/rejected': -231.2994842529297, 'referece_logps/chosen': -257.837890625, 'logits/rejected': -0.05844712257385254, 'logits/chosen': 0.24404078722000122, 'epoch': 3.21}


 54%|█████▎    | 8631/16104 [39:40:46<39:03:55, 18.82s/it]

 54%|█████▎    | 8632/16104 [39:41:04<38:36:58, 18.61s/it]

 54%|█████▎    | 8633/16104 [39:41:18<35:36:04, 17.15s/it]
{'loss': 0.3717, 'learning_rate': 9.31871002138634e-07, 'rewards/chosen': -1.6878553628921509, 'rewards/rejected': -2.249706506729126, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5618512034416199, 'policy_logps/rejected': -330.99847412109375, 'policy_logps/chosen': -455.3169250488281, 'referece_logps/rejected': -308.50140380859375, 'referece_logps/chosen': -438.4383239746094, 'logits/rejected': -1.035176396369934, 'logits/chosen': -1.1845130920410156, 'epoch': 3.22}


 54%|█████▎    | 8635/16104 [39:41:40<28:54:39, 13.93s/it]
{'loss': 0.388, 'learning_rate': 9.314696897064564e-07, 'rewards/chosen': -1.420110821723938, 'rewards/rejected': -2.837641716003418, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4175312519073486, 'policy_logps/rejected': -400.5238037109375, 'policy_logps/chosen': -345.3992004394531, 'referece_logps/rejected': -372.1473388671875, 'referece_logps/chosen': -331.1980895996094, 'logits/rejected': -1.0953123569488525, 'logits/chosen': -1.0646885633468628, 'epoch': 3.22}


 54%|█████▎    | 8637/16104 [39:42:18<34:05:17, 16.43s/it]

 54%|█████▎    | 8638/16104 [39:42:29<30:43:12, 14.81s/it]
{'loss': 0.3539, 'learning_rate': 9.308677418697812e-07, 'rewards/chosen': -1.1942797899246216, 'rewards/rejected': -3.0107998847961426, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8165197372436523, 'policy_logps/rejected': -451.4571533203125, 'policy_logps/chosen': -405.2018127441406, 'referece_logps/rejected': -421.34912109375, 'referece_logps/chosen': -393.2590026855469, 'logits/rejected': -0.5718728303909302, 'logits/chosen': -0.45574072003364563, 'epoch': 3.22}

 54%|█████▎    | 8639/16104 [39:42:39<28:09:07, 13.58s/it]


 54%|█████▎    | 8641/16104 [39:43:09<28:42:11, 13.85s/it]

 54%|█████▎    | 8642/16104 [39:43:20<26:55:37, 12.99s/it]

 54%|█████▎    | 8643/16104 [39:43:42<32:49:07, 15.84s/it]

 54%|█████▎    | 8644/16104 [39:44:02<35:12:20, 16.99s/it]

 54%|█████▎    | 8645/16104 [39:44:22<37:02:22, 17.88s/it]
{'loss': 0.3825, 'learning_rate': 9.294632951746075e-07, 'rewards/chosen': -1.32827627658844, 'rewards/rejected': -3.1365835666656494, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8083070516586304, 'policy_logps/rejected': -337.7382507324219, 'policy_logps/chosen': -430.419189453125, 'referece_logps/rejected': -306.3724060058594, 'referece_logps/chosen': -417.13641357421875, 'logits/rejected': -0.6892088055610657, 'logits/chosen': -0.7421935200691223, 'epoch': 3.22}


 54%|█████▎    | 8647/16104 [39:44:55<34:50:43, 16.82s/it]

 54%|█████▎    | 8648/16104 [39:45:15<37:00:01, 17.86s/it]
{'loss': 0.3393, 'learning_rate': 9.288614320858198e-07, 'rewards/chosen': -1.3818705081939697, 'rewards/rejected': -2.481114149093628, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0992437601089478, 'policy_logps/rejected': -314.88720703125, 'policy_logps/chosen': -443.66448974609375, 'referece_logps/rejected': -290.0760192871094, 'referece_logps/chosen': -429.8457946777344, 'logits/rejected': -1.0526114702224731, 'logits/chosen': -1.0314719676971436, 'epoch': 3.22}

 54%|█████▎    | 8649/16104 [39:45:35<38:32:30, 18.61s/it]


 54%|█████▎    | 8651/16104 [39:46:14<39:45:13, 19.20s/it]
{'loss': 0.3593, 'learning_rate': 9.2825959489617e-07, 'rewards/chosen': -1.7920098304748535, 'rewards/rejected': -4.3601579666137695, 'rewards/accuracies': 0.75, 'rewards/margins': 2.568148374557495, 'policy_logps/rejected': -353.2767639160156, 'policy_logps/chosen': -330.740966796875, 'referece_logps/rejected': -309.6751708984375, 'referece_logps/chosen': -312.82086181640625, 'logits/rejected': -0.6017245054244995, 'logits/chosen': -0.5742810964584351, 'epoch': 3.22}


 54%|█████▎    | 8653/16104 [39:46:40<33:25:58, 16.15s/it]

 54%|█████▎    | 8654/16104 [39:46:55<32:30:11, 15.71s/it]

 54%|█████▎    | 8655/16104 [39:47:12<33:22:24, 16.13s/it]

 54%|█████▍    | 8656/16104 [39:47:29<33:40:15, 16.27s/it]
{'loss': 0.2805, 'learning_rate': 9.272565910621638e-07, 'rewards/chosen': -1.796235203742981, 'rewards/rejected': -4.19348669052124, 'rewards/accuracies': 0.875, 'rewards/margins': 2.397251605987549, 'policy_logps/rejected': -366.7880859375, 'policy_logps/chosen': -367.58099365234375, 'referece_logps/rejected': -324.853271484375, 'referece_logps/chosen': -349.61865234375, 'logits/rejected': -0.2560897767543793, 'logits/chosen': -0.29886993765830994, 'epoch': 3.23}

 54%|█████▍    | 8657/16104 [39:47:40<30:13:37, 14.61s/it]


 54%|█████▍    | 8659/16104 [39:48:05<27:42:25, 13.40s/it]

 54%|█████▍    | 8660/16104 [39:48:24<31:26:12, 15.20s/it]

 54%|█████▍    | 8661/16104 [39:48:37<29:49:06, 14.42s/it]
{'loss': 0.4928, 'learning_rate': 9.262536607931692e-07, 'rewards/chosen': -1.7302706241607666, 'rewards/rejected': -2.996331214904785, 'rewards/accuracies': 0.75, 'rewards/margins': 1.266060471534729, 'policy_logps/rejected': -393.3014831542969, 'policy_logps/chosen': -319.4147644042969, 'referece_logps/rejected': -363.338134765625, 'referece_logps/chosen': -302.1120300292969, 'logits/rejected': -0.7505868673324585, 'logits/chosen': -0.7334730625152588, 'epoch': 3.23}


 54%|█████▍    | 8663/16104 [39:49:05<29:48:48, 14.42s/it]

 54%|█████▍    | 8664/16104 [39:49:23<32:12:38, 15.59s/it]

 54%|█████▍    | 8665/16104 [39:49:36<30:49:23, 14.92s/it]

 54%|█████▍    | 8666/16104 [39:49:48<29:08:58, 14.11s/it]
{'loss': 0.3684, 'learning_rate': 9.252508051034443e-07, 'rewards/chosen': -2.141672134399414, 'rewards/rejected': -4.462866306304932, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3211944103240967, 'policy_logps/rejected': -350.7746276855469, 'policy_logps/chosen': -387.39581298828125, 'referece_logps/rejected': -306.14599609375, 'referece_logps/chosen': -365.9790954589844, 'logits/rejected': -0.4642253518104553, 'logits/chosen': -0.59788978099823, 'epoch': 3.23}


 54%|█████▍    | 8668/16104 [39:50:17<29:31:30, 14.29s/it]

 54%|█████▍    | 8669/16104 [39:50:29<28:22:23, 13.74s/it]
{'loss': 0.3261, 'learning_rate': 9.246491279095617e-07, 'rewards/chosen': -1.8909982442855835, 'rewards/rejected': -4.5323920249938965, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6413938999176025, 'policy_logps/rejected': -247.45132446289062, 'policy_logps/chosen': -356.5700988769531, 'referece_logps/rejected': -202.12738037109375, 'referece_logps/chosen': -337.6601257324219, 'logits/rejected': 0.11768283694982529, 'logits/chosen': -0.02219913899898529, 'epoch': 3.23}

 54%|█████▍    | 8670/16104 [39:50:46<29:56:17, 14.50s/it]

 54%|█████▍    | 8671/16104 [39:51:06<33:13:47, 16.09s/it]


 54%|█████▍    | 8673/16104 [39:51:32<30:30:09, 14.78s/it]
{'loss': 0.3894, 'learning_rate': 9.23846934361991e-07, 'rewards/chosen': -2.106081008911133, 'rewards/rejected': -3.265228033065796, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1591469049453735, 'policy_logps/rejected': -357.27496337890625, 'policy_logps/chosen': -442.330810546875, 'referece_logps/rejected': -324.6227111816406, 'referece_logps/chosen': -421.2699890136719, 'logits/rejected': -0.70535808801651, 'logits/chosen': -0.7148531079292297, 'epoch': 3.23}


 54%|█████▍    | 8675/16104 [39:52:03<31:14:34, 15.14s/it]
{'loss': 0.4182, 'learning_rate': 9.2344585603892e-07, 'rewards/chosen': -2.023585557937622, 'rewards/rejected': -2.8643858432769775, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8408000469207764, 'policy_logps/rejected': -509.0975036621094, 'policy_logps/chosen': -381.8009033203125, 'referece_logps/rejected': -480.4536437988281, 'referece_logps/chosen': -361.5650329589844, 'logits/rejected': 0.38462740182876587, 'logits/chosen': 0.6000071167945862, 'epoch': 3.23}


 54%|█████▍    | 8677/16104 [39:52:40<34:40:53, 16.81s/it]
{'loss': 0.4301, 'learning_rate': 9.23044790102856e-07, 'rewards/chosen': -1.3629448413848877, 'rewards/rejected': -3.1972100734710693, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8342649936676025, 'policy_logps/rejected': -395.9138488769531, 'policy_logps/chosen': -392.18084716796875, 'referece_logps/rejected': -363.94171142578125, 'referece_logps/chosen': -378.5513916015625, 'logits/rejected': 0.21241621673107147, 'logits/chosen': 0.2568358778953552, 'epoch': 3.23}

 54%|█████▍    | 8678/16104 [39:53:00<37:01:54, 17.95s/it]


 54%|█████▍    | 8680/16104 [39:53:32<34:46:04, 16.86s/it]

 54%|█████▍    | 8681/16104 [39:53:49<34:30:59, 16.74s/it]

 54%|█████▍    | 8682/16104 [39:54:09<36:46:24, 17.84s/it]

 54%|█████▍    | 8683/16104 [39:54:27<37:02:38, 17.97s/it]

 54%|█████▍    | 8684/16104 [39:54:47<38:07:51, 18.50s/it]

 54%|█████▍    | 8685/16104 [39:55:07<38:59:02, 18.92s/it]
{'loss': 0.3164, 'learning_rate': 9.214406515265442e-07, 'rewards/chosen': -2.25423264503479, 'rewards/rejected': -6.266060829162598, 'rewards/accuracies': 1.0, 'rewards/margins': 4.01182746887207, 'policy_logps/rejected': -581.2877807617188, 'policy_logps/chosen': -553.8268432617188, 'referece_logps/rejected': -518.627197265625, 'referece_logps/chosen': -531.2845458984375, 'logits/rejected': -0.16887310147285461, 'logits/chosen': 0.03300437331199646, 'epoch': 3.24}

 54%|█████▍    | 8686/16104 [39:55:28<40:07:16, 19.47s/it]


 54%|█████▍    | 8688/16104 [39:56:05<39:16:42, 19.07s/it]

 54%|█████▍    | 8689/16104 [39:56:25<40:14:38, 19.54s/it]

 54%|█████▍    | 8690/16104 [39:56:37<35:31:07, 17.25s/it]
{'loss': 0.28, 'learning_rate': 9.204381679333722e-07, 'rewards/chosen': -1.1464074850082397, 'rewards/rejected': -3.8848092555999756, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7384018898010254, 'policy_logps/rejected': -393.41162109375, 'policy_logps/chosen': -373.98748779296875, 'referece_logps/rejected': -354.56353759765625, 'referece_logps/chosen': -362.5234375, 'logits/rejected': -0.3571527600288391, 'logits/chosen': -0.3202468156814575, 'epoch': 3.24}

 54%|█████▍    | 8691/16104 [39:56:54<35:17:34, 17.14s/it]


 54%|█████▍    | 8693/16104 [39:57:19<30:14:02, 14.69s/it]
{'loss': 0.5191, 'learning_rate': 9.198367163336026e-07, 'rewards/chosen': -1.8863133192062378, 'rewards/rejected': -2.2658350467681885, 'rewards/accuracies': 0.75, 'rewards/margins': 0.37952202558517456, 'policy_logps/rejected': -538.51171875, 'policy_logps/chosen': -395.94512939453125, 'referece_logps/rejected': -515.8533325195312, 'referece_logps/chosen': -377.0820007324219, 'logits/rejected': -1.1036431789398193, 'logits/chosen': -0.9199318289756775, 'epoch': 3.24}


 54%|█████▍    | 8695/16104 [39:57:53<32:33:47, 15.82s/it]
{'loss': 0.3861, 'learning_rate': 9.194357648006458e-07, 'rewards/chosen': -1.7828967571258545, 'rewards/rejected': -2.8762118816375732, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0933153629302979, 'policy_logps/rejected': -386.2045593261719, 'policy_logps/chosen': -365.0771484375, 'referece_logps/rejected': -357.4424133300781, 'referece_logps/chosen': -347.2481994628906, 'logits/rejected': 0.09503059834241867, 'logits/chosen': 0.0662493109703064, 'epoch': 3.24}

 54%|█████▍    | 8696/16104 [39:58:06<30:57:18, 15.04s/it]


 54%|█████▍    | 8698/16104 [39:58:47<36:08:59, 17.57s/it]
{'loss': 0.2404, 'learning_rate': 9.188343619637367e-07, 'rewards/chosen': -1.246567964553833, 'rewards/rejected': -3.888800621032715, 'rewards/accuracies': 1.0, 'rewards/margins': 2.642232656478882, 'policy_logps/rejected': -330.402587890625, 'policy_logps/chosen': -324.94158935546875, 'referece_logps/rejected': -291.51458740234375, 'referece_logps/chosen': -312.47589111328125, 'logits/rejected': -0.29065629839897156, 'logits/chosen': -0.28185731172561646, 'epoch': 3.24}

 54%|█████▍    | 8699/16104 [39:59:09<38:26:49, 18.69s/it]

 54%|█████▍    | 8700/16104 [39:59:28<39:07:39, 19.02s/it]

 54%|█████▍    | 8701/16104 [39:59:44<37:09:51, 18.07s/it]


 54%|█████▍    | 8703/16104 [40:00:21<37:24:02, 18.19s/it]
{'loss': 0.3636, 'learning_rate': 9.178320896762363e-07, 'rewards/chosen': -1.852102518081665, 'rewards/rejected': -3.5116231441497803, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6595203876495361, 'policy_logps/rejected': -433.2983703613281, 'policy_logps/chosen': -434.7422790527344, 'referece_logps/rejected': -398.18212890625, 'referece_logps/chosen': -416.22125244140625, 'logits/rejected': 0.38618195056915283, 'logits/chosen': 0.38768643140792847, 'epoch': 3.24}

 54%|█████▍    | 8704/16104 [40:00:36<35:28:16, 17.26s/it]

 54%|█████▍    | 8705/16104 [40:00:53<35:06:32, 17.08s/it]

 54%|█████▍    | 8706/16104 [40:01:15<38:13:22, 18.60s/it]

 54%|█████▍    | 8707/16104 [40:01:35<38:45:23, 18.86s/it]

 54%|█████▍    | 8708/16104 [40:01:55<39:27:01, 19.20s/it]

 54%|█████▍    | 8709/16104 [40:02:13<39:07:27, 19.05s/it]

 54%|█████▍    | 8710/16104 [40:02:27<35:45:20, 17.41s/it]

 54%|█████▍    | 8711/16104 [40:02:45<36:24:18, 17.73s/it]

 54%|█████▍    | 8712/16104 [40:03:07<38:41:19, 18.84s/it]

 54%|█████▍    | 8713/16104 [40:03:25<38:00:30, 18.51s/it]


 54%|█████▍    | 8715/16104 [40:03:50<31:40:42, 15.43s/it]
{'loss': 0.434, 'learning_rate': 9.1542697714745e-07, 'rewards/chosen': -2.1583099365234375, 'rewards/rejected': -2.6489663124084473, 'rewards/accuracies': 0.75, 'rewards/margins': 0.49065595865249634, 'policy_logps/rejected': -289.1151123046875, 'policy_logps/chosen': -289.689208984375, 'referece_logps/rejected': -262.62548828125, 'referece_logps/chosen': -268.1061096191406, 'logits/rejected': 1.2639656066894531, 'logits/chosen': 1.1324427127838135, 'epoch': 3.25}


 54%|█████▍    | 8717/16104 [40:04:28<35:02:55, 17.08s/it]
{'loss': 0.2734, 'learning_rate': 9.150261725767988e-07, 'rewards/chosen': -1.7974238395690918, 'rewards/rejected': -3.6459097862243652, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8484859466552734, 'policy_logps/rejected': -296.5645446777344, 'policy_logps/chosen': -443.01153564453125, 'referece_logps/rejected': -260.10546875, 'referece_logps/chosen': -425.0373229980469, 'logits/rejected': -0.6427112221717834, 'logits/chosen': -0.5943211317062378, 'epoch': 3.25}

 54%|█████▍    | 8718/16104 [40:04:43<33:50:00, 16.49s/it]


 54%|█████▍    | 8720/16104 [40:05:24<38:13:01, 18.63s/it]

 54%|█████▍    | 8721/16104 [40:05:42<37:50:24, 18.45s/it]
{'loss': 0.318, 'learning_rate': 9.142246047484627e-07, 'rewards/chosen': -1.8757352828979492, 'rewards/rejected': -3.079496145248413, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2037607431411743, 'policy_logps/rejected': -246.71885681152344, 'policy_logps/chosen': -236.1038818359375, 'referece_logps/rejected': -215.92388916015625, 'referece_logps/chosen': -217.34652709960938, 'logits/rejected': -0.07338637858629227, 'logits/chosen': -0.0019117668271064758, 'epoch': 3.25}

 54%|█████▍    | 8722/16104 [40:06:01<37:47:44, 18.43s/it]


 54%|█████▍    | 8724/16104 [40:06:40<39:19:44, 19.18s/it]
{'loss': 0.2792, 'learning_rate': 9.136234652814005e-07, 'rewards/chosen': -1.4101300239562988, 'rewards/rejected': -2.498772144317627, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0886421203613281, 'policy_logps/rejected': -347.4042663574219, 'policy_logps/chosen': -267.73846435546875, 'referece_logps/rejected': -322.4165344238281, 'referece_logps/chosen': -253.63717651367188, 'logits/rejected': -0.8052501678466797, 'logits/chosen': -0.9358197450637817, 'epoch': 3.25}

 54%|█████▍    | 8725/16104 [40:06:51<34:02:06, 16.60s/it]

 54%|█████▍    | 8726/16104 [40:07:11<36:02:38, 17.59s/it]


 54%|█████▍    | 8728/16104 [40:07:36<31:27:04, 15.35s/it]
{'loss': 0.5533, 'learning_rate': 9.128219949469969e-07, 'rewards/chosen': -1.6064194440841675, 'rewards/rejected': -2.2803096771240234, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6738903522491455, 'policy_logps/rejected': -469.74664306640625, 'policy_logps/chosen': -444.1490173339844, 'referece_logps/rejected': -446.943603515625, 'referece_logps/chosen': -428.0848693847656, 'logits/rejected': 0.22801490128040314, 'logits/chosen': 0.35282102227211, 'epoch': 3.25}

 54%|█████▍    | 8729/16104 [40:07:51<31:10:52, 15.22s/it]

 54%|█████▍    | 8730/16104 [40:08:13<35:02:40, 17.11s/it]


 54%|█████▍    | 8732/16104 [40:08:47<35:13:31, 17.20s/it]
{'loss': 0.3297, 'learning_rate': 9.120205810366849e-07, 'rewards/chosen': -1.567642331123352, 'rewards/rejected': -3.846149444580078, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2785072326660156, 'policy_logps/rejected': -448.9478454589844, 'policy_logps/chosen': -600.3118896484375, 'referece_logps/rejected': -410.4863586425781, 'referece_logps/chosen': -584.6354370117188, 'logits/rejected': 0.044700682163238525, 'logits/chosen': 0.0008481740951538086, 'epoch': 3.25}


 54%|█████▍    | 8734/16104 [40:09:16<32:51:23, 16.05s/it]
{'loss': 0.4192, 'learning_rate': 9.116198954026576e-07, 'rewards/chosen': -2.140036106109619, 'rewards/rejected': -2.842439889907837, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7024035453796387, 'policy_logps/rejected': -356.2771301269531, 'policy_logps/chosen': -349.78790283203125, 'referece_logps/rejected': -327.852783203125, 'referece_logps/chosen': -328.3875732421875, 'logits/rejected': -0.8903351426124573, 'logits/chosen': -0.6749482750892639, 'epoch': 3.25}

 54%|█████▍    | 8735/16104 [40:09:29<30:37:35, 14.96s/it]

 54%|█████▍    | 8736/16104 [40:09:40<28:01:06, 13.69s/it]


 54%|█████▍    | 8738/16104 [40:10:16<32:53:25, 16.07s/it]
{'loss': 0.3832, 'learning_rate': 9.108185671010292e-07, 'rewards/chosen': -1.534041404724121, 'rewards/rejected': -4.328363418579102, 'rewards/accuracies': 0.75, 'rewards/margins': 2.7943222522735596, 'policy_logps/rejected': -366.43988037109375, 'policy_logps/chosen': -366.7125549316406, 'referece_logps/rejected': -323.15625, 'referece_logps/chosen': -351.3721618652344, 'logits/rejected': -0.2508818209171295, 'logits/chosen': -0.3008822202682495, 'epoch': 3.26}

 54%|█████▍    | 8739/16104 [40:10:36<35:08:46, 17.18s/it]

 54%|█████▍    | 8740/16104 [40:10:49<32:45:30, 16.01s/it]

 54%|█████▍    | 8741/16104 [40:11:09<35:05:58, 17.16s/it]

 54%|█████▍    | 8742/16104 [40:11:20<31:10:01, 15.24s/it]

 54%|█████▍    | 8743/16104 [40:11:39<33:55:06, 16.59s/it]

 54%|█████▍    | 8744/16104 [40:11:59<35:46:48, 17.50s/it]

 54%|█████▍    | 8745/16104 [40:12:16<35:27:35, 17.35s/it]


 54%|█████▍    | 8747/16104 [40:12:55<37:21:14, 18.28s/it]

 54%|█████▍    | 8748/16104 [40:13:14<38:12:07, 18.70s/it]
{'loss': 0.3725, 'learning_rate': 9.088155000097514e-07, 'rewards/chosen': -1.6463676691055298, 'rewards/rejected': -3.146705150604248, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5003377199172974, 'policy_logps/rejected': -235.67205810546875, 'policy_logps/chosen': -279.41131591796875, 'referece_logps/rejected': -204.2050018310547, 'referece_logps/chosen': -262.9476318359375, 'logits/rejected': -0.7079750895500183, 'logits/chosen': -0.8375181555747986, 'epoch': 3.26}

 54%|█████▍    | 8749/16104 [40:13:33<38:30:31, 18.85s/it]

 54%|█████▍    | 8750/16104 [40:13:54<39:25:01, 19.30s/it]

 54%|█████▍    | 8751/16104 [40:14:13<39:23:21, 19.28s/it]

 54%|█████▍    | 8752/16104 [40:14:29<37:34:15, 18.40s/it]

 54%|█████▍    | 8753/16104 [40:14:45<36:03:20, 17.66s/it]


 54%|█████▍    | 8755/16104 [40:15:17<33:03:50, 16.20s/it]

 54%|█████▍    | 8756/16104 [40:15:39<36:41:11, 17.97s/it]
{'loss': 0.4272, 'learning_rate': 9.072133115252112e-07, 'rewards/chosen': -1.9126203060150146, 'rewards/rejected': -3.1138010025024414, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2011809349060059, 'policy_logps/rejected': -365.3908386230469, 'policy_logps/chosen': -338.9337463378906, 'referece_logps/rejected': -334.2528076171875, 'referece_logps/chosen': -319.80755615234375, 'logits/rejected': -0.05765223503112793, 'logits/chosen': -0.02434016764163971, 'epoch': 3.26}


 54%|█████▍    | 8758/16104 [40:16:11<35:20:37, 17.32s/it]

 54%|█████▍    | 8759/16104 [40:16:23<32:00:35, 15.69s/it]

 54%|█████▍    | 8760/16104 [40:16:39<32:13:44, 15.80s/it]
{'loss': 0.2886, 'learning_rate': 9.064123071049916e-07, 'rewards/chosen': -1.1959497928619385, 'rewards/rejected': -3.224802017211914, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0288522243499756, 'policy_logps/rejected': -385.6246337890625, 'policy_logps/chosen': -404.7413024902344, 'referece_logps/rejected': -353.37664794921875, 'referece_logps/chosen': -392.78179931640625, 'logits/rejected': -0.3507176637649536, 'logits/chosen': -0.19470003247261047, 'epoch': 3.26}

 54%|█████▍    | 8761/16104 [40:16:52<30:51:09, 15.13s/it]


 54%|█████▍    | 8763/16104 [40:17:19<28:57:30, 14.20s/it]

 54%|█████▍    | 8764/16104 [40:17:39<32:22:45, 15.88s/it]

 54%|█████▍    | 8765/16104 [40:17:50<29:48:30, 14.62s/it]
{'loss': 0.3005, 'learning_rate': 9.054111368207198e-07, 'rewards/chosen': -1.548439860343933, 'rewards/rejected': -2.6876397132873535, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1391996145248413, 'policy_logps/rejected': -322.04644775390625, 'policy_logps/chosen': -303.7643737792969, 'referece_logps/rejected': -295.16998291015625, 'referece_logps/chosen': -288.27996826171875, 'logits/rejected': 0.0752016231417656, 'logits/chosen': 0.14039947092533112, 'epoch': 3.27}

 54%|█████▍    | 8766/16104 [40:18:02<27:53:52, 13.69s/it]

 54%|█████▍    | 8767/16104 [40:18:21<31:19:08, 15.37s/it]

 54%|█████▍    | 8768/16104 [40:18:41<34:13:47, 16.80s/it]

 54%|█████▍    | 8769/16104 [40:18:53<31:15:31, 15.34s/it]


 54%|█████▍    | 8771/16104 [40:19:25<31:35:36, 15.51s/it]

 54%|█████▍    | 8772/16104 [40:19:37<29:31:53, 14.50s/it]

 54%|█████▍    | 8773/16104 [40:19:59<33:45:14, 16.58s/it]

 54%|█████▍    | 8774/16104 [40:20:19<35:50:59, 17.61s/it]
{'loss': 0.3059, 'learning_rate': 9.036092720454977e-07, 'rewards/chosen': -1.790391445159912, 'rewards/rejected': -3.991722822189331, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2013309001922607, 'policy_logps/rejected': -456.5465087890625, 'policy_logps/chosen': -445.7693786621094, 'referece_logps/rejected': -416.6292724609375, 'referece_logps/chosen': -427.865478515625, 'logits/rejected': 0.06786160171031952, 'logits/chosen': 0.3034738302230835, 'epoch': 3.27}

 54%|█████▍    | 8775/16104 [40:20:38<37:08:28, 18.24s/it]


 55%|█████▍    | 8777/16104 [40:21:09<33:45:12, 16.58s/it]

 55%|█████▍    | 8778/16104 [40:21:29<35:39:14, 17.52s/it]

 55%|█████▍    | 8779/16104 [40:21:45<34:54:12, 17.15s/it]

 55%|█████▍    | 8780/16104 [40:22:05<36:23:02, 17.88s/it]

 55%|█████▍    | 8781/16104 [40:22:25<37:34:17, 18.47s/it]
{'loss': 0.3546, 'learning_rate': 9.02208039716304e-07, 'rewards/chosen': -2.528104782104492, 'rewards/rejected': -4.491416931152344, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9633119106292725, 'policy_logps/rejected': -398.71002197265625, 'policy_logps/chosen': -502.9832763671875, 'referece_logps/rejected': -353.7958984375, 'referece_logps/chosen': -477.7022399902344, 'logits/rejected': 0.4791317880153656, 'logits/chosen': 0.4042988419532776, 'epoch': 3.27}

 55%|█████▍    | 8782/16104 [40:22:42<36:45:05, 18.07s/it]

 55%|█████▍    | 8783/16104 [40:22:58<35:16:39, 17.35s/it]


 55%|█████▍    | 8785/16104 [40:23:33<35:54:00, 17.66s/it]
{'loss': 0.2272, 'learning_rate': 9.014074223789549e-07, 'rewards/chosen': -1.6465880870819092, 'rewards/rejected': -4.078892707824707, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4323043823242188, 'policy_logps/rejected': -256.16619873046875, 'policy_logps/chosen': -302.0221862792969, 'referece_logps/rejected': -215.37728881835938, 'referece_logps/chosen': -285.5563049316406, 'logits/rejected': -0.2816188335418701, 'logits/chosen': -0.28321486711502075, 'epoch': 3.27}

 55%|█████▍    | 8786/16104 [40:23:45<32:04:46, 15.78s/it]


 55%|█████▍    | 8788/16104 [40:24:17<32:58:45, 16.23s/it]
{'loss': 0.293, 'learning_rate': 9.008070012241843e-07, 'rewards/chosen': -1.5193235874176025, 'rewards/rejected': -3.6201963424682617, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1008729934692383, 'policy_logps/rejected': -427.3450927734375, 'policy_logps/chosen': -497.03790283203125, 'referece_logps/rejected': -391.14312744140625, 'referece_logps/chosen': -481.8446350097656, 'logits/rejected': -0.43909573554992676, 'logits/chosen': -0.4607890844345093, 'epoch': 3.27}

 55%|█████▍    | 8789/16104 [40:24:37<35:01:28, 17.24s/it]

 55%|█████▍    | 8790/16104 [40:24:53<34:23:23, 16.93s/it]

 55%|█████▍    | 8791/16104 [40:25:08<33:26:47, 16.46s/it]

 55%|█████▍    | 8792/16104 [40:25:31<36:53:51, 18.17s/it]

 55%|█████▍    | 8793/16104 [40:25:48<36:33:19, 18.00s/it]

 55%|█████▍    | 8794/16104 [40:26:04<35:29:06, 17.48s/it]

 55%|█████▍    | 8795/16104 [40:26:26<38:09:05, 18.79s/it]

 55%|█████▍    | 8796/16104 [40:26:45<38:13:30, 18.83s/it]

 55%|█████▍    | 8797/16104 [40:26:57<33:42:42, 16.61s/it]

 55%|█████▍    | 8798/16104 [40:27:12<33:06:39, 16.32s/it]

 55%|█████▍    | 8799/16104 [40:27:23<29:50:38, 14.71s/it]

 55%|█████▍    | 8800/16104 [40:27:38<29:48:30, 14.69s/it]

 55%|█████▍    | 8801/16104 [40:27:57<32:46:51, 16.16s/it]

 55%|█████▍    | 8802/16104 [40:28:08<29:26:15, 14.51s/it]

 55%|█████▍    | 8803/16104 [40:28:19<27:05:50, 13.36s/it]

 55%|█████▍    | 8804/16104 [40:28:34<28:32:04, 14.07s/it]

 55%|█████▍    | 8805/16104 [40:28:49<29:01:37, 14.32s/it]


 55%|█████▍    | 8807/16104 [40:29:28<33:57:30, 16.75s/it]

 55%|█████▍    | 8808/16104 [40:29:48<35:50:22, 17.68s/it]
{'loss': 0.4036, 'learning_rate': 8.968051269589161e-07, 'rewards/chosen': -1.2168546915054321, 'rewards/rejected': -2.7901954650878906, 'rewards/accuracies': 0.875, 'rewards/margins': 1.573340654373169, 'policy_logps/rejected': -594.9049072265625, 'policy_logps/chosen': -567.1912841796875, 'referece_logps/rejected': -567.0029296875, 'referece_logps/chosen': -555.0227661132812, 'logits/rejected': -0.4556119441986084, 'logits/chosen': -0.4351569414138794, 'epoch': 3.28}

 55%|█████▍    | 8809/16104 [40:30:04<35:02:12, 17.29s/it]

 55%|█████▍    | 8810/16104 [40:30:19<33:40:25, 16.62s/it]

 55%|█████▍    | 8811/16104 [40:30:42<37:14:59, 18.39s/it]


 55%|█████▍    | 8813/16104 [40:31:24<40:15:10, 19.88s/it]

 55%|█████▍    | 8814/16104 [40:31:42<39:06:25, 19.31s/it]
{'loss': 0.2376, 'learning_rate': 8.95604887337837e-07, 'rewards/chosen': -1.6745742559432983, 'rewards/rejected': -3.48272705078125, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8081527948379517, 'policy_logps/rejected': -385.24835205078125, 'policy_logps/chosen': -412.09649658203125, 'referece_logps/rejected': -350.4210510253906, 'referece_logps/chosen': -395.35076904296875, 'logits/rejected': 0.43182989954948425, 'logits/chosen': 0.4119659960269928, 'epoch': 3.28}

 55%|█████▍    | 8815/16104 [40:31:58<36:57:17, 18.25s/it]

 55%|█████▍    | 8816/16104 [40:32:13<35:08:03, 17.36s/it]

 55%|█████▍    | 8817/16104 [40:32:34<37:12:56, 18.39s/it]

 55%|█████▍    | 8818/16104 [40:32:45<33:10:30, 16.39s/it]

 55%|█████▍    | 8819/16104 [40:33:06<35:24:09, 17.49s/it]

 55%|█████▍    | 8820/16104 [40:33:25<36:49:43, 18.20s/it]

 55%|█████▍    | 8821/16104 [40:33:39<33:53:29, 16.75s/it]

 55%|█████▍    | 8822/16104 [40:33:51<31:12:36, 15.43s/it]

 55%|█████▍    | 8823/16104 [40:34:11<33:57:28, 16.79s/it]

 55%|█████▍    | 8824/16104 [40:34:32<36:38:54, 18.12s/it]

 55%|█████▍    | 8825/16104 [40:34:47<34:33:14, 17.09s/it]

 55%|█████▍    | 8826/16104 [40:34:58<30:44:40, 15.21s/it]

 55%|█████▍    | 8827/16104 [40:35:13<30:29:34, 15.09s/it]

 55%|█████▍    | 8828/16104 [40:35:31<32:29:28, 16.08s/it]

 55%|█████▍    | 8829/16104 [40:35:49<33:57:58, 16.81s/it]

 55%|█████▍    | 8830/16104 [40:36:12<37:16:57, 18.45s/it]

 55%|█████▍    | 8831/16104 [40:36:24<33:46:17, 16.72s/it]

 55%|█████▍    | 8832/16104 [40:36:43<35:08:20, 17.40s/it]


 55%|█████▍    | 8834/16104 [40:37:14<32:26:10, 16.06s/it]

 55%|█████▍    | 8835/16104 [40:37:34<34:45:48, 17.22s/it]

 55%|█████▍    | 8836/16104 [40:37:50<34:03:13, 16.87s/it]
{'loss': 0.4158, 'learning_rate': 8.912053226914061e-07, 'rewards/chosen': -2.6723570823669434, 'rewards/rejected': -3.5141851902008057, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8418279886245728, 'policy_logps/rejected': -438.18426513671875, 'policy_logps/chosen': -352.0479736328125, 'referece_logps/rejected': -403.0423889160156, 'referece_logps/chosen': -325.3243713378906, 'logits/rejected': -0.08110029250383377, 'logits/chosen': -0.0063415467739105225, 'epoch': 3.29}

 55%|█████▍    | 8837/16104 [40:38:11<36:22:22, 18.02s/it]

 55%|█████▍    | 8838/16104 [40:38:24<33:07:40, 16.41s/it]

 55%|█████▍    | 8839/16104 [40:38:42<34:17:30, 16.99s/it]

 55%|█████▍    | 8840/16104 [40:38:58<33:48:37, 16.76s/it]

 55%|█████▍    | 8841/16104 [40:39:18<35:32:28, 17.62s/it]


 55%|█████▍    | 8843/16104 [40:39:55<35:38:02, 17.67s/it]

 55%|█████▍    | 8844/16104 [40:40:13<36:24:04, 18.05s/it]

 55%|█████▍    | 8845/16104 [40:40:27<33:36:14, 16.67s/it]

 55%|█████▍    | 8846/16104 [40:40:38<30:30:21, 15.13s/it]

 55%|█████▍    | 8847/16104 [40:40:52<29:48:22, 14.79s/it]

 55%|█████▍    | 8848/16104 [40:41:14<33:45:28, 16.75s/it]

 55%|█████▍    | 8849/16104 [40:41:33<35:13:50, 17.48s/it]

 55%|█████▍    | 8850/16104 [40:41:44<31:06:21, 15.44s/it]

 55%|█████▍    | 8851/16104 [40:42:02<32:41:51, 16.23s/it]

 55%|█████▍    | 8852/16104 [40:42:20<33:41:29, 16.73s/it]

 55%|█████▍    | 8853/16104 [40:42:38<34:43:21, 17.24s/it]

 55%|█████▍    | 8854/16104 [40:42:52<32:47:53, 16.29s/it]

 55%|█████▍    | 8855/16104 [40:43:04<30:23:36, 15.09s/it]

 55%|█████▍    | 8856/16104 [40:43:22<32:05:14, 15.94s/it]

 55%|█████▍    | 8857/16104 [40:43:40<33:07:35, 16.46s/it]

 55%|█████▌    | 8858/16104 [40:43:57<33:16:53, 16.54s/it]

 55%|█████▌    | 8859/16104 [40:44:17<35:32:44, 17.66s/it]

 55%|█████▌    | 8860/16104 [40:44:33<34:39:30, 17.22s/it]

 55%|█████▌    | 8861/16104 [40:44:45<31:30:16, 15.66s/it]

 55%|█████▌    | 8862/16104 [40:45:04<33:37:01, 16.71s/it]

 55%|█████▌    | 8863/16104 [40:45:23<34:48:16, 17.30s/it]

 55%|█████▌    | 8864/16104 [40:45:39<34:01:23, 16.92s/it]

 55%|█████▌    | 8865/16104 [40:45:56<33:50:57, 16.83s/it]

 55%|█████▌    | 8866/16104 [40:46:16<35:39:41, 17.74s/it]

 55%|█████▌    | 8867/16104 [40:46:34<36:11:50, 18.01s/it]

 55%|█████▌    | 8868/16104 [40:46:48<33:51:32, 16.85s/it]

 55%|█████▌    | 8869/16104 [40:46:59<30:20:02, 15.09s/it]

 55%|█████▌    | 8870/16104 [40:47:11<28:03:23, 13.96s/it]

 55%|█████▌    | 8871/16104 [40:47:22<26:27:44, 13.17s/it]

 55%|█████▌    | 8872/16104 [40:47:42<30:26:01, 15.15s/it]

 55%|█████▌    | 8873/16104 [40:47:52<27:45:57, 13.82s/it]

 55%|█████▌    | 8874/16104 [40:48:12<31:06:26, 15.49s/it]

 55%|█████▌    | 8875/16104 [40:48:31<33:09:00, 16.51s/it]

 55%|█████▌    | 8876/16104 [40:48:50<35:03:08, 17.46s/it]

 55%|█████▌    | 8877/16104 [40:49:02<31:29:02, 15.68s/it]

 55%|█████▌    | 8878/16104 [40:49:20<33:07:06, 16.50s/it]

 55%|█████▌    | 8879/16104 [40:49:40<35:11:37, 17.54s/it]

 55%|█████▌    | 8880/16104 [40:49:51<31:19:09, 15.61s/it]

 55%|█████▌    | 8881/16104 [40:50:04<29:23:42, 14.65s/it]

 55%|█████▌    | 8882/16104 [40:50:19<29:36:47, 14.76s/it]

 55%|█████▌    | 8883/16104 [40:50:31<27:55:47, 13.92s/it]

 55%|█████▌    | 8884/16104 [40:50:50<31:19:45, 15.62s/it]

 55%|█████▌    | 8885/16104 [40:51:01<28:20:38, 14.13s/it]

 55%|█████▌    | 8886/16104 [40:51:12<26:16:21, 13.10s/it]

 55%|█████▌    | 8887/16104 [40:51:24<25:28:12, 12.71s/it]

 55%|█████▌    | 8888/16104 [40:51:34<24:12:44, 12.08s/it]

 55%|█████▌    | 8889/16104 [40:51:46<23:57:46, 11.96s/it]

 55%|█████▌    | 8890/16104 [40:52:01<25:38:22, 12.79s/it]

 55%|█████▌    | 8891/16104 [40:52:20<29:18:34, 14.63s/it]

 55%|█████▌    | 8892/16104 [40:52:38<31:27:15, 15.70s/it]

 55%|█████▌    | 8893/16104 [40:52:50<29:11:10, 14.57s/it]

 55%|█████▌    | 8894/16104 [40:53:02<28:02:07, 14.00s/it]

 55%|█████▌    | 8895/16104 [40:53:24<32:57:16, 16.46s/it]

 55%|█████▌    | 8896/16104 [40:53:44<34:32:23, 17.25s/it]

 55%|█████▌    | 8897/16104 [40:54:02<35:20:04, 17.65s/it]

 55%|█████▌    | 8898/16104 [40:54:22<36:32:03, 18.25s/it]

 55%|█████▌    | 8899/16104 [40:54:42<37:30:28, 18.74s/it]

 55%|█████▌    | 8900/16104 [40:55:03<39:01:06, 19.50s/it]

 55%|█████▌    | 8901/16104 [40:55:19<37:00:39, 18.50s/it]

 55%|█████▌    | 8902/16104 [40:55:39<37:49:14, 18.91s/it]

 55%|█████▌    | 8903/16104 [40:55:54<35:29:10, 17.74s/it]
{'loss': 0.3416, 'learning_rate': 8.778201314804916e-07, 'rewards/chosen': -1.4302383661270142, 'rewards/rejected': -3.048637628555298, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6183993816375732, 'policy_logps/rejected': -397.1846923828125, 'policy_logps/chosen': -357.7330627441406, 'referece_logps/rejected': -366.6982727050781, 'referece_logps/chosen': -343.4306945800781, 'logits/rejected': -0.6827771067619324, 'logits/chosen': -0.6408376693725586, 'epoch': 3.32}


 55%|█████▌    | 8905/16104 [40:56:27<33:14:12, 16.62s/it]
{'loss': 0.4249, 'learning_rate': 8.774209024820935e-07, 'rewards/chosen': -1.3959324359893799, 'rewards/rejected': -3.50921368598938, 'rewards/accuracies': 1.0, 'rewards/margins': 2.11328125, 'policy_logps/rejected': -500.3561706542969, 'policy_logps/chosen': -425.33355712890625, 'referece_logps/rejected': -465.2640075683594, 'referece_logps/chosen': -411.3742370605469, 'logits/rejected': 0.06857161223888397, 'logits/chosen': 0.283382773399353, 'epoch': 3.32}


 55%|█████▌    | 8907/16104 [40:56:50<28:14:51, 14.13s/it]
{'loss': 0.4125, 'learning_rate': 8.77021693317868e-07, 'rewards/chosen': -1.6139720678329468, 'rewards/rejected': -3.347139358520508, 'rewards/accuracies': 0.875, 'rewards/margins': 1.733167052268982, 'policy_logps/rejected': -440.9353332519531, 'policy_logps/chosen': -373.5152587890625, 'referece_logps/rejected': -407.46392822265625, 'referece_logps/chosen': -357.37554931640625, 'logits/rejected': -1.533634066581726, 'logits/chosen': -1.5337650775909424, 'epoch': 3.32}


 55%|█████▌    | 8909/16104 [40:57:24<31:30:06, 15.76s/it]

 55%|█████▌    | 8910/16104 [40:57:45<34:34:55, 17.31s/it]
{'loss': 0.3001, 'learning_rate': 8.764229169019046e-07, 'rewards/chosen': -0.939978837966919, 'rewards/rejected': -3.4423065185546875, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5023274421691895, 'policy_logps/rejected': -401.1445007324219, 'policy_logps/chosen': -439.3883972167969, 'referece_logps/rejected': -366.7214660644531, 'referece_logps/chosen': -429.98858642578125, 'logits/rejected': 0.28143835067749023, 'logits/chosen': 0.33406737446784973, 'epoch': 3.32}


 55%|█████▌    | 8912/16104 [40:58:25<36:49:49, 18.44s/it]

 55%|█████▌    | 8913/16104 [40:58:36<32:18:10, 16.17s/it]

 55%|█████▌    | 8914/16104 [40:58:50<31:25:53, 15.74s/it]

 55%|█████▌    | 8915/16104 [40:59:03<29:30:25, 14.78s/it]

 55%|█████▌    | 8916/16104 [40:59:19<30:10:10, 15.11s/it]

 55%|█████▌    | 8917/16104 [40:59:32<29:14:54, 14.65s/it]

 55%|█████▌    | 8918/16104 [40:59:50<31:00:36, 15.54s/it]

 55%|█████▌    | 8919/16104 [41:00:12<34:52:13, 17.47s/it]

 55%|█████▌    | 8920/16104 [41:00:30<35:29:07, 17.78s/it]

 55%|█████▌    | 8921/16104 [41:00:44<32:55:16, 16.50s/it]

 55%|█████▌    | 8922/16104 [41:01:04<34:48:33, 17.45s/it]

 55%|█████▌    | 8923/16104 [41:01:22<35:10:08, 17.63s/it]
{'loss': 0.2664, 'learning_rate': 8.738287417849921e-07, 'rewards/chosen': -2.2869815826416016, 'rewards/rejected': -3.148181200027466, 'rewards/accuracies': 0.75, 'rewards/margins': 0.861199676990509, 'policy_logps/rejected': -435.3116455078125, 'policy_logps/chosen': -335.7893371582031, 'referece_logps/rejected': -403.8298034667969, 'referece_logps/chosen': -312.9195251464844, 'logits/rejected': -0.3516392409801483, 'logits/chosen': -0.17450270056724548, 'epoch': 3.32}

 55%|█████▌    | 8924/16104 [41:01:34<32:08:27, 16.12s/it]


 55%|█████▌    | 8926/16104 [41:01:59<28:02:19, 14.06s/it]

 55%|█████▌    | 8927/16104 [41:02:19<31:20:21, 15.72s/it]

 55%|█████▌    | 8928/16104 [41:02:31<29:30:58, 14.81s/it]

 55%|█████▌    | 8929/16104 [41:02:51<32:31:57, 16.32s/it]

 55%|█████▌    | 8930/16104 [41:03:12<35:06:32, 17.62s/it]
{'loss': 0.43, 'learning_rate': 8.724322344001022e-07, 'rewards/chosen': -2.5241177082061768, 'rewards/rejected': -3.95978045463562, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4356627464294434, 'policy_logps/rejected': -318.6410217285156, 'policy_logps/chosen': -319.7982482910156, 'referece_logps/rejected': -279.043212890625, 'referece_logps/chosen': -294.5570373535156, 'logits/rejected': -0.7263317704200745, 'logits/chosen': -0.9190788269042969, 'epoch': 3.33}


 55%|█████▌    | 8932/16104 [41:03:46<35:07:20, 17.63s/it]

 55%|█████▌    | 8933/16104 [41:04:07<37:04:10, 18.61s/it]

 55%|█████▌    | 8934/16104 [41:04:24<36:13:05, 18.18s/it]

 55%|█████▌    | 8935/16104 [41:04:44<37:01:39, 18.59s/it]

 55%|█████▌    | 8936/16104 [41:05:02<36:57:29, 18.56s/it]

 55%|█████▌    | 8937/16104 [41:05:15<33:49:16, 16.99s/it]

 56%|█████▌    | 8938/16104 [41:05:37<36:27:00, 18.31s/it]

 56%|█████▌    | 8939/16104 [41:05:49<32:37:53, 16.40s/it]

 56%|█████▌    | 8940/16104 [41:06:01<30:18:18, 15.23s/it]
{'loss': 0.2913, 'learning_rate': 8.70437663165266e-07, 'rewards/chosen': -1.429248571395874, 'rewards/rejected': -3.414182186126709, 'rewards/accuracies': 0.875, 'rewards/margins': 1.984933614730835, 'policy_logps/rejected': -400.317138671875, 'policy_logps/chosen': -330.2039794921875, 'referece_logps/rejected': -366.17529296875, 'referece_logps/chosen': -315.91143798828125, 'logits/rejected': -0.02364906668663025, 'logits/chosen': 0.17197713255882263, 'epoch': 3.33}


 56%|█████▌    | 8942/16104 [41:06:40<34:28:55, 17.33s/it]

 56%|█████▌    | 8943/16104 [41:06:59<35:41:41, 17.94s/it]
{'loss': 0.3008, 'learning_rate': 8.698393936277653e-07, 'rewards/chosen': -2.3862643241882324, 'rewards/rejected': -4.706989765167236, 'rewards/accuracies': 0.875, 'rewards/margins': 2.320725440979004, 'policy_logps/rejected': -313.4907531738281, 'policy_logps/chosen': -330.6219482421875, 'referece_logps/rejected': -266.42083740234375, 'referece_logps/chosen': -306.7593078613281, 'logits/rejected': -0.6936541199684143, 'logits/chosen': -0.833636462688446, 'epoch': 3.33}


 56%|█████▌    | 8945/16104 [41:07:40<37:52:05, 19.04s/it]

 56%|█████▌    | 8946/16104 [41:08:00<38:40:04, 19.45s/it]

 56%|█████▌    | 8947/16104 [41:08:18<37:27:22, 18.84s/it]

 56%|█████▌    | 8948/16104 [41:08:29<33:17:59, 16.75s/it]

 56%|█████▌    | 8949/16104 [41:08:49<35:06:58, 17.67s/it]

 56%|█████▌    | 8950/16104 [41:09:09<36:34:12, 18.40s/it]
{'loss': 0.2558, 'learning_rate': 8.684436160330282e-07, 'rewards/chosen': -1.8236898183822632, 'rewards/rejected': -5.238409042358398, 'rewards/accuracies': 1.0, 'rewards/margins': 3.4147191047668457, 'policy_logps/rejected': -403.578125, 'policy_logps/chosen': -405.59521484375, 'referece_logps/rejected': -351.19403076171875, 'referece_logps/chosen': -387.35833740234375, 'logits/rejected': -0.38365399837493896, 'logits/chosen': -0.3592779338359833, 'epoch': 3.33}


 56%|█████▌    | 8952/16104 [41:09:44<35:42:12, 17.97s/it]

 56%|█████▌    | 8953/16104 [41:10:02<36:06:27, 18.18s/it]

 56%|█████▌    | 8954/16104 [41:10:22<37:01:47, 18.64s/it]

 56%|█████▌    | 8955/16104 [41:10:42<37:47:37, 19.03s/it]
{'loss': 0.3203, 'learning_rate': 8.674467915261775e-07, 'rewards/chosen': -1.5655364990234375, 'rewards/rejected': -3.803856611251831, 'rewards/accuracies': 0.625, 'rewards/margins': 2.2383198738098145, 'policy_logps/rejected': -475.66748046875, 'policy_logps/chosen': -497.34906005859375, 'referece_logps/rejected': -437.62890625, 'referece_logps/chosen': -481.69366455078125, 'logits/rejected': -0.9832473993301392, 'logits/chosen': -1.0615140199661255, 'epoch': 3.34}


 56%|█████▌    | 8957/16104 [41:11:13<34:20:53, 17.30s/it]

 56%|█████▌    | 8958/16104 [41:11:34<36:15:19, 18.26s/it]

 56%|█████▌    | 8959/16104 [41:11:52<36:19:15, 18.30s/it]

 56%|█████▌    | 8960/16104 [41:12:12<37:21:25, 18.82s/it]
{'loss': 0.3486, 'learning_rate': 8.664501010696618e-07, 'rewards/chosen': -1.3784127235412598, 'rewards/rejected': -3.7915616035461426, 'rewards/accuracies': 0.875, 'rewards/margins': 2.413148880004883, 'policy_logps/rejected': -411.0340576171875, 'policy_logps/chosen': -327.7369689941406, 'referece_logps/rejected': -373.1184387207031, 'referece_logps/chosen': -313.9528503417969, 'logits/rejected': -0.45181503891944885, 'logits/chosen': -0.38735172152519226, 'epoch': 3.34}


 56%|█████▌    | 8962/16104 [41:12:44<34:04:22, 17.17s/it]

 56%|█████▌    | 8963/16104 [41:13:02<34:46:28, 17.53s/it]

 56%|█████▌    | 8964/16104 [41:13:14<31:47:59, 16.03s/it]

 56%|█████▌    | 8965/16104 [41:13:30<31:22:30, 15.82s/it]

 56%|█████▌    | 8966/16104 [41:13:45<31:08:03, 15.70s/it]

 56%|█████▌    | 8967/16104 [41:14:03<32:37:36, 16.46s/it]

 56%|█████▌    | 8968/16104 [41:14:25<35:21:38, 17.84s/it]

 56%|█████▌    | 8969/16104 [41:14:44<36:23:57, 18.37s/it]

 56%|█████▌    | 8970/16104 [41:15:04<37:09:32, 18.75s/it]

 56%|█████▌    | 8971/16104 [41:15:23<37:40:01, 19.01s/it]
{'loss': 0.3021, 'learning_rate': 8.64257858889469e-07, 'rewards/chosen': -1.2070167064666748, 'rewards/rejected': -3.6467440128326416, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4397270679473877, 'policy_logps/rejected': -473.9566650390625, 'policy_logps/chosen': -432.73602294921875, 'referece_logps/rejected': -437.4892578125, 'referece_logps/chosen': -420.66583251953125, 'logits/rejected': -0.12633398175239563, 'logits/chosen': -0.09678965061903, 'epoch': 3.34}


 56%|█████▌    | 8973/16104 [41:16:03<38:23:59, 19.39s/it]

 56%|█████▌    | 8974/16104 [41:16:20<37:01:57, 18.70s/it]

 56%|█████▌    | 8975/16104 [41:16:40<37:41:55, 19.04s/it]

 56%|█████▌    | 8976/16104 [41:17:00<38:16:58, 19.33s/it]

 56%|█████▌    | 8977/16104 [41:17:16<36:29:44, 18.43s/it]

 56%|█████▌    | 8978/16104 [41:17:33<35:29:17, 17.93s/it]

 56%|█████▌    | 8979/16104 [41:17:51<35:30:04, 17.94s/it]
{'loss': 0.2768, 'learning_rate': 8.626639176443964e-07, 'rewards/chosen': -1.9307482242584229, 'rewards/rejected': -3.5810136795043945, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6502655744552612, 'policy_logps/rejected': -302.2445983886719, 'policy_logps/chosen': -325.81561279296875, 'referece_logps/rejected': -266.4344787597656, 'referece_logps/chosen': -306.50811767578125, 'logits/rejected': -0.7805371284484863, 'logits/chosen': -0.6921949982643127, 'epoch': 3.35}


 56%|█████▌    | 8981/16104 [41:18:22<32:09:49, 16.26s/it]

 56%|█████▌    | 8982/16104 [41:18:41<33:54:57, 17.14s/it]

 56%|█████▌    | 8983/16104 [41:18:52<30:06:34, 15.22s/it]

 56%|█████▌    | 8984/16104 [41:19:08<30:53:53, 15.62s/it]

 56%|█████▌    | 8985/16104 [41:19:28<33:14:48, 16.81s/it]
{'loss': 0.3828, 'learning_rate': 8.614686948154679e-07, 'rewards/chosen': -1.8768314123153687, 'rewards/rejected': -2.929178476333618, 'rewards/accuracies': 0.625, 'rewards/margins': 1.052347183227539, 'policy_logps/rejected': -350.52392578125, 'policy_logps/chosen': -271.57647705078125, 'referece_logps/rejected': -321.2321472167969, 'referece_logps/chosen': -252.8081817626953, 'logits/rejected': -0.9191532731056213, 'logits/chosen': -0.6987176537513733, 'epoch': 3.35}

 56%|█████▌    | 8986/16104 [41:19:45<33:42:00, 17.04s/it]


 56%|█████▌    | 8988/16104 [41:20:22<34:45:08, 17.58s/it]

 56%|█████▌    | 8989/16104 [41:20:35<31:43:00, 16.05s/it]

 56%|█████▌    | 8990/16104 [41:20:54<33:50:45, 17.13s/it]
{'loss': 0.3698, 'learning_rate': 8.604728298230443e-07, 'rewards/chosen': -2.0761730670928955, 'rewards/rejected': -3.9693872928619385, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8932139873504639, 'policy_logps/rejected': -555.0838623046875, 'policy_logps/chosen': -431.9465637207031, 'referece_logps/rejected': -515.3899536132812, 'referece_logps/chosen': -411.18487548828125, 'logits/rejected': -0.44771358370780945, 'logits/chosen': -0.2504783868789673, 'epoch': 3.35}


 56%|█████▌    | 8992/16104 [41:21:25<31:28:50, 15.94s/it]

 56%|█████▌    | 8993/16104 [41:21:40<31:12:32, 15.80s/it]

 56%|█████▌    | 8994/16104 [41:21:53<29:34:00, 14.97s/it]

 56%|█████▌    | 8995/16104 [41:22:06<28:19:43, 14.35s/it]
{'loss': 0.4316, 'learning_rate': 8.59477105933684e-07, 'rewards/chosen': -1.1650457382202148, 'rewards/rejected': -2.894243001937866, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7291969060897827, 'policy_logps/rejected': -286.60748291015625, 'policy_logps/chosen': -364.42681884765625, 'referece_logps/rejected': -257.6650390625, 'referece_logps/chosen': -352.7763671875, 'logits/rejected': -0.5887106657028198, 'logits/chosen': -0.6562942266464233, 'epoch': 3.35}


 56%|█████▌    | 8997/16104 [41:22:39<30:17:11, 15.34s/it]

 56%|█████▌    | 8998/16104 [41:22:57<31:43:39, 16.07s/it]

 56%|█████▌    | 8999/16104 [41:23:13<31:41:45, 16.06s/it]

 56%|█████▌    | 9000/16104 [41:23:33<33:50:53, 17.15s/it]
{'loss': 0.3962, 'learning_rate': 8.584815241543586e-07, 'rewards/chosen': -1.7438700199127197, 'rewards/rejected': -3.7052688598632812, 'rewards/accuracies': 0.875, 'rewards/margins': 1.961398720741272, 'policy_logps/rejected': -522.0418701171875, 'policy_logps/chosen': -370.3987121582031, 'referece_logps/rejected': -484.9891662597656, 'referece_logps/chosen': -352.96002197265625, 'logits/rejected': -0.8711752891540527, 'logits/chosen': -0.7577207684516907, 'epoch': 3.35}


 56%|█████▌    | 9002/16104 [41:24:26<42:16:58, 21.43s/it]
{'loss': 0.3024, 'learning_rate': 8.58083331458972e-07, 'rewards/chosen': -1.9466800689697266, 'rewards/rejected': -2.4548463821411133, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5081664323806763, 'policy_logps/rejected': -437.16387939453125, 'policy_logps/chosen': -434.69244384765625, 'referece_logps/rejected': -412.6153564453125, 'referece_logps/chosen': -415.2256774902344, 'logits/rejected': 0.024826765060424805, 'logits/chosen': -0.035542964935302734, 'epoch': 3.35}


 56%|█████▌    | 9004/16104 [41:24:59<38:03:51, 19.30s/it]

 56%|█████▌    | 9005/16104 [41:25:14<35:20:26, 17.92s/it]

 56%|█████▌    | 9006/16104 [41:25:31<34:48:09, 17.65s/it]
{'loss': 0.3962, 'learning_rate': 8.572870150220143e-07, 'rewards/chosen': -1.0472265481948853, 'rewards/rejected': -2.1922786235809326, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1450523138046265, 'policy_logps/rejected': -476.64337158203125, 'policy_logps/chosen': -407.39862060546875, 'referece_logps/rejected': -454.7205810546875, 'referece_logps/chosen': -396.92633056640625, 'logits/rejected': -0.6996715068817139, 'logits/chosen': -0.8129353523254395, 'epoch': 3.36}


 56%|█████▌    | 9008/16104 [41:25:57<30:38:06, 15.54s/it]

 56%|█████▌    | 9009/16104 [41:26:11<29:33:21, 15.00s/it]

 56%|█████▌    | 9010/16104 [41:26:31<32:14:53, 16.37s/it]

 56%|█████▌    | 9011/16104 [41:26:45<30:57:49, 15.72s/it]

 56%|█████▌    | 9012/16104 [41:27:05<33:43:50, 17.12s/it]

 56%|█████▌    | 9013/16104 [41:27:25<35:17:45, 17.92s/it]

 56%|█████▌    | 9014/16104 [41:27:41<34:11:08, 17.36s/it]

 56%|█████▌    | 9015/16104 [41:28:01<35:35:34, 18.08s/it]
{'loss': 0.2124, 'learning_rate': 8.554956415441262e-07, 'rewards/chosen': -1.7542892694473267, 'rewards/rejected': -4.000090599060059, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2458012104034424, 'policy_logps/rejected': -409.4902038574219, 'policy_logps/chosen': -338.0614013671875, 'referece_logps/rejected': -369.48931884765625, 'referece_logps/chosen': -320.5185241699219, 'logits/rejected': -0.3973511755466461, 'logits/chosen': -0.32411909103393555, 'epoch': 3.36}


 56%|█████▌    | 9017/16104 [41:28:27<30:22:22, 15.43s/it]

 56%|█████▌    | 9018/16104 [41:28:43<30:59:06, 15.74s/it]

 56%|█████▌    | 9019/16104 [41:28:55<28:42:15, 14.59s/it]

 56%|█████▌    | 9020/16104 [41:29:13<30:51:40, 15.68s/it]
{'loss': 0.3186, 'learning_rate': 8.545006382717485e-07, 'rewards/chosen': -2.483529806137085, 'rewards/rejected': -3.870948553085327, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3874188661575317, 'policy_logps/rejected': -342.4512939453125, 'policy_logps/chosen': -351.6038513183594, 'referece_logps/rejected': -303.7418212890625, 'referece_logps/chosen': -326.7685546875, 'logits/rejected': -0.05911216884851456, 'logits/chosen': -0.034170906990766525, 'epoch': 3.36}


 56%|█████▌    | 9022/16104 [41:29:51<34:29:21, 17.53s/it]

 56%|█████▌    | 9023/16104 [41:30:05<32:33:59, 16.56s/it]
{'loss': 0.3934, 'learning_rate': 8.539037068724296e-07, 'rewards/chosen': -1.5530133247375488, 'rewards/rejected': -1.8300373554229736, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2770240902900696, 'policy_logps/rejected': -350.6646728515625, 'policy_logps/chosen': -444.78692626953125, 'referece_logps/rejected': -332.36431884765625, 'referece_logps/chosen': -429.2568359375, 'logits/rejected': -0.3802908658981323, 'logits/chosen': -0.4114229679107666, 'epoch': 3.36}


 56%|█████▌    | 9025/16104 [41:30:33<29:30:43, 15.01s/it]
{'loss': 0.4253, 'learning_rate': 8.535057821420801e-07, 'rewards/chosen': -1.5612646341323853, 'rewards/rejected': -3.109457015991211, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5481925010681152, 'policy_logps/rejected': -354.4801025390625, 'policy_logps/chosen': -365.7912902832031, 'referece_logps/rejected': -323.38555908203125, 'referece_logps/chosen': -350.1786804199219, 'logits/rejected': -0.5027337074279785, 'logits/chosen': -0.6033504009246826, 'epoch': 3.36}

 56%|█████▌    | 9026/16104 [41:30:44<26:58:33, 13.72s/it]


 56%|█████▌    | 9028/16104 [41:31:05<23:58:05, 12.19s/it]
{'loss': 0.3781, 'learning_rate': 8.5290893951132e-07, 'rewards/chosen': -1.8675400018692017, 'rewards/rejected': -3.118708848953247, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2511687278747559, 'policy_logps/rejected': -465.5251159667969, 'policy_logps/chosen': -495.960693359375, 'referece_logps/rejected': -434.3380126953125, 'referece_logps/chosen': -477.2853088378906, 'logits/rejected': 0.30961501598358154, 'logits/chosen': 0.30377429723739624, 'epoch': 3.36}

 56%|█████▌    | 9029/16104 [41:31:16<23:01:56, 11.72s/it]

 56%|█████▌    | 9030/16104 [41:31:30<24:20:39, 12.39s/it]

 56%|█████▌    | 9031/16104 [41:31:42<24:16:11, 12.35s/it]


 56%|█████▌    | 9033/16104 [41:32:04<22:41:54, 11.56s/it]

 56%|█████▌    | 9034/16104 [41:32:23<27:29:39, 14.00s/it]
{'loss': 0.3856, 'learning_rate': 8.517154151196548e-07, 'rewards/chosen': -1.5170955657958984, 'rewards/rejected': -3.1381609439849854, 'rewards/accuracies': 0.875, 'rewards/margins': 1.621065378189087, 'policy_logps/rejected': -495.941650390625, 'policy_logps/chosen': -361.1705017089844, 'referece_logps/rejected': -464.5600891113281, 'referece_logps/chosen': -345.9995422363281, 'logits/rejected': -0.15702469646930695, 'logits/chosen': -0.14010734856128693, 'epoch': 3.37}


 56%|█████▌    | 9036/16104 [41:32:57<30:33:17, 15.56s/it]

 56%|█████▌    | 9037/16104 [41:33:10<28:39:06, 14.60s/it]

 56%|█████▌    | 9038/16104 [41:33:26<29:18:42, 14.93s/it]

 56%|█████▌    | 9039/16104 [41:33:48<33:34:58, 17.11s/it]
{'loss': 0.2621, 'learning_rate': 8.507209763415038e-07, 'rewards/chosen': -1.1688114404678345, 'rewards/rejected': -3.8781800270080566, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7093684673309326, 'policy_logps/rejected': -517.7830810546875, 'policy_logps/chosen': -401.36572265625, 'referece_logps/rejected': -479.0012512207031, 'referece_logps/chosen': -389.6776428222656, 'logits/rejected': -0.3454442620277405, 'logits/chosen': -0.17140036821365356, 'epoch': 3.37}

 56%|█████▌    | 9040/16104 [41:34:02<32:06:14, 16.36s/it]


 56%|█████▌    | 9042/16104 [41:34:36<31:59:36, 16.31s/it]

 56%|█████▌    | 9043/16104 [41:34:53<32:45:14, 16.70s/it]
{'loss': 0.2673, 'learning_rate': 8.499255339655595e-07, 'rewards/chosen': -1.5577908754348755, 'rewards/rejected': -3.8922688961029053, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3344781398773193, 'policy_logps/rejected': -328.896484375, 'policy_logps/chosen': -466.0444641113281, 'referece_logps/rejected': -289.9737854003906, 'referece_logps/chosen': -450.46661376953125, 'logits/rejected': 0.07491838932037354, 'logits/chosen': -0.01804313063621521, 'epoch': 3.37}

 56%|█████▌    | 9044/16104 [41:35:08<31:54:35, 16.27s/it]

 56%|█████▌    | 9045/16104 [41:35:31<35:22:10, 18.04s/it]


 56%|█████▌    | 9047/16104 [41:36:04<34:29:19, 17.59s/it]

 56%|█████▌    | 9048/16104 [41:36:22<34:36:52, 17.66s/it]
{'loss': 0.1593, 'learning_rate': 8.489313676484975e-07, 'rewards/chosen': -1.3551794290542603, 'rewards/rejected': -4.496545791625977, 'rewards/accuracies': 1.0, 'rewards/margins': 3.141366481781006, 'policy_logps/rejected': -484.3134460449219, 'policy_logps/chosen': -407.0791015625, 'referece_logps/rejected': -439.3479919433594, 'referece_logps/chosen': -393.5273132324219, 'logits/rejected': -0.255310595035553, 'logits/chosen': -0.21028845012187958, 'epoch': 3.37}

 56%|█████▌    | 9049/16104 [41:36:43<36:42:43, 18.73s/it]

 56%|█████▌    | 9050/16104 [41:36:55<32:50:38, 16.76s/it]

 56%|█████▌    | 9051/16104 [41:37:16<35:33:03, 18.15s/it]


 56%|█████▌    | 9053/16104 [41:37:54<36:14:40, 18.51s/it]

 56%|█████▌    | 9054/16104 [41:38:12<36:01:34, 18.40s/it]
{'loss': 0.4437, 'learning_rate': 8.477385698193303e-07, 'rewards/chosen': -1.8861074447631836, 'rewards/rejected': -3.6079201698303223, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7218128442764282, 'policy_logps/rejected': -602.6803588867188, 'policy_logps/chosen': -507.32318115234375, 'referece_logps/rejected': -566.6011352539062, 'referece_logps/chosen': -488.4620666503906, 'logits/rejected': -0.7093903422355652, 'logits/chosen': -0.6122879385948181, 'epoch': 3.37}


 56%|█████▌    | 9056/16104 [41:38:50<36:09:30, 18.47s/it]

 56%|█████▌    | 9057/16104 [41:39:02<32:16:33, 16.49s/it]

 56%|█████▌    | 9058/16104 [41:39:16<30:42:41, 15.69s/it]
{'loss': 0.215, 'learning_rate': 8.469434943442581e-07, 'rewards/chosen': -1.234318494796753, 'rewards/rejected': -5.458742618560791, 'rewards/accuracies': 1.0, 'rewards/margins': 4.224423885345459, 'policy_logps/rejected': -327.9336242675781, 'policy_logps/chosen': -376.019287109375, 'referece_logps/rejected': -273.3462219238281, 'referece_logps/chosen': -363.6761169433594, 'logits/rejected': -0.28711503744125366, 'logits/chosen': -0.19674405455589294, 'epoch': 3.37}


 56%|█████▋    | 9060/16104 [41:39:50<32:36:47, 16.67s/it]

 56%|█████▋    | 9061/16104 [41:40:10<34:15:05, 17.51s/it]

 56%|█████▋    | 9062/16104 [41:40:30<35:38:36, 18.22s/it]

 56%|█████▋    | 9063/16104 [41:40:46<34:26:24, 17.61s/it]
{'loss': 0.3372, 'learning_rate': 8.459497893674067e-07, 'rewards/chosen': -2.045416831970215, 'rewards/rejected': -4.235856533050537, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1904399394989014, 'policy_logps/rejected': -401.7685546875, 'policy_logps/chosen': -354.2322082519531, 'referece_logps/rejected': -359.40997314453125, 'referece_logps/chosen': -333.778076171875, 'logits/rejected': -0.7304621934890747, 'logits/chosen': -0.6779600381851196, 'epoch': 3.38}


 56%|█████▋    | 9065/16104 [41:41:18<32:53:28, 16.82s/it]
{'loss': 0.349, 'learning_rate': 8.455523509416333e-07, 'rewards/chosen': -2.2637929916381836, 'rewards/rejected': -3.57070255279541, 'rewards/accuracies': 0.75, 'rewards/margins': 1.306909441947937, 'policy_logps/rejected': -379.599365234375, 'policy_logps/chosen': -255.92039489746094, 'referece_logps/rejected': -343.8923034667969, 'referece_logps/chosen': -233.282470703125, 'logits/rejected': -0.7415611147880554, 'logits/chosen': -0.5387039184570312, 'epoch': 3.38}

 56%|█████▋    | 9066/16104 [41:41:41<36:08:58, 18.49s/it]


 56%|█████▋    | 9068/16104 [41:42:14<34:10:57, 17.49s/it]
{'loss': 0.3096, 'learning_rate': 8.449562401806907e-07, 'rewards/chosen': -1.3633216619491577, 'rewards/rejected': -2.8336122035980225, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4702906608581543, 'policy_logps/rejected': -422.7878723144531, 'policy_logps/chosen': -447.7478942871094, 'referece_logps/rejected': -394.45172119140625, 'referece_logps/chosen': -434.11468505859375, 'logits/rejected': -0.49723851680755615, 'logits/chosen': -0.39532825350761414, 'epoch': 3.38}


 56%|█████▋    | 9070/16104 [41:42:56<37:26:10, 19.16s/it]
{'loss': 0.2385, 'learning_rate': 8.445588643523163e-07, 'rewards/chosen': -0.8818430304527283, 'rewards/rejected': -5.507811546325684, 'rewards/accuracies': 0.875, 'rewards/margins': 4.625968933105469, 'policy_logps/rejected': -555.4640502929688, 'policy_logps/chosen': -531.6884155273438, 'referece_logps/rejected': -500.3858947753906, 'referece_logps/chosen': -522.8699951171875, 'logits/rejected': -0.5740258693695068, 'logits/chosen': -0.40029528737068176, 'epoch': 3.38}


 56%|█████▋    | 9072/16104 [41:43:28<35:00:44, 17.92s/it]

 56%|█████▋    | 9073/16104 [41:43:46<34:48:56, 17.83s/it]

 56%|█████▋    | 9074/16104 [41:44:04<35:07:43, 17.99s/it]

 56%|█████▋    | 9075/16104 [41:44:20<33:45:41, 17.29s/it]
{'loss': 0.2301, 'learning_rate': 8.435655349597689e-07, 'rewards/chosen': -1.5926425457000732, 'rewards/rejected': -4.560956954956055, 'rewards/accuracies': 1.0, 'rewards/margins': 2.9683141708374023, 'policy_logps/rejected': -215.32740783691406, 'policy_logps/chosen': -236.954345703125, 'referece_logps/rejected': -169.7178192138672, 'referece_logps/chosen': -221.02792358398438, 'logits/rejected': -0.565468966960907, 'logits/chosen': -0.6555668115615845, 'epoch': 3.38}


 56%|█████▋    | 9077/16104 [41:44:52<31:31:19, 16.15s/it]

 56%|█████▋    | 9078/16104 [41:45:02<28:15:11, 14.48s/it]
{'loss': 0.3398, 'learning_rate': 8.429696131965895e-07, 'rewards/chosen': -1.5095986127853394, 'rewards/rejected': -4.786003112792969, 'rewards/accuracies': 0.875, 'rewards/margins': 3.276404857635498, 'policy_logps/rejected': -549.090576171875, 'policy_logps/chosen': -443.92437744140625, 'referece_logps/rejected': -501.2305908203125, 'referece_logps/chosen': -428.8283996582031, 'logits/rejected': -0.16964875161647797, 'logits/chosen': -0.05584391951560974, 'epoch': 3.38}

 56%|█████▋    | 9079/16104 [41:45:19<29:48:10, 15.27s/it]

 56%|█████▋    | 9080/16104 [41:45:35<30:07:01, 15.44s/it]


 56%|█████▋    | 9082/16104 [41:46:09<30:25:17, 15.60s/it]

 56%|█████▋    | 9083/16104 [41:46:25<30:44:39, 15.76s/it]
{'loss': 0.3015, 'learning_rate': 8.419765374082695e-07, 'rewards/chosen': -1.497347354888916, 'rewards/rejected': -5.0162672996521, 'rewards/accuracies': 1.0, 'rewards/margins': 3.5189199447631836, 'policy_logps/rejected': -336.6546630859375, 'policy_logps/chosen': -392.1539306640625, 'referece_logps/rejected': -286.4919738769531, 'referece_logps/chosen': -377.1805114746094, 'logits/rejected': -0.7556749582290649, 'logits/chosen': -0.7182309627532959, 'epoch': 3.38}


 56%|█████▋    | 9085/16104 [41:46:54<30:29:04, 15.64s/it]
{'loss': 0.3624, 'learning_rate': 8.415793517830205e-07, 'rewards/chosen': -1.7058268785476685, 'rewards/rejected': -2.8971526622772217, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1913257837295532, 'policy_logps/rejected': -327.1443176269531, 'policy_logps/chosen': -452.53936767578125, 'referece_logps/rejected': -298.1728210449219, 'referece_logps/chosen': -435.4811096191406, 'logits/rejected': -0.029522087424993515, 'logits/chosen': -0.06722530722618103, 'epoch': 3.38}


 56%|█████▋    | 9087/16104 [41:47:29<32:27:17, 16.65s/it]

 56%|█████▋    | 9088/16104 [41:47:48<34:09:42, 17.53s/it]
{'loss': 0.4849, 'learning_rate': 8.409836214282131e-07, 'rewards/chosen': -1.177626132965088, 'rewards/rejected': -2.9510371685028076, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7734107971191406, 'policy_logps/rejected': -371.52911376953125, 'policy_logps/chosen': -303.2958984375, 'referece_logps/rejected': -342.01873779296875, 'referece_logps/chosen': -291.5196533203125, 'logits/rejected': -0.835749089717865, 'logits/chosen': -0.8704230785369873, 'epoch': 3.39}

 56%|█████▋    | 9089/16104 [41:47:59<30:11:54, 15.50s/it]


 56%|█████▋    | 9091/16104 [41:48:20<25:15:35, 12.97s/it]

 56%|█████▋    | 9092/16104 [41:48:31<23:55:12, 12.28s/it]
{'loss': 0.3503, 'learning_rate': 8.401894043808988e-07, 'rewards/chosen': -1.7278205156326294, 'rewards/rejected': -3.992149829864502, 'rewards/accuracies': 0.875, 'rewards/margins': 2.264329433441162, 'policy_logps/rejected': -413.70880126953125, 'policy_logps/chosen': -322.34857177734375, 'referece_logps/rejected': -373.78729248046875, 'referece_logps/chosen': -305.07037353515625, 'logits/rejected': -0.7852835059165955, 'logits/chosen': -0.754589319229126, 'epoch': 3.39}

 56%|█████▋    | 9093/16104 [41:48:50<27:47:55, 14.27s/it]


 56%|█████▋    | 9095/16104 [41:49:33<34:50:21, 17.89s/it]
{'loss': 0.2998, 'learning_rate': 8.395938094458502e-07, 'rewards/chosen': -1.8673903942108154, 'rewards/rejected': -4.361835956573486, 'rewards/accuracies': 0.875, 'rewards/margins': 2.494445562362671, 'policy_logps/rejected': -455.5626220703125, 'policy_logps/chosen': -559.173583984375, 'referece_logps/rejected': -411.9442443847656, 'referece_logps/chosen': -540.4996337890625, 'logits/rejected': -0.6434959173202515, 'logits/chosen': -0.8232155442237854, 'epoch': 3.39}


 56%|█████▋    | 9097/16104 [41:50:05<32:09:35, 16.52s/it]
{'loss': 0.4354, 'learning_rate': 8.391967785860156e-07, 'rewards/chosen': -1.824141502380371, 'rewards/rejected': -3.487154006958008, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6630125045776367, 'policy_logps/rejected': -426.8820495605469, 'policy_logps/chosen': -408.3364562988281, 'referece_logps/rejected': -392.0104675292969, 'referece_logps/chosen': -390.09503173828125, 'logits/rejected': -0.3999459147453308, 'logits/chosen': -0.4782141149044037, 'epoch': 3.39}


 57%|█████▋    | 9099/16104 [41:50:32<29:18:42, 15.06s/it]

 57%|█████▋    | 9100/16104 [41:50:43<26:41:05, 13.72s/it]

 57%|█████▋    | 9101/16104 [41:51:03<30:18:55, 15.58s/it]

 57%|█████▋    | 9102/16104 [41:51:21<31:33:32, 16.23s/it]

 57%|█████▋    | 9103/16104 [41:51:40<33:35:30, 17.27s/it]
{'loss': 0.4297, 'learning_rate': 8.380058423781148e-07, 'rewards/chosen': -1.7263342142105103, 'rewards/rejected': -4.425122261047363, 'rewards/accuracies': 0.875, 'rewards/margins': 2.6987881660461426, 'policy_logps/rejected': -310.288818359375, 'policy_logps/chosen': -323.34625244140625, 'referece_logps/rejected': -266.03759765625, 'referece_logps/chosen': -306.0829162597656, 'logits/rejected': -0.5447807312011719, 'logits/chosen': -0.45082399249076843, 'epoch': 3.39}

 57%|█████▋    | 9104/16104 [41:51:56<32:21:19, 16.64s/it]


 57%|█████▋    | 9106/16104 [41:52:30<33:00:50, 16.98s/it]
{'loss': 0.4398, 'learning_rate': 8.374104626306346e-07, 'rewards/chosen': -2.126950979232788, 'rewards/rejected': -3.590916633605957, 'rewards/accuracies': 0.75, 'rewards/margins': 1.463965892791748, 'policy_logps/rejected': -215.259521484375, 'policy_logps/chosen': -289.27593994140625, 'referece_logps/rejected': -179.35035705566406, 'referece_logps/chosen': -268.0064392089844, 'logits/rejected': -0.9269458055496216, 'logits/chosen': -0.8297783732414246, 'epoch': 3.39}

 57%|█████▋    | 9107/16104 [41:52:48<33:25:04, 17.19s/it]

 57%|█████▋    | 9108/16104 [41:53:02<31:33:17, 16.24s/it]


 57%|█████▋    | 9110/16104 [41:53:37<32:47:14, 16.88s/it]
{'loss': 0.4387, 'learning_rate': 8.36616715083303e-07, 'rewards/chosen': -1.7930344343185425, 'rewards/rejected': -2.366281032562256, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5732468366622925, 'policy_logps/rejected': -255.9453582763672, 'policy_logps/chosen': -197.92929077148438, 'referece_logps/rejected': -232.2825469970703, 'referece_logps/chosen': -179.99896240234375, 'logits/rejected': 0.04015606641769409, 'logits/chosen': -0.029505550861358643, 'epoch': 3.39}


 57%|█████▋    | 9112/16104 [41:54:09<30:50:22, 15.88s/it]
{'loss': 0.4373, 'learning_rate': 8.362198809324022e-07, 'rewards/chosen': -0.9554874897003174, 'rewards/rejected': -2.367497444152832, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4120100736618042, 'policy_logps/rejected': -376.6451721191406, 'policy_logps/chosen': -350.57977294921875, 'referece_logps/rejected': -352.97021484375, 'referece_logps/chosen': -341.0248718261719, 'logits/rejected': 0.11933538317680359, 'logits/chosen': 0.0035306736826896667, 'epoch': 3.39}


 57%|█████▋    | 9114/16104 [41:54:37<28:44:00, 14.80s/it]
{'loss': 0.3538, 'learning_rate': 8.358230732822933e-07, 'rewards/chosen': -1.308748722076416, 'rewards/rejected': -2.982255697250366, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6735069751739502, 'policy_logps/rejected': -519.74169921875, 'policy_logps/chosen': -431.3209228515625, 'referece_logps/rejected': -489.9191589355469, 'referece_logps/chosen': -418.2333984375, 'logits/rejected': -0.4939870536327362, 'logits/chosen': -0.4028840661048889, 'epoch': 3.4}

 57%|█████▋    | 9115/16104 [41:54:51<28:37:59, 14.75s/it]

 57%|█████▋    | 9116/16104 [41:55:03<27:02:35, 13.93s/it]


 57%|█████▋    | 9118/16104 [41:55:41<32:21:41, 16.68s/it]

 57%|█████▋    | 9119/16104 [41:55:54<30:19:32, 15.63s/it]
{'loss': 0.3625, 'learning_rate': 8.348311705193292e-07, 'rewards/chosen': -1.8103151321411133, 'rewards/rejected': -2.572502851486206, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7621878981590271, 'policy_logps/rejected': -479.8013916015625, 'policy_logps/chosen': -416.0948486328125, 'referece_logps/rejected': -454.076416015625, 'referece_logps/chosen': -397.9916687011719, 'logits/rejected': -0.5049843788146973, 'logits/chosen': -0.42305564880371094, 'epoch': 3.4}

 57%|█████▋    | 9120/16104 [41:56:10<30:02:41, 15.49s/it]

 57%|█████▋    | 9121/16104 [41:56:26<30:25:06, 15.68s/it]


 57%|█████▋    | 9123/16104 [41:57:05<34:45:17, 17.92s/it]

 57%|█████▋    | 9124/16104 [41:57:23<34:36:31, 17.85s/it]

 57%|█████▋    | 9125/16104 [41:57:43<35:57:14, 18.55s/it]
{'loss': 0.2364, 'learning_rate': 8.336411077773552e-07, 'rewards/chosen': -1.5384316444396973, 'rewards/rejected': -3.229644536972046, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6912126541137695, 'policy_logps/rejected': -376.6172790527344, 'policy_logps/chosen': -349.4342041015625, 'referece_logps/rejected': -344.32086181640625, 'referece_logps/chosen': -334.0499267578125, 'logits/rejected': -0.41500505805015564, 'logits/chosen': -0.4006195664405823, 'epoch': 3.4}


 57%|█████▋    | 9127/16104 [41:58:21<36:06:54, 18.63s/it]

 57%|█████▋    | 9128/16104 [41:58:37<34:42:55, 17.92s/it]
{'loss': 0.2323, 'learning_rate': 8.330461671464956e-07, 'rewards/chosen': -1.662164568901062, 'rewards/rejected': -4.11795711517334, 'rewards/accuracies': 0.75, 'rewards/margins': 2.4557924270629883, 'policy_logps/rejected': -420.0803527832031, 'policy_logps/chosen': -349.15716552734375, 'referece_logps/rejected': -378.90081787109375, 'referece_logps/chosen': -332.5355529785156, 'logits/rejected': -0.10142073035240173, 'logits/chosen': -0.06662295758724213, 'epoch': 3.4}


 57%|█████▋    | 9130/16104 [41:59:07<32:00:19, 16.52s/it]

 57%|█████▋    | 9131/16104 [41:59:27<33:53:38, 17.50s/it]
{'loss': 0.4292, 'learning_rate': 8.324512872978582e-07, 'rewards/chosen': -1.0962539911270142, 'rewards/rejected': -2.1513004302978516, 'rewards/accuracies': 0.75, 'rewards/margins': 1.055046558380127, 'policy_logps/rejected': -335.6278076171875, 'policy_logps/chosen': -318.1047058105469, 'referece_logps/rejected': -314.1148376464844, 'referece_logps/chosen': -307.14215087890625, 'logits/rejected': -0.7829129695892334, 'logits/chosen': -0.6880607604980469, 'epoch': 3.4}


 57%|█████▋    | 9133/16104 [42:00:08<36:24:55, 18.81s/it]
{'loss': 0.2826, 'learning_rate': 8.320547346069531e-07, 'rewards/chosen': -1.7683076858520508, 'rewards/rejected': -4.283712863922119, 'rewards/accuracies': 0.75, 'rewards/margins': 2.5154054164886475, 'policy_logps/rejected': -333.6732177734375, 'policy_logps/chosen': -292.8614807128906, 'referece_logps/rejected': -290.8360595703125, 'referece_logps/chosen': -275.17840576171875, 'logits/rejected': -0.7559465169906616, 'logits/chosen': -0.8212347030639648, 'epoch': 3.4}

 57%|█████▋    | 9134/16104 [42:00:20<32:56:46, 17.02s/it]


 57%|█████▋    | 9136/16104 [42:00:49<30:42:19, 15.86s/it]
{'loss': 0.2969, 'learning_rate': 8.314599565432886e-07, 'rewards/chosen': -1.3442119359970093, 'rewards/rejected': -3.6171088218688965, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2728970050811768, 'policy_logps/rejected': -419.9292297363281, 'policy_logps/chosen': -546.7137451171875, 'referece_logps/rejected': -383.7581787109375, 'referece_logps/chosen': -533.2716064453125, 'logits/rejected': -0.23727303743362427, 'logits/chosen': -0.28315162658691406, 'epoch': 3.4}

 57%|█████▋    | 9137/16104 [42:01:07<31:30:01, 16.28s/it]

 57%|█████▋    | 9138/16104 [42:01:20<30:09:41, 15.59s/it]

 57%|█████▋    | 9139/16104 [42:01:43<34:02:39, 17.60s/it]

 57%|█████▋    | 9140/16104 [42:02:05<36:43:52, 18.99s/it]

 57%|█████▋    | 9141/16104 [42:02:16<32:08:17, 16.62s/it]

 57%|█████▋    | 9142/16104 [42:02:29<30:03:20, 15.54s/it]

 57%|█████▋    | 9143/16104 [42:02:47<31:10:47, 16.13s/it]


 57%|█████▋    | 9145/16104 [42:03:18<31:12:35, 16.15s/it]

 57%|█████▋    | 9146/16104 [42:03:36<32:17:32, 16.71s/it]
{'loss': 0.3793, 'learning_rate': 8.294778073673761e-07, 'rewards/chosen': -2.174384355545044, 'rewards/rejected': -3.9085330963134766, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7341489791870117, 'policy_logps/rejected': -386.1332702636719, 'policy_logps/chosen': -473.9779052734375, 'referece_logps/rejected': -347.0479736328125, 'referece_logps/chosen': -452.2340087890625, 'logits/rejected': -0.06748791038990021, 'logits/chosen': -0.20880989730358124, 'epoch': 3.41}

 57%|█████▋    | 9147/16104 [42:03:55<33:53:55, 17.54s/it]

 57%|█████▋    | 9148/16104 [42:04:13<34:10:07, 17.68s/it]

 57%|█████▋    | 9149/16104 [42:04:28<32:39:55, 16.91s/it]

 57%|█████▋    | 9150/16104 [42:04:39<29:20:37, 15.19s/it]

 57%|█████▋    | 9151/16104 [42:04:51<27:22:45, 14.18s/it]

 57%|█████▋    | 9152/16104 [42:05:04<26:44:30, 13.85s/it]

 57%|█████▋    | 9153/16104 [42:05:27<31:37:38, 16.38s/it]

 57%|█████▋    | 9154/16104 [42:05:46<33:37:25, 17.42s/it]

 57%|█████▋    | 9155/16104 [42:06:05<34:02:57, 17.64s/it]


 57%|█████▋    | 9157/16104 [42:06:34<30:31:28, 15.82s/it]
{'loss': 0.3197, 'learning_rate': 8.272982402927894e-07, 'rewards/chosen': -1.4838309288024902, 'rewards/rejected': -4.04710578918457, 'rewards/accuracies': 1.0, 'rewards/margins': 2.56327486038208, 'policy_logps/rejected': -437.8211364746094, 'policy_logps/chosen': -360.1426086425781, 'referece_logps/rejected': -397.3500671386719, 'referece_logps/chosen': -345.30426025390625, 'logits/rejected': -0.46655359864234924, 'logits/chosen': -0.44501522183418274, 'epoch': 3.41}

 57%|█████▋    | 9158/16104 [42:06:45<27:25:57, 14.22s/it]


 57%|█████▋    | 9160/16104 [42:07:20<31:02:54, 16.10s/it]

 57%|█████▋    | 9161/16104 [42:07:32<28:40:16, 14.87s/it]
{'loss': 0.2818, 'learning_rate': 8.265058794692948e-07, 'rewards/chosen': -1.7932037115097046, 'rewards/rejected': -2.9490702152252197, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1558666229248047, 'policy_logps/rejected': -370.91119384765625, 'policy_logps/chosen': -376.69110107421875, 'referece_logps/rejected': -341.42047119140625, 'referece_logps/chosen': -358.7590637207031, 'logits/rejected': 0.0009169504046440125, 'logits/chosen': 0.07218621671199799, 'epoch': 3.41}

 57%|█████▋    | 9162/16104 [42:07:44<27:14:58, 14.13s/it]


 57%|█████▋    | 9164/16104 [42:08:10<25:35:37, 13.28s/it]
{'loss': 0.3429, 'learning_rate': 8.259116825141677e-07, 'rewards/chosen': -2.2312891483306885, 'rewards/rejected': -4.0513458251953125, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8200569152832031, 'policy_logps/rejected': -405.68267822265625, 'policy_logps/chosen': -449.546630859375, 'referece_logps/rejected': -365.1692199707031, 'referece_logps/chosen': -427.2337341308594, 'logits/rejected': -0.43181049823760986, 'logits/chosen': -0.4394585192203522, 'epoch': 3.41}


 57%|█████▋    | 9166/16104 [42:08:40<27:18:14, 14.17s/it]
{'loss': 0.4015, 'learning_rate': 8.255155864083115e-07, 'rewards/chosen': -1.6619982719421387, 'rewards/rejected': -3.4372832775115967, 'rewards/accuracies': 0.875, 'rewards/margins': 1.775284767150879, 'policy_logps/rejected': -461.0346374511719, 'policy_logps/chosen': -409.8488464355469, 'referece_logps/rejected': -426.66180419921875, 'referece_logps/chosen': -393.2288818359375, 'logits/rejected': -0.10849297791719437, 'logits/chosen': -0.07741313427686691, 'epoch': 3.42}

 57%|█████▋    | 9167/16104 [42:08:54<27:08:19, 14.08s/it]

 57%|█████▋    | 9168/16104 [42:09:13<29:58:19, 15.56s/it]


 57%|█████▋    | 9170/16104 [42:09:44<30:00:41, 15.58s/it]
{'loss': 0.285, 'learning_rate': 8.247234789591561e-07, 'rewards/chosen': -2.821753740310669, 'rewards/rejected': -4.97700834274292, 'rewards/accuracies': 0.875, 'rewards/margins': 2.155254364013672, 'policy_logps/rejected': -306.4879150390625, 'policy_logps/chosen': -388.00738525390625, 'referece_logps/rejected': -256.71783447265625, 'referece_logps/chosen': -359.78985595703125, 'logits/rejected': -0.4478664696216583, 'logits/chosen': -0.5116999745368958, 'epoch': 3.42}

 57%|█████▋    | 9171/16104 [42:10:02<31:17:46, 16.25s/it]

 57%|█████▋    | 9172/16104 [42:10:21<33:10:00, 17.22s/it]

 57%|█████▋    | 9173/16104 [42:10:41<34:27:23, 17.90s/it]

 57%|█████▋    | 9174/16104 [42:11:01<35:31:13, 18.45s/it]

 57%|█████▋    | 9175/16104 [42:11:19<35:26:02, 18.41s/it]


 57%|█████▋    | 9177/16104 [42:11:48<32:15:44, 16.77s/it]
{'loss': 0.4677, 'learning_rate': 8.233375642060347e-07, 'rewards/chosen': -1.8533200025558472, 'rewards/rejected': -3.1962759494781494, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3429560661315918, 'policy_logps/rejected': -435.79669189453125, 'policy_logps/chosen': -457.7671813964844, 'referece_logps/rejected': -403.83392333984375, 'referece_logps/chosen': -439.2340087890625, 'logits/rejected': 0.6373193264007568, 'logits/chosen': 0.6113720536231995, 'epoch': 3.42}

 57%|█████▋    | 9178/16104 [42:11:59<28:43:05, 14.93s/it]

 57%|█████▋    | 9179/16104 [42:12:18<30:52:05, 16.05s/it]

 57%|█████▋    | 9180/16104 [42:12:37<33:03:11, 17.19s/it]

 57%|█████▋    | 9181/16104 [42:12:58<34:56:46, 18.17s/it]

 57%|█████▋    | 9182/16104 [42:13:13<33:10:58, 17.26s/it]

 57%|█████▋    | 9183/16104 [42:13:33<34:54:36, 18.16s/it]

 57%|█████▋    | 9184/16104 [42:13:52<34:57:37, 18.19s/it]

 57%|█████▋    | 9185/16104 [42:14:11<35:50:02, 18.64s/it]

 57%|█████▋    | 9186/16104 [42:14:25<33:14:14, 17.30s/it]

 57%|█████▋    | 9187/16104 [42:14:45<34:34:01, 17.99s/it]

 57%|█████▋    | 9188/16104 [42:15:05<35:32:50, 18.50s/it]

 57%|█████▋    | 9189/16104 [42:15:17<31:51:50, 16.59s/it]

 57%|█████▋    | 9190/16104 [42:15:28<28:29:59, 14.84s/it]


 57%|█████▋    | 9192/16104 [42:16:04<31:42:20, 16.51s/it]

 57%|█████▋    | 9193/16104 [42:16:18<30:15:32, 15.76s/it]
{'loss': 0.3636, 'learning_rate': 8.201710783967622e-07, 'rewards/chosen': -1.9637131690979004, 'rewards/rejected': -3.7319998741149902, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7682865858078003, 'policy_logps/rejected': -322.27838134765625, 'policy_logps/chosen': -498.51983642578125, 'referece_logps/rejected': -284.9583740234375, 'referece_logps/chosen': -478.8826904296875, 'logits/rejected': -0.7555044889450073, 'logits/chosen': -0.8680512309074402, 'epoch': 3.43}

 57%|█████▋    | 9194/16104 [42:16:38<32:22:54, 16.87s/it]

 57%|█████▋    | 9195/16104 [42:16:57<33:52:52, 17.65s/it]


 57%|█████▋    | 9197/16104 [42:17:36<36:00:22, 18.77s/it]
{'loss': 0.4234, 'learning_rate': 8.193797466397475e-07, 'rewards/chosen': -2.2318217754364014, 'rewards/rejected': -3.639474391937256, 'rewards/accuracies': 0.75, 'rewards/margins': 1.407652497291565, 'policy_logps/rejected': -418.9939270019531, 'policy_logps/chosen': -425.2705078125, 'referece_logps/rejected': -382.5992126464844, 'referece_logps/chosen': -402.9523010253906, 'logits/rejected': 0.06462924927473068, 'logits/chosen': 0.1282811164855957, 'epoch': 3.43}

 57%|█████▋    | 9198/16104 [42:17:51<33:45:07, 17.59s/it]

 57%|█████▋    | 9199/16104 [42:18:11<34:56:50, 18.22s/it]


 57%|█████▋    | 9201/16104 [42:18:45<33:10:41, 17.30s/it]
{'loss': 0.2519, 'learning_rate': 8.185885317853118e-07, 'rewards/chosen': -1.9538480043411255, 'rewards/rejected': -4.612325191497803, 'rewards/accuracies': 0.875, 'rewards/margins': 2.658477306365967, 'policy_logps/rejected': -254.74058532714844, 'policy_logps/chosen': -365.23193359375, 'referece_logps/rejected': -208.61732482910156, 'referece_logps/chosen': -345.6934814453125, 'logits/rejected': -0.4319083094596863, 'logits/chosen': -0.5037582516670227, 'epoch': 3.43}

 57%|█████▋    | 9202/16104 [42:19:01<32:39:14, 17.03s/it]

 57%|█████▋    | 9203/16104 [42:19:14<30:16:51, 15.80s/it]

 57%|█████▋    | 9204/16104 [42:19:36<33:50:22, 17.66s/it]

 57%|█████▋    | 9205/16104 [42:19:56<35:10:12, 18.35s/it]

 57%|█████▋    | 9206/16104 [42:20:10<32:38:29, 17.04s/it]

 57%|█████▋    | 9207/16104 [42:20:26<32:03:41, 16.74s/it]

 57%|█████▋    | 9208/16104 [42:20:46<33:53:24, 17.69s/it]

 57%|█████▋    | 9209/16104 [42:21:02<33:03:31, 17.26s/it]

 57%|█████▋    | 9210/16104 [42:21:22<34:27:13, 17.99s/it]

 57%|█████▋    | 9211/16104 [42:21:42<35:29:02, 18.53s/it]


 57%|█████▋    | 9213/16104 [42:22:19<34:59:20, 18.28s/it]
{'loss': 0.3243, 'learning_rate': 8.16215593758067e-07, 'rewards/chosen': -1.529136300086975, 'rewards/rejected': -4.265089988708496, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7359538078308105, 'policy_logps/rejected': -510.1659851074219, 'policy_logps/chosen': -455.2652587890625, 'referece_logps/rejected': -467.51507568359375, 'referece_logps/chosen': -439.973876953125, 'logits/rejected': -0.65636146068573, 'logits/chosen': -0.6705471277236938, 'epoch': 3.43}


 57%|█████▋    | 9215/16104 [42:22:53<33:33:27, 17.54s/it]
{'loss': 0.353, 'learning_rate': 8.158202077953086e-07, 'rewards/chosen': -1.5904057025909424, 'rewards/rejected': -3.2057135105133057, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6153080463409424, 'policy_logps/rejected': -382.9716796875, 'policy_logps/chosen': -478.89276123046875, 'referece_logps/rejected': -350.91455078125, 'referece_logps/chosen': -462.9886779785156, 'logits/rejected': -0.08948637545108795, 'logits/chosen': -0.20815636217594147, 'epoch': 3.43}

 57%|█████▋    | 9216/16104 [42:23:13<35:22:13, 18.49s/it]

 57%|█████▋    | 9217/16104 [42:23:29<33:29:20, 17.51s/it]

 57%|█████▋    | 9218/16104 [42:23:48<34:40:47, 18.13s/it]

 57%|█████▋    | 9219/16104 [42:24:04<33:33:55, 17.55s/it]

 57%|█████▋    | 9220/16104 [42:24:23<33:58:29, 17.77s/it]

 57%|█████▋    | 9221/16104 [42:24:34<30:05:13, 15.74s/it]

 57%|█████▋    | 9222/16104 [42:24:53<32:17:12, 16.89s/it]


 57%|█████▋    | 9224/16104 [42:25:15<26:25:39, 13.83s/it]
{'loss': 0.2284, 'learning_rate': 8.140413406812971e-07, 'rewards/chosen': -1.4290010929107666, 'rewards/rejected': -5.082745552062988, 'rewards/accuracies': 1.0, 'rewards/margins': 3.653744697570801, 'policy_logps/rejected': -280.66851806640625, 'policy_logps/chosen': -443.24853515625, 'referece_logps/rejected': -229.841064453125, 'referece_logps/chosen': -428.9585266113281, 'logits/rejected': -0.7631527781486511, 'logits/chosen': -0.6060110330581665, 'epoch': 3.44}

 57%|█████▋    | 9225/16104 [42:25:26<24:36:27, 12.88s/it]


 57%|█████▋    | 9227/16104 [42:25:47<22:30:25, 11.78s/it]
{'loss': 0.38, 'learning_rate': 8.134485200912874e-07, 'rewards/chosen': -1.5706994533538818, 'rewards/rejected': -3.199688196182251, 'rewards/accuracies': 1.0, 'rewards/margins': 1.628988265991211, 'policy_logps/rejected': -508.6895446777344, 'policy_logps/chosen': -424.4299011230469, 'referece_logps/rejected': -476.6926574707031, 'referece_logps/chosen': -408.7228698730469, 'logits/rejected': -0.18413066864013672, 'logits/chosen': -0.16479751467704773, 'epoch': 3.44}

 57%|█████▋    | 9228/16104 [42:25:59<22:14:56, 11.65s/it]

 57%|█████▋    | 9229/16104 [42:26:15<24:54:13, 13.04s/it]

 57%|█████▋    | 9230/16104 [42:26:32<27:14:56, 14.27s/it]

 57%|█████▋    | 9231/16104 [42:26:49<28:36:51, 14.99s/it]

 57%|█████▋    | 9232/16104 [42:27:08<31:16:31, 16.38s/it]

 57%|█████▋    | 9233/16104 [42:27:20<28:35:34, 14.98s/it]

 57%|█████▋    | 9234/16104 [42:27:36<29:20:44, 15.38s/it]

 57%|█████▋    | 9235/16104 [42:27:56<31:54:00, 16.72s/it]


 57%|█████▋    | 9237/16104 [42:28:39<36:28:51, 19.13s/it]
{'loss': 0.3002, 'learning_rate': 8.114729431821944e-07, 'rewards/chosen': -1.3010571002960205, 'rewards/rejected': -3.093869924545288, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7928130626678467, 'policy_logps/rejected': -353.8833923339844, 'policy_logps/chosen': -240.6245574951172, 'referece_logps/rejected': -322.9447326660156, 'referece_logps/chosen': -227.61398315429688, 'logits/rejected': -0.31635376811027527, 'logits/chosen': -0.3560554087162018, 'epoch': 3.44}

 57%|█████▋    | 9238/16104 [42:28:59<36:47:39, 19.29s/it]

 57%|█████▋    | 9239/16104 [42:29:13<33:49:02, 17.73s/it]


 57%|█████▋    | 9241/16104 [42:29:45<31:23:23, 16.47s/it]
{'loss': 0.3601, 'learning_rate': 8.106829255062265e-07, 'rewards/chosen': -2.028536558151245, 'rewards/rejected': -3.3005831241607666, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2720465660095215, 'policy_logps/rejected': -353.4903259277344, 'policy_logps/chosen': -328.877197265625, 'referece_logps/rejected': -320.4844970703125, 'referece_logps/chosen': -308.591796875, 'logits/rejected': -0.2488333135843277, 'logits/chosen': -0.3490418791770935, 'epoch': 3.44}


 57%|█████▋    | 9243/16104 [42:30:17<31:33:09, 16.56s/it]

 57%|█████▋    | 9244/16104 [42:30:29<28:48:42, 15.12s/it]
{'loss': 0.4176, 'learning_rate': 8.100904926325284e-07, 'rewards/chosen': -1.7315195798873901, 'rewards/rejected': -3.7396183013916016, 'rewards/accuracies': 0.875, 'rewards/margins': 2.00809907913208, 'policy_logps/rejected': -274.69287109375, 'policy_logps/chosen': -324.2174987792969, 'referece_logps/rejected': -237.29666137695312, 'referece_logps/chosen': -306.9023132324219, 'logits/rejected': -0.596083402633667, 'logits/chosen': -0.6276941299438477, 'epoch': 3.44}

 57%|█████▋    | 9245/16104 [42:30:49<31:27:40, 16.51s/it]

 57%|█████▋    | 9246/16104 [42:31:04<30:23:46, 15.96s/it]

 57%|█████▋    | 9247/16104 [42:31:22<31:39:44, 16.62s/it]

 57%|█████▋    | 9248/16104 [42:31:39<31:58:40, 16.79s/it]

 57%|█████▋    | 9249/16104 [42:31:57<32:50:33, 17.25s/it]

 57%|█████▋    | 9250/16104 [42:32:17<34:10:19, 17.95s/it]

 57%|█████▋    | 9251/16104 [42:32:29<30:39:24, 16.10s/it]

 57%|█████▋    | 9252/16104 [42:32:47<31:38:15, 16.62s/it]

 57%|█████▋    | 9253/16104 [42:32:57<28:16:19, 14.86s/it]

 57%|█████▋    | 9254/16104 [42:33:08<25:54:06, 13.61s/it]

 57%|█████▋    | 9255/16104 [42:33:19<24:16:45, 12.76s/it]


 57%|█████▋    | 9257/16104 [42:33:49<27:15:25, 14.33s/it]

 57%|█████▋    | 9258/16104 [42:34:04<27:39:30, 14.54s/it]

 57%|█████▋    | 9259/16104 [42:34:23<30:03:52, 15.81s/it]

 58%|█████▊    | 9260/16104 [42:34:44<32:58:22, 17.34s/it]

 58%|█████▊    | 9261/16104 [42:35:01<33:07:44, 17.43s/it]

 58%|█████▊    | 9262/16104 [42:35:17<32:04:22, 16.88s/it]

 58%|█████▊    | 9263/16104 [42:35:36<33:37:20, 17.69s/it]

 58%|█████▊    | 9264/16104 [42:35:49<30:35:24, 16.10s/it]

 58%|█████▊    | 9265/16104 [42:36:04<30:09:53, 15.88s/it]

 58%|█████▊    | 9266/16104 [42:36:20<30:09:40, 15.88s/it]

 58%|█████▊    | 9267/16104 [42:36:42<33:26:49, 17.61s/it]

 58%|█████▊    | 9268/16104 [42:36:54<30:34:25, 16.10s/it]

 58%|█████▊    | 9269/16104 [42:37:12<31:13:32, 16.45s/it]

 58%|█████▊    | 9270/16104 [42:37:28<31:23:42, 16.54s/it]

 58%|█████▊    | 9271/16104 [42:37:43<30:13:53, 15.93s/it]

 58%|█████▊    | 9272/16104 [42:38:02<32:16:51, 17.01s/it]

 58%|█████▊    | 9273/16104 [42:38:15<29:47:05, 15.70s/it]

 58%|█████▊    | 9274/16104 [42:38:35<32:06:32, 16.92s/it]

 58%|█████▊    | 9275/16104 [42:38:53<33:03:52, 17.43s/it]

 58%|█████▊    | 9276/16104 [42:39:13<34:21:00, 18.11s/it]

 58%|█████▊    | 9277/16104 [42:39:33<35:35:16, 18.77s/it]
{'loss': 0.3515, 'learning_rate': 8.035783416682672e-07, 'rewards/chosen': -1.5453890562057495, 'rewards/rejected': -3.517472267150879, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9720832109451294, 'policy_logps/rejected': -518.87646484375, 'policy_logps/chosen': -408.16412353515625, 'referece_logps/rejected': -483.7017822265625, 'referece_logps/chosen': -392.71026611328125, 'logits/rejected': -0.8177942633628845, 'logits/chosen': -0.8541322350502014, 'epoch': 3.46}

 58%|█████▊    | 9278/16104 [42:39:50<34:27:24, 18.17s/it]


 58%|█████▊    | 9280/16104 [42:40:32<36:56:56, 19.49s/it]

 58%|█████▊    | 9281/16104 [42:40:43<32:07:46, 16.95s/it]

 58%|█████▊    | 9282/16104 [42:41:04<34:06:06, 18.00s/it]

 58%|█████▊    | 9283/16104 [42:41:23<34:41:03, 18.31s/it]
{'loss': 0.4624, 'learning_rate': 8.023952354530788e-07, 'rewards/chosen': -1.3031091690063477, 'rewards/rejected': -2.3468332290649414, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0437241792678833, 'policy_logps/rejected': -414.8625793457031, 'policy_logps/chosen': -543.3237915039062, 'referece_logps/rejected': -391.39422607421875, 'referece_logps/chosen': -530.292724609375, 'logits/rejected': 0.14424240589141846, 'logits/chosen': 0.06411567330360413, 'epoch': 3.46}


 58%|█████▊    | 9285/16104 [42:41:58<34:32:06, 18.23s/it]

 58%|█████▊    | 9286/16104 [42:42:18<35:21:35, 18.67s/it]
{'loss': 0.2847, 'learning_rate': 8.01803790149588e-07, 'rewards/chosen': -1.5983656644821167, 'rewards/rejected': -3.824972629547119, 'rewards/accuracies': 1.0, 'rewards/margins': 2.226606607437134, 'policy_logps/rejected': -302.1261291503906, 'policy_logps/chosen': -469.88128662109375, 'referece_logps/rejected': -263.87640380859375, 'referece_logps/chosen': -453.89764404296875, 'logits/rejected': -0.7437503337860107, 'logits/chosen': -0.9271270036697388, 'epoch': 3.46}


 58%|█████▊    | 9288/16104 [42:42:57<36:11:20, 19.11s/it]

 58%|█████▊    | 9289/16104 [42:43:13<34:40:10, 18.31s/it]

 58%|█████▊    | 9290/16104 [42:43:29<33:09:27, 17.52s/it]

 58%|█████▊    | 9291/16104 [42:43:49<34:33:23, 18.26s/it]

 58%|█████▊    | 9292/16104 [42:44:02<31:47:39, 16.80s/it]

 58%|█████▊    | 9293/16104 [42:44:18<31:22:01, 16.58s/it]

 58%|█████▊    | 9294/16104 [42:44:35<31:40:23, 16.74s/it]

 58%|█████▊    | 9295/16104 [42:44:50<30:41:58, 16.23s/it]

 58%|█████▊    | 9296/16104 [42:45:11<33:22:06, 17.64s/it]

 58%|█████▊    | 9297/16104 [42:45:22<29:28:32, 15.59s/it]

 58%|█████▊    | 9298/16104 [42:45:39<30:04:54, 15.91s/it]

 58%|█████▊    | 9299/16104 [42:45:53<29:00:11, 15.34s/it]

 58%|█████▊    | 9300/16104 [42:46:03<26:22:46, 13.96s/it]

 58%|█████▊    | 9301/16104 [42:46:24<30:01:26, 15.89s/it]

 58%|█████▊    | 9302/16104 [42:46:45<33:03:44, 17.50s/it]

 58%|█████▊    | 9303/16104 [42:46:57<29:52:40, 15.82s/it]

 58%|█████▊    | 9304/16104 [42:47:17<32:12:30, 17.05s/it]

 58%|█████▊    | 9305/16104 [42:47:36<33:23:21, 17.68s/it]
{'loss': 0.3175, 'learning_rate': 7.980596544158976e-07, 'rewards/chosen': -1.3751345872879028, 'rewards/rejected': -2.9021902084350586, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5270555019378662, 'policy_logps/rejected': -239.0533447265625, 'policy_logps/chosen': -350.7319030761719, 'referece_logps/rejected': -210.03143310546875, 'referece_logps/chosen': -336.9805908203125, 'logits/rejected': -0.3827999234199524, 'logits/chosen': -0.4299379587173462, 'epoch': 3.47}


 58%|█████▊    | 9307/16104 [42:48:00<27:52:27, 14.76s/it]
{'loss': 0.32, 'learning_rate': 7.976657054623614e-07, 'rewards/chosen': -1.4493378400802612, 'rewards/rejected': -3.033878803253174, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5845410823822021, 'policy_logps/rejected': -403.26947021484375, 'policy_logps/chosen': -620.2655639648438, 'referece_logps/rejected': -372.93072509765625, 'referece_logps/chosen': -605.7721557617188, 'logits/rejected': -0.444452702999115, 'logits/chosen': -0.6655641794204712, 'epoch': 3.47}


 58%|█████▊    | 9309/16104 [42:48:29<27:16:51, 14.45s/it]

 58%|█████▊    | 9310/16104 [42:48:43<26:57:29, 14.28s/it]

 58%|█████▊    | 9311/16104 [42:49:02<29:43:47, 15.76s/it]

 58%|█████▊    | 9312/16104 [42:49:13<26:56:53, 14.28s/it]

 58%|█████▊    | 9313/16104 [42:49:33<30:03:29, 15.93s/it]

 58%|█████▊    | 9314/16104 [42:49:52<31:55:49, 16.93s/it]

 58%|█████▊    | 9315/16104 [42:50:04<28:39:07, 15.19s/it]

 58%|█████▊    | 9316/16104 [42:50:19<28:59:36, 15.38s/it]

 58%|█████▊    | 9317/16104 [42:50:39<31:31:00, 16.72s/it]
{'loss': 0.2154, 'learning_rate': 7.956964530563616e-07, 'rewards/chosen': -2.4189388751983643, 'rewards/rejected': -5.322231292724609, 'rewards/accuracies': 1.0, 'rewards/margins': 2.903292179107666, 'policy_logps/rejected': -390.46832275390625, 'policy_logps/chosen': -363.5162658691406, 'referece_logps/rejected': -337.2460021972656, 'referece_logps/chosen': -339.32684326171875, 'logits/rejected': -0.30649110674858093, 'logits/chosen': -0.24633997678756714, 'epoch': 3.47}


 58%|█████▊    | 9319/16104 [42:51:14<31:47:17, 16.87s/it]

 58%|█████▊    | 9320/16104 [42:51:32<32:08:01, 17.05s/it]

 58%|█████▊    | 9321/16104 [42:51:42<28:33:45, 15.16s/it]

 58%|█████▊    | 9322/16104 [42:52:02<30:54:19, 16.41s/it]

 58%|█████▊    | 9323/16104 [42:52:21<32:42:30, 17.36s/it]

 58%|█████▊    | 9324/16104 [42:52:38<32:39:03, 17.34s/it]

 58%|█████▊    | 9325/16104 [42:52:57<33:03:49, 17.56s/it]

 58%|█████▊    | 9326/16104 [42:53:15<33:32:40, 17.82s/it]

 58%|█████▊    | 9327/16104 [42:53:27<30:14:20, 16.06s/it]

 58%|█████▊    | 9328/16104 [42:53:39<28:07:10, 14.94s/it]

 58%|█████▊    | 9329/16104 [42:53:56<29:17:53, 15.57s/it]

 58%|█████▊    | 9330/16104 [42:54:07<26:33:27, 14.11s/it]

 58%|█████▊    | 9331/16104 [42:54:23<27:53:38, 14.83s/it]

 58%|█████▊    | 9332/16104 [42:54:43<30:30:47, 16.22s/it]
{'loss': 0.2204, 'learning_rate': 7.927441265183712e-07, 'rewards/chosen': -1.5810397863388062, 'rewards/rejected': -4.732951641082764, 'rewards/accuracies': 0.875, 'rewards/margins': 3.151912212371826, 'policy_logps/rejected': -281.0643615722656, 'policy_logps/chosen': -362.3876953125, 'referece_logps/rejected': -233.73483276367188, 'referece_logps/chosen': -346.5772705078125, 'logits/rejected': -0.13093574345111847, 'logits/chosen': -0.20784173905849457, 'epoch': 3.48}


 58%|█████▊    | 9334/16104 [42:55:12<28:57:18, 15.40s/it]

 58%|█████▊    | 9335/16104 [42:55:25<27:49:32, 14.80s/it]

 58%|█████▊    | 9336/16104 [42:55:36<25:39:09, 13.65s/it]

 58%|█████▊    | 9337/16104 [42:55:56<28:46:24, 15.31s/it]

 58%|█████▊    | 9338/16104 [42:56:14<30:23:34, 16.17s/it]

 58%|█████▊    | 9339/16104 [42:56:25<27:21:14, 14.56s/it]

 58%|█████▊    | 9340/16104 [42:56:38<26:55:35, 14.33s/it]

 58%|█████▊    | 9341/16104 [42:56:50<25:08:18, 13.38s/it]

 58%|█████▊    | 9342/16104 [42:57:02<24:44:13, 13.17s/it]

 58%|█████▊    | 9343/16104 [42:57:13<23:20:00, 12.42s/it]

 58%|█████▊    | 9344/16104 [42:57:26<23:58:07, 12.76s/it]

 58%|█████▊    | 9345/16104 [42:57:40<24:06:57, 12.84s/it]

 58%|█████▊    | 9346/16104 [42:57:54<25:00:01, 13.32s/it]
{'loss': 0.4231, 'learning_rate': 7.899903231353943e-07, 'rewards/chosen': -2.156698226928711, 'rewards/rejected': -4.174919605255127, 'rewards/accuracies': 1.0, 'rewards/margins': 2.018220901489258, 'policy_logps/rejected': -531.6805419921875, 'policy_logps/chosen': -411.1384582519531, 'referece_logps/rejected': -489.9313049316406, 'referece_logps/chosen': -389.57147216796875, 'logits/rejected': 0.4052128195762634, 'logits/chosen': 0.6753231287002563, 'epoch': 3.48}


 58%|█████▊    | 9348/16104 [42:58:20<24:42:52, 13.17s/it]

 58%|█████▊    | 9349/16104 [42:58:40<28:23:06, 15.13s/it]

 58%|█████▊    | 9350/16104 [42:58:58<30:17:59, 16.15s/it]

 58%|█████▊    | 9351/16104 [42:59:10<27:43:32, 14.78s/it]

 58%|█████▊    | 9352/16104 [42:59:22<26:00:31, 13.87s/it]

 58%|█████▊    | 9353/16104 [42:59:42<29:37:07, 15.79s/it]

 58%|█████▊    | 9354/16104 [42:59:53<27:05:14, 14.45s/it]

 58%|█████▊    | 9355/16104 [43:00:10<28:37:04, 15.27s/it]

 58%|█████▊    | 9356/16104 [43:00:29<30:15:36, 16.14s/it]

 58%|█████▊    | 9357/16104 [43:00:42<28:38:16, 15.28s/it]

 58%|█████▊    | 9358/16104 [43:01:01<30:51:24, 16.47s/it]

 58%|█████▊    | 9359/16104 [43:01:23<33:39:58, 17.97s/it]

 58%|█████▊    | 9360/16104 [43:01:36<30:57:55, 16.53s/it]

 58%|█████▊    | 9361/16104 [43:01:56<32:47:13, 17.50s/it]
{'loss': 0.2592, 'learning_rate': 7.870416678065637e-07, 'rewards/chosen': -1.688693642616272, 'rewards/rejected': -3.9506494998931885, 'rewards/accuracies': 1.0, 'rewards/margins': 2.261955976486206, 'policy_logps/rejected': -273.9754943847656, 'policy_logps/chosen': -314.50225830078125, 'referece_logps/rejected': -234.468994140625, 'referece_logps/chosen': -297.61529541015625, 'logits/rejected': -0.6616753935813904, 'logits/chosen': -0.745329737663269, 'epoch': 3.49}


 58%|█████▊    | 9363/16104 [43:02:33<34:12:32, 18.27s/it]
{'loss': 0.3335, 'learning_rate': 7.86648659624282e-07, 'rewards/chosen': -1.7639936208724976, 'rewards/rejected': -3.5609734058380127, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7969796657562256, 'policy_logps/rejected': -266.6107177734375, 'policy_logps/chosen': -233.47384643554688, 'referece_logps/rejected': -231.0009765625, 'referece_logps/chosen': -215.83392333984375, 'logits/rejected': -0.6536523699760437, 'logits/chosen': -0.412747859954834, 'epoch': 3.49}

 58%|█████▊    | 9364/16104 [43:02:54<35:26:17, 18.93s/it]


 58%|█████▊    | 9366/16104 [43:03:35<36:40:50, 19.60s/it]
{'loss': 0.3054, 'learning_rate': 7.86059212099048e-07, 'rewards/chosen': -2.219069480895996, 'rewards/rejected': -3.571009397506714, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3519399166107178, 'policy_logps/rejected': -397.4376220703125, 'policy_logps/chosen': -527.9691772460938, 'referece_logps/rejected': -361.7275390625, 'referece_logps/chosen': -505.7785339355469, 'logits/rejected': -0.02609126642346382, 'logits/chosen': -0.08695400506258011, 'epoch': 3.49}


 58%|█████▊    | 9368/16104 [43:04:11<35:05:02, 18.75s/it]

 58%|█████▊    | 9369/16104 [43:04:31<35:49:39, 19.15s/it]
{'loss': 0.3761, 'learning_rate': 7.854698424623915e-07, 'rewards/chosen': -1.7765812873840332, 'rewards/rejected': -3.329580545425415, 'rewards/accuracies': 0.875, 'rewards/margins': 1.552999496459961, 'policy_logps/rejected': -489.8765869140625, 'policy_logps/chosen': -484.71875, 'referece_logps/rejected': -456.5807800292969, 'referece_logps/chosen': -466.95294189453125, 'logits/rejected': 0.25114795565605164, 'logits/chosen': 0.3982081413269043, 'epoch': 3.49}


 58%|█████▊    | 9371/16104 [43:05:03<32:37:15, 17.44s/it]
{'loss': 0.2306, 'learning_rate': 7.85076972748681e-07, 'rewards/chosen': -1.278045892715454, 'rewards/rejected': -3.455467939376831, 'rewards/accuracies': 0.875, 'rewards/margins': 2.177422046661377, 'policy_logps/rejected': -400.2579345703125, 'policy_logps/chosen': -449.115478515625, 'referece_logps/rejected': -365.7032165527344, 'referece_logps/chosen': -436.3350830078125, 'logits/rejected': -0.9060716032981873, 'logits/chosen': -0.8768776059150696, 'epoch': 3.49}


 58%|█████▊    | 9373/16104 [43:05:40<33:41:19, 18.02s/it]
{'loss': 0.3421, 'learning_rate': 7.846841378110499e-07, 'rewards/chosen': -1.2502671480178833, 'rewards/rejected': -1.8438657522201538, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5935989022254944, 'policy_logps/rejected': -438.8758544921875, 'policy_logps/chosen': -340.97998046875, 'referece_logps/rejected': -420.4371643066406, 'referece_logps/chosen': -328.477294921875, 'logits/rejected': 0.1284504234790802, 'logits/chosen': 0.0774708166718483, 'epoch': 3.49}


 58%|█████▊    | 9375/16104 [43:06:05<28:39:40, 15.33s/it]
{'loss': 0.3388, 'learning_rate': 7.842913377130614e-07, 'rewards/chosen': -1.034144639968872, 'rewards/rejected': -2.2317488193511963, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1976042985916138, 'policy_logps/rejected': -405.7789306640625, 'policy_logps/chosen': -471.1083984375, 'referece_logps/rejected': -383.46148681640625, 'referece_logps/chosen': -460.7669677734375, 'logits/rejected': -0.5621504187583923, 'logits/chosen': -0.4427683651447296, 'epoch': 3.49}


 58%|█████▊    | 9377/16104 [43:06:27<24:36:43, 13.17s/it]

 58%|█████▊    | 9378/16104 [43:06:38<23:10:49, 12.41s/it]
{'loss': 0.4253, 'learning_rate': 7.837022030294411e-07, 'rewards/chosen': -1.7923513650894165, 'rewards/rejected': -2.3703579902648926, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5780068635940552, 'policy_logps/rejected': -353.057861328125, 'policy_logps/chosen': -311.5509948730469, 'referece_logps/rejected': -329.35430908203125, 'referece_logps/chosen': -293.62750244140625, 'logits/rejected': -0.296833336353302, 'logits/chosen': -0.1455470621585846, 'epoch': 3.49}


 58%|█████▊    | 9380/16104 [43:06:59<21:26:40, 11.48s/it]

 58%|█████▊    | 9381/16104 [43:07:17<25:02:17, 13.41s/it]

 58%|█████▊    | 9382/16104 [43:07:35<27:47:03, 14.88s/it]
{'loss': 0.3146, 'learning_rate': 7.829168126498579e-07, 'rewards/chosen': -1.7257858514785767, 'rewards/rejected': -3.837942123413086, 'rewards/accuracies': 0.75, 'rewards/margins': 2.112156391143799, 'policy_logps/rejected': -260.7105407714844, 'policy_logps/chosen': -322.39654541015625, 'referece_logps/rejected': -222.33114624023438, 'referece_logps/chosen': -305.1387023925781, 'logits/rejected': -0.3150099515914917, 'logits/chosen': -0.3426485061645508, 'epoch': 3.5}


 58%|█████▊    | 9384/16104 [43:08:07<29:16:33, 15.68s/it]

 58%|█████▊    | 9385/16104 [43:08:29<32:50:36, 17.60s/it]
{'loss': 0.2705, 'learning_rate': 7.823278620420939e-07, 'rewards/chosen': -1.0694677829742432, 'rewards/rejected': -3.9324870109558105, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8630192279815674, 'policy_logps/rejected': -347.6785888671875, 'policy_logps/chosen': -394.59765625, 'referece_logps/rejected': -308.3537292480469, 'referece_logps/chosen': -383.9029846191406, 'logits/rejected': -1.1385270357131958, 'logits/chosen': -0.878182053565979, 'epoch': 3.5}


 58%|█████▊    | 9387/16104 [43:08:57<29:01:43, 15.56s/it]

 58%|█████▊    | 9388/16104 [43:09:10<27:25:04, 14.70s/it]

 58%|█████▊    | 9389/16104 [43:09:26<28:07:59, 15.08s/it]
{'loss': 0.3732, 'learning_rate': 7.815427178752975e-07, 'rewards/chosen': -0.9981575012207031, 'rewards/rejected': -3.147313117980957, 'rewards/accuracies': 1.0, 'rewards/margins': 2.149155616760254, 'policy_logps/rejected': -254.13076782226562, 'policy_logps/chosen': -299.7796936035156, 'referece_logps/rejected': -222.65765380859375, 'referece_logps/chosen': -289.7981262207031, 'logits/rejected': -0.08815046399831772, 'logits/chosen': -0.09851662069559097, 'epoch': 3.5}

 58%|█████▊    | 9390/16104 [43:09:48<32:09:38, 17.24s/it]

 58%|█████▊    | 9391/16104 [43:10:08<33:41:41, 18.07s/it]

 58%|█████▊    | 9392/16104 [43:10:20<30:13:32, 16.21s/it]


 58%|█████▊    | 9394/16104 [43:10:55<31:48:39, 17.07s/it]

 58%|█████▊    | 9395/16104 [43:11:15<33:13:16, 17.83s/it]

 58%|█████▊    | 9396/16104 [43:11:34<33:51:16, 18.17s/it]

 58%|█████▊    | 9397/16104 [43:11:54<34:45:38, 18.66s/it]

 58%|█████▊    | 9398/16104 [43:12:13<35:13:59, 18.91s/it]
{'loss': 0.3987, 'learning_rate': 7.797766612377268e-07, 'rewards/chosen': -1.8131260871887207, 'rewards/rejected': -3.616698741912842, 'rewards/accuracies': 0.75, 'rewards/margins': 1.803572416305542, 'policy_logps/rejected': -570.2179565429688, 'policy_logps/chosen': -525.6217041015625, 'referece_logps/rejected': -534.0509643554688, 'referece_logps/chosen': -507.4904479980469, 'logits/rejected': 0.06726871430873871, 'logits/chosen': -0.08043371140956879, 'epoch': 3.5}

 58%|█████▊    | 9399/16104 [43:12:30<34:13:06, 18.37s/it]


 58%|█████▊    | 9401/16104 [43:13:08<34:32:20, 18.55s/it]

 58%|█████▊    | 9402/16104 [43:13:22<31:42:04, 17.03s/it]
{'loss': 0.4411, 'learning_rate': 7.789919784517393e-07, 'rewards/chosen': -1.1682531833648682, 'rewards/rejected': -3.545456647872925, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3772032260894775, 'policy_logps/rejected': -484.91680908203125, 'policy_logps/chosen': -548.3447875976562, 'referece_logps/rejected': -449.462158203125, 'referece_logps/chosen': -536.6621704101562, 'logits/rejected': 0.0040160780772566795, 'logits/chosen': -0.0410369411110878, 'epoch': 3.5}


 58%|█████▊    | 9404/16104 [43:13:52<29:56:08, 16.08s/it]
{'loss': 0.3352, 'learning_rate': 7.785996906680181e-07, 'rewards/chosen': -1.5093629360198975, 'rewards/rejected': -3.2987265586853027, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7893640995025635, 'policy_logps/rejected': -363.039794921875, 'policy_logps/chosen': -243.56436157226562, 'referece_logps/rejected': -330.0525207519531, 'referece_logps/chosen': -228.47073364257812, 'logits/rejected': -1.231677770614624, 'logits/chosen': -1.1672145128250122, 'epoch': 3.5}


 58%|█████▊    | 9406/16104 [43:14:26<31:16:00, 16.81s/it]
{'loss': 0.2992, 'learning_rate': 7.782074387084467e-07, 'rewards/chosen': -1.590165615081787, 'rewards/rejected': -4.486892223358154, 'rewards/accuracies': 1.0, 'rewards/margins': 2.896726131439209, 'policy_logps/rejected': -293.498046875, 'policy_logps/chosen': -327.1931457519531, 'referece_logps/rejected': -248.62911987304688, 'referece_logps/chosen': -311.29150390625, 'logits/rejected': -0.2738437354564667, 'logits/chosen': -0.3138090670108795, 'epoch': 3.5}


 58%|█████▊    | 9408/16104 [43:14:57<29:43:10, 15.98s/it]

 58%|█████▊    | 9409/16104 [43:15:08<26:47:14, 14.40s/it]

 58%|█████▊    | 9410/16104 [43:15:20<25:27:22, 13.69s/it]
{'loss': 0.3229, 'learning_rate': 7.774230425156247e-07, 'rewards/chosen': -1.735454797744751, 'rewards/rejected': -2.615394115447998, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8799395561218262, 'policy_logps/rejected': -483.64239501953125, 'policy_logps/chosen': -398.5323486328125, 'referece_logps/rejected': -457.48846435546875, 'referece_logps/chosen': -381.1777648925781, 'logits/rejected': -0.17891345918178558, 'logits/chosen': -0.0627155601978302, 'epoch': 3.51}

 58%|█████▊    | 9411/16104 [43:15:31<23:54:05, 12.86s/it]


 58%|█████▊    | 9413/16104 [43:16:10<30:24:28, 16.36s/it]

 58%|█████▊    | 9414/16104 [43:16:28<31:17:01, 16.83s/it]

 58%|█████▊    | 9415/16104 [43:16:43<30:35:40, 16.47s/it]
{'loss': 0.2699, 'learning_rate': 7.764427499158627e-07, 'rewards/chosen': -3.5393450260162354, 'rewards/rejected': -5.9469895362854, 'rewards/accuracies': 0.875, 'rewards/margins': 2.407644271850586, 'policy_logps/rejected': -618.9898681640625, 'policy_logps/chosen': -509.935302734375, 'referece_logps/rejected': -559.5199584960938, 'referece_logps/chosen': -474.5418701171875, 'logits/rejected': -0.6663535237312317, 'logits/chosen': -0.5910118818283081, 'epoch': 3.51}


 58%|█████▊    | 9417/16104 [43:17:18<30:52:38, 16.62s/it]
{'loss': 0.2719, 'learning_rate': 7.760506961234719e-07, 'rewards/chosen': -2.193845510482788, 'rewards/rejected': -6.00242280960083, 'rewards/accuracies': 0.875, 'rewards/margins': 3.808577537536621, 'policy_logps/rejected': -521.5552978515625, 'policy_logps/chosen': -406.7625732421875, 'referece_logps/rejected': -461.5310974121094, 'referece_logps/chosen': -384.8240966796875, 'logits/rejected': -0.6473632454872131, 'logits/chosen': -0.49374914169311523, 'epoch': 3.51}

 58%|█████▊    | 9418/16104 [43:17:35<31:10:53, 16.79s/it]


 58%|█████▊    | 9420/16104 [43:18:13<33:14:43, 17.91s/it]

 59%|█████▊    | 9421/16104 [43:18:34<34:57:54, 18.83s/it]

 59%|█████▊    | 9422/16104 [43:18:50<33:37:39, 18.12s/it]

 59%|█████▊    | 9423/16104 [43:19:10<34:51:54, 18.79s/it]
{'loss': 0.4239, 'learning_rate': 7.748747524195917e-07, 'rewards/chosen': -1.8152633905410767, 'rewards/rejected': -3.1919972896575928, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3767337799072266, 'policy_logps/rejected': -297.6457214355469, 'policy_logps/chosen': -286.76239013671875, 'referece_logps/rejected': -265.7257080078125, 'referece_logps/chosen': -268.6097412109375, 'logits/rejected': -0.6518176198005676, 'logits/chosen': -0.7573812007904053, 'epoch': 3.51}

 59%|█████▊    | 9424/16104 [43:19:27<33:53:38, 18.27s/it]

 59%|█████▊    | 9425/16104 [43:19:47<34:48:12, 18.76s/it]

 59%|█████▊    | 9426/16104 [43:19:59<31:04:10, 16.75s/it]


 59%|█████▊    | 9428/16104 [43:20:29<30:05:00, 16.22s/it]

 59%|█████▊    | 9429/16104 [43:20:46<30:09:57, 16.27s/it]

 59%|█████▊    | 9430/16104 [43:21:03<30:29:27, 16.45s/it]

 59%|█████▊    | 9431/16104 [43:21:16<28:30:04, 15.38s/it]
{'loss': 0.2185, 'learning_rate': 7.73307337753149e-07, 'rewards/chosen': -1.6527655124664307, 'rewards/rejected': -4.489284515380859, 'rewards/accuracies': 0.875, 'rewards/margins': 2.8365187644958496, 'policy_logps/rejected': -335.95135498046875, 'policy_logps/chosen': -402.62823486328125, 'referece_logps/rejected': -291.05853271484375, 'referece_logps/chosen': -386.1006164550781, 'logits/rejected': -0.046007607132196426, 'logits/chosen': 0.08390414714813232, 'epoch': 3.51}


 59%|█████▊    | 9433/16104 [43:21:45<27:06:12, 14.63s/it]

 59%|█████▊    | 9434/16104 [43:22:04<29:35:09, 15.97s/it]

 59%|█████▊    | 9435/16104 [43:22:21<30:09:44, 16.28s/it]

 59%|█████▊    | 9436/16104 [43:22:40<31:40:50, 17.10s/it]

 59%|█████▊    | 9437/16104 [43:22:59<32:48:09, 17.71s/it]

 59%|█████▊    | 9438/16104 [43:23:16<32:31:29, 17.57s/it]

 59%|█████▊    | 9439/16104 [43:23:33<31:56:43, 17.25s/it]

 59%|█████▊    | 9440/16104 [43:23:46<29:54:51, 16.16s/it]

 59%|█████▊    | 9441/16104 [43:24:06<31:47:11, 17.17s/it]
{'loss': 0.3254, 'learning_rate': 7.713488952063555e-07, 'rewards/chosen': -2.8723349571228027, 'rewards/rejected': -5.839263439178467, 'rewards/accuracies': 0.875, 'rewards/margins': 2.966928482055664, 'policy_logps/rejected': -526.3057861328125, 'policy_logps/chosen': -469.7572021484375, 'referece_logps/rejected': -467.9130859375, 'referece_logps/chosen': -441.03387451171875, 'logits/rejected': -0.7650237679481506, 'logits/chosen': -0.775154173374176, 'epoch': 3.52}

 59%|█████▊    | 9442/16104 [43:24:23<32:04:46, 17.34s/it]


 59%|█████▊    | 9444/16104 [43:25:02<34:09:09, 18.46s/it]

 59%|█████▊    | 9445/16104 [43:25:16<31:38:19, 17.10s/it]

 59%|█████▊    | 9446/16104 [43:25:36<33:17:24, 18.00s/it]
{'loss': 0.3228, 'learning_rate': 7.703700202882941e-07, 'rewards/chosen': -3.0535640716552734, 'rewards/rejected': -4.249970436096191, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1964064836502075, 'policy_logps/rejected': -374.71514892578125, 'policy_logps/chosen': -413.0960693359375, 'referece_logps/rejected': -332.2154541015625, 'referece_logps/chosen': -382.5603942871094, 'logits/rejected': -0.7587637305259705, 'logits/chosen': -0.7533442378044128, 'epoch': 3.52}

 59%|█████▊    | 9447/16104 [43:25:48<29:43:10, 16.07s/it]

 59%|█████▊    | 9448/16104 [43:26:07<31:44:33, 17.17s/it]

 59%|█████▊    | 9449/16104 [43:26:21<30:03:33, 16.26s/it]


 59%|█████▊    | 9451/16104 [43:26:53<28:48:47, 15.59s/it]

 59%|█████▊    | 9452/16104 [43:27:09<29:01:35, 15.71s/it]

 59%|█████▊    | 9453/16104 [43:27:27<30:18:16, 16.40s/it]

 59%|█████▊    | 9454/16104 [43:27:45<31:10:34, 16.88s/it]
{'loss': 0.3685, 'learning_rate': 7.688043038560876e-07, 'rewards/chosen': -1.7725889682769775, 'rewards/rejected': -4.011134624481201, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2385454177856445, 'policy_logps/rejected': -426.58258056640625, 'policy_logps/chosen': -334.9324035644531, 'referece_logps/rejected': -386.47125244140625, 'referece_logps/chosen': -317.2065124511719, 'logits/rejected': -0.5592302680015564, 'logits/chosen': -0.44042202830314636, 'epoch': 3.52}

 59%|█████▊    | 9455/16104 [43:28:04<32:18:08, 17.49s/it]


 59%|█████▊    | 9457/16104 [43:28:34<29:29:28, 15.97s/it]
{'loss': 0.3914, 'learning_rate': 7.682173142889038e-07, 'rewards/chosen': -2.353916645050049, 'rewards/rejected': -3.9535553455352783, 'rewards/accuracies': 0.875, 'rewards/margins': 1.59963858127594, 'policy_logps/rejected': -406.1400146484375, 'policy_logps/chosen': -344.7810974121094, 'referece_logps/rejected': -366.60443115234375, 'referece_logps/chosen': -321.241943359375, 'logits/rejected': -0.5730574131011963, 'logits/chosen': -0.41496986150741577, 'epoch': 3.52}

 59%|█████▊    | 9458/16104 [43:28:50<29:13:05, 15.83s/it]

 59%|█████▊    | 9459/16104 [43:29:04<28:09:28, 15.25s/it]

 59%|█████▊    | 9460/16104 [43:29:23<30:33:38, 16.56s/it]


 59%|█████▉    | 9462/16104 [43:29:45<24:57:18, 13.53s/it]
{'loss': 0.3497, 'learning_rate': 7.672391859695763e-07, 'rewards/chosen': -1.6450575590133667, 'rewards/rejected': -3.63045334815979, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9853956699371338, 'policy_logps/rejected': -371.65460205078125, 'policy_logps/chosen': -392.6459045410156, 'referece_logps/rejected': -335.35009765625, 'referece_logps/chosen': -376.1953430175781, 'logits/rejected': -0.7395790815353394, 'logits/chosen': -0.45099636912345886, 'epoch': 3.53}


 59%|█████▉    | 9464/16104 [43:30:06<22:18:07, 12.09s/it]

 59%|█████▉    | 9465/16104 [43:30:22<24:33:45, 13.32s/it]
{'loss': 0.393, 'learning_rate': 7.666524219017567e-07, 'rewards/chosen': -2.227926015853882, 'rewards/rejected': -3.9768412113189697, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7489153146743774, 'policy_logps/rejected': -429.74798583984375, 'policy_logps/chosen': -442.4974365234375, 'referece_logps/rejected': -389.9795837402344, 'referece_logps/chosen': -420.2181091308594, 'logits/rejected': -1.1491572856903076, 'logits/chosen': -1.286828637123108, 'epoch': 3.53}


 59%|█████▉    | 9467/16104 [43:30:47<23:42:27, 12.86s/it]

 59%|█████▉    | 9468/16104 [43:30:57<22:28:28, 12.19s/it]

 59%|█████▉    | 9469/16104 [43:31:11<23:07:11, 12.54s/it]

 59%|█████▉    | 9470/16104 [43:31:27<25:23:23, 13.78s/it]

 59%|█████▉    | 9471/16104 [43:31:41<25:08:09, 13.64s/it]

 59%|█████▉    | 9472/16104 [43:31:57<26:48:34, 14.55s/it]
{'loss': 0.2665, 'learning_rate': 7.65283636489073e-07, 'rewards/chosen': -2.3709802627563477, 'rewards/rejected': -3.0839297771453857, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7129495143890381, 'policy_logps/rejected': -274.5209655761719, 'policy_logps/chosen': -340.9078674316406, 'referece_logps/rejected': -243.68165588378906, 'referece_logps/chosen': -317.1980895996094, 'logits/rejected': -0.8695404529571533, 'logits/chosen': -1.2560421228408813, 'epoch': 3.53}

 59%|█████▉    | 9473/16104 [43:32:10<25:45:25, 13.98s/it]


 59%|█████▉    | 9475/16104 [43:32:37<25:14:54, 13.71s/it]
{'loss': 0.3544, 'learning_rate': 7.64697156431598e-07, 'rewards/chosen': -2.6597118377685547, 'rewards/rejected': -3.168194532394409, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5084825754165649, 'policy_logps/rejected': -459.5330505371094, 'policy_logps/chosen': -451.8080139160156, 'referece_logps/rejected': -427.85113525390625, 'referece_logps/chosen': -425.2109069824219, 'logits/rejected': -0.48066776990890503, 'logits/chosen': -0.3770243525505066, 'epoch': 3.53}

 59%|█████▉    | 9476/16104 [43:32:54<27:02:55, 14.69s/it]

 59%|█████▉    | 9477/16104 [43:33:14<29:45:21, 16.16s/it]


 59%|█████▉    | 9479/16104 [43:33:43<27:57:19, 15.19s/it]

 59%|█████▉    | 9480/16104 [43:34:00<28:42:13, 15.60s/it]
{'loss': 0.3369, 'learning_rate': 7.637198801429592e-07, 'rewards/chosen': -1.547585368156433, 'rewards/rejected': -3.8214826583862305, 'rewards/accuracies': 0.875, 'rewards/margins': 2.273897171020508, 'policy_logps/rejected': -548.9216918945312, 'policy_logps/chosen': -450.0791015625, 'referece_logps/rejected': -510.7069091796875, 'referece_logps/chosen': -434.6032409667969, 'logits/rejected': -1.0756139755249023, 'logits/chosen': -1.0917093753814697, 'epoch': 3.53}

 59%|█████▉    | 9481/16104 [43:34:12<27:06:28, 14.73s/it]

 59%|█████▉    | 9482/16104 [43:34:24<25:30:56, 13.87s/it]


 59%|█████▉    | 9484/16104 [43:34:55<27:24:04, 14.90s/it]

 59%|█████▉    | 9485/16104 [43:35:13<29:02:33, 15.80s/it]

 59%|█████▉    | 9486/16104 [43:35:29<29:13:58, 15.90s/it]

 59%|█████▉    | 9487/16104 [43:35:49<31:16:51, 17.02s/it]
{'loss': 0.2851, 'learning_rate': 7.623520949941737e-07, 'rewards/chosen': -1.4689738750457764, 'rewards/rejected': -3.826950788497925, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3579769134521484, 'policy_logps/rejected': -256.6484680175781, 'policy_logps/chosen': -254.33363342285156, 'referece_logps/rejected': -218.3789825439453, 'referece_logps/chosen': -239.64390563964844, 'logits/rejected': -1.394627571105957, 'logits/chosen': -1.2616313695907593, 'epoch': 3.53}


 59%|█████▉    | 9489/16104 [43:36:25<32:14:00, 17.54s/it]

 59%|█████▉    | 9490/16104 [43:36:38<29:18:35, 15.95s/it]
{'loss': 0.2707, 'learning_rate': 7.61766045400133e-07, 'rewards/chosen': -1.662363886833191, 'rewards/rejected': -3.7125675678253174, 'rewards/accuracies': 0.875, 'rewards/margins': 2.050203561782837, 'policy_logps/rejected': -487.7945556640625, 'policy_logps/chosen': -557.847900390625, 'referece_logps/rejected': -450.6688537597656, 'referece_logps/chosen': -541.2242431640625, 'logits/rejected': -0.6643189191818237, 'logits/chosen': -0.7676095962524414, 'epoch': 3.54}

 59%|█████▉    | 9491/16104 [43:36:52<28:18:09, 15.41s/it]

 59%|█████▉    | 9492/16104 [43:37:02<25:43:58, 14.01s/it]

 59%|█████▉    | 9493/16104 [43:37:23<29:10:35, 15.89s/it]

 59%|█████▉    | 9494/16104 [43:37:43<31:27:44, 17.14s/it]


 59%|█████▉    | 9496/16104 [43:38:12<29:20:38, 15.99s/it]
{'loss': 0.4586, 'learning_rate': 7.60594206624066e-07, 'rewards/chosen': -2.009394407272339, 'rewards/rejected': -2.9248645305633545, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9154700040817261, 'policy_logps/rejected': -405.5619201660156, 'policy_logps/chosen': -342.97955322265625, 'referece_logps/rejected': -376.3132629394531, 'referece_logps/chosen': -322.8856201171875, 'logits/rejected': 0.5037484169006348, 'logits/chosen': 0.4273611307144165, 'epoch': 3.54}

 59%|█████▉    | 9497/16104 [43:38:31<31:11:22, 16.99s/it]

 59%|█████▉    | 9498/16104 [43:38:42<27:56:07, 15.22s/it]

 59%|█████▉    | 9499/16104 [43:39:03<31:00:20, 16.90s/it]

 59%|█████▉    | 9500/16104 [43:39:23<32:28:03, 17.70s/it]


 59%|█████▉    | 9502/16104 [43:40:16<39:13:42, 21.39s/it]
{'loss': 0.308, 'learning_rate': 7.594227164860543e-07, 'rewards/chosen': -1.5359084606170654, 'rewards/rejected': -3.1623411178588867, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6264326572418213, 'policy_logps/rejected': -443.6030578613281, 'policy_logps/chosen': -466.3583679199219, 'referece_logps/rejected': -411.97967529296875, 'referece_logps/chosen': -450.999267578125, 'logits/rejected': -0.3959304094314575, 'logits/chosen': -0.48336729407310486, 'epoch': 3.54}


 59%|█████▉    | 9504/16104 [43:40:52<35:53:42, 19.58s/it]
{'loss': 0.3421, 'learning_rate': 7.590322975433856e-07, 'rewards/chosen': -2.1768839359283447, 'rewards/rejected': -5.0747857093811035, 'rewards/accuracies': 0.875, 'rewards/margins': 2.8979015350341797, 'policy_logps/rejected': -471.3507080078125, 'policy_logps/chosen': -483.7234802246094, 'referece_logps/rejected': -420.60284423828125, 'referece_logps/chosen': -461.9546203613281, 'logits/rejected': 0.011571932584047318, 'logits/chosen': -0.20861181616783142, 'epoch': 3.54}


 59%|█████▉    | 9506/16104 [43:41:30<35:03:47, 19.13s/it]

 59%|█████▉    | 9507/16104 [43:41:52<36:27:53, 19.90s/it]
{'loss': 0.307, 'learning_rate': 7.584467422559233e-07, 'rewards/chosen': -2.170707941055298, 'rewards/rejected': -4.085225582122803, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9145174026489258, 'policy_logps/rejected': -340.2388000488281, 'policy_logps/chosen': -332.3643493652344, 'referece_logps/rejected': -299.3865661621094, 'referece_logps/chosen': -310.6572265625, 'logits/rejected': -0.36727166175842285, 'logits/chosen': -0.4801994562149048, 'epoch': 3.54}

 59%|█████▉    | 9508/16104 [43:42:11<36:07:18, 19.71s/it]

 59%|█████▉    | 9509/16104 [43:42:31<36:09:39, 19.74s/it]

 59%|█████▉    | 9510/16104 [43:42:48<34:52:37, 19.04s/it]


 59%|█████▉    | 9512/16104 [43:43:20<31:52:35, 17.41s/it]
{'loss': 0.3902, 'learning_rate': 7.57471012307281e-07, 'rewards/chosen': -1.3835465908050537, 'rewards/rejected': -3.1384220123291016, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7548754215240479, 'policy_logps/rejected': -259.398193359375, 'policy_logps/chosen': -230.6474609375, 'referece_logps/rejected': -228.0139617919922, 'referece_logps/chosen': -216.81201171875, 'logits/rejected': -0.887179434299469, 'logits/chosen': -0.8624027371406555, 'epoch': 3.54}

 59%|█████▉    | 9513/16104 [43:43:39<32:40:29, 17.85s/it]


 59%|█████▉    | 9515/16104 [43:44:10<31:13:40, 17.06s/it]
{'loss': 0.247, 'learning_rate': 7.568856920037085e-07, 'rewards/chosen': -1.187955379486084, 'rewards/rejected': -4.736058712005615, 'rewards/accuracies': 0.875, 'rewards/margins': 3.5481035709381104, 'policy_logps/rejected': -363.2405090332031, 'policy_logps/chosen': -476.63677978515625, 'referece_logps/rejected': -315.87994384765625, 'referece_logps/chosen': -464.75726318359375, 'logits/rejected': -1.1602530479431152, 'logits/chosen': -1.2783749103546143, 'epoch': 3.55}

 59%|█████▉    | 9516/16104 [43:44:30<33:03:09, 18.06s/it]

 59%|█████▉    | 9517/16104 [43:44:43<30:11:20, 16.50s/it]

 59%|█████▉    | 9518/16104 [43:44:59<30:04:23, 16.44s/it]


 59%|█████▉    | 9520/16104 [43:45:30<29:44:57, 16.27s/it]
{'loss': 0.2925, 'learning_rate': 7.559103549577852e-07, 'rewards/chosen': -1.3143129348754883, 'rewards/rejected': -3.3392951488494873, 'rewards/accuracies': 0.875, 'rewards/margins': 2.02498197555542, 'policy_logps/rejected': -361.20001220703125, 'policy_logps/chosen': -404.1434326171875, 'referece_logps/rejected': -327.80706787109375, 'referece_logps/chosen': -391.00030517578125, 'logits/rejected': -0.5736175775527954, 'logits/chosen': -0.643783688545227, 'epoch': 3.55}


 59%|█████▉    | 9522/16104 [43:46:02<29:25:08, 16.09s/it]
{'loss': 0.1697, 'learning_rate': 7.555202892012149e-07, 'rewards/chosen': -1.7603774070739746, 'rewards/rejected': -3.9701249599456787, 'rewards/accuracies': 1.0, 'rewards/margins': 2.209747552871704, 'policy_logps/rejected': -256.46173095703125, 'policy_logps/chosen': -398.5953369140625, 'referece_logps/rejected': -216.76046752929688, 'referece_logps/chosen': -380.9915771484375, 'logits/rejected': -0.30960580706596375, 'logits/chosen': -0.39726343750953674, 'epoch': 3.55}

 59%|█████▉    | 9523/16104 [43:46:19<29:56:06, 16.38s/it]

 59%|█████▉    | 9524/16104 [43:46:41<32:42:56, 17.90s/it]


 59%|█████▉    | 9526/16104 [43:47:06<27:59:19, 15.32s/it]

 59%|█████▉    | 9527/16104 [43:47:28<31:32:20, 17.26s/it]
{'loss': 0.5638, 'learning_rate': 7.545452980165463e-07, 'rewards/chosen': -1.7826862335205078, 'rewards/rejected': -2.6119155883789062, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8292293548583984, 'policy_logps/rejected': -598.839599609375, 'policy_logps/chosen': -480.25299072265625, 'referece_logps/rejected': -572.720458984375, 'referece_logps/chosen': -462.42608642578125, 'logits/rejected': -0.4704861640930176, 'logits/chosen': -0.48192429542541504, 'epoch': 3.55}

 59%|█████▉    | 9528/16104 [43:47:45<31:43:22, 17.37s/it]

 59%|█████▉    | 9529/16104 [43:48:05<32:58:02, 18.05s/it]


 59%|█████▉    | 9531/16104 [43:48:40<31:49:32, 17.43s/it]
{'loss': 0.3986, 'learning_rate': 7.537654837449306e-07, 'rewards/chosen': -1.6200780868530273, 'rewards/rejected': -3.0330281257629395, 'rewards/accuracies': 0.875, 'rewards/margins': 1.412950038909912, 'policy_logps/rejected': -403.0205078125, 'policy_logps/chosen': -340.9900207519531, 'referece_logps/rejected': -372.69024658203125, 'referece_logps/chosen': -324.78924560546875, 'logits/rejected': -0.47243303060531616, 'logits/chosen': -0.2274133861064911, 'epoch': 3.55}


 59%|█████▉    | 9533/16104 [43:49:12<30:11:16, 16.54s/it]
{'loss': 0.3681, 'learning_rate': 7.533756363413321e-07, 'rewards/chosen': -2.0416488647460938, 'rewards/rejected': -3.2163450717926025, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1746963262557983, 'policy_logps/rejected': -304.6417236328125, 'policy_logps/chosen': -324.6613464355469, 'referece_logps/rejected': -272.478271484375, 'referece_logps/chosen': -304.244873046875, 'logits/rejected': -0.3653494119644165, 'logits/chosen': -0.45300716161727905, 'epoch': 3.55}

 59%|█████▉    | 9534/16104 [43:49:32<31:33:08, 17.29s/it]

 59%|█████▉    | 9535/16104 [43:49:51<32:36:07, 17.87s/it]

 59%|█████▉    | 9536/16104 [43:50:11<33:44:47, 18.50s/it]


 59%|█████▉    | 9538/16104 [43:50:32<26:37:33, 14.60s/it]

 59%|█████▉    | 9539/16104 [43:50:50<28:30:35, 15.63s/it]
{'loss': 0.3789, 'learning_rate': 7.522063338163172e-07, 'rewards/chosen': -1.9229217767715454, 'rewards/rejected': -3.644543170928955, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7216212749481201, 'policy_logps/rejected': -574.25341796875, 'policy_logps/chosen': -396.0340576171875, 'referece_logps/rejected': -537.8080444335938, 'referece_logps/chosen': -376.80487060546875, 'logits/rejected': 0.8857268691062927, 'logits/chosen': 0.9331154823303223, 'epoch': 3.55}

 59%|█████▉    | 9540/16104 [43:51:07<28:48:58, 15.80s/it]

 59%|█████▉    | 9541/16104 [43:51:19<27:02:20, 14.83s/it]

 59%|█████▉    | 9542/16104 [43:51:35<27:43:00, 15.21s/it]

 59%|█████▉    | 9543/16104 [43:51:49<27:03:45, 14.85s/it]


 59%|█████▉    | 9545/16104 [43:52:19<26:36:01, 14.60s/it]
{'loss': 0.3446, 'learning_rate': 7.510373921443148e-07, 'rewards/chosen': -2.0168991088867188, 'rewards/rejected': -3.165940761566162, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1490418910980225, 'policy_logps/rejected': -386.189208984375, 'policy_logps/chosen': -404.7978515625, 'referece_logps/rejected': -354.52978515625, 'referece_logps/chosen': -384.62884521484375, 'logits/rejected': -0.7487860321998596, 'logits/chosen': -0.6616557836532593, 'epoch': 3.56}


 59%|█████▉    | 9547/16104 [43:52:46<26:07:37, 14.34s/it]

 59%|█████▉    | 9548/16104 [43:53:05<28:15:00, 15.51s/it]

 59%|█████▉    | 9549/16104 [43:53:24<30:34:52, 16.80s/it]
{'loss': 0.3132, 'learning_rate': 7.502582990108669e-07, 'rewards/chosen': -2.5348832607269287, 'rewards/rejected': -4.043222427368164, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5083391666412354, 'policy_logps/rejected': -347.3024597167969, 'policy_logps/chosen': -403.3688659667969, 'referece_logps/rejected': -306.8702392578125, 'referece_logps/chosen': -378.02001953125, 'logits/rejected': -0.42040297389030457, 'logits/chosen': -0.41879189014434814, 'epoch': 3.56}


 59%|█████▉    | 9551/16104 [43:54:00<31:29:00, 17.30s/it]
{'loss': 0.291, 'learning_rate': 7.498688130276131e-07, 'rewards/chosen': -2.2072157859802246, 'rewards/rejected': -3.5604171752929688, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3532015085220337, 'policy_logps/rejected': -294.42816162109375, 'policy_logps/chosen': -271.857421875, 'referece_logps/rejected': -258.823974609375, 'referece_logps/chosen': -249.78524780273438, 'logits/rejected': -0.2832609713077545, 'logits/chosen': -0.4449648857116699, 'epoch': 3.56}

 59%|█████▉    | 9552/16104 [43:54:14<29:12:39, 16.05s/it]

 59%|█████▉    | 9553/16104 [43:54:34<31:27:02, 17.28s/it]

 59%|█████▉    | 9554/16104 [43:54:56<33:52:52, 18.62s/it]

 59%|█████▉    | 9555/16104 [43:55:09<31:15:57, 17.19s/it]

 59%|█████▉    | 9556/16104 [43:55:25<30:22:16, 16.70s/it]

 59%|█████▉    | 9557/16104 [43:55:38<28:32:04, 15.69s/it]

 59%|█████▉    | 9558/16104 [43:55:56<29:37:49, 16.30s/it]

 59%|█████▉    | 9559/16104 [43:56:16<31:44:30, 17.46s/it]

 59%|█████▉    | 9560/16104 [43:56:36<33:02:17, 18.18s/it]

 59%|█████▉    | 9561/16104 [43:56:58<35:07:54, 19.33s/it]


 59%|█████▉    | 9563/16104 [43:57:29<31:44:35, 17.47s/it]
{'loss': 0.2688, 'learning_rate': 7.475327492666204e-07, 'rewards/chosen': -1.6398322582244873, 'rewards/rejected': -3.498295783996582, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8584635257720947, 'policy_logps/rejected': -363.20849609375, 'policy_logps/chosen': -497.84149169921875, 'referece_logps/rejected': -328.2254943847656, 'referece_logps/chosen': -481.443115234375, 'logits/rejected': 0.8527034521102905, 'logits/chosen': 1.0486986637115479, 'epoch': 3.56}

 59%|█████▉    | 9564/16104 [43:57:49<33:12:08, 18.28s/it]

 59%|█████▉    | 9565/16104 [43:58:08<33:29:56, 18.44s/it]

 59%|█████▉    | 9566/16104 [43:58:20<30:06:47, 16.58s/it]


 59%|█████▉    | 9568/16104 [43:58:49<27:22:54, 15.08s/it]
{'loss': 0.4319, 'learning_rate': 7.46559822627283e-07, 'rewards/chosen': -1.3168617486953735, 'rewards/rejected': -2.432800531387329, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1159387826919556, 'policy_logps/rejected': -561.2445068359375, 'policy_logps/chosen': -483.09051513671875, 'referece_logps/rejected': -536.9165649414062, 'referece_logps/chosen': -469.921875, 'logits/rejected': 0.35211825370788574, 'logits/chosen': 0.5636744499206543, 'epoch': 3.56}


 59%|█████▉    | 9570/16104 [43:59:15<25:42:38, 14.17s/it]
{'loss': 0.4457, 'learning_rate': 7.461707236812041e-07, 'rewards/chosen': -2.157315731048584, 'rewards/rejected': -3.861646890640259, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7043311595916748, 'policy_logps/rejected': -394.4781494140625, 'policy_logps/chosen': -373.493896484375, 'referece_logps/rejected': -355.86163330078125, 'referece_logps/chosen': -351.9207458496094, 'logits/rejected': -0.30571749806404114, 'logits/chosen': -0.15956787765026093, 'epoch': 3.57}

 59%|█████▉    | 9571/16104 [43:59:25<23:53:21, 13.16s/it]

 59%|█████▉    | 9572/16104 [43:59:44<26:42:52, 14.72s/it]


 59%|█████▉    | 9574/16104 [44:00:19<29:09:03, 16.07s/it]

 59%|█████▉    | 9575/16104 [44:00:33<28:11:08, 15.54s/it]
{'loss': 0.3598, 'learning_rate': 7.451981561410366e-07, 'rewards/chosen': -1.6017128229141235, 'rewards/rejected': -3.318998098373413, 'rewards/accuracies': 0.375, 'rewards/margins': 1.717285394668579, 'policy_logps/rejected': -343.73126220703125, 'policy_logps/chosen': -388.05303955078125, 'referece_logps/rejected': -310.5412902832031, 'referece_logps/chosen': -372.03582763671875, 'logits/rejected': -0.9320055246353149, 'logits/chosen': -0.9041954278945923, 'epoch': 3.57}

 59%|█████▉    | 9576/16104 [44:00:50<29:13:57, 16.12s/it]

 59%|█████▉    | 9577/16104 [44:01:10<31:08:38, 17.18s/it]

 59%|█████▉    | 9578/16104 [44:01:26<30:44:56, 16.96s/it]

 59%|█████▉    | 9579/16104 [44:01:49<33:34:43, 18.53s/it]


 59%|█████▉    | 9581/16104 [44:02:19<29:39:44, 16.37s/it]
{'loss': 0.4202, 'learning_rate': 7.44031415316588e-07, 'rewards/chosen': -1.7384263277053833, 'rewards/rejected': -2.1866939067840576, 'rewards/accuracies': 0.75, 'rewards/margins': 0.44826772809028625, 'policy_logps/rejected': -322.2166442871094, 'policy_logps/chosen': -307.9553527832031, 'referece_logps/rejected': -300.34967041015625, 'referece_logps/chosen': -290.57110595703125, 'logits/rejected': -0.8549275398254395, 'logits/chosen': -0.7245503067970276, 'epoch': 3.57}

 60%|█████▉    | 9582/16104 [44:02:31<27:37:42, 15.25s/it]

 60%|█████▉    | 9583/16104 [44:02:46<27:11:00, 15.01s/it]

 60%|█████▉    | 9584/16104 [44:02:57<25:09:12, 13.89s/it]

 60%|█████▉    | 9585/16104 [44:03:16<28:03:33, 15.50s/it]

 60%|█████▉    | 9586/16104 [44:03:34<29:11:44, 16.13s/it]

 60%|█████▉    | 9587/16104 [44:03:50<29:19:49, 16.20s/it]

 60%|█████▉    | 9588/16104 [44:04:01<26:12:28, 14.48s/it]

 60%|█████▉    | 9589/16104 [44:04:17<26:59:37, 14.92s/it]

 60%|█████▉    | 9590/16104 [44:04:32<27:11:04, 15.02s/it]

 60%|█████▉    | 9591/16104 [44:04:44<25:47:08, 14.25s/it]

 60%|█████▉    | 9592/16104 [44:04:55<23:53:32, 13.21s/it]

 60%|█████▉    | 9593/16104 [44:05:16<28:08:55, 15.56s/it]

 60%|█████▉    | 9594/16104 [44:05:38<31:38:34, 17.50s/it]

 60%|█████▉    | 9595/16104 [44:05:58<32:59:18, 18.25s/it]

 60%|█████▉    | 9596/16104 [44:06:10<29:38:53, 16.40s/it]

 60%|█████▉    | 9597/16104 [44:06:31<31:44:34, 17.56s/it]


 60%|█████▉    | 9599/16104 [44:07:08<32:51:40, 18.19s/it]
{'loss': 0.3118, 'learning_rate': 7.405334361839746e-07, 'rewards/chosen': -1.89797043800354, 'rewards/rejected': -4.758767127990723, 'rewards/accuracies': 0.875, 'rewards/margins': 2.8607966899871826, 'policy_logps/rejected': -249.65603637695312, 'policy_logps/chosen': -234.61972045898438, 'referece_logps/rejected': -202.06838989257812, 'referece_logps/chosen': -215.63998413085938, 'logits/rejected': -0.2021864354610443, 'logits/chosen': 0.0774027407169342, 'epoch': 3.58}

 60%|█████▉    | 9600/16104 [44:07:24<31:51:39, 17.64s/it]

 60%|█████▉    | 9601/16104 [44:07:36<28:56:45, 16.02s/it]

 60%|█████▉    | 9602/16104 [44:07:58<31:59:26, 17.71s/it]

 60%|█████▉    | 9603/16104 [44:08:17<32:57:28, 18.25s/it]


 60%|█████▉    | 9605/16104 [44:08:54<32:33:24, 18.03s/it]
{'loss': 0.4266, 'learning_rate': 7.393681965799934e-07, 'rewards/chosen': -1.792392611503601, 'rewards/rejected': -3.12207293510437, 'rewards/accuracies': 0.875, 'rewards/margins': 1.32968008518219, 'policy_logps/rejected': -312.995361328125, 'policy_logps/chosen': -358.5992431640625, 'referece_logps/rejected': -281.774658203125, 'referece_logps/chosen': -340.6753234863281, 'logits/rejected': -0.14470437169075012, 'logits/chosen': -0.19256626069545746, 'epoch': 3.58}

 60%|█████▉    | 9606/16104 [44:09:11<31:59:42, 17.73s/it]

 60%|█████▉    | 9607/16104 [44:09:27<31:02:17, 17.20s/it]

 60%|█████▉    | 9608/16104 [44:09:41<29:32:32, 16.37s/it]

 60%|█████▉    | 9609/16104 [44:09:58<29:44:27, 16.48s/it]

 60%|█████▉    | 9610/16104 [44:10:13<29:00:43, 16.08s/it]

 60%|█████▉    | 9611/16104 [44:10:33<30:58:33, 17.17s/it]

 60%|█████▉    | 9612/16104 [44:10:53<32:32:15, 18.04s/it]

 60%|█████▉    | 9613/16104 [44:11:04<28:34:30, 15.85s/it]


 60%|█████▉    | 9615/16104 [44:11:34<27:10:15, 15.07s/it]
{'loss': 0.4023, 'learning_rate': 7.374269748527055e-07, 'rewards/chosen': -1.6182760000228882, 'rewards/rejected': -2.382401943206787, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7641260623931885, 'policy_logps/rejected': -384.54248046875, 'policy_logps/chosen': -403.99664306640625, 'referece_logps/rejected': -360.7184753417969, 'referece_logps/chosen': -387.81390380859375, 'logits/rejected': -0.30475926399230957, 'logits/chosen': -0.3668668270111084, 'epoch': 3.58}

 60%|█████▉    | 9616/16104 [44:11:47<26:22:14, 14.63s/it]

 60%|█████▉    | 9617/16104 [44:12:03<26:49:39, 14.89s/it]


 60%|█████▉    | 9619/16104 [44:12:36<28:02:23, 15.57s/it]
{'loss': 0.3305, 'learning_rate': 7.366507831254183e-07, 'rewards/chosen': -1.1269780397415161, 'rewards/rejected': -4.483883857727051, 'rewards/accuracies': 0.875, 'rewards/margins': 3.356905460357666, 'policy_logps/rejected': -405.9316711425781, 'policy_logps/chosen': -418.56329345703125, 'referece_logps/rejected': -361.09283447265625, 'referece_logps/chosen': -407.2934875488281, 'logits/rejected': -0.08920681476593018, 'logits/chosen': -0.006399688310921192, 'epoch': 3.58}


 60%|█████▉    | 9621/16104 [44:13:08<28:58:51, 16.09s/it]
{'loss': 0.3587, 'learning_rate': 7.362627511480524e-07, 'rewards/chosen': -1.1354292631149292, 'rewards/rejected': -2.7010579109191895, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5656286478042603, 'policy_logps/rejected': -669.4866333007812, 'policy_logps/chosen': -441.3035888671875, 'referece_logps/rejected': -642.4760131835938, 'referece_logps/chosen': -429.9493103027344, 'logits/rejected': 0.36236777901649475, 'logits/chosen': 0.43179771304130554, 'epoch': 3.58}

 60%|█████▉    | 9622/16104 [44:13:30<32:05:54, 17.83s/it]

 60%|█████▉    | 9623/16104 [44:13:50<33:26:04, 18.57s/it]

 60%|█████▉    | 9624/16104 [44:14:09<33:23:59, 18.56s/it]

 60%|█████▉    | 9625/16104 [44:14:30<34:49:40, 19.35s/it]

 60%|█████▉    | 9626/16104 [44:14:50<35:00:06, 19.45s/it]

 60%|█████▉    | 9627/16104 [44:15:09<35:14:47, 19.59s/it]

 60%|█████▉    | 9628/16104 [44:15:24<32:24:05, 18.01s/it]

 60%|█████▉    | 9629/16104 [44:15:43<33:18:59, 18.52s/it]

 60%|█████▉    | 9630/16104 [44:16:04<34:17:38, 19.07s/it]

 60%|█████▉    | 9631/16104 [44:16:17<31:11:04, 17.34s/it]


 60%|█████▉    | 9633/16104 [44:16:56<33:12:14, 18.47s/it]
{'loss': 0.3257, 'learning_rate': 7.339354576468412e-07, 'rewards/chosen': -2.0113086700439453, 'rewards/rejected': -4.095795631408691, 'rewards/accuracies': 1.0, 'rewards/margins': 2.084487199783325, 'policy_logps/rejected': -270.42877197265625, 'policy_logps/chosen': -237.46328735351562, 'referece_logps/rejected': -229.47080993652344, 'referece_logps/chosen': -217.3502197265625, 'logits/rejected': -0.8576680421829224, 'logits/chosen': -0.8300192356109619, 'epoch': 3.59}

 60%|█████▉    | 9634/16104 [44:17:16<33:56:22, 18.88s/it]

 60%|█████▉    | 9635/16104 [44:17:37<34:49:30, 19.38s/it]

 60%|█████▉    | 9636/16104 [44:17:56<34:51:47, 19.40s/it]

 60%|█████▉    | 9637/16104 [44:18:09<31:18:27, 17.43s/it]

 60%|█████▉    | 9638/16104 [44:18:26<31:04:39, 17.30s/it]

 60%|█████▉    | 9639/16104 [44:18:43<30:42:22, 17.10s/it]

 60%|█████▉    | 9640/16104 [44:18:54<27:28:35, 15.30s/it]


 60%|█████▉    | 9642/16104 [44:19:26<28:59:58, 16.16s/it]
{'loss': 0.2886, 'learning_rate': 7.321910038626367e-07, 'rewards/chosen': -1.739659309387207, 'rewards/rejected': -4.19792366027832, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4582645893096924, 'policy_logps/rejected': -368.60626220703125, 'policy_logps/chosen': -471.412353515625, 'referece_logps/rejected': -326.62701416015625, 'referece_logps/chosen': -454.0157470703125, 'logits/rejected': -0.4560939073562622, 'logits/chosen': -0.35921722650527954, 'epoch': 3.59}

 60%|█████▉    | 9643/16104 [44:19:49<32:17:19, 17.99s/it]

 60%|█████▉    | 9644/16104 [44:20:00<28:40:00, 15.98s/it]

 60%|█████▉    | 9645/16104 [44:20:19<30:18:25, 16.89s/it]

 60%|█████▉    | 9646/16104 [44:20:33<28:58:03, 16.15s/it]

 60%|█████▉    | 9647/16104 [44:20:44<25:59:19, 14.49s/it]

 60%|█████▉    | 9648/16104 [44:20:55<24:03:31, 13.42s/it]


 60%|█████▉    | 9650/16104 [44:21:24<25:09:59, 14.04s/it]

 60%|█████▉    | 9651/16104 [44:21:37<24:19:50, 13.57s/it]

 60%|█████▉    | 9652/16104 [44:21:52<24:59:42, 13.95s/it]

 60%|█████▉    | 9653/16104 [44:22:05<24:22:45, 13.60s/it]

 60%|█████▉    | 9654/16104 [44:22:25<27:47:14, 15.51s/it]

 60%|█████▉    | 9655/16104 [44:22:43<29:37:12, 16.53s/it]

 60%|█████▉    | 9656/16104 [44:23:03<31:24:44, 17.54s/it]

 60%|█████▉    | 9657/16104 [44:23:22<31:55:34, 17.83s/it]

 60%|█████▉    | 9658/16104 [44:23:33<28:12:45, 15.76s/it]

 60%|█████▉    | 9659/16104 [44:23:52<30:13:45, 16.89s/it]

 60%|█████▉    | 9660/16104 [44:24:03<26:52:11, 15.01s/it]

 60%|█████▉    | 9661/16104 [44:24:25<30:50:54, 17.24s/it]

 60%|█████▉    | 9662/16104 [44:24:45<32:04:51, 17.93s/it]

 60%|██████    | 9663/16104 [44:25:04<32:51:08, 18.36s/it]

 60%|██████    | 9664/16104 [44:25:19<30:40:09, 17.14s/it]

 60%|██████    | 9665/16104 [44:25:33<29:07:41, 16.29s/it]

 60%|██████    | 9666/16104 [44:25:49<29:03:30, 16.25s/it]

 60%|██████    | 9667/16104 [44:26:01<26:34:19, 14.86s/it]

 60%|██████    | 9668/16104 [44:26:14<25:33:33, 14.30s/it]

 60%|██████    | 9669/16104 [44:26:30<26:26:39, 14.79s/it]

 60%|██████    | 9670/16104 [44:26:42<25:16:21, 14.14s/it]

 60%|██████    | 9671/16104 [44:27:02<28:13:01, 15.79s/it]

 60%|██████    | 9672/16104 [44:27:17<28:07:24, 15.74s/it]

 60%|██████    | 9673/16104 [44:27:30<26:34:42, 14.88s/it]

 60%|██████    | 9674/16104 [44:27:43<25:35:45, 14.33s/it]

 60%|██████    | 9675/16104 [44:28:00<26:57:36, 15.10s/it]

 60%|██████    | 9676/16104 [44:28:22<30:18:17, 16.97s/it]

 60%|██████    | 9677/16104 [44:28:36<28:47:11, 16.12s/it]

 60%|██████    | 9678/16104 [44:28:50<27:30:36, 15.41s/it]

 60%|██████    | 9679/16104 [44:29:07<28:35:43, 16.02s/it]

 60%|██████    | 9680/16104 [44:29:27<30:36:39, 17.15s/it]

 60%|██████    | 9681/16104 [44:29:45<31:23:17, 17.59s/it]

 60%|██████    | 9682/16104 [44:30:00<29:42:16, 16.65s/it]

 60%|██████    | 9683/16104 [44:30:12<27:17:06, 15.30s/it]

 60%|██████    | 9684/16104 [44:30:24<25:44:21, 14.43s/it]

 60%|██████    | 9685/16104 [44:30:37<24:59:24, 14.02s/it]

 60%|██████    | 9686/16104 [44:30:58<28:44:31, 16.12s/it]

 60%|██████    | 9687/16104 [44:31:21<32:00:29, 17.96s/it]

 60%|██████    | 9688/16104 [44:31:37<31:17:00, 17.55s/it]

 60%|██████    | 9689/16104 [44:31:57<32:32:32, 18.26s/it]

 60%|██████    | 9690/16104 [44:32:12<30:39:23, 17.21s/it]

 60%|██████    | 9691/16104 [44:32:29<30:27:10, 17.10s/it]

 60%|██████    | 9692/16104 [44:32:41<27:53:22, 15.66s/it]

 60%|██████    | 9693/16104 [44:33:00<29:46:06, 16.72s/it]

 60%|██████    | 9694/16104 [44:33:21<32:08:29, 18.05s/it]

 60%|██████    | 9695/16104 [44:33:37<30:36:13, 17.19s/it]

 60%|██████    | 9696/16104 [44:33:51<28:52:11, 16.22s/it]

 60%|██████    | 9697/16104 [44:34:03<26:57:59, 15.15s/it]

 60%|██████    | 9698/16104 [44:34:23<29:20:24, 16.49s/it]

 60%|██████    | 9699/16104 [44:34:45<32:32:26, 18.29s/it]

 60%|██████    | 9700/16104 [44:34:58<29:43:21, 16.71s/it]

 60%|██████    | 9701/16104 [44:35:17<30:39:39, 17.24s/it]

 60%|██████    | 9702/16104 [44:35:31<29:10:02, 16.40s/it]

 60%|██████    | 9703/16104 [44:35:45<27:53:30, 15.69s/it]

 60%|██████    | 9704/16104 [44:36:05<30:05:12, 16.92s/it]

 60%|██████    | 9705/16104 [44:36:25<31:36:31, 17.78s/it]
{'loss': 0.2785, 'learning_rate': 7.200047171323256e-07, 'rewards/chosen': -1.9641286134719849, 'rewards/rejected': -3.9707860946655273, 'rewards/accuracies': 0.75, 'rewards/margins': 2.006657361984253, 'policy_logps/rejected': -481.730712890625, 'policy_logps/chosen': -517.3025512695312, 'referece_logps/rejected': -442.02288818359375, 'referece_logps/chosen': -497.66119384765625, 'logits/rejected': -0.1910388469696045, 'logits/chosen': -0.08015866577625275, 'epoch': 3.62}


 60%|██████    | 9707/16104 [44:36:59<31:30:07, 17.73s/it]

 60%|██████    | 9708/16104 [44:37:11<28:12:37, 15.88s/it]

 60%|██████    | 9709/16104 [44:37:23<26:02:09, 14.66s/it]

 60%|██████    | 9710/16104 [44:37:43<28:47:37, 16.21s/it]

 60%|██████    | 9711/16104 [44:38:00<29:29:04, 16.60s/it]

 60%|██████    | 9712/16104 [44:38:21<31:59:37, 18.02s/it]
{'loss': 0.5124, 'learning_rate': 7.18653424465925e-07, 'rewards/chosen': -1.6688661575317383, 'rewards/rejected': -2.8649919033050537, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1961255073547363, 'policy_logps/rejected': -357.2125244140625, 'policy_logps/chosen': -384.0710754394531, 'referece_logps/rejected': -328.5625915527344, 'referece_logps/chosen': -367.3824157714844, 'logits/rejected': -0.6707587242126465, 'logits/chosen': -0.7249743938446045, 'epoch': 3.62}


 60%|██████    | 9714/16104 [44:38:50<28:09:37, 15.87s/it]
{'loss': 0.3498, 'learning_rate': 7.182674431585702e-07, 'rewards/chosen': -1.7484930753707886, 'rewards/rejected': -3.522225856781006, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7737330198287964, 'policy_logps/rejected': -462.3133544921875, 'policy_logps/chosen': -406.60845947265625, 'referece_logps/rejected': -427.09112548828125, 'referece_logps/chosen': -389.1235046386719, 'logits/rejected': -0.2124878168106079, 'logits/chosen': -0.13865041732788086, 'epoch': 3.62}


 60%|██████    | 9716/16104 [44:39:23<29:04:20, 16.38s/it]

 60%|██████    | 9717/16104 [44:39:33<26:02:24, 14.68s/it]
{'loss': 0.3808, 'learning_rate': 7.176885566914375e-07, 'rewards/chosen': -1.372612476348877, 'rewards/rejected': -3.1776022911071777, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8049898147583008, 'policy_logps/rejected': -366.1888427734375, 'policy_logps/chosen': -301.6529541015625, 'referece_logps/rejected': -334.4128112792969, 'referece_logps/chosen': -287.9268493652344, 'logits/rejected': -1.5058460235595703, 'logits/chosen': -1.2583547830581665, 'epoch': 3.62}


 60%|██████    | 9719/16104 [44:39:55<22:27:21, 12.66s/it]

 60%|██████    | 9720/16104 [44:40:05<21:26:55, 12.10s/it]
{'loss': 0.3956, 'learning_rate': 7.171097730043172e-07, 'rewards/chosen': -1.4515420198440552, 'rewards/rejected': -2.8629138469696045, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4113717079162598, 'policy_logps/rejected': -477.4560852050781, 'policy_logps/chosen': -477.7489013671875, 'referece_logps/rejected': -448.82696533203125, 'referece_logps/chosen': -463.23345947265625, 'logits/rejected': 0.17702502012252808, 'logits/chosen': 0.16529470682144165, 'epoch': 3.62}


 60%|██████    | 9722/16104 [44:40:27<20:09:55, 11.38s/it]

 60%|██████    | 9723/16104 [44:40:37<19:46:38, 11.16s/it]
{'loss': 0.2787, 'learning_rate': 7.165310923079247e-07, 'rewards/chosen': -1.9083815813064575, 'rewards/rejected': -3.672842264175415, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7644606828689575, 'policy_logps/rejected': -446.8149719238281, 'policy_logps/chosen': -468.73321533203125, 'referece_logps/rejected': -410.0865783691406, 'referece_logps/chosen': -449.6494445800781, 'logits/rejected': -1.0928606986999512, 'logits/chosen': -0.7935282588005066, 'epoch': 3.62}


 60%|██████    | 9725/16104 [44:41:05<22:50:35, 12.89s/it]

 60%|██████    | 9726/16104 [44:41:20<23:27:55, 13.24s/it]

 60%|██████    | 9727/16104 [44:41:40<27:10:32, 15.34s/it]
{'loss': 0.2872, 'learning_rate': 7.157596786179958e-07, 'rewards/chosen': -1.8862924575805664, 'rewards/rejected': -4.791754245758057, 'rewards/accuracies': 0.875, 'rewards/margins': 2.9054622650146484, 'policy_logps/rejected': -347.4861755371094, 'policy_logps/chosen': -340.6927795410156, 'referece_logps/rejected': -299.5686340332031, 'referece_logps/chosen': -321.8298034667969, 'logits/rejected': -0.5398851633071899, 'logits/chosen': -0.5086854696273804, 'epoch': 3.62}


 60%|██████    | 9729/16104 [44:42:13<28:09:59, 15.91s/it]
{'loss': 0.2534, 'learning_rate': 7.153740407299967e-07, 'rewards/chosen': -1.7501391172409058, 'rewards/rejected': -4.0969157218933105, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3467764854431152, 'policy_logps/rejected': -432.21319580078125, 'policy_logps/chosen': -447.6178894042969, 'referece_logps/rejected': -391.2439880371094, 'referece_logps/chosen': -430.11651611328125, 'logits/rejected': -0.2676464319229126, 'logits/chosen': -0.4540662169456482, 'epoch': 3.62}


 60%|██████    | 9731/16104 [44:42:47<28:53:04, 16.32s/it]
{'loss': 0.3082, 'learning_rate': 7.14988448896509e-07, 'rewards/chosen': -2.0070416927337646, 'rewards/rejected': -3.232020854949951, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2249794006347656, 'policy_logps/rejected': -327.4325866699219, 'policy_logps/chosen': -289.2241516113281, 'referece_logps/rejected': -295.11236572265625, 'referece_logps/chosen': -269.1537780761719, 'logits/rejected': -0.5808358788490295, 'logits/chosen': -0.7080650925636292, 'epoch': 3.63}


 60%|██████    | 9733/16104 [44:43:23<31:03:45, 17.55s/it]

 60%|██████    | 9734/16104 [44:43:42<31:25:44, 17.76s/it]

 60%|██████    | 9735/16104 [44:44:01<32:20:27, 18.28s/it]
{'loss': 0.4409, 'learning_rate': 7.142174036426266e-07, 'rewards/chosen': -1.0433030128479004, 'rewards/rejected': -3.316417932510376, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2731151580810547, 'policy_logps/rejected': -345.78155517578125, 'policy_logps/chosen': -462.0459289550781, 'referece_logps/rejected': -312.61737060546875, 'referece_logps/chosen': -451.6129150390625, 'logits/rejected': -0.6008920669555664, 'logits/chosen': -0.5347867608070374, 'epoch': 3.63}

 60%|██████    | 9736/16104 [44:44:14<29:35:57, 16.73s/it]


 60%|██████    | 9738/16104 [44:44:53<31:59:37, 18.09s/it]

 60%|██████    | 9739/16104 [44:45:05<28:53:30, 16.34s/it]
{'loss': 0.2333, 'learning_rate': 7.134465433553907e-07, 'rewards/chosen': -2.0662708282470703, 'rewards/rejected': -4.90496826171875, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8386974334716797, 'policy_logps/rejected': -488.5600891113281, 'policy_logps/chosen': -293.42547607421875, 'referece_logps/rejected': -439.5104064941406, 'referece_logps/chosen': -272.76275634765625, 'logits/rejected': -0.6375924348831177, 'logits/chosen': -0.3000611364841461, 'epoch': 3.63}


 60%|██████    | 9741/16104 [44:45:27<23:54:59, 13.53s/it]

 60%|██████    | 9742/16104 [44:45:47<27:09:35, 15.37s/it]

 61%|██████    | 9743/16104 [44:46:03<27:51:09, 15.76s/it]
{'loss': 0.4408, 'learning_rate': 7.126758685337245e-07, 'rewards/chosen': -1.249658465385437, 'rewards/rejected': -3.6927218437194824, 'rewards/accuracies': 1.0, 'rewards/margins': 2.443063259124756, 'policy_logps/rejected': -357.08154296875, 'policy_logps/chosen': -334.2283630371094, 'referece_logps/rejected': -320.15435791015625, 'referece_logps/chosen': -321.73175048828125, 'logits/rejected': 0.10641852766275406, 'logits/chosen': 0.08032142370939255, 'epoch': 3.63}

 61%|██████    | 9744/16104 [44:46:16<26:13:28, 14.84s/it]


 61%|██████    | 9746/16104 [44:46:49<27:53:01, 15.79s/it]

 61%|██████    | 9747/16104 [44:47:01<25:35:22, 14.49s/it]

 61%|██████    | 9748/16104 [44:47:14<24:49:58, 14.07s/it]

 61%|██████    | 9749/16104 [44:47:29<25:26:32, 14.41s/it]

 61%|██████    | 9750/16104 [44:47:47<27:11:47, 15.41s/it]
{'loss': 0.3516, 'learning_rate': 7.113276353725714e-07, 'rewards/chosen': -1.7380359172821045, 'rewards/rejected': -4.474951267242432, 'rewards/accuracies': 0.875, 'rewards/margins': 2.7369158267974854, 'policy_logps/rejected': -399.1582946777344, 'policy_logps/chosen': -530.96240234375, 'referece_logps/rejected': -354.4088134765625, 'referece_logps/chosen': -513.58203125, 'logits/rejected': 0.1811976432800293, 'logits/chosen': 0.2427137792110443, 'epoch': 3.63}


 61%|██████    | 9752/16104 [44:48:19<28:34:44, 16.20s/it]
{'loss': 0.2993, 'learning_rate': 7.109425308769104e-07, 'rewards/chosen': -2.18806529045105, 'rewards/rejected': -5.157504081726074, 'rewards/accuracies': 0.875, 'rewards/margins': 2.9694392681121826, 'policy_logps/rejected': -438.2289123535156, 'policy_logps/chosen': -486.7306213378906, 'referece_logps/rejected': -386.6538391113281, 'referece_logps/chosen': -464.8499755859375, 'logits/rejected': 0.18289917707443237, 'logits/chosen': 0.18641796708106995, 'epoch': 3.63}


 61%|██████    | 9754/16104 [44:48:55<30:45:28, 17.44s/it]
{'loss': 0.351, 'learning_rate': 7.105574731528105e-07, 'rewards/chosen': -1.517912745475769, 'rewards/rejected': -3.651209831237793, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1332969665527344, 'policy_logps/rejected': -270.7670593261719, 'policy_logps/chosen': -315.561279296875, 'referece_logps/rejected': -234.2549591064453, 'referece_logps/chosen': -300.38214111328125, 'logits/rejected': -0.32940569519996643, 'logits/chosen': -0.4384647011756897, 'epoch': 3.63}


 61%|██████    | 9756/16104 [44:49:35<33:04:35, 18.76s/it]
{'loss': 0.3123, 'learning_rate': 7.101724622625769e-07, 'rewards/chosen': -2.579993724822998, 'rewards/rejected': -4.488791465759277, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9087982177734375, 'policy_logps/rejected': -481.99859619140625, 'policy_logps/chosen': -422.0212707519531, 'referece_logps/rejected': -437.1106872558594, 'referece_logps/chosen': -396.2213134765625, 'logits/rejected': 0.07011020183563232, 'logits/chosen': 0.21557125449180603, 'epoch': 3.63}

 61%|██████    | 9757/16104 [44:49:55<33:41:16, 19.11s/it]

 61%|██████    | 9758/16104 [44:50:15<34:09:39, 19.38s/it]

 61%|██████    | 9759/16104 [44:50:34<34:18:50, 19.47s/it]


 61%|██████    | 9761/16104 [44:51:09<32:43:20, 18.57s/it]

 61%|██████    | 9762/16104 [44:51:21<29:02:27, 16.48s/it]

 61%|██████    | 9763/16104 [44:51:42<31:37:19, 17.95s/it]

 61%|██████    | 9764/16104 [44:51:59<30:56:21, 17.57s/it]
{'loss': 0.3414, 'learning_rate': 7.086328882861426e-07, 'rewards/chosen': -1.993445873260498, 'rewards/rejected': -2.9639978408813477, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9705519676208496, 'policy_logps/rejected': -245.1907501220703, 'policy_logps/chosen': -438.93603515625, 'referece_logps/rejected': -215.55078125, 'referece_logps/chosen': -419.0015869140625, 'logits/rejected': -0.4472582936286926, 'logits/chosen': -0.5231606364250183, 'epoch': 3.64}


 61%|██████    | 9766/16104 [44:52:32<28:55:44, 16.43s/it]

 61%|██████    | 9767/16104 [44:52:46<28:01:24, 15.92s/it]

 61%|██████    | 9768/16104 [44:53:02<27:55:41, 15.87s/it]

 61%|██████    | 9769/16104 [44:53:16<26:50:44, 15.26s/it]

 61%|██████    | 9770/16104 [44:53:34<28:28:17, 16.18s/it]

 61%|██████    | 9771/16104 [44:53:49<27:26:26, 15.60s/it]

 61%|██████    | 9772/16104 [44:54:00<25:16:07, 14.37s/it]

 61%|██████    | 9773/16104 [44:54:18<27:21:16, 15.55s/it]

 61%|██████    | 9774/16104 [44:54:39<29:50:34, 16.97s/it]

 61%|██████    | 9775/16104 [44:54:56<29:58:50, 17.05s/it]

 61%|██████    | 9776/16104 [44:55:16<31:42:53, 18.04s/it]

 61%|██████    | 9777/16104 [44:55:32<30:21:37, 17.27s/it]

 61%|██████    | 9778/16104 [44:55:50<30:40:04, 17.45s/it]
{'loss': 0.2706, 'learning_rate': 7.05940451316839e-07, 'rewards/chosen': -1.6977369785308838, 'rewards/rejected': -3.351912021636963, 'rewards/accuracies': 0.875, 'rewards/margins': 1.654175043106079, 'policy_logps/rejected': -342.31536865234375, 'policy_logps/chosen': -491.1177673339844, 'referece_logps/rejected': -308.7962646484375, 'referece_logps/chosen': -474.140380859375, 'logits/rejected': -0.04353198781609535, 'logits/chosen': -0.20087112486362457, 'epoch': 3.64}


 61%|██████    | 9780/16104 [44:56:18<28:02:00, 15.96s/it]

 61%|██████    | 9781/16104 [44:56:36<29:09:05, 16.60s/it]

 61%|██████    | 9782/16104 [44:56:55<30:48:12, 17.54s/it]

 61%|██████    | 9783/16104 [44:57:16<32:15:35, 18.37s/it]

 61%|██████    | 9784/16104 [44:57:34<32:06:37, 18.29s/it]

 61%|██████    | 9785/16104 [44:57:52<31:47:33, 18.11s/it]
{'loss': 0.4004, 'learning_rate': 7.045951057978e-07, 'rewards/chosen': -2.0867362022399902, 'rewards/rejected': -3.428287982940674, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3415515422821045, 'policy_logps/rejected': -328.88720703125, 'policy_logps/chosen': -257.23779296875, 'referece_logps/rejected': -294.6043395996094, 'referece_logps/chosen': -236.37042236328125, 'logits/rejected': -0.19164066016674042, 'logits/chosen': -0.16327263414859772, 'epoch': 3.65}


 61%|██████    | 9787/16104 [44:58:26<31:36:21, 18.01s/it]

 61%|██████    | 9788/16104 [44:58:41<30:11:46, 17.21s/it]

 61%|██████    | 9789/16104 [44:58:55<28:04:55, 16.01s/it]

 61%|██████    | 9790/16104 [44:59:05<25:20:53, 14.45s/it]

 61%|██████    | 9791/16104 [44:59:17<23:35:14, 13.45s/it]

 61%|██████    | 9792/16104 [44:59:30<23:31:58, 13.42s/it]

 61%|██████    | 9793/16104 [44:59:52<27:58:08, 15.95s/it]
{'loss': 0.2502, 'learning_rate': 7.030582851963835e-07, 'rewards/chosen': -1.5565717220306396, 'rewards/rejected': -3.0991265773773193, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5425549745559692, 'policy_logps/rejected': -309.921142578125, 'policy_logps/chosen': -288.1284484863281, 'referece_logps/rejected': -278.92987060546875, 'referece_logps/chosen': -272.562744140625, 'logits/rejected': 0.1502743512392044, 'logits/chosen': 0.17070794105529785, 'epoch': 3.65}


 61%|██████    | 9795/16104 [45:00:23<27:50:12, 15.88s/it]

 61%|██████    | 9796/16104 [45:00:39<27:52:55, 15.91s/it]
{'loss': 0.3107, 'learning_rate': 7.024821754522415e-07, 'rewards/chosen': -2.102982997894287, 'rewards/rejected': -4.580651760101318, 'rewards/accuracies': 0.875, 'rewards/margins': 2.477668523788452, 'policy_logps/rejected': -444.41827392578125, 'policy_logps/chosen': -709.9637451171875, 'referece_logps/rejected': -398.61175537109375, 'referece_logps/chosen': -688.933837890625, 'logits/rejected': -0.7994371652603149, 'logits/chosen': -0.7913825511932373, 'epoch': 3.65}


 61%|██████    | 9798/16104 [45:01:00<23:18:50, 13.31s/it]

 61%|██████    | 9799/16104 [45:01:11<21:56:11, 12.53s/it]

 61%|██████    | 9800/16104 [45:01:22<20:57:21, 11.97s/it]

 61%|██████    | 9801/16104 [45:01:36<22:24:24, 12.80s/it]

 61%|██████    | 9802/16104 [45:01:49<22:17:11, 12.73s/it]

 61%|██████    | 9803/16104 [45:02:11<27:02:44, 15.45s/it]

 61%|██████    | 9804/16104 [45:02:26<26:50:27, 15.34s/it]

 61%|██████    | 9805/16104 [45:02:36<24:23:58, 13.94s/it]
{'loss': 0.3445, 'learning_rate': 7.007544969554215e-07, 'rewards/chosen': -2.21623158454895, 'rewards/rejected': -4.165475845336914, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9492439031600952, 'policy_logps/rejected': -316.82989501953125, 'policy_logps/chosen': -410.4901123046875, 'referece_logps/rejected': -275.1751403808594, 'referece_logps/chosen': -388.3277893066406, 'logits/rejected': -0.4051337242126465, 'logits/chosen': -0.5498078465461731, 'epoch': 3.65}


 61%|██████    | 9807/16104 [45:02:58<21:27:46, 12.27s/it]

 61%|██████    | 9808/16104 [45:03:09<20:38:08, 11.80s/it]

 61%|██████    | 9809/16104 [45:03:20<20:23:10, 11.66s/it]

 61%|██████    | 9810/16104 [45:03:31<20:09:15, 11.53s/it]

 61%|██████    | 9811/16104 [45:03:42<19:51:51, 11.36s/it]

 61%|██████    | 9812/16104 [45:03:59<22:49:12, 13.06s/it]

 61%|██████    | 9813/16104 [45:04:11<22:15:43, 12.74s/it]

 61%|██████    | 9814/16104 [45:04:24<22:25:36, 12.84s/it]

 61%|██████    | 9815/16104 [45:04:44<26:19:54, 15.07s/it]

 61%|██████    | 9816/16104 [45:04:57<24:48:48, 14.21s/it]
{'loss': 0.4677, 'learning_rate': 6.986442220241948e-07, 'rewards/chosen': -1.8119535446166992, 'rewards/rejected': -2.5371809005737305, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7252272367477417, 'policy_logps/rejected': -297.4383239746094, 'policy_logps/chosen': -295.78131103515625, 'referece_logps/rejected': -272.0664978027344, 'referece_logps/chosen': -277.66180419921875, 'logits/rejected': -0.6789422035217285, 'logits/chosen': -0.6265130043029785, 'epoch': 3.66}


 61%|██████    | 9818/16104 [45:05:28<25:39:12, 14.69s/it]
{'loss': 0.3303, 'learning_rate': 6.982606938453854e-07, 'rewards/chosen': -1.4013162851333618, 'rewards/rejected': -4.1748528480529785, 'rewards/accuracies': 0.875, 'rewards/margins': 2.7735366821289062, 'policy_logps/rejected': -263.0268859863281, 'policy_logps/chosen': -281.0312805175781, 'referece_logps/rejected': -221.27833557128906, 'referece_logps/chosen': -267.01812744140625, 'logits/rejected': 0.42649340629577637, 'logits/chosen': 0.5551515817642212, 'epoch': 3.66}


 61%|██████    | 9820/16104 [45:05:53<23:53:55, 13.69s/it]

 61%|██████    | 9821/16104 [45:06:13<27:02:45, 15.50s/it]

 61%|██████    | 9822/16104 [45:06:30<28:00:54, 16.05s/it]
{'loss': 0.1955, 'learning_rate': 6.974937840205344e-07, 'rewards/chosen': -1.6975171566009521, 'rewards/rejected': -4.616786956787109, 'rewards/accuracies': 1.0, 'rewards/margins': 2.919269561767578, 'policy_logps/rejected': -315.09283447265625, 'policy_logps/chosen': -317.08599853515625, 'referece_logps/rejected': -268.92498779296875, 'referece_logps/chosen': -300.11083984375, 'logits/rejected': -0.6339406967163086, 'logits/chosen': -0.7309955358505249, 'epoch': 3.66}


 61%|██████    | 9824/16104 [45:07:07<30:04:15, 17.24s/it]
{'loss': 0.2765, 'learning_rate': 6.971104024985852e-07, 'rewards/chosen': -1.5643762350082397, 'rewards/rejected': -4.927299499511719, 'rewards/accuracies': 0.875, 'rewards/margins': 3.3629231452941895, 'policy_logps/rejected': -453.6372375488281, 'policy_logps/chosen': -350.3622131347656, 'referece_logps/rejected': -404.3642578125, 'referece_logps/chosen': -334.7184143066406, 'logits/rejected': -0.14368748664855957, 'logits/chosen': -0.09443840384483337, 'epoch': 3.66}

 61%|██████    | 9825/16104 [45:07:20<28:08:58, 16.14s/it]


 61%|██████    | 9827/16104 [45:07:57<29:41:07, 17.03s/it]

 61%|██████    | 9828/16104 [45:08:15<30:24:50, 17.45s/it]

 61%|██████    | 9829/16104 [45:08:31<29:31:55, 16.94s/it]

 61%|██████    | 9830/16104 [45:08:43<27:05:30, 15.55s/it]

 61%|██████    | 9831/16104 [45:08:59<27:12:56, 15.62s/it]
{'loss': 0.482, 'learning_rate': 6.957689535301627e-07, 'rewards/chosen': -1.2794640064239502, 'rewards/rejected': -2.478286027908325, 'rewards/accuracies': 0.875, 'rewards/margins': 1.198822259902954, 'policy_logps/rejected': -518.9578857421875, 'policy_logps/chosen': -471.1068115234375, 'referece_logps/rejected': -494.1750183105469, 'referece_logps/chosen': -458.3121643066406, 'logits/rejected': -0.4698321521282196, 'logits/chosen': -0.17210648953914642, 'epoch': 3.66}

 61%|██████    | 9832/16104 [45:09:14<26:51:10, 15.41s/it]


 61%|██████    | 9834/16104 [45:09:49<28:53:37, 16.59s/it]

 61%|██████    | 9835/16104 [45:10:07<29:37:43, 17.01s/it]
{'loss': 0.3706, 'learning_rate': 6.95002681839106e-07, 'rewards/chosen': -1.4098896980285645, 'rewards/rejected': -2.7452213764190674, 'rewards/accuracies': 0.75, 'rewards/margins': 1.335331678390503, 'policy_logps/rejected': -450.5726013183594, 'policy_logps/chosen': -396.6479797363281, 'referece_logps/rejected': -423.1203918457031, 'referece_logps/chosen': -382.5491027832031, 'logits/rejected': 0.31891176104545593, 'logits/chosen': 0.40537333488464355, 'epoch': 3.66}

 61%|██████    | 9836/16104 [45:10:26<30:54:19, 17.75s/it]


 61%|██████    | 9838/16104 [45:11:01<30:13:08, 17.36s/it]
{'loss': 0.2324, 'learning_rate': 6.944281075893901e-07, 'rewards/chosen': -1.7152892351150513, 'rewards/rejected': -4.001175880432129, 'rewards/accuracies': 0.75, 'rewards/margins': 2.285886287689209, 'policy_logps/rejected': -313.2122497558594, 'policy_logps/chosen': -372.814208984375, 'referece_logps/rejected': -273.2004699707031, 'referece_logps/chosen': -355.6612854003906, 'logits/rejected': -0.2245526909828186, 'logits/chosen': -0.39303672313690186, 'epoch': 3.67}


 61%|██████    | 9840/16104 [45:11:33<28:53:06, 16.60s/it]

 61%|██████    | 9841/16104 [45:11:47<27:44:13, 15.94s/it]

 61%|██████    | 9842/16104 [45:11:59<25:44:53, 14.80s/it]

 61%|██████    | 9843/16104 [45:12:19<28:20:57, 16.30s/it]
{'loss': 0.468, 'learning_rate': 6.934707311617056e-07, 'rewards/chosen': -2.0829529762268066, 'rewards/rejected': -3.302294969558716, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2193418741226196, 'policy_logps/rejected': -479.812255859375, 'policy_logps/chosen': -642.9412841796875, 'referece_logps/rejected': -446.7892761230469, 'referece_logps/chosen': -622.1117553710938, 'logits/rejected': 0.5142769813537598, 'logits/chosen': 0.3500227928161621, 'epoch': 3.67}


 61%|██████    | 9845/16104 [45:12:45<25:43:49, 14.80s/it]
{'loss': 0.461, 'learning_rate': 6.930878673340083e-07, 'rewards/chosen': -1.7227842807769775, 'rewards/rejected': -3.307626247406006, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5848419666290283, 'policy_logps/rejected': -389.9065246582031, 'policy_logps/chosen': -436.97943115234375, 'referece_logps/rejected': -356.8302917480469, 'referece_logps/chosen': -419.7515869140625, 'logits/rejected': -0.7991276979446411, 'logits/chosen': -0.9695447087287903, 'epoch': 3.67}


 61%|██████    | 9847/16104 [45:13:13<24:39:17, 14.19s/it]
{'loss': 0.4079, 'learning_rate': 6.927050531668843e-07, 'rewards/chosen': -2.6082706451416016, 'rewards/rejected': -3.021355628967285, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4130852222442627, 'policy_logps/rejected': -399.01080322265625, 'policy_logps/chosen': -313.40972900390625, 'referece_logps/rejected': -368.7972412109375, 'referece_logps/chosen': -287.3270263671875, 'logits/rejected': 0.09702746570110321, 'logits/chosen': 0.032917320728302, 'epoch': 3.67}

 61%|██████    | 9848/16104 [45:13:32<27:04:37, 15.58s/it]

 61%|██████    | 9849/16104 [45:13:50<28:17:46, 16.29s/it]


 61%|██████    | 9851/16104 [45:14:28<30:36:30, 17.62s/it]
{'loss': 0.3795, 'learning_rate': 6.919395740621158e-07, 'rewards/chosen': -1.017099380493164, 'rewards/rejected': -2.5893187522888184, 'rewards/accuracies': 0.75, 'rewards/margins': 1.572219729423523, 'policy_logps/rejected': -344.4235534667969, 'policy_logps/chosen': -491.384765625, 'referece_logps/rejected': -318.53033447265625, 'referece_logps/chosen': -481.2137756347656, 'logits/rejected': -0.04039478674530983, 'logits/chosen': -0.09658348560333252, 'epoch': 3.67}

 61%|██████    | 9852/16104 [45:14:50<33:06:42, 19.07s/it]


 61%|██████    | 9854/16104 [45:15:14<26:25:03, 15.22s/it]

 61%|██████    | 9855/16104 [45:15:25<24:36:24, 14.18s/it]

 61%|██████    | 9856/16104 [45:15:45<27:38:21, 15.93s/it]

 61%|██████    | 9857/16104 [45:16:01<27:38:09, 15.93s/it]
{'loss': 0.2644, 'learning_rate': 6.907917294075532e-07, 'rewards/chosen': -0.9851576685905457, 'rewards/rejected': -4.1270036697387695, 'rewards/accuracies': 1.0, 'rewards/margins': 3.141845464706421, 'policy_logps/rejected': -407.77203369140625, 'policy_logps/chosen': -489.33795166015625, 'referece_logps/rejected': -366.50201416015625, 'referece_logps/chosen': -479.48638916015625, 'logits/rejected': -0.44673430919647217, 'logits/chosen': -0.3874225616455078, 'epoch': 3.67}

 61%|██████    | 9858/16104 [45:16:13<25:27:37, 14.67s/it]

 61%|██████    | 9859/16104 [45:16:33<28:06:50, 16.21s/it]


 61%|██████    | 9861/16104 [45:17:13<31:44:04, 18.30s/it]

 61%|██████    | 9862/16104 [45:17:30<30:40:21, 17.69s/it]

 61%|██████    | 9863/16104 [45:17:48<30:52:47, 17.81s/it]

 61%|██████▏   | 9864/16104 [45:18:07<31:48:32, 18.35s/it]

 61%|██████▏   | 9865/16104 [45:18:22<29:59:18, 17.30s/it]

 61%|██████▏   | 9866/16104 [45:18:34<27:09:55, 15.68s/it]
{'loss': 0.2939, 'learning_rate': 6.890708072395709e-07, 'rewards/chosen': -1.8840117454528809, 'rewards/rejected': -3.346978187561035, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4629662036895752, 'policy_logps/rejected': -235.7902069091797, 'policy_logps/chosen': -329.0716857910156, 'referece_logps/rejected': -202.32041931152344, 'referece_logps/chosen': -310.2315979003906, 'logits/rejected': -0.14978347718715668, 'logits/chosen': -0.11649034172296524, 'epoch': 3.68}

 61%|██████▏   | 9867/16104 [45:18:50<27:30:24, 15.88s/it]

 61%|██████▏   | 9868/16104 [45:19:08<28:33:31, 16.49s/it]


 61%|██████▏   | 9870/16104 [45:19:35<25:29:43, 14.72s/it]
{'loss': 0.3529, 'learning_rate': 6.883062796262011e-07, 'rewards/chosen': -1.8964650630950928, 'rewards/rejected': -3.2623045444488525, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3658394813537598, 'policy_logps/rejected': -495.2003173828125, 'policy_logps/chosen': -538.6824340820312, 'referece_logps/rejected': -462.5772705078125, 'referece_logps/chosen': -519.7177734375, 'logits/rejected': -0.10006315261125565, 'logits/chosen': -0.22013334929943085, 'epoch': 3.68}

 61%|██████▏   | 9871/16104 [45:19:49<25:03:23, 14.47s/it]

 61%|██████▏   | 9872/16104 [45:20:07<26:39:59, 15.40s/it]

 61%|██████▏   | 9873/16104 [45:20:27<29:05:13, 16.81s/it]


 61%|██████▏   | 9875/16104 [45:21:08<32:08:01, 18.57s/it]
{'loss': 0.2343, 'learning_rate': 6.873509038602109e-07, 'rewards/chosen': -1.8932710886001587, 'rewards/rejected': -5.765736103057861, 'rewards/accuracies': 1.0, 'rewards/margins': 3.872465133666992, 'policy_logps/rejected': -395.1134033203125, 'policy_logps/chosen': -354.6653747558594, 'referece_logps/rejected': -337.4560241699219, 'referece_logps/chosen': -335.7326354980469, 'logits/rejected': -0.1791655421257019, 'logits/chosen': -0.14514674246311188, 'epoch': 3.68}

 61%|██████▏   | 9876/16104 [45:21:25<31:19:05, 18.10s/it]

 61%|██████▏   | 9877/16104 [45:21:47<33:25:33, 19.32s/it]

 61%|██████▏   | 9878/16104 [45:22:03<31:32:54, 18.24s/it]


 61%|██████▏   | 9880/16104 [45:22:42<32:53:15, 19.02s/it]
{'loss': 0.2697, 'learning_rate': 6.863958442745419e-07, 'rewards/chosen': -2.005044937133789, 'rewards/rejected': -4.8571553230285645, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8521103858947754, 'policy_logps/rejected': -334.5068054199219, 'policy_logps/chosen': -294.5682373046875, 'referece_logps/rejected': -285.93524169921875, 'referece_logps/chosen': -274.5177917480469, 'logits/rejected': -0.45862919092178345, 'logits/chosen': -0.38229143619537354, 'epoch': 3.68}

 61%|██████▏   | 9881/16104 [45:23:01<33:11:39, 19.20s/it]

 61%|██████▏   | 9882/16104 [45:23:19<32:25:03, 18.76s/it]


 61%|██████▏   | 9884/16104 [45:23:50<29:32:25, 17.10s/it]
{'loss': 0.339, 'learning_rate': 6.856320249048968e-07, 'rewards/chosen': -1.5348455905914307, 'rewards/rejected': -3.8900747299194336, 'rewards/accuracies': 0.75, 'rewards/margins': 2.355229616165161, 'policy_logps/rejected': -346.2912902832031, 'policy_logps/chosen': -366.4245300292969, 'referece_logps/rejected': -307.3905029296875, 'referece_logps/chosen': -351.0760803222656, 'logits/rejected': 0.3612021207809448, 'logits/chosen': 0.35781949758529663, 'epoch': 3.68}


 61%|██████▏   | 9886/16104 [45:24:22<29:30:25, 17.08s/it]

 61%|██████▏   | 9887/16104 [45:24:38<28:51:23, 16.71s/it]

 61%|██████▏   | 9888/16104 [45:24:58<30:30:04, 17.66s/it]

 61%|██████▏   | 9889/16104 [45:25:16<30:42:58, 17.79s/it]
{'loss': 0.4093, 'learning_rate': 6.84677536877523e-07, 'rewards/chosen': -2.311314105987549, 'rewards/rejected': -4.4608635902404785, 'rewards/accuracies': 0.75, 'rewards/margins': 2.149549722671509, 'policy_logps/rejected': -402.0903625488281, 'policy_logps/chosen': -425.4781799316406, 'referece_logps/rejected': -357.481689453125, 'referece_logps/chosen': -402.3650207519531, 'logits/rejected': -0.694645345211029, 'logits/chosen': -0.7490832805633545, 'epoch': 3.68}

 61%|██████▏   | 9890/16104 [45:25:33<30:13:51, 17.51s/it]

 61%|██████▏   | 9891/16104 [45:25:54<31:55:04, 18.49s/it]

 61%|██████▏   | 9892/16104 [45:26:12<31:39:19, 18.35s/it]

 61%|██████▏   | 9893/16104 [45:26:26<29:29:23, 17.09s/it]

 61%|██████▏   | 9894/16104 [45:26:39<27:42:13, 16.06s/it]

 61%|██████▏   | 9895/16104 [45:26:59<29:44:08, 17.24s/it]

 61%|██████▏   | 9896/16104 [45:27:19<31:10:23, 18.08s/it]

 61%|██████▏   | 9897/16104 [45:27:31<27:53:39, 16.18s/it]


 61%|██████▏   | 9899/16104 [45:27:58<25:03:36, 14.54s/it]
{'loss': 0.3949, 'learning_rate': 6.827695184393678e-07, 'rewards/chosen': -1.5392688512802124, 'rewards/rejected': -3.5333147048950195, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9940460920333862, 'policy_logps/rejected': -308.08465576171875, 'policy_logps/chosen': -444.169921875, 'referece_logps/rejected': -272.7514953613281, 'referece_logps/chosen': -428.77728271484375, 'logits/rejected': -0.3738242983818054, 'logits/chosen': -0.4740765392780304, 'epoch': 3.69}

 61%|██████▏   | 9900/16104 [45:28:09<23:06:36, 13.41s/it]


 61%|██████▏   | 9902/16104 [45:28:44<27:14:06, 15.81s/it]

 61%|██████▏   | 9903/16104 [45:28:56<25:23:00, 14.74s/it]
{'loss': 0.3705, 'learning_rate': 6.82006669943031e-07, 'rewards/chosen': -1.7003051042556763, 'rewards/rejected': -3.8070192337036133, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1067137718200684, 'policy_logps/rejected': -407.49188232421875, 'policy_logps/chosen': -394.0653076171875, 'referece_logps/rejected': -369.42169189453125, 'referece_logps/chosen': -377.062255859375, 'logits/rejected': -1.6765217781066895, 'logits/chosen': -1.649470329284668, 'epoch': 3.69}

 62%|██████▏   | 9904/16104 [45:29:16<27:48:24, 16.15s/it]

 62%|██████▏   | 9905/16104 [45:29:33<28:22:14, 16.48s/it]

 62%|██████▏   | 9906/16104 [45:29:44<25:22:52, 14.74s/it]

 62%|██████▏   | 9907/16104 [45:30:06<29:09:39, 16.94s/it]


 62%|██████▏   | 9909/16104 [45:30:39<28:50:10, 16.76s/it]

 62%|██████▏   | 9910/16104 [45:30:58<30:15:49, 17.59s/it]
{'loss': 0.3937, 'learning_rate': 6.806721806121645e-07, 'rewards/chosen': -1.4314641952514648, 'rewards/rejected': -3.934232234954834, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5027682781219482, 'policy_logps/rejected': -499.6453857421875, 'policy_logps/chosen': -492.4534912109375, 'referece_logps/rejected': -460.3030700683594, 'referece_logps/chosen': -478.13885498046875, 'logits/rejected': -0.18669334053993225, 'logits/chosen': 0.14281302690505981, 'epoch': 3.69}

 62%|██████▏   | 9911/16104 [45:31:18<31:22:05, 18.23s/it]


 62%|██████▏   | 9913/16104 [45:31:51<29:19:18, 17.05s/it]

 62%|██████▏   | 9914/16104 [45:32:10<30:34:41, 17.78s/it]

 62%|██████▏   | 9915/16104 [45:32:32<32:46:19, 19.06s/it]
{'loss': 0.3161, 'learning_rate': 6.797193613144152e-07, 'rewards/chosen': -1.4747538566589355, 'rewards/rejected': -2.8096494674682617, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3348954916000366, 'policy_logps/rejected': -364.39312744140625, 'policy_logps/chosen': -393.9822082519531, 'referece_logps/rejected': -336.296630859375, 'referece_logps/chosen': -379.23468017578125, 'logits/rejected': -0.8273046016693115, 'logits/chosen': -0.8389179706573486, 'epoch': 3.69}

 62%|██████▏   | 9916/16104 [45:32:50<31:58:04, 18.60s/it]

 62%|██████▏   | 9917/16104 [45:33:10<32:29:15, 18.90s/it]

 62%|██████▏   | 9918/16104 [45:33:32<34:16:58, 19.95s/it]

 62%|██████▏   | 9919/16104 [45:33:43<29:56:58, 17.43s/it]

 62%|██████▏   | 9920/16104 [45:34:03<31:08:58, 18.13s/it]

 62%|██████▏   | 9921/16104 [45:34:16<28:13:20, 16.43s/it]

 62%|██████▏   | 9922/16104 [45:34:35<29:49:10, 17.37s/it]


 62%|██████▏   | 9924/16104 [45:35:03<26:21:03, 15.35s/it]
 62%|██████▏   | 9924/16104 [45:35:03<26:21:03, 15.35s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f75ee8ce3a0>
Traceback (most recent call last):
  File "/mnt/petrelfs/songmingyang/anaconda3/envs/vcd_origin/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    self._shutdown_workers()
  File "/mnt/petrelfs/songmingyang/anaconda3/envs/vcd_origin/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1423, in _shutdown_workers
    self._worker_result_queue.put((None, None))
