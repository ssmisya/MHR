{"train/loss": 0.4293, "train/learning_rate": 6.780051034488903e-07, "train/rewards/chosen": -1.8984129428863525, "train/rewards/rejected": -3.2153825759887695, "train/rewards/accuracies": 0.75, "train/rewards/margins": 1.316969633102417, "train/policy_logps/rejected": -319.3927917480469, "train/policy_logps/chosen": -535.0084228515625, "train/referece_logps/rejected": -287.2389831542969, "train/referece_logps/chosen": -516.0242919921875, "train/logits/rejected": -0.6272665858268738, "train/logits/chosen": -0.7456670999526978, "train/epoch": 3.7, "train/global_step": 9924, "_timestamp": 1712465957.7059617, "_runtime": 164109.8777487278, "_step": 9923}