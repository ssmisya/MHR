{"train/loss": 0.6056, "train/learning_rate": 1.2416677789621025e-06, "train/rewards/chosen": -0.24088823795318604, "train/rewards/rejected": -1.454988718032837, "train/rewards/accuracies": 0.875, "train/rewards/margins": 1.2141003608703613, "train/policy_logps/rejected": -422.3206481933594, "train/policy_logps/chosen": -465.585693359375, "train/referece_logps/rejected": -407.77081298828125, "train/referece_logps/chosen": -463.17681884765625, "train/logits/rejected": -1.2501133680343628, "train/logits/chosen": -1.2507648468017578, "train/epoch": 1.32, "train/global_step": 3142, "_timestamp": 1711730288.8490705, "_runtime": 33726.6907145977, "_step": 3141}