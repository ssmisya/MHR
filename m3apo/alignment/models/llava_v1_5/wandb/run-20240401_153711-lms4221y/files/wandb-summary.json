{"train/loss": 0.6763, "train/learning_rate": 1.9983438379719064e-06, "train/rewards/chosen": -0.15153560042381287, "train/rewards/rejected": -0.2742696702480316, "train/rewards/accuracies": 0.375, "train/rewards/margins": 0.12273408472537994, "train/policy_logps/rejected": -360.9477233886719, "train/policy_logps/chosen": -434.9396057128906, "train/referece_logps/rejected": -358.20501708984375, "train/referece_logps/chosen": -433.42425537109375, "train/logits/rejected": 0.1475559026002884, "train/logits/chosen": 0.16465458273887634, "train/epoch": 0.29, "train/global_step": 683, "_timestamp": 1711964383.4347942, "_runtime": 7351.547142267227, "_step": 682}