{"train/loss": 0.3483, "train/learning_rate": 6.721085481342803e-07, "train/rewards/chosen": -2.3870041370391846, "train/rewards/rejected": -3.6317384243011475, "train/rewards/accuracies": 0.875, "train/rewards/margins": 1.244734287261963, "train/policy_logps/rejected": -390.54974365234375, "train/policy_logps/chosen": -350.7668151855469, "train/referece_logps/rejected": -354.2323303222656, "train/referece_logps/chosen": -326.896728515625, "train/logits/rejected": -0.7763621211051941, "train/logits/chosen": -0.7940947413444519, "train/epoch": 3.71, "train/global_step": 9955, "_timestamp": 1712466011.8068259, "_runtime": 164155.6523668766, "_step": 9954}