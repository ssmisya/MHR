{"train/loss": 0.4035, "train/learning_rate": 6.822758698811051e-07, "train/rewards/chosen": -0.9418593645095825, "train/rewards/rejected": -3.35081148147583, "train/rewards/accuracies": 1.0, "train/rewards/margins": 2.408951759338379, "train/policy_logps/rejected": -229.2603302001953, "train/policy_logps/chosen": -193.5734405517578, "train/referece_logps/rejected": -195.75221252441406, "train/referece_logps/chosen": -184.15481567382812, "train/logits/rejected": -0.9697415232658386, "train/logits/chosen": -0.8831192851066589, "train/epoch": 1.84, "train/global_step": 1651, "_timestamp": 1711730288.7604368, "_runtime": 32756.741312742233, "_step": 1650}