  0%|          | 0/2685 [00:00<?, ?it/s]/mnt/petrelfs/songmingyang/code/mm/MAPO/m3apo/alignment/trainer/llava_dpo_trainer.py:179: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/2685 [00:24<17:55:37, 24.05s/it]
{'loss': 0.6931, 'learning_rate': 2.4691358024691355e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'policy_logps/rejected': -320.08447265625, 'policy_logps/chosen': -313.1751403808594, 'referece_logps/rejected': -320.08447265625, 'referece_logps/chosen': -313.1751403808594, 'logits/rejected': 0.23195649683475494, 'logits/chosen': 0.14115238189697266, 'epoch': 0.0}
[2024-03-29 15:33:05,720] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  0%|          | 3/2685 [01:12<17:59:53, 24.16s/it]
[2024-03-29 15:33:29,530] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6935, 'learning_rate': 7.407407407407407e-08, 'rewards/chosen': -0.021652700379490852, 'rewards/rejected': -0.033428385853767395, 'rewards/accuracies': 0.625, 'rewards/margins': 0.011775683611631393, 'policy_logps/rejected': -291.8025207519531, 'policy_logps/chosen': -327.8359680175781, 'referece_logps/rejected': -291.4682922363281, 'referece_logps/chosen': -327.61944580078125, 'logits/rejected': -0.08425535261631012, 'logits/chosen': -0.10037815570831299, 'epoch': 0.0}


  0%|          | 5/2685 [01:50<15:56:12, 21.41s/it]
{'loss': 0.686, 'learning_rate': 1.2345679012345677e-07, 'rewards/chosen': -0.015536976046860218, 'rewards/rejected': -0.03038768842816353, 'rewards/accuracies': 0.625, 'rewards/margins': 0.01485071238130331, 'policy_logps/rejected': -337.5848693847656, 'policy_logps/chosen': -330.9378967285156, 'referece_logps/rejected': -337.2810363769531, 'referece_logps/chosen': -330.782470703125, 'logits/rejected': 0.39893776178359985, 'logits/chosen': 0.42242321372032166, 'epoch': 0.01}


  0%|          | 7/2685 [02:28<14:58:42, 20.14s/it]

  0%|          | 8/2685 [02:48<14:54:50, 20.06s/it]
{'loss': 0.6928, 'learning_rate': 1.9753086419753084e-07, 'rewards/chosen': -0.00676841801032424, 'rewards/rejected': 0.02524108625948429, 'rewards/accuracies': 0.5, 'rewards/margins': -0.032009512186050415, 'policy_logps/rejected': -361.0695495605469, 'policy_logps/chosen': -328.91314697265625, 'referece_logps/rejected': -361.32196044921875, 'referece_logps/chosen': -328.8454895019531, 'logits/rejected': -0.7167830467224121, 'logits/chosen': -0.7575812339782715, 'epoch': 0.01}

  0%|          | 9/2685 [03:07<14:46:19, 19.87s/it]


  0%|          | 11/2685 [03:44<14:23:36, 19.38s/it]
{'loss': 0.698, 'learning_rate': 2.716049382716049e-07, 'rewards/chosen': -0.02784443087875843, 'rewards/rejected': -0.02851238287985325, 'rewards/accuracies': 0.5, 'rewards/margins': 0.00066795275779441, 'policy_logps/rejected': -390.1002502441406, 'policy_logps/chosen': -389.0654296875, 'referece_logps/rejected': -389.8150939941406, 'referece_logps/chosen': -388.7869567871094, 'logits/rejected': -0.40351125597953796, 'logits/chosen': -0.5185996294021606, 'epoch': 0.01}

  0%|          | 12/2685 [04:03<14:22:54, 19.37s/it]

  0%|          | 13/2685 [04:23<14:26:24, 19.46s/it]

  1%|          | 14/2685 [04:43<14:37:40, 19.72s/it]

  1%|          | 15/2685 [05:01<14:11:18, 19.13s/it]

  1%|          | 16/2685 [05:23<14:52:01, 20.05s/it]

  1%|          | 17/2685 [05:43<14:48:49, 19.99s/it]

  1%|          | 18/2685 [06:03<14:42:33, 19.86s/it]


  1%|          | 20/2685 [06:42<14:45:32, 19.94s/it]
[2024-03-29 15:38:59,655] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6936, 'learning_rate': 4.938271604938271e-07, 'rewards/chosen': -0.016833685338497162, 'rewards/rejected': 0.025395013391971588, 'rewards/accuracies': 0.375, 'rewards/margins': -0.04222869873046875, 'policy_logps/rejected': -387.5281982421875, 'policy_logps/chosen': -373.56585693359375, 'referece_logps/rejected': -387.7821960449219, 'referece_logps/chosen': -373.3974914550781, 'logits/rejected': -0.522988498210907, 'logits/chosen': -0.5827685594558716, 'epoch': 0.02}


  1%|          | 22/2685 [07:22<14:53:54, 20.14s/it]
[2024-03-29 15:39:39,512] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 23/2685 [07:42<14:57:15, 20.22s/it]
[2024-03-29 15:39:59,928] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6866, 'learning_rate': 5.679012345679012e-07, 'rewards/chosen': -0.02634248696267605, 'rewards/rejected': -0.0032926565036177635, 'rewards/accuracies': 0.125, 'rewards/margins': -0.02304983139038086, 'policy_logps/rejected': -254.54998779296875, 'policy_logps/chosen': -256.928466796875, 'referece_logps/rejected': -254.51705932617188, 'referece_logps/chosen': -256.6650390625, 'logits/rejected': -0.5255694389343262, 'logits/chosen': -0.510866105556488, 'epoch': 0.03}

  1%|          | 24/2685 [08:01<14:37:53, 19.79s/it]


  1%|          | 26/2685 [08:44<15:10:34, 20.55s/it]
{'loss': 0.6861, 'learning_rate': 6.419753086419752e-07, 'rewards/chosen': 0.011347484774887562, 'rewards/rejected': 0.0008296025916934013, 'rewards/accuracies': 0.625, 'rewards/margins': 0.01051788218319416, 'policy_logps/rejected': -222.2205810546875, 'policy_logps/chosen': -219.45968627929688, 'referece_logps/rejected': -222.2288818359375, 'referece_logps/chosen': -219.5731658935547, 'logits/rejected': -0.8663890361785889, 'logits/chosen': -0.8430235385894775, 'epoch': 0.03}

  1%|          | 27/2685 [09:02<14:27:56, 19.59s/it]


  1%|          | 29/2685 [09:44<15:04:52, 20.44s/it]
{'loss': 0.6886, 'learning_rate': 7.160493827160494e-07, 'rewards/chosen': -0.003185845445841551, 'rewards/rejected': 0.008539389818906784, 'rewards/accuracies': 0.375, 'rewards/margins': -0.011725234799087048, 'policy_logps/rejected': -287.0782165527344, 'policy_logps/chosen': -312.15838623046875, 'referece_logps/rejected': -287.16357421875, 'referece_logps/chosen': -312.1265563964844, 'logits/rejected': -0.6511831283569336, 'logits/chosen': -0.6711269617080688, 'epoch': 0.03}

  1%|          | 30/2685 [10:06<15:19:23, 20.78s/it]


  1%|          | 32/2685 [10:50<15:56:41, 21.64s/it]
{'loss': 0.6873, 'learning_rate': 7.901234567901234e-07, 'rewards/chosen': 0.004148291889578104, 'rewards/rejected': -0.015274048782885075, 'rewards/accuracies': 0.5, 'rewards/margins': 0.019422343000769615, 'policy_logps/rejected': -280.90838623046875, 'policy_logps/chosen': -330.2164001464844, 'referece_logps/rejected': -280.75567626953125, 'referece_logps/chosen': -330.2579345703125, 'logits/rejected': -0.5382530093193054, 'logits/chosen': -0.6471325755119324, 'epoch': 0.04}

  1%|          | 33/2685 [11:11<15:41:01, 21.29s/it]
[2024-03-29 15:43:51,635] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 34/2685 [11:34<16:08:52, 21.93s/it]
[2024-03-29 15:44:12,590] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  1%|▏         | 36/2685 [12:16<15:49:28, 21.51s/it]
{'loss': 0.6935, 'learning_rate': 8.888888888888888e-07, 'rewards/chosen': 0.014876509085297585, 'rewards/rejected': 0.011220932006835938, 'rewards/accuracies': 0.625, 'rewards/margins': 0.003655575215816498, 'policy_logps/rejected': -337.7150573730469, 'policy_logps/chosen': -295.64532470703125, 'referece_logps/rejected': -337.8272705078125, 'referece_logps/chosen': -295.79412841796875, 'logits/rejected': -0.07794997841119766, 'logits/chosen': -0.22068250179290771, 'epoch': 0.04}
[2024-03-29 15:44:55,485] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 37/2685 [12:38<15:51:45, 21.57s/it]

  1%|▏         | 38/2685 [13:00<15:58:56, 21.74s/it]

  1%|▏         | 39/2685 [13:19<15:20:45, 20.88s/it]

  1%|▏         | 40/2685 [13:43<16:01:30, 21.81s/it]
[2024-03-29 15:46:20,863] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 41/2685 [14:03<15:42:04, 21.38s/it]

  2%|▏         | 42/2685 [14:20<14:42:01, 20.02s/it]
[2024-03-29 15:46:59,064] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 43/2685 [14:42<14:59:04, 20.42s/it]
[2024-03-29 15:47:18,778] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 44/2685 [15:01<14:49:25, 20.21s/it]

  2%|▏         | 45/2685 [15:20<14:29:19, 19.76s/it]
[2024-03-29 15:47:59,519] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 46/2685 [15:42<14:59:00, 20.44s/it]

  2%|▏         | 47/2685 [16:06<15:44:29, 21.48s/it]

  2%|▏         | 48/2685 [16:26<15:23:59, 21.02s/it]

  2%|▏         | 49/2685 [16:49<15:46:40, 21.55s/it]

  2%|▏         | 50/2685 [17:11<16:01:33, 21.90s/it]

  2%|▏         | 51/2685 [17:33<16:03:28, 21.95s/it]

  2%|▏         | 52/2685 [17:56<16:05:30, 22.00s/it]
[2024-03-29 15:50:35,050] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 53/2685 [18:18<16:04:58, 22.00s/it]


  2%|▏         | 55/2685 [18:49<13:31:13, 18.51s/it]
{'loss': 0.6833, 'learning_rate': 1.3580246913580246e-06, 'rewards/chosen': -0.011555289849638939, 'rewards/rejected': -0.02578716352581978, 'rewards/accuracies': 0.625, 'rewards/margins': 0.014231875538825989, 'policy_logps/rejected': -400.0561218261719, 'policy_logps/chosen': -315.5346374511719, 'referece_logps/rejected': -399.7982177734375, 'referece_logps/chosen': -315.4190673828125, 'logits/rejected': -0.7229138612747192, 'logits/chosen': -0.8099198341369629, 'epoch': 0.06}

  2%|▏         | 56/2685 [19:08<13:46:32, 18.86s/it]

  2%|▏         | 57/2685 [19:30<14:19:52, 19.63s/it]

  2%|▏         | 58/2685 [19:52<14:47:17, 20.27s/it]
[2024-03-29 15:52:32,670] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 59/2685 [20:15<15:30:19, 21.26s/it]

  2%|▏         | 60/2685 [20:33<14:37:54, 20.07s/it]


  2%|▏         | 62/2685 [21:15<15:02:11, 20.64s/it]
{'loss': 0.6621, 'learning_rate': 1.530864197530864e-06, 'rewards/chosen': -0.01054458785802126, 'rewards/rejected': -0.0264205913990736, 'rewards/accuracies': 0.5, 'rewards/margins': 0.015876008197665215, 'policy_logps/rejected': -234.6898651123047, 'policy_logps/chosen': -320.63433837890625, 'referece_logps/rejected': -234.42568969726562, 'referece_logps/chosen': -320.5289001464844, 'logits/rejected': -0.4705810546875, 'logits/chosen': -0.37193411588668823, 'epoch': 0.07}
[2024-03-29 15:53:53,750] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 63/2685 [21:36<15:11:23, 20.86s/it]
[2024-03-29 15:54:15,737] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 64/2685 [21:58<15:25:52, 21.19s/it]

  2%|▏         | 65/2685 [22:17<14:46:43, 20.31s/it]

  2%|▏         | 66/2685 [22:38<15:00:02, 20.62s/it]

  2%|▏         | 67/2685 [22:58<14:49:58, 20.40s/it]

  3%|▎         | 68/2685 [23:18<14:44:12, 20.27s/it]

  3%|▎         | 69/2685 [23:34<13:54:58, 19.15s/it]

  3%|▎         | 70/2685 [23:53<13:51:32, 19.08s/it]
[2024-03-29 15:56:32,924] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 71/2685 [24:15<14:33:17, 20.04s/it]

  3%|▎         | 72/2685 [24:33<13:58:29, 19.25s/it]

  3%|▎         | 73/2685 [24:53<14:06:16, 19.44s/it]

  3%|▎         | 74/2685 [25:15<14:48:54, 20.43s/it]

  3%|▎         | 75/2685 [25:36<14:52:53, 20.53s/it]

  3%|▎         | 76/2685 [26:00<15:30:19, 21.39s/it]

  3%|▎         | 77/2685 [26:21<15:22:32, 21.22s/it]

  3%|▎         | 78/2685 [26:40<15:03:16, 20.79s/it]


  3%|▎         | 80/2685 [27:18<14:25:57, 19.95s/it]

  3%|▎         | 81/2685 [27:37<14:03:53, 19.44s/it]

  3%|▎         | 82/2685 [27:58<14:23:49, 19.91s/it]
[2024-03-29 16:00:15,078] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 83/2685 [28:21<15:06:21, 20.90s/it]

  3%|▎         | 84/2685 [28:41<14:55:15, 20.65s/it]

  3%|▎         | 85/2685 [29:05<15:35:03, 21.58s/it]

  3%|▎         | 86/2685 [29:25<15:23:56, 21.33s/it]

  3%|▎         | 87/2685 [29:47<15:26:35, 21.40s/it]

  3%|▎         | 88/2685 [30:05<14:41:41, 20.37s/it]
{'loss': 0.6362, 'learning_rate': 1.9999643400041095e-06, 'rewards/chosen': -0.11128368228673935, 'rewards/rejected': -0.14075861871242523, 'rewards/accuracies': 0.625, 'rewards/margins': 0.029474928975105286, 'policy_logps/rejected': -427.5963439941406, 'policy_logps/chosen': -367.5390930175781, 'referece_logps/rejected': -426.188720703125, 'referece_logps/chosen': -366.4262390136719, 'logits/rejected': -0.008986242115497589, 'logits/chosen': -0.06446776539087296, 'epoch': 0.1}


  3%|▎         | 90/2685 [30:47<14:49:44, 20.57s/it]

  3%|▎         | 91/2685 [31:07<14:44:42, 20.46s/it]

  3%|▎         | 92/2685 [31:23<13:40:32, 18.99s/it]

  3%|▎         | 93/2685 [31:39<13:05:44, 18.19s/it]

  4%|▎         | 94/2685 [32:01<13:53:46, 19.31s/it]

  4%|▎         | 95/2685 [32:21<14:03:55, 19.55s/it]

  4%|▎         | 96/2685 [32:43<14:30:21, 20.17s/it]

  4%|▎         | 97/2685 [33:01<14:08:56, 19.68s/it]
{'loss': 0.6092, 'learning_rate': 1.9998136993930044e-06, 'rewards/chosen': 0.0710507407784462, 'rewards/rejected': -0.30778568983078003, 'rewards/accuracies': 1.0, 'rewards/margins': 0.378836452960968, 'policy_logps/rejected': -318.29046630859375, 'policy_logps/chosen': -176.39744567871094, 'referece_logps/rejected': -315.21258544921875, 'referece_logps/chosen': -177.1079559326172, 'logits/rejected': 0.06368366628885269, 'logits/chosen': 0.038112714886665344, 'epoch': 0.11}


  4%|▎         | 99/2685 [33:47<15:17:39, 21.29s/it]

  4%|▎         | 100/2685 [34:08<15:09:23, 21.11s/it]
{'loss': 0.588, 'learning_rate': 1.9997372903805266e-06, 'rewards/chosen': -0.6737027168273926, 'rewards/rejected': -0.8394128680229187, 'rewards/accuracies': 0.5, 'rewards/margins': 0.16571027040481567, 'policy_logps/rejected': -467.8696594238281, 'policy_logps/chosen': -450.30902099609375, 'referece_logps/rejected': -459.4755554199219, 'referece_logps/chosen': -443.572021484375, 'logits/rejected': 0.40134894847869873, 'logits/chosen': 0.3562915027141571, 'epoch': 0.11}


  4%|▍         | 102/2685 [34:49<14:49:56, 20.67s/it]
{'loss': 0.6004, 'learning_rate': 1.9996790752964303e-06, 'rewards/chosen': -0.14667245745658875, 'rewards/rejected': -0.6196852326393127, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4730128049850464, 'policy_logps/rejected': -426.4983215332031, 'policy_logps/chosen': -358.21160888671875, 'referece_logps/rejected': -420.3014831542969, 'referece_logps/chosen': -356.7449035644531, 'logits/rejected': 0.012230992317199707, 'logits/chosen': 0.052910275757312775, 'epoch': 0.11}


  4%|▍         | 104/2685 [35:29<14:31:00, 20.25s/it]

  4%|▍         | 105/2685 [35:49<14:30:38, 20.25s/it]

  4%|▍         | 106/2685 [36:12<14:59:28, 20.93s/it]

  4%|▍         | 107/2685 [36:35<15:33:52, 21.73s/it]
{'loss': 0.5851, 'learning_rate': 1.999508075020784e-06, 'rewards/chosen': 0.019409751519560814, 'rewards/rejected': -0.08223876357078552, 'rewards/accuracies': 0.5, 'rewards/margins': 0.10164850950241089, 'policy_logps/rejected': -179.64297485351562, 'policy_logps/chosen': -179.10549926757812, 'referece_logps/rejected': -178.82057189941406, 'referece_logps/chosen': -179.29959106445312, 'logits/rejected': -0.21797336637973785, 'logits/chosen': -0.3092045485973358, 'epoch': 0.12}

  4%|▍         | 108/2685 [36:54<14:58:34, 20.92s/it]

  4%|▍         | 109/2685 [37:14<14:44:11, 20.59s/it]


  4%|▍         | 111/2685 [37:50<13:34:00, 18.97s/it]

  4%|▍         | 112/2685 [38:07<13:10:13, 18.43s/it]

  4%|▍         | 113/2685 [38:29<13:58:46, 19.57s/it]

  4%|▍         | 114/2685 [38:51<14:32:04, 20.35s/it]

  4%|▍         | 115/2685 [39:13<14:51:58, 20.82s/it]
{'loss': 0.6115, 'learning_rate': 1.9991588281537217e-06, 'rewards/chosen': 0.0014354721643030643, 'rewards/rejected': -0.23281536996364594, 'rewards/accuracies': 0.75, 'rewards/margins': 0.23425082862377167, 'policy_logps/rejected': -372.4371643066406, 'policy_logps/chosen': -410.46868896484375, 'referece_logps/rejected': -370.1089782714844, 'referece_logps/chosen': -410.4830627441406, 'logits/rejected': -0.47401782870292664, 'logits/chosen': -0.5315930843353271, 'epoch': 0.13}


  4%|▍         | 117/2685 [39:57<15:16:16, 21.41s/it]
{'loss': 0.5656, 'learning_rate': 1.999056972145032e-06, 'rewards/chosen': -0.12368737161159515, 'rewards/rejected': -0.7013862729072571, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5776989459991455, 'policy_logps/rejected': -394.184814453125, 'policy_logps/chosen': -348.2808837890625, 'referece_logps/rejected': -387.1709899902344, 'referece_logps/chosen': -347.04400634765625, 'logits/rejected': -0.5933892726898193, 'logits/chosen': -0.8254623413085938, 'epoch': 0.13}


  4%|▍         | 119/2685 [40:39<15:05:03, 21.16s/it]

  4%|▍         | 120/2685 [40:59<14:49:15, 20.80s/it]

  5%|▍         | 121/2685 [41:21<15:09:34, 21.28s/it]

  5%|▍         | 122/2685 [41:43<15:11:50, 21.35s/it]
{'loss': 0.5498, 'learning_rate': 1.998776885959594e-06, 'rewards/chosen': -0.62583327293396, 'rewards/rejected': -0.7652149796485901, 'rewards/accuracies': 0.75, 'rewards/margins': 0.13938169181346893, 'policy_logps/rejected': -407.0653076171875, 'policy_logps/chosen': -335.1055908203125, 'referece_logps/rejected': -399.4131774902344, 'referece_logps/chosen': -328.84716796875, 'logits/rejected': 0.495607852935791, 'logits/chosen': 0.45386841893196106, 'epoch': 0.14}


  5%|▍         | 124/2685 [42:19<13:52:15, 19.50s/it]

  5%|▍         | 125/2685 [42:40<14:08:17, 19.88s/it]

  5%|▍         | 126/2685 [42:58<13:46:25, 19.38s/it]

  5%|▍         | 127/2685 [43:19<14:07:25, 19.88s/it]

  5%|▍         | 128/2685 [43:37<13:45:25, 19.37s/it]
{'loss': 0.5508, 'learning_rate': 1.9983928103046025e-06, 'rewards/chosen': -0.07320785522460938, 'rewards/rejected': -0.42058277130126953, 'rewards/accuracies': 0.625, 'rewards/margins': 0.34737491607666016, 'policy_logps/rejected': -341.2236328125, 'policy_logps/chosen': -369.3951110839844, 'referece_logps/rejected': -337.017822265625, 'referece_logps/chosen': -368.66302490234375, 'logits/rejected': 0.33959412574768066, 'logits/chosen': 0.26188361644744873, 'epoch': 0.14}


  5%|▍         | 130/2685 [44:20<14:25:42, 20.33s/it]

  5%|▍         | 131/2685 [44:38<13:53:39, 19.58s/it]

  5%|▍         | 132/2685 [44:58<14:01:51, 19.78s/it]

  5%|▍         | 133/2685 [45:14<13:16:44, 18.73s/it]

  5%|▍         | 134/2685 [45:38<14:18:13, 20.19s/it]

  5%|▌         | 135/2685 [45:59<14:34:16, 20.57s/it]
{'loss': 0.5985, 'learning_rate': 1.997878604232291e-06, 'rewards/chosen': -0.33565929532051086, 'rewards/rejected': -0.37114888429641724, 'rewards/accuracies': 0.625, 'rewards/margins': 0.03548955172300339, 'policy_logps/rejected': -313.0182800292969, 'policy_logps/chosen': -327.52374267578125, 'referece_logps/rejected': -309.3067626953125, 'referece_logps/chosen': -324.1671447753906, 'logits/rejected': -0.14073674380779266, 'logits/chosen': -0.15542522072792053, 'epoch': 0.15}


  5%|▌         | 137/2685 [46:46<15:33:10, 21.97s/it]

  5%|▌         | 138/2685 [47:04<14:45:22, 20.86s/it]
{'loss': 0.5325, 'learning_rate': 1.997636441548347e-06, 'rewards/chosen': -0.6732919812202454, 'rewards/rejected': -0.86126309633255, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1879711151123047, 'policy_logps/rejected': -337.91290283203125, 'policy_logps/chosen': -368.84881591796875, 'referece_logps/rejected': -329.30029296875, 'referece_logps/chosen': -362.1158447265625, 'logits/rejected': 0.055591143667697906, 'logits/chosen': 0.09484488517045975, 'epoch': 0.15}

  5%|▌         | 139/2685 [47:23<14:16:14, 20.18s/it]


  5%|▌         | 141/2685 [48:02<14:14:17, 20.15s/it]

  5%|▌         | 142/2685 [48:24<14:34:18, 20.63s/it]

  5%|▌         | 143/2685 [48:44<14:21:11, 20.33s/it]

  5%|▌         | 144/2685 [49:04<14:21:12, 20.34s/it]

  5%|▌         | 145/2685 [49:21<13:43:59, 19.46s/it]

  5%|▌         | 146/2685 [49:44<14:20:20, 20.33s/it]

  5%|▌         | 147/2685 [50:04<14:16:15, 20.24s/it]

  6%|▌         | 148/2685 [50:25<14:21:08, 20.37s/it]
{'loss': 0.5154, 'learning_rate': 1.9967348667050058e-06, 'rewards/chosen': -1.042487382888794, 'rewards/rejected': -1.5064647197723389, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4639773964881897, 'policy_logps/rejected': -532.75, 'policy_logps/chosen': -583.8294677734375, 'referece_logps/rejected': -517.6854248046875, 'referece_logps/chosen': -573.4046020507812, 'logits/rejected': 1.508563756942749, 'logits/chosen': 1.5438380241394043, 'epoch': 0.17}


  6%|▌         | 150/2685 [51:04<13:59:46, 19.88s/it]
{'loss': 0.5981, 'learning_rate': 1.9965371381818598e-06, 'rewards/chosen': 0.1607881486415863, 'rewards/rejected': -0.5008211135864258, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6616092920303345, 'policy_logps/rejected': -311.42022705078125, 'policy_logps/chosen': -199.07069396972656, 'referece_logps/rejected': -306.4119873046875, 'referece_logps/chosen': -200.67857360839844, 'logits/rejected': -0.42923763394355774, 'logits/chosen': -0.3375261127948761, 'epoch': 0.17}


  6%|▌         | 152/2685 [51:36<12:41:42, 18.04s/it]

  6%|▌         | 153/2685 [52:00<13:52:07, 19.72s/it]

  6%|▌         | 154/2685 [52:21<14:09:49, 20.15s/it]

  6%|▌         | 155/2685 [52:40<13:56:40, 19.84s/it]

  6%|▌         | 156/2685 [53:00<13:55:45, 19.83s/it]

  6%|▌         | 157/2685 [53:20<13:58:43, 19.91s/it]

  6%|▌         | 158/2685 [53:42<14:28:10, 20.61s/it]

  6%|▌         | 159/2685 [53:59<13:39:45, 19.47s/it]

  6%|▌         | 160/2685 [54:21<14:06:40, 20.12s/it]

  6%|▌         | 161/2685 [54:43<14:31:14, 20.71s/it]

  6%|▌         | 162/2685 [55:00<13:44:16, 19.60s/it]

  6%|▌         | 163/2685 [55:18<13:31:11, 19.30s/it]

  6%|▌         | 164/2685 [55:40<13:58:28, 19.96s/it]

  6%|▌         | 165/2685 [56:00<14:01:01, 20.02s/it]
{'loss': 0.4496, 'learning_rate': 1.994869323391895e-06, 'rewards/chosen': -0.7347723245620728, 'rewards/rejected': -1.4845678806304932, 'rewards/accuracies': 1.0, 'rewards/margins': 0.74979567527771, 'policy_logps/rejected': -374.6355285644531, 'policy_logps/chosen': -375.3148193359375, 'referece_logps/rejected': -359.78985595703125, 'referece_logps/chosen': -367.9670715332031, 'logits/rejected': -0.0725158303976059, 'logits/chosen': -0.08378949016332626, 'epoch': 0.18}


  6%|▌         | 167/2685 [56:41<14:08:48, 20.23s/it]

  6%|▋         | 168/2685 [57:01<14:02:46, 20.09s/it]

  6%|▋         | 169/2685 [57:22<14:19:12, 20.49s/it]

  6%|▋         | 170/2685 [57:43<14:18:42, 20.49s/it]

  6%|▋         | 171/2685 [58:04<14:28:01, 20.72s/it]

  6%|▋         | 172/2685 [58:26<14:45:33, 21.14s/it]

  6%|▋         | 173/2685 [58:39<13:04:10, 18.73s/it]

  6%|▋         | 174/2685 [59:00<13:31:00, 19.38s/it]

  7%|▋         | 175/2685 [59:21<13:48:17, 19.80s/it]

  7%|▋         | 176/2685 [59:41<13:46:43, 19.77s/it]
{'loss': 0.5476, 'learning_rate': 1.9934391586095946e-06, 'rewards/chosen': -0.47414475679397583, 'rewards/rejected': -0.7766756415367126, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3025309443473816, 'policy_logps/rejected': -313.28179931640625, 'policy_logps/chosen': -256.3992919921875, 'referece_logps/rejected': -305.5150451660156, 'referece_logps/chosen': -251.65785217285156, 'logits/rejected': -0.02245987206697464, 'logits/chosen': -0.0924510806798935, 'epoch': 0.2}


  7%|▋         | 178/2685 [1:00:17<13:18:19, 19.11s/it]

  7%|▋         | 179/2685 [1:00:35<13:10:58, 18.94s/it]

  7%|▋         | 180/2685 [1:00:53<12:56:47, 18.61s/it]

  7%|▋         | 181/2685 [1:01:12<13:06:16, 18.84s/it]

  7%|▋         | 182/2685 [1:01:31<13:01:52, 18.74s/it]

  7%|▋         | 183/2685 [1:01:49<12:52:40, 18.53s/it]

  7%|▋         | 184/2685 [1:02:11<13:32:05, 19.48s/it]

  7%|▋         | 185/2685 [1:02:31<13:44:36, 19.79s/it]
{'loss': 0.4618, 'learning_rate': 1.9921388761311075e-06, 'rewards/chosen': -0.36237066984176636, 'rewards/rejected': -1.434846043586731, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0724751949310303, 'policy_logps/rejected': -604.534912109375, 'policy_logps/chosen': -506.2093505859375, 'referece_logps/rejected': -590.1864624023438, 'referece_logps/chosen': -502.58563232421875, 'logits/rejected': 0.7485019564628601, 'logits/chosen': 0.6821599006652832, 'epoch': 0.21}


  7%|▋         | 187/2685 [1:03:14<14:20:35, 20.67s/it]

  7%|▋         | 188/2685 [1:03:36<14:25:29, 20.80s/it]

  7%|▋         | 189/2685 [1:03:53<13:40:47, 19.73s/it]

  7%|▋         | 190/2685 [1:04:10<13:03:55, 18.85s/it]

  7%|▋         | 191/2685 [1:04:33<14:05:44, 20.35s/it]
{'loss': 0.5093, 'learning_rate': 1.9912070283030093e-06, 'rewards/chosen': -0.4447264075279236, 'rewards/rejected': -1.2603942155838013, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8156678080558777, 'policy_logps/rejected': -416.2588195800781, 'policy_logps/chosen': -375.87774658203125, 'referece_logps/rejected': -403.6548156738281, 'referece_logps/chosen': -371.4304504394531, 'logits/rejected': 0.3834698796272278, 'logits/chosen': 0.17881697416305542, 'epoch': 0.21}

  7%|▋         | 192/2685 [1:04:54<14:06:32, 20.37s/it]

  7%|▋         | 193/2685 [1:05:16<14:26:34, 20.86s/it]

  7%|▋         | 194/2685 [1:05:38<14:44:12, 21.30s/it]

  7%|▋         | 195/2685 [1:06:00<14:55:53, 21.59s/it]

  7%|▋         | 196/2685 [1:06:22<14:57:00, 21.62s/it]

  7%|▋         | 197/2685 [1:06:43<14:43:51, 21.31s/it]


  7%|▋         | 199/2685 [1:07:26<14:44:32, 21.35s/it]
{'loss': 0.5023, 'learning_rate': 1.989883781376592e-06, 'rewards/chosen': -1.2490112781524658, 'rewards/rejected': -2.0304715633392334, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7814602255821228, 'policy_logps/rejected': -506.2373046875, 'policy_logps/chosen': -514.3060913085938, 'referece_logps/rejected': -485.9325866699219, 'referece_logps/chosen': -501.81597900390625, 'logits/rejected': -0.12908336520195007, 'logits/chosen': -0.04586811363697052, 'epoch': 0.22}


  7%|▋         | 201/2685 [1:08:08<14:39:02, 21.23s/it]
{'loss': 0.4871, 'learning_rate': 1.9895385568095978e-06, 'rewards/chosen': -0.40575021505355835, 'rewards/rejected': -1.7612513303756714, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3555012941360474, 'policy_logps/rejected': -392.49267578125, 'policy_logps/chosen': -308.32489013671875, 'referece_logps/rejected': -374.8801574707031, 'referece_logps/chosen': -304.26739501953125, 'logits/rejected': 0.0948667973279953, 'logits/chosen': 0.09977315366268158, 'epoch': 0.22}


  8%|▊         | 203/2685 [1:08:48<14:17:19, 20.72s/it]
{'loss': 0.5086, 'learning_rate': 1.9891875710779553e-06, 'rewards/chosen': -0.4862295389175415, 'rewards/rejected': -1.5927841663360596, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1065545082092285, 'policy_logps/rejected': -345.15997314453125, 'policy_logps/chosen': -287.9708251953125, 'referece_logps/rejected': -329.2321472167969, 'referece_logps/chosen': -283.1085205078125, 'logits/rejected': -0.20788946747779846, 'logits/chosen': -0.18018963932991028, 'epoch': 0.23}

  8%|▊         | 204/2685 [1:09:09<14:22:13, 20.85s/it]

  8%|▊         | 205/2685 [1:09:27<13:41:19, 19.87s/it]

  8%|▊         | 206/2685 [1:09:47<13:47:19, 20.02s/it]


  8%|▊         | 208/2685 [1:10:23<13:08:41, 19.10s/it]
{'loss': 0.4891, 'learning_rate': 1.9882849151462577e-06, 'rewards/chosen': -0.649541437625885, 'rewards/rejected': -1.692919135093689, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0433777570724487, 'policy_logps/rejected': -449.6873474121094, 'policy_logps/chosen': -454.64788818359375, 'referece_logps/rejected': -432.7581787109375, 'referece_logps/chosen': -448.1524658203125, 'logits/rejected': 0.4400571584701538, 'logits/chosen': 0.4935503900051117, 'epoch': 0.23}


  8%|▊         | 210/2685 [1:11:05<13:45:19, 20.01s/it]

  8%|▊         | 211/2685 [1:11:26<13:48:11, 20.09s/it]

  8%|▊         | 212/2685 [1:11:46<13:49:11, 20.12s/it]

  8%|▊         | 213/2685 [1:12:06<13:46:24, 20.06s/it]
{'loss': 0.5098, 'learning_rate': 1.9873462976445554e-06, 'rewards/chosen': -1.2369394302368164, 'rewards/rejected': -2.240429401397705, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0034899711608887, 'policy_logps/rejected': -427.4596862792969, 'policy_logps/chosen': -436.090576171875, 'referece_logps/rejected': -405.055419921875, 'referece_logps/chosen': -423.72119140625, 'logits/rejected': -0.31119054555892944, 'logits/chosen': -0.3371155261993408, 'epoch': 0.24}


  8%|▊         | 215/2685 [1:12:46<13:43:54, 20.01s/it]

  8%|▊         | 216/2685 [1:13:04<13:20:30, 19.45s/it]

  8%|▊         | 217/2685 [1:13:23<13:17:11, 19.38s/it]
{'loss': 0.5365, 'learning_rate': 1.98656953422053e-06, 'rewards/chosen': -0.47265928983688354, 'rewards/rejected': -1.098441243171692, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6257819533348083, 'policy_logps/rejected': -314.94921875, 'policy_logps/chosen': -336.13372802734375, 'referece_logps/rejected': -303.9648132324219, 'referece_logps/chosen': -331.4071350097656, 'logits/rejected': -0.34612932801246643, 'logits/chosen': -0.2143845111131668, 'epoch': 0.24}

  8%|▊         | 218/2685 [1:13:43<13:16:26, 19.37s/it]


  8%|▊         | 220/2685 [1:14:24<13:40:40, 19.98s/it]
{'loss': 0.5135, 'learning_rate': 1.985971882983256e-06, 'rewards/chosen': -0.9497959017753601, 'rewards/rejected': -2.1400723457336426, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1902765035629272, 'policy_logps/rejected': -533.5852661132812, 'policy_logps/chosen': -367.0538330078125, 'referece_logps/rejected': -512.1845092773438, 'referece_logps/chosen': -357.5558776855469, 'logits/rejected': -0.14111611247062683, 'logits/chosen': -0.17111116647720337, 'epoch': 0.25}

  8%|▊         | 221/2685 [1:14:45<13:45:47, 20.11s/it]


  8%|▊         | 223/2685 [1:15:24<13:36:25, 19.90s/it]
{'loss': 0.5456, 'learning_rate': 1.985361315855577e-06, 'rewards/chosen': -0.09966689348220825, 'rewards/rejected': -0.6459248661994934, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5462579727172852, 'policy_logps/rejected': -217.36334228515625, 'policy_logps/chosen': -163.43702697753906, 'referece_logps/rejected': -210.9040985107422, 'referece_logps/chosen': -162.4403533935547, 'logits/rejected': -1.0521495342254639, 'logits/chosen': -1.162536859512329, 'epoch': 0.25}


  8%|▊         | 225/2685 [1:16:06<14:00:19, 20.50s/it]
{'loss': 0.5188, 'learning_rate': 1.9849470995518993e-06, 'rewards/chosen': -0.6470991373062134, 'rewards/rejected': -1.2477304935455322, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6006312966346741, 'policy_logps/rejected': -343.57025146484375, 'policy_logps/chosen': -365.24700927734375, 'referece_logps/rejected': -331.09295654296875, 'referece_logps/chosen': -358.7759704589844, 'logits/rejected': -0.008831365033984184, 'logits/chosen': -0.07156405597925186, 'epoch': 0.25}

  8%|▊         | 226/2685 [1:16:25<13:35:35, 19.90s/it]


  8%|▊         | 228/2685 [1:17:00<12:42:29, 18.62s/it]
{'loss': 0.4076, 'learning_rate': 1.9843150237975342e-06, 'rewards/chosen': -0.6793645620346069, 'rewards/rejected': -1.688929557800293, 'rewards/accuracies': 1.0, 'rewards/margins': 1.009564995765686, 'policy_logps/rejected': -334.48095703125, 'policy_logps/chosen': -285.5515441894531, 'referece_logps/rejected': -317.5917053222656, 'referece_logps/chosen': -278.75787353515625, 'logits/rejected': -0.34478357434272766, 'logits/chosen': -0.3495280146598816, 'epoch': 0.25}

  9%|▊         | 229/2685 [1:17:15<11:57:57, 17.54s/it]

  9%|▊         | 230/2685 [1:17:33<12:02:13, 17.65s/it]


  9%|▊         | 232/2685 [1:18:12<12:44:38, 18.70s/it]
{'loss': 0.4754, 'learning_rate': 1.983452199957626e-06, 'rewards/chosen': -0.4058591425418854, 'rewards/rejected': -2.0992515087127686, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6933921575546265, 'policy_logps/rejected': -384.02276611328125, 'policy_logps/chosen': -379.0535583496094, 'referece_logps/rejected': -363.0302429199219, 'referece_logps/chosen': -374.9950256347656, 'logits/rejected': -0.13381308317184448, 'logits/chosen': -0.21913407742977142, 'epoch': 0.26}

  9%|▊         | 233/2685 [1:18:33<13:08:47, 19.30s/it]


  9%|▉         | 235/2685 [1:19:13<13:19:07, 19.57s/it]

  9%|▉         | 236/2685 [1:19:34<13:43:24, 20.17s/it]

  9%|▉         | 237/2685 [1:19:54<13:41:46, 20.14s/it]

  9%|▉         | 238/2685 [1:20:17<14:08:30, 20.81s/it]

  9%|▉         | 239/2685 [1:20:36<13:55:12, 20.49s/it]

  9%|▉         | 240/2685 [1:20:56<13:44:58, 20.24s/it]
{'loss': 0.44, 'learning_rate': 1.9816578642515498e-06, 'rewards/chosen': -0.4064316749572754, 'rewards/rejected': -1.7915103435516357, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3850786685943604, 'policy_logps/rejected': -341.11065673828125, 'policy_logps/chosen': -235.72377014160156, 'referece_logps/rejected': -323.195556640625, 'referece_logps/chosen': -231.65945434570312, 'logits/rejected': -0.5044101476669312, 'logits/chosen': -0.4916599988937378, 'epoch': 0.27}

  9%|▉         | 241/2685 [1:21:18<14:05:08, 20.75s/it]

  9%|▉         | 242/2685 [1:21:39<14:10:24, 20.89s/it]


  9%|▉         | 244/2685 [1:22:22<14:26:41, 21.30s/it]

  9%|▉         | 245/2685 [1:22:44<14:33:46, 21.49s/it]
{'loss': 0.5074, 'learning_rate': 1.9804899571364166e-06, 'rewards/chosen': -0.9112635254859924, 'rewards/rejected': -1.9944498538970947, 'rewards/accuracies': 0.875, 'rewards/margins': 1.083186388015747, 'policy_logps/rejected': -431.9429626464844, 'policy_logps/chosen': -424.4173583984375, 'referece_logps/rejected': -411.9984436035156, 'referece_logps/chosen': -415.3046875, 'logits/rejected': -0.69062739610672, 'logits/chosen': -0.7703356146812439, 'epoch': 0.27}

  9%|▉         | 246/2685 [1:23:04<14:11:21, 20.94s/it]

  9%|▉         | 247/2685 [1:23:23<13:53:41, 20.52s/it]

  9%|▉         | 248/2685 [1:23:45<14:11:58, 20.98s/it]


  9%|▉         | 250/2685 [1:24:28<14:20:16, 21.20s/it]

  9%|▉         | 251/2685 [1:24:49<14:12:32, 21.02s/it]

  9%|▉         | 252/2685 [1:25:09<13:58:12, 20.67s/it]

  9%|▉         | 253/2685 [1:25:25<13:00:46, 19.26s/it]
{'loss': 0.4553, 'learning_rate': 1.978547113826699e-06, 'rewards/chosen': -2.0559463500976562, 'rewards/rejected': -2.2436599731445312, 'rewards/accuracies': 0.625, 'rewards/margins': 0.18771377205848694, 'policy_logps/rejected': -460.87225341796875, 'policy_logps/chosen': -491.9967346191406, 'referece_logps/rejected': -438.4356689453125, 'referece_logps/chosen': -471.43731689453125, 'logits/rejected': 0.07797625660896301, 'logits/chosen': 0.14108973741531372, 'epoch': 0.28}

  9%|▉         | 254/2685 [1:25:43<12:52:29, 19.07s/it]

  9%|▉         | 255/2685 [1:26:03<13:02:05, 19.31s/it]


 10%|▉         | 257/2685 [1:26:45<13:28:52, 19.99s/it]

 10%|▉         | 258/2685 [1:27:07<13:51:25, 20.55s/it]

 10%|▉         | 259/2685 [1:27:23<12:54:02, 19.14s/it]
{'loss': 0.4508, 'learning_rate': 1.977030151260355e-06, 'rewards/chosen': -0.46915867924690247, 'rewards/rejected': -1.2418248653411865, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7726660966873169, 'policy_logps/rejected': -512.5265502929688, 'policy_logps/chosen': -509.84906005859375, 'referece_logps/rejected': -500.10833740234375, 'referece_logps/chosen': -505.1573791503906, 'logits/rejected': -0.6543601751327515, 'logits/chosen': -0.6158028244972229, 'epoch': 0.29}

 10%|▉         | 260/2685 [1:27:42<12:59:45, 19.29s/it]


 10%|▉         | 262/2685 [1:28:20<12:46:37, 18.98s/it]

 10%|▉         | 263/2685 [1:28:42<13:23:33, 19.91s/it]
{'loss': 0.4422, 'learning_rate': 1.9759903962771154e-06, 'rewards/chosen': -0.7405893206596375, 'rewards/rejected': -2.0548148155212402, 'rewards/accuracies': 0.875, 'rewards/margins': 1.314225435256958, 'policy_logps/rejected': -327.1550598144531, 'policy_logps/chosen': -303.5079040527344, 'referece_logps/rejected': -306.6069030761719, 'referece_logps/chosen': -296.10198974609375, 'logits/rejected': -0.7155588865280151, 'logits/chosen': -0.6148387789726257, 'epoch': 0.29}


 10%|▉         | 265/2685 [1:29:23<13:34:43, 20.20s/it]

 10%|▉         | 266/2685 [1:29:43<13:27:10, 20.02s/it]
{'loss': 0.4924, 'learning_rate': 1.975195662715787e-06, 'rewards/chosen': -1.136394739151001, 'rewards/rejected': -1.6356340646743774, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4992392957210541, 'policy_logps/rejected': -350.1277770996094, 'policy_logps/chosen': -368.99371337890625, 'referece_logps/rejected': -333.77142333984375, 'referece_logps/chosen': -357.6297607421875, 'logits/rejected': -0.9271557927131653, 'logits/chosen': -1.0065582990646362, 'epoch': 0.3}


 10%|▉         | 268/2685 [1:30:21<13:01:02, 19.39s/it]

 10%|█         | 269/2685 [1:30:39<12:40:11, 18.88s/it]

 10%|█         | 270/2685 [1:30:59<12:54:45, 19.25s/it]
{'loss': 0.4608, 'learning_rate': 1.974116147995387e-06, 'rewards/chosen': -0.7282913327217102, 'rewards/rejected': -2.1126816272735596, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3843903541564941, 'policy_logps/rejected': -439.2945556640625, 'policy_logps/chosen': -484.9952697753906, 'referece_logps/rejected': -418.167724609375, 'referece_logps/chosen': -477.7123107910156, 'logits/rejected': 0.34722790122032166, 'logits/chosen': 0.21703723073005676, 'epoch': 0.3}

 10%|█         | 271/2685 [1:31:20<13:21:07, 19.91s/it]

 10%|█         | 272/2685 [1:31:40<13:19:37, 19.88s/it]

 10%|█         | 273/2685 [1:32:00<13:24:48, 20.02s/it]

 10%|█         | 274/2685 [1:32:22<13:37:32, 20.35s/it]


 10%|█         | 276/2685 [1:32:57<12:40:17, 18.94s/it]
{'loss': 0.4815, 'learning_rate': 1.972454348670362e-06, 'rewards/chosen': -1.0969936847686768, 'rewards/rejected': -2.079493761062622, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9824998378753662, 'policy_logps/rejected': -333.3763427734375, 'policy_logps/chosen': -274.28802490234375, 'referece_logps/rejected': -312.5814208984375, 'referece_logps/chosen': -263.318115234375, 'logits/rejected': -0.39689937233924866, 'logits/chosen': -0.4321293532848358, 'epoch': 0.31}


 10%|█         | 278/2685 [1:33:36<12:53:22, 19.28s/it]
{'loss': 0.394, 'learning_rate': 1.9718890878306586e-06, 'rewards/chosen': -0.45373183488845825, 'rewards/rejected': -2.2803122997283936, 'rewards/accuracies': 0.875, 'rewards/margins': 1.826580286026001, 'policy_logps/rejected': -314.8336181640625, 'policy_logps/chosen': -329.6571350097656, 'referece_logps/rejected': -292.030517578125, 'referece_logps/chosen': -325.1198425292969, 'logits/rejected': -0.2615339756011963, 'logits/chosen': -0.18884098529815674, 'epoch': 0.31}


 10%|█         | 280/2685 [1:34:15<13:09:01, 19.68s/it]
{'loss': 0.402, 'learning_rate': 1.9713181685827844e-06, 'rewards/chosen': -1.8606176376342773, 'rewards/rejected': -1.9182472229003906, 'rewards/accuracies': 0.5, 'rewards/margins': 0.05762942135334015, 'policy_logps/rejected': -527.8834228515625, 'policy_logps/chosen': -597.12353515625, 'referece_logps/rejected': -508.7008972167969, 'referece_logps/chosen': -578.517333984375, 'logits/rejected': 1.2301661968231201, 'logits/chosen': 1.1601505279541016, 'epoch': 0.31}


 11%|█         | 282/2685 [1:34:49<12:07:36, 18.17s/it]
{'loss': 0.3512, 'learning_rate': 1.9707415942506726e-06, 'rewards/chosen': -0.1751095950603485, 'rewards/rejected': -0.9644736051559448, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7893639206886292, 'policy_logps/rejected': -335.8133850097656, 'policy_logps/chosen': -222.17787170410156, 'referece_logps/rejected': -326.16864013671875, 'referece_logps/chosen': -220.42678833007812, 'logits/rejected': -0.13797330856323242, 'logits/chosen': -0.16387122869491577, 'epoch': 0.32}

 11%|█         | 283/2685 [1:35:10<12:48:46, 19.20s/it]


 11%|█         | 285/2685 [1:35:50<12:56:23, 19.41s/it]
{'loss': 0.4596, 'learning_rate': 1.9698661368216816e-06, 'rewards/chosen': -1.2019195556640625, 'rewards/rejected': -1.619685411453247, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4177657961845398, 'policy_logps/rejected': -412.59967041015625, 'policy_logps/chosen': -483.2997131347656, 'referece_logps/rejected': -396.4028625488281, 'referece_logps/chosen': -471.280517578125, 'logits/rejected': -0.4113965928554535, 'logits/chosen': -0.46049198508262634, 'epoch': 0.32}

 11%|█         | 286/2685 [1:36:08<12:42:17, 19.07s/it]

 11%|█         | 287/2685 [1:36:25<12:14:29, 18.38s/it]


 11%|█         | 289/2685 [1:37:05<12:49:18, 19.26s/it]
{'loss': 0.3984, 'learning_rate': 1.968679099061394e-06, 'rewards/chosen': -0.2507600486278534, 'rewards/rejected': -1.9171384572982788, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6663784980773926, 'policy_logps/rejected': -473.72344970703125, 'policy_logps/chosen': -417.73870849609375, 'referece_logps/rejected': -454.5520935058594, 'referece_logps/chosen': -415.2310791015625, 'logits/rejected': -0.056313998997211456, 'logits/chosen': 0.05403481423854828, 'epoch': 0.32}

 11%|█         | 290/2685 [1:37:25<12:53:44, 19.38s/it]

 11%|█         | 291/2685 [1:37:43<12:42:08, 19.10s/it]

 11%|█         | 292/2685 [1:38:04<13:00:43, 19.58s/it]

 11%|█         | 293/2685 [1:38:24<13:04:35, 19.68s/it]

 11%|█         | 294/2685 [1:38:43<12:56:16, 19.48s/it]

 11%|█         | 295/2685 [1:39:02<12:49:42, 19.32s/it]


 11%|█         | 297/2685 [1:39:44<13:15:42, 19.99s/it]
{'loss': 0.5079, 'learning_rate': 1.966237375176093e-06, 'rewards/chosen': -1.0296279191970825, 'rewards/rejected': -2.734344720840454, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7047168016433716, 'policy_logps/rejected': -338.3765563964844, 'policy_logps/chosen': -368.9639587402344, 'referece_logps/rejected': -311.03314208984375, 'referece_logps/chosen': -358.66766357421875, 'logits/rejected': -0.9063669443130493, 'logits/chosen': -0.8544650077819824, 'epoch': 0.33}

 11%|█         | 298/2685 [1:40:04<13:20:24, 20.12s/it]

 11%|█         | 299/2685 [1:40:25<13:28:50, 20.34s/it]

 11%|█         | 300/2685 [1:40:46<13:29:12, 20.36s/it]

 11%|█         | 301/2685 [1:41:07<13:37:16, 20.57s/it]


 11%|█▏        | 303/2685 [1:41:44<12:57:26, 19.58s/it]
{'loss': 0.4341, 'learning_rate': 1.9643470021510556e-06, 'rewards/chosen': -0.8400520086288452, 'rewards/rejected': -1.1353049278259277, 'rewards/accuracies': 0.875, 'rewards/margins': 0.2952529191970825, 'policy_logps/rejected': -206.62026977539062, 'policy_logps/chosen': -248.79132080078125, 'referece_logps/rejected': -195.26722717285156, 'referece_logps/chosen': -240.3907928466797, 'logits/rejected': -0.5195475816726685, 'logits/chosen': -0.5001230239868164, 'epoch': 0.34}

 11%|█▏        | 304/2685 [1:42:04<13:06:31, 19.82s/it]

 11%|█▏        | 305/2685 [1:42:25<13:15:27, 20.05s/it]


 11%|█▏        | 307/2685 [1:43:02<12:38:23, 19.14s/it]
{'loss': 0.4262, 'learning_rate': 1.9630586748652544e-06, 'rewards/chosen': -0.8087334036827087, 'rewards/rejected': -1.382021188735962, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5732877254486084, 'policy_logps/rejected': -274.106689453125, 'policy_logps/chosen': -305.0551452636719, 'referece_logps/rejected': -260.2864685058594, 'referece_logps/chosen': -296.96783447265625, 'logits/rejected': -0.6232858300209045, 'logits/chosen': -0.5640077590942383, 'epoch': 0.34}

 11%|█▏        | 308/2685 [1:43:20<12:29:59, 18.93s/it]

 12%|█▏        | 309/2685 [1:43:41<12:49:06, 19.42s/it]

 12%|█▏        | 310/2685 [1:44:02<13:12:42, 20.03s/it]

 12%|█▏        | 311/2685 [1:44:24<13:28:32, 20.44s/it]

 12%|█▏        | 312/2685 [1:44:44<13:23:08, 20.31s/it]

 12%|█▏        | 313/2685 [1:45:03<13:14:15, 20.09s/it]


 12%|█▏        | 315/2685 [1:45:46<13:41:27, 20.80s/it]
{'loss': 0.3786, 'learning_rate': 1.960414766954328e-06, 'rewards/chosen': -0.5112947821617126, 'rewards/rejected': -1.8405193090438843, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3292244672775269, 'policy_logps/rejected': -278.1943664550781, 'policy_logps/chosen': -249.0198516845703, 'referece_logps/rejected': -259.7891845703125, 'referece_logps/chosen': -243.90689086914062, 'logits/rejected': -0.2662452459335327, 'logits/chosen': -0.31400907039642334, 'epoch': 0.35}


 12%|█▏        | 317/2685 [1:46:26<13:25:53, 20.42s/it]
{'loss': 0.5195, 'learning_rate': 1.9597398012648404e-06, 'rewards/chosen': -1.266162633895874, 'rewards/rejected': -2.104597568511963, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8384348154067993, 'policy_logps/rejected': -298.744873046875, 'policy_logps/chosen': -268.22015380859375, 'referece_logps/rejected': -277.6988830566406, 'referece_logps/chosen': -255.55850219726562, 'logits/rejected': -0.5042996406555176, 'logits/chosen': -0.34045639634132385, 'epoch': 0.35}

 12%|█▏        | 318/2685 [1:46:40<12:08:44, 18.47s/it]

 12%|█▏        | 319/2685 [1:47:02<12:47:09, 19.45s/it]

 12%|█▏        | 320/2685 [1:47:20<12:29:01, 19.00s/it]

 12%|█▏        | 321/2685 [1:47:40<12:49:46, 19.54s/it]

 12%|█▏        | 322/2685 [1:47:58<12:24:50, 18.91s/it]

 12%|█▏        | 323/2685 [1:48:19<12:53:04, 19.64s/it]


 12%|█▏        | 325/2685 [1:48:56<12:33:48, 19.16s/it]
{'loss': 0.4629, 'learning_rate': 1.95698410155021e-06, 'rewards/chosen': -1.5593260526657104, 'rewards/rejected': -2.7156081199645996, 'rewards/accuracies': 0.875, 'rewards/margins': 1.15628182888031, 'policy_logps/rejected': -386.5789794921875, 'policy_logps/chosen': -393.05078125, 'referece_logps/rejected': -359.42291259765625, 'referece_logps/chosen': -377.4575500488281, 'logits/rejected': -0.10813657939434052, 'logits/chosen': -0.16624248027801514, 'epoch': 0.36}

 12%|█▏        | 326/2685 [1:49:17<12:50:37, 19.60s/it]

 12%|█▏        | 327/2685 [1:49:35<12:38:23, 19.30s/it]

 12%|█▏        | 328/2685 [1:49:55<12:46:11, 19.50s/it]

 12%|█▏        | 329/2685 [1:50:19<13:35:59, 20.78s/it]

 12%|█▏        | 330/2685 [1:50:40<13:38:33, 20.85s/it]

 12%|█▏        | 331/2685 [1:51:00<13:23:44, 20.49s/it]

 12%|█▏        | 332/2685 [1:51:21<13:29:28, 20.64s/it]

 12%|█▏        | 333/2685 [1:51:39<12:59:38, 19.89s/it]

 12%|█▏        | 334/2685 [1:52:00<13:10:39, 20.18s/it]

 12%|█▏        | 335/2685 [1:52:20<13:05:23, 20.05s/it]

 13%|█▎        | 336/2685 [1:52:38<12:43:43, 19.51s/it]

 13%|█▎        | 337/2685 [1:53:00<13:18:31, 20.41s/it]

 13%|█▎        | 338/2685 [1:53:21<13:19:36, 20.44s/it]

 13%|█▎        | 339/2685 [1:53:41<13:20:31, 20.47s/it]

 13%|█▎        | 340/2685 [1:54:00<12:58:25, 19.92s/it]

 13%|█▎        | 341/2685 [1:54:20<12:56:26, 19.87s/it]

 13%|█▎        | 342/2685 [1:54:42<13:22:25, 20.55s/it]

 13%|█▎        | 343/2685 [1:54:58<12:29:36, 19.20s/it]

 13%|█▎        | 344/2685 [1:55:14<11:57:25, 18.39s/it]

 13%|█▎        | 345/2685 [1:55:35<12:22:07, 19.03s/it]

 13%|█▎        | 346/2685 [1:55:57<12:59:44, 20.00s/it]

 13%|█▎        | 347/2685 [1:56:15<12:38:08, 19.46s/it]

 13%|█▎        | 348/2685 [1:56:36<12:47:29, 19.70s/it]

 13%|█▎        | 349/2685 [1:56:55<12:46:10, 19.68s/it]

 13%|█▎        | 350/2685 [1:57:16<12:51:44, 19.83s/it]

 13%|█▎        | 351/2685 [1:57:37<13:06:16, 20.21s/it]

 13%|█▎        | 352/2685 [1:58:00<13:42:26, 21.15s/it]

 13%|█▎        | 353/2685 [1:58:20<13:30:35, 20.86s/it]

 13%|█▎        | 354/2685 [1:58:41<13:26:19, 20.75s/it]

 13%|█▎        | 355/2685 [1:58:58<12:43:19, 19.66s/it]

 13%|█▎        | 356/2685 [1:59:17<12:43:59, 19.68s/it]

 13%|█▎        | 357/2685 [1:59:35<12:13:15, 18.90s/it]

 13%|█▎        | 358/2685 [1:59:53<12:11:25, 18.86s/it]

 13%|█▎        | 359/2685 [2:00:14<12:37:24, 19.54s/it]

 13%|█▎        | 360/2685 [2:00:34<12:41:04, 19.64s/it]

 13%|█▎        | 361/2685 [2:00:52<12:18:53, 19.08s/it]

 13%|█▎        | 362/2685 [2:01:06<11:21:47, 17.61s/it]

 14%|█▎        | 363/2685 [2:01:24<11:26:52, 17.75s/it]

 14%|█▎        | 364/2685 [2:01:44<11:48:52, 18.33s/it]

 14%|█▎        | 365/2685 [2:02:01<11:36:43, 18.02s/it]

 14%|█▎        | 366/2685 [2:02:23<12:14:40, 19.01s/it]

 14%|█▎        | 367/2685 [2:02:44<12:41:18, 19.71s/it]

 14%|█▎        | 368/2685 [2:03:04<12:40:48, 19.70s/it]


 14%|█▍        | 370/2685 [2:03:45<13:03:11, 20.30s/it]
{'loss': 0.3939, 'learning_rate': 1.939830088059521e-06, 'rewards/chosen': -0.036623284220695496, 'rewards/rejected': -1.5348948240280151, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4982717037200928, 'policy_logps/rejected': -251.8438720703125, 'policy_logps/chosen': -187.51797485351562, 'referece_logps/rejected': -236.49490356445312, 'referece_logps/chosen': -187.15171813964844, 'logits/rejected': -0.772077202796936, 'logits/chosen': -0.7696395516395569, 'epoch': 0.41}

 14%|█▍        | 371/2685 [2:04:07<13:17:08, 20.67s/it]

 14%|█▍        | 372/2685 [2:04:26<13:06:44, 20.41s/it]

 14%|█▍        | 373/2685 [2:04:43<12:15:37, 19.09s/it]

 14%|█▍        | 374/2685 [2:05:00<11:51:20, 18.47s/it]
[2024-03-29 17:37:33,352] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 375/2685 [2:05:16<11:27:00, 17.84s/it]


 14%|█▍        | 377/2685 [2:05:57<12:25:42, 19.39s/it]

 14%|█▍        | 378/2685 [2:06:18<12:34:46, 19.63s/it]
{'loss': 0.4211, 'learning_rate': 1.9364889747693804e-06, 'rewards/chosen': -0.43476569652557373, 'rewards/rejected': -1.4702932834625244, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0355275869369507, 'policy_logps/rejected': -260.3575439453125, 'policy_logps/chosen': -239.3223114013672, 'referece_logps/rejected': -245.65460205078125, 'referece_logps/chosen': -234.97467041015625, 'logits/rejected': -0.1270633041858673, 'logits/chosen': -0.09768366813659668, 'epoch': 0.42}

 14%|█▍        | 379/2685 [2:06:37<12:33:51, 19.61s/it]

 14%|█▍        | 380/2685 [2:06:59<12:55:00, 20.17s/it]

 14%|█▍        | 381/2685 [2:07:20<13:09:30, 20.56s/it]

 14%|█▍        | 382/2685 [2:07:40<13:01:06, 20.35s/it]

 14%|█▍        | 383/2685 [2:08:00<12:54:10, 20.18s/it]

 14%|█▍        | 384/2685 [2:08:19<12:49:02, 20.05s/it]

 14%|█▍        | 385/2685 [2:08:39<12:45:01, 19.96s/it]
[2024-03-29 17:41:17,224] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 386/2685 [2:09:00<12:52:21, 20.16s/it]

 14%|█▍        | 387/2685 [2:09:22<13:18:48, 20.86s/it]

 14%|█▍        | 388/2685 [2:09:43<13:21:58, 20.95s/it]

 14%|█▍        | 389/2685 [2:10:03<13:07:13, 20.57s/it]

 15%|█▍        | 390/2685 [2:10:20<12:28:23, 19.57s/it]

 15%|█▍        | 391/2685 [2:10:39<12:21:42, 19.40s/it]

 15%|█▍        | 392/2685 [2:11:02<12:56:29, 20.32s/it]

 15%|█▍        | 393/2685 [2:11:22<12:56:41, 20.33s/it]

 15%|█▍        | 394/2685 [2:11:44<13:13:30, 20.78s/it]

 15%|█▍        | 395/2685 [2:12:01<12:33:16, 19.74s/it]

 15%|█▍        | 396/2685 [2:12:24<13:04:07, 20.55s/it]

 15%|█▍        | 397/2685 [2:12:47<13:31:03, 21.27s/it]

 15%|█▍        | 398/2685 [2:13:03<12:31:00, 19.70s/it]

 15%|█▍        | 399/2685 [2:13:23<12:32:39, 19.75s/it]

 15%|█▍        | 400/2685 [2:13:45<13:03:56, 20.59s/it]

 15%|█▍        | 401/2685 [2:14:06<13:06:03, 20.65s/it]

 15%|█▍        | 402/2685 [2:14:28<13:22:48, 21.10s/it]

 15%|█▌        | 403/2685 [2:14:45<12:38:46, 19.95s/it]

 15%|█▌        | 404/2685 [2:15:05<12:35:04, 19.86s/it]

 15%|█▌        | 405/2685 [2:15:26<12:52:40, 20.33s/it]

 15%|█▌        | 406/2685 [2:15:49<13:19:29, 21.05s/it]

 15%|█▌        | 407/2685 [2:16:09<13:06:05, 20.70s/it]

 15%|█▌        | 408/2685 [2:16:29<13:00:06, 20.56s/it]

 15%|█▌        | 409/2685 [2:16:49<12:49:48, 20.29s/it]

 15%|█▌        | 410/2685 [2:17:10<12:58:11, 20.52s/it]

 15%|█▌        | 411/2685 [2:17:29<12:44:18, 20.17s/it]

 15%|█▌        | 412/2685 [2:17:48<12:21:19, 19.57s/it]


 15%|█▌        | 414/2685 [2:18:31<13:00:57, 20.63s/it]

 15%|█▌        | 415/2685 [2:18:51<12:50:36, 20.37s/it]
{'loss': 0.3762, 'learning_rate': 1.9199066758674746e-06, 'rewards/chosen': -1.3498646020889282, 'rewards/rejected': -1.9236161708831787, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5737515687942505, 'policy_logps/rejected': -459.447265625, 'policy_logps/chosen': -448.5875549316406, 'referece_logps/rejected': -440.21112060546875, 'referece_logps/chosen': -435.0888977050781, 'logits/rejected': -0.639592707157135, 'logits/chosen': -0.5716378092765808, 'epoch': 0.46}


 16%|█▌        | 417/2685 [2:19:33<13:03:20, 20.72s/it]

 16%|█▌        | 418/2685 [2:19:50<12:27:15, 19.78s/it]

 16%|█▌        | 419/2685 [2:20:09<12:16:33, 19.50s/it]

 16%|█▌        | 420/2685 [2:20:29<12:20:01, 19.60s/it]

 16%|█▌        | 421/2685 [2:20:50<12:32:53, 19.95s/it]

 16%|█▌        | 422/2685 [2:21:10<12:38:20, 20.11s/it]
{'loss': 0.4635, 'learning_rate': 1.916562255869976e-06, 'rewards/chosen': -0.5398896932601929, 'rewards/rejected': -1.3192691802978516, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7793794870376587, 'policy_logps/rejected': -254.4686279296875, 'policy_logps/chosen': -240.64483642578125, 'referece_logps/rejected': -241.27590942382812, 'referece_logps/chosen': -235.24591064453125, 'logits/rejected': -0.6830805540084839, 'logits/chosen': -0.7214831113815308, 'epoch': 0.47}


 16%|█▌        | 424/2685 [2:21:50<12:36:40, 20.08s/it]

 16%|█▌        | 425/2685 [2:22:10<12:32:37, 19.98s/it]
{'loss': 0.3715, 'learning_rate': 1.915108907957125e-06, 'rewards/chosen': -1.2437489032745361, 'rewards/rejected': -3.853585720062256, 'rewards/accuracies': 0.875, 'rewards/margins': 2.6098365783691406, 'policy_logps/rejected': -389.69281005859375, 'policy_logps/chosen': -336.8023681640625, 'referece_logps/rejected': -351.156982421875, 'referece_logps/chosen': -324.3648681640625, 'logits/rejected': -0.8373522758483887, 'logits/chosen': -0.9019359946250916, 'epoch': 0.47}

 16%|█▌        | 426/2685 [2:22:27<11:51:54, 18.91s/it]


 16%|█▌        | 428/2685 [2:23:08<12:23:09, 19.76s/it]

 16%|█▌        | 429/2685 [2:23:28<12:31:38, 19.99s/it]

 16%|█▌        | 430/2685 [2:23:51<12:59:29, 20.74s/it]

 16%|█▌        | 431/2685 [2:24:10<12:47:36, 20.43s/it]

 16%|█▌        | 432/2685 [2:24:31<12:51:41, 20.55s/it]

 16%|█▌        | 433/2685 [2:24:51<12:46:31, 20.42s/it]

 16%|█▌        | 434/2685 [2:25:13<13:03:15, 20.88s/it]
{'loss': 0.5062, 'learning_rate': 1.9106770154971507e-06, 'rewards/chosen': -0.7076956033706665, 'rewards/rejected': -1.954763412475586, 'rewards/accuracies': 0.75, 'rewards/margins': 1.247067928314209, 'policy_logps/rejected': -351.34039306640625, 'policy_logps/chosen': -311.0481262207031, 'referece_logps/rejected': -331.792724609375, 'referece_logps/chosen': -303.9711608886719, 'logits/rejected': -0.13149091601371765, 'logits/chosen': -0.18997158110141754, 'epoch': 0.48}


 16%|█▌        | 436/2685 [2:25:53<12:41:01, 20.30s/it]

 16%|█▋        | 437/2685 [2:26:14<12:50:32, 20.57s/it]
{'loss': 0.3166, 'learning_rate': 1.909175832943666e-06, 'rewards/chosen': -0.8596876859664917, 'rewards/rejected': -2.599339723587036, 'rewards/accuracies': 0.875, 'rewards/margins': 1.739652395248413, 'policy_logps/rejected': -394.93402099609375, 'policy_logps/chosen': -396.73529052734375, 'referece_logps/rejected': -368.94061279296875, 'referece_logps/chosen': -388.1383972167969, 'logits/rejected': -0.3638761639595032, 'logits/chosen': -0.27678149938583374, 'epoch': 0.49}


 16%|█▋        | 439/2685 [2:26:55<12:44:21, 20.42s/it]

 16%|█▋        | 440/2685 [2:27:14<12:26:58, 19.96s/it]

 16%|█▋        | 441/2685 [2:27:34<12:35:10, 20.19s/it]
{'loss': 0.4364, 'learning_rate': 1.9071557331334667e-06, 'rewards/chosen': -1.4494062662124634, 'rewards/rejected': -3.0686745643615723, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6192686557769775, 'policy_logps/rejected': -437.90087890625, 'policy_logps/chosen': -432.79608154296875, 'referece_logps/rejected': -407.21417236328125, 'referece_logps/chosen': -418.302001953125, 'logits/rejected': -0.09111686050891876, 'logits/chosen': -0.042480044066905975, 'epoch': 0.49}


 16%|█▋        | 443/2685 [2:28:09<11:33:15, 18.55s/it]

 17%|█▋        | 444/2685 [2:28:25<11:02:37, 17.74s/it]

 17%|█▋        | 445/2685 [2:28:44<11:24:01, 18.32s/it]

 17%|█▋        | 446/2685 [2:29:04<11:43:36, 18.86s/it]

 17%|█▋        | 447/2685 [2:29:26<12:09:09, 19.55s/it]

 17%|█▋        | 448/2685 [2:29:44<11:51:54, 19.09s/it]

 17%|█▋        | 449/2685 [2:29:59<11:09:08, 17.96s/it]

 17%|█▋        | 450/2685 [2:30:21<11:59:46, 19.32s/it]

 17%|█▋        | 451/2685 [2:30:42<12:14:26, 19.73s/it]

 17%|█▋        | 452/2685 [2:31:00<11:56:09, 19.24s/it]

 17%|█▋        | 453/2685 [2:31:20<11:59:57, 19.35s/it]

 17%|█▋        | 454/2685 [2:31:43<12:40:44, 20.46s/it]
{'loss': 0.3576, 'learning_rate': 1.9004447538281734e-06, 'rewards/chosen': -1.5038037300109863, 'rewards/rejected': -2.630812644958496, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1270089149475098, 'policy_logps/rejected': -375.0862731933594, 'policy_logps/chosen': -306.7586975097656, 'referece_logps/rejected': -348.77813720703125, 'referece_logps/chosen': -291.720703125, 'logits/rejected': -0.11579160392284393, 'logits/chosen': -0.14740285277366638, 'epoch': 0.51}

 17%|█▋        | 455/2685 [2:32:01<12:20:14, 19.92s/it]


 17%|█▋        | 457/2685 [2:32:41<12:12:10, 19.72s/it]
{'loss': 0.3743, 'learning_rate': 1.898864550982364e-06, 'rewards/chosen': -0.6627882122993469, 'rewards/rejected': -2.144866466522217, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4820783138275146, 'policy_logps/rejected': -384.23895263671875, 'policy_logps/chosen': -334.9183044433594, 'referece_logps/rejected': -362.7903137207031, 'referece_logps/chosen': -328.2904357910156, 'logits/rejected': 0.3858424425125122, 'logits/chosen': 0.3942760229110718, 'epoch': 0.51}


 17%|█▋        | 459/2685 [2:33:21<12:22:32, 20.01s/it]

 17%|█▋        | 460/2685 [2:33:40<12:10:11, 19.69s/it]

 17%|█▋        | 461/2685 [2:33:59<12:10:46, 19.71s/it]

 17%|█▋        | 462/2685 [2:34:16<11:33:50, 18.73s/it]

 17%|█▋        | 463/2685 [2:34:37<12:02:07, 19.50s/it]

 17%|█▋        | 464/2685 [2:34:58<12:14:07, 19.83s/it]

 17%|█▋        | 465/2685 [2:35:19<12:33:25, 20.36s/it]

 17%|█▋        | 466/2685 [2:35:39<12:29:21, 20.26s/it]

 17%|█▋        | 467/2685 [2:36:00<12:34:46, 20.42s/it]

 17%|█▋        | 468/2685 [2:36:22<12:50:17, 20.85s/it]

 17%|█▋        | 469/2685 [2:36:40<12:21:49, 20.09s/it]

 18%|█▊        | 470/2685 [2:37:02<12:42:25, 20.65s/it]

 18%|█▊        | 471/2685 [2:37:22<12:33:13, 20.41s/it]

 18%|█▊        | 472/2685 [2:37:42<12:25:50, 20.22s/it]

 18%|█▊        | 473/2685 [2:38:03<12:36:38, 20.52s/it]

 18%|█▊        | 474/2685 [2:38:22<12:14:52, 19.94s/it]

 18%|█▊        | 475/2685 [2:38:41<12:09:03, 19.79s/it]

 18%|█▊        | 476/2685 [2:39:01<12:07:47, 19.77s/it]

 18%|█▊        | 477/2685 [2:39:21<12:16:10, 20.00s/it]

 18%|█▊        | 478/2685 [2:39:43<12:27:16, 20.32s/it]

 18%|█▊        | 479/2685 [2:40:02<12:20:43, 20.15s/it]

 18%|█▊        | 480/2685 [2:40:22<12:11:28, 19.90s/it]

 18%|█▊        | 481/2685 [2:40:43<12:25:20, 20.29s/it]

 18%|█▊        | 482/2685 [2:41:03<12:18:26, 20.11s/it]

 18%|█▊        | 483/2685 [2:41:19<11:34:22, 18.92s/it]

 18%|█▊        | 484/2685 [2:41:35<10:59:43, 17.98s/it]

 18%|█▊        | 485/2685 [2:41:54<11:20:41, 18.56s/it]

 18%|█▊        | 486/2685 [2:42:10<10:51:09, 17.77s/it]

 18%|█▊        | 487/2685 [2:42:30<11:09:10, 18.27s/it]

 18%|█▊        | 488/2685 [2:42:43<10:15:40, 16.81s/it]
{'loss': 0.3834, 'learning_rate': 1.8818501648171418e-06, 'rewards/chosen': -0.4622095227241516, 'rewards/rejected': -1.6083312034606934, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1461217403411865, 'policy_logps/rejected': -393.1820373535156, 'policy_logps/chosen': -342.12261962890625, 'referece_logps/rejected': -377.0987548828125, 'referece_logps/chosen': -337.5005187988281, 'logits/rejected': -1.2633503675460815, 'logits/chosen': -1.3134591579437256, 'epoch': 0.55}


 18%|█▊        | 490/2685 [2:43:23<11:14:23, 18.43s/it]

 18%|█▊        | 491/2685 [2:43:42<11:23:02, 18.68s/it]
{'loss': 0.4016, 'learning_rate': 1.880137763156124e-06, 'rewards/chosen': -0.7043513655662537, 'rewards/rejected': -1.8086962699890137, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1043449640274048, 'policy_logps/rejected': -361.45159912109375, 'policy_logps/chosen': -206.89317321777344, 'referece_logps/rejected': -343.3646240234375, 'referece_logps/chosen': -199.84963989257812, 'logits/rejected': -0.8910059928894043, 'logits/chosen': -0.8323670625686646, 'epoch': 0.55}


 18%|█▊        | 493/2685 [2:44:20<11:32:22, 18.95s/it]

 18%|█▊        | 494/2685 [2:44:42<12:03:27, 19.81s/it]

 18%|█▊        | 495/2685 [2:44:58<11:20:21, 18.64s/it]

 18%|█▊        | 496/2685 [2:45:18<11:31:44, 18.96s/it]

 19%|█▊        | 497/2685 [2:45:38<11:40:48, 19.22s/it]

 19%|█▊        | 498/2685 [2:45:54<11:11:21, 18.42s/it]

 19%|█▊        | 499/2685 [2:46:12<11:08:09, 18.34s/it]

 19%|█▊        | 500/2685 [2:46:29<10:48:18, 17.80s/it]
 19%|█▊        | 500/2685 [2:46:29<10:48:18, 17.80s/it]/mnt/petrelfs/songmingyang/anaconda3/envs/vcd_origin/lib/python3.9/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
 19%|█▊        | 501/2685 [2:47:05<14:11:13, 23.39s/it]

 19%|█▊        | 502/2685 [2:47:24<13:19:08, 21.96s/it]

 19%|█▊        | 503/2685 [2:47:45<13:09:46, 21.72s/it]
{'loss': 0.3943, 'learning_rate': 1.8731730880937868e-06, 'rewards/chosen': -1.0660057067871094, 'rewards/rejected': -2.250988006591797, 'rewards/accuracies': 0.375, 'rewards/margins': 1.184982419013977, 'policy_logps/rejected': -303.4791564941406, 'policy_logps/chosen': -285.89471435546875, 'referece_logps/rejected': -280.9692687988281, 'referece_logps/chosen': -275.23468017578125, 'logits/rejected': -0.7727845311164856, 'logits/chosen': -0.7186155915260315, 'epoch': 0.56}


 19%|█▉        | 505/2685 [2:48:27<12:59:44, 21.46s/it]

 19%|█▉        | 506/2685 [2:48:48<12:48:03, 21.15s/it]

 19%|█▉        | 507/2685 [2:49:07<12:32:29, 20.73s/it]

 19%|█▉        | 508/2685 [2:49:28<12:35:58, 20.84s/it]

 19%|█▉        | 509/2685 [2:49:48<12:22:51, 20.48s/it]

 19%|█▉        | 510/2685 [2:50:10<12:35:16, 20.84s/it]
{'loss': 0.3371, 'learning_rate': 1.8690257510677628e-06, 'rewards/chosen': -2.0470292568206787, 'rewards/rejected': -4.555296421051025, 'rewards/accuracies': 0.875, 'rewards/margins': 2.508267402648926, 'policy_logps/rejected': -502.78619384765625, 'policy_logps/chosen': -482.2279357910156, 'referece_logps/rejected': -457.23321533203125, 'referece_logps/chosen': -461.75762939453125, 'logits/rejected': -0.5348126888275146, 'logits/chosen': -0.5001718401908875, 'epoch': 0.57}


 19%|█▉        | 512/2685 [2:50:48<11:57:17, 19.81s/it]
[2024-03-29 18:23:05,464] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▉        | 513/2685 [2:51:06<11:39:19, 19.32s/it]

 19%|█▉        | 514/2685 [2:51:28<12:02:58, 19.98s/it]

 19%|█▉        | 515/2685 [2:51:47<11:53:31, 19.73s/it]

 19%|█▉        | 516/2685 [2:52:05<11:32:51, 19.17s/it]

 19%|█▉        | 517/2685 [2:52:26<11:59:00, 19.90s/it]

 19%|█▉        | 518/2685 [2:52:42<11:16:17, 18.73s/it]

 19%|█▉        | 519/2685 [2:53:01<11:13:52, 18.67s/it]

 19%|█▉        | 520/2685 [2:53:17<10:41:24, 17.78s/it]

 19%|█▉        | 521/2685 [2:53:28<9:37:54, 16.02s/it]

 19%|█▉        | 522/2685 [2:53:44<9:37:13, 16.01s/it]

 19%|█▉        | 523/2685 [2:54:03<9:59:07, 16.63s/it]

 20%|█▉        | 524/2685 [2:54:24<10:53:57, 18.16s/it]

 20%|█▉        | 525/2685 [2:54:44<11:13:59, 18.72s/it]

 20%|█▉        | 526/2685 [2:55:04<11:24:37, 19.03s/it]

 20%|█▉        | 527/2685 [2:55:25<11:42:37, 19.54s/it]
{'loss': 0.4252, 'learning_rate': 1.8586962083185965e-06, 'rewards/chosen': -1.562595009803772, 'rewards/rejected': -3.6055281162261963, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0429329872131348, 'policy_logps/rejected': -331.5093688964844, 'policy_logps/chosen': -359.520263671875, 'referece_logps/rejected': -295.4540710449219, 'referece_logps/chosen': -343.8942565917969, 'logits/rejected': -0.10244150459766388, 'logits/chosen': -0.1751301884651184, 'epoch': 0.59}


 20%|█▉        | 529/2685 [2:56:11<12:44:28, 21.28s/it]

 20%|█▉        | 530/2685 [2:56:29<12:13:26, 20.42s/it]

 20%|█▉        | 531/2685 [2:56:49<12:09:03, 20.31s/it]
{'loss': 0.337, 'learning_rate': 1.8562130717655878e-06, 'rewards/chosen': -0.554493248462677, 'rewards/rejected': -2.882939577102661, 'rewards/accuracies': 0.875, 'rewards/margins': 2.328446865081787, 'policy_logps/rejected': -371.1780700683594, 'policy_logps/chosen': -325.5754089355469, 'referece_logps/rejected': -342.34869384765625, 'referece_logps/chosen': -320.0304870605469, 'logits/rejected': -0.7302894592285156, 'logits/chosen': -0.6110612750053406, 'epoch': 0.59}


 20%|█▉        | 533/2685 [2:57:25<11:31:06, 19.27s/it]

 20%|█▉        | 534/2685 [2:57:44<11:31:23, 19.29s/it]

 20%|█▉        | 535/2685 [2:58:02<11:15:05, 18.84s/it]

 20%|█▉        | 536/2685 [2:58:23<11:38:50, 19.51s/it]
[2024-03-29 18:30:40,641] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 537/2685 [2:58:44<11:55:06, 19.98s/it]
[2024-03-29 18:31:01,698] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 538/2685 [2:59:04<11:52:04, 19.90s/it]

 20%|██        | 539/2685 [2:59:24<11:53:40, 19.95s/it]
[2024-03-29 18:31:41,500] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 540/2685 [2:59:43<11:41:05, 19.61s/it]

 20%|██        | 541/2685 [3:00:04<12:00:59, 20.18s/it]

 20%|██        | 542/2685 [3:00:25<12:08:20, 20.39s/it]

 20%|██        | 543/2685 [3:00:45<12:03:43, 20.27s/it]

 20%|██        | 544/2685 [3:01:02<11:26:39, 19.24s/it]

 20%|██        | 545/2685 [3:01:19<11:03:42, 18.61s/it]

 20%|██        | 546/2685 [3:01:35<10:36:51, 17.86s/it]

 20%|██        | 547/2685 [3:01:57<11:21:32, 19.13s/it]

 20%|██        | 548/2685 [3:02:17<11:27:20, 19.30s/it]
{'loss': 0.4363, 'learning_rate': 1.8454379967176446e-06, 'rewards/chosen': -1.5947821140289307, 'rewards/rejected': -3.1001851558685303, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5054024457931519, 'policy_logps/rejected': -424.9432678222656, 'policy_logps/chosen': -391.32415771484375, 'referece_logps/rejected': -393.9414367675781, 'referece_logps/chosen': -375.3763122558594, 'logits/rejected': 0.3434447944164276, 'logits/chosen': 0.2782430350780487, 'epoch': 0.61}

 20%|██        | 549/2685 [3:02:38<11:39:39, 19.65s/it]

 20%|██        | 550/2685 [3:02:56<11:22:58, 19.19s/it]


 21%|██        | 552/2685 [3:03:26<10:06:19, 17.06s/it]

 21%|██        | 553/2685 [3:03:47<10:52:16, 18.36s/it]

 21%|██        | 554/2685 [3:04:09<11:21:54, 19.20s/it]

 21%|██        | 555/2685 [3:04:29<11:38:00, 19.66s/it]

 21%|██        | 556/2685 [3:04:47<11:10:44, 18.90s/it]

 21%|██        | 557/2685 [3:05:05<11:02:15, 18.67s/it]

 21%|██        | 558/2685 [3:05:24<11:11:29, 18.94s/it]
{'loss': 0.4111, 'learning_rate': 1.8389333019214525e-06, 'rewards/chosen': -1.0649020671844482, 'rewards/rejected': -2.482182502746582, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4172804355621338, 'policy_logps/rejected': -358.08123779296875, 'policy_logps/chosen': -382.9962463378906, 'referece_logps/rejected': -333.2593688964844, 'referece_logps/chosen': -372.34722900390625, 'logits/rejected': 0.1550607830286026, 'logits/chosen': 0.16611027717590332, 'epoch': 0.62}

 21%|██        | 559/2685 [3:05:44<11:20:49, 19.21s/it]


 21%|██        | 561/2685 [3:06:22<11:16:54, 19.12s/it]
{'loss': 0.2918, 'learning_rate': 1.8369580391072431e-06, 'rewards/chosen': -0.33449724316596985, 'rewards/rejected': -1.0892606973648071, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7547634840011597, 'policy_logps/rejected': -248.7094268798828, 'policy_logps/chosen': -197.16915893554688, 'referece_logps/rejected': -237.8168182373047, 'referece_logps/chosen': -193.82418823242188, 'logits/rejected': -0.5408132672309875, 'logits/chosen': -0.5585216283798218, 'epoch': 0.63}
[2024-03-29 18:39:03,599] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 21%|██        | 563/2685 [3:07:05<11:49:48, 20.07s/it]

 21%|██        | 564/2685 [3:07:25<11:47:44, 20.02s/it]

 21%|██        | 565/2685 [3:07:46<11:53:33, 20.20s/it]

 21%|██        | 566/2685 [3:08:03<11:23:02, 19.34s/it]
{'loss': 0.4059, 'learning_rate': 1.8336415831250988e-06, 'rewards/chosen': -0.6605216860771179, 'rewards/rejected': -3.1788086891174316, 'rewards/accuracies': 1.0, 'rewards/margins': 2.518287420272827, 'policy_logps/rejected': -396.8648681640625, 'policy_logps/chosen': -361.44384765625, 'referece_logps/rejected': -365.0767517089844, 'referece_logps/chosen': -354.8386535644531, 'logits/rejected': -0.26846078038215637, 'logits/chosen': -0.3099450469017029, 'epoch': 0.63}

 21%|██        | 567/2685 [3:08:22<11:17:57, 19.21s/it]


 21%|██        | 569/2685 [3:08:57<10:42:05, 18.21s/it]

 21%|██        | 570/2685 [3:09:17<10:59:43, 18.72s/it]

 21%|██▏       | 571/2685 [3:09:39<11:35:18, 19.73s/it]
{'loss': 0.4065, 'learning_rate': 1.8302947927123763e-06, 'rewards/chosen': -1.3879345655441284, 'rewards/rejected': -3.2577483654022217, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8698136806488037, 'policy_logps/rejected': -386.79058837890625, 'policy_logps/chosen': -296.3331298828125, 'referece_logps/rejected': -354.21307373046875, 'referece_logps/chosen': -282.45379638671875, 'logits/rejected': -0.5078392028808594, 'logits/chosen': -0.5074746012687683, 'epoch': 0.64}

 21%|██▏       | 572/2685 [3:10:00<11:47:01, 20.08s/it]


 21%|██▏       | 574/2685 [3:10:39<11:33:47, 19.72s/it]

 21%|██▏       | 575/2685 [3:10:59<11:33:40, 19.73s/it]
{'loss': 0.4454, 'learning_rate': 1.8275956013930672e-06, 'rewards/chosen': -0.7985885739326477, 'rewards/rejected': -2.5016934871673584, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7031049728393555, 'policy_logps/rejected': -464.7673645019531, 'policy_logps/chosen': -550.1377563476562, 'referece_logps/rejected': -439.75042724609375, 'referece_logps/chosen': -542.15185546875, 'logits/rejected': -0.1825985163450241, 'logits/chosen': -0.14754043519496918, 'epoch': 0.64}


 21%|██▏       | 577/2685 [3:11:35<10:54:25, 18.63s/it]

 22%|██▏       | 578/2685 [3:11:54<10:58:51, 18.76s/it]

 22%|██▏       | 579/2685 [3:12:13<11:08:21, 19.04s/it]

 22%|██▏       | 580/2685 [3:12:36<11:41:35, 20.00s/it]
[2024-03-29 18:44:53,132] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3222, 'learning_rate': 1.8241945166362097e-06, 'rewards/chosen': -0.43120133876800537, 'rewards/rejected': -2.0115585327148438, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5803570747375488, 'policy_logps/rejected': -482.48052978515625, 'policy_logps/chosen': -473.0861511230469, 'referece_logps/rejected': -462.364990234375, 'referece_logps/chosen': -468.7741394042969, 'logits/rejected': 1.235815405845642, 'logits/chosen': 1.213472604751587, 'epoch': 0.65}
[2024-03-29 18:45:13,948] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 22%|██▏       | 581/2685 [3:12:57<11:49:52, 20.24s/it]


 22%|██▏       | 583/2685 [3:13:33<11:12:02, 19.18s/it]

 22%|██▏       | 584/2685 [3:13:53<11:19:58, 19.42s/it]

 22%|██▏       | 585/2685 [3:14:13<11:23:27, 19.53s/it]

 22%|██▏       | 586/2685 [3:14:33<11:26:21, 19.62s/it]

 22%|██▏       | 587/2685 [3:14:53<11:32:10, 19.80s/it]
{'loss': 0.3622, 'learning_rate': 1.8193826415772414e-06, 'rewards/chosen': -0.5691210031509399, 'rewards/rejected': -2.5737905502319336, 'rewards/accuracies': 0.875, 'rewards/margins': 2.004669427871704, 'policy_logps/rejected': -399.5381774902344, 'policy_logps/chosen': -455.01409912109375, 'referece_logps/rejected': -373.80029296875, 'referece_logps/chosen': -449.3228759765625, 'logits/rejected': -0.14296534657478333, 'logits/chosen': -0.14837193489074707, 'epoch': 0.66}

 22%|██▏       | 588/2685 [3:15:15<11:51:32, 20.36s/it]

 22%|██▏       | 589/2685 [3:15:33<11:28:09, 19.70s/it]

 22%|██▏       | 590/2685 [3:15:55<11:50:32, 20.35s/it]

 22%|██▏       | 591/2685 [3:16:14<11:42:45, 20.14s/it]


 22%|██▏       | 593/2685 [3:16:52<11:18:56, 19.47s/it]

 22%|██▏       | 594/2685 [3:17:13<11:44:33, 20.22s/it]

 22%|██▏       | 595/2685 [3:17:34<11:50:45, 20.40s/it]
{'loss': 0.4551, 'learning_rate': 1.813811818817863e-06, 'rewards/chosen': -0.9400933980941772, 'rewards/rejected': -1.8872828483581543, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9471895098686218, 'policy_logps/rejected': -289.9169616699219, 'policy_logps/chosen': -309.5835266113281, 'referece_logps/rejected': -271.04412841796875, 'referece_logps/chosen': -300.1825866699219, 'logits/rejected': -0.5592888593673706, 'logits/chosen': -0.582427978515625, 'epoch': 0.66}

 22%|██▏       | 596/2685 [3:17:51<11:14:41, 19.38s/it]

 22%|██▏       | 597/2685 [3:18:11<11:16:17, 19.43s/it]


 22%|██▏       | 599/2685 [3:18:52<11:37:48, 20.07s/it]
{'loss': 0.4088, 'learning_rate': 1.8109979465095012e-06, 'rewards/chosen': -0.2885648012161255, 'rewards/rejected': -2.2379372119903564, 'rewards/accuracies': 1.0, 'rewards/margins': 1.949372410774231, 'policy_logps/rejected': -311.2758483886719, 'policy_logps/chosen': -265.1915283203125, 'referece_logps/rejected': -288.8964538574219, 'referece_logps/chosen': -262.3058776855469, 'logits/rejected': 0.21314573287963867, 'logits/chosen': 0.17091701924800873, 'epoch': 0.67}

 22%|██▏       | 600/2685 [3:19:07<10:46:44, 18.61s/it]


 22%|██▏       | 602/2685 [3:19:46<11:02:12, 19.07s/it]

 22%|██▏       | 603/2685 [3:20:06<11:05:57, 19.19s/it]

 22%|██▏       | 604/2685 [3:20:26<11:14:28, 19.45s/it]

 23%|██▎       | 605/2685 [3:20:46<11:26:42, 19.81s/it]
{'loss': 0.3602, 'learning_rate': 1.8067417460341848e-06, 'rewards/chosen': -0.10195256024599075, 'rewards/rejected': -2.387686014175415, 'rewards/accuracies': 1.0, 'rewards/margins': 2.285733461380005, 'policy_logps/rejected': -355.7807922363281, 'policy_logps/chosen': -324.1644287109375, 'referece_logps/rejected': -331.9039306640625, 'referece_logps/chosen': -323.1449279785156, 'logits/rejected': 0.3681895434856415, 'logits/chosen': 0.3683713376522064, 'epoch': 0.68}

 23%|██▎       | 606/2685 [3:21:06<11:20:38, 19.64s/it]

 23%|██▎       | 607/2685 [3:21:27<11:39:55, 20.21s/it]

 23%|██▎       | 608/2685 [3:21:47<11:34:26, 20.06s/it]

 23%|██▎       | 609/2685 [3:22:07<11:35:38, 20.11s/it]


 23%|██▎       | 611/2685 [3:22:50<11:54:46, 20.68s/it]
{'loss': 0.3119, 'learning_rate': 1.802443273546722e-06, 'rewards/chosen': -0.17985722422599792, 'rewards/rejected': -1.9744685888290405, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7946115732192993, 'policy_logps/rejected': -326.8823547363281, 'policy_logps/chosen': -264.1459655761719, 'referece_logps/rejected': -307.1376647949219, 'referece_logps/chosen': -262.347412109375, 'logits/rejected': -0.06361892819404602, 'logits/chosen': -0.10279142111539841, 'epoch': 0.68}


 23%|██▎       | 613/2685 [3:23:29<11:37:01, 20.18s/it]
{'loss': 0.3497, 'learning_rate': 1.8010010944693845e-06, 'rewards/chosen': -1.091493844985962, 'rewards/rejected': -3.1324734687805176, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0409798622131348, 'policy_logps/rejected': -390.736083984375, 'policy_logps/chosen': -420.9880676269531, 'referece_logps/rejected': -359.41131591796875, 'referece_logps/chosen': -410.0731201171875, 'logits/rejected': 0.5617313981056213, 'logits/chosen': 0.5516577959060669, 'epoch': 0.68}


 23%|██▎       | 615/2685 [3:24:06<11:00:51, 19.16s/it]

 23%|██▎       | 616/2685 [3:24:28<11:29:47, 20.00s/it]

 23%|██▎       | 617/2685 [3:24:49<11:32:44, 20.10s/it]

 23%|██▎       | 618/2685 [3:25:08<11:30:44, 20.05s/it]

 23%|██▎       | 619/2685 [3:25:28<11:27:35, 19.97s/it]

 23%|██▎       | 620/2685 [3:25:46<11:05:40, 19.34s/it]
{'loss': 0.3933, 'learning_rate': 1.7959167980932905e-06, 'rewards/chosen': -0.5768497586250305, 'rewards/rejected': -2.4435133934020996, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8666635751724243, 'policy_logps/rejected': -331.8059997558594, 'policy_logps/chosen': -274.1889953613281, 'referece_logps/rejected': -307.3708801269531, 'referece_logps/chosen': -268.42047119140625, 'logits/rejected': -0.3157500922679901, 'logits/chosen': -0.23280003666877747, 'epoch': 0.69}

 23%|██▎       | 621/2685 [3:26:06<11:10:11, 19.48s/it]


 23%|██▎       | 623/2685 [3:26:46<11:21:12, 19.82s/it]
{'loss': 0.3813, 'learning_rate': 1.7937204156716231e-06, 'rewards/chosen': -0.5556930303573608, 'rewards/rejected': -2.908263683319092, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3525707721710205, 'policy_logps/rejected': -294.9960021972656, 'policy_logps/chosen': -268.72589111328125, 'referece_logps/rejected': -265.913330078125, 'referece_logps/chosen': -263.1689758300781, 'logits/rejected': 0.09292377531528473, 'logits/chosen': 0.16650733351707458, 'epoch': 0.7}


 23%|██▎       | 625/2685 [3:27:23<10:50:08, 18.94s/it]

 23%|██▎       | 626/2685 [3:27:45<11:18:37, 19.78s/it]

 23%|██▎       | 627/2685 [3:28:02<10:56:17, 19.13s/it]
{'loss': 0.4023, 'learning_rate': 1.7907757369376984e-06, 'rewards/chosen': -1.6893880367279053, 'rewards/rejected': -2.4999303817749023, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8105421662330627, 'policy_logps/rejected': -354.38824462890625, 'policy_logps/chosen': -370.74456787109375, 'referece_logps/rejected': -329.3889465332031, 'referece_logps/chosen': -353.8506774902344, 'logits/rejected': -0.5774860382080078, 'logits/chosen': -0.6457565426826477, 'epoch': 0.7}

 23%|██▎       | 628/2685 [3:28:22<11:00:41, 19.27s/it]

 23%|██▎       | 629/2685 [3:28:43<11:24:20, 19.97s/it]


 24%|██▎       | 631/2685 [3:29:24<11:32:24, 20.23s/it]
{'loss': 0.3508, 'learning_rate': 1.7878126424177157e-06, 'rewards/chosen': -1.3347783088684082, 'rewards/rejected': -3.1762146949768066, 'rewards/accuracies': 0.75, 'rewards/margins': 1.841436505317688, 'policy_logps/rejected': -405.3207092285156, 'policy_logps/chosen': -301.5723876953125, 'referece_logps/rejected': -373.5585632324219, 'referece_logps/chosen': -288.224609375, 'logits/rejected': -0.2945064902305603, 'logits/chosen': -0.47488197684288025, 'epoch': 0.71}

 24%|██▎       | 632/2685 [3:29:44<11:23:51, 19.99s/it]

 24%|██▎       | 633/2685 [3:30:04<11:26:30, 20.07s/it]


 24%|██▎       | 635/2685 [3:30:43<11:17:28, 19.83s/it]

 24%|██▎       | 636/2685 [3:31:04<11:31:05, 20.24s/it]
{'loss': 0.3451, 'learning_rate': 1.7840829822345558e-06, 'rewards/chosen': -1.2156157493591309, 'rewards/rejected': -3.251659631729126, 'rewards/accuracies': 0.875, 'rewards/margins': 2.036043882369995, 'policy_logps/rejected': -478.19158935546875, 'policy_logps/chosen': -462.79583740234375, 'referece_logps/rejected': -445.6750183105469, 'referece_logps/chosen': -450.6396484375, 'logits/rejected': 0.02559680864214897, 'logits/chosen': 0.06713628023862839, 'epoch': 0.71}


 24%|██▍       | 638/2685 [3:31:40<10:54:18, 19.18s/it]
{'loss': 0.3331, 'learning_rate': 1.7825831218185472e-06, 'rewards/chosen': -0.4967975318431854, 'rewards/rejected': -2.108459711074829, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6116623878479004, 'policy_logps/rejected': -304.28533935546875, 'policy_logps/chosen': -271.01470947265625, 'referece_logps/rejected': -283.2007141113281, 'referece_logps/chosen': -266.0467529296875, 'logits/rejected': 0.13788288831710815, 'logits/chosen': 0.17855091392993927, 'epoch': 0.71}

 24%|██▍       | 639/2685 [3:32:02<11:20:31, 19.96s/it]

 24%|██▍       | 640/2685 [3:32:22<11:13:57, 19.77s/it]


 24%|██▍       | 642/2685 [3:32:59<10:46:10, 18.98s/it]

 24%|██▍       | 643/2685 [3:33:21<11:21:54, 20.04s/it]
{'loss': 0.323, 'learning_rate': 1.7788135563290974e-06, 'rewards/chosen': -0.2294626384973526, 'rewards/rejected': -2.5024235248565674, 'rewards/accuracies': 1.0, 'rewards/margins': 2.272960901260376, 'policy_logps/rejected': -471.9541320800781, 'policy_logps/chosen': -343.7626647949219, 'referece_logps/rejected': -446.92987060546875, 'referece_logps/chosen': -341.468017578125, 'logits/rejected': 0.048551224172115326, 'logits/chosen': -0.010680850595235825, 'epoch': 0.72}

 24%|██▍       | 644/2685 [3:33:38<10:46:03, 18.99s/it]

 24%|██▍       | 645/2685 [3:33:56<10:41:32, 18.87s/it]

 24%|██▍       | 646/2685 [3:34:16<10:48:19, 19.08s/it]

 24%|██▍       | 647/2685 [3:34:36<10:53:34, 19.24s/it]


 24%|██▍       | 649/2685 [3:35:13<10:47:56, 19.09s/it]

 24%|██▍       | 650/2685 [3:35:33<10:53:06, 19.26s/it]
{'loss': 0.3673, 'learning_rate': 1.773488585447203e-06, 'rewards/chosen': -1.4615293741226196, 'rewards/rejected': -3.129840850830078, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6683112382888794, 'policy_logps/rejected': -242.36248779296875, 'policy_logps/chosen': -251.11021423339844, 'referece_logps/rejected': -211.06410217285156, 'referece_logps/chosen': -236.4949188232422, 'logits/rejected': -0.8384791016578674, 'logits/chosen': -0.7391244173049927, 'epoch': 0.73}

 24%|██▍       | 651/2685 [3:35:56<11:28:48, 20.32s/it]

 24%|██▍       | 652/2685 [3:36:14<11:09:48, 19.77s/it]

 24%|██▍       | 653/2685 [3:36:36<11:27:00, 20.29s/it]

 24%|██▍       | 654/2685 [3:36:59<11:53:00, 21.06s/it]


 24%|██▍       | 656/2685 [3:37:35<10:59:05, 19.49s/it]

 24%|██▍       | 657/2685 [3:37:55<11:01:30, 19.57s/it]

 25%|██▍       | 658/2685 [3:38:11<10:23:18, 18.45s/it]
{'loss': 0.3645, 'learning_rate': 1.7673353775402665e-06, 'rewards/chosen': -0.4248112738132477, 'rewards/rejected': -2.735618829727173, 'rewards/accuracies': 0.875, 'rewards/margins': 2.310807704925537, 'policy_logps/rejected': -326.2264099121094, 'policy_logps/chosen': -260.0758056640625, 'referece_logps/rejected': -298.8702087402344, 'referece_logps/chosen': -255.8276824951172, 'logits/rejected': -0.35009127855300903, 'logits/chosen': -0.21085165441036224, 'epoch': 0.74}

 25%|██▍       | 659/2685 [3:38:30<10:33:09, 18.75s/it]

 25%|██▍       | 660/2685 [3:38:50<10:46:26, 19.15s/it]


 25%|██▍       | 662/2685 [3:39:24<9:52:49, 17.58s/it]

 25%|██▍       | 663/2685 [3:39:44<10:20:07, 18.40s/it]

 25%|██▍       | 664/2685 [3:40:05<10:49:46, 19.29s/it]

 25%|██▍       | 665/2685 [3:40:25<10:54:09, 19.43s/it]
{'loss': 0.346, 'learning_rate': 1.7618926655951478e-06, 'rewards/chosen': -1.3348462581634521, 'rewards/rejected': -3.234113931655884, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8992674350738525, 'policy_logps/rejected': -365.92718505859375, 'policy_logps/chosen': -364.90771484375, 'referece_logps/rejected': -333.5860595703125, 'referece_logps/chosen': -351.5591735839844, 'logits/rejected': 0.011166036128997803, 'logits/chosen': 0.06293381750583649, 'epoch': 0.74}


 25%|██▍       | 667/2685 [3:41:03<10:52:57, 19.41s/it]

 25%|██▍       | 668/2685 [3:41:18<10:02:34, 17.92s/it]

 25%|██▍       | 669/2685 [3:41:38<10:22:06, 18.52s/it]

 25%|██▍       | 670/2685 [3:41:51<9:32:38, 17.05s/it]

 25%|██▍       | 671/2685 [3:42:07<9:25:35, 16.85s/it]

 25%|██▌       | 672/2685 [3:42:27<9:54:21, 17.72s/it]

 25%|██▌       | 673/2685 [3:42:48<10:23:22, 18.59s/it]
{'loss': 0.3367, 'learning_rate': 1.7556059096387021e-06, 'rewards/chosen': -0.8655716180801392, 'rewards/rejected': -3.2479586601257324, 'rewards/accuracies': 1.0, 'rewards/margins': 2.382387161254883, 'policy_logps/rejected': -501.2595520019531, 'policy_logps/chosen': -414.2440185546875, 'referece_logps/rejected': -468.7799987792969, 'referece_logps/chosen': -405.5882873535156, 'logits/rejected': -0.4739615023136139, 'logits/chosen': -0.41963985562324524, 'epoch': 0.75}

 25%|██▌       | 674/2685 [3:43:06<10:20:38, 18.52s/it]


 25%|██▌       | 676/2685 [3:43:44<10:26:08, 18.70s/it]
{'loss': 0.3776, 'learning_rate': 1.7532301979560634e-06, 'rewards/chosen': -0.8026561737060547, 'rewards/rejected': -2.2329201698303223, 'rewards/accuracies': 0.625, 'rewards/margins': 1.430263876914978, 'policy_logps/rejected': -307.41375732421875, 'policy_logps/chosen': -324.7516784667969, 'referece_logps/rejected': -285.0845642089844, 'referece_logps/chosen': -316.72509765625, 'logits/rejected': -0.6806551218032837, 'logits/chosen': -0.7041147947311401, 'epoch': 0.76}

 25%|██▌       | 677/2685 [3:44:01<10:12:20, 18.30s/it]


 25%|██▌       | 679/2685 [3:44:42<10:52:03, 19.50s/it]
{'loss': 0.3187, 'learning_rate': 1.750844619218537e-06, 'rewards/chosen': -0.8949812650680542, 'rewards/rejected': -2.1718130111694336, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2768317461013794, 'policy_logps/rejected': -305.4917297363281, 'policy_logps/chosen': -225.19259643554688, 'referece_logps/rejected': -283.77362060546875, 'referece_logps/chosen': -216.2427978515625, 'logits/rejected': -1.0106157064437866, 'logits/chosen': -1.0481213331222534, 'epoch': 0.76}

 25%|██▌       | 680/2685 [3:45:05<11:23:39, 20.46s/it]

 25%|██▌       | 681/2685 [3:45:27<11:44:38, 21.10s/it]

 25%|██▌       | 682/2685 [3:45:47<11:31:32, 20.72s/it]

 25%|██▌       | 683/2685 [3:46:09<11:47:01, 21.19s/it]

 25%|██▌       | 684/2685 [3:46:31<11:51:22, 21.33s/it]

 26%|██▌       | 685/2685 [3:46:51<11:35:32, 20.87s/it]


 26%|██▌       | 687/2685 [3:47:26<10:36:06, 19.10s/it]

 26%|██▌       | 688/2685 [3:47:48<11:08:31, 20.09s/it]
{'loss': 0.3182, 'learning_rate': 1.7436289938230093e-06, 'rewards/chosen': -1.185689926147461, 'rewards/rejected': -3.2052719593048096, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0195820331573486, 'policy_logps/rejected': -363.8834533691406, 'policy_logps/chosen': -357.6326904296875, 'referece_logps/rejected': -331.8306884765625, 'referece_logps/chosen': -345.7758483886719, 'logits/rejected': -0.5044869184494019, 'logits/chosen': -0.42204058170318604, 'epoch': 0.77}


 26%|██▌       | 690/2685 [3:48:30<11:18:18, 20.40s/it]
{'loss': 0.335, 'learning_rate': 1.7420135854509108e-06, 'rewards/chosen': -1.4020452499389648, 'rewards/rejected': -3.3794078826904297, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9773626327514648, 'policy_logps/rejected': -478.09527587890625, 'policy_logps/chosen': -444.4424743652344, 'referece_logps/rejected': -444.3011474609375, 'referece_logps/chosen': -430.4219970703125, 'logits/rejected': 0.16674959659576416, 'logits/chosen': 0.1087530106306076, 'epoch': 0.77}

 26%|██▌       | 691/2685 [3:48:50<11:11:11, 20.20s/it]

 26%|██▌       | 692/2685 [3:49:11<11:15:37, 20.34s/it]

 26%|██▌       | 693/2685 [3:49:30<11:03:54, 20.00s/it]

 26%|██▌       | 694/2685 [3:49:47<10:32:36, 19.06s/it]


 26%|██▌       | 696/2685 [3:50:26<10:50:57, 19.64s/it]

 26%|██▌       | 697/2685 [3:50:46<10:52:57, 19.71s/it]
{'loss': 0.3542, 'learning_rate': 1.7363256976511972e-06, 'rewards/chosen': -2.2485861778259277, 'rewards/rejected': -3.3035194873809814, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0549330711364746, 'policy_logps/rejected': -334.70611572265625, 'policy_logps/chosen': -363.8191223144531, 'referece_logps/rejected': -301.67095947265625, 'referece_logps/chosen': -341.333251953125, 'logits/rejected': -0.1367465853691101, 'logits/chosen': -0.05817180871963501, 'epoch': 0.78}

 26%|██▌       | 698/2685 [3:51:09<11:24:27, 20.67s/it]

 26%|██▌       | 699/2685 [3:51:27<10:56:38, 19.84s/it]


 26%|██▌       | 701/2685 [3:52:07<10:53:46, 19.77s/it]
{'loss': 0.4311, 'learning_rate': 1.733051871829826e-06, 'rewards/chosen': -0.885044276714325, 'rewards/rejected': -2.3334810733795166, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4484368562698364, 'policy_logps/rejected': -301.39892578125, 'policy_logps/chosen': -244.02288818359375, 'referece_logps/rejected': -278.06414794921875, 'referece_logps/chosen': -235.1724395751953, 'logits/rejected': -0.3696286678314209, 'logits/chosen': -0.29446423053741455, 'epoch': 0.78}

 26%|██▌       | 702/2685 [3:52:26<10:47:03, 19.58s/it]

 26%|██▌       | 703/2685 [3:52:45<10:45:29, 19.54s/it]

 26%|██▌       | 704/2685 [3:53:06<10:53:03, 19.78s/it]

 26%|██▋       | 705/2685 [3:53:23<10:30:13, 19.10s/it]

 26%|██▋       | 706/2685 [3:53:44<10:43:48, 19.52s/it]


 26%|██▋       | 708/2685 [3:54:21<10:38:05, 19.37s/it]

 26%|██▋       | 709/2685 [3:54:43<11:05:06, 20.20s/it]
{'loss': 0.3581, 'learning_rate': 1.7264530823322247e-06, 'rewards/chosen': -0.700154185295105, 'rewards/rejected': -1.9889315366744995, 'rewards/accuracies': 0.875, 'rewards/margins': 1.288777232170105, 'policy_logps/rejected': -362.8473205566406, 'policy_logps/chosen': -315.16766357421875, 'referece_logps/rejected': -342.9579772949219, 'referece_logps/chosen': -308.1661071777344, 'logits/rejected': 0.24940146505832672, 'logits/chosen': 0.11235131323337555, 'epoch': 0.79}


 26%|██▋       | 711/2685 [3:55:24<11:15:24, 20.53s/it]
{'loss': 0.3336, 'learning_rate': 1.7247927872291198e-06, 'rewards/chosen': -1.3677071332931519, 'rewards/rejected': -2.974094867706299, 'rewards/accuracies': 0.75, 'rewards/margins': 1.606387734413147, 'policy_logps/rejected': -350.2087097167969, 'policy_logps/chosen': -333.5761413574219, 'referece_logps/rejected': -320.4677734375, 'referece_logps/chosen': -319.8990783691406, 'logits/rejected': -0.7942615747451782, 'logits/chosen': -0.7836939096450806, 'epoch': 0.79}

 27%|██▋       | 712/2685 [3:55:44<11:03:00, 20.16s/it]

 27%|██▋       | 713/2685 [3:56:06<11:18:22, 20.64s/it]


 27%|██▋       | 715/2685 [3:56:47<11:18:49, 20.68s/it]

 27%|██▋       | 716/2685 [3:57:09<11:33:34, 21.13s/it]
{'loss': 0.3287, 'learning_rate': 1.7206236090706134e-06, 'rewards/chosen': -2.1795530319213867, 'rewards/rejected': -4.8269476890563965, 'rewards/accuracies': 0.875, 'rewards/margins': 2.647394895553589, 'policy_logps/rejected': -436.0618896484375, 'policy_logps/chosen': -333.3257141113281, 'referece_logps/rejected': -387.79241943359375, 'referece_logps/chosen': -311.5301818847656, 'logits/rejected': -0.41593635082244873, 'logits/chosen': -0.4171787202358246, 'epoch': 0.8}


 27%|██▋       | 718/2685 [3:57:49<11:17:57, 20.68s/it]
{'loss': 0.322, 'learning_rate': 1.7189485871338328e-06, 'rewards/chosen': -0.49497348070144653, 'rewards/rejected': -1.7932746410369873, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2983012199401855, 'policy_logps/rejected': -275.21759033203125, 'policy_logps/chosen': -213.78546142578125, 'referece_logps/rejected': -257.28485107421875, 'referece_logps/chosen': -208.8357696533203, 'logits/rejected': -0.19475674629211426, 'logits/chosen': -0.13149389624595642, 'epoch': 0.8}

 27%|██▋       | 719/2685 [3:58:12<11:44:53, 21.51s/it]

 27%|██▋       | 720/2685 [3:58:34<11:40:35, 21.39s/it]

 27%|██▋       | 721/2685 [3:58:54<11:25:54, 20.95s/it]

 27%|██▋       | 722/2685 [3:59:10<10:39:33, 19.55s/it]


 27%|██▋       | 724/2685 [3:59:47<10:18:31, 18.92s/it]
{'loss': 0.3353, 'learning_rate': 1.7138984458313745e-06, 'rewards/chosen': -1.561726450920105, 'rewards/rejected': -2.5759596824645996, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0142333507537842, 'policy_logps/rejected': -468.8463134765625, 'policy_logps/chosen': -383.4800720214844, 'referece_logps/rejected': -443.0867004394531, 'referece_logps/chosen': -367.86279296875, 'logits/rejected': 0.5938704609870911, 'logits/chosen': 0.5523867011070251, 'epoch': 0.81}

 27%|██▋       | 725/2685 [4:00:07<10:26:05, 19.17s/it]

 27%|██▋       | 726/2685 [4:00:29<10:53:08, 20.00s/it]

 27%|██▋       | 727/2685 [4:00:46<10:26:36, 19.20s/it]

 27%|██▋       | 728/2685 [4:01:05<10:29:34, 19.30s/it]


 27%|██▋       | 730/2685 [4:01:41<10:05:24, 18.58s/it]
{'loss': 0.3128, 'learning_rate': 1.7088108973612308e-06, 'rewards/chosen': -1.1497308015823364, 'rewards/rejected': -4.884903907775879, 'rewards/accuracies': 1.0, 'rewards/margins': 3.735172748565674, 'policy_logps/rejected': -383.90631103515625, 'policy_logps/chosen': -296.05712890625, 'referece_logps/rejected': -335.0572509765625, 'referece_logps/chosen': -284.559814453125, 'logits/rejected': -0.7817402482032776, 'logits/chosen': -0.765467643737793, 'epoch': 0.82}

 27%|██▋       | 731/2685 [4:01:58<9:48:32, 18.07s/it]

 27%|██▋       | 732/2685 [4:02:18<10:05:13, 18.59s/it]


 27%|██▋       | 734/2685 [4:03:03<11:08:29, 20.56s/it]
{'loss': 0.3538, 'learning_rate': 1.7053985481853266e-06, 'rewards/chosen': -0.7293089032173157, 'rewards/rejected': -3.1637051105499268, 'rewards/accuracies': 0.875, 'rewards/margins': 2.434396266937256, 'policy_logps/rejected': -381.497314453125, 'policy_logps/chosen': -423.95416259765625, 'referece_logps/rejected': -349.8602600097656, 'referece_logps/chosen': -416.66107177734375, 'logits/rejected': 0.0689251571893692, 'logits/chosen': 0.010401159524917603, 'epoch': 0.82}

 27%|██▋       | 735/2685 [4:03:25<11:18:37, 20.88s/it]

 27%|██▋       | 736/2685 [4:03:46<11:24:52, 21.08s/it]

 27%|██▋       | 737/2685 [4:04:08<11:25:39, 21.12s/it]

 27%|██▋       | 738/2685 [4:04:26<11:01:23, 20.38s/it]

 28%|██▊       | 739/2685 [4:04:46<10:53:31, 20.15s/it]

 28%|██▊       | 740/2685 [4:05:06<10:48:59, 20.02s/it]

 28%|██▊       | 741/2685 [4:05:24<10:34:14, 19.58s/it]


 28%|██▊       | 743/2685 [4:06:03<10:31:26, 19.51s/it]
{'loss': 0.3281, 'learning_rate': 1.6976608211742376e-06, 'rewards/chosen': -0.407941073179245, 'rewards/rejected': -3.8629379272460938, 'rewards/accuracies': 1.0, 'rewards/margins': 3.4549965858459473, 'policy_logps/rejected': -375.2443542480469, 'policy_logps/chosen': -294.9132385253906, 'referece_logps/rejected': -336.614990234375, 'referece_logps/chosen': -290.8338317871094, 'logits/rejected': -0.7005853056907654, 'logits/chosen': -0.6899341344833374, 'epoch': 0.83}

 28%|██▊       | 744/2685 [4:06:24<10:42:46, 19.87s/it]

 28%|██▊       | 745/2685 [4:06:41<10:15:26, 19.03s/it]

 28%|██▊       | 746/2685 [4:06:58<9:54:44, 18.40s/it]

 28%|██▊       | 747/2685 [4:07:17<9:56:38, 18.47s/it]


 28%|██▊       | 749/2685 [4:07:59<10:41:40, 19.89s/it]
{'loss': 0.2925, 'learning_rate': 1.6924565846110931e-06, 'rewards/chosen': -1.1824709177017212, 'rewards/rejected': -3.4205873012542725, 'rewards/accuracies': 1.0, 'rewards/margins': 2.238116502761841, 'policy_logps/rejected': -445.7027282714844, 'policy_logps/chosen': -354.30548095703125, 'referece_logps/rejected': -411.49688720703125, 'referece_logps/chosen': -342.4808349609375, 'logits/rejected': -0.00020867586135864258, 'logits/chosen': -0.0851031243801117, 'epoch': 0.84}

 28%|██▊       | 750/2685 [4:08:19<10:37:17, 19.76s/it]

 28%|██▊       | 751/2685 [4:08:37<10:22:34, 19.31s/it]

 28%|██▊       | 752/2685 [4:08:59<10:45:27, 20.04s/it]

 28%|██▊       | 753/2685 [4:09:20<10:58:28, 20.45s/it]


 28%|██▊       | 755/2685 [4:10:01<10:58:24, 20.47s/it]
{'loss': 0.3296, 'learning_rate': 1.6872160644004257e-06, 'rewards/chosen': -1.2672361135482788, 'rewards/rejected': -3.6235499382019043, 'rewards/accuracies': 0.875, 'rewards/margins': 2.356313705444336, 'policy_logps/rejected': -417.71466064453125, 'policy_logps/chosen': -294.49542236328125, 'referece_logps/rejected': -381.47918701171875, 'referece_logps/chosen': -281.82305908203125, 'logits/rejected': -0.2638404369354248, 'logits/chosen': -0.2063576579093933, 'epoch': 0.84}

 28%|██▊       | 756/2685 [4:10:23<11:10:11, 20.85s/it]


 28%|██▊       | 758/2685 [4:11:08<11:33:03, 21.58s/it]

 28%|██▊       | 759/2685 [4:11:28<11:19:35, 21.17s/it]
{'loss': 0.2967, 'learning_rate': 1.6837023622027386e-06, 'rewards/chosen': -1.0949515104293823, 'rewards/rejected': -3.9847404956817627, 'rewards/accuracies': 1.0, 'rewards/margins': 2.88978910446167, 'policy_logps/rejected': -332.261474609375, 'policy_logps/chosen': -315.0520324707031, 'referece_logps/rejected': -292.4140625, 'referece_logps/chosen': -304.1025390625, 'logits/rejected': -0.3466184139251709, 'logits/chosen': -0.2208094447851181, 'epoch': 0.85}

 28%|██▊       | 760/2685 [4:11:49<11:17:27, 21.12s/it]

 28%|██▊       | 761/2685 [4:12:11<11:31:12, 21.56s/it]

 28%|██▊       | 762/2685 [4:12:29<10:51:13, 20.32s/it]


 28%|██▊       | 764/2685 [4:13:11<11:02:03, 20.68s/it]

 28%|██▊       | 765/2685 [4:13:30<10:50:12, 20.32s/it]

 29%|██▊       | 766/2685 [4:13:50<10:48:31, 20.28s/it]

 29%|██▊       | 767/2685 [4:14:10<10:40:47, 20.05s/it]

 29%|██▊       | 768/2685 [4:14:32<10:56:48, 20.56s/it]

 29%|██▊       | 769/2685 [4:14:53<11:08:00, 20.92s/it]

 29%|██▊       | 770/2685 [4:15:13<10:55:54, 20.55s/it]

 29%|██▊       | 771/2685 [4:15:33<10:52:05, 20.44s/it]

 29%|██▉       | 772/2685 [4:15:51<10:29:46, 19.75s/it]

 29%|██▉       | 773/2685 [4:16:08<9:54:32, 18.66s/it]

 29%|██▉       | 774/2685 [4:16:27<10:04:50, 18.99s/it]

 29%|██▉       | 775/2685 [4:16:42<9:20:14, 17.60s/it]

 29%|██▉       | 776/2685 [4:17:03<9:54:24, 18.68s/it]

 29%|██▉       | 777/2685 [4:17:22<9:58:04, 18.81s/it]

 29%|██▉       | 778/2685 [4:17:41<10:03:49, 19.00s/it]

 29%|██▉       | 779/2685 [4:17:57<9:27:19, 17.86s/it]

 29%|██▉       | 780/2685 [4:18:16<9:42:36, 18.35s/it]

 29%|██▉       | 781/2685 [4:18:36<9:59:46, 18.90s/it]

 29%|██▉       | 782/2685 [4:18:57<10:12:09, 19.30s/it]

 29%|██▉       | 783/2685 [4:19:18<10:29:01, 19.84s/it]

 29%|██▉       | 784/2685 [4:19:34<9:53:16, 18.72s/it]

 29%|██▉       | 785/2685 [4:19:51<9:37:28, 18.24s/it]

 29%|██▉       | 786/2685 [4:20:11<9:53:46, 18.76s/it]

 29%|██▉       | 787/2685 [4:20:31<10:03:58, 19.09s/it]

 29%|██▉       | 788/2685 [4:20:48<9:46:00, 18.53s/it]

 29%|██▉       | 789/2685 [4:21:08<10:01:33, 19.04s/it]

 29%|██▉       | 790/2685 [4:21:28<10:13:07, 19.41s/it]

 29%|██▉       | 791/2685 [4:21:52<10:53:39, 20.71s/it]

 29%|██▉       | 792/2685 [4:22:11<10:33:31, 20.08s/it]

 30%|██▉       | 793/2685 [4:22:30<10:27:30, 19.90s/it]

 30%|██▉       | 794/2685 [4:22:49<10:20:45, 19.70s/it]

 30%|██▉       | 795/2685 [4:23:12<10:47:59, 20.57s/it]

 30%|██▉       | 796/2685 [4:23:31<10:34:28, 20.15s/it]

 30%|██▉       | 797/2685 [4:23:53<10:47:03, 20.56s/it]
{'loss': 0.3297, 'learning_rate': 1.6495397826893825e-06, 'rewards/chosen': -0.5259679555892944, 'rewards/rejected': -3.259653091430664, 'rewards/accuracies': 0.75, 'rewards/margins': 2.733684539794922, 'policy_logps/rejected': -386.3006591796875, 'policy_logps/chosen': -392.3458557128906, 'referece_logps/rejected': -353.7041015625, 'referece_logps/chosen': -387.086181640625, 'logits/rejected': 0.4631302058696747, 'logits/chosen': 0.5010184645652771, 'epoch': 0.89}


 30%|██▉       | 799/2685 [4:24:33<10:43:24, 20.47s/it]
{'loss': 0.5064, 'learning_rate': 1.6477033009892104e-06, 'rewards/chosen': -1.2514100074768066, 'rewards/rejected': -3.3229103088378906, 'rewards/accuracies': 0.625, 'rewards/margins': 2.071500062942505, 'policy_logps/rejected': -259.57659912109375, 'policy_logps/chosen': -246.34649658203125, 'referece_logps/rejected': -226.34751892089844, 'referece_logps/chosen': -233.8323974609375, 'logits/rejected': -0.5864680409431458, 'logits/chosen': -0.6153842210769653, 'epoch': 0.89}


 30%|██▉       | 801/2685 [4:25:16<10:51:41, 20.75s/it]

 30%|██▉       | 802/2685 [4:25:36<10:45:37, 20.57s/it]

 30%|██▉       | 803/2685 [4:25:50<9:50:03, 18.81s/it]
[2024-03-29 19:58:07,879] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 30%|██▉       | 804/2685 [4:26:09<9:47:06, 18.73s/it]

 30%|██▉       | 805/2685 [4:26:26<9:30:01, 18.19s/it]

 30%|███       | 806/2685 [4:26:38<8:32:32, 16.37s/it]

 30%|███       | 807/2685 [4:26:54<8:29:33, 16.28s/it]

 30%|███       | 808/2685 [4:27:07<7:59:56, 15.34s/it]

 30%|███       | 809/2685 [4:27:29<9:01:00, 17.30s/it]

 30%|███       | 810/2685 [4:27:42<8:20:37, 16.02s/it]

 30%|███       | 811/2685 [4:28:04<9:17:44, 17.86s/it]

 30%|███       | 812/2685 [4:28:27<10:05:39, 19.40s/it]
[2024-03-29 20:00:44,746] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 30%|███       | 813/2685 [4:28:50<10:36:39, 20.41s/it]
[2024-03-29 20:01:07,494] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 30%|███       | 814/2685 [4:29:11<10:45:16, 20.69s/it]
[2024-03-29 20:01:28,857] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 30%|███       | 815/2685 [4:29:29<10:20:13, 19.90s/it]
[2024-03-29 20:01:46,907] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 30%|███       | 816/2685 [4:29:53<10:51:35, 20.92s/it]

 30%|███       | 817/2685 [4:30:13<10:47:26, 20.80s/it]

 30%|███       | 818/2685 [4:30:33<10:41:25, 20.61s/it]

 31%|███       | 819/2685 [4:30:53<10:35:17, 20.43s/it]
{'loss': 0.3617, 'learning_rate': 1.6291328553706702e-06, 'rewards/chosen': -1.9591456651687622, 'rewards/rejected': -3.4521701335906982, 'rewards/accuracies': 1.0, 'rewards/margins': 1.493024468421936, 'policy_logps/rejected': -494.0357360839844, 'policy_logps/chosen': -391.9740295410156, 'referece_logps/rejected': -459.51397705078125, 'referece_logps/chosen': -372.3825378417969, 'logits/rejected': -0.6020568609237671, 'logits/chosen': -0.6707748770713806, 'epoch': 0.92}
[2024-03-29 20:03:32,678] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 31%|███       | 821/2685 [4:31:37<11:00:23, 21.26s/it]

 31%|███       | 822/2685 [4:31:57<10:44:47, 20.77s/it]

 31%|███       | 823/2685 [4:32:16<10:31:32, 20.35s/it]

 31%|███       | 824/2685 [4:32:33<9:53:18, 19.13s/it]

 31%|███       | 825/2685 [4:32:51<9:48:24, 18.98s/it]

 31%|███       | 826/2685 [4:33:13<10:13:53, 19.81s/it]

 31%|███       | 827/2685 [4:33:36<10:40:20, 20.68s/it]
[2024-03-29 20:05:53,290] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 31%|███       | 828/2685 [4:33:56<10:33:05, 20.46s/it]
[2024-03-29 20:06:13,225] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 31%|███       | 829/2685 [4:34:16<10:27:39, 20.29s/it]
{'loss': 0.3258, 'learning_rate': 1.6197095979192917e-06, 'rewards/chosen': -0.9519171714782715, 'rewards/rejected': -3.334196090698242, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3822789192199707, 'policy_logps/rejected': -375.2440185546875, 'policy_logps/chosen': -296.4119567871094, 'referece_logps/rejected': -341.9020690917969, 'referece_logps/chosen': -286.8927917480469, 'logits/rejected': -0.038812197744846344, 'logits/chosen': -0.03174280747771263, 'epoch': 0.93}


 31%|███       | 831/2685 [4:34:55<10:17:53, 20.00s/it]
{'loss': 0.3605, 'learning_rate': 1.6178140784513729e-06, 'rewards/chosen': -1.5636954307556152, 'rewards/rejected': -2.90773344039917, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3440380096435547, 'policy_logps/rejected': -369.271728515625, 'policy_logps/chosen': -266.98260498046875, 'referece_logps/rejected': -340.19439697265625, 'referece_logps/chosen': -251.3456268310547, 'logits/rejected': -0.5377315878868103, 'logits/chosen': -0.6015446186065674, 'epoch': 0.93}

 31%|███       | 832/2685 [4:35:18<10:40:16, 20.73s/it]

 31%|███       | 833/2685 [4:35:35<10:09:52, 19.76s/it]

 31%|███       | 834/2685 [4:35:55<10:14:15, 19.91s/it]

 31%|███       | 835/2685 [4:36:17<10:32:09, 20.50s/it]

 31%|███       | 836/2685 [4:36:40<10:49:54, 21.09s/it]

 31%|███       | 837/2685 [4:37:03<11:14:41, 21.91s/it]

 31%|███       | 838/2685 [4:37:21<10:30:38, 20.49s/it]
{'loss': 0.2755, 'learning_rate': 1.6111515068809685e-06, 'rewards/chosen': -0.6465862393379211, 'rewards/rejected': -2.8537721633911133, 'rewards/accuracies': 0.875, 'rewards/margins': 2.207185983657837, 'policy_logps/rejected': -452.21649169921875, 'policy_logps/chosen': -440.082275390625, 'referece_logps/rejected': -423.67877197265625, 'referece_logps/chosen': -433.61639404296875, 'logits/rejected': 0.12524749338626862, 'logits/chosen': 0.07693417370319366, 'epoch': 0.94}

 31%|███       | 839/2685 [4:37:40<10:16:31, 20.04s/it]


 31%|███▏      | 841/2685 [4:38:21<10:35:55, 20.69s/it]
[2024-03-29 20:10:38,750] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 31%|███▏      | 842/2685 [4:38:37<9:53:10, 19.31s/it]
[2024-03-29 20:10:54,840] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 31%|███▏      | 843/2685 [4:38:56<9:46:45, 19.11s/it]

 31%|███▏      | 844/2685 [4:39:12<9:20:08, 18.26s/it]

 31%|███▏      | 845/2685 [4:39:35<10:02:52, 19.66s/it]

 32%|███▏      | 846/2685 [4:39:55<10:00:52, 19.60s/it]

 32%|███▏      | 847/2685 [4:40:15<10:04:37, 19.74s/it]

 32%|███▏      | 848/2685 [4:40:35<10:04:49, 19.75s/it]

 32%|███▏      | 849/2685 [4:40:48<9:03:48, 17.77s/it]

 32%|███▏      | 850/2685 [4:41:08<9:27:21, 18.55s/it]

 32%|███▏      | 851/2685 [4:41:31<10:05:29, 19.81s/it]
[2024-03-29 20:13:48,256] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 32%|███▏      | 852/2685 [4:41:47<9:34:33, 18.81s/it]
[2024-03-29 20:14:04,726] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 32%|███▏      | 853/2685 [4:42:10<10:11:42, 20.03s/it]
[2024-03-29 20:14:27,623] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 32%|███▏      | 854/2685 [4:42:30<10:13:13, 20.09s/it]
[2024-03-29 20:14:47,860] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3777, 'learning_rate': 1.595759867096156e-06, 'rewards/chosen': -0.9130504727363586, 'rewards/rejected': -3.4351806640625, 'rewards/accuracies': 0.875, 'rewards/margins': 2.522130250930786, 'policy_logps/rejected': -357.9956359863281, 'policy_logps/chosen': -416.66522216796875, 'referece_logps/rejected': -323.6438293457031, 'referece_logps/chosen': -407.53466796875, 'logits/rejected': -0.3094809055328369, 'logits/chosen': -0.27012544870376587, 'epoch': 0.95}

 32%|███▏      | 855/2685 [4:42:50<10:08:59, 19.97s/it]

 32%|███▏      | 856/2685 [4:43:08<9:46:53, 19.25s/it]

 32%|███▏      | 857/2685 [4:43:29<10:02:24, 19.77s/it]

 32%|███▏      | 858/2685 [4:43:47<9:53:02, 19.48s/it]

 32%|███▏      | 859/2685 [4:44:07<9:57:55, 19.65s/it]

 32%|███▏      | 860/2685 [4:44:26<9:45:02, 19.23s/it]

 32%|███▏      | 861/2685 [4:44:47<10:02:19, 19.81s/it]

 32%|███▏      | 862/2685 [4:45:06<9:51:08, 19.46s/it]

 32%|███▏      | 863/2685 [4:45:19<8:58:41, 17.74s/it]

 32%|███▏      | 864/2685 [4:45:41<9:33:00, 18.88s/it]

 32%|███▏      | 865/2685 [4:45:59<9:25:30, 18.64s/it]

 32%|███▏      | 866/2685 [4:46:19<9:42:30, 19.21s/it]

 32%|███▏      | 867/2685 [4:46:41<9:58:58, 19.77s/it]

 32%|███▏      | 868/2685 [4:47:01<10:02:23, 19.89s/it]

 32%|███▏      | 869/2685 [4:47:21<10:06:00, 20.02s/it]

 32%|███▏      | 870/2685 [4:47:39<9:44:54, 19.34s/it]

 32%|███▏      | 871/2685 [4:47:57<9:32:13, 18.93s/it]

 32%|███▏      | 872/2685 [4:48:21<10:24:03, 20.65s/it]
[2024-03-29 20:20:38,855] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 33%|███▎      | 873/2685 [4:48:44<10:37:57, 21.12s/it]
[2024-03-29 20:21:01,081] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 33%|███▎      | 874/2685 [4:49:06<10:46:30, 21.42s/it]
[2024-03-29 20:21:23,188] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 33%|███▎      | 875/2685 [4:49:25<10:30:51, 20.91s/it]

 33%|███▎      | 876/2685 [4:49:46<10:24:24, 20.71s/it]

 33%|███▎      | 877/2685 [4:50:06<10:16:01, 20.44s/it]

 33%|███▎      | 878/2685 [4:50:24<10:00:28, 19.94s/it]
{'loss': 0.3801, 'learning_rate': 1.5722580081707672e-06, 'rewards/chosen': -0.6951228380203247, 'rewards/rejected': -2.4816362857818604, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7865134477615356, 'policy_logps/rejected': -303.50482177734375, 'policy_logps/chosen': -297.7834167480469, 'referece_logps/rejected': -278.6884460449219, 'referece_logps/chosen': -290.8321838378906, 'logits/rejected': -0.21789120137691498, 'logits/chosen': -0.07435089349746704, 'epoch': 0.98}


 33%|███▎      | 880/2685 [4:51:00<9:19:26, 18.60s/it]

 33%|███▎      | 881/2685 [4:51:20<9:36:14, 19.17s/it]

 33%|███▎      | 882/2685 [4:51:40<9:40:46, 19.33s/it]

 33%|███▎      | 883/2685 [4:52:01<9:59:04, 19.95s/it]
{'loss': 0.289, 'learning_rate': 1.5673007423010401e-06, 'rewards/chosen': -0.6699181199073792, 'rewards/rejected': -2.6514337062835693, 'rewards/accuracies': 0.875, 'rewards/margins': 1.981515645980835, 'policy_logps/rejected': -238.5133819580078, 'policy_logps/chosen': -285.1575927734375, 'referece_logps/rejected': -211.99903869628906, 'referece_logps/chosen': -278.4584045410156, 'logits/rejected': -0.47659099102020264, 'logits/chosen': -0.3615521788597107, 'epoch': 0.99}

 33%|███▎      | 884/2685 [4:52:23<10:12:11, 20.40s/it]

 33%|███▎      | 885/2685 [4:52:43<10:07:19, 20.24s/it]


 33%|███▎      | 887/2685 [4:53:22<10:04:02, 20.16s/it]

 33%|███▎      | 888/2685 [4:53:44<10:17:13, 20.61s/it]

 33%|███▎      | 889/2685 [4:54:06<10:32:38, 21.14s/it]
{'loss': 0.3271, 'learning_rate': 1.5613247906113241e-06, 'rewards/chosen': -1.4977039098739624, 'rewards/rejected': -5.5072126388549805, 'rewards/accuracies': 0.875, 'rewards/margins': 4.009509086608887, 'policy_logps/rejected': -543.1588134765625, 'policy_logps/chosen': -402.1302185058594, 'referece_logps/rejected': -488.08673095703125, 'referece_logps/chosen': -387.1531982421875, 'logits/rejected': 0.32489705085754395, 'logits/chosen': 0.3868408799171448, 'epoch': 0.99}

 33%|███▎      | 890/2685 [4:54:21<9:33:47, 19.18s/it]


 33%|███▎      | 892/2685 [4:54:59<9:32:52, 19.17s/it]

 33%|███▎      | 893/2685 [4:55:18<9:27:45, 19.01s/it]
{'loss': 0.3013, 'learning_rate': 1.5573244631224363e-06, 'rewards/chosen': -1.3795819282531738, 'rewards/rejected': -3.093632936477661, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7140510082244873, 'policy_logps/rejected': -259.73382568359375, 'policy_logps/chosen': -194.84344482421875, 'referece_logps/rejected': -228.79751586914062, 'referece_logps/chosen': -181.04763793945312, 'logits/rejected': -0.7176905274391174, 'logits/chosen': -0.6983680129051208, 'epoch': 1.0}


 33%|███▎      | 895/2685 [4:56:00<10:00:27, 20.13s/it]
{'loss': 0.2939, 'learning_rate': 1.5553194263760406e-06, 'rewards/chosen': -1.9047610759735107, 'rewards/rejected': -4.222786903381348, 'rewards/accuracies': 0.875, 'rewards/margins': 2.318025588989258, 'policy_logps/rejected': -401.9234313964844, 'policy_logps/chosen': -417.9248046875, 'referece_logps/rejected': -359.69549560546875, 'referece_logps/chosen': -398.87713623046875, 'logits/rejected': 0.4791699945926666, 'logits/chosen': 0.5968875885009766, 'epoch': 1.0}


 33%|███▎      | 897/2685 [4:56:44<10:33:34, 21.26s/it]

 33%|███▎      | 898/2685 [4:57:06<10:37:21, 21.40s/it]

 33%|███▎      | 899/2685 [4:57:26<10:21:50, 20.89s/it]

 34%|███▎      | 900/2685 [4:57:46<10:17:09, 20.74s/it]
{'loss': 0.3079, 'learning_rate': 1.5502927152373913e-06, 'rewards/chosen': -0.4606305956840515, 'rewards/rejected': -3.41009521484375, 'rewards/accuracies': 0.875, 'rewards/margins': 2.9494645595550537, 'policy_logps/rejected': -391.1340026855469, 'policy_logps/chosen': -396.69598388671875, 'referece_logps/rejected': -357.0330810546875, 'referece_logps/chosen': -392.0896911621094, 'logits/rejected': -0.17797443270683289, 'logits/chosen': -0.1583653688430786, 'epoch': 1.01}

 34%|███▎      | 901/2685 [4:58:07<10:16:59, 20.75s/it]

 34%|███▎      | 902/2685 [4:58:27<10:10:15, 20.54s/it]


 34%|███▎      | 904/2685 [4:59:04<9:43:07, 19.64s/it]

 34%|███▎      | 905/2685 [4:59:24<9:39:41, 19.54s/it]

 34%|███▎      | 906/2685 [4:59:46<10:02:23, 20.32s/it]

 34%|███▍      | 907/2685 [5:00:06<10:05:05, 20.42s/it]

 34%|███▍      | 908/2685 [5:00:26<10:00:10, 20.27s/it]
{'loss': 0.4349, 'learning_rate': 1.5422084039167475e-06, 'rewards/chosen': -0.3299597203731537, 'rewards/rejected': -2.667015314102173, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3370556831359863, 'policy_logps/rejected': -307.402587890625, 'policy_logps/chosen': -297.60418701171875, 'referece_logps/rejected': -280.732421875, 'referece_logps/chosen': -294.3045654296875, 'logits/rejected': -0.5069252252578735, 'logits/chosen': -0.5414266586303711, 'epoch': 1.01}


 34%|███▍      | 910/2685 [5:00:58<9:04:04, 18.39s/it]

 34%|███▍      | 911/2685 [5:01:20<9:29:53, 19.27s/it]
{'loss': 0.2634, 'learning_rate': 1.5391637249648687e-06, 'rewards/chosen': -1.3965445756912231, 'rewards/rejected': -3.911855697631836, 'rewards/accuracies': 0.75, 'rewards/margins': 2.5153112411499023, 'policy_logps/rejected': -408.737548828125, 'policy_logps/chosen': -419.974853515625, 'referece_logps/rejected': -369.6189880371094, 'referece_logps/chosen': -406.0094299316406, 'logits/rejected': -0.3694852590560913, 'logits/chosen': -0.3924522399902344, 'epoch': 1.02}


 34%|███▍      | 913/2685 [5:01:57<9:15:37, 18.81s/it]

 34%|███▍      | 914/2685 [5:02:18<9:36:20, 19.53s/it]

 34%|███▍      | 915/2685 [5:02:42<10:15:04, 20.85s/it]
{'loss': 0.3049, 'learning_rate': 1.5350931732676538e-06, 'rewards/chosen': -1.9029182195663452, 'rewards/rejected': -4.953561305999756, 'rewards/accuracies': 0.875, 'rewards/margins': 3.0506432056427, 'policy_logps/rejected': -318.700927734375, 'policy_logps/chosen': -275.95220947265625, 'referece_logps/rejected': -269.1653137207031, 'referece_logps/chosen': -256.92303466796875, 'logits/rejected': -0.5398678779602051, 'logits/chosen': -0.6225545406341553, 'epoch': 1.02}

 34%|███▍      | 916/2685 [5:03:03<10:18:44, 20.99s/it]


 34%|███▍      | 918/2685 [5:03:43<10:02:55, 20.47s/it]

 34%|███▍      | 919/2685 [5:03:57<9:04:41, 18.51s/it]

 34%|███▍      | 920/2685 [5:04:10<8:21:56, 17.06s/it]
{'loss': 0.4252, 'learning_rate': 1.5299874709591757e-06, 'rewards/chosen': -0.8790179491043091, 'rewards/rejected': -3.320744752883911, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4417271614074707, 'policy_logps/rejected': -247.71295166015625, 'policy_logps/chosen': -249.42079162597656, 'referece_logps/rejected': -214.5054931640625, 'referece_logps/chosen': -240.63055419921875, 'logits/rejected': -0.8265610337257385, 'logits/chosen': -0.8464420437812805, 'epoch': 1.03}


 34%|███▍      | 922/2685 [5:04:49<9:02:25, 18.46s/it]

 34%|███▍      | 923/2685 [5:05:08<9:06:23, 18.61s/it]
{'loss': 0.3131, 'learning_rate': 1.5269147808025974e-06, 'rewards/chosen': -0.5114391446113586, 'rewards/rejected': -2.24161958694458, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7301807403564453, 'policy_logps/rejected': -271.9288330078125, 'policy_logps/chosen': -147.21270751953125, 'referece_logps/rejected': -249.5126495361328, 'referece_logps/chosen': -142.0983123779297, 'logits/rejected': -0.6334836483001709, 'logits/chosen': -0.6753703355789185, 'epoch': 1.03}


 34%|███▍      | 925/2685 [5:05:49<9:32:01, 19.50s/it]

 34%|███▍      | 926/2685 [5:06:11<9:51:37, 20.18s/it]

 35%|███▍      | 927/2685 [5:06:30<9:44:04, 19.93s/it]
{'loss': 0.3552, 'learning_rate': 1.5228071304952348e-06, 'rewards/chosen': -0.4365178048610687, 'rewards/rejected': -1.7914657592773438, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3549479246139526, 'policy_logps/rejected': -256.406005859375, 'policy_logps/chosen': -257.80572509765625, 'referece_logps/rejected': -238.4913330078125, 'referece_logps/chosen': -253.4405517578125, 'logits/rejected': -0.06530694663524628, 'logits/chosen': -0.18772196769714355, 'epoch': 1.04}


 35%|███▍      | 929/2685 [5:07:08<9:29:49, 19.47s/it]
{'loss': 0.4082, 'learning_rate': 1.5207487336272734e-06, 'rewards/chosen': -2.0567963123321533, 'rewards/rejected': -4.081432342529297, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0246362686157227, 'policy_logps/rejected': -350.8316650390625, 'policy_logps/chosen': -335.0569763183594, 'referece_logps/rejected': -310.0173645019531, 'referece_logps/chosen': -314.489013671875, 'logits/rejected': 0.5674516558647156, 'logits/chosen': 0.5666918754577637, 'epoch': 1.04}

 35%|███▍      | 930/2685 [5:07:28<9:30:06, 19.49s/it]


 35%|███▍      | 932/2685 [5:08:05<9:16:11, 19.04s/it]
{'loss': 0.3716, 'learning_rate': 1.517655457381612e-06, 'rewards/chosen': -0.9952916502952576, 'rewards/rejected': -1.9299545288085938, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9346629977226257, 'policy_logps/rejected': -298.17254638671875, 'policy_logps/chosen': -292.57220458984375, 'referece_logps/rejected': -278.87298583984375, 'referece_logps/chosen': -282.61932373046875, 'logits/rejected': -0.49438250064849854, 'logits/chosen': -0.5635716915130615, 'epoch': 1.04}


 35%|███▍      | 934/2685 [5:08:45<9:26:54, 19.43s/it]
{'loss': 0.408, 'learning_rate': 1.5155895034310441e-06, 'rewards/chosen': -0.4890771806240082, 'rewards/rejected': -3.729145050048828, 'rewards/accuracies': 0.875, 'rewards/margins': 3.240067481994629, 'policy_logps/rejected': -448.2803039550781, 'policy_logps/chosen': -477.7437744140625, 'referece_logps/rejected': -410.9888000488281, 'referece_logps/chosen': -472.8529968261719, 'logits/rejected': 0.6066941022872925, 'logits/chosen': 0.6238106489181519, 'epoch': 1.04}

 35%|███▍      | 935/2685 [5:09:06<9:43:45, 20.01s/it]

 35%|███▍      | 936/2685 [5:09:26<9:41:50, 19.96s/it]

 35%|███▍      | 937/2685 [5:09:48<10:02:12, 20.67s/it]

 35%|███▍      | 938/2685 [5:10:10<10:10:27, 20.97s/it]


 35%|███▌      | 940/2685 [5:10:48<9:47:48, 20.21s/it]
{'loss': 0.2757, 'learning_rate': 1.5093736789841516e-06, 'rewards/chosen': -1.3772292137145996, 'rewards/rejected': -4.594468116760254, 'rewards/accuracies': 0.875, 'rewards/margins': 3.217238664627075, 'policy_logps/rejected': -542.0014038085938, 'policy_logps/chosen': -504.84930419921875, 'referece_logps/rejected': -496.0567321777344, 'referece_logps/chosen': -491.07696533203125, 'logits/rejected': 0.40791621804237366, 'logits/chosen': 0.35032373666763306, 'epoch': 1.05}


 35%|███▌      | 942/2685 [5:11:30<9:55:00, 20.48s/it]

 35%|███▌      | 943/2685 [5:11:54<10:26:05, 21.56s/it]

 35%|███▌      | 944/2685 [5:12:15<10:26:06, 21.58s/it]
{'loss': 0.3175, 'learning_rate': 1.5052149478634858e-06, 'rewards/chosen': -0.772235631942749, 'rewards/rejected': -2.3087825775146484, 'rewards/accuracies': 0.625, 'rewards/margins': 1.536547064781189, 'policy_logps/rejected': -194.6659698486328, 'policy_logps/chosen': -237.7987823486328, 'referece_logps/rejected': -171.57814025878906, 'referece_logps/chosen': -230.07640075683594, 'logits/rejected': -0.9344308972358704, 'logits/chosen': -0.8275024890899658, 'epoch': 1.05}

 35%|███▌      | 945/2685 [5:12:36<10:17:54, 21.31s/it]

 35%|███▌      | 946/2685 [5:12:54<9:52:01, 20.43s/it]


 35%|███▌      | 948/2685 [5:13:35<9:48:46, 20.34s/it]
{'loss': 0.3941, 'learning_rate': 1.5010444511688928e-06, 'rewards/chosen': -1.496013879776001, 'rewards/rejected': -2.757505416870117, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2614916563034058, 'policy_logps/rejected': -326.7698974609375, 'policy_logps/chosen': -292.5694274902344, 'referece_logps/rejected': -299.19482421875, 'referece_logps/chosen': -277.6092834472656, 'logits/rejected': -0.35309067368507385, 'logits/chosen': -0.3866955041885376, 'epoch': 1.06}


 35%|███▌      | 950/2685 [5:14:15<9:53:19, 20.52s/it]
{'loss': 0.3243, 'learning_rate': 1.4989548210718522e-06, 'rewards/chosen': -0.7639983296394348, 'rewards/rejected': -3.4790468215942383, 'rewards/accuracies': 1.0, 'rewards/margins': 2.71504807472229, 'policy_logps/rejected': -306.9645080566406, 'policy_logps/chosen': -272.6033020019531, 'referece_logps/rejected': -272.174072265625, 'referece_logps/chosen': -264.96331787109375, 'logits/rejected': -0.27661389112472534, 'logits/chosen': -0.2788037061691284, 'epoch': 1.06}

 35%|███▌      | 951/2685 [5:14:34<9:38:03, 20.00s/it]

 35%|███▌      | 952/2685 [5:14:54<9:35:05, 19.91s/it]


 36%|███▌      | 954/2685 [5:15:38<10:01:40, 20.86s/it]

 36%|███▌      | 955/2685 [5:15:57<9:46:33, 20.34s/it]

 36%|███▌      | 956/2685 [5:16:18<9:52:50, 20.57s/it]

 36%|███▌      | 957/2685 [5:16:37<9:43:24, 20.26s/it]
{'loss': 0.4043, 'learning_rate': 1.4916183192358715e-06, 'rewards/chosen': -1.5484814643859863, 'rewards/rejected': -3.491832971572876, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9433516263961792, 'policy_logps/rejected': -533.3778686523438, 'policy_logps/chosen': -336.3586730957031, 'referece_logps/rejected': -498.4595642089844, 'referece_logps/chosen': -320.87384033203125, 'logits/rejected': 0.31649768352508545, 'logits/chosen': 0.2900059223175049, 'epoch': 1.07}

 36%|███▌      | 958/2685 [5:16:58<9:48:24, 20.44s/it]


 36%|███▌      | 960/2685 [5:17:35<9:18:22, 19.42s/it]

 36%|███▌      | 961/2685 [5:17:58<9:48:13, 20.47s/it]

 36%|███▌      | 962/2685 [5:18:20<10:02:30, 20.98s/it]

 36%|███▌      | 963/2685 [5:18:38<9:32:22, 19.94s/it]

 36%|███▌      | 964/2685 [5:18:52<8:44:33, 18.29s/it]

 36%|███▌      | 965/2685 [5:19:15<9:25:45, 19.74s/it]
{'loss': 0.388, 'learning_rate': 1.4831908430096113e-06, 'rewards/chosen': -1.4233460426330566, 'rewards/rejected': -2.9166722297668457, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4933258295059204, 'policy_logps/rejected': -307.5248718261719, 'policy_logps/chosen': -269.38653564453125, 'referece_logps/rejected': -278.358154296875, 'referece_logps/chosen': -255.15306091308594, 'logits/rejected': -0.9367517232894897, 'logits/chosen': -0.7494768500328064, 'epoch': 1.08}


 36%|███▌      | 967/2685 [5:19:57<9:46:21, 20.48s/it]
{'loss': 0.3287, 'learning_rate': 1.4810769103163005e-06, 'rewards/chosen': -0.728667140007019, 'rewards/rejected': -4.063878536224365, 'rewards/accuracies': 0.75, 'rewards/margins': 3.335211992263794, 'policy_logps/rejected': -518.5654296875, 'policy_logps/chosen': -439.99444580078125, 'referece_logps/rejected': -477.9266357421875, 'referece_logps/chosen': -432.7077331542969, 'logits/rejected': 0.16035573184490204, 'logits/chosen': 0.2116578221321106, 'epoch': 1.08}


 36%|███▌      | 969/2685 [5:20:34<9:17:36, 19.50s/it]
{'loss': 0.3791, 'learning_rate': 1.4789601767586172e-06, 'rewards/chosen': -1.2981421947479248, 'rewards/rejected': -3.057508945465088, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7593668699264526, 'policy_logps/rejected': -620.67236328125, 'policy_logps/chosen': -540.78271484375, 'referece_logps/rejected': -590.0972900390625, 'referece_logps/chosen': -527.80126953125, 'logits/rejected': -0.09201046079397202, 'logits/chosen': -0.09770047664642334, 'epoch': 1.08}


 36%|███▌      | 971/2685 [5:21:14<9:27:18, 19.86s/it]

 36%|███▌      | 972/2685 [5:21:34<9:26:30, 19.84s/it]
{'loss': 0.3005, 'learning_rate': 1.4757798517640936e-06, 'rewards/chosen': -0.4104737341403961, 'rewards/rejected': -2.8064260482788086, 'rewards/accuracies': 0.75, 'rewards/margins': 2.3959522247314453, 'policy_logps/rejected': -336.3349914550781, 'policy_logps/chosen': -288.0584716796875, 'referece_logps/rejected': -308.270751953125, 'referece_logps/chosen': -283.9537353515625, 'logits/rejected': -0.2884480357170105, 'logits/chosen': -0.2678261995315552, 'epoch': 1.09}

 36%|███▌      | 973/2685 [5:21:51<9:05:03, 19.10s/it]


 36%|███▋      | 975/2685 [5:22:32<9:24:43, 19.81s/it]
{'loss': 0.3533, 'learning_rate': 1.472593294218187e-06, 'rewards/chosen': -1.84541654586792, 'rewards/rejected': -2.7324252128601074, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8870086669921875, 'policy_logps/rejected': -489.3648681640625, 'policy_logps/chosen': -386.9512023925781, 'referece_logps/rejected': -462.04058837890625, 'referece_logps/chosen': -368.4970703125, 'logits/rejected': 0.7108118534088135, 'logits/chosen': 0.5340250134468079, 'epoch': 1.09}

 36%|███▋      | 976/2685 [5:22:49<8:57:17, 18.86s/it]


 36%|███▋      | 978/2685 [5:23:32<9:33:18, 20.15s/it]

 36%|███▋      | 979/2685 [5:23:48<9:00:09, 19.00s/it]

 36%|███▋      | 980/2685 [5:24:12<9:39:33, 20.40s/it]
{'loss': 0.3168, 'learning_rate': 1.467268628273062e-06, 'rewards/chosen': -1.6418296098709106, 'rewards/rejected': -3.200802803039551, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5589733123779297, 'policy_logps/rejected': -439.108154296875, 'policy_logps/chosen': -413.1501159667969, 'referece_logps/rejected': -407.10015869140625, 'referece_logps/chosen': -396.7318115234375, 'logits/rejected': -0.3862999677658081, 'logits/chosen': -0.25392425060272217, 'epoch': 1.09}

 37%|███▋      | 981/2685 [5:24:33<9:49:40, 20.76s/it]

 37%|███▋      | 982/2685 [5:24:55<9:59:56, 21.14s/it]

 37%|███▋      | 983/2685 [5:25:14<9:36:25, 20.32s/it]

 37%|███▋      | 984/2685 [5:25:35<9:42:46, 20.56s/it]

 37%|███▋      | 985/2685 [5:25:53<9:23:05, 19.87s/it]

 37%|███▋      | 986/2685 [5:26:15<9:36:15, 20.35s/it]

 37%|███▋      | 987/2685 [5:26:35<9:39:22, 20.47s/it]

 37%|███▋      | 988/2685 [5:26:49<8:44:42, 18.55s/it]

 37%|███▋      | 989/2685 [5:27:12<9:14:43, 19.62s/it]

 37%|███▋      | 990/2685 [5:27:31<9:16:06, 19.68s/it]


 37%|███▋      | 992/2685 [5:28:14<9:40:13, 20.56s/it]

 37%|███▋      | 993/2685 [5:28:34<9:32:55, 20.32s/it]
{'loss': 0.3204, 'learning_rate': 1.453345408606677e-06, 'rewards/chosen': -0.7927243113517761, 'rewards/rejected': -2.293166160583496, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5004417896270752, 'policy_logps/rejected': -341.79742431640625, 'policy_logps/chosen': -307.1717224121094, 'referece_logps/rejected': -318.8657531738281, 'referece_logps/chosen': -299.24444580078125, 'logits/rejected': 0.3593443036079407, 'logits/chosen': 0.3439851403236389, 'epoch': 1.11}


 37%|███▋      | 995/2685 [5:29:14<9:27:56, 20.16s/it]

 37%|███▋      | 996/2685 [5:29:33<9:11:01, 19.57s/it]

 37%|███▋      | 997/2685 [5:29:52<9:10:26, 19.57s/it]
{'loss': 0.386, 'learning_rate': 1.4490387467392389e-06, 'rewards/chosen': -1.6101759672164917, 'rewards/rejected': -4.382623672485352, 'rewards/accuracies': 0.875, 'rewards/margins': 2.7724475860595703, 'policy_logps/rejected': -552.9658813476562, 'policy_logps/chosen': -425.43798828125, 'referece_logps/rejected': -509.1396484375, 'referece_logps/chosen': -409.3362121582031, 'logits/rejected': 0.6476043462753296, 'logits/chosen': 0.6591606736183167, 'epoch': 1.11}

 37%|███▋      | 998/2685 [5:30:08<8:38:53, 18.45s/it]

 37%|███▋      | 999/2685 [5:30:23<8:08:44, 17.39s/it]

 37%|███▋      | 1000/2685 [5:30:45<8:46:23, 18.74s/it]

 37%|███▋      | 1001/2685 [5:31:18<10:47:20, 23.06s/it]

 37%|███▋      | 1002/2685 [5:31:38<10:22:52, 22.21s/it]

 37%|███▋      | 1003/2685 [5:31:58<10:04:09, 21.55s/it]


 37%|███▋      | 1005/2685 [5:32:33<8:55:32, 19.13s/it]

 37%|███▋      | 1006/2685 [5:32:53<9:03:53, 19.44s/it]
{'loss': 0.2754, 'learning_rate': 1.4393106761175242e-06, 'rewards/chosen': -0.8491129279136658, 'rewards/rejected': -2.335601806640625, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4864888191223145, 'policy_logps/rejected': -242.580078125, 'policy_logps/chosen': -227.92324829101562, 'referece_logps/rejected': -219.22406005859375, 'referece_logps/chosen': -219.43212890625, 'logits/rejected': -0.7722916603088379, 'logits/chosen': -0.7192001342773438, 'epoch': 1.12}

 38%|███▊      | 1007/2685 [5:33:14<9:14:30, 19.83s/it]


 38%|███▊      | 1009/2685 [5:33:55<9:24:06, 20.20s/it]
{'loss': 0.3116, 'learning_rate': 1.4360564195609945e-06, 'rewards/chosen': -2.117737054824829, 'rewards/rejected': -3.959439992904663, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8417028188705444, 'policy_logps/rejected': -328.83160400390625, 'policy_logps/chosen': -278.9399108886719, 'referece_logps/rejected': -289.23724365234375, 'referece_logps/chosen': -257.7625427246094, 'logits/rejected': -0.244698166847229, 'logits/chosen': -0.3610624074935913, 'epoch': 1.13}


 38%|███▊      | 1011/2685 [5:34:37<9:35:54, 20.64s/it]

 38%|███▊      | 1012/2685 [5:34:56<9:28:20, 20.38s/it]

 38%|███▊      | 1013/2685 [5:35:19<9:42:19, 20.90s/it]

 38%|███▊      | 1014/2685 [5:35:41<9:54:20, 21.34s/it]

 38%|███▊      | 1015/2685 [5:36:03<10:01:30, 21.61s/it]

 38%|███▊      | 1016/2685 [5:36:25<10:02:19, 21.65s/it]
{'loss': 0.3163, 'learning_rate': 1.42844101401821e-06, 'rewards/chosen': -0.8698252439498901, 'rewards/rejected': -3.2299418449401855, 'rewards/accuracies': 0.875, 'rewards/margins': 2.360117197036743, 'policy_logps/rejected': -343.5231628417969, 'policy_logps/chosen': -249.01327514648438, 'referece_logps/rejected': -311.2237548828125, 'referece_logps/chosen': -240.31503295898438, 'logits/rejected': -0.7199309468269348, 'logits/chosen': -0.746329665184021, 'epoch': 1.14}

 38%|███▊      | 1017/2685 [5:36:45<9:52:50, 21.33s/it]

 38%|███▊      | 1018/2685 [5:37:05<9:40:13, 20.88s/it]


 38%|███▊      | 1020/2685 [5:37:43<9:06:50, 19.71s/it]
{'loss': 0.2838, 'learning_rate': 1.4240755995770534e-06, 'rewards/chosen': -1.0063199996948242, 'rewards/rejected': -3.6044013500213623, 'rewards/accuracies': 0.875, 'rewards/margins': 2.598081111907959, 'policy_logps/rejected': -266.78631591796875, 'policy_logps/chosen': -241.5623321533203, 'referece_logps/rejected': -230.7423095703125, 'referece_logps/chosen': -231.49911499023438, 'logits/rejected': -0.0390683189034462, 'logits/chosen': -0.05848957598209381, 'epoch': 1.14}

 38%|███▊      | 1021/2685 [5:38:04<9:16:25, 20.06s/it]

 38%|███▊      | 1022/2685 [5:38:24<9:13:28, 19.97s/it]

 38%|███▊      | 1023/2685 [5:38:44<9:20:22, 20.23s/it]

 38%|███▊      | 1024/2685 [5:39:02<9:00:43, 19.53s/it]


 38%|███▊      | 1026/2685 [5:39:43<9:11:38, 19.95s/it]
{'loss': 0.2992, 'learning_rate': 1.4175089922850632e-06, 'rewards/chosen': -0.2771669626235962, 'rewards/rejected': -2.1826932430267334, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9055263996124268, 'policy_logps/rejected': -209.54180908203125, 'policy_logps/chosen': -235.13510131835938, 'referece_logps/rejected': -187.71485900878906, 'referece_logps/chosen': -232.36341857910156, 'logits/rejected': -0.6863381266593933, 'logits/chosen': -0.666425347328186, 'epoch': 1.15}

 38%|███▊      | 1027/2685 [5:40:03<9:09:22, 19.88s/it]

 38%|███▊      | 1028/2685 [5:40:22<9:06:52, 19.80s/it]


 38%|███▊      | 1030/2685 [5:41:01<9:02:04, 19.65s/it]

 38%|███▊      | 1031/2685 [5:41:21<9:03:39, 19.72s/it]

 38%|███▊      | 1032/2685 [5:41:43<9:22:26, 20.42s/it]

 38%|███▊      | 1033/2685 [5:42:03<9:17:39, 20.25s/it]

 39%|███▊      | 1034/2685 [5:42:23<9:16:33, 20.23s/it]

 39%|███▊      | 1035/2685 [5:42:43<9:14:00, 20.15s/it]

 39%|███▊      | 1036/2685 [5:43:05<9:30:43, 20.77s/it]
{'loss': 0.3692, 'learning_rate': 1.406516202074976e-06, 'rewards/chosen': -2.740933895111084, 'rewards/rejected': -3.8800594806671143, 'rewards/accuracies': 0.5, 'rewards/margins': 1.1391254663467407, 'policy_logps/rejected': -622.4209594726562, 'policy_logps/chosen': -659.3521118164062, 'referece_logps/rejected': -583.6203002929688, 'referece_logps/chosen': -631.9428100585938, 'logits/rejected': 0.36957672238349915, 'logits/chosen': 0.31021225452423096, 'epoch': 1.16}

 39%|███▊      | 1037/2685 [5:43:26<9:32:43, 20.85s/it]

 39%|███▊      | 1038/2685 [5:43:47<9:26:50, 20.65s/it]

 39%|███▊      | 1039/2685 [5:44:09<9:40:38, 21.17s/it]

 39%|███▊      | 1040/2685 [5:44:30<9:36:37, 21.03s/it]

 39%|███▉      | 1041/2685 [5:44:50<9:31:41, 20.86s/it]

 39%|███▉      | 1042/2685 [5:45:10<9:24:58, 20.63s/it]


 39%|███▉      | 1044/2685 [5:45:47<8:55:52, 19.59s/it]
{'loss': 0.4218, 'learning_rate': 1.3976792915134387e-06, 'rewards/chosen': -1.0146498680114746, 'rewards/rejected': -4.38766622543335, 'rewards/accuracies': 1.0, 'rewards/margins': 3.373016357421875, 'policy_logps/rejected': -423.93255615234375, 'policy_logps/chosen': -394.2567138671875, 'referece_logps/rejected': -380.0558776855469, 'referece_logps/chosen': -384.1101989746094, 'logits/rejected': 0.37709906697273254, 'logits/chosen': 0.39118248224258423, 'epoch': 1.17}

 39%|███▉      | 1045/2685 [5:46:09<9:12:33, 20.22s/it]


 39%|███▉      | 1047/2685 [5:46:50<9:11:04, 20.19s/it]
{'loss': 0.3206, 'learning_rate': 1.3943558551133186e-06, 'rewards/chosen': -0.3703858256340027, 'rewards/rejected': -2.553985595703125, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1835997104644775, 'policy_logps/rejected': -221.27200317382812, 'policy_logps/chosen': -215.87924194335938, 'referece_logps/rejected': -195.73214721679688, 'referece_logps/chosen': -212.17538452148438, 'logits/rejected': -0.33803656697273254, 'logits/chosen': -0.32193249464035034, 'epoch': 1.17}


 39%|███▉      | 1049/2685 [5:47:34<9:40:05, 21.27s/it]
{'loss': 0.2713, 'learning_rate': 1.392137358197932e-06, 'rewards/chosen': -0.963695228099823, 'rewards/rejected': -2.9680118560791016, 'rewards/accuracies': 1.0, 'rewards/margins': 2.004316568374634, 'policy_logps/rejected': -367.5057067871094, 'policy_logps/chosen': -394.0848388671875, 'referece_logps/rejected': -337.82562255859375, 'referece_logps/chosen': -384.4478759765625, 'logits/rejected': -0.2785980701446533, 'logits/chosen': -0.28651171922683716, 'epoch': 1.17}

 39%|███▉      | 1050/2685 [5:47:51<9:06:42, 20.06s/it]

 39%|███▉      | 1051/2685 [5:48:11<9:05:46, 20.04s/it]

 39%|███▉      | 1052/2685 [5:48:33<9:19:43, 20.57s/it]

 39%|███▉      | 1053/2685 [5:48:53<9:16:01, 20.44s/it]

 39%|███▉      | 1054/2685 [5:49:13<9:11:03, 20.27s/it]

 39%|███▉      | 1055/2685 [5:49:33<9:12:10, 20.33s/it]

 39%|███▉      | 1056/2685 [5:49:52<9:01:06, 19.93s/it]


 39%|███▉      | 1058/2685 [5:50:30<8:40:43, 19.20s/it]

 39%|███▉      | 1059/2685 [5:50:50<8:44:55, 19.37s/it]

 39%|███▉      | 1060/2685 [5:51:12<9:09:10, 20.28s/it]
{'loss': 0.2689, 'learning_rate': 1.3798951625930416e-06, 'rewards/chosen': -0.9815903902053833, 'rewards/rejected': -4.08124303817749, 'rewards/accuracies': 0.875, 'rewards/margins': 3.0996527671813965, 'policy_logps/rejected': -441.1356201171875, 'policy_logps/chosen': -377.1800842285156, 'referece_logps/rejected': -400.32318115234375, 'referece_logps/chosen': -367.36419677734375, 'logits/rejected': -0.2742308974266052, 'logits/chosen': -0.22825750708580017, 'epoch': 1.18}

 40%|███▉      | 1061/2685 [5:51:29<8:45:01, 19.40s/it]

 40%|███▉      | 1062/2685 [5:51:49<8:46:00, 19.45s/it]

 40%|███▉      | 1063/2685 [5:52:12<9:15:45, 20.56s/it]

 40%|███▉      | 1064/2685 [5:52:30<8:53:32, 19.75s/it]

 40%|███▉      | 1065/2685 [5:52:47<8:36:07, 19.12s/it]

 40%|███▉      | 1066/2685 [5:53:04<8:15:17, 18.36s/it]

 40%|███▉      | 1067/2685 [5:53:25<8:34:17, 19.07s/it]

 40%|███▉      | 1068/2685 [5:53:45<8:46:06, 19.52s/it]

 40%|███▉      | 1069/2685 [5:54:06<8:54:25, 19.84s/it]

 40%|███▉      | 1070/2685 [5:54:20<8:10:44, 18.23s/it]

 40%|███▉      | 1071/2685 [5:54:38<8:04:09, 18.00s/it]

 40%|███▉      | 1072/2685 [5:54:57<8:13:19, 18.35s/it]

 40%|███▉      | 1073/2685 [5:55:17<8:24:55, 18.79s/it]


 40%|████      | 1075/2685 [5:55:54<8:15:41, 18.47s/it]
{'loss': 0.2417, 'learning_rate': 1.3630938600064746e-06, 'rewards/chosen': -1.0565581321716309, 'rewards/rejected': -2.6276261806488037, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5710680484771729, 'policy_logps/rejected': -303.4350280761719, 'policy_logps/chosen': -326.8371887207031, 'referece_logps/rejected': -277.15875244140625, 'referece_logps/chosen': -316.2716064453125, 'logits/rejected': -0.3264724612236023, 'logits/chosen': -0.032121602445840836, 'epoch': 1.2}

 40%|████      | 1076/2685 [5:56:10<7:54:54, 17.71s/it]

 40%|████      | 1077/2685 [5:56:32<8:26:49, 18.91s/it]

 40%|████      | 1078/2685 [5:56:54<8:53:56, 19.94s/it]


 40%|████      | 1080/2685 [5:57:30<8:37:02, 19.33s/it]
{'loss': 0.2955, 'learning_rate': 1.3574667291876047e-06, 'rewards/chosen': -0.39343103766441345, 'rewards/rejected': -2.687910556793213, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2944793701171875, 'policy_logps/rejected': -266.5306396484375, 'policy_logps/chosen': -222.68553161621094, 'referece_logps/rejected': -239.65151977539062, 'referece_logps/chosen': -218.75123596191406, 'logits/rejected': 0.2911698818206787, 'logits/chosen': 0.26238229870796204, 'epoch': 1.21}

 40%|████      | 1081/2685 [5:57:48<8:22:32, 18.80s/it]

 40%|████      | 1082/2685 [5:58:09<8:41:10, 19.51s/it]

 40%|████      | 1083/2685 [5:58:32<9:03:54, 20.37s/it]

 40%|████      | 1084/2685 [5:58:51<8:56:00, 20.09s/it]

 40%|████      | 1085/2685 [5:59:05<8:08:52, 18.33s/it]

 40%|████      | 1086/2685 [5:59:25<8:19:55, 18.76s/it]

 40%|████      | 1087/2685 [5:59:43<8:16:52, 18.66s/it]

 41%|████      | 1088/2685 [6:00:05<8:40:41, 19.56s/it]

 41%|████      | 1089/2685 [6:00:26<8:48:44, 19.88s/it]

 41%|████      | 1090/2685 [6:00:43<8:28:19, 19.12s/it]

 41%|████      | 1091/2685 [6:01:03<8:33:12, 19.32s/it]

 41%|████      | 1092/2685 [6:01:24<8:48:19, 19.90s/it]

 41%|████      | 1093/2685 [6:01:45<8:57:06, 20.24s/it]


 41%|████      | 1095/2685 [6:02:27<9:05:04, 20.57s/it]
{'loss': 0.3292, 'learning_rate': 1.3405081134380264e-06, 'rewards/chosen': -1.1676571369171143, 'rewards/rejected': -3.4492387771606445, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2815818786621094, 'policy_logps/rejected': -357.44287109375, 'policy_logps/chosen': -302.7573547363281, 'referece_logps/rejected': -322.95050048828125, 'referece_logps/chosen': -291.080810546875, 'logits/rejected': -0.6888206005096436, 'logits/chosen': -0.5610958337783813, 'epoch': 1.22}

 41%|████      | 1096/2685 [6:02:45<8:48:41, 19.96s/it]

 41%|████      | 1097/2685 [6:03:07<9:00:14, 20.41s/it]

 41%|████      | 1098/2685 [6:03:26<8:46:45, 19.92s/it]

 41%|████      | 1099/2685 [6:03:45<8:46:59, 19.94s/it]

 41%|████      | 1100/2685 [6:04:09<9:17:30, 21.10s/it]

 41%|████      | 1101/2685 [6:04:29<9:08:07, 20.76s/it]

 41%|████      | 1102/2685 [6:04:50<9:07:59, 20.77s/it]

 41%|████      | 1103/2685 [6:05:11<9:12:15, 20.95s/it]

 41%|████      | 1104/2685 [6:05:30<8:54:15, 20.28s/it]

 41%|████      | 1105/2685 [6:05:54<9:19:40, 21.25s/it]

 41%|████      | 1106/2685 [6:06:12<8:57:46, 20.43s/it]

 41%|████      | 1107/2685 [6:06:33<8:56:50, 20.41s/it]

 41%|████▏     | 1108/2685 [6:06:50<8:29:25, 19.38s/it]

 41%|████▏     | 1109/2685 [6:07:09<8:31:57, 19.49s/it]

 41%|████▏     | 1110/2685 [6:07:32<8:54:15, 20.35s/it]

 41%|████▏     | 1111/2685 [6:07:51<8:48:52, 20.16s/it]

 41%|████▏     | 1112/2685 [6:08:11<8:44:42, 20.01s/it]


 41%|████▏     | 1114/2685 [6:08:51<8:46:00, 20.09s/it]

 42%|████▏     | 1115/2685 [6:09:12<8:54:31, 20.43s/it]

 42%|████▏     | 1116/2685 [6:09:33<8:56:21, 20.51s/it]

 42%|████▏     | 1117/2685 [6:09:52<8:45:26, 20.11s/it]

 42%|████▏     | 1118/2685 [6:10:13<8:46:38, 20.16s/it]

 42%|████▏     | 1119/2685 [6:10:33<8:49:33, 20.29s/it]

 42%|████▏     | 1120/2685 [6:10:55<8:58:52, 20.66s/it]

 42%|████▏     | 1121/2685 [6:11:15<8:53:04, 20.45s/it]

 42%|████▏     | 1122/2685 [6:11:32<8:27:33, 19.48s/it]

 42%|████▏     | 1123/2685 [6:11:53<8:41:40, 20.04s/it]

 42%|████▏     | 1124/2685 [6:12:13<8:37:32, 19.89s/it]

 42%|████▏     | 1125/2685 [6:12:36<9:03:03, 20.89s/it]

 42%|████▏     | 1126/2685 [6:12:56<8:56:13, 20.64s/it]

 42%|████▏     | 1127/2685 [6:13:16<8:49:41, 20.40s/it]

 42%|████▏     | 1128/2685 [6:13:36<8:45:04, 20.23s/it]

 42%|████▏     | 1129/2685 [6:13:56<8:42:32, 20.15s/it]

 42%|████▏     | 1130/2685 [6:14:15<8:32:01, 19.76s/it]

 42%|████▏     | 1131/2685 [6:14:36<8:42:35, 20.18s/it]

 42%|████▏     | 1132/2685 [6:14:56<8:42:56, 20.20s/it]

 42%|████▏     | 1133/2685 [6:15:14<8:24:52, 19.52s/it]

 42%|████▏     | 1134/2685 [6:15:34<8:25:50, 19.57s/it]

 42%|████▏     | 1135/2685 [6:15:51<8:12:16, 19.06s/it]

 42%|████▏     | 1136/2685 [6:16:11<8:18:27, 19.31s/it]

 42%|████▏     | 1137/2685 [6:16:29<8:08:11, 18.92s/it]

 42%|████▏     | 1138/2685 [6:16:51<8:25:09, 19.59s/it]

 42%|████▏     | 1139/2685 [6:17:12<8:37:23, 20.08s/it]

 42%|████▏     | 1140/2685 [6:17:31<8:32:22, 19.90s/it]

 42%|████▏     | 1141/2685 [6:17:53<8:43:14, 20.33s/it]

 43%|████▎     | 1142/2685 [6:18:14<8:53:18, 20.74s/it]

 43%|████▎     | 1143/2685 [6:18:31<8:22:01, 19.53s/it]

 43%|████▎     | 1144/2685 [6:18:48<8:02:25, 18.78s/it]

 43%|████▎     | 1145/2685 [6:19:08<8:10:09, 19.10s/it]

 43%|████▎     | 1146/2685 [6:19:21<7:22:49, 17.26s/it]

 43%|████▎     | 1147/2685 [6:19:43<7:57:52, 18.64s/it]

 43%|████▎     | 1148/2685 [6:20:03<8:07:31, 19.03s/it]

 43%|████▎     | 1149/2685 [6:20:25<8:29:52, 19.92s/it]

 43%|████▎     | 1150/2685 [6:20:42<8:09:35, 19.14s/it]

 43%|████▎     | 1151/2685 [6:20:57<7:40:31, 18.01s/it]

 43%|████▎     | 1152/2685 [6:21:14<7:32:22, 17.71s/it]

 43%|████▎     | 1153/2685 [6:21:33<7:37:50, 17.93s/it]

 43%|████▎     | 1154/2685 [6:21:53<7:51:28, 18.48s/it]

 43%|████▎     | 1155/2685 [6:22:12<8:00:50, 18.86s/it]

 43%|████▎     | 1156/2685 [6:22:32<8:07:14, 19.12s/it]

 43%|████▎     | 1157/2685 [6:22:51<8:07:04, 19.13s/it]

 43%|████▎     | 1158/2685 [6:23:10<8:06:57, 19.13s/it]

 43%|████▎     | 1159/2685 [6:23:31<8:18:12, 19.59s/it]

 43%|████▎     | 1160/2685 [6:23:51<8:24:36, 19.85s/it]

 43%|████▎     | 1161/2685 [6:24:06<7:41:09, 18.16s/it]

 43%|████▎     | 1162/2685 [6:24:22<7:29:43, 17.72s/it]

 43%|████▎     | 1163/2685 [6:24:44<8:01:01, 18.96s/it]

 43%|████▎     | 1164/2685 [6:25:06<8:21:47, 19.79s/it]

 43%|████▎     | 1165/2685 [6:25:26<8:26:03, 19.98s/it]
{'loss': 0.3201, 'learning_rate': 1.2599841965078687e-06, 'rewards/chosen': -1.3731881380081177, 'rewards/rejected': -3.923119068145752, 'rewards/accuracies': 1.0, 'rewards/margins': 2.549931049346924, 'policy_logps/rejected': -384.0111083984375, 'policy_logps/chosen': -351.5125427246094, 'referece_logps/rejected': -344.7799377441406, 'referece_logps/chosen': -337.7806396484375, 'logits/rejected': 0.21029551327228546, 'logits/chosen': 0.30975693464279175, 'epoch': 1.3}


 43%|████▎     | 1167/2685 [6:26:07<8:30:41, 20.19s/it]

 44%|████▎     | 1168/2685 [6:26:24<8:07:24, 19.28s/it]
{'loss': 0.3739, 'learning_rate': 1.2564876138405392e-06, 'rewards/chosen': -1.1714740991592407, 'rewards/rejected': -3.7679810523986816, 'rewards/accuracies': 0.75, 'rewards/margins': 2.5965068340301514, 'policy_logps/rejected': -573.4268798828125, 'policy_logps/chosen': -624.8983764648438, 'referece_logps/rejected': -535.7471313476562, 'referece_logps/chosen': -613.1836547851562, 'logits/rejected': 0.9698815941810608, 'logits/chosen': 0.9718352556228638, 'epoch': 1.31}


 44%|████▎     | 1170/2685 [6:27:04<8:12:33, 19.51s/it]

 44%|████▎     | 1171/2685 [6:27:20<7:44:14, 18.40s/it]

 44%|████▎     | 1172/2685 [6:27:43<8:24:04, 19.99s/it]

 44%|████▎     | 1173/2685 [6:28:02<8:10:01, 19.45s/it]

 44%|████▎     | 1174/2685 [6:28:21<8:13:04, 19.58s/it]
{'loss': 0.293, 'learning_rate': 1.2494844146570158e-06, 'rewards/chosen': -0.8758240342140198, 'rewards/rejected': -4.238361358642578, 'rewards/accuracies': 0.875, 'rewards/margins': 3.3625376224517822, 'policy_logps/rejected': -334.7152099609375, 'policy_logps/chosen': -251.9263916015625, 'referece_logps/rejected': -292.3315734863281, 'referece_logps/chosen': -243.16815185546875, 'logits/rejected': -0.12038633227348328, 'logits/chosen': -0.14202207326889038, 'epoch': 1.31}


 44%|████▍     | 1176/2685 [6:29:05<8:46:46, 20.95s/it]

 44%|████▍     | 1177/2685 [6:29:27<8:53:53, 21.24s/it]

 44%|████▍     | 1178/2685 [6:29:48<8:49:56, 21.10s/it]

 44%|████▍     | 1179/2685 [6:30:06<8:26:33, 20.18s/it]
{'loss': 0.2734, 'learning_rate': 1.2436384137335218e-06, 'rewards/chosen': -1.4645588397979736, 'rewards/rejected': -3.8435020446777344, 'rewards/accuracies': 1.0, 'rewards/margins': 2.37894344329834, 'policy_logps/rejected': -409.82049560546875, 'policy_logps/chosen': -385.66436767578125, 'referece_logps/rejected': -371.385498046875, 'referece_logps/chosen': -371.018798828125, 'logits/rejected': 0.17330294847488403, 'logits/chosen': 0.11734575033187866, 'epoch': 1.32}


 44%|████▍     | 1181/2685 [6:30:46<8:33:42, 20.49s/it]

 44%|████▍     | 1182/2685 [6:31:04<8:15:37, 19.79s/it]

 44%|████▍     | 1183/2685 [6:31:26<8:27:39, 20.28s/it]

 44%|████▍     | 1184/2685 [6:31:44<8:12:04, 19.67s/it]

 44%|████▍     | 1185/2685 [6:32:04<8:10:29, 19.62s/it]
{'loss': 0.3831, 'learning_rate': 1.236611528934562e-06, 'rewards/chosen': -1.8317593336105347, 'rewards/rejected': -4.365813732147217, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5340545177459717, 'policy_logps/rejected': -482.5334777832031, 'policy_logps/chosen': -444.3036193847656, 'referece_logps/rejected': -438.8753662109375, 'referece_logps/chosen': -425.98602294921875, 'logits/rejected': 0.37016454339027405, 'logits/chosen': 0.39573007822036743, 'epoch': 1.32}

 44%|████▍     | 1186/2685 [6:32:25<8:23:59, 20.17s/it]


 44%|████▍     | 1188/2685 [6:33:08<8:42:13, 20.93s/it]

 44%|████▍     | 1189/2685 [6:33:28<8:36:32, 20.72s/it]

 44%|████▍     | 1190/2685 [6:33:48<8:28:42, 20.42s/it]

 44%|████▍     | 1191/2685 [6:34:07<8:16:36, 19.94s/it]

 44%|████▍     | 1192/2685 [6:34:26<8:13:33, 19.83s/it]

 44%|████▍     | 1193/2685 [6:34:44<7:58:54, 19.26s/it]

 44%|████▍     | 1194/2685 [6:35:08<8:31:51, 20.60s/it]

 45%|████▍     | 1195/2685 [6:35:29<8:32:36, 20.64s/it]

 45%|████▍     | 1196/2685 [6:35:43<7:44:42, 18.73s/it]

 45%|████▍     | 1197/2685 [6:36:00<7:32:28, 18.25s/it]
{'loss': 0.2731, 'learning_rate': 1.2225209339563143e-06, 'rewards/chosen': -0.8733166456222534, 'rewards/rejected': -3.3968682289123535, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5235514640808105, 'policy_logps/rejected': -392.90972900390625, 'policy_logps/chosen': -304.4950866699219, 'referece_logps/rejected': -358.9410400390625, 'referece_logps/chosen': -295.76190185546875, 'logits/rejected': 0.049745112657547, 'logits/chosen': 0.004182189702987671, 'epoch': 1.34}


 45%|████▍     | 1199/2685 [6:36:37<7:32:24, 18.27s/it]

 45%|████▍     | 1200/2685 [6:36:57<7:43:14, 18.72s/it]

 45%|████▍     | 1201/2685 [6:37:17<7:53:16, 19.14s/it]

 45%|████▍     | 1202/2685 [6:37:37<8:01:41, 19.49s/it]

 45%|████▍     | 1203/2685 [6:37:56<7:54:33, 19.21s/it]
{'loss': 0.3054, 'learning_rate': 1.2154579621022776e-06, 'rewards/chosen': -1.9352569580078125, 'rewards/rejected': -4.022851467132568, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0875942707061768, 'policy_logps/rejected': -454.27325439453125, 'policy_logps/chosen': -379.7646484375, 'referece_logps/rejected': -414.0447692871094, 'referece_logps/chosen': -360.4120788574219, 'logits/rejected': 0.025320813059806824, 'logits/chosen': 0.029551386833190918, 'epoch': 1.34}


 45%|████▍     | 1205/2685 [6:38:34<7:54:21, 19.23s/it]
{'loss': 0.1838, 'learning_rate': 1.213101111043952e-06, 'rewards/chosen': -1.2091118097305298, 'rewards/rejected': -4.030284881591797, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8211727142333984, 'policy_logps/rejected': -346.25140380859375, 'policy_logps/chosen': -236.1817626953125, 'referece_logps/rejected': -305.94854736328125, 'referece_logps/chosen': -224.0906524658203, 'logits/rejected': -0.4977980852127075, 'logits/chosen': -0.3232618570327759, 'epoch': 1.35}


 45%|████▍     | 1207/2685 [6:39:15<8:13:41, 20.04s/it]

 45%|████▍     | 1208/2685 [6:39:33<7:55:52, 19.33s/it]
{'loss': 0.3149, 'learning_rate': 1.2095635124527487e-06, 'rewards/chosen': -1.1943764686584473, 'rewards/rejected': -3.505876302719116, 'rewards/accuracies': 0.875, 'rewards/margins': 2.311499834060669, 'policy_logps/rejected': -342.56463623046875, 'policy_logps/chosen': -292.7168884277344, 'referece_logps/rejected': -307.505859375, 'referece_logps/chosen': -280.7731018066406, 'logits/rejected': -0.573580265045166, 'logits/chosen': -0.5423626899719238, 'epoch': 1.35}


 45%|████▌     | 1210/2685 [6:40:16<8:22:59, 20.46s/it]

 45%|████▌     | 1211/2685 [6:40:36<8:17:46, 20.26s/it]

 45%|████▌     | 1212/2685 [6:40:56<8:18:13, 20.29s/it]

 45%|████▌     | 1213/2685 [6:41:19<8:34:15, 20.96s/it]
{'loss': 0.2954, 'learning_rate': 1.2036614372361308e-06, 'rewards/chosen': -0.8015223145484924, 'rewards/rejected': -2.8835716247558594, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0820491313934326, 'policy_logps/rejected': -236.48045349121094, 'policy_logps/chosen': -338.7987976074219, 'referece_logps/rejected': -207.64474487304688, 'referece_logps/chosen': -330.7835693359375, 'logits/rejected': -0.24725253880023956, 'logits/chosen': -0.19442325830459595, 'epoch': 1.36}

 45%|████▌     | 1214/2685 [6:41:40<8:33:28, 20.94s/it]

 45%|████▌     | 1215/2685 [6:42:00<8:25:02, 20.61s/it]

 45%|████▌     | 1216/2685 [6:42:20<8:21:47, 20.50s/it]


 45%|████▌     | 1218/2685 [6:43:02<8:28:39, 20.80s/it]
{'loss': 0.3845, 'learning_rate': 1.1977519512162914e-06, 'rewards/chosen': -1.5388059616088867, 'rewards/rejected': -3.7859275341033936, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2471213340759277, 'policy_logps/rejected': -364.343505859375, 'policy_logps/chosen': -368.7539367675781, 'referece_logps/rejected': -326.4842224121094, 'referece_logps/chosen': -353.3658752441406, 'logits/rejected': 0.3288254737854004, 'logits/chosen': 0.4024621844291687, 'epoch': 1.36}


 45%|████▌     | 1220/2685 [6:43:45<8:35:40, 21.12s/it]
{'loss': 0.2659, 'learning_rate': 1.1953861299420834e-06, 'rewards/chosen': -1.2876373529434204, 'rewards/rejected': -3.0049805641174316, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7173433303833008, 'policy_logps/rejected': -291.9639892578125, 'policy_logps/chosen': -294.4269714355469, 'referece_logps/rejected': -261.9141540527344, 'referece_logps/chosen': -281.55059814453125, 'logits/rejected': -0.3428382873535156, 'logits/chosen': -0.384689599275589, 'epoch': 1.36}

 45%|████▌     | 1221/2685 [6:44:05<8:29:40, 20.89s/it]


 46%|████▌     | 1223/2685 [6:44:41<7:49:12, 19.26s/it]
{'loss': 0.3211, 'learning_rate': 1.1918352694267628e-06, 'rewards/chosen': -1.5173370838165283, 'rewards/rejected': -3.051071882247925, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5337347984313965, 'policy_logps/rejected': -255.2449951171875, 'policy_logps/chosen': -204.55618286132812, 'referece_logps/rejected': -224.73428344726562, 'referece_logps/chosen': -189.3828125, 'logits/rejected': -0.9623400568962097, 'logits/chosen': -0.9320729970932007, 'epoch': 1.37}


 46%|████▌     | 1225/2685 [6:45:23<8:06:47, 20.01s/it]
{'loss': 0.3662, 'learning_rate': 1.1894666301129824e-06, 'rewards/chosen': -0.820115327835083, 'rewards/rejected': -3.3549418449401855, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5348265171051025, 'policy_logps/rejected': -381.8700866699219, 'policy_logps/chosen': -349.77325439453125, 'referece_logps/rejected': -348.3206481933594, 'referece_logps/chosen': -341.5721435546875, 'logits/rejected': -0.0011480972170829773, 'logits/chosen': -0.014819130301475525, 'epoch': 1.37}


 46%|████▌     | 1227/2685 [6:46:04<8:12:04, 20.25s/it]

 46%|████▌     | 1228/2685 [6:46:21<7:49:27, 19.33s/it]
{'loss': 0.3662, 'learning_rate': 1.1859116071629147e-06, 'rewards/chosen': -2.1255152225494385, 'rewards/rejected': -4.046277046203613, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9207619428634644, 'policy_logps/rejected': -272.38140869140625, 'policy_logps/chosen': -291.944580078125, 'referece_logps/rejected': -231.9186553955078, 'referece_logps/chosen': -270.68939208984375, 'logits/rejected': 0.03808923810720444, 'logits/chosen': 0.05709993839263916, 'epoch': 1.37}


 46%|████▌     | 1230/2685 [6:47:01<7:57:21, 19.68s/it]

 46%|████▌     | 1231/2685 [6:47:13<7:00:24, 17.35s/it]

 46%|████▌     | 1232/2685 [6:47:35<7:34:02, 18.75s/it]

 46%|████▌     | 1233/2685 [6:47:56<7:53:21, 19.56s/it]

 46%|████▌     | 1234/2685 [6:48:16<7:56:31, 19.70s/it]
{'loss': 0.3468, 'learning_rate': 1.178794301731132e-06, 'rewards/chosen': -0.8906171321868896, 'rewards/rejected': -3.217613458633423, 'rewards/accuracies': 0.75, 'rewards/margins': 2.326996088027954, 'policy_logps/rejected': -368.81884765625, 'policy_logps/chosen': -310.679931640625, 'referece_logps/rejected': -336.6427001953125, 'referece_logps/chosen': -301.77374267578125, 'logits/rejected': 0.5484423041343689, 'logits/chosen': 0.5972086191177368, 'epoch': 1.38}

 46%|████▌     | 1235/2685 [6:48:36<7:55:42, 19.68s/it]


 46%|████▌     | 1237/2685 [6:49:18<8:09:20, 20.28s/it]
{'loss': 0.4385, 'learning_rate': 1.1752321124836545e-06, 'rewards/chosen': -0.6183130145072937, 'rewards/rejected': -3.0733890533447266, 'rewards/accuracies': 0.875, 'rewards/margins': 2.455075979232788, 'policy_logps/rejected': -374.3515930175781, 'policy_logps/chosen': -413.5035705566406, 'referece_logps/rejected': -343.6177062988281, 'referece_logps/chosen': -407.3204650878906, 'logits/rejected': -0.8080357313156128, 'logits/chosen': -0.8650736212730408, 'epoch': 1.38}

 46%|████▌     | 1238/2685 [6:49:34<7:40:23, 19.09s/it]

 46%|████▌     | 1239/2685 [6:49:58<8:15:39, 20.57s/it]


 46%|████▌     | 1241/2685 [6:50:33<7:29:30, 18.68s/it]
{'loss': 0.3243, 'learning_rate': 1.1704789641432794e-06, 'rewards/chosen': -1.3312065601348877, 'rewards/rejected': -4.5936198234558105, 'rewards/accuracies': 0.875, 'rewards/margins': 3.262413263320923, 'policy_logps/rejected': -374.4756774902344, 'policy_logps/chosen': -325.79327392578125, 'referece_logps/rejected': -328.5394592285156, 'referece_logps/chosen': -312.4812316894531, 'logits/rejected': -0.1511220932006836, 'logits/chosen': -0.16768115758895874, 'epoch': 1.39}


 46%|████▋     | 1243/2685 [6:51:15<8:03:43, 20.13s/it]

 46%|████▋     | 1244/2685 [6:51:37<8:15:21, 20.63s/it]

 46%|████▋     | 1245/2685 [6:51:57<8:11:20, 20.47s/it]

 46%|████▋     | 1246/2685 [6:52:18<8:13:27, 20.57s/it]

 46%|████▋     | 1247/2685 [6:52:38<8:07:15, 20.33s/it]

 46%|████▋     | 1248/2685 [6:52:59<8:13:44, 20.62s/it]
{'loss': 0.3212, 'learning_rate': 1.1621514679971057e-06, 'rewards/chosen': -0.6517449617385864, 'rewards/rejected': -3.205482244491577, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5537374019622803, 'policy_logps/rejected': -306.21063232421875, 'policy_logps/chosen': -299.3895568847656, 'referece_logps/rejected': -274.15582275390625, 'referece_logps/chosen': -292.87213134765625, 'logits/rejected': -0.3813115954399109, 'logits/chosen': -0.26123374700546265, 'epoch': 1.39}


 47%|████▋     | 1250/2685 [6:53:34<7:28:13, 18.74s/it]

 47%|████▋     | 1251/2685 [6:53:55<7:45:04, 19.46s/it]

 47%|████▋     | 1252/2685 [6:54:15<7:48:21, 19.61s/it]
{'loss': 0.3396, 'learning_rate': 1.157387668354454e-06, 'rewards/chosen': -1.8890762329101562, 'rewards/rejected': -4.364481449127197, 'rewards/accuracies': 1.0, 'rewards/margins': 2.475404739379883, 'policy_logps/rejected': -499.84942626953125, 'policy_logps/chosen': -443.6570739746094, 'referece_logps/rejected': -456.20458984375, 'referece_logps/chosen': -424.76629638671875, 'logits/rejected': -0.25387948751449585, 'logits/chosen': -0.2809443771839142, 'epoch': 1.4}

 47%|████▋     | 1253/2685 [6:54:32<7:33:40, 19.01s/it]


 47%|████▋     | 1255/2685 [6:55:11<7:37:14, 19.19s/it]

 47%|████▋     | 1256/2685 [6:55:29<7:27:41, 18.80s/it]
{'loss': 0.1723, 'learning_rate': 1.1526202034278373e-06, 'rewards/chosen': -0.9109471440315247, 'rewards/rejected': -5.116408348083496, 'rewards/accuracies': 1.0, 'rewards/margins': 4.205461025238037, 'policy_logps/rejected': -412.1050109863281, 'policy_logps/chosen': -334.27374267578125, 'referece_logps/rejected': -360.9409484863281, 'referece_logps/chosen': -325.164306640625, 'logits/rejected': -0.34393060207366943, 'logits/chosen': -0.32836008071899414, 'epoch': 1.4}

 47%|████▋     | 1257/2685 [6:55:50<7:45:45, 19.57s/it]


 47%|████▋     | 1259/2685 [6:56:36<8:18:42, 20.98s/it]
{'loss': 0.3027, 'learning_rate': 1.1490422661761743e-06, 'rewards/chosen': -0.6696817278862, 'rewards/rejected': -3.6617424488067627, 'rewards/accuracies': 1.0, 'rewards/margins': 2.992060661315918, 'policy_logps/rejected': -388.38055419921875, 'policy_logps/chosen': -353.27288818359375, 'referece_logps/rejected': -351.7631530761719, 'referece_logps/chosen': -346.5760498046875, 'logits/rejected': 0.9259933829307556, 'logits/chosen': 0.9056531190872192, 'epoch': 1.41}


 47%|████▋     | 1261/2685 [6:57:21<8:37:43, 21.81s/it]

 47%|████▋     | 1262/2685 [6:57:41<8:27:23, 21.39s/it]

 47%|████▋     | 1263/2685 [6:58:04<8:35:22, 21.75s/it]
{'loss': 0.2522, 'learning_rate': 1.1442686542086609e-06, 'rewards/chosen': -2.054577112197876, 'rewards/rejected': -5.171359539031982, 'rewards/accuracies': 0.875, 'rewards/margins': 3.1167821884155273, 'policy_logps/rejected': -409.0071105957031, 'policy_logps/chosen': -431.5623779296875, 'referece_logps/rejected': -357.29351806640625, 'referece_logps/chosen': -411.0166015625, 'logits/rejected': 0.2580243945121765, 'logits/chosen': 0.24218107759952545, 'epoch': 1.41}


 47%|████▋     | 1265/2685 [6:58:44<8:08:35, 20.64s/it]

 47%|████▋     | 1266/2685 [6:59:04<8:08:17, 20.65s/it]

 47%|████▋     | 1267/2685 [6:59:22<7:50:02, 19.89s/it]

 47%|████▋     | 1268/2685 [6:59:38<7:19:12, 18.60s/it]
{'loss': 0.2942, 'learning_rate': 1.1382969276148036e-06, 'rewards/chosen': -1.2708909511566162, 'rewards/rejected': -3.494068145751953, 'rewards/accuracies': 0.875, 'rewards/margins': 2.223177194595337, 'policy_logps/rejected': -412.6202697753906, 'policy_logps/chosen': -365.6378173828125, 'referece_logps/rejected': -377.6795959472656, 'referece_logps/chosen': -352.9289245605469, 'logits/rejected': -0.2883446216583252, 'logits/chosen': -0.25791865587234497, 'epoch': 1.42}


 47%|████▋     | 1270/2685 [7:00:06<6:27:35, 16.43s/it]

 47%|████▋     | 1271/2685 [7:00:28<7:07:46, 18.15s/it]

 47%|████▋     | 1272/2685 [7:00:48<7:21:22, 18.74s/it]

 47%|████▋     | 1273/2685 [7:01:06<7:18:24, 18.63s/it]

 47%|████▋     | 1274/2685 [7:01:26<7:26:10, 18.97s/it]
{'loss': 0.3971, 'learning_rate': 1.1311242321633891e-06, 'rewards/chosen': -1.4056943655014038, 'rewards/rejected': -3.1806488037109375, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7749541997909546, 'policy_logps/rejected': -420.4195861816406, 'policy_logps/chosen': -522.6211547851562, 'referece_logps/rejected': -388.6131286621094, 'referece_logps/chosen': -508.5642395019531, 'logits/rejected': 0.8079403638839722, 'logits/chosen': 0.7736189365386963, 'epoch': 1.42}

 47%|████▋     | 1275/2685 [7:01:49<7:52:18, 20.10s/it]

 48%|████▊     | 1276/2685 [7:02:09<7:51:42, 20.09s/it]

 48%|████▊     | 1277/2685 [7:02:27<7:37:00, 19.47s/it]


 48%|████▊     | 1279/2685 [7:03:06<7:41:42, 19.70s/it]
{'loss': 0.3313, 'learning_rate': 1.1251417215372345e-06, 'rewards/chosen': -1.1992790699005127, 'rewards/rejected': -3.292846918106079, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0935678482055664, 'policy_logps/rejected': -483.0513916015625, 'policy_logps/chosen': -332.9209899902344, 'referece_logps/rejected': -450.1229553222656, 'referece_logps/chosen': -320.9281921386719, 'logits/rejected': -0.482370525598526, 'logits/chosen': -0.39049893617630005, 'epoch': 1.43}


 48%|████▊     | 1281/2685 [7:03:48<7:53:59, 20.26s/it]

 48%|████▊     | 1282/2685 [7:04:10<8:05:27, 20.76s/it]

 48%|████▊     | 1283/2685 [7:04:30<8:03:34, 20.69s/it]

 48%|████▊     | 1284/2685 [7:04:50<7:57:41, 20.46s/it]

 48%|████▊     | 1285/2685 [7:05:10<7:52:37, 20.26s/it]
{'loss': 0.2664, 'learning_rate': 1.1179567171508461e-06, 'rewards/chosen': -1.1747803688049316, 'rewards/rejected': -3.484175682067871, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3093950748443604, 'policy_logps/rejected': -499.19940185546875, 'policy_logps/chosen': -413.86358642578125, 'referece_logps/rejected': -464.3576354980469, 'referece_logps/chosen': -402.1157531738281, 'logits/rejected': 0.2511816620826721, 'logits/chosen': 0.20164000988006592, 'epoch': 1.44}

 48%|████▊     | 1286/2685 [7:05:27<7:31:16, 19.35s/it]


 48%|████▊     | 1288/2685 [7:06:12<8:02:42, 20.73s/it]
{'loss': 0.254, 'learning_rate': 1.1143618736339177e-06, 'rewards/chosen': -1.389366865158081, 'rewards/rejected': -4.910701751708984, 'rewards/accuracies': 0.875, 'rewards/margins': 3.5213348865509033, 'policy_logps/rejected': -449.1518859863281, 'policy_logps/chosen': -264.5269470214844, 'referece_logps/rejected': -400.04486083984375, 'referece_logps/chosen': -250.63327026367188, 'logits/rejected': 0.563239336013794, 'logits/chosen': 0.5192776322364807, 'epoch': 1.44}


 48%|████▊     | 1290/2685 [7:06:52<7:53:03, 20.35s/it]
{'loss': 0.2558, 'learning_rate': 1.1119644761033077e-06, 'rewards/chosen': -1.1863811016082764, 'rewards/rejected': -3.4398670196533203, 'rewards/accuracies': 1.0, 'rewards/margins': 2.253485918045044, 'policy_logps/rejected': -300.5661315917969, 'policy_logps/chosen': -209.3943634033203, 'referece_logps/rejected': -266.1674499511719, 'referece_logps/chosen': -197.5305633544922, 'logits/rejected': -0.6772960424423218, 'logits/chosen': -0.48535865545272827, 'epoch': 1.44}

 48%|████▊     | 1291/2685 [7:07:10<7:32:39, 19.48s/it]

 48%|████▊     | 1292/2685 [7:07:31<7:47:25, 20.13s/it]


 48%|████▊     | 1294/2685 [7:08:13<7:54:17, 20.46s/it]
{'loss': 0.2346, 'learning_rate': 1.107167739408006e-06, 'rewards/chosen': -0.04324650019407272, 'rewards/rejected': -3.463672637939453, 'rewards/accuracies': 0.875, 'rewards/margins': 3.4204261302948, 'policy_logps/rejected': -302.11480712890625, 'policy_logps/chosen': -275.43218994140625, 'referece_logps/rejected': -267.47808837890625, 'referece_logps/chosen': -274.999755859375, 'logits/rejected': -0.3292590379714966, 'logits/chosen': -0.4568001627922058, 'epoch': 1.45}


 48%|████▊     | 1296/2685 [7:08:59<8:24:34, 21.80s/it]

 48%|████▊     | 1297/2685 [7:09:20<8:23:03, 21.75s/it]

 48%|████▊     | 1298/2685 [7:09:42<8:23:25, 21.78s/it]
{'loss': 0.3667, 'learning_rate': 1.1023685069631897e-06, 'rewards/chosen': -0.9187606573104858, 'rewards/rejected': -4.18839693069458, 'rewards/accuracies': 1.0, 'rewards/margins': 3.2696361541748047, 'policy_logps/rejected': -564.35546875, 'policy_logps/chosen': -400.5202331542969, 'referece_logps/rejected': -522.471435546875, 'referece_logps/chosen': -391.3326416015625, 'logits/rejected': 0.19132235646247864, 'logits/chosen': 0.1566384732723236, 'epoch': 1.45}

 48%|████▊     | 1299/2685 [7:10:04<8:21:43, 21.72s/it]

 48%|████▊     | 1300/2685 [7:10:24<8:07:35, 21.12s/it]

 48%|████▊     | 1301/2685 [7:10:44<7:59:22, 20.78s/it]


 49%|████▊     | 1303/2685 [7:11:13<6:52:25, 17.91s/it]
{'loss': 0.3286, 'learning_rate': 1.096366127032863e-06, 'rewards/chosen': -2.41409969329834, 'rewards/rejected': -3.5720067024230957, 'rewards/accuracies': 0.5, 'rewards/margins': 1.1579067707061768, 'policy_logps/rejected': -330.005859375, 'policy_logps/chosen': -396.1412048339844, 'referece_logps/rejected': -294.28582763671875, 'referece_logps/chosen': -372.000244140625, 'logits/rejected': 0.16409948468208313, 'logits/chosen': 0.19745439291000366, 'epoch': 1.46}


 49%|████▊     | 1305/2685 [7:11:55<7:24:48, 19.34s/it]
{'loss': 0.2633, 'learning_rate': 1.0939641809892766e-06, 'rewards/chosen': -0.8942626714706421, 'rewards/rejected': -4.684899806976318, 'rewards/accuracies': 1.0, 'rewards/margins': 3.7906370162963867, 'policy_logps/rejected': -520.9398803710938, 'policy_logps/chosen': -459.2642822265625, 'referece_logps/rejected': -474.09088134765625, 'referece_logps/chosen': -450.3216552734375, 'logits/rejected': 0.10691985487937927, 'logits/chosen': 0.03767712414264679, 'epoch': 1.46}

 49%|████▊     | 1306/2685 [7:12:16<7:36:10, 19.85s/it]

 49%|████▊     | 1307/2685 [7:12:38<7:55:55, 20.72s/it]


 49%|████▉     | 1309/2685 [7:13:15<7:29:26, 19.60s/it]

 49%|████▉     | 1310/2685 [7:13:37<7:46:14, 20.34s/it]

 49%|████▉     | 1311/2685 [7:13:57<7:40:34, 20.11s/it]
{'loss': 0.3833, 'learning_rate': 1.086755116414252e-06, 'rewards/chosen': -0.8160382509231567, 'rewards/rejected': -3.8133420944213867, 'rewards/accuracies': 0.875, 'rewards/margins': 2.9973039627075195, 'policy_logps/rejected': -241.474609375, 'policy_logps/chosen': -196.62393188476562, 'referece_logps/rejected': -203.3411865234375, 'referece_logps/chosen': -188.46351623535156, 'logits/rejected': -0.4452323019504547, 'logits/chosen': -0.18107308447360992, 'epoch': 1.46}


 49%|████▉     | 1313/2685 [7:14:43<8:15:58, 21.69s/it]

 49%|████▉     | 1314/2685 [7:15:03<8:04:33, 21.21s/it]

 49%|████▉     | 1315/2685 [7:15:23<7:53:23, 20.73s/it]

 49%|████▉     | 1316/2685 [7:15:43<7:48:37, 20.54s/it]

 49%|████▉     | 1317/2685 [7:16:03<7:43:47, 20.34s/it]

 49%|████▉     | 1318/2685 [7:16:27<8:08:00, 21.42s/it]
{'loss': 0.3308, 'learning_rate': 1.0783388221858724e-06, 'rewards/chosen': -0.21146580576896667, 'rewards/rejected': -2.7308270931243896, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5193610191345215, 'policy_logps/rejected': -234.58349609375, 'policy_logps/chosen': -196.35760498046875, 'referece_logps/rejected': -207.27523803710938, 'referece_logps/chosen': -194.242919921875, 'logits/rejected': -0.86747807264328, 'logits/chosen': -0.8186344504356384, 'epoch': 1.47}

 49%|████▉     | 1319/2685 [7:16:49<8:09:35, 21.50s/it]

 49%|████▉     | 1320/2685 [7:17:08<7:57:45, 21.00s/it]

 49%|████▉     | 1321/2685 [7:17:28<7:49:58, 20.67s/it]


 49%|████▉     | 1323/2685 [7:18:13<8:09:46, 21.58s/it]

 49%|████▉     | 1324/2685 [7:18:32<7:48:22, 20.65s/it]

 49%|████▉     | 1325/2685 [7:18:51<7:41:19, 20.35s/it]

 49%|████▉     | 1326/2685 [7:19:13<7:50:04, 20.75s/it]
{'loss': 0.3856, 'learning_rate': 1.0687133938526602e-06, 'rewards/chosen': -1.7955607175827026, 'rewards/rejected': -3.095567226409912, 'rewards/accuracies': 0.625, 'rewards/margins': 1.300006628036499, 'policy_logps/rejected': -434.37347412109375, 'policy_logps/chosen': -413.1864929199219, 'referece_logps/rejected': -403.41778564453125, 'referece_logps/chosen': -395.2308654785156, 'logits/rejected': 0.3136957287788391, 'logits/chosen': 0.33185693621635437, 'epoch': 1.48}


 49%|████▉     | 1328/2685 [7:19:57<8:03:20, 21.37s/it]
{'loss': 0.3432, 'learning_rate': 1.066306001602384e-06, 'rewards/chosen': -1.6064025163650513, 'rewards/rejected': -3.9503185749053955, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3439157009124756, 'policy_logps/rejected': -482.2549133300781, 'policy_logps/chosen': -397.2278137207031, 'referece_logps/rejected': -442.75177001953125, 'referece_logps/chosen': -381.16375732421875, 'logits/rejected': -0.03910943120718002, 'logits/chosen': -0.07088087499141693, 'epoch': 1.48}

 49%|████▉     | 1329/2685 [7:20:14<7:31:30, 19.98s/it]

 50%|████▉     | 1330/2685 [7:20:36<7:44:28, 20.57s/it]

 50%|████▉     | 1331/2685 [7:20:56<7:41:23, 20.45s/it]

 50%|████▉     | 1332/2685 [7:21:16<7:39:31, 20.38s/it]

 50%|████▉     | 1333/2685 [7:21:36<7:34:51, 20.19s/it]

 50%|████▉     | 1334/2685 [7:21:55<7:23:58, 19.72s/it]

 50%|████▉     | 1335/2685 [7:22:16<7:37:11, 20.32s/it]

 50%|████▉     | 1336/2685 [7:22:39<7:50:27, 20.92s/it]


 50%|████▉     | 1338/2685 [7:23:19<7:43:23, 20.64s/it]
{'loss': 0.2345, 'learning_rate': 1.0542635301735156e-06, 'rewards/chosen': -0.9645513296127319, 'rewards/rejected': -3.0993504524230957, 'rewards/accuracies': 0.875, 'rewards/margins': 2.134799003601074, 'policy_logps/rejected': -379.61041259765625, 'policy_logps/chosen': -369.5501708984375, 'referece_logps/rejected': -348.6169128417969, 'referece_logps/chosen': -359.9046325683594, 'logits/rejected': 0.0833168476819992, 'logits/chosen': -0.012910149991512299, 'epoch': 1.49}

 50%|████▉     | 1339/2685 [7:23:38<7:33:00, 20.19s/it]


 50%|████▉     | 1341/2685 [7:24:20<7:41:11, 20.59s/it]
{'loss': 0.3186, 'learning_rate': 1.0506491688387128e-06, 'rewards/chosen': -1.0635616779327393, 'rewards/rejected': -3.393397092819214, 'rewards/accuracies': 0.875, 'rewards/margins': 2.329835891723633, 'policy_logps/rejected': -232.393798828125, 'policy_logps/chosen': -271.1365966796875, 'referece_logps/rejected': -198.45982360839844, 'referece_logps/chosen': -260.5010070800781, 'logits/rejected': -0.567053496837616, 'logits/chosen': -0.6656673550605774, 'epoch': 1.5}


 50%|█████     | 1343/2685 [7:25:00<7:34:04, 20.30s/it]
{'loss': 0.271, 'learning_rate': 1.0482392230888432e-06, 'rewards/chosen': -1.3455625772476196, 'rewards/rejected': -3.001349449157715, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6557868719100952, 'policy_logps/rejected': -222.35296630859375, 'policy_logps/chosen': -176.92845153808594, 'referece_logps/rejected': -192.3394775390625, 'referece_logps/chosen': -163.47280883789062, 'logits/rejected': -0.9364548921585083, 'logits/chosen': -1.0705724954605103, 'epoch': 1.5}

 50%|█████     | 1344/2685 [7:25:17<7:14:13, 19.43s/it]


 50%|█████     | 1346/2685 [7:25:57<7:18:25, 19.65s/it]
{'loss': 0.2671, 'learning_rate': 1.0446237822512128e-06, 'rewards/chosen': -1.5132356882095337, 'rewards/rejected': -3.054755449295044, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5415198802947998, 'policy_logps/rejected': -394.6108093261719, 'policy_logps/chosen': -319.2644348144531, 'referece_logps/rejected': -364.06329345703125, 'referece_logps/chosen': -304.132080078125, 'logits/rejected': 0.1718055009841919, 'logits/chosen': 0.18597853183746338, 'epoch': 1.5}

 50%|█████     | 1347/2685 [7:26:18<7:26:08, 20.01s/it]

 50%|█████     | 1348/2685 [7:26:37<7:17:18, 19.62s/it]

 50%|█████     | 1349/2685 [7:26:59<7:30:35, 20.24s/it]

 50%|█████     | 1350/2685 [7:27:18<7:26:33, 20.07s/it]


 50%|█████     | 1352/2685 [7:28:02<7:43:50, 20.88s/it]
{'loss': 0.386, 'learning_rate': 1.037391194276326e-06, 'rewards/chosen': -1.2533142566680908, 'rewards/rejected': -3.984410285949707, 'rewards/accuracies': 0.875, 'rewards/margins': 2.731096029281616, 'policy_logps/rejected': -460.4527587890625, 'policy_logps/chosen': -434.0589599609375, 'referece_logps/rejected': -420.608642578125, 'referece_logps/chosen': -421.52581787109375, 'logits/rejected': 0.4918610155582428, 'logits/chosen': 0.3744213879108429, 'epoch': 1.51}

 50%|█████     | 1353/2685 [7:28:19<7:16:23, 19.66s/it]

 50%|█████     | 1354/2685 [7:28:35<6:51:29, 18.55s/it]

 50%|█████     | 1355/2685 [7:28:56<7:12:57, 19.53s/it]


 51%|█████     | 1357/2685 [7:29:36<7:14:47, 19.64s/it]

 51%|█████     | 1358/2685 [7:29:58<7:30:26, 20.37s/it]

 51%|█████     | 1359/2685 [7:30:18<7:28:37, 20.30s/it]
{'loss': 0.2966, 'learning_rate': 1.0289507253262357e-06, 'rewards/chosen': -2.1767306327819824, 'rewards/rejected': -3.7724356651306152, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5957049131393433, 'policy_logps/rejected': -347.5956115722656, 'policy_logps/chosen': -368.0376281738281, 'referece_logps/rejected': -309.8713073730469, 'referece_logps/chosen': -346.27032470703125, 'logits/rejected': -0.18038249015808105, 'logits/chosen': -0.22132010757923126, 'epoch': 1.52}


 51%|█████     | 1361/2685 [7:31:00<7:36:27, 20.69s/it]

 51%|█████     | 1362/2685 [7:31:22<7:46:24, 21.15s/it]

 51%|█████     | 1363/2685 [7:31:40<7:23:55, 20.15s/it]
{'loss': 0.2763, 'learning_rate': 1.0241266345571644e-06, 'rewards/chosen': -0.792792797088623, 'rewards/rejected': -3.26957106590271, 'rewards/accuracies': 1.0, 'rewards/margins': 2.476778268814087, 'policy_logps/rejected': -332.54608154296875, 'policy_logps/chosen': -311.99395751953125, 'referece_logps/rejected': -299.8503723144531, 'referece_logps/chosen': -304.0660095214844, 'logits/rejected': -0.051224932074546814, 'logits/chosen': -0.072220578789711, 'epoch': 1.52}

 51%|█████     | 1364/2685 [7:32:03<7:44:16, 21.09s/it]

 51%|█████     | 1365/2685 [7:32:24<7:37:15, 20.78s/it]


 51%|█████     | 1367/2685 [7:33:00<7:08:16, 19.50s/it]

 51%|█████     | 1368/2685 [7:33:19<6:59:20, 19.10s/it]
{'loss': 0.2829, 'learning_rate': 1.018095744136763e-06, 'rewards/chosen': -1.1749844551086426, 'rewards/rejected': -4.1455979347229, 'rewards/accuracies': 1.0, 'rewards/margins': 2.9706132411956787, 'policy_logps/rejected': -401.45001220703125, 'policy_logps/chosen': -335.4278564453125, 'referece_logps/rejected': -359.9939880371094, 'referece_logps/chosen': -323.6780090332031, 'logits/rejected': 0.2712244391441345, 'logits/chosen': 0.18498361110687256, 'epoch': 1.53}


 51%|█████     | 1370/2685 [7:33:58<7:07:37, 19.51s/it]
{'loss': 0.2932, 'learning_rate': 1.0156831913081482e-06, 'rewards/chosen': -2.8904953002929688, 'rewards/rejected': -5.61934232711792, 'rewards/accuracies': 0.75, 'rewards/margins': 2.728846788406372, 'policy_logps/rejected': -407.40283203125, 'policy_logps/chosen': -319.10235595703125, 'referece_logps/rejected': -351.2094421386719, 'referece_logps/chosen': -290.1973876953125, 'logits/rejected': -0.5305396914482117, 'logits/chosen': -0.5026221871376038, 'epoch': 1.53}

 51%|█████     | 1371/2685 [7:34:15<6:48:40, 18.66s/it]

 51%|█████     | 1372/2685 [7:34:35<6:57:54, 19.10s/it]


 51%|█████     | 1374/2685 [7:35:12<6:52:42, 18.89s/it]
{'loss': 0.2809, 'learning_rate': 1.0108578257715034e-06, 'rewards/chosen': -1.8114949464797974, 'rewards/rejected': -3.940910816192627, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1294162273406982, 'policy_logps/rejected': -264.0853271484375, 'policy_logps/chosen': -168.27093505859375, 'referece_logps/rejected': -224.67620849609375, 'referece_logps/chosen': -150.15599060058594, 'logits/rejected': -0.22801923751831055, 'logits/chosen': -0.6403990983963013, 'epoch': 1.54}

 51%|█████     | 1375/2685 [7:35:33<7:03:44, 19.41s/it]


 51%|█████▏    | 1377/2685 [7:36:08<6:44:15, 18.54s/it]
{'loss': 0.3819, 'learning_rate': 1.0072386295340571e-06, 'rewards/chosen': -3.2327308654785156, 'rewards/rejected': -6.038025856018066, 'rewards/accuracies': 0.75, 'rewards/margins': 2.80529522895813, 'policy_logps/rejected': -440.21795654296875, 'policy_logps/chosen': -421.4698791503906, 'referece_logps/rejected': -379.8377380371094, 'referece_logps/chosen': -389.1426086425781, 'logits/rejected': -0.40830540657043457, 'logits/chosen': -0.50059974193573, 'epoch': 1.54}

 51%|█████▏    | 1378/2685 [7:36:29<6:55:50, 19.09s/it]

 51%|█████▏    | 1379/2685 [7:36:45<6:39:27, 18.35s/it]

 51%|█████▏    | 1380/2685 [7:37:04<6:39:33, 18.37s/it]


 51%|█████▏    | 1382/2685 [7:37:43<6:50:04, 18.88s/it]
{'loss': 0.3726, 'learning_rate': 1.001206448499033e-06, 'rewards/chosen': -0.7531448602676392, 'rewards/rejected': -2.5271952152252197, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7740503549575806, 'policy_logps/rejected': -259.729248046875, 'policy_logps/chosen': -220.10232543945312, 'referece_logps/rejected': -234.4573211669922, 'referece_logps/chosen': -212.57089233398438, 'logits/rejected': -0.18098007142543793, 'logits/chosen': -0.36281269788742065, 'epoch': 1.54}

 52%|█████▏    | 1383/2685 [7:38:01<6:46:43, 18.74s/it]

 52%|█████▏    | 1384/2685 [7:38:21<6:53:03, 19.05s/it]


 52%|█████▏    | 1386/2685 [7:38:59<6:50:55, 18.98s/it]
{'loss': 0.2783, 'learning_rate': 9.96380661526931e-07, 'rewards/chosen': -2.3077356815338135, 'rewards/rejected': -3.533510208129883, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2257740497589111, 'policy_logps/rejected': -319.0318298339844, 'policy_logps/chosen': -267.6459045410156, 'referece_logps/rejected': -283.6967468261719, 'referece_logps/chosen': -244.56854248046875, 'logits/rejected': 0.008336231112480164, 'logits/chosen': -0.08542503416538239, 'epoch': 1.55}

 52%|█████▏    | 1387/2685 [7:39:17<6:48:36, 18.89s/it]

 52%|█████▏    | 1388/2685 [7:39:30<6:10:41, 17.15s/it]

 52%|█████▏    | 1389/2685 [7:39:52<6:41:11, 18.57s/it]

 52%|█████▏    | 1390/2685 [7:40:12<6:47:53, 18.90s/it]

 52%|█████▏    | 1391/2685 [7:40:30<6:44:34, 18.76s/it]

 52%|█████▏    | 1392/2685 [7:40:50<6:52:39, 19.15s/it]

 52%|█████▏    | 1393/2685 [7:41:13<7:16:38, 20.28s/it]

 52%|█████▏    | 1394/2685 [7:41:33<7:09:17, 19.95s/it]

 52%|█████▏    | 1395/2685 [7:41:50<6:54:41, 19.29s/it]


 52%|█████▏    | 1397/2685 [7:42:29<6:52:33, 19.22s/it]
{'loss': 0.3081, 'learning_rate': 9.83110519986069e-07, 'rewards/chosen': -1.9783501625061035, 'rewards/rejected': -3.678287982940674, 'rewards/accuracies': 0.625, 'rewards/margins': 1.6999375820159912, 'policy_logps/rejected': -416.24737548828125, 'policy_logps/chosen': -372.83673095703125, 'referece_logps/rejected': -379.4644470214844, 'referece_logps/chosen': -353.0532531738281, 'logits/rejected': -0.2692584991455078, 'logits/chosen': -0.32828378677368164, 'epoch': 1.56}

 52%|█████▏    | 1398/2685 [7:42:48<6:54:33, 19.33s/it]

 52%|█████▏    | 1399/2685 [7:43:09<7:01:22, 19.66s/it]

 52%|█████▏    | 1400/2685 [7:43:29<7:01:52, 19.70s/it]

 52%|█████▏    | 1401/2685 [7:43:49<7:04:18, 19.83s/it]

 52%|█████▏    | 1402/2685 [7:44:10<7:15:11, 20.35s/it]


 52%|█████▏    | 1404/2685 [7:44:43<6:26:28, 18.10s/it]
{'loss': 0.435, 'learning_rate': 9.746672856868122e-07, 'rewards/chosen': -1.7555311918258667, 'rewards/rejected': -2.604673147201538, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8491418361663818, 'policy_logps/rejected': -384.3082580566406, 'policy_logps/chosen': -321.4012451171875, 'referece_logps/rejected': -358.2615051269531, 'referece_logps/chosen': -303.845947265625, 'logits/rejected': -0.06052301451563835, 'logits/chosen': -0.09523787349462509, 'epoch': 1.57}

 52%|█████▏    | 1405/2685 [7:45:04<6:46:49, 19.07s/it]

 52%|█████▏    | 1406/2685 [7:45:23<6:43:48, 18.94s/it]

 52%|█████▏    | 1407/2685 [7:45:41<6:36:26, 18.61s/it]

 52%|█████▏    | 1408/2685 [7:46:02<6:51:50, 19.35s/it]

 52%|█████▏    | 1409/2685 [7:46:22<6:58:14, 19.67s/it]

 53%|█████▎    | 1410/2685 [7:46:43<7:03:06, 19.91s/it]

 53%|█████▎    | 1411/2685 [7:47:06<7:21:25, 20.79s/it]


 53%|█████▎    | 1413/2685 [7:47:41<6:51:50, 19.43s/it]

 53%|█████▎    | 1414/2685 [7:48:01<6:57:00, 19.69s/it]

 53%|█████▎    | 1415/2685 [7:48:19<6:44:17, 19.10s/it]
{'loss': 0.2048, 'learning_rate': 9.614032281000874e-07, 'rewards/chosen': -1.3074121475219727, 'rewards/rejected': -4.7994465827941895, 'rewards/accuracies': 1.0, 'rewards/margins': 3.492034912109375, 'policy_logps/rejected': -313.33648681640625, 'policy_logps/chosen': -316.27020263671875, 'referece_logps/rejected': -265.342041015625, 'referece_logps/chosen': -303.1960754394531, 'logits/rejected': -0.2626495957374573, 'logits/chosen': -0.2762477993965149, 'epoch': 1.58}

 53%|█████▎    | 1416/2685 [7:48:40<6:54:40, 19.61s/it]

 53%|█████▎    | 1417/2685 [7:49:00<6:58:20, 19.80s/it]

 53%|█████▎    | 1418/2685 [7:49:22<7:10:54, 20.41s/it]

 53%|█████▎    | 1419/2685 [7:49:43<7:15:00, 20.62s/it]

 53%|█████▎    | 1420/2685 [7:50:02<7:05:14, 20.17s/it]

 53%|█████▎    | 1421/2685 [7:50:22<7:02:43, 20.07s/it]

 53%|█████▎    | 1422/2685 [7:50:43<7:04:39, 20.17s/it]

 53%|█████▎    | 1423/2685 [7:51:04<7:12:41, 20.57s/it]

 53%|█████▎    | 1424/2685 [7:51:22<6:57:20, 19.86s/it]

 53%|█████▎    | 1425/2685 [7:51:45<7:13:04, 20.62s/it]

 53%|█████▎    | 1426/2685 [7:52:04<7:06:24, 20.32s/it]


 53%|█████▎    | 1428/2685 [7:52:40<6:38:57, 19.04s/it]
{'loss': 0.2485, 'learning_rate': 9.457364698264846e-07, 'rewards/chosen': -1.8006203174591064, 'rewards/rejected': -3.707862615585327, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9072425365447998, 'policy_logps/rejected': -498.3187561035156, 'policy_logps/chosen': -343.202880859375, 'referece_logps/rejected': -461.2401428222656, 'referece_logps/chosen': -325.1966247558594, 'logits/rejected': 0.15201130509376526, 'logits/chosen': 0.21265588700771332, 'epoch': 1.6}

 53%|█████▎    | 1429/2685 [7:52:59<6:40:27, 19.13s/it]

 53%|█████▎    | 1430/2685 [7:53:19<6:44:02, 19.32s/it]

 53%|█████▎    | 1431/2685 [7:53:37<6:37:24, 19.01s/it]

 53%|█████▎    | 1432/2685 [7:53:54<6:26:28, 18.51s/it]

 53%|█████▎    | 1433/2685 [7:54:15<6:40:41, 19.20s/it]

 53%|█████▎    | 1434/2685 [7:54:37<6:58:22, 20.07s/it]

 53%|█████▎    | 1435/2685 [7:54:55<6:44:33, 19.42s/it]

 53%|█████▎    | 1436/2685 [7:55:15<6:44:20, 19.42s/it]

 54%|█████▎    | 1437/2685 [7:55:35<6:49:13, 19.67s/it]

 54%|█████▎    | 1438/2685 [7:55:56<6:59:13, 20.17s/it]

 54%|█████▎    | 1439/2685 [7:56:16<6:58:52, 20.17s/it]

 54%|█████▎    | 1440/2685 [7:56:36<6:57:29, 20.12s/it]

 54%|█████▎    | 1441/2685 [7:56:56<6:55:25, 20.04s/it]

 54%|█████▎    | 1442/2685 [7:57:16<6:55:28, 20.06s/it]

 54%|█████▎    | 1443/2685 [7:57:37<7:01:56, 20.38s/it]

 54%|█████▍    | 1444/2685 [7:58:01<7:23:49, 21.46s/it]

 54%|█████▍    | 1445/2685 [7:58:20<7:04:06, 20.52s/it]

 54%|█████▍    | 1446/2685 [7:58:42<7:17:28, 21.19s/it]

 54%|█████▍    | 1447/2685 [7:59:02<7:03:56, 20.55s/it]

 54%|█████▍    | 1448/2685 [7:59:21<6:57:38, 20.26s/it]

 54%|█████▍    | 1449/2685 [7:59:40<6:46:28, 19.73s/it]

 54%|█████▍    | 1450/2685 [7:59:58<6:35:48, 19.23s/it]

 54%|█████▍    | 1451/2685 [8:00:17<6:38:27, 19.37s/it]

 54%|█████▍    | 1452/2685 [8:00:37<6:42:15, 19.57s/it]

 54%|█████▍    | 1453/2685 [8:00:58<6:45:26, 19.75s/it]


 54%|█████▍    | 1455/2685 [8:01:38<6:47:46, 19.89s/it]

 54%|█████▍    | 1456/2685 [8:01:58<6:47:54, 19.91s/it]
{'loss': 0.2477, 'learning_rate': 9.120430469359215e-07, 'rewards/chosen': -1.0846418142318726, 'rewards/rejected': -4.374422073364258, 'rewards/accuracies': 0.875, 'rewards/margins': 3.2897801399230957, 'policy_logps/rejected': -530.1111450195312, 'policy_logps/chosen': -554.037109375, 'referece_logps/rejected': -486.366943359375, 'referece_logps/chosen': -543.190673828125, 'logits/rejected': 0.3543768525123596, 'logits/chosen': 0.3724537193775177, 'epoch': 1.63}

 54%|█████▍    | 1457/2685 [8:02:18<6:50:12, 20.04s/it]

 54%|█████▍    | 1458/2685 [8:02:39<6:52:57, 20.19s/it]

 54%|█████▍    | 1459/2685 [8:03:00<7:00:22, 20.57s/it]


 54%|█████▍    | 1461/2685 [8:03:44<7:12:16, 21.19s/it]
{'loss': 0.2337, 'learning_rate': 9.060358190107233e-07, 'rewards/chosen': -1.274800181388855, 'rewards/rejected': -3.439182758331299, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1643826961517334, 'policy_logps/rejected': -369.61077880859375, 'policy_logps/chosen': -302.29669189453125, 'referece_logps/rejected': -335.21893310546875, 'referece_logps/chosen': -289.5487060546875, 'logits/rejected': 0.14363202452659607, 'logits/chosen': 0.23642182350158691, 'epoch': 1.63}

 54%|█████▍    | 1462/2685 [8:04:04<7:03:11, 20.76s/it]

 54%|█████▍    | 1463/2685 [8:04:24<6:55:57, 20.42s/it]

 55%|█████▍    | 1464/2685 [8:04:41<6:37:29, 19.53s/it]

 55%|█████▍    | 1465/2685 [8:04:59<6:27:25, 19.05s/it]


 55%|█████▍    | 1467/2685 [8:05:40<6:39:58, 19.70s/it]

 55%|█████▍    | 1468/2685 [8:06:03<7:03:52, 20.90s/it]

 55%|█████▍    | 1469/2685 [8:06:23<6:57:42, 20.61s/it]

 55%|█████▍    | 1470/2685 [8:06:42<6:47:10, 20.11s/it]

 55%|█████▍    | 1471/2685 [8:06:58<6:22:12, 18.89s/it]
{'loss': 0.315, 'learning_rate': 8.940318390915572e-07, 'rewards/chosen': -0.2960037291049957, 'rewards/rejected': -3.119352102279663, 'rewards/accuracies': 0.875, 'rewards/margins': 2.823348045349121, 'policy_logps/rejected': -228.74700927734375, 'policy_logps/chosen': -230.6220245361328, 'referece_logps/rejected': -197.55348205566406, 'referece_logps/chosen': -227.6619873046875, 'logits/rejected': -0.661087155342102, 'logits/chosen': -0.6461449861526489, 'epoch': 1.64}


 55%|█████▍    | 1473/2685 [8:07:38<6:34:25, 19.53s/it]

 55%|█████▍    | 1474/2685 [8:07:55<6:17:32, 18.71s/it]

 55%|█████▍    | 1475/2685 [8:08:15<6:23:43, 19.03s/it]

 55%|█████▍    | 1476/2685 [8:08:35<6:28:04, 19.26s/it]
{'loss': 0.2955, 'learning_rate': 8.880355238966921e-07, 'rewards/chosen': -1.6420294046401978, 'rewards/rejected': -3.174691677093506, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5326626300811768, 'policy_logps/rejected': -386.23162841796875, 'policy_logps/chosen': -355.8587951660156, 'referece_logps/rejected': -354.48468017578125, 'referece_logps/chosen': -339.4384765625, 'logits/rejected': -0.23352891206741333, 'logits/chosen': -0.16075347363948822, 'epoch': 1.65}


 55%|█████▌    | 1478/2685 [8:09:05<5:45:08, 17.16s/it]

 55%|█████▌    | 1479/2685 [8:09:26<6:12:00, 18.51s/it]

 55%|█████▌    | 1480/2685 [8:09:44<6:09:56, 18.42s/it]

 55%|█████▌    | 1481/2685 [8:10:02<6:01:57, 18.04s/it]

 55%|█████▌    | 1482/2685 [8:10:21<6:11:00, 18.50s/it]

 55%|█████▌    | 1483/2685 [8:10:41<6:17:33, 18.85s/it]

 55%|█████▌    | 1484/2685 [8:11:00<6:19:54, 18.98s/it]

 55%|█████▌    | 1485/2685 [8:11:20<6:25:28, 19.27s/it]

 55%|█████▌    | 1486/2685 [8:11:41<6:32:22, 19.64s/it]

 55%|█████▌    | 1487/2685 [8:11:58<6:19:55, 19.03s/it]

 55%|█████▌    | 1488/2685 [8:12:21<6:45:11, 20.31s/it]

 55%|█████▌    | 1489/2685 [8:12:36<6:08:44, 18.50s/it]

 55%|█████▌    | 1490/2685 [8:12:50<5:44:50, 17.31s/it]

 56%|█████▌    | 1491/2685 [8:13:08<5:45:40, 17.37s/it]

 56%|█████▌    | 1492/2685 [8:13:26<5:50:54, 17.65s/it]

 56%|█████▌    | 1493/2685 [8:13:47<6:07:38, 18.51s/it]

 56%|█████▌    | 1494/2685 [8:14:06<6:14:20, 18.86s/it]

 56%|█████▌    | 1495/2685 [8:14:20<5:44:26, 17.37s/it]
{'loss': 0.3114, 'learning_rate': 8.652885377741392e-07, 'rewards/chosen': -1.9925875663757324, 'rewards/rejected': -5.110157489776611, 'rewards/accuracies': 1.0, 'rewards/margins': 3.117569923400879, 'policy_logps/rejected': -462.3843994140625, 'policy_logps/chosen': -272.1275329589844, 'referece_logps/rejected': -411.2828369140625, 'referece_logps/chosen': -252.2017059326172, 'logits/rejected': 0.18859760463237762, 'logits/chosen': 0.04252038151025772, 'epoch': 1.67}


 56%|█████▌    | 1497/2685 [8:15:02<6:15:56, 18.99s/it]

 56%|█████▌    | 1498/2685 [8:15:20<6:10:46, 18.74s/it]
{'loss': 0.3858, 'learning_rate': 8.617030723851964e-07, 'rewards/chosen': -0.42949408292770386, 'rewards/rejected': -3.2222862243652344, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7927920818328857, 'policy_logps/rejected': -265.09222412109375, 'policy_logps/chosen': -239.47669982910156, 'referece_logps/rejected': -232.86936950683594, 'referece_logps/chosen': -235.18174743652344, 'logits/rejected': -0.075685054063797, 'logits/chosen': -0.174957275390625, 'epoch': 1.67}


 56%|█████▌    | 1500/2685 [8:16:03<6:39:41, 20.24s/it]

 56%|█████▌    | 1501/2685 [8:16:36<7:58:17, 24.24s/it]

 56%|█████▌    | 1502/2685 [8:16:56<7:31:08, 22.88s/it]

 56%|█████▌    | 1503/2685 [8:17:17<7:19:04, 22.29s/it]

 56%|█████▌    | 1504/2685 [8:17:38<7:10:11, 21.86s/it]

 56%|█████▌    | 1505/2685 [8:17:56<6:46:42, 20.68s/it]

 56%|█████▌    | 1506/2685 [8:18:10<6:10:13, 18.84s/it]
{'loss': 0.3163, 'learning_rate': 8.521508157568113e-07, 'rewards/chosen': -1.3416054248809814, 'rewards/rejected': -3.083864450454712, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7422587871551514, 'policy_logps/rejected': -329.6715087890625, 'policy_logps/chosen': -328.03564453125, 'referece_logps/rejected': -298.8328552246094, 'referece_logps/chosen': -314.6195983886719, 'logits/rejected': -0.571068286895752, 'logits/chosen': -0.6372202634811401, 'epoch': 1.68}


 56%|█████▌    | 1508/2685 [8:18:51<6:22:23, 19.49s/it]

 56%|█████▌    | 1509/2685 [8:19:15<6:49:04, 20.87s/it]

 56%|█████▌    | 1510/2685 [8:19:35<6:45:50, 20.72s/it]

 56%|█████▋    | 1511/2685 [8:19:57<6:52:43, 21.09s/it]
{'loss': 0.2375, 'learning_rate': 8.461875927904332e-07, 'rewards/chosen': -0.7068331241607666, 'rewards/rejected': -3.252639055252075, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5458059310913086, 'policy_logps/rejected': -272.7707824707031, 'policy_logps/chosen': -255.95245361328125, 'referece_logps/rejected': -240.24436950683594, 'referece_logps/chosen': -248.88414001464844, 'logits/rejected': -0.5268146395683289, 'logits/chosen': -0.5612463355064392, 'epoch': 1.69}


 56%|█████▋    | 1513/2685 [8:20:38<6:42:49, 20.62s/it]

 56%|█████▋    | 1514/2685 [8:20:58<6:37:28, 20.37s/it]

 56%|█████▋    | 1515/2685 [8:21:16<6:23:50, 19.68s/it]
{'loss': 0.4083, 'learning_rate': 8.414210337794165e-07, 'rewards/chosen': -1.1531078815460205, 'rewards/rejected': -3.4579458236694336, 'rewards/accuracies': 0.875, 'rewards/margins': 2.304837465286255, 'policy_logps/rejected': -455.7137756347656, 'policy_logps/chosen': -302.8736267089844, 'referece_logps/rejected': -421.13433837890625, 'referece_logps/chosen': -291.342529296875, 'logits/rejected': 0.4998047649860382, 'logits/chosen': 0.48376139998435974, 'epoch': 1.69}

 56%|█████▋    | 1516/2685 [8:21:36<6:22:14, 19.62s/it]


 57%|█████▋    | 1518/2685 [8:22:18<6:39:42, 20.55s/it]

 57%|█████▋    | 1519/2685 [8:22:35<6:19:00, 19.50s/it]

 57%|█████▋    | 1520/2685 [8:22:57<6:34:11, 20.30s/it]
{'loss': 0.2365, 'learning_rate': 8.354680413353902e-07, 'rewards/chosen': -2.020080327987671, 'rewards/rejected': -4.435810089111328, 'rewards/accuracies': 0.875, 'rewards/margins': 2.415729522705078, 'policy_logps/rejected': -441.9490051269531, 'policy_logps/chosen': -336.63494873046875, 'referece_logps/rejected': -397.5909118652344, 'referece_logps/chosen': -316.43414306640625, 'logits/rejected': -0.2955191135406494, 'logits/chosen': -0.30930134654045105, 'epoch': 1.7}


 57%|█████▋    | 1522/2685 [8:23:37<6:30:36, 20.15s/it]

 57%|█████▋    | 1523/2685 [8:23:56<6:26:12, 19.94s/it]

 57%|█████▋    | 1524/2685 [8:24:17<6:31:33, 20.24s/it]

 57%|█████▋    | 1525/2685 [8:24:37<6:29:59, 20.17s/it]

 57%|█████▋    | 1526/2685 [8:24:53<6:05:02, 18.90s/it]
{'loss': 0.2509, 'learning_rate': 8.283323722438452e-07, 'rewards/chosen': -0.1811414510011673, 'rewards/rejected': -4.091879367828369, 'rewards/accuracies': 0.875, 'rewards/margins': 3.9107375144958496, 'policy_logps/rejected': -403.56011962890625, 'policy_logps/chosen': -327.0975036621094, 'referece_logps/rejected': -362.6413269042969, 'referece_logps/chosen': -325.28607177734375, 'logits/rejected': -0.5763181447982788, 'logits/chosen': -0.5769717693328857, 'epoch': 1.71}


 57%|█████▋    | 1528/2685 [8:25:35<6:21:57, 19.81s/it]
{'loss': 0.2204, 'learning_rate': 8.259557963440827e-07, 'rewards/chosen': -1.163644552230835, 'rewards/rejected': -4.869056224822998, 'rewards/accuracies': 0.875, 'rewards/margins': 3.705411434173584, 'policy_logps/rejected': -443.08831787109375, 'policy_logps/chosen': -345.06597900390625, 'referece_logps/rejected': -394.39776611328125, 'referece_logps/chosen': -333.4295654296875, 'logits/rejected': -0.2763587236404419, 'logits/chosen': -0.1566404104232788, 'epoch': 1.71}


 57%|█████▋    | 1530/2685 [8:26:08<5:47:21, 18.04s/it]

 57%|█████▋    | 1531/2685 [8:26:26<5:47:28, 18.07s/it]

 57%|█████▋    | 1532/2685 [8:26:43<5:37:38, 17.57s/it]

 57%|█████▋    | 1533/2685 [8:27:05<6:02:06, 18.86s/it]

 57%|█████▋    | 1534/2685 [8:27:25<6:12:08, 19.40s/it]

 57%|█████▋    | 1535/2685 [8:27:50<6:40:39, 20.90s/it]

 57%|█████▋    | 1536/2685 [8:28:12<6:47:24, 21.28s/it]

 57%|█████▋    | 1537/2685 [8:28:28<6:15:48, 19.64s/it]

 57%|█████▋    | 1538/2685 [8:28:51<6:35:11, 20.67s/it]

 57%|█████▋    | 1539/2685 [8:29:13<6:41:19, 21.01s/it]
{'loss': 0.3025, 'learning_rate': 8.129031122891459e-07, 'rewards/chosen': -1.431665062904358, 'rewards/rejected': -2.941244125366211, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5095789432525635, 'policy_logps/rejected': -330.5764465332031, 'policy_logps/chosen': -315.8978271484375, 'referece_logps/rejected': -301.1640319824219, 'referece_logps/chosen': -301.5811462402344, 'logits/rejected': 0.3159981369972229, 'logits/chosen': 0.3128572702407837, 'epoch': 1.72}


 57%|█████▋    | 1541/2685 [8:29:47<6:06:06, 19.20s/it]

 57%|█████▋    | 1542/2685 [8:30:06<6:04:58, 19.16s/it]

 57%|█████▋    | 1543/2685 [8:30:28<6:18:52, 19.91s/it]

 58%|█████▊    | 1544/2685 [8:30:45<6:02:17, 19.05s/it]
{'loss': 0.238, 'learning_rate': 8.069808288842268e-07, 'rewards/chosen': -1.3509941101074219, 'rewards/rejected': -4.701336860656738, 'rewards/accuracies': 1.0, 'rewards/margins': 3.3503427505493164, 'policy_logps/rejected': -429.6906433105469, 'policy_logps/chosen': -343.3283996582031, 'referece_logps/rejected': -382.67724609375, 'referece_logps/chosen': -329.8184509277344, 'logits/rejected': -0.5583590865135193, 'logits/chosen': -0.45905643701553345, 'epoch': 1.73}


 58%|█████▊    | 1546/2685 [8:31:28<6:27:38, 20.42s/it]

 58%|█████▊    | 1547/2685 [8:31:49<6:33:36, 20.75s/it]

 58%|█████▊    | 1548/2685 [8:32:10<6:35:02, 20.85s/it]

 58%|█████▊    | 1549/2685 [8:32:33<6:45:58, 21.44s/it]

 58%|█████▊    | 1550/2685 [8:32:52<6:29:32, 20.59s/it]

 58%|█████▊    | 1551/2685 [8:33:08<6:03:37, 19.24s/it]

 58%|█████▊    | 1552/2685 [8:33:25<5:52:27, 18.66s/it]

 58%|█████▊    | 1553/2685 [8:33:46<6:06:21, 19.42s/it]

 58%|█████▊    | 1554/2685 [8:34:10<6:31:23, 20.76s/it]

 58%|█████▊    | 1555/2685 [8:34:24<5:54:06, 18.80s/it]

 58%|█████▊    | 1556/2685 [8:34:40<5:35:49, 17.85s/it]
{'loss': 0.3164, 'learning_rate': 7.927964145864929e-07, 'rewards/chosen': -1.962235927581787, 'rewards/rejected': -5.471174240112305, 'rewards/accuracies': 0.875, 'rewards/margins': 3.5089378356933594, 'policy_logps/rejected': -494.9837646484375, 'policy_logps/chosen': -464.2186584472656, 'referece_logps/rejected': -440.2720642089844, 'referece_logps/chosen': -444.5963134765625, 'logits/rejected': -1.0043725967407227, 'logits/chosen': -1.0086688995361328, 'epoch': 1.74}


 58%|█████▊    | 1558/2685 [8:35:16<5:40:53, 18.15s/it]

 58%|█████▊    | 1559/2685 [8:35:36<5:50:28, 18.68s/it]

 58%|█████▊    | 1560/2685 [8:35:55<5:53:04, 18.83s/it]

 58%|█████▊    | 1561/2685 [8:36:16<6:03:26, 19.40s/it]

 58%|█████▊    | 1562/2685 [8:36:38<6:19:38, 20.28s/it]

 58%|█████▊    | 1563/2685 [8:37:00<6:31:07, 20.92s/it]

 58%|█████▊    | 1564/2685 [8:37:22<6:34:32, 21.12s/it]
{'loss': 0.2951, 'learning_rate': 7.833640819156411e-07, 'rewards/chosen': -2.3121070861816406, 'rewards/rejected': -3.397599697113037, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0854930877685547, 'policy_logps/rejected': -395.76568603515625, 'policy_logps/chosen': -373.65997314453125, 'referece_logps/rejected': -361.7896728515625, 'referece_logps/chosen': -350.5389099121094, 'logits/rejected': -0.734061598777771, 'logits/chosen': -0.7876760959625244, 'epoch': 1.75}


 58%|█████▊    | 1566/2685 [8:38:04<6:34:47, 21.17s/it]

 58%|█████▊    | 1567/2685 [8:38:23<6:18:01, 20.29s/it]
{'loss': 0.2533, 'learning_rate': 7.798321127307796e-07, 'rewards/chosen': -1.951921820640564, 'rewards/rejected': -3.859344959259033, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9074230194091797, 'policy_logps/rejected': -354.8998718261719, 'policy_logps/chosen': -228.54995727539062, 'referece_logps/rejected': -316.306396484375, 'referece_logps/chosen': -209.03074645996094, 'logits/rejected': -0.5288072824478149, 'logits/chosen': -0.516925573348999, 'epoch': 1.75}

 58%|█████▊    | 1568/2685 [8:38:45<6:28:36, 20.87s/it]


 58%|█████▊    | 1570/2685 [8:39:24<6:17:20, 20.31s/it]
{'loss': 0.3583, 'learning_rate': 7.763030276690376e-07, 'rewards/chosen': -1.0134456157684326, 'rewards/rejected': -3.3305416107177734, 'rewards/accuracies': 0.75, 'rewards/margins': 2.31709623336792, 'policy_logps/rejected': -357.0894775390625, 'policy_logps/chosen': -348.2747802734375, 'referece_logps/rejected': -323.7840576171875, 'referece_logps/chosen': -338.14031982421875, 'logits/rejected': 0.3178051710128784, 'logits/chosen': 0.26879408955574036, 'epoch': 1.75}


 59%|█████▊    | 1572/2685 [8:40:03<6:04:24, 19.64s/it]
{'loss': 0.2113, 'learning_rate': 7.73951929416265e-07, 'rewards/chosen': -1.580282211303711, 'rewards/rejected': -5.41832971572876, 'rewards/accuracies': 0.875, 'rewards/margins': 3.8380472660064697, 'policy_logps/rejected': -326.0124206542969, 'policy_logps/chosen': -286.6730651855469, 'referece_logps/rejected': -271.82916259765625, 'referece_logps/chosen': -270.8702697753906, 'logits/rejected': -0.41816622018814087, 'logits/chosen': -0.5108257532119751, 'epoch': 1.76}


 59%|█████▊    | 1574/2685 [8:40:42<6:07:56, 19.87s/it]

 59%|█████▊    | 1575/2685 [8:41:02<6:07:00, 19.84s/it]
{'loss': 0.3064, 'learning_rate': 7.704277539403303e-07, 'rewards/chosen': -0.9274063110351562, 'rewards/rejected': -2.991100549697876, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0636940002441406, 'policy_logps/rejected': -201.60284423828125, 'policy_logps/chosen': -260.7442932128906, 'referece_logps/rejected': -171.69183349609375, 'referece_logps/chosen': -251.47018432617188, 'logits/rejected': -0.22424697875976562, 'logits/chosen': -0.18224798142910004, 'epoch': 1.76}


 59%|█████▊    | 1577/2685 [8:41:40<5:56:11, 19.29s/it]

 59%|█████▉    | 1578/2685 [8:42:02<6:08:38, 19.98s/it]
{'loss': 0.3375, 'learning_rate': 7.669065857813599e-07, 'rewards/chosen': -1.5160906314849854, 'rewards/rejected': -6.647785663604736, 'rewards/accuracies': 1.0, 'rewards/margins': 5.13169527053833, 'policy_logps/rejected': -413.64947509765625, 'policy_logps/chosen': -366.4126892089844, 'referece_logps/rejected': -347.171630859375, 'referece_logps/chosen': -351.25177001953125, 'logits/rejected': -0.6221673488616943, 'logits/chosen': -0.6299750208854675, 'epoch': 1.76}


 59%|█████▉    | 1580/2685 [8:42:38<5:50:31, 19.03s/it]

 59%|█████▉    | 1581/2685 [8:42:58<5:53:30, 19.21s/it]

 59%|█████▉    | 1582/2685 [8:43:14<5:33:29, 18.14s/it]
{'loss': 0.3443, 'learning_rate': 7.622164526696905e-07, 'rewards/chosen': -1.5061571598052979, 'rewards/rejected': -3.477689027786255, 'rewards/accuracies': 0.875, 'rewards/margins': 1.971531867980957, 'policy_logps/rejected': -389.6006774902344, 'policy_logps/chosen': -336.74530029296875, 'referece_logps/rejected': -354.8238220214844, 'referece_logps/chosen': -321.68365478515625, 'logits/rejected': -0.2912557125091553, 'logits/chosen': -0.3830861449241638, 'epoch': 1.77}

 59%|█████▉    | 1583/2685 [8:43:32<5:32:01, 18.08s/it]

 59%|█████▉    | 1584/2685 [8:43:51<5:41:05, 18.59s/it]

 59%|█████▉    | 1585/2685 [8:44:12<5:50:24, 19.11s/it]

 59%|█████▉    | 1586/2685 [8:44:31<5:50:44, 19.15s/it]

 59%|█████▉    | 1587/2685 [8:44:52<5:58:41, 19.60s/it]

 59%|█████▉    | 1588/2685 [8:45:10<5:49:04, 19.09s/it]

 59%|█████▉    | 1589/2685 [8:45:29<5:52:21, 19.29s/it]


 59%|█████▉    | 1591/2685 [8:46:07<5:45:51, 18.97s/it]
{'loss': 0.2725, 'learning_rate': 7.516840660738721e-07, 'rewards/chosen': -1.6084215641021729, 'rewards/rejected': -4.2686872482299805, 'rewards/accuracies': 0.875, 'rewards/margins': 2.6602659225463867, 'policy_logps/rejected': -506.2778625488281, 'policy_logps/chosen': -421.5670471191406, 'referece_logps/rejected': -463.59100341796875, 'referece_logps/chosen': -405.48284912109375, 'logits/rejected': -0.022935405373573303, 'logits/chosen': -0.01628550887107849, 'epoch': 1.78}


 59%|█████▉    | 1593/2685 [8:46:48<6:01:21, 19.85s/it]

 59%|█████▉    | 1594/2685 [8:47:10<6:12:09, 20.47s/it]

 59%|█████▉    | 1595/2685 [8:47:28<6:01:16, 19.89s/it]

 59%|█████▉    | 1596/2685 [8:47:49<6:03:15, 20.01s/it]
{'loss': 0.27, 'learning_rate': 7.458453107107777e-07, 'rewards/chosen': -1.660925030708313, 'rewards/rejected': -3.1949777603149414, 'rewards/accuracies': 0.75, 'rewards/margins': 1.534053087234497, 'policy_logps/rejected': -279.1321105957031, 'policy_logps/chosen': -287.88751220703125, 'referece_logps/rejected': -247.18234252929688, 'referece_logps/chosen': -271.27825927734375, 'logits/rejected': -0.026290148496627808, 'logits/chosen': 0.016343578696250916, 'epoch': 1.78}

 59%|█████▉    | 1597/2685 [8:48:09<6:05:52, 20.18s/it]


 60%|█████▉    | 1599/2685 [8:48:45<5:46:30, 19.14s/it]

 60%|█████▉    | 1600/2685 [8:49:07<5:59:05, 19.86s/it]
{'loss': 0.3026, 'learning_rate': 7.411809548974791e-07, 'rewards/chosen': -0.42095571756362915, 'rewards/rejected': -2.5518455505371094, 'rewards/accuracies': 0.875, 'rewards/margins': 2.130889654159546, 'policy_logps/rejected': -322.85809326171875, 'policy_logps/chosen': -320.9709167480469, 'referece_logps/rejected': -297.33966064453125, 'referece_logps/chosen': -316.7613525390625, 'logits/rejected': 0.10564951598644257, 'logits/chosen': 0.06016472727060318, 'epoch': 1.79}


 60%|█████▉    | 1602/2685 [8:49:48<6:10:23, 20.52s/it]
{'loss': 0.3082, 'learning_rate': 7.388510304985931e-07, 'rewards/chosen': -0.9566133618354797, 'rewards/rejected': -3.6824731826782227, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7258596420288086, 'policy_logps/rejected': -345.747314453125, 'policy_logps/chosen': -292.33770751953125, 'referece_logps/rejected': -308.92254638671875, 'referece_logps/chosen': -282.7715759277344, 'logits/rejected': -0.7906772494316101, 'logits/chosen': -0.8582725524902344, 'epoch': 1.79}


 60%|█████▉    | 1604/2685 [8:50:29<6:08:47, 20.47s/it]

 60%|█████▉    | 1605/2685 [8:50:49<6:04:44, 20.26s/it]

 60%|█████▉    | 1606/2685 [8:51:08<6:01:47, 20.12s/it]
{'loss': 0.2808, 'learning_rate': 7.341957565412063e-07, 'rewards/chosen': -1.9388699531555176, 'rewards/rejected': -4.202535629272461, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2636659145355225, 'policy_logps/rejected': -362.0011901855469, 'policy_logps/chosen': -351.8265380859375, 'referece_logps/rejected': -319.9757995605469, 'referece_logps/chosen': -332.4378356933594, 'logits/rejected': 0.1245032474398613, 'logits/chosen': 0.13426703214645386, 'epoch': 1.79}

 60%|█████▉    | 1607/2685 [8:51:22<5:26:58, 18.20s/it]


 60%|█████▉    | 1609/2685 [8:52:03<5:45:56, 19.29s/it]

 60%|█████▉    | 1610/2685 [8:52:22<5:48:03, 19.43s/it]

 60%|██████    | 1611/2685 [8:52:41<5:45:31, 19.30s/it]

 60%|██████    | 1612/2685 [8:53:01<5:48:50, 19.51s/it]

 60%|██████    | 1613/2685 [8:53:19<5:36:22, 18.83s/it]
{'loss': 0.3972, 'learning_rate': 7.260639872201328e-07, 'rewards/chosen': -1.2824223041534424, 'rewards/rejected': -3.822223663330078, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5398013591766357, 'policy_logps/rejected': -261.3280334472656, 'policy_logps/chosen': -257.7595520019531, 'referece_logps/rejected': -223.10581970214844, 'referece_logps/chosen': -244.93533325195312, 'logits/rejected': -0.3873968720436096, 'logits/chosen': -0.2920834422111511, 'epoch': 1.8}

 60%|██████    | 1614/2685 [8:53:40<5:50:19, 19.63s/it]

 60%|██████    | 1615/2685 [8:53:58<5:41:59, 19.18s/it]

 60%|██████    | 1616/2685 [8:54:16<5:35:41, 18.84s/it]

 60%|██████    | 1617/2685 [8:54:38<5:49:31, 19.64s/it]


 60%|██████    | 1619/2685 [8:55:17<5:49:34, 19.68s/it]

 60%|██████    | 1620/2685 [8:55:39<5:59:55, 20.28s/it]

 60%|██████    | 1621/2685 [8:55:59<5:58:27, 20.21s/it]
{'loss': 0.3309, 'learning_rate': 7.167944933176959e-07, 'rewards/chosen': -1.8704639673233032, 'rewards/rejected': -3.9251327514648438, 'rewards/accuracies': 0.875, 'rewards/margins': 2.054669141769409, 'policy_logps/rejected': -366.53564453125, 'policy_logps/chosen': -333.7487487792969, 'referece_logps/rejected': -327.2843017578125, 'referece_logps/chosen': -315.04412841796875, 'logits/rejected': -0.021083712577819824, 'logits/chosen': 0.007463440299034119, 'epoch': 1.81}

 60%|██████    | 1622/2685 [8:56:20<6:05:43, 20.64s/it]

 60%|██████    | 1623/2685 [8:56:40<6:02:10, 20.46s/it]


 61%|██████    | 1625/2685 [8:57:21<5:59:18, 20.34s/it]

 61%|██████    | 1626/2685 [8:57:39<5:48:35, 19.75s/it]
{'loss': 0.3434, 'learning_rate': 7.110144016701063e-07, 'rewards/chosen': -1.987621784210205, 'rewards/rejected': -3.7606594562530518, 'rewards/accuracies': 0.875, 'rewards/margins': 1.773037314414978, 'policy_logps/rejected': -352.8143005371094, 'policy_logps/chosen': -337.6136474609375, 'referece_logps/rejected': -315.2077331542969, 'referece_logps/chosen': -317.7374267578125, 'logits/rejected': -0.3096315264701843, 'logits/chosen': -0.31747153401374817, 'epoch': 1.82}


 61%|██████    | 1628/2685 [8:58:18<5:44:50, 19.57s/it]

 61%|██████    | 1629/2685 [8:58:36<5:36:15, 19.11s/it]

 61%|██████    | 1630/2685 [8:58:56<5:40:08, 19.34s/it]

 61%|██████    | 1631/2685 [8:59:15<5:38:45, 19.28s/it]

 61%|██████    | 1632/2685 [8:59:35<5:40:53, 19.42s/it]
{'loss': 0.3435, 'learning_rate': 7.040921907226447e-07, 'rewards/chosen': -1.6871460676193237, 'rewards/rejected': -5.604886531829834, 'rewards/accuracies': 0.75, 'rewards/margins': 3.917741060256958, 'policy_logps/rejected': -599.5338134765625, 'policy_logps/chosen': -478.9780578613281, 'referece_logps/rejected': -543.4849243164062, 'referece_logps/chosen': -462.1065368652344, 'logits/rejected': 0.09701237082481384, 'logits/chosen': 0.11444731056690216, 'epoch': 1.82}

 61%|██████    | 1633/2685 [8:59:56<5:52:02, 20.08s/it]

 61%|██████    | 1634/2685 [9:00:16<5:49:49, 19.97s/it]

 61%|██████    | 1635/2685 [9:00:36<5:50:16, 20.02s/it]


 61%|██████    | 1637/2685 [9:01:19<6:02:36, 20.76s/it]

 61%|██████    | 1638/2685 [9:01:39<5:56:28, 20.43s/it]

 61%|██████    | 1639/2685 [9:02:00<5:56:16, 20.44s/it]
{'loss': 0.3134, 'learning_rate': 6.960359001085732e-07, 'rewards/chosen': -2.2127859592437744, 'rewards/rejected': -4.339020729064941, 'rewards/accuracies': 1.0, 'rewards/margins': 2.126235008239746, 'policy_logps/rejected': -384.0860900878906, 'policy_logps/chosen': -358.83258056640625, 'referece_logps/rejected': -340.6958312988281, 'referece_logps/chosen': -336.7047119140625, 'logits/rejected': -0.022450938820838928, 'logits/chosen': -0.08392247557640076, 'epoch': 1.83}


 61%|██████    | 1641/2685 [9:02:33<5:18:59, 18.33s/it]

 61%|██████    | 1642/2685 [9:02:54<5:31:27, 19.07s/it]

 61%|██████    | 1643/2685 [9:03:15<5:42:20, 19.71s/it]

 61%|██████    | 1644/2685 [9:03:36<5:47:03, 20.00s/it]

 61%|██████▏   | 1645/2685 [9:03:55<5:44:38, 19.88s/it]

 61%|██████▏   | 1646/2685 [9:04:14<5:39:21, 19.60s/it]

 61%|██████▏   | 1647/2685 [9:04:28<5:07:43, 17.79s/it]
{'loss': 0.306, 'learning_rate': 6.868552896356117e-07, 'rewards/chosen': -1.1235255002975464, 'rewards/rejected': -4.424800872802734, 'rewards/accuracies': 0.875, 'rewards/margins': 3.3012752532958984, 'policy_logps/rejected': -353.89093017578125, 'policy_logps/chosen': -354.2380065917969, 'referece_logps/rejected': -309.64288330078125, 'referece_logps/chosen': -343.0027770996094, 'logits/rejected': 0.08306963741779327, 'logits/chosen': 0.06533030420541763, 'epoch': 1.84}

 61%|██████▏   | 1648/2685 [9:04:48<5:22:00, 18.63s/it]

 61%|██████▏   | 1649/2685 [9:05:09<5:30:13, 19.12s/it]


 61%|██████▏   | 1651/2685 [9:05:51<5:51:03, 20.37s/it]
