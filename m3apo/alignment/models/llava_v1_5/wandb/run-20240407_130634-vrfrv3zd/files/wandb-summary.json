{"train/loss": 0.5079, "train/learning_rate": 1.346069882904247e-06, "train/rewards/chosen": -1.0908188819885254, "train/rewards/rejected": -1.8304157257080078, "train/rewards/accuracies": 0.75, "train/rewards/margins": 0.7395970225334167, "train/policy_logps/rejected": -411.5654296875, "train/policy_logps/chosen": -390.5146789550781, "train/referece_logps/rejected": -393.2612609863281, "train/referece_logps/chosen": -379.60650634765625, "train/logits/rejected": -0.459267795085907, "train/logits/chosen": -0.22573231160640717, "train/epoch": 2.44, "train/global_step": 6537, "_timestamp": 1712575486.7600148, "_runtime": 109091.84085988998, "_step": 6536}