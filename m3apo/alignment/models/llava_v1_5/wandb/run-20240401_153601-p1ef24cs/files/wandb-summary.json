{"train/loss": 0.5557, "train/learning_rate": 1.998355118725076e-06, "train/rewards/chosen": -0.7386383414268494, "train/rewards/rejected": -2.023588180541992, "train/rewards/accuracies": 0.75, "train/rewards/margins": 1.284949541091919, "train/policy_logps/rejected": -698.2479858398438, "train/policy_logps/chosen": -499.11767578125, "train/referece_logps/rejected": -678.0120849609375, "train/referece_logps/chosen": -491.73138427734375, "train/logits/rejected": -0.6047943234443665, "train/logits/chosen": -0.3048827052116394, "train/epoch": 0.29, "train/global_step": 690, "_timestamp": 1711964398.302961, "_runtime": 7437.216794013977, "_step": 689}