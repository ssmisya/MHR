{"train/loss": 0.6799, "train/learning_rate": 1.9998210198146018e-06, "train/rewards/chosen": -0.20507584512233734, "train/rewards/rejected": -0.08072376251220703, "train/rewards/accuracies": 0.25, "train/rewards/margins": -0.12435206770896912, "train/policy_logps/rejected": -433.419189453125, "train/policy_logps/chosen": -352.88177490234375, "train/referece_logps/rejected": -432.6119384765625, "train/referece_logps/chosen": -350.8310241699219, "train/logits/rejected": 0.46287819743156433, "train/logits/chosen": 0.3777470290660858, "train/epoch": 0.22, "train/global_step": 682, "_timestamp": 1711964373.5094604, "_runtime": 7359.54630947113, "_step": 681}