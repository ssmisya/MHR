{"train/loss": 0.1785, "train/learning_rate": 1.345692458030223e-06, "train/rewards/chosen": -1.8531825542449951, "train/rewards/rejected": -6.95755672454834, "train/rewards/accuracies": 0.875, "train/rewards/margins": 5.104373455047607, "train/policy_logps/rejected": -404.490234375, "train/policy_logps/chosen": -325.7546691894531, "train/referece_logps/rejected": -334.9146728515625, "train/referece_logps/chosen": -307.2228698730469, "train/logits/rejected": -0.15360768139362335, "train/logits/chosen": -0.1271347999572754, "train/epoch": 2.44, "train/global_step": 6539, "_timestamp": 1712575037.3546999, "_runtime": 108699.75470280647, "_step": 6538}