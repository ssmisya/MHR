{"train/loss": 0.3429, "train/learning_rate": 1.347201821302623e-06, "train/rewards/chosen": -1.393379807472229, "train/rewards/rejected": -2.7918272018432617, "train/rewards/accuracies": 0.625, "train/rewards/margins": 1.3984475135803223, "train/policy_logps/rejected": -306.9786071777344, "train/policy_logps/chosen": -302.8958435058594, "train/referece_logps/rejected": -279.0603332519531, "train/referece_logps/chosen": -288.9620361328125, "train/logits/rejected": -0.6007305383682251, "train/logits/chosen": -0.6472851634025574, "train/epoch": 2.43, "train/global_step": 6531, "_timestamp": 1712575100.7227209, "_runtime": 108722.87249088287, "_step": 6530}