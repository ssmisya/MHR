  0%|          | 0/16104 [00:00<?, ?it/s]/mnt/petrelfs/songmingyang/code/mm/MAPO/m3apo/alignment/trainer/llava_dpo_trainer.py:179: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/16104 [00:15<69:05:22, 15.45s/it]

  0%|          | 2/16104 [00:31<70:55:23, 15.86s/it]

  0%|          | 3/16104 [00:49<75:21:26, 16.85s/it]
{'loss': 0.6865, 'learning_rate': 1.2396694214876033e-08, 'rewards/chosen': 0.005567931570112705, 'rewards/rejected': 0.004411696456372738, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0011562341824173927, 'policy_logps/rejected': -472.0621643066406, 'policy_logps/chosen': -399.450927734375, 'referece_logps/rejected': -472.10626220703125, 'referece_logps/chosen': -399.5066223144531, 'logits/rejected': -0.1418411284685135, 'logits/chosen': -0.04484618455171585, 'epoch': 0.0}

  0%|          | 4/16104 [01:09<80:41:12, 18.04s/it]

  0%|          | 5/16104 [01:28<82:17:21, 18.40s/it]

  0%|          | 6/16104 [01:40<72:36:27, 16.24s/it]


  0%|          | 8/16104 [02:21<83:19:12, 18.64s/it]
[2024-04-05 15:36:18,591] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6963, 'learning_rate': 3.305785123966942e-08, 'rewards/chosen': -0.012624356895685196, 'rewards/rejected': -0.047210268676280975, 'rewards/accuracies': 0.625, 'rewards/margins': 0.03458590805530548, 'policy_logps/rejected': -506.60150146484375, 'policy_logps/chosen': -458.5234375, 'referece_logps/rejected': -506.1293640136719, 'referece_logps/chosen': -458.39715576171875, 'logits/rejected': -0.3156728446483612, 'logits/chosen': -0.10599657893180847, 'epoch': 0.0}

  0%|          | 9/16104 [02:42<86:03:57, 19.25s/it]


  0%|          | 11/16104 [03:15<79:25:47, 17.77s/it]
[2024-04-05 15:37:12,542] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6953, 'learning_rate': 4.545454545454545e-08, 'rewards/chosen': -0.051189325749874115, 'rewards/rejected': -0.04126186668872833, 'rewards/accuracies': 0.375, 'rewards/margins': -0.009927460923790932, 'policy_logps/rejected': -409.96856689453125, 'policy_logps/chosen': -462.2209777832031, 'referece_logps/rejected': -409.5559387207031, 'referece_logps/chosen': -461.7091064453125, 'logits/rejected': 0.2826431095600128, 'logits/chosen': 0.2764758765697479, 'epoch': 0.0}

  0%|          | 12/16104 [03:26<69:57:00, 15.65s/it]

  0%|          | 13/16104 [03:37<63:13:39, 14.15s/it]

  0%|          | 14/16104 [03:57<71:38:13, 16.03s/it]

  0%|          | 15/16104 [04:09<65:23:48, 14.63s/it]

  0%|          | 16/16104 [04:27<70:38:30, 15.81s/it]

  0%|          | 17/16104 [04:41<68:16:00, 15.28s/it]

  0%|          | 18/16104 [04:54<65:05:24, 14.57s/it]

  0%|          | 19/16104 [05:05<59:54:14, 13.41s/it]

  0%|          | 20/16104 [05:21<63:05:42, 14.12s/it]

  0%|          | 21/16104 [05:41<71:03:15, 15.90s/it]


  0%|          | 23/16104 [06:04<60:54:34, 13.64s/it]
{'loss': 0.7005, 'learning_rate': 9.504132231404959e-08, 'rewards/chosen': -0.02699432522058487, 'rewards/rejected': -0.0016223902348428965, 'rewards/accuracies': 0.375, 'rewards/margins': -0.025371933355927467, 'policy_logps/rejected': -232.83526611328125, 'policy_logps/chosen': -462.8725280761719, 'referece_logps/rejected': -232.8190460205078, 'referece_logps/chosen': -462.6025695800781, 'logits/rejected': -0.6593732833862305, 'logits/chosen': -0.6033384203910828, 'epoch': 0.01}

  0%|          | 24/16104 [06:15<57:51:36, 12.95s/it]

  0%|          | 25/16104 [06:26<55:48:57, 12.50s/it]


  0%|          | 27/16104 [06:52<56:24:50, 12.63s/it]
{'loss': 0.6968, 'learning_rate': 1.115702479338843e-07, 'rewards/chosen': -0.015614127740263939, 'rewards/rejected': -0.018236352130770683, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0026222248561680317, 'policy_logps/rejected': -187.07986450195312, 'policy_logps/chosen': -409.2841491699219, 'referece_logps/rejected': -186.89749145507812, 'referece_logps/chosen': -409.1280212402344, 'logits/rejected': -0.28433895111083984, 'logits/chosen': -0.0811954215168953, 'epoch': 0.01}

  0%|          | 28/16104 [07:07<59:37:09, 13.35s/it]


  0%|          | 30/16104 [07:42<68:03:47, 15.24s/it]

  0%|          | 31/16104 [08:04<77:18:34, 17.32s/it]
{'loss': 0.6899, 'learning_rate': 1.28099173553719e-07, 'rewards/chosen': -0.02353229559957981, 'rewards/rejected': 0.008031940087676048, 'rewards/accuracies': 0.375, 'rewards/margins': -0.03156423568725586, 'policy_logps/rejected': -379.73687744140625, 'policy_logps/chosen': -322.8621826171875, 'referece_logps/rejected': -379.81719970703125, 'referece_logps/chosen': -322.6268615722656, 'logits/rejected': -0.2617620527744293, 'logits/chosen': -0.38460633158683777, 'epoch': 0.01}

  0%|          | 32/16104 [08:20<76:02:32, 17.03s/it]

  0%|          | 33/16104 [08:38<77:00:08, 17.25s/it]

  0%|          | 34/16104 [08:56<78:31:43, 17.59s/it]


  0%|          | 36/16104 [09:36<83:35:31, 18.73s/it]

  0%|          | 37/16104 [09:52<80:12:51, 17.97s/it]

  0%|          | 38/16104 [10:10<79:55:23, 17.91s/it]
{'loss': 0.6941, 'learning_rate': 1.5702479338842976e-07, 'rewards/chosen': 0.018453311175107956, 'rewards/rejected': 0.0031108870171010494, 'rewards/accuracies': 0.625, 'rewards/margins': 0.015342425554990768, 'policy_logps/rejected': -366.75372314453125, 'policy_logps/chosen': -374.253662109375, 'referece_logps/rejected': -366.7848205566406, 'referece_logps/chosen': -374.438232421875, 'logits/rejected': -0.20534399151802063, 'logits/chosen': -0.28747615218162537, 'epoch': 0.01}

  0%|          | 39/16104 [10:27<78:39:34, 17.63s/it]

  0%|          | 40/16104 [10:48<84:07:31, 18.85s/it]

  0%|          | 41/16104 [11:03<78:54:50, 17.69s/it]

  0%|          | 42/16104 [11:24<83:11:36, 18.65s/it]


  0%|          | 44/16104 [11:52<72:13:32, 16.19s/it]
{'loss': 0.6877, 'learning_rate': 1.818181818181818e-07, 'rewards/chosen': -0.007376288995146751, 'rewards/rejected': -8.390634320676327e-06, 'rewards/accuracies': 0.5, 'rewards/margins': -0.007367897313088179, 'policy_logps/rejected': -406.2306213378906, 'policy_logps/chosen': -340.2430419921875, 'referece_logps/rejected': -406.2305603027344, 'referece_logps/chosen': -340.1692810058594, 'logits/rejected': -0.3388980031013489, 'logits/chosen': -0.26963546872138977, 'epoch': 0.02}


  0%|          | 46/16104 [12:28<77:46:52, 17.44s/it]
{'loss': 0.6928, 'learning_rate': 1.9008264462809918e-07, 'rewards/chosen': 0.010489655658602715, 'rewards/rejected': 0.021993637084960938, 'rewards/accuracies': 0.5, 'rewards/margins': -0.011503979563713074, 'policy_logps/rejected': -457.69317626953125, 'policy_logps/chosen': -412.2580261230469, 'referece_logps/rejected': -457.91314697265625, 'referece_logps/chosen': -412.3629455566406, 'logits/rejected': -0.4342484474182129, 'logits/chosen': -0.5336580276489258, 'epoch': 0.02}


  0%|          | 48/16104 [13:00<73:13:17, 16.42s/it]
{'loss': 0.6895, 'learning_rate': 1.9834710743801653e-07, 'rewards/chosen': -0.03985586389899254, 'rewards/rejected': 0.0054405187256634235, 'rewards/accuracies': 0.125, 'rewards/margins': -0.04529638588428497, 'policy_logps/rejected': -392.3778381347656, 'policy_logps/chosen': -451.61895751953125, 'referece_logps/rejected': -392.4322509765625, 'referece_logps/chosen': -451.2203674316406, 'logits/rejected': -0.3985534906387329, 'logits/chosen': -0.3888065218925476, 'epoch': 0.02}

  0%|          | 49/16104 [13:14<70:31:47, 15.81s/it]

  0%|          | 50/16104 [13:26<64:14:28, 14.41s/it]


  0%|          | 52/16104 [14:00<69:15:45, 15.53s/it]

  0%|          | 53/16104 [14:22<78:00:41, 17.50s/it]
{'loss': 0.6952, 'learning_rate': 2.190082644628099e-07, 'rewards/chosen': -0.015315053053200245, 'rewards/rejected': -0.004642677027732134, 'rewards/accuracies': 0.5, 'rewards/margins': -0.010672380216419697, 'policy_logps/rejected': -449.83648681640625, 'policy_logps/chosen': -353.8240051269531, 'referece_logps/rejected': -449.7900695800781, 'referece_logps/chosen': -353.6708679199219, 'logits/rejected': 0.0404820591211319, 'logits/chosen': 0.11297887563705444, 'epoch': 0.02}

  0%|          | 54/16104 [14:35<71:34:44, 16.06s/it]

  0%|          | 55/16104 [14:48<66:57:54, 15.02s/it]


  0%|          | 57/16104 [15:26<76:29:43, 17.16s/it]
{'loss': 0.6896, 'learning_rate': 2.355371900826446e-07, 'rewards/chosen': 0.01561431773006916, 'rewards/rejected': -0.00021839141845703125, 'rewards/accuracies': 0.625, 'rewards/margins': 0.01583271287381649, 'policy_logps/rejected': -417.1537780761719, 'policy_logps/chosen': -517.4633178710938, 'referece_logps/rejected': -417.151611328125, 'referece_logps/chosen': -517.6194458007812, 'logits/rejected': -0.7036834955215454, 'logits/chosen': -0.8347069621086121, 'epoch': 0.02}


  0%|          | 59/16104 [16:04<81:29:11, 18.28s/it]
{'loss': 0.6884, 'learning_rate': 2.43801652892562e-07, 'rewards/chosen': 0.04937286674976349, 'rewards/rejected': 0.009666632860898972, 'rewards/accuracies': 0.75, 'rewards/margins': 0.03970623016357422, 'policy_logps/rejected': -268.97064208984375, 'policy_logps/chosen': -481.4835510253906, 'referece_logps/rejected': -269.0672912597656, 'referece_logps/chosen': -481.977294921875, 'logits/rejected': 0.15304583311080933, 'logits/chosen': 0.09904903918504715, 'epoch': 0.02}

  0%|          | 60/16104 [16:25<84:50:13, 19.04s/it]


  0%|          | 62/16104 [16:56<77:37:21, 17.42s/it]

  0%|          | 63/16104 [17:14<78:03:39, 17.52s/it]
{'loss': 0.6933, 'learning_rate': 2.603305785123967e-07, 'rewards/chosen': 0.013484957627952099, 'rewards/rejected': -0.004596140701323748, 'rewards/accuracies': 0.375, 'rewards/margins': 0.018081095069646835, 'policy_logps/rejected': -545.305419921875, 'policy_logps/chosen': -528.264892578125, 'referece_logps/rejected': -545.2593994140625, 'referece_logps/chosen': -528.3997802734375, 'logits/rejected': 0.620681643486023, 'logits/chosen': 0.5724502205848694, 'epoch': 0.02}

  0%|          | 64/16104 [17:33<80:18:38, 18.02s/it]

  0%|          | 65/16104 [17:44<70:37:31, 15.85s/it]

  0%|          | 66/16104 [17:55<63:54:49, 14.35s/it]


  0%|          | 68/16104 [18:16<55:45:38, 12.52s/it]

  0%|          | 69/16104 [18:34<62:46:31, 14.09s/it]
{'loss': 0.6997, 'learning_rate': 2.8512396694214875e-07, 'rewards/chosen': 0.004559136927127838, 'rewards/rejected': -0.019618798047304153, 'rewards/accuracies': 0.5, 'rewards/margins': 0.02417793497443199, 'policy_logps/rejected': -430.0970458984375, 'policy_logps/chosen': -397.33367919921875, 'referece_logps/rejected': -429.90087890625, 'referece_logps/chosen': -397.3792724609375, 'logits/rejected': 0.4160284399986267, 'logits/chosen': 0.4423489272594452, 'epoch': 0.03}
[2024-04-05 15:52:54,342] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  0%|          | 71/16104 [19:10<70:01:33, 15.72s/it]
{'loss': 0.6892, 'learning_rate': 2.9338842975206613e-07, 'rewards/chosen': 0.006088447757065296, 'rewards/rejected': 0.0032720565795898438, 'rewards/accuracies': 0.375, 'rewards/margins': 0.0028163925744593143, 'policy_logps/rejected': -425.0792236328125, 'policy_logps/chosen': -464.1962585449219, 'referece_logps/rejected': -425.11199951171875, 'referece_logps/chosen': -464.257080078125, 'logits/rejected': -0.7568663954734802, 'logits/chosen': -0.7943547964096069, 'epoch': 0.03}

  0%|          | 72/16104 [19:31<76:23:47, 17.15s/it]

  0%|          | 73/16104 [19:48<76:09:35, 17.10s/it]

  0%|          | 74/16104 [20:03<73:14:22, 16.45s/it]

  0%|          | 75/16104 [20:24<78:54:07, 17.72s/it]


  0%|          | 77/16104 [21:05<85:47:56, 19.27s/it]
{'loss': 0.6904, 'learning_rate': 3.1818181818181815e-07, 'rewards/chosen': -0.0003854753449559212, 'rewards/rejected': 0.03778906166553497, 'rewards/accuracies': 0.5, 'rewards/margins': -0.03817453980445862, 'policy_logps/rejected': -439.12664794921875, 'policy_logps/chosen': -435.63409423828125, 'referece_logps/rejected': -439.5045471191406, 'referece_logps/chosen': -435.6302185058594, 'logits/rejected': -0.20990288257598877, 'logits/chosen': -0.10315164178609848, 'epoch': 0.03}

  0%|          | 78/16104 [21:26<87:57:18, 19.76s/it]

  0%|          | 79/16104 [21:50<94:05:57, 21.14s/it]

  0%|          | 80/16104 [22:06<87:48:38, 19.73s/it]

  1%|          | 81/16104 [22:18<76:51:51, 17.27s/it]

  1%|          | 82/16104 [22:31<71:40:57, 16.11s/it]

  1%|          | 83/16104 [22:42<64:25:40, 14.48s/it]


  1%|          | 85/16104 [23:05<57:02:53, 12.82s/it]
{'loss': 0.6919, 'learning_rate': 3.512396694214876e-07, 'rewards/chosen': 0.0011283895000815392, 'rewards/rejected': -0.00644950894638896, 'rewards/accuracies': 0.5, 'rewards/margins': 0.007577897049486637, 'policy_logps/rejected': -454.5791015625, 'policy_logps/chosen': -353.35882568359375, 'referece_logps/rejected': -454.5146179199219, 'referece_logps/chosen': -353.3701171875, 'logits/rejected': -0.7870098352432251, 'logits/chosen': -0.7743498682975769, 'epoch': 0.03}


  1%|          | 87/16104 [23:33<58:40:03, 13.19s/it]
{'loss': 0.6948, 'learning_rate': 3.5950413223140497e-07, 'rewards/chosen': -0.011156845837831497, 'rewards/rejected': 0.028149034827947617, 'rewards/accuracies': 0.375, 'rewards/margins': -0.039305880665779114, 'policy_logps/rejected': -606.6265869140625, 'policy_logps/chosen': -442.4960021972656, 'referece_logps/rejected': -606.9080810546875, 'referece_logps/chosen': -442.38446044921875, 'logits/rejected': -0.35683634877204895, 'logits/chosen': -0.08303218334913254, 'epoch': 0.03}

  1%|          | 88/16104 [23:47<60:04:37, 13.50s/it]

  1%|          | 89/16104 [24:01<60:42:02, 13.64s/it]

  1%|          | 90/16104 [24:15<61:07:36, 13.74s/it]

  1%|          | 91/16104 [24:28<59:56:10, 13.47s/it]

  1%|          | 92/16104 [24:42<60:21:33, 13.57s/it]

  1%|          | 93/16104 [25:03<70:57:36, 15.96s/it]

  1%|          | 94/16104 [25:21<72:48:57, 16.37s/it]

  1%|          | 95/16104 [25:36<71:58:42, 16.19s/it]

  1%|          | 96/16104 [25:54<73:47:27, 16.59s/it]

  1%|          | 97/16104 [26:06<67:26:52, 15.17s/it]


  1%|          | 99/16104 [26:33<65:15:05, 14.68s/it]
{'loss': 0.6837, 'learning_rate': 4.090909090909091e-07, 'rewards/chosen': 0.05657463148236275, 'rewards/rejected': 0.039221715182065964, 'rewards/accuracies': 0.375, 'rewards/margins': 0.017352910712361336, 'policy_logps/rejected': -278.2629699707031, 'policy_logps/chosen': -593.1070556640625, 'referece_logps/rejected': -278.6551818847656, 'referece_logps/chosen': -593.6727905273438, 'logits/rejected': -0.2804045081138611, 'logits/chosen': -0.4792664051055908, 'epoch': 0.04}

  1%|          | 100/16104 [26:45<61:53:38, 13.92s/it]


  1%|          | 102/16104 [27:19<67:07:41, 15.10s/it]
{'loss': 0.6854, 'learning_rate': 4.2148760330578507e-07, 'rewards/chosen': 0.0029602053109556437, 'rewards/rejected': 0.026598740369081497, 'rewards/accuracies': 0.375, 'rewards/margins': -0.023638535290956497, 'policy_logps/rejected': -541.2357177734375, 'policy_logps/chosen': -440.79534912109375, 'referece_logps/rejected': -541.501708984375, 'referece_logps/chosen': -440.8249206542969, 'logits/rejected': -1.0040034055709839, 'logits/chosen': -0.8203614950180054, 'epoch': 0.04}

  1%|          | 103/16104 [27:36<69:42:58, 15.69s/it]

  1%|          | 104/16104 [27:53<71:14:45, 16.03s/it]

  1%|          | 105/16104 [28:13<76:24:15, 17.19s/it]

  1%|          | 106/16104 [28:32<79:16:14, 17.84s/it]

  1%|          | 107/16104 [28:49<77:44:12, 17.49s/it]

  1%|          | 108/16104 [29:05<75:40:05, 17.03s/it]


  1%|          | 110/16104 [29:29<65:24:52, 14.72s/it]
{'loss': 0.699, 'learning_rate': 4.545454545454545e-07, 'rewards/chosen': 0.010050964541733265, 'rewards/rejected': 0.029024504125118256, 'rewards/accuracies': 0.625, 'rewards/margins': -0.018973540514707565, 'policy_logps/rejected': -371.1156005859375, 'policy_logps/chosen': -408.130126953125, 'referece_logps/rejected': -371.40582275390625, 'referece_logps/chosen': -408.2306823730469, 'logits/rejected': -0.5098263621330261, 'logits/chosen': -0.5175761580467224, 'epoch': 0.04}

  1%|          | 111/16104 [29:45<66:35:59, 14.99s/it]
[2024-04-05 16:04:03,048] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 112/16104 [30:06<74:25:46, 16.76s/it]
[2024-04-05 16:04:17,282] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 113/16104 [30:20<71:03:54, 16.00s/it]


  1%|          | 115/16104 [30:59<80:57:52, 18.23s/it]
{'loss': 0.6977, 'learning_rate': 4.7520661157024796e-07, 'rewards/chosen': 0.024842262268066406, 'rewards/rejected': 0.027565957978367805, 'rewards/accuracies': 0.625, 'rewards/margins': -0.00272369384765625, 'policy_logps/rejected': -486.08251953125, 'policy_logps/chosen': -547.7415161132812, 'referece_logps/rejected': -486.358154296875, 'referece_logps/chosen': -547.989990234375, 'logits/rejected': 0.07280132174491882, 'logits/chosen': 0.21128791570663452, 'epoch': 0.04}

  1%|          | 116/16104 [31:16<79:07:37, 17.82s/it]


  1%|          | 118/16104 [31:55<83:26:17, 18.79s/it]
{'loss': 0.6926, 'learning_rate': 4.87603305785124e-07, 'rewards/chosen': 0.01428904477506876, 'rewards/rejected': -0.006120013538748026, 'rewards/accuracies': 0.5, 'rewards/margins': 0.020409058779478073, 'policy_logps/rejected': -288.1432800292969, 'policy_logps/chosen': -255.51812744140625, 'referece_logps/rejected': -288.0820617675781, 'referece_logps/chosen': -255.66099548339844, 'logits/rejected': -0.636045515537262, 'logits/chosen': -0.5684163570404053, 'epoch': 0.04}

  1%|          | 119/16104 [32:16<86:50:32, 19.56s/it]

  1%|          | 120/16104 [32:36<87:21:55, 19.68s/it]

  1%|          | 121/16104 [32:54<85:01:47, 19.15s/it]

  1%|          | 122/16104 [33:16<88:31:13, 19.94s/it]

  1%|          | 123/16104 [33:29<79:33:54, 17.92s/it]

  1%|          | 124/16104 [33:43<73:34:55, 16.58s/it]

  1%|          | 125/16104 [33:59<73:30:14, 16.56s/it]

  1%|          | 126/16104 [34:19<78:09:37, 17.61s/it]
[2024-04-05 16:08:40,298] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 127/16104 [34:43<86:14:14, 19.43s/it]

  1%|          | 128/16104 [35:07<91:49:48, 20.69s/it]

  1%|          | 129/16104 [35:24<87:33:18, 19.73s/it]

  1%|          | 130/16104 [35:42<85:06:57, 19.18s/it]

  1%|          | 131/16104 [35:58<80:27:23, 18.13s/it]
[2024-04-05 16:10:09,039] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 132/16104 [36:12<74:59:24, 16.90s/it]

  1%|          | 133/16104 [36:32<79:13:48, 17.86s/it]

  1%|          | 134/16104 [36:53<83:30:36, 18.83s/it]

  1%|          | 135/16104 [37:10<81:43:14, 18.42s/it]

  1%|          | 136/16104 [37:26<77:31:31, 17.48s/it]
[2024-04-05 16:11:40,097] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 137/16104 [37:43<77:03:31, 17.37s/it]

{'loss': 0.7032, 'learning_rate': 5.702479338842975e-07, 'rewards/chosen': 0.060724832117557526, 'rewards/rejected': 0.03239097446203232, 'rewards/accuracies': 0.625, 'rewards/margins': 0.028333857655525208, 'policy_logps/rejected': -439.496826171875, 'policy_logps/chosen': -440.4476013183594, 'referece_logps/rejected': -439.82073974609375, 'referece_logps/chosen': -441.0548400878906, 'logits/rejected': 0.24286891520023346, 'logits/chosen': 0.29830625653266907, 'epoch': 0.05}
  1%|          | 138/16104 [38:00<76:27:05, 17.24s/it]

  1%|          | 139/16104 [38:12<69:59:18, 15.78s/it]

  1%|          | 140/16104 [38:33<76:20:31, 17.22s/it]

  1%|          | 141/16104 [38:48<73:11:17, 16.51s/it]

  1%|          | 142/16104 [38:59<66:44:13, 15.05s/it]

  1%|          | 143/16104 [39:16<69:32:06, 15.68s/it]

  1%|          | 144/16104 [39:28<64:18:24, 14.51s/it]

  1%|          | 145/16104 [39:51<74:51:37, 16.89s/it]

  1%|          | 146/16104 [40:08<76:13:05, 17.19s/it]

  1%|          | 147/16104 [40:27<77:39:21, 17.52s/it]
[2024-04-05 16:14:45,064] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 148/16104 [40:48<82:20:11, 18.58s/it]
[2024-04-05 16:15:02,162] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 149/16104 [41:05<80:21:49, 18.13s/it]

  1%|          | 150/16104 [41:25<83:28:55, 18.84s/it]

  1%|          | 151/16104 [41:47<87:43:16, 19.80s/it]
[2024-04-05 16:15:58,645] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 152/16104 [42:01<79:58:27, 18.05s/it]

  1%|          | 153/16104 [42:14<72:54:58, 16.46s/it]

  1%|          | 154/16104 [42:27<68:10:41, 15.39s/it]

  1%|          | 155/16104 [42:39<64:09:01, 14.48s/it]

  1%|          | 156/16104 [42:55<65:17:31, 14.74s/it]

  1%|          | 157/16104 [43:06<60:17:17, 13.61s/it]

  1%|          | 158/16104 [43:18<58:02:36, 13.10s/it]

  1%|          | 159/16104 [43:32<60:07:10, 13.57s/it]

  1%|          | 160/16104 [43:45<58:26:03, 13.19s/it]

  1%|          | 161/16104 [43:58<58:07:08, 13.12s/it]

  1%|          | 162/16104 [44:16<65:17:46, 14.75s/it]

  1%|          | 163/16104 [44:34<68:54:40, 15.56s/it]

  1%|          | 164/16104 [44:51<71:14:56, 16.09s/it]

  1%|          | 165/16104 [45:05<68:56:10, 15.57s/it]

  1%|          | 166/16104 [45:22<70:09:16, 15.85s/it]
[2024-04-05 16:19:40,403] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 167/16104 [45:43<77:32:30, 17.52s/it]

  1%|          | 168/16104 [46:02<79:35:04, 17.98s/it]

  1%|          | 169/16104 [46:13<69:46:58, 15.77s/it]

  1%|          | 170/16104 [46:24<63:10:55, 14.27s/it]

  1%|          | 171/16104 [46:34<58:31:24, 13.22s/it]

  1%|          | 172/16104 [46:47<57:26:54, 12.98s/it]

  1%|          | 173/16104 [47:02<61:05:33, 13.81s/it]

  1%|          | 174/16104 [47:16<60:35:25, 13.69s/it]

  1%|          | 175/16104 [47:31<61:58:22, 14.01s/it]

  1%|          | 176/16104 [47:41<57:35:40, 13.02s/it]

  1%|          | 177/16104 [47:52<54:37:00, 12.35s/it]

  1%|          | 178/16104 [48:12<65:11:46, 14.74s/it]
[2024-04-05 16:22:31,260] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 179/16104 [48:34<74:11:10, 16.77s/it]
[2024-04-05 16:22:42,690] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 180/16104 [48:45<67:05:37, 15.17s/it]

  1%|          | 181/16104 [49:10<79:16:52, 17.92s/it]

  1%|          | 182/16104 [49:28<79:15:09, 17.92s/it]

  1%|          | 183/16104 [49:42<74:00:59, 16.74s/it]

  1%|          | 184/16104 [49:59<74:52:59, 16.93s/it]

  1%|          | 185/16104 [50:11<68:11:54, 15.42s/it]

  1%|          | 186/16104 [50:33<77:00:39, 17.42s/it]

  1%|          | 187/16104 [50:48<73:17:38, 16.58s/it]

  1%|          | 188/16104 [51:10<80:39:03, 18.24s/it]

  1%|          | 189/16104 [51:25<76:16:21, 17.25s/it]

  1%|          | 190/16104 [51:35<67:35:24, 15.29s/it]

  1%|          | 191/16104 [51:47<62:09:54, 14.06s/it]

  1%|          | 192/16104 [52:03<65:10:08, 14.74s/it]


  1%|          | 194/16104 [52:40<74:58:59, 16.97s/it]
[2024-04-05 16:26:37,445] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 195/16104 [52:53<70:04:28, 15.86s/it]
[2024-04-05 16:26:50,713] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 196/16104 [53:10<70:21:00, 15.92s/it]

  1%|          | 197/16104 [53:24<68:42:38, 15.55s/it]
{'loss': 0.6879, 'learning_rate': 8.140495867768594e-07, 'rewards/chosen': 0.12567482888698578, 'rewards/rejected': 0.09165306389331818, 'rewards/accuracies': 0.625, 'rewards/margins': 0.034021757543087006, 'policy_logps/rejected': -589.1362915039062, 'policy_logps/chosen': -546.3989868164062, 'referece_logps/rejected': -590.0528564453125, 'referece_logps/chosen': -547.6557006835938, 'logits/rejected': 0.7416821718215942, 'logits/chosen': 0.6481357216835022, 'epoch': 0.07}


  1%|          | 199/16104 [53:47<59:53:31, 13.56s/it]

  1%|          | 200/16104 [54:03<62:32:18, 14.16s/it]

  1%|          | 201/16104 [54:19<64:50:50, 14.68s/it]

  1%|▏         | 202/16104 [54:40<73:15:02, 16.58s/it]

  1%|▏         | 203/16104 [54:56<72:26:02, 16.40s/it]

  1%|▏         | 204/16104 [55:16<77:47:04, 17.61s/it]
[2024-04-05 16:29:13,390] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 205/16104 [55:28<70:32:36, 15.97s/it]

  1%|▏         | 206/16104 [55:48<75:32:06, 17.10s/it]

  1%|▏         | 207/16104 [56:10<81:27:35, 18.45s/it]

  1%|▏         | 208/16104 [56:22<73:43:48, 16.70s/it]

  1%|▏         | 209/16104 [56:46<82:49:02, 18.76s/it]

  1%|▏         | 210/16104 [57:04<82:39:24, 18.72s/it]

  1%|▏         | 211/16104 [57:15<72:22:42, 16.39s/it]

  1%|▏         | 212/16104 [57:32<72:17:06, 16.37s/it]

  1%|▏         | 213/16104 [57:47<70:27:49, 15.96s/it]

  1%|▏         | 214/16104 [57:59<66:07:44, 14.98s/it]

  1%|▏         | 215/16104 [58:14<65:37:27, 14.87s/it]

  1%|▏         | 216/16104 [58:29<65:51:14, 14.92s/it]

  1%|▏         | 217/16104 [58:40<60:13:50, 13.65s/it]

  1%|▏         | 218/16104 [58:51<56:28:32, 12.80s/it]

  1%|▏         | 219/16104 [59:03<55:59:00, 12.69s/it]

  1%|▏         | 220/16104 [59:16<56:30:46, 12.81s/it]

  1%|▏         | 221/16104 [59:34<63:51:36, 14.47s/it]
{'loss': 0.6835, 'learning_rate': 9.132231404958677e-07, 'rewards/chosen': 0.0967317596077919, 'rewards/rejected': -0.003415728220716119, 'rewards/accuracies': 0.875, 'rewards/margins': 0.10014748573303223, 'policy_logps/rejected': -362.2528991699219, 'policy_logps/chosen': -377.06976318359375, 'referece_logps/rejected': -362.21875, 'referece_logps/chosen': -378.0370788574219, 'logits/rejected': -0.7506409883499146, 'logits/chosen': -0.8002253174781799, 'epoch': 0.08}


  1%|▏         | 223/16104 [1:00:11<70:22:23, 15.95s/it]
{'loss': 0.7001, 'learning_rate': 9.214876033057852e-07, 'rewards/chosen': 0.08097973465919495, 'rewards/rejected': 0.14372901618480682, 'rewards/accuracies': 0.25, 'rewards/margins': -0.06274928897619247, 'policy_logps/rejected': -617.6925659179688, 'policy_logps/chosen': -414.26177978515625, 'referece_logps/rejected': -619.1299438476562, 'referece_logps/chosen': -415.0715637207031, 'logits/rejected': -0.015289101749658585, 'logits/chosen': 0.035452719777822495, 'epoch': 0.08}


  1%|▏         | 225/16104 [1:00:45<72:34:35, 16.45s/it]

  1%|▏         | 226/16104 [1:01:06<78:28:29, 17.79s/it]

  1%|▏         | 227/16104 [1:01:27<82:16:50, 18.66s/it]

  1%|▏         | 228/16104 [1:01:45<82:09:14, 18.63s/it]

  1%|▏         | 229/16104 [1:02:04<81:56:16, 18.58s/it]

  1%|▏         | 230/16104 [1:02:16<74:09:31, 16.82s/it]

  1%|▏         | 231/16104 [1:02:32<72:23:04, 16.42s/it]

  1%|▏         | 232/16104 [1:02:48<72:22:36, 16.42s/it]

  1%|▏         | 233/16104 [1:03:10<78:58:02, 17.91s/it]

  1%|▏         | 234/16104 [1:03:31<83:05:56, 18.85s/it]

  1%|▏         | 235/16104 [1:03:48<81:19:17, 18.45s/it]

  1%|▏         | 236/16104 [1:04:10<85:59:00, 19.51s/it]

  1%|▏         | 237/16104 [1:04:33<90:01:30, 20.43s/it]

  1%|▏         | 238/16104 [1:04:54<91:15:18, 20.71s/it]

  1%|▏         | 239/16104 [1:05:09<82:55:52, 18.82s/it]

  1%|▏         | 240/16104 [1:05:29<85:25:57, 19.39s/it]

  1%|▏         | 241/16104 [1:05:47<83:16:26, 18.90s/it]

  2%|▏         | 242/16104 [1:06:02<78:28:51, 17.81s/it]

  2%|▏         | 243/16104 [1:06:24<82:50:47, 18.80s/it]
{'loss': 0.6805, 'learning_rate': 1.0041322314049588e-06, 'rewards/chosen': 0.11773376911878586, 'rewards/rejected': -0.0008442889666184783, 'rewards/accuracies': 0.75, 'rewards/margins': 0.11857806146144867, 'policy_logps/rejected': -449.1421813964844, 'policy_logps/chosen': -522.4786987304688, 'referece_logps/rejected': -449.13372802734375, 'referece_logps/chosen': -523.6560668945312, 'logits/rejected': 1.123684048652649, 'logits/chosen': 0.9974222183227539, 'epoch': 0.09}


  2%|▏         | 245/16104 [1:06:53<71:57:12, 16.33s/it]
{'loss': 0.6842, 'learning_rate': 1.012396694214876e-06, 'rewards/chosen': 0.14602769911289215, 'rewards/rejected': 0.04676666855812073, 'rewards/accuracies': 0.875, 'rewards/margins': 0.09926104545593262, 'policy_logps/rejected': -358.169189453125, 'policy_logps/chosen': -412.2857666015625, 'referece_logps/rejected': -358.6368713378906, 'referece_logps/chosen': -413.74603271484375, 'logits/rejected': -0.0963304191827774, 'logits/chosen': 0.10112470388412476, 'epoch': 0.09}


  2%|▏         | 247/16104 [1:07:22<68:03:24, 15.45s/it]

  2%|▏         | 248/16104 [1:07:38<68:48:51, 15.62s/it]
{'loss': 0.693, 'learning_rate': 1.024793388429752e-06, 'rewards/chosen': 0.3131301999092102, 'rewards/rejected': 0.12993945181369781, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1831907331943512, 'policy_logps/rejected': -353.6522521972656, 'policy_logps/chosen': -494.5619812011719, 'referece_logps/rejected': -354.95166015625, 'referece_logps/chosen': -497.6932678222656, 'logits/rejected': -0.16572506725788116, 'logits/chosen': -0.26331812143325806, 'epoch': 0.09}


  2%|▏         | 250/16104 [1:08:11<72:15:46, 16.41s/it]
{'loss': 0.6494, 'learning_rate': 1.0330578512396692e-06, 'rewards/chosen': 0.07568559050559998, 'rewards/rejected': 0.056867312639951706, 'rewards/accuracies': 0.625, 'rewards/margins': 0.018818281590938568, 'policy_logps/rejected': -262.0968322753906, 'policy_logps/chosen': -292.94061279296875, 'referece_logps/rejected': -262.66552734375, 'referece_logps/chosen': -293.6974792480469, 'logits/rejected': -0.4811742901802063, 'logits/chosen': -0.24093249440193176, 'epoch': 0.09}

  2%|▏         | 251/16104 [1:08:34<82:06:34, 18.65s/it]


  2%|▏         | 253/16104 [1:09:09<80:24:26, 18.26s/it]
{'loss': 0.6595, 'learning_rate': 1.0454545454545454e-06, 'rewards/chosen': 0.06933966279029846, 'rewards/rejected': 0.09625701606273651, 'rewards/accuracies': 0.125, 'rewards/margins': -0.026917362585663795, 'policy_logps/rejected': -444.2342224121094, 'policy_logps/chosen': -429.4378356933594, 'referece_logps/rejected': -445.1968078613281, 'referece_logps/chosen': -430.1312255859375, 'logits/rejected': 0.319362610578537, 'logits/chosen': 0.2743673324584961, 'epoch': 0.09}


  2%|▏         | 255/16104 [1:09:45<80:27:40, 18.28s/it]
{'loss': 0.6657, 'learning_rate': 1.0537190082644626e-06, 'rewards/chosen': 0.08341418206691742, 'rewards/rejected': 0.08997106552124023, 'rewards/accuracies': 0.625, 'rewards/margins': -0.0065568918362259865, 'policy_logps/rejected': -407.50421142578125, 'policy_logps/chosen': -407.82794189453125, 'referece_logps/rejected': -408.4039306640625, 'referece_logps/chosen': -408.662109375, 'logits/rejected': -0.3430479168891907, 'logits/chosen': -0.2090311348438263, 'epoch': 0.1}


  2%|▏         | 257/16104 [1:10:17<73:34:11, 16.71s/it]

  2%|▏         | 258/16104 [1:10:40<81:32:21, 18.52s/it]

  2%|▏         | 259/16104 [1:10:59<83:28:37, 18.97s/it]

  2%|▏         | 260/16104 [1:11:11<74:04:32, 16.83s/it]

  2%|▏         | 261/16104 [1:11:27<72:48:47, 16.55s/it]
{'loss': 0.7027, 'learning_rate': 1.0785123966942149e-06, 'rewards/chosen': -0.008210085332393646, 'rewards/rejected': -0.012525946833193302, 'rewards/accuracies': 0.625, 'rewards/margins': 0.004315856844186783, 'policy_logps/rejected': -372.83203125, 'policy_logps/chosen': -248.89620971679688, 'referece_logps/rejected': -372.706787109375, 'referece_logps/chosen': -248.8140869140625, 'logits/rejected': -0.6991022229194641, 'logits/chosen': -0.6040495038032532, 'epoch': 0.1}


  2%|▏         | 263/16104 [1:12:08<81:12:00, 18.45s/it]

  2%|▏         | 264/16104 [1:12:28<83:10:33, 18.90s/it]
{'loss': 0.6602, 'learning_rate': 1.0909090909090908e-06, 'rewards/chosen': 0.024252889677882195, 'rewards/rejected': -0.05013694241642952, 'rewards/accuracies': 0.75, 'rewards/margins': 0.07438983768224716, 'policy_logps/rejected': -569.4278564453125, 'policy_logps/chosen': -523.3817749023438, 'referece_logps/rejected': -568.926513671875, 'referece_logps/chosen': -523.6243286132812, 'logits/rejected': -0.7354041934013367, 'logits/chosen': -0.5679381489753723, 'epoch': 0.1}


  2%|▏         | 266/16104 [1:12:57<74:29:23, 16.93s/it]
{'loss': 0.6893, 'learning_rate': 1.099173553719008e-06, 'rewards/chosen': 0.2664255201816559, 'rewards/rejected': 0.18967457115650177, 'rewards/accuracies': 0.625, 'rewards/margins': 0.07675094902515411, 'policy_logps/rejected': -466.1810302734375, 'policy_logps/chosen': -518.878662109375, 'referece_logps/rejected': -468.0777587890625, 'referece_logps/chosen': -521.5429077148438, 'logits/rejected': 0.03327185660600662, 'logits/chosen': 0.19648593664169312, 'epoch': 0.1}


  2%|▏         | 268/16104 [1:13:31<74:25:12, 16.92s/it]

  2%|▏         | 269/16104 [1:13:48<74:37:40, 16.97s/it]

  2%|▏         | 270/16104 [1:14:01<69:44:30, 15.86s/it]

  2%|▏         | 271/16104 [1:14:23<77:42:33, 17.67s/it]
{'loss': 0.6457, 'learning_rate': 1.1198347107438016e-06, 'rewards/chosen': 0.14107723534107208, 'rewards/rejected': 0.10758829116821289, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03348894044756889, 'policy_logps/rejected': -434.398681640625, 'policy_logps/chosen': -378.27783203125, 'referece_logps/rejected': -435.474609375, 'referece_logps/chosen': -379.6886291503906, 'logits/rejected': -0.5026945471763611, 'logits/chosen': -0.5407424569129944, 'epoch': 0.1}


  2%|▏         | 273/16104 [1:14:58<76:58:09, 17.50s/it]
{'loss': 0.6869, 'learning_rate': 1.128099173553719e-06, 'rewards/chosen': 0.1076938658952713, 'rewards/rejected': 0.11205405741930008, 'rewards/accuracies': 0.375, 'rewards/margins': -0.004360198974609375, 'policy_logps/rejected': -296.8912048339844, 'policy_logps/chosen': -350.3766784667969, 'referece_logps/rejected': -298.0117492675781, 'referece_logps/chosen': -351.45361328125, 'logits/rejected': 0.5406874418258667, 'logits/chosen': 0.45205575227737427, 'epoch': 0.1}


  2%|▏         | 275/16104 [1:15:27<70:06:16, 15.94s/it]
{'loss': 0.6762, 'learning_rate': 1.1363636363636364e-06, 'rewards/chosen': 0.2429424524307251, 'rewards/rejected': 0.18542443215847015, 'rewards/accuracies': 0.625, 'rewards/margins': 0.05751800537109375, 'policy_logps/rejected': -440.87310791015625, 'policy_logps/chosen': -514.997802734375, 'referece_logps/rejected': -442.7273254394531, 'referece_logps/chosen': -517.42724609375, 'logits/rejected': -0.17012569308280945, 'logits/chosen': -0.11210498958826065, 'epoch': 0.1}


  2%|▏         | 277/16104 [1:15:59<69:42:42, 15.86s/it]
{'loss': 0.6787, 'learning_rate': 1.1446280991735536e-06, 'rewards/chosen': 0.2553424835205078, 'rewards/rejected': 0.04091015085577965, 'rewards/accuracies': 1.0, 'rewards/margins': 0.21443234384059906, 'policy_logps/rejected': -284.097412109375, 'policy_logps/chosen': -471.0805358886719, 'referece_logps/rejected': -284.50653076171875, 'referece_logps/chosen': -473.63397216796875, 'logits/rejected': -0.5909595489501953, 'logits/chosen': -0.7001581788063049, 'epoch': 0.1}


  2%|▏         | 279/16104 [1:16:35<74:27:11, 16.94s/it]

  2%|▏         | 280/16104 [1:16:48<68:26:09, 15.57s/it]
{'loss': 0.6616, 'learning_rate': 1.1570247933884296e-06, 'rewards/chosen': 0.15809468924999237, 'rewards/rejected': 0.13966892659664154, 'rewards/accuracies': 0.625, 'rewards/margins': 0.018425749614834785, 'policy_logps/rejected': -357.0432434082031, 'policy_logps/chosen': -373.7357177734375, 'referece_logps/rejected': -358.43988037109375, 'referece_logps/chosen': -375.3166809082031, 'logits/rejected': -0.22813986241817474, 'logits/chosen': -0.16762980818748474, 'epoch': 0.1}

  2%|▏         | 281/16104 [1:17:09<75:48:38, 17.25s/it]

  2%|▏         | 282/16104 [1:17:25<74:21:46, 16.92s/it]

  2%|▏         | 283/16104 [1:17:37<67:31:40, 15.37s/it]


  2%|▏         | 285/16104 [1:18:21<83:09:31, 18.92s/it]

  2%|▏         | 286/16104 [1:18:42<85:54:13, 19.55s/it]
{'loss': 0.6738, 'learning_rate': 1.1818181818181818e-06, 'rewards/chosen': 0.2013172209262848, 'rewards/rejected': 0.1657579392194748, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0355592742562294, 'policy_logps/rejected': -467.87823486328125, 'policy_logps/chosen': -488.08734130859375, 'referece_logps/rejected': -469.53582763671875, 'referece_logps/chosen': -490.1005554199219, 'logits/rejected': 0.36202600598335266, 'logits/chosen': 0.33653324842453003, 'epoch': 0.11}


  2%|▏         | 288/16104 [1:19:20<85:04:49, 19.37s/it]
{'loss': 0.6649, 'learning_rate': 1.190082644628099e-06, 'rewards/chosen': 0.1569330245256424, 'rewards/rejected': 0.17814978957176208, 'rewards/accuracies': 0.5, 'rewards/margins': -0.021216772496700287, 'policy_logps/rejected': -419.5684814453125, 'policy_logps/chosen': -421.9371337890625, 'referece_logps/rejected': -421.3499755859375, 'referece_logps/chosen': -423.5064697265625, 'logits/rejected': 0.44613075256347656, 'logits/chosen': 0.4999905824661255, 'epoch': 0.11}


  2%|▏         | 290/16104 [1:19:58<85:39:45, 19.50s/it]

  2%|▏         | 291/16104 [1:20:20<88:14:42, 20.09s/it]

  2%|▏         | 292/16104 [1:20:40<88:47:54, 20.22s/it]
{'loss': 0.6704, 'learning_rate': 1.2066115702479338e-06, 'rewards/chosen': 0.07517404109239578, 'rewards/rejected': 0.07907132804393768, 'rewards/accuracies': 0.625, 'rewards/margins': -0.00389728881418705, 'policy_logps/rejected': -328.3326721191406, 'policy_logps/chosen': -313.1656494140625, 'referece_logps/rejected': -329.1233825683594, 'referece_logps/chosen': -313.9173889160156, 'logits/rejected': -0.27252113819122314, 'logits/chosen': -0.09457260370254517, 'epoch': 0.11}

  2%|▏         | 293/16104 [1:20:51<76:11:10, 17.35s/it]


  2%|▏         | 295/16104 [1:21:31<82:47:55, 18.85s/it]

  2%|▏         | 296/16104 [1:21:48<80:17:59, 18.29s/it]
{'loss': 0.6959, 'learning_rate': 1.2231404958677686e-06, 'rewards/chosen': 0.331787109375, 'rewards/rejected': 0.21110154688358307, 'rewards/accuracies': 0.875, 'rewards/margins': 0.12068558484315872, 'policy_logps/rejected': -466.25225830078125, 'policy_logps/chosen': -620.7529907226562, 'referece_logps/rejected': -468.36328125, 'referece_logps/chosen': -624.0708618164062, 'logits/rejected': -0.6137160658836365, 'logits/chosen': -0.8493032455444336, 'epoch': 0.11}

  2%|▏         | 297/16104 [1:21:59<70:33:57, 16.07s/it]


  2%|▏         | 299/16104 [1:22:37<76:47:32, 17.49s/it]
{'loss': 0.6522, 'learning_rate': 1.2355371900826447e-06, 'rewards/chosen': 0.021669674664735794, 'rewards/rejected': 0.07122553884983063, 'rewards/accuracies': 0.375, 'rewards/margins': -0.04955587163567543, 'policy_logps/rejected': -502.4957275390625, 'policy_logps/chosen': -451.3583984375, 'referece_logps/rejected': -503.2080383300781, 'referece_logps/chosen': -451.57513427734375, 'logits/rejected': -0.5869358777999878, 'logits/chosen': -0.6558918952941895, 'epoch': 0.11}


  2%|▏         | 301/16104 [1:23:16<81:20:37, 18.53s/it]
{'loss': 0.682, 'learning_rate': 1.243801652892562e-06, 'rewards/chosen': 0.04204884171485901, 'rewards/rejected': 0.08374481648206711, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0416959747672081, 'policy_logps/rejected': -377.8539733886719, 'policy_logps/chosen': -280.3526306152344, 'referece_logps/rejected': -378.6914367675781, 'referece_logps/chosen': -280.77313232421875, 'logits/rejected': -0.5862890481948853, 'logits/chosen': -0.47524476051330566, 'epoch': 0.11}


  2%|▏         | 303/16104 [1:23:57<84:22:33, 19.22s/it]

  2%|▏         | 304/16104 [1:24:16<84:02:12, 19.15s/it]

  2%|▏         | 305/16104 [1:24:32<80:50:01, 18.42s/it]

  2%|▏         | 306/16104 [1:24:53<83:26:31, 19.01s/it]

  2%|▏         | 307/16104 [1:25:14<85:54:41, 19.58s/it]

  2%|▏         | 308/16104 [1:25:32<84:23:22, 19.23s/it]
{'loss': 0.6459, 'learning_rate': 1.2727272727272726e-06, 'rewards/chosen': 0.243072509765625, 'rewards/rejected': 0.1208585798740387, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1222139298915863, 'policy_logps/rejected': -406.9931335449219, 'policy_logps/chosen': -512.1176147460938, 'referece_logps/rejected': -408.20172119140625, 'referece_logps/chosen': -514.54833984375, 'logits/rejected': -0.40606918931007385, 'logits/chosen': -0.40345075726509094, 'epoch': 0.11}

  2%|▏         | 309/16104 [1:25:53<86:35:50, 19.74s/it]


  2%|▏         | 311/16104 [1:26:30<85:18:20, 19.45s/it]

  2%|▏         | 312/16104 [1:26:51<86:07:31, 19.63s/it]

  2%|▏         | 313/16104 [1:27:04<77:40:53, 17.71s/it]

  2%|▏         | 314/16104 [1:27:16<71:00:43, 16.19s/it]
{'loss': 0.6705, 'learning_rate': 1.2975206611570246e-06, 'rewards/chosen': 0.2622974216938019, 'rewards/rejected': 0.1410580724477768, 'rewards/accuracies': 0.5, 'rewards/margins': 0.12123937904834747, 'policy_logps/rejected': -475.4401550292969, 'policy_logps/chosen': -560.1857299804688, 'referece_logps/rejected': -476.8507080078125, 'referece_logps/chosen': -562.8086547851562, 'logits/rejected': -0.7424487471580505, 'logits/chosen': -0.7475484013557434, 'epoch': 0.12}

  2%|▏         | 315/16104 [1:27:27<63:48:56, 14.55s/it]


  2%|▏         | 317/16104 [1:28:03<70:49:04, 16.15s/it]

  2%|▏         | 318/16104 [1:28:26<80:33:26, 18.37s/it]

  2%|▏         | 319/16104 [1:28:38<72:12:28, 16.47s/it]
{'loss': 0.6602, 'learning_rate': 1.318181818181818e-06, 'rewards/chosen': 0.31001532077789307, 'rewards/rejected': 0.24439993500709534, 'rewards/accuracies': 0.75, 'rewards/margins': 0.06561537832021713, 'policy_logps/rejected': -302.4364929199219, 'policy_logps/chosen': -481.1070251464844, 'referece_logps/rejected': -304.8804931640625, 'referece_logps/chosen': -484.2071838378906, 'logits/rejected': 0.20761623978614807, 'logits/chosen': 0.3453359603881836, 'epoch': 0.12}


  2%|▏         | 321/16104 [1:29:01<60:41:58, 13.85s/it]
{'loss': 0.6551, 'learning_rate': 1.3264462809917355e-06, 'rewards/chosen': 0.04900326952338219, 'rewards/rejected': -0.0060367584228515625, 'rewards/accuracies': 0.625, 'rewards/margins': 0.05504003167152405, 'policy_logps/rejected': -263.2296142578125, 'policy_logps/chosen': -331.56982421875, 'referece_logps/rejected': -263.1692199707031, 'referece_logps/chosen': -332.0598449707031, 'logits/rejected': -0.17661304771900177, 'logits/chosen': -0.29311200976371765, 'epoch': 0.12}


  2%|▏         | 323/16104 [1:29:45<79:21:25, 18.10s/it]

  2%|▏         | 324/16104 [1:30:07<84:35:26, 19.30s/it]

  2%|▏         | 325/16104 [1:30:18<73:59:32, 16.88s/it]

  2%|▏         | 326/16104 [1:30:40<80:19:37, 18.33s/it]

  2%|▏         | 327/16104 [1:31:01<83:33:38, 19.07s/it]

  2%|▏         | 328/16104 [1:31:18<81:37:46, 18.63s/it]
{'loss': 0.6863, 'learning_rate': 1.3553719008264461e-06, 'rewards/chosen': 0.3246379792690277, 'rewards/rejected': 0.15054799616336823, 'rewards/accuracies': 0.75, 'rewards/margins': 0.17408999800682068, 'policy_logps/rejected': -492.6935729980469, 'policy_logps/chosen': -491.871337890625, 'referece_logps/rejected': -494.19903564453125, 'referece_logps/chosen': -495.1176452636719, 'logits/rejected': -0.2444741278886795, 'logits/chosen': -0.2438931167125702, 'epoch': 0.12}


  2%|▏         | 330/16104 [1:31:57<82:31:03, 18.83s/it]

  2%|▏         | 331/16104 [1:32:14<80:16:14, 18.32s/it]
{'loss': 0.6709, 'learning_rate': 1.3677685950413222e-06, 'rewards/chosen': 0.17245864868164062, 'rewards/rejected': 0.10765992105007172, 'rewards/accuracies': 0.25, 'rewards/margins': 0.0647987350821495, 'policy_logps/rejected': -577.9058837890625, 'policy_logps/chosen': -567.5606689453125, 'referece_logps/rejected': -578.982421875, 'referece_logps/chosen': -569.2852172851562, 'logits/rejected': -0.45573604106903076, 'logits/chosen': -0.562954306602478, 'epoch': 0.12}


  2%|▏         | 333/16104 [1:32:45<72:34:46, 16.57s/it]

  2%|▏         | 334/16104 [1:33:03<74:11:13, 16.94s/it]

  2%|▏         | 335/16104 [1:33:21<76:02:52, 17.36s/it]
{'loss': 0.713, 'learning_rate': 1.384297520661157e-06, 'rewards/chosen': -0.1558235138654709, 'rewards/rejected': -0.06722335517406464, 'rewards/accuracies': 0.375, 'rewards/margins': -0.08860015124082565, 'policy_logps/rejected': -396.890380859375, 'policy_logps/chosen': -448.49932861328125, 'referece_logps/rejected': -396.2181396484375, 'referece_logps/chosen': -446.94110107421875, 'logits/rejected': 0.19855386018753052, 'logits/chosen': 0.13164016604423523, 'epoch': 0.12}


  2%|▏         | 337/16104 [1:33:49<68:45:01, 15.70s/it]

  2%|▏         | 338/16104 [1:34:02<65:59:39, 15.07s/it]
{'loss': 0.6363, 'learning_rate': 1.396694214876033e-06, 'rewards/chosen': 0.03847303241491318, 'rewards/rejected': -0.18349742889404297, 'rewards/accuracies': 0.875, 'rewards/margins': 0.22197046875953674, 'policy_logps/rejected': -361.829833984375, 'policy_logps/chosen': -373.90869140625, 'referece_logps/rejected': -359.994873046875, 'referece_logps/chosen': -374.2934265136719, 'logits/rejected': 0.07767923176288605, 'logits/chosen': -0.020916972309350967, 'epoch': 0.13}

  2%|▏         | 339/16104 [1:34:24<74:26:31, 17.00s/it]

  2%|▏         | 340/16104 [1:34:40<73:33:57, 16.80s/it]

  2%|▏         | 341/16104 [1:34:58<74:50:59, 17.09s/it]


  2%|▏         | 343/16104 [1:35:39<82:01:37, 18.74s/it]

  2%|▏         | 344/16104 [1:35:53<75:18:16, 17.20s/it]

  2%|▏         | 345/16104 [1:36:05<68:39:29, 15.68s/it]
{'loss': 0.6626, 'learning_rate': 1.4256198347107438e-06, 'rewards/chosen': 0.2669617533683777, 'rewards/rejected': 0.19773530960083008, 'rewards/accuracies': 0.625, 'rewards/margins': 0.0692264586687088, 'policy_logps/rejected': -480.7651062011719, 'policy_logps/chosen': -331.5041809082031, 'referece_logps/rejected': -482.7424621582031, 'referece_logps/chosen': -334.17376708984375, 'logits/rejected': -0.27632853388786316, 'logits/chosen': -0.31300032138824463, 'epoch': 0.13}


  2%|▏         | 347/16104 [1:36:39<74:10:28, 16.95s/it]

  2%|▏         | 348/16104 [1:36:51<67:38:58, 15.46s/it]
{'loss': 0.659, 'learning_rate': 1.4380165289256199e-06, 'rewards/chosen': 0.20661793649196625, 'rewards/rejected': 0.01630553975701332, 'rewards/accuracies': 0.75, 'rewards/margins': 0.19031238555908203, 'policy_logps/rejected': -328.8873291015625, 'policy_logps/chosen': -407.9195861816406, 'referece_logps/rejected': -329.0503845214844, 'referece_logps/chosen': -409.9857482910156, 'logits/rejected': -0.2676767110824585, 'logits/chosen': 0.029313646256923676, 'epoch': 0.13}

  2%|▏         | 349/16104 [1:37:14<78:05:20, 17.84s/it]

  2%|▏         | 350/16104 [1:37:26<70:24:24, 16.09s/it]


  2%|▏         | 352/16104 [1:38:05<79:13:23, 18.11s/it]
{'loss': 0.6381, 'learning_rate': 1.4545454545454544e-06, 'rewards/chosen': 0.2888657748699188, 'rewards/rejected': 0.1413125842809677, 'rewards/accuracies': 0.625, 'rewards/margins': 0.14755316078662872, 'policy_logps/rejected': -410.29510498046875, 'policy_logps/chosen': -421.4108581542969, 'referece_logps/rejected': -411.70819091796875, 'referece_logps/chosen': -424.2995300292969, 'logits/rejected': -0.09313143789768219, 'logits/chosen': 0.22840556502342224, 'epoch': 0.13}

  2%|▏         | 353/16104 [1:38:26<82:32:21, 18.86s/it]

  2%|▏         | 354/16104 [1:38:46<84:34:34, 19.33s/it]

  2%|▏         | 355/16104 [1:39:07<85:34:58, 19.56s/it]


  2%|▏         | 357/16104 [1:39:38<77:15:11, 17.66s/it]
{'loss': 0.6541, 'learning_rate': 1.475206611570248e-06, 'rewards/chosen': -0.0005415081977844238, 'rewards/rejected': -0.1414049118757248, 'rewards/accuracies': 0.875, 'rewards/margins': 0.14086341857910156, 'policy_logps/rejected': -334.7558288574219, 'policy_logps/chosen': -321.46234130859375, 'referece_logps/rejected': -333.3417663574219, 'referece_logps/chosen': -321.45697021484375, 'logits/rejected': -0.3050123453140259, 'logits/chosen': -0.29901206493377686, 'epoch': 0.13}

  2%|▏         | 358/16104 [1:39:59<82:03:48, 18.76s/it]


  2%|▏         | 360/16104 [1:40:40<86:01:05, 19.67s/it]

  2%|▏         | 361/16104 [1:40:52<75:56:59, 17.37s/it]

  2%|▏         | 362/16104 [1:41:04<69:16:07, 15.84s/it]

  2%|▏         | 363/16104 [1:41:22<72:05:26, 16.49s/it]

  2%|▏         | 364/16104 [1:41:36<68:49:35, 15.74s/it]
{'loss': 0.6448, 'learning_rate': 1.5041322314049587e-06, 'rewards/chosen': 0.1456693559885025, 'rewards/rejected': 0.1010688841342926, 'rewards/accuracies': 0.625, 'rewards/margins': 0.044600486755371094, 'policy_logps/rejected': -348.3507080078125, 'policy_logps/chosen': -375.52130126953125, 'referece_logps/rejected': -349.36138916015625, 'referece_logps/chosen': -376.9779968261719, 'logits/rejected': -0.46974092721939087, 'logits/chosen': -0.4238361716270447, 'epoch': 0.14}


  2%|▏         | 366/16104 [1:42:03<64:38:30, 14.79s/it]
{'loss': 0.6797, 'learning_rate': 1.512396694214876e-06, 'rewards/chosen': 0.27870866656303406, 'rewards/rejected': 0.16834226250648499, 'rewards/accuracies': 0.75, 'rewards/margins': 0.11036640405654907, 'policy_logps/rejected': -428.45306396484375, 'policy_logps/chosen': -575.073974609375, 'referece_logps/rejected': -430.136474609375, 'referece_logps/chosen': -577.8610229492188, 'logits/rejected': -0.5443583130836487, 'logits/chosen': -0.9255237579345703, 'epoch': 0.14}


  2%|▏         | 368/16104 [1:42:34<63:35:21, 14.55s/it]

  2%|▏         | 369/16104 [1:42:52<68:13:15, 15.61s/it]

  2%|▏         | 370/16104 [1:43:10<72:23:53, 16.57s/it]

  2%|▏         | 371/16104 [1:43:26<70:51:41, 16.21s/it]
{'loss': 0.6627, 'learning_rate': 1.5330578512396693e-06, 'rewards/chosen': 0.2929147481918335, 'rewards/rejected': 0.26303017139434814, 'rewards/accuracies': 0.375, 'rewards/margins': 0.02988462522625923, 'policy_logps/rejected': -478.0381164550781, 'policy_logps/chosen': -472.337890625, 'referece_logps/rejected': -480.6684265136719, 'referece_logps/chosen': -475.2670593261719, 'logits/rejected': 0.15649254620075226, 'logits/chosen': 0.24089685082435608, 'epoch': 0.14}

  2%|▏         | 372/16104 [1:43:47<77:17:45, 17.69s/it]

  2%|▏         | 373/16104 [1:43:59<69:48:28, 15.98s/it]


  2%|▏         | 375/16104 [1:44:31<68:22:56, 15.65s/it]
{'loss': 0.6903, 'learning_rate': 1.549586776859504e-06, 'rewards/chosen': 0.0870402380824089, 'rewards/rejected': 0.13616371154785156, 'rewards/accuracies': 0.25, 'rewards/margins': -0.049123480916023254, 'policy_logps/rejected': -317.5982666015625, 'policy_logps/chosen': -360.76116943359375, 'referece_logps/rejected': -318.9598693847656, 'referece_logps/chosen': -361.631591796875, 'logits/rejected': 0.028880946338176727, 'logits/chosen': 0.0354204922914505, 'epoch': 0.14}


  2%|▏         | 377/16104 [1:45:16<84:08:31, 19.26s/it]

  2%|▏         | 378/16104 [1:45:34<83:13:02, 19.05s/it]
{'loss': 0.6351, 'learning_rate': 1.56198347107438e-06, 'rewards/chosen': 0.1658899337053299, 'rewards/rejected': -0.04991912096738815, 'rewards/accuracies': 0.75, 'rewards/margins': 0.21580906212329865, 'policy_logps/rejected': -420.9033508300781, 'policy_logps/chosen': -410.33660888671875, 'referece_logps/rejected': -420.40411376953125, 'referece_logps/chosen': -411.99554443359375, 'logits/rejected': -0.5767624378204346, 'logits/chosen': -0.4804752469062805, 'epoch': 0.14}

  2%|▏         | 379/16104 [1:45:55<84:54:34, 19.44s/it]


  2%|▏         | 381/16104 [1:46:34<85:50:06, 19.65s/it]
{'loss': 0.666, 'learning_rate': 1.574380165289256e-06, 'rewards/chosen': 0.09869709610939026, 'rewards/rejected': 0.10730677098035812, 'rewards/accuracies': 0.5, 'rewards/margins': -0.008609677664935589, 'policy_logps/rejected': -373.9179382324219, 'policy_logps/chosen': -294.7752380371094, 'referece_logps/rejected': -374.99102783203125, 'referece_logps/chosen': -295.76220703125, 'logits/rejected': -0.7444882988929749, 'logits/chosen': -0.7241472005844116, 'epoch': 0.14}


  2%|▏         | 383/16104 [1:47:13<85:06:45, 19.49s/it]
{'loss': 0.6483, 'learning_rate': 1.5826446280991734e-06, 'rewards/chosen': 0.10086364299058914, 'rewards/rejected': 0.09143085777759552, 'rewards/accuracies': 0.375, 'rewards/margins': 0.009432785212993622, 'policy_logps/rejected': -261.72509765625, 'policy_logps/chosen': -364.51324462890625, 'referece_logps/rejected': -262.6394348144531, 'referece_logps/chosen': -365.5218505859375, 'logits/rejected': -0.33156901597976685, 'logits/chosen': -0.36728113889694214, 'epoch': 0.14}


  2%|▏         | 385/16104 [1:47:46<79:00:01, 18.09s/it]
{'loss': 0.6506, 'learning_rate': 1.5909090909090908e-06, 'rewards/chosen': 0.12742498517036438, 'rewards/rejected': 0.04830551892518997, 'rewards/accuracies': 0.625, 'rewards/margins': 0.0791194811463356, 'policy_logps/rejected': -429.59698486328125, 'policy_logps/chosen': -591.3538818359375, 'referece_logps/rejected': -430.08001708984375, 'referece_logps/chosen': -592.628173828125, 'logits/rejected': -0.13093827664852142, 'logits/chosen': -0.1486777365207672, 'epoch': 0.14}


  2%|▏         | 387/16104 [1:48:10<65:15:58, 14.95s/it]

  2%|▏         | 388/16104 [1:48:26<66:42:59, 15.28s/it]
{'loss': 0.6544, 'learning_rate': 1.603305785123967e-06, 'rewards/chosen': 0.0342676155269146, 'rewards/rejected': -0.05256523936986923, 'rewards/accuracies': 0.75, 'rewards/margins': 0.08683284372091293, 'policy_logps/rejected': -418.171142578125, 'policy_logps/chosen': -414.2654724121094, 'referece_logps/rejected': -417.6455078125, 'referece_logps/chosen': -414.608154296875, 'logits/rejected': -0.5606987476348877, 'logits/chosen': -0.5443412661552429, 'epoch': 0.14}

  2%|▏         | 389/16104 [1:48:41<66:30:44, 15.24s/it]


  2%|▏         | 391/16104 [1:49:17<73:16:53, 16.79s/it]

  2%|▏         | 392/16104 [1:49:29<66:59:12, 15.35s/it]
{'loss': 0.6243, 'learning_rate': 1.6198347107438015e-06, 'rewards/chosen': 0.34209880232810974, 'rewards/rejected': 0.05790939927101135, 'rewards/accuracies': 0.875, 'rewards/margins': 0.2841894328594208, 'policy_logps/rejected': -355.4225769042969, 'policy_logps/chosen': -447.13507080078125, 'referece_logps/rejected': -356.001708984375, 'referece_logps/chosen': -450.5559997558594, 'logits/rejected': -0.08812125027179718, 'logits/chosen': 0.007617250084877014, 'epoch': 0.15}


  2%|▏         | 394/16104 [1:50:12<81:58:44, 18.79s/it]

  2%|▏         | 395/16104 [1:50:31<81:01:47, 18.57s/it]
{'loss': 0.6467, 'learning_rate': 1.6322314049586776e-06, 'rewards/chosen': 0.18398629128932953, 'rewards/rejected': 0.09903448820114136, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08495178818702698, 'policy_logps/rejected': -296.4276428222656, 'policy_logps/chosen': -321.5031433105469, 'referece_logps/rejected': -297.41796875, 'referece_logps/chosen': -323.343017578125, 'logits/rejected': -0.6147198677062988, 'logits/chosen': -0.7154973149299622, 'epoch': 0.15}

  2%|▏         | 396/16104 [1:50:43<73:31:29, 16.85s/it]

  2%|▏         | 397/16104 [1:51:02<75:15:21, 17.25s/it]


  2%|▏         | 399/16104 [1:51:37<76:54:05, 17.63s/it]

  2%|▏         | 400/16104 [1:51:54<76:49:58, 17.61s/it]
{'loss': 0.6648, 'learning_rate': 1.652892561983471e-06, 'rewards/chosen': 0.15973587334156036, 'rewards/rejected': 0.011704543605446815, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1480313241481781, 'policy_logps/rejected': -318.6766052246094, 'policy_logps/chosen': -413.8194274902344, 'referece_logps/rejected': -318.7936706542969, 'referece_logps/chosen': -415.416748046875, 'logits/rejected': -0.6909236907958984, 'logits/chosen': -0.7071980834007263, 'epoch': 0.15}

  2%|▏         | 401/16104 [1:52:14<79:01:04, 18.12s/it]


  3%|▎         | 403/16104 [1:52:38<66:13:00, 15.18s/it]
{'loss': 0.6577, 'learning_rate': 1.665289256198347e-06, 'rewards/chosen': 0.058119021356105804, 'rewards/rejected': 0.006252668797969818, 'rewards/accuracies': 0.625, 'rewards/margins': 0.05186634138226509, 'policy_logps/rejected': -386.59344482421875, 'policy_logps/chosen': -445.36065673828125, 'referece_logps/rejected': -386.65594482421875, 'referece_logps/chosen': -445.94183349609375, 'logits/rejected': 0.6257860660552979, 'logits/chosen': 0.5866333246231079, 'epoch': 0.15}


  3%|▎         | 405/16104 [1:53:19<77:05:59, 17.68s/it]

  3%|▎         | 406/16104 [1:53:37<77:38:49, 17.81s/it]
{'loss': 0.6455, 'learning_rate': 1.677685950413223e-06, 'rewards/chosen': -0.042235665023326874, 'rewards/rejected': -0.006427432410418987, 'rewards/accuracies': 0.5, 'rewards/margins': -0.03580822795629501, 'policy_logps/rejected': -263.4953308105469, 'policy_logps/chosen': -252.39065551757812, 'referece_logps/rejected': -263.4310302734375, 'referece_logps/chosen': -251.96829223632812, 'logits/rejected': -0.043083347380161285, 'logits/chosen': 0.010571524500846863, 'epoch': 0.15}


  3%|▎         | 408/16104 [1:54:14<78:39:24, 18.04s/it]

  3%|▎         | 409/16104 [1:54:32<78:43:03, 18.06s/it]
{'loss': 0.6335, 'learning_rate': 1.6900826446280991e-06, 'rewards/chosen': 0.2854442596435547, 'rewards/rejected': 0.026127051562070847, 'rewards/accuracies': 0.625, 'rewards/margins': 0.25931721925735474, 'policy_logps/rejected': -362.5849914550781, 'policy_logps/chosen': -385.6058654785156, 'referece_logps/rejected': -362.84625244140625, 'referece_logps/chosen': -388.4603271484375, 'logits/rejected': -0.3211928606033325, 'logits/chosen': -0.29970160126686096, 'epoch': 0.15}


  3%|▎         | 411/16104 [1:55:11<80:34:56, 18.49s/it]
{'loss': 0.6247, 'learning_rate': 1.6983471074380164e-06, 'rewards/chosen': -0.005827810615301132, 'rewards/rejected': 0.1348128318786621, 'rewards/accuracies': 0.25, 'rewards/margins': -0.14064064621925354, 'policy_logps/rejected': -313.7956237792969, 'policy_logps/chosen': -329.96624755859375, 'referece_logps/rejected': -315.143798828125, 'referece_logps/chosen': -329.9079895019531, 'logits/rejected': 0.02919638156890869, 'logits/chosen': -0.11925190687179565, 'epoch': 0.15}

  3%|▎         | 412/16104 [1:55:34<85:41:54, 19.66s/it]


  3%|▎         | 414/16104 [1:56:09<80:27:51, 18.46s/it]

  3%|▎         | 415/16104 [1:56:29<82:15:23, 18.87s/it]

  3%|▎         | 416/16104 [1:56:45<79:04:06, 18.14s/it]
{'loss': 0.6518, 'learning_rate': 1.7190082644628098e-06, 'rewards/chosen': 0.048406027257442474, 'rewards/rejected': -0.08123406767845154, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1296401023864746, 'policy_logps/rejected': -506.57244873046875, 'policy_logps/chosen': -326.86328125, 'referece_logps/rejected': -505.7601318359375, 'referece_logps/chosen': -327.34735107421875, 'logits/rejected': -0.5545593500137329, 'logits/chosen': -0.6713967323303223, 'epoch': 0.15}

  3%|▎         | 417/16104 [1:56:56<69:11:25, 15.88s/it]


  3%|▎         | 419/16104 [1:57:29<68:19:52, 15.68s/it]

  3%|▎         | 420/16104 [1:57:40<62:47:11, 14.41s/it]
{'loss': 0.6963, 'learning_rate': 1.7355371900826445e-06, 'rewards/chosen': 0.13060474395751953, 'rewards/rejected': 0.20500411093235016, 'rewards/accuracies': 0.375, 'rewards/margins': -0.07439938187599182, 'policy_logps/rejected': -422.8684387207031, 'policy_logps/chosen': -446.3554382324219, 'referece_logps/rejected': -424.9184875488281, 'referece_logps/chosen': -447.66143798828125, 'logits/rejected': -0.6419086456298828, 'logits/chosen': -0.7282424569129944, 'epoch': 0.16}


  3%|▎         | 422/16104 [1:58:07<60:02:23, 13.78s/it]

  3%|▎         | 423/16104 [1:58:25<66:12:35, 15.20s/it]

  3%|▎         | 424/16104 [1:58:45<72:21:13, 16.61s/it]

  3%|▎         | 425/16104 [1:58:56<65:20:49, 15.00s/it]

  3%|▎         | 426/16104 [1:59:09<62:08:27, 14.27s/it]
{'loss': 0.6575, 'learning_rate': 1.7603305785123966e-06, 'rewards/chosen': 0.38962215185165405, 'rewards/rejected': 0.08613870292901993, 'rewards/accuracies': 0.875, 'rewards/margins': 0.30348342657089233, 'policy_logps/rejected': -375.10809326171875, 'policy_logps/chosen': -640.6746826171875, 'referece_logps/rejected': -375.96942138671875, 'referece_logps/chosen': -644.5709228515625, 'logits/rejected': -0.6708599328994751, 'logits/chosen': -0.5906960964202881, 'epoch': 0.16}

  3%|▎         | 427/16104 [1:59:28<68:36:50, 15.76s/it]

  3%|▎         | 428/16104 [1:59:42<65:28:24, 15.04s/it]

  3%|▎         | 429/16104 [1:59:54<62:20:27, 14.32s/it]

  3%|▎         | 430/16104 [2:00:09<63:12:58, 14.52s/it]


  3%|▎         | 432/16104 [2:00:41<66:51:42, 15.36s/it]

  3%|▎         | 433/16104 [2:01:02<74:54:44, 17.21s/it]
{'loss': 0.6448, 'learning_rate': 1.7892561983471072e-06, 'rewards/chosen': 0.13365383446216583, 'rewards/rejected': -0.05968323349952698, 'rewards/accuracies': 0.625, 'rewards/margins': 0.19333705306053162, 'policy_logps/rejected': -355.23516845703125, 'policy_logps/chosen': -566.7189331054688, 'referece_logps/rejected': -354.6383361816406, 'referece_logps/chosen': -568.0554809570312, 'logits/rejected': -0.38979458808898926, 'logits/chosen': -0.4128231704235077, 'epoch': 0.16}

  3%|▎         | 434/16104 [2:01:18<72:51:10, 16.74s/it]

  3%|▎         | 435/16104 [2:01:32<69:35:45, 15.99s/it]

  3%|▎         | 436/16104 [2:01:54<77:07:10, 17.72s/it]

  3%|▎         | 437/16104 [2:02:17<84:17:16, 19.37s/it]

  3%|▎         | 438/16104 [2:02:34<81:15:15, 18.67s/it]


  3%|▎         | 440/16104 [2:03:15<85:10:14, 19.57s/it]
{'loss': 0.6169, 'learning_rate': 1.818181818181818e-06, 'rewards/chosen': 0.2487354278564453, 'rewards/rejected': -0.10853244364261627, 'rewards/accuracies': 1.0, 'rewards/margins': 0.3572678565979004, 'policy_logps/rejected': -297.81097412109375, 'policy_logps/chosen': -390.3948669433594, 'referece_logps/rejected': -296.72564697265625, 'referece_logps/chosen': -392.8822021484375, 'logits/rejected': -0.5733875632286072, 'logits/chosen': -0.6015651226043701, 'epoch': 0.16}

  3%|▎         | 441/16104 [2:03:28<76:17:04, 17.53s/it]


  3%|▎         | 443/16104 [2:03:53<64:27:49, 14.82s/it]
{'loss': 0.6735, 'learning_rate': 1.8305785123966942e-06, 'rewards/chosen': 1.0029575824737549, 'rewards/rejected': 0.08505258709192276, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9179049730300903, 'policy_logps/rejected': -569.4396362304688, 'policy_logps/chosen': -711.92919921875, 'referece_logps/rejected': -570.2901611328125, 'referece_logps/chosen': -721.9588012695312, 'logits/rejected': 0.07174023985862732, 'logits/chosen': 0.07279251515865326, 'epoch': 0.17}

  3%|▎         | 444/16104 [2:04:12<70:16:12, 16.15s/it]

  3%|▎         | 445/16104 [2:04:23<63:03:25, 14.50s/it]


  3%|▎         | 447/16104 [2:04:47<58:54:51, 13.55s/it]

  3%|▎         | 448/16104 [2:05:07<67:10:13, 15.45s/it]
{'loss': 0.6865, 'learning_rate': 1.8512396694214876e-06, 'rewards/chosen': 0.3989017903804779, 'rewards/rejected': 0.38605254888534546, 'rewards/accuracies': 0.625, 'rewards/margins': 0.012849219143390656, 'policy_logps/rejected': -632.2268676757812, 'policy_logps/chosen': -518.2417602539062, 'referece_logps/rejected': -636.0874633789062, 'referece_logps/chosen': -522.2308349609375, 'logits/rejected': 0.022461533546447754, 'logits/chosen': -0.0228651762008667, 'epoch': 0.17}

  3%|▎         | 449/16104 [2:05:19<63:07:35, 14.52s/it]

  3%|▎         | 450/16104 [2:05:36<65:14:18, 15.00s/it]


  3%|▎         | 452/16104 [2:06:13<73:16:22, 16.85s/it]
{'loss': 0.6411, 'learning_rate': 1.8677685950413223e-06, 'rewards/chosen': -0.12346898019313812, 'rewards/rejected': -0.2663629353046417, 'rewards/accuracies': 0.375, 'rewards/margins': 0.1428939700126648, 'policy_logps/rejected': -422.7738952636719, 'policy_logps/chosen': -410.8511047363281, 'referece_logps/rejected': -420.11029052734375, 'referece_logps/chosen': -409.6164245605469, 'logits/rejected': -0.5269164443016052, 'logits/chosen': -0.4008326530456543, 'epoch': 0.17}


  3%|▎         | 454/16104 [2:06:45<69:49:00, 16.06s/it]
{'loss': 0.6391, 'learning_rate': 1.8760330578512396e-06, 'rewards/chosen': 0.28655797243118286, 'rewards/rejected': 0.10801830887794495, 'rewards/accuracies': 0.75, 'rewards/margins': 0.17853966355323792, 'policy_logps/rejected': -395.3841247558594, 'policy_logps/chosen': -459.75335693359375, 'referece_logps/rejected': -396.46429443359375, 'referece_logps/chosen': -462.618896484375, 'logits/rejected': 0.23460784554481506, 'logits/chosen': 0.23048964142799377, 'epoch': 0.17}

  3%|▎         | 455/16104 [2:07:06<75:58:51, 17.48s/it]

  3%|▎         | 456/16104 [2:07:22<74:15:23, 17.08s/it]

  3%|▎         | 457/16104 [2:07:36<69:36:53, 16.02s/it]

  3%|▎         | 458/16104 [2:07:57<76:20:14, 17.56s/it]

  3%|▎         | 459/16104 [2:08:19<81:57:35, 18.86s/it]

  3%|▎         | 460/16104 [2:08:37<81:01:53, 18.65s/it]

  3%|▎         | 461/16104 [2:08:57<83:04:06, 19.12s/it]

  3%|▎         | 462/16104 [2:09:18<84:53:33, 19.54s/it]

  3%|▎         | 463/16104 [2:09:39<86:57:49, 20.02s/it]

  3%|▎         | 464/16104 [2:09:51<76:00:10, 17.49s/it]


  3%|▎         | 466/16104 [2:10:16<65:12:12, 15.01s/it]
{'loss': 0.6576, 'learning_rate': 1.9256198347107436e-06, 'rewards/chosen': 0.4209478497505188, 'rewards/rejected': 0.18772469460964203, 'rewards/accuracies': 0.625, 'rewards/margins': 0.23322315514087677, 'policy_logps/rejected': -440.10711669921875, 'policy_logps/chosen': -495.8599853515625, 'referece_logps/rejected': -441.984375, 'referece_logps/chosen': -500.06939697265625, 'logits/rejected': -0.14181670546531677, 'logits/chosen': -0.265036940574646, 'epoch': 0.17}

  3%|▎         | 467/16104 [2:10:27<60:38:11, 13.96s/it]

  3%|▎         | 468/16104 [2:10:41<60:23:34, 13.90s/it]

  3%|▎         | 469/16104 [2:10:58<65:01:49, 14.97s/it]

  3%|▎         | 470/16104 [2:11:12<63:09:42, 14.54s/it]

  3%|▎         | 471/16104 [2:11:33<72:16:58, 16.65s/it]

  3%|▎         | 472/16104 [2:11:54<77:37:31, 17.88s/it]

  3%|▎         | 473/16104 [2:12:12<77:56:55, 17.95s/it]

  3%|▎         | 474/16104 [2:12:34<82:15:02, 18.94s/it]

  3%|▎         | 475/16104 [2:12:55<85:24:11, 19.67s/it]

  3%|▎         | 476/16104 [2:13:15<85:24:31, 19.67s/it]

  3%|▎         | 477/16104 [2:13:29<79:06:58, 18.23s/it]

  3%|▎         | 478/16104 [2:13:51<83:27:40, 19.23s/it]
[2024-04-05 17:48:10,213] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 479/16104 [2:14:13<86:56:41, 20.03s/it]

  3%|▎         | 480/16104 [2:14:35<89:03:31, 20.52s/it]

  3%|▎         | 481/16104 [2:14:52<85:17:12, 19.65s/it]

  3%|▎         | 482/16104 [2:15:13<86:16:30, 19.88s/it]

  3%|▎         | 483/16104 [2:15:32<86:13:24, 19.87s/it]

  3%|▎         | 484/16104 [2:15:49<82:15:43, 18.96s/it]

  3%|▎         | 485/16104 [2:16:04<77:18:56, 17.82s/it]

  3%|▎         | 486/16104 [2:16:16<69:19:42, 15.98s/it]

  3%|▎         | 487/16104 [2:16:31<67:58:40, 15.67s/it]

  3%|▎         | 488/16104 [2:16:47<68:42:22, 15.84s/it]

  3%|▎         | 489/16104 [2:17:11<79:21:11, 18.29s/it]

  3%|▎         | 490/16104 [2:17:32<82:42:54, 19.07s/it]

  3%|▎         | 491/16104 [2:17:51<81:45:18, 18.85s/it]

  3%|▎         | 492/16104 [2:18:09<81:21:47, 18.76s/it]

  3%|▎         | 493/16104 [2:18:22<73:20:55, 16.91s/it]

  3%|▎         | 494/16104 [2:18:44<79:51:10, 18.42s/it]


  3%|▎         | 496/16104 [2:19:20<80:21:04, 18.53s/it]

  3%|▎         | 497/16104 [2:19:41<82:56:11, 19.13s/it]
{'loss': 0.6079, 'learning_rate': 1.999996581826146e-06, 'rewards/chosen': 0.26822203397750854, 'rewards/rejected': 0.08130722492933273, 'rewards/accuracies': 0.5, 'rewards/margins': 0.1869148313999176, 'policy_logps/rejected': -451.4141540527344, 'policy_logps/chosen': -694.2754516601562, 'referece_logps/rejected': -452.2271728515625, 'referece_logps/chosen': -696.9576416015625, 'logits/rejected': 0.2918575406074524, 'logits/chosen': 0.3702957332134247, 'epoch': 0.19}

  3%|▎         | 498/16104 [2:19:52<72:54:31, 16.82s/it]

  3%|▎         | 499/16104 [2:20:06<69:02:55, 15.93s/it]

  3%|▎         | 500/16104 [2:20:25<72:57:10, 16.83s/it]/mnt/petrelfs/songmingyang/anaconda3/envs/vcd_origin/lib/python3.9/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
  3%|▎         | 501/16104 [2:21:00<97:12:34, 22.43s/it]

  3%|▎         | 502/16104 [2:21:23<96:55:42, 22.37s/it]
{'loss': 0.6413, 'learning_rate': 1.9999934468180475e-06, 'rewards/chosen': 0.2862730324268341, 'rewards/rejected': 0.09550552070140839, 'rewards/accuracies': 0.5, 'rewards/margins': 0.19076749682426453, 'policy_logps/rejected': -324.3932189941406, 'policy_logps/chosen': -419.39483642578125, 'referece_logps/rejected': -325.3482971191406, 'referece_logps/chosen': -422.2575988769531, 'logits/rejected': -0.02875687927007675, 'logits/chosen': -0.0052485838532447815, 'epoch': 0.19}


  3%|▎         | 504/16104 [2:21:54<82:06:50, 18.95s/it]

  3%|▎         | 505/16104 [2:22:06<72:58:09, 16.84s/it]
{'loss': 0.654, 'learning_rate': 1.9999910803947497e-06, 'rewards/chosen': 0.3547138571739197, 'rewards/rejected': 0.18279723823070526, 'rewards/accuracies': 0.5, 'rewards/margins': 0.17191660404205322, 'policy_logps/rejected': -643.5182495117188, 'policy_logps/chosen': -679.979736328125, 'referece_logps/rejected': -645.34619140625, 'referece_logps/chosen': -683.52685546875, 'logits/rejected': 0.3554806709289551, 'logits/chosen': 0.46777451038360596, 'epoch': 0.19}


  3%|▎         | 507/16104 [2:22:43<77:10:27, 17.81s/it]

  3%|▎         | 508/16104 [2:23:07<85:20:57, 19.70s/it]
{'loss': 0.672, 'learning_rate': 1.999988349908648e-06, 'rewards/chosen': 0.0005626669153571129, 'rewards/rejected': -0.02088432013988495, 'rewards/accuracies': 0.5, 'rewards/margins': 0.02144700288772583, 'policy_logps/rejected': -515.9730834960938, 'policy_logps/chosen': -387.3585510253906, 'referece_logps/rejected': -515.7642211914062, 'referece_logps/chosen': -387.36419677734375, 'logits/rejected': -1.0449594259262085, 'logits/chosen': -0.9186252355575562, 'epoch': 0.19}


  3%|▎         | 510/16104 [2:23:41<77:32:40, 17.90s/it]

  3%|▎         | 511/16104 [2:23:57<75:18:30, 17.39s/it]
[2024-04-05 17:57:53,970] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 512/16104 [2:24:11<70:49:50, 16.35s/it]
{'loss': 0.5952, 'learning_rate': 1.999984142942334e-06, 'rewards/chosen': 0.05982398986816406, 'rewards/rejected': -0.08757402002811432, 'rewards/accuracies': 0.625, 'rewards/margins': 0.14739800989627838, 'policy_logps/rejected': -280.0211181640625, 'policy_logps/chosen': -364.7518615722656, 'referece_logps/rejected': -279.1453552246094, 'referece_logps/chosen': -365.35009765625, 'logits/rejected': -0.6885702610015869, 'logits/chosen': -0.43741169571876526, 'epoch': 0.19}

  3%|▎         | 513/16104 [2:24:23<65:48:09, 15.19s/it]
[2024-04-05 17:58:42,640] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 514/16104 [2:24:45<74:57:00, 17.31s/it]

  3%|▎         | 515/16104 [2:25:06<78:45:34, 18.19s/it]


  3%|▎         | 517/16104 [2:25:37<71:16:39, 16.46s/it]
{'loss': 0.6102, 'learning_rate': 1.999977974084128e-06, 'rewards/chosen': 0.16402950882911682, 'rewards/rejected': -0.09586506336927414, 'rewards/accuracies': 0.5, 'rewards/margins': 0.25989457964897156, 'policy_logps/rejected': -309.56011962890625, 'policy_logps/chosen': -336.73345947265625, 'referece_logps/rejected': -308.60150146484375, 'referece_logps/chosen': -338.373779296875, 'logits/rejected': -0.4824776351451874, 'logits/chosen': -0.40289798378944397, 'epoch': 0.19}


  3%|▎         | 519/16104 [2:26:01<61:25:50, 14.19s/it]

  3%|▎         | 520/16104 [2:26:19<66:57:54, 15.47s/it]
{'loss': 0.5559, 'learning_rate': 1.9999737873580796e-06, 'rewards/chosen': 0.5745854377746582, 'rewards/rejected': -0.0343807227909565, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6089661717414856, 'policy_logps/rejected': -447.224365234375, 'policy_logps/chosen': -519.9722900390625, 'referece_logps/rejected': -446.8805847167969, 'referece_logps/chosen': -525.7182006835938, 'logits/rejected': -0.7752175331115723, 'logits/chosen': -0.6791926026344299, 'epoch': 0.19}

  3%|▎         | 521/16104 [2:26:39<72:55:28, 16.85s/it]


  3%|▎         | 523/16104 [2:27:05<64:21:43, 14.87s/it]

  3%|▎         | 524/16104 [2:27:25<70:36:56, 16.32s/it]
{'loss': 0.6743, 'learning_rate': 1.9999676387468417e-06, 'rewards/chosen': 0.31616687774658203, 'rewards/rejected': 0.3473578095436096, 'rewards/accuracies': 0.375, 'rewards/margins': -0.031190913170576096, 'policy_logps/rejected': -348.2195739746094, 'policy_logps/chosen': -400.10015869140625, 'referece_logps/rejected': -351.6931457519531, 'referece_logps/chosen': -403.2618408203125, 'logits/rejected': -0.4540272355079651, 'logits/chosen': -0.5586909651756287, 'epoch': 0.2}


  3%|▎         | 526/16104 [2:27:55<68:48:56, 15.90s/it]

  3%|▎         | 527/16104 [2:28:07<63:43:34, 14.73s/it]
{'loss': 0.6922, 'learning_rate': 1.9999626025582095e-06, 'rewards/chosen': 0.4977741837501526, 'rewards/rejected': 0.5560967922210693, 'rewards/accuracies': 0.625, 'rewards/margins': -0.05832260102033615, 'policy_logps/rejected': -484.5776062011719, 'policy_logps/chosen': -558.6876220703125, 'referece_logps/rejected': -490.13861083984375, 'referece_logps/chosen': -563.6654052734375, 'logits/rejected': 0.10622786730527878, 'logits/chosen': 0.20592746138572693, 'epoch': 0.2}

  3%|▎         | 528/16104 [2:28:18<59:04:27, 13.65s/it]


  3%|▎         | 530/16104 [2:28:45<57:48:17, 13.36s/it]
{'loss': 0.6805, 'learning_rate': 1.9999572023171417e-06, 'rewards/chosen': 0.37183648347854614, 'rewards/rejected': 0.06463884562253952, 'rewards/accuracies': 0.625, 'rewards/margins': 0.307197630405426, 'policy_logps/rejected': -441.4408874511719, 'policy_logps/chosen': -337.9394836425781, 'referece_logps/rejected': -442.0872802734375, 'referece_logps/chosen': -341.6578369140625, 'logits/rejected': -0.7908293008804321, 'logits/chosen': -0.6964666843414307, 'epoch': 0.2}

  3%|▎         | 531/16104 [2:29:02<62:12:43, 14.38s/it]

  3%|▎         | 532/16104 [2:29:14<58:49:36, 13.60s/it]


  3%|▎         | 534/16104 [2:29:51<69:59:08, 16.18s/it]

  3%|▎         | 535/16104 [2:30:07<69:50:50, 16.15s/it]

  3%|▎         | 536/16104 [2:30:21<67:36:32, 15.63s/it]
{'loss': 0.6496, 'learning_rate': 1.999945309685697e-06, 'rewards/chosen': 0.2538217604160309, 'rewards/rejected': 0.2747730016708374, 'rewards/accuracies': 0.375, 'rewards/margins': -0.020951271057128906, 'policy_logps/rejected': -329.3739929199219, 'policy_logps/chosen': -472.90997314453125, 'referece_logps/rejected': -332.1217041015625, 'referece_logps/chosen': -475.4482116699219, 'logits/rejected': -0.4117889702320099, 'logits/chosen': -0.24676799774169922, 'epoch': 0.2}

  3%|▎         | 537/16104 [2:30:42<73:56:37, 17.10s/it]
[2024-04-05 18:05:03,661] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  3%|▎         | 539/16104 [2:31:23<79:56:09, 18.49s/it]
[2024-04-05 18:05:20,242] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6129, 'learning_rate': 1.9999388172996495e-06, 'rewards/chosen': 0.6800466775894165, 'rewards/rejected': 0.3010302782058716, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3790164291858673, 'policy_logps/rejected': -446.97711181640625, 'policy_logps/chosen': -479.72821044921875, 'referece_logps/rejected': -449.9874267578125, 'referece_logps/chosen': -486.5286865234375, 'logits/rejected': -0.7931070327758789, 'logits/chosen': -0.6638746857643127, 'epoch': 0.2}


  3%|▎         | 541/16104 [2:31:57<75:32:30, 17.47s/it]
{'loss': 0.611, 'learning_rate': 1.9999342867955903e-06, 'rewards/chosen': 0.3214830458164215, 'rewards/rejected': 0.09983003884553909, 'rewards/accuracies': 0.5, 'rewards/margins': 0.22165298461914062, 'policy_logps/rejected': -369.3386535644531, 'policy_logps/chosen': -403.8079528808594, 'referece_logps/rejected': -370.3369140625, 'referece_logps/chosen': -407.0228271484375, 'logits/rejected': -0.6044086217880249, 'logits/chosen': -0.6372859477996826, 'epoch': 0.2}

  3%|▎         | 542/16104 [2:32:12<72:30:18, 16.77s/it]

  3%|▎         | 543/16104 [2:32:26<69:14:16, 16.02s/it]
[2024-04-05 18:06:45,300] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 544/16104 [2:32:48<76:31:53, 17.71s/it]

  3%|▎         | 545/16104 [2:33:00<69:43:32, 16.13s/it]

  3%|▎         | 546/16104 [2:33:16<68:45:09, 15.91s/it]


  3%|▎         | 548/16104 [2:34:00<82:09:42, 19.01s/it]

  3%|▎         | 549/16104 [2:34:17<80:42:08, 18.68s/it]
{'loss': 0.6172, 'learning_rate': 1.9999145468220444e-06, 'rewards/chosen': 0.10522757470607758, 'rewards/rejected': -0.11752758920192719, 'rewards/accuracies': 0.75, 'rewards/margins': 0.22275516390800476, 'policy_logps/rejected': -477.9068908691406, 'policy_logps/chosen': -337.9957275390625, 'referece_logps/rejected': -476.73162841796875, 'referece_logps/chosen': -339.0480041503906, 'logits/rejected': -0.9431322813034058, 'logits/chosen': -0.7370189428329468, 'epoch': 0.2}

  3%|▎         | 550/16104 [2:34:37<81:39:48, 18.90s/it]


  3%|▎         | 552/16104 [2:35:13<79:32:04, 18.41s/it]
{'loss': 0.5947, 'learning_rate': 1.99990647693174e-06, 'rewards/chosen': 0.0776798278093338, 'rewards/rejected': -0.2019045054912567, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2795843183994293, 'policy_logps/rejected': -533.316650390625, 'policy_logps/chosen': -528.4281005859375, 'referece_logps/rejected': -531.297607421875, 'referece_logps/chosen': -529.2048950195312, 'logits/rejected': 0.25267407298088074, 'logits/chosen': 0.2747773230075836, 'epoch': 0.21}

  3%|▎         | 553/16104 [2:35:32<79:48:10, 18.47s/it]

  3%|▎         | 554/16104 [2:35:54<84:53:13, 19.65s/it]

  3%|▎         | 555/16104 [2:36:09<78:45:37, 18.24s/it]

  3%|▎         | 556/16104 [2:36:26<76:28:54, 17.71s/it]

  3%|▎         | 557/16104 [2:36:42<74:11:58, 17.18s/it]

  3%|▎         | 558/16104 [2:37:01<76:39:40, 17.75s/it]

  3%|▎         | 559/16104 [2:37:15<72:08:54, 16.71s/it]

  3%|▎         | 560/16104 [2:37:32<72:01:57, 16.68s/it]

  3%|▎         | 561/16104 [2:37:46<69:09:57, 16.02s/it]

  3%|▎         | 562/16104 [2:38:02<68:44:53, 15.92s/it]

  3%|▎         | 563/16104 [2:38:20<71:26:18, 16.55s/it]

  4%|▎         | 564/16104 [2:38:39<74:36:04, 17.28s/it]


  4%|▎         | 566/16104 [2:39:09<69:23:32, 16.08s/it]
{'loss': 0.6024, 'learning_rate': 1.9998640041826736e-06, 'rewards/chosen': 0.41131457686424255, 'rewards/rejected': 0.17994318902492523, 'rewards/accuracies': 0.625, 'rewards/margins': 0.23137140274047852, 'policy_logps/rejected': -495.6412353515625, 'policy_logps/chosen': -420.1155090332031, 'referece_logps/rejected': -497.44061279296875, 'referece_logps/chosen': -424.2286376953125, 'logits/rejected': -0.6713901162147522, 'logits/chosen': -0.3613150119781494, 'epoch': 0.21}

  4%|▎         | 567/16104 [2:39:21<63:59:22, 14.83s/it]

  4%|▎         | 568/16104 [2:39:37<64:54:31, 15.04s/it]

  4%|▎         | 569/16104 [2:39:49<61:10:48, 14.18s/it]

  4%|▎         | 570/16104 [2:40:02<59:27:53, 13.78s/it]

  4%|▎         | 571/16104 [2:40:20<65:28:12, 15.17s/it]

  4%|▎         | 572/16104 [2:40:32<60:49:45, 14.10s/it]

  4%|▎         | 573/16104 [2:40:53<69:45:41, 16.17s/it]

  4%|▎         | 574/16104 [2:41:15<77:16:51, 17.91s/it]

  4%|▎         | 575/16104 [2:41:33<77:05:16, 17.87s/it]

  4%|▎         | 576/16104 [2:41:50<76:20:23, 17.70s/it]


  4%|▎         | 578/16104 [2:42:21<70:02:59, 16.24s/it]

  4%|▎         | 579/16104 [2:42:37<70:04:24, 16.25s/it]

  4%|▎         | 580/16104 [2:42:53<69:56:32, 16.22s/it]
{'loss': 0.6218, 'learning_rate': 1.9998136039673076e-06, 'rewards/chosen': 0.09743738174438477, 'rewards/rejected': -0.1725298911333084, 'rewards/accuracies': 0.75, 'rewards/margins': 0.26996728777885437, 'policy_logps/rejected': -281.3100891113281, 'policy_logps/chosen': -264.5101623535156, 'referece_logps/rejected': -279.5848083496094, 'referece_logps/chosen': -265.48455810546875, 'logits/rejected': -0.5528741478919983, 'logits/chosen': -0.25535133481025696, 'epoch': 0.22}

  4%|▎         | 581/16104 [2:43:08<68:21:33, 15.85s/it]


  4%|▎         | 583/16104 [2:43:49<78:38:59, 18.24s/it]

  4%|▎         | 584/16104 [2:44:10<82:08:33, 19.05s/it]

  4%|▎         | 585/16104 [2:44:25<76:51:34, 17.83s/it]

  4%|▎         | 586/16104 [2:44:37<69:06:54, 16.03s/it]

  4%|▎         | 587/16104 [2:44:56<73:10:54, 16.98s/it]

  4%|▎         | 588/16104 [2:45:18<79:43:35, 18.50s/it]

  4%|▎         | 589/16104 [2:45:39<82:59:28, 19.26s/it]

  4%|▎         | 590/16104 [2:45:57<80:23:23, 18.65s/it]
{'loss': 0.6497, 'learning_rate': 1.999772750481546e-06, 'rewards/chosen': -0.0005268137902021408, 'rewards/rejected': -0.16126032173633575, 'rewards/accuracies': 0.5, 'rewards/margins': 0.16073352098464966, 'policy_logps/rejected': -254.49778747558594, 'policy_logps/chosen': -397.98040771484375, 'referece_logps/rejected': -252.88519287109375, 'referece_logps/chosen': -397.9751281738281, 'logits/rejected': 0.8787076473236084, 'logits/chosen': 0.9143962860107422, 'epoch': 0.22}
[2024-04-05 18:20:13,561] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  4%|▎         | 592/16104 [2:46:37<83:30:22, 19.38s/it]
{'loss': 0.5756, 'learning_rate': 1.9997640944678767e-06, 'rewards/chosen': -0.2374313324689865, 'rewards/rejected': -0.4458249807357788, 'rewards/accuracies': 0.75, 'rewards/margins': 0.20839367806911469, 'policy_logps/rejected': -404.6283264160156, 'policy_logps/chosen': -370.0425720214844, 'referece_logps/rejected': -400.17010498046875, 'referece_logps/chosen': -367.66827392578125, 'logits/rejected': -0.09736651182174683, 'logits/chosen': -0.1092124879360199, 'epoch': 0.22}


  4%|▎         | 594/16104 [2:47:15<82:56:59, 19.25s/it]

  4%|▎         | 595/16104 [2:47:34<83:10:41, 19.31s/it]
{'loss': 0.5589, 'learning_rate': 1.9997508071310087e-06, 'rewards/chosen': -0.052010346204042435, 'rewards/rejected': -0.5901573300361633, 'rewards/accuracies': 0.875, 'rewards/margins': 0.53814697265625, 'policy_logps/rejected': -297.7002868652344, 'policy_logps/chosen': -255.77162170410156, 'referece_logps/rejected': -291.7987060546875, 'referece_logps/chosen': -255.25149536132812, 'logits/rejected': 0.1601833701133728, 'logits/chosen': 0.11503778398036957, 'epoch': 0.22}


  4%|▎         | 597/16104 [2:48:13<84:33:01, 19.63s/it]
[2024-04-05 18:22:10,596] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▎         | 598/16104 [2:48:36<88:15:49, 20.49s/it]
{'loss': 0.6154, 'learning_rate': 1.999737155818813e-06, 'rewards/chosen': 0.029902460053563118, 'rewards/rejected': -0.062399107962846756, 'rewards/accuracies': 0.625, 'rewards/margins': 0.09230157732963562, 'policy_logps/rejected': -314.5481872558594, 'policy_logps/chosen': -404.7704162597656, 'referece_logps/rejected': -313.9241943359375, 'referece_logps/chosen': -405.0694580078125, 'logits/rejected': -0.1808430254459381, 'logits/chosen': -0.051259614527225494, 'epoch': 0.22}


  4%|▎         | 600/16104 [2:49:15<87:48:03, 20.39s/it]

  4%|▎         | 601/16104 [2:49:26<75:24:59, 17.51s/it]

  4%|▎         | 602/16104 [2:49:38<67:43:50, 15.73s/it]
[2024-04-05 18:23:34,917] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▎         | 603/16104 [2:49:57<73:00:10, 16.95s/it]

  4%|▍         | 604/16104 [2:50:19<79:25:14, 18.45s/it]

  4%|▍         | 605/16104 [2:50:41<84:00:48, 19.51s/it]

  4%|▍         | 606/16104 [2:50:59<81:22:42, 18.90s/it]

  4%|▍         | 607/16104 [2:51:20<84:09:05, 19.55s/it]

  4%|▍         | 608/16104 [2:51:41<85:54:52, 19.96s/it]

  4%|▍         | 609/16104 [2:51:56<79:49:00, 18.54s/it]

  4%|▍         | 610/16104 [2:52:17<83:15:00, 19.34s/it]

  4%|▍         | 611/16104 [2:52:34<79:49:23, 18.55s/it]
{'loss': 0.6292, 'learning_rate': 1.9996737943194446e-06, 'rewards/chosen': -0.011544235050678253, 'rewards/rejected': -0.29200437664985657, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2804601788520813, 'policy_logps/rejected': -371.0498352050781, 'policy_logps/chosen': -368.0536193847656, 'referece_logps/rejected': -368.1297912597656, 'referece_logps/chosen': -367.938232421875, 'logits/rejected': -0.501083493232727, 'logits/chosen': -0.3125719428062439, 'epoch': 0.23}


  4%|▍         | 613/16104 [2:53:17<86:21:29, 20.07s/it]
[2024-04-05 18:27:14,578] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 614/16104 [2:53:35<83:40:06, 19.45s/it]

  4%|▍         | 615/16104 [2:53:58<87:22:23, 20.31s/it]

  4%|▍         | 616/16104 [2:54:17<86:10:44, 20.03s/it]
[2024-04-05 18:28:14,274] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 617/16104 [2:54:33<80:51:31, 18.80s/it]

  4%|▍         | 618/16104 [2:54:52<81:51:12, 19.03s/it]

  4%|▍         | 619/16104 [2:55:04<72:30:40, 16.86s/it]

  4%|▍         | 620/16104 [2:55:22<74:15:20, 17.26s/it]

  4%|▍         | 621/16104 [2:55:39<73:39:50, 17.13s/it]

  4%|▍         | 622/16104 [2:55:59<76:31:06, 17.79s/it]

  4%|▍         | 623/16104 [2:56:15<74:17:09, 17.27s/it]

  4%|▍         | 624/16104 [2:56:31<73:34:27, 17.11s/it]

  4%|▍         | 625/16104 [2:56:46<70:47:11, 16.46s/it]

  4%|▍         | 626/16104 [2:57:01<68:22:03, 15.90s/it]

  4%|▍         | 627/16104 [2:57:16<67:01:44, 15.59s/it]

  4%|▍         | 628/16104 [2:57:27<61:10:27, 14.23s/it]

  4%|▍         | 629/16104 [2:57:42<61:43:16, 14.36s/it]

  4%|▍         | 630/16104 [2:57:53<58:28:09, 13.60s/it]

  4%|▍         | 631/16104 [2:58:10<62:44:55, 14.60s/it]

  4%|▍         | 632/16104 [2:58:23<59:50:43, 13.92s/it]

  4%|▍         | 633/16104 [2:58:44<69:42:20, 16.22s/it]

  4%|▍         | 634/16104 [2:58:58<66:38:04, 15.51s/it]

  4%|▍         | 635/16104 [2:59:15<68:06:45, 15.85s/it]

  4%|▍         | 636/16104 [2:59:38<77:36:52, 18.06s/it]

  4%|▍         | 637/16104 [3:00:00<82:16:23, 19.15s/it]

  4%|▍         | 638/16104 [3:00:22<86:15:10, 20.08s/it]

  4%|▍         | 639/16104 [3:00:36<78:06:36, 18.18s/it]

  4%|▍         | 640/16104 [3:00:51<73:52:35, 17.20s/it]

  4%|▍         | 641/16104 [3:01:10<77:01:39, 17.93s/it]

  4%|▍         | 642/16104 [3:01:31<81:09:32, 18.90s/it]

  4%|▍         | 643/16104 [3:01:54<85:48:36, 19.98s/it]

  4%|▍         | 644/16104 [3:02:11<82:00:26, 19.10s/it]

  4%|▍         | 645/16104 [3:02:32<84:44:32, 19.73s/it]

  4%|▍         | 646/16104 [3:02:50<81:49:39, 19.06s/it]

  4%|▍         | 647/16104 [3:03:05<77:43:01, 18.10s/it]

  4%|▍         | 648/16104 [3:03:23<77:21:09, 18.02s/it]

  4%|▍         | 649/16104 [3:03:35<69:47:58, 16.26s/it]

  4%|▍         | 650/16104 [3:03:47<63:17:04, 14.74s/it]

  4%|▍         | 651/16104 [3:04:05<68:20:20, 15.92s/it]

  4%|▍         | 652/16104 [3:04:24<71:48:48, 16.73s/it]

  4%|▍         | 653/16104 [3:04:40<71:32:56, 16.67s/it]

  4%|▍         | 654/16104 [3:05:00<75:25:13, 17.57s/it]
[2024-04-05 18:38:57,424] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 655/16104 [3:05:13<68:49:09, 16.04s/it]

  4%|▍         | 656/16104 [3:05:27<67:12:20, 15.66s/it]

  4%|▍         | 657/16104 [3:05:39<61:50:15, 14.41s/it]

  4%|▍         | 658/16104 [3:05:53<61:00:30, 14.22s/it]

  4%|▍         | 659/16104 [3:06:08<61:57:26, 14.44s/it]

  4%|▍         | 660/16104 [3:06:20<59:37:17, 13.90s/it]

  4%|▍         | 661/16104 [3:06:40<66:48:53, 15.58s/it]

  4%|▍         | 662/16104 [3:06:53<63:16:12, 14.75s/it]

  4%|▍         | 663/16104 [3:07:13<71:04:28, 16.57s/it]

  4%|▍         | 664/16104 [3:07:29<69:59:11, 16.32s/it]

  4%|▍         | 665/16104 [3:07:45<69:15:17, 16.15s/it]

  4%|▍         | 666/16104 [3:08:07<76:34:00, 17.85s/it]

  4%|▍         | 667/16104 [3:08:27<79:09:02, 18.46s/it]

  4%|▍         | 668/16104 [3:08:45<79:26:13, 18.53s/it]

  4%|▍         | 669/16104 [3:09:03<79:03:24, 18.44s/it]

  4%|▍         | 670/16104 [3:09:18<73:37:30, 17.17s/it]

  4%|▍         | 671/16104 [3:09:34<72:15:01, 16.85s/it]

  4%|▍         | 672/16104 [3:09:51<72:37:55, 16.94s/it]

  4%|▍         | 673/16104 [3:10:03<66:17:06, 15.46s/it]

  4%|▍         | 674/16104 [3:10:20<68:01:18, 15.87s/it]

  4%|▍         | 675/16104 [3:10:44<78:14:16, 18.26s/it]

  4%|▍         | 676/16104 [3:11:04<80:46:21, 18.85s/it]

  4%|▍         | 677/16104 [3:11:19<76:16:06, 17.80s/it]

  4%|▍         | 678/16104 [3:11:39<79:28:12, 18.55s/it]

  4%|▍         | 679/16104 [3:12:01<83:47:04, 19.55s/it]

  4%|▍         | 680/16104 [3:12:22<85:32:21, 19.97s/it]

  4%|▍         | 681/16104 [3:12:38<80:40:04, 18.83s/it]

  4%|▍         | 682/16104 [3:12:57<80:21:17, 18.76s/it]

  4%|▍         | 683/16104 [3:13:19<84:39:31, 19.76s/it]
{'loss': 0.6088, 'learning_rate': 1.9991991413570934e-06, 'rewards/chosen': 0.3838132917881012, 'rewards/rejected': -0.18058615922927856, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5643994212150574, 'policy_logps/rejected': -313.10296630859375, 'policy_logps/chosen': -439.9075622558594, 'referece_logps/rejected': -311.297119140625, 'referece_logps/chosen': -443.7456970214844, 'logits/rejected': -0.3497437536716461, 'logits/chosen': -0.3085263669490814, 'epoch': 0.25}

  4%|▍         | 684/16104 [3:13:38<83:57:49, 19.60s/it]


  4%|▍         | 686/16104 [3:14:14<79:44:33, 18.62s/it]

  4%|▍         | 687/16104 [3:14:31<77:43:42, 18.15s/it]

  4%|▍         | 688/16104 [3:14:43<69:41:01, 16.27s/it]

  4%|▍         | 689/16104 [3:15:06<78:44:18, 18.39s/it]
{'loss': 0.718, 'learning_rate': 1.9991501272834256e-06, 'rewards/chosen': -0.03393735736608505, 'rewards/rejected': 0.18636873364448547, 'rewards/accuracies': 0.625, 'rewards/margins': -0.22030609846115112, 'policy_logps/rejected': -326.94866943359375, 'policy_logps/chosen': -421.20025634765625, 'referece_logps/rejected': -328.8123474121094, 'referece_logps/chosen': -420.86090087890625, 'logits/rejected': 0.48642846941947937, 'logits/chosen': 0.5148385167121887, 'epoch': 0.26}


  4%|▍         | 691/16104 [3:15:35<70:30:55, 16.47s/it]
{'loss': 0.5862, 'learning_rate': 1.999133465916077e-06, 'rewards/chosen': -0.04863356426358223, 'rewards/rejected': -0.5871052742004395, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5384715795516968, 'policy_logps/rejected': -329.3344421386719, 'policy_logps/chosen': -324.40130615234375, 'referece_logps/rejected': -323.46337890625, 'referece_logps/chosen': -323.9149475097656, 'logits/rejected': -0.15723681449890137, 'logits/chosen': -0.2488766610622406, 'epoch': 0.26}

  4%|▍         | 692/16104 [3:15:52<71:27:14, 16.69s/it]

  4%|▍         | 693/16104 [3:16:09<70:48:46, 16.54s/it]


  4%|▍         | 695/16104 [3:16:40<70:12:39, 16.40s/it]
{'loss': 0.6367, 'learning_rate': 1.9990996581833266e-06, 'rewards/chosen': 0.3904499113559723, 'rewards/rejected': -0.04729089513421059, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4377408027648926, 'policy_logps/rejected': -415.5113220214844, 'policy_logps/chosen': -602.4802856445312, 'referece_logps/rejected': -415.03839111328125, 'referece_logps/chosen': -606.3848266601562, 'logits/rejected': -0.4386325776576996, 'logits/chosen': -0.4913637638092041, 'epoch': 0.26}


  4%|▍         | 697/16104 [3:17:13<72:16:58, 16.89s/it]
{'loss': 0.5469, 'learning_rate': 1.9990825118233955e-06, 'rewards/chosen': 0.0745338425040245, 'rewards/rejected': -0.21377964317798615, 'rewards/accuracies': 0.75, 'rewards/margins': 0.28831347823143005, 'policy_logps/rejected': -292.3005676269531, 'policy_logps/chosen': -308.0365905761719, 'referece_logps/rejected': -290.16278076171875, 'referece_logps/chosen': -308.78192138671875, 'logits/rejected': -0.22269178926944733, 'logits/chosen': -0.2263440042734146, 'epoch': 0.26}


  4%|▍         | 699/16104 [3:17:50<77:10:27, 18.03s/it]

  4%|▍         | 700/16104 [3:18:11<81:00:45, 18.93s/it]

  4%|▍         | 701/16104 [3:18:30<80:23:11, 18.79s/it]

  4%|▍         | 702/16104 [3:18:46<76:33:53, 17.90s/it]

  4%|▍         | 703/16104 [3:19:00<72:28:46, 16.94s/it]

  4%|▍         | 704/16104 [3:19:16<71:12:39, 16.65s/it]

  4%|▍         | 705/16104 [3:19:31<68:55:23, 16.11s/it]
{'loss': 0.6466, 'learning_rate': 1.999012309825006e-06, 'rewards/chosen': 0.13544999063014984, 'rewards/rejected': -0.16615019738674164, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3016001880168915, 'policy_logps/rejected': -236.32180786132812, 'policy_logps/chosen': -455.9719543457031, 'referece_logps/rejected': -234.66029357910156, 'referece_logps/chosen': -457.32647705078125, 'logits/rejected': -0.7605675458908081, 'logits/chosen': -0.4826662242412567, 'epoch': 0.26}


  4%|▍         | 707/16104 [3:20:06<68:56:15, 16.12s/it]

  4%|▍         | 708/16104 [3:20:17<63:10:22, 14.77s/it]

  4%|▍         | 709/16104 [3:20:29<58:41:07, 13.72s/it]
{'loss': 0.6289, 'learning_rate': 1.9989762389304604e-06, 'rewards/chosen': 0.27365797758102417, 'rewards/rejected': 0.04570120573043823, 'rewards/accuracies': 0.5, 'rewards/margins': 0.22795680165290833, 'policy_logps/rejected': -547.38427734375, 'policy_logps/chosen': -454.7740478515625, 'referece_logps/rejected': -547.84130859375, 'referece_logps/chosen': -457.5106201171875, 'logits/rejected': -0.46546751260757446, 'logits/chosen': -0.09939193725585938, 'epoch': 0.26}

  4%|▍         | 710/16104 [3:20:41<56:49:53, 13.29s/it]


  4%|▍         | 712/16104 [3:21:14<63:19:52, 14.81s/it]

  4%|▍         | 713/16104 [3:21:36<72:02:14, 16.85s/it]

  4%|▍         | 714/16104 [3:21:49<66:27:36, 15.55s/it]

  4%|▍         | 715/16104 [3:21:59<60:31:08, 14.16s/it]
{'loss': 0.5862, 'learning_rate': 1.998920920284968e-06, 'rewards/chosen': 0.10005312412977219, 'rewards/rejected': 0.0046396260149776936, 'rewards/accuracies': 0.75, 'rewards/margins': 0.09541349112987518, 'policy_logps/rejected': -460.48760986328125, 'policy_logps/chosen': -312.0332946777344, 'referece_logps/rejected': -460.53399658203125, 'referece_logps/chosen': -313.0338134765625, 'logits/rejected': -0.7123887538909912, 'logits/chosen': -0.5377575159072876, 'epoch': 0.27}

  4%|▍         | 716/16104 [3:22:21<69:46:42, 16.32s/it]


  4%|▍         | 718/16104 [3:23:05<82:38:21, 19.34s/it]

  4%|▍         | 719/16104 [3:23:23<80:59:04, 18.95s/it]
{'loss': 0.5769, 'learning_rate': 1.9988832330203323e-06, 'rewards/chosen': 0.1848011016845703, 'rewards/rejected': -0.5038981437683105, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6886991858482361, 'policy_logps/rejected': -219.04385375976562, 'policy_logps/chosen': -327.9254150390625, 'referece_logps/rejected': -214.00486755371094, 'referece_logps/chosen': -329.7734375, 'logits/rejected': -0.8808137774467468, 'logits/chosen': -0.5638254284858704, 'epoch': 0.27}


  4%|▍         | 721/16104 [3:23:56<76:41:15, 17.95s/it]
{'loss': 0.573, 'learning_rate': 1.99886414694683e-06, 'rewards/chosen': 0.3067741394042969, 'rewards/rejected': -0.4333503544330597, 'rewards/accuracies': 0.75, 'rewards/margins': 0.740124523639679, 'policy_logps/rejected': -393.68621826171875, 'policy_logps/chosen': -511.8494567871094, 'referece_logps/rejected': -389.3526916503906, 'referece_logps/chosen': -514.9171142578125, 'logits/rejected': 0.7219796180725098, 'logits/chosen': 0.6658241152763367, 'epoch': 0.27}


  4%|▍         | 723/16104 [3:24:34<79:32:31, 18.62s/it]

  4%|▍         | 724/16104 [3:24:58<85:42:02, 20.06s/it]

  5%|▍         | 725/16104 [3:25:12<77:59:06, 18.26s/it]

  5%|▍         | 726/16104 [3:25:28<74:57:26, 17.55s/it]
{'loss': 0.605, 'learning_rate': 1.9988157246677513e-06, 'rewards/chosen': 0.21419468522071838, 'rewards/rejected': 0.22383728623390198, 'rewards/accuracies': 0.375, 'rewards/margins': -0.009642589837312698, 'policy_logps/rejected': -401.669677734375, 'policy_logps/chosen': -396.74566650390625, 'referece_logps/rejected': -403.90802001953125, 'referece_logps/chosen': -398.88763427734375, 'logits/rejected': -0.08718439936637878, 'logits/chosen': 0.03510221838951111, 'epoch': 0.27}


  5%|▍         | 728/16104 [3:25:56<66:22:55, 15.54s/it]
{'loss': 0.683, 'learning_rate': 1.998796072926217e-06, 'rewards/chosen': -0.04396018385887146, 'rewards/rejected': 0.06042424216866493, 'rewards/accuracies': 0.625, 'rewards/margins': -0.10438438504934311, 'policy_logps/rejected': -441.8484191894531, 'policy_logps/chosen': -411.2307434082031, 'referece_logps/rejected': -442.4526672363281, 'referece_logps/chosen': -410.7911682128906, 'logits/rejected': -0.5311799049377441, 'logits/chosen': -0.35800227522850037, 'epoch': 0.27}

  5%|▍         | 729/16104 [3:26:15<71:06:56, 16.65s/it]
[2024-04-05 19:00:34,678] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 730/16104 [3:26:37<78:05:29, 18.29s/it]


  5%|▍         | 732/16104 [3:27:14<77:36:17, 18.17s/it]
[2024-04-05 19:01:11,434] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 733/16104 [3:27:28<72:24:03, 16.96s/it]
{'loss': 0.6205, 'learning_rate': 1.998746236525447e-06, 'rewards/chosen': -0.04962863773107529, 'rewards/rejected': -0.22161775827407837, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1719890981912613, 'policy_logps/rejected': -300.9178161621094, 'policy_logps/chosen': -343.8003234863281, 'referece_logps/rejected': -298.7016296386719, 'referece_logps/chosen': -343.30401611328125, 'logits/rejected': 0.3048650622367859, 'logits/chosen': 0.15668004751205444, 'epoch': 0.27}


  5%|▍         | 735/16104 [3:28:01<72:08:14, 16.90s/it]

  5%|▍         | 736/16104 [3:28:13<65:57:54, 15.45s/it]
{'loss': 0.5971, 'learning_rate': 1.998715849868946e-06, 'rewards/chosen': -0.3433927297592163, 'rewards/rejected': -0.7353250980377197, 'rewards/accuracies': 0.75, 'rewards/margins': 0.39193230867385864, 'policy_logps/rejected': -576.3855590820312, 'policy_logps/chosen': -502.3074951171875, 'referece_logps/rejected': -569.0323486328125, 'referece_logps/chosen': -498.87359619140625, 'logits/rejected': -0.05993417650461197, 'logits/chosen': -0.25585657358169556, 'epoch': 0.27}

  5%|▍         | 737/16104 [3:28:30<67:33:01, 15.82s/it]


  5%|▍         | 739/16104 [3:28:57<61:42:08, 14.46s/it]

  5%|▍         | 740/16104 [3:29:12<62:49:22, 14.72s/it]

  5%|▍         | 741/16104 [3:29:33<70:37:28, 16.55s/it]

  5%|▍         | 742/16104 [3:29:54<76:55:35, 18.03s/it]
{'loss': 0.5985, 'learning_rate': 1.998653985771534e-06, 'rewards/chosen': 0.41178643703460693, 'rewards/rejected': 0.19173088669776917, 'rewards/accuracies': 0.5, 'rewards/margins': 0.22005556523799896, 'policy_logps/rejected': -403.5050048828125, 'policy_logps/chosen': -475.55426025390625, 'referece_logps/rejected': -405.42236328125, 'referece_logps/chosen': -479.672119140625, 'logits/rejected': -0.41999414563179016, 'logits/chosen': -0.12942780554294586, 'epoch': 0.28}


  5%|▍         | 744/16104 [3:30:27<70:52:11, 16.61s/it]

  5%|▍         | 745/16104 [3:30:39<65:17:28, 15.30s/it]

  5%|▍         | 746/16104 [3:30:55<66:14:54, 15.53s/it]

  5%|▍         | 747/16104 [3:31:09<64:00:23, 15.00s/it]

  5%|▍         | 748/16104 [3:31:29<71:05:02, 16.66s/it]
[2024-04-05 19:05:26,527] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5814, 'learning_rate': 1.998590667370204e-06, 'rewards/chosen': 0.424234002828598, 'rewards/rejected': 0.016840357333421707, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4073936641216278, 'policy_logps/rejected': -390.84478759765625, 'policy_logps/chosen': -505.3340759277344, 'referece_logps/rejected': -391.01318359375, 'referece_logps/chosen': -509.576416015625, 'logits/rejected': 0.6533203125, 'logits/chosen': 0.7152026295661926, 'epoch': 0.28}


  5%|▍         | 750/16104 [3:31:59<66:04:09, 15.49s/it]

  5%|▍         | 751/16104 [3:32:11<61:18:43, 14.38s/it]
{'loss': 0.5945, 'learning_rate': 1.9985584628343026e-06, 'rewards/chosen': 0.04971121996641159, 'rewards/rejected': -0.13592606782913208, 'rewards/accuracies': 0.875, 'rewards/margins': 0.18563729524612427, 'policy_logps/rejected': -348.70257568359375, 'policy_logps/chosen': -364.38116455078125, 'referece_logps/rejected': -347.34326171875, 'referece_logps/chosen': -364.8782958984375, 'logits/rejected': -0.24229249358177185, 'logits/chosen': -0.3756486773490906, 'epoch': 0.28}


  5%|▍         | 753/16104 [3:32:41<63:13:35, 14.83s/it]

  5%|▍         | 754/16104 [3:32:51<57:56:38, 13.59s/it]

  5%|▍         | 755/16104 [3:33:02<54:34:12, 12.80s/it]

  5%|▍         | 756/16104 [3:33:15<54:17:31, 12.73s/it]
{'loss': 0.6979, 'learning_rate': 1.9985039807442362e-06, 'rewards/chosen': 0.05097884684801102, 'rewards/rejected': 0.1899440735578537, 'rewards/accuracies': 0.5, 'rewards/margins': -0.13896523416042328, 'policy_logps/rejected': -525.5220336914062, 'policy_logps/chosen': -409.68426513671875, 'referece_logps/rejected': -527.42138671875, 'referece_logps/chosen': -410.19403076171875, 'logits/rejected': 0.03540751338005066, 'logits/chosen': 0.009181883186101913, 'epoch': 0.28}

  5%|▍         | 757/16104 [3:33:38<67:02:51, 15.73s/it]


  5%|▍         | 759/16104 [3:34:19<76:50:52, 18.03s/it]

  5%|▍         | 760/16104 [3:34:34<73:52:06, 17.33s/it]

  5%|▍         | 761/16104 [3:34:55<77:50:19, 18.26s/it]

  5%|▍         | 762/16104 [3:35:12<76:55:29, 18.05s/it]

  5%|▍         | 763/16104 [3:35:25<69:39:14, 16.35s/it]
{'loss': 0.5579, 'learning_rate': 1.998426009397568e-06, 'rewards/chosen': -0.02396351471543312, 'rewards/rejected': -0.17695467174053192, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1529911607503891, 'policy_logps/rejected': -580.9051513671875, 'policy_logps/chosen': -369.55596923828125, 'referece_logps/rejected': -579.1356201171875, 'referece_logps/chosen': -369.31634521484375, 'logits/rejected': -0.0759626179933548, 'logits/chosen': 0.024315109476447105, 'epoch': 0.28}


  5%|▍         | 765/16104 [3:36:08<80:50:41, 18.97s/it]

  5%|▍         | 766/16104 [3:36:29<84:37:03, 19.86s/it]
[2024-04-05 19:10:26,743] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 767/16104 [3:36:46<80:56:59, 19.00s/it]
[2024-04-05 19:10:43,738] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 768/16104 [3:37:09<85:07:05, 19.98s/it]
{'loss': 0.5486, 'learning_rate': 1.9983691039261353e-06, 'rewards/chosen': 0.0011926665902137756, 'rewards/rejected': -0.4059774875640869, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4071701169013977, 'policy_logps/rejected': -460.94256591796875, 'policy_logps/chosen': -394.9447021484375, 'referece_logps/rejected': -456.8828125, 'referece_logps/chosen': -394.9566345214844, 'logits/rejected': -0.7820415496826172, 'logits/chosen': -0.8971197605133057, 'epoch': 0.29}


  5%|▍         | 770/16104 [3:37:51<87:37:41, 20.57s/it]
[2024-04-05 19:11:48,352] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6078, 'learning_rate': 1.9983460590336457e-06, 'rewards/chosen': -0.44813674688339233, 'rewards/rejected': -0.13307645916938782, 'rewards/accuracies': 0.5, 'rewards/margins': -0.3150602877140045, 'policy_logps/rejected': -474.03564453125, 'policy_logps/chosen': -527.85693359375, 'referece_logps/rejected': -472.704833984375, 'referece_logps/chosen': -523.3756103515625, 'logits/rejected': 0.4035117030143738, 'logits/chosen': 0.39929214119911194, 'epoch': 0.29}
[2024-04-05 19:12:09,443] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 771/16104 [3:38:12<88:17:02, 20.73s/it]


  5%|▍         | 773/16104 [3:38:51<84:51:41, 19.93s/it]
{'loss': 0.5576, 'learning_rate': 1.998311188809489e-06, 'rewards/chosen': -0.13584958016872406, 'rewards/rejected': -0.2723843455314636, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13653478026390076, 'policy_logps/rejected': -411.76751708984375, 'policy_logps/chosen': -412.5514221191406, 'referece_logps/rejected': -409.0436706542969, 'referece_logps/chosen': -411.19293212890625, 'logits/rejected': -0.8145333528518677, 'logits/chosen': -0.7157464027404785, 'epoch': 0.29}


  5%|▍         | 775/16104 [3:39:23<78:28:21, 18.43s/it]
{'loss': 0.5247, 'learning_rate': 1.9982877400752555e-06, 'rewards/chosen': 0.1367313414812088, 'rewards/rejected': -0.7680436968803406, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9047751426696777, 'policy_logps/rejected': -336.84344482421875, 'policy_logps/chosen': -646.7074584960938, 'referece_logps/rejected': -329.16302490234375, 'referece_logps/chosen': -648.0748291015625, 'logits/rejected': 0.7501481175422668, 'logits/chosen': 0.6655154228210449, 'epoch': 0.29}

  5%|▍         | 776/16104 [3:39:36<71:09:51, 16.71s/it]


  5%|▍         | 778/16104 [3:40:11<73:53:16, 17.36s/it]

  5%|▍         | 779/16104 [3:40:31<76:26:59, 17.96s/it]
{'loss': 0.5911, 'learning_rate': 1.9982403580203676e-06, 'rewards/chosen': -0.3034898042678833, 'rewards/rejected': -0.39721909165382385, 'rewards/accuracies': 0.625, 'rewards/margins': 0.09372929483652115, 'policy_logps/rejected': -306.2635498046875, 'policy_logps/chosen': -368.96746826171875, 'referece_logps/rejected': -302.2913818359375, 'referece_logps/chosen': -365.93255615234375, 'logits/rejected': -0.9822723269462585, 'logits/chosen': -0.9740487933158875, 'epoch': 0.29}


  5%|▍         | 781/16104 [3:41:01<68:24:49, 16.07s/it]

  5%|▍         | 782/16104 [3:41:18<69:34:06, 16.35s/it]

  5%|▍         | 783/16104 [3:41:39<76:15:07, 17.92s/it]
[2024-04-05 19:15:36,596] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6602, 'learning_rate': 1.9981923298758513e-06, 'rewards/chosen': -0.18366090953350067, 'rewards/rejected': -0.6812637448310852, 'rewards/accuracies': 0.625, 'rewards/margins': 0.49760282039642334, 'policy_logps/rejected': -448.65814208984375, 'policy_logps/chosen': -452.2392578125, 'referece_logps/rejected': -441.8455505371094, 'referece_logps/chosen': -450.4026794433594, 'logits/rejected': -0.3361019194126129, 'logits/chosen': -0.19551610946655273, 'epoch': 0.29}


  5%|▍         | 785/16104 [3:42:15<77:36:23, 18.24s/it]
[2024-04-05 19:16:12,572] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6403, 'learning_rate': 1.99816807352968e-06, 'rewards/chosen': -0.3015059530735016, 'rewards/rejected': -0.24195098876953125, 'rewards/accuracies': 0.625, 'rewards/margins': -0.05955497920513153, 'policy_logps/rejected': -522.068115234375, 'policy_logps/chosen': -563.1943969726562, 'referece_logps/rejected': -519.6486206054688, 'referece_logps/chosen': -560.1793823242188, 'logits/rejected': -0.06778499484062195, 'logits/chosen': -0.03329741954803467, 'epoch': 0.29}
[2024-04-05 19:16:27,411] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 786/16104 [3:42:30<73:15:50, 17.22s/it]

  5%|▍         | 787/16104 [3:42:46<71:35:57, 16.83s/it]


  5%|▍         | 789/16104 [3:43:18<70:51:08, 16.65s/it]

  5%|▍         | 790/16104 [3:43:39<76:48:37, 18.06s/it]

  5%|▍         | 791/16104 [3:44:01<81:26:01, 19.14s/it]

  5%|▍         | 792/16104 [3:44:14<73:13:00, 17.21s/it]

  5%|▍         | 793/16104 [3:44:27<68:37:53, 16.14s/it]

  5%|▍         | 794/16104 [3:44:47<73:36:54, 17.31s/it]

  5%|▍         | 795/16104 [3:45:03<71:51:55, 16.90s/it]

  5%|▍         | 796/16104 [3:45:20<71:20:34, 16.78s/it]
{'loss': 0.5837, 'learning_rate': 1.998031776728211e-06, 'rewards/chosen': 0.175774946808815, 'rewards/rejected': -0.39530104398727417, 'rewards/accuracies': 0.625, 'rewards/margins': 0.571075975894928, 'policy_logps/rejected': -277.0272216796875, 'policy_logps/chosen': -421.30120849609375, 'referece_logps/rejected': -273.07421875, 'referece_logps/chosen': -423.0589599609375, 'logits/rejected': -0.40573447942733765, 'logits/chosen': -0.4694368243217468, 'epoch': 0.3}


  5%|▍         | 798/16104 [3:45:42<59:26:59, 13.98s/it]

  5%|▍         | 799/16104 [3:46:00<64:22:58, 15.14s/it]
{'loss': 0.6503, 'learning_rate': 1.9979937570294745e-06, 'rewards/chosen': -0.10145033895969391, 'rewards/rejected': -0.29084813594818115, 'rewards/accuracies': 0.625, 'rewards/margins': 0.18939782679080963, 'policy_logps/rejected': -390.28851318359375, 'policy_logps/chosen': -563.7027587890625, 'referece_logps/rejected': -387.38006591796875, 'referece_logps/chosen': -562.6882934570312, 'logits/rejected': -0.4654356837272644, 'logits/chosen': -0.5506795644760132, 'epoch': 0.3}

  5%|▍         | 800/16104 [3:46:13<61:15:51, 14.41s/it]

  5%|▍         | 801/16104 [3:46:35<71:40:28, 16.86s/it]

  5%|▍         | 802/16104 [3:46:54<74:43:27, 17.58s/it]

  5%|▍         | 803/16104 [3:47:13<75:27:40, 17.75s/it]

  5%|▍         | 804/16104 [3:47:35<81:04:06, 19.07s/it]

  5%|▍         | 805/16104 [3:47:45<70:18:36, 16.54s/it]
[2024-04-05 19:22:04,461] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▌         | 806/16104 [3:48:07<76:57:27, 18.11s/it]

  5%|▌         | 807/16104 [3:48:27<78:38:44, 18.51s/it]


  5%|▌         | 809/16104 [3:49:00<73:21:29, 17.27s/it]

  5%|▌         | 810/16104 [3:49:12<66:47:40, 15.72s/it]
{'loss': 0.561, 'learning_rate': 1.9978512430358297e-06, 'rewards/chosen': -0.010179713368415833, 'rewards/rejected': -0.20866796374320984, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1984882354736328, 'policy_logps/rejected': -405.1023864746094, 'policy_logps/chosen': -510.5521240234375, 'referece_logps/rejected': -403.01568603515625, 'referece_logps/chosen': -510.45025634765625, 'logits/rejected': -0.14118465781211853, 'logits/chosen': -0.34616196155548096, 'epoch': 0.3}


  5%|▌         | 812/16104 [3:49:46<70:30:31, 16.60s/it]
{'loss': 0.5634, 'learning_rate': 1.9978248066367877e-06, 'rewards/chosen': 0.086554154753685, 'rewards/rejected': -0.12490072846412659, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2114548683166504, 'policy_logps/rejected': -377.5103454589844, 'policy_logps/chosen': -386.517822265625, 'referece_logps/rejected': -376.2613525390625, 'referece_logps/chosen': -387.38336181640625, 'logits/rejected': -0.1116345226764679, 'logits/chosen': 0.0415828675031662, 'epoch': 0.3}


  5%|▌         | 814/16104 [3:50:30<81:27:21, 19.18s/it]
[2024-04-05 19:24:27,208] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5125, 'learning_rate': 1.9977982087825712e-06, 'rewards/chosen': -0.12122900038957596, 'rewards/rejected': -0.7316011190414429, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6103721857070923, 'policy_logps/rejected': -539.7660522460938, 'policy_logps/chosen': -502.7598571777344, 'referece_logps/rejected': -532.4500122070312, 'referece_logps/chosen': -501.5475769042969, 'logits/rejected': 0.3677377700805664, 'logits/chosen': 0.33089345693588257, 'epoch': 0.3}
[2024-04-05 19:24:42,389] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  5%|▌         | 816/16104 [3:51:00<72:05:23, 16.98s/it]
{'loss': 0.5381, 'learning_rate': 1.9977714494774837e-06, 'rewards/chosen': 0.0232512466609478, 'rewards/rejected': -0.5950902700424194, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6183415651321411, 'policy_logps/rejected': -486.4725036621094, 'policy_logps/chosen': -571.063720703125, 'referece_logps/rejected': -480.5216064453125, 'referece_logps/chosen': -571.2962646484375, 'logits/rejected': -0.9354128837585449, 'logits/chosen': -0.7665528059005737, 'epoch': 0.3}
[2024-04-05 19:25:16,057] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  5%|▌         | 818/16104 [3:51:38<76:29:59, 18.02s/it]
{'loss': 0.6206, 'learning_rate': 1.9977445287258553e-06, 'rewards/chosen': 0.04887428879737854, 'rewards/rejected': 0.10507487505674362, 'rewards/accuracies': 0.5, 'rewards/margins': -0.05620058625936508, 'policy_logps/rejected': -380.9435119628906, 'policy_logps/chosen': -478.29522705078125, 'referece_logps/rejected': -381.9942626953125, 'referece_logps/chosen': -478.783935546875, 'logits/rejected': 0.46458545327186584, 'logits/chosen': 0.7008065581321716, 'epoch': 0.3}

  5%|▌         | 819/16104 [3:51:55<76:06:42, 17.93s/it]

  5%|▌         | 820/16104 [3:52:07<68:25:02, 16.12s/it]


  5%|▌         | 822/16104 [3:52:38<65:24:29, 15.41s/it]
{'loss': 0.6051, 'learning_rate': 1.997690202900426e-06, 'rewards/chosen': -0.17373809218406677, 'rewards/rejected': -0.5874304175376892, 'rewards/accuracies': 0.375, 'rewards/margins': 0.41369229555130005, 'policy_logps/rejected': -469.06011962890625, 'policy_logps/chosen': -493.5552978515625, 'referece_logps/rejected': -463.18585205078125, 'referece_logps/chosen': -491.81787109375, 'logits/rejected': 0.19711488485336304, 'logits/chosen': 0.1511155366897583, 'epoch': 0.31}

  5%|▌         | 823/16104 [3:52:49<60:01:24, 14.14s/it]

  5%|▌         | 824/16104 [3:53:09<67:18:04, 15.86s/it]
[2024-04-05 19:27:26,750] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  5%|▌         | 826/16104 [3:53:44<69:48:40, 16.45s/it]

  5%|▌         | 827/16104 [3:54:00<69:43:25, 16.43s/it]
{'loss': 0.6464, 'learning_rate': 1.997621387559991e-06, 'rewards/chosen': 0.02315712533891201, 'rewards/rejected': -0.20441246032714844, 'rewards/accuracies': 0.75, 'rewards/margins': 0.227569580078125, 'policy_logps/rejected': -489.0515441894531, 'policy_logps/chosen': -474.68255615234375, 'referece_logps/rejected': -487.0074462890625, 'referece_logps/chosen': -474.9140930175781, 'logits/rejected': -0.27212679386138916, 'logits/chosen': -0.269462525844574, 'epoch': 0.31}

  5%|▌         | 828/16104 [3:54:24<78:27:33, 18.49s/it]


  5%|▌         | 830/16104 [3:54:48<64:54:17, 15.30s/it]

  5%|▌         | 831/16104 [3:54:59<59:00:33, 13.91s/it]
{'loss': 0.6658, 'learning_rate': 1.9975656088841503e-06, 'rewards/chosen': 0.29614850878715515, 'rewards/rejected': -0.1216663345694542, 'rewards/accuracies': 0.75, 'rewards/margins': 0.41781482100486755, 'policy_logps/rejected': -419.8984375, 'policy_logps/chosen': -471.2235412597656, 'referece_logps/rejected': -418.6817626953125, 'referece_logps/chosen': -474.18505859375, 'logits/rejected': -0.1402752548456192, 'logits/chosen': -0.13279934227466583, 'epoch': 0.31}


  5%|▌         | 833/16104 [3:55:30<65:08:06, 15.36s/it]
[2024-04-05 19:29:27,495] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▌         | 834/16104 [3:55:48<68:33:59, 16.16s/it]
[2024-04-05 19:29:45,550] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▌         | 835/16104 [3:56:04<68:00:03, 16.03s/it]
{'loss': 0.6374, 'learning_rate': 1.997509184555398e-06, 'rewards/chosen': 0.16212043166160583, 'rewards/rejected': 0.22075462341308594, 'rewards/accuracies': 0.625, 'rewards/margins': -0.058634184300899506, 'policy_logps/rejected': -508.9278259277344, 'policy_logps/chosen': -502.7895812988281, 'referece_logps/rejected': -511.13543701171875, 'referece_logps/chosen': -504.4107360839844, 'logits/rejected': 0.5152312517166138, 'logits/chosen': 0.3445334732532501, 'epoch': 0.31}


  5%|▌         | 837/16104 [3:56:39<73:20:58, 17.30s/it]
{'loss': 0.5207, 'learning_rate': 1.997480730282576e-06, 'rewards/chosen': 0.34244459867477417, 'rewards/rejected': -0.18194332718849182, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5243879556655884, 'policy_logps/rejected': -398.7942199707031, 'policy_logps/chosen': -360.9169616699219, 'referece_logps/rejected': -396.97479248046875, 'referece_logps/chosen': -364.3414306640625, 'logits/rejected': -0.4105220437049866, 'logits/chosen': -0.36295828223228455, 'epoch': 0.31}


  5%|▌         | 839/16104 [3:57:21<80:23:51, 18.96s/it]

  5%|▌         | 840/16104 [3:57:38<78:59:37, 18.63s/it]
{'loss': 0.5932, 'learning_rate': 1.997437746250725e-06, 'rewards/chosen': 0.2504880428314209, 'rewards/rejected': -0.3532387614250183, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6037267446517944, 'policy_logps/rejected': -369.93402099609375, 'policy_logps/chosen': -430.4269104003906, 'referece_logps/rejected': -366.401611328125, 'referece_logps/chosen': -432.9317626953125, 'logits/rejected': 0.6292499303817749, 'logits/chosen': 0.5963992476463318, 'epoch': 0.31}

  5%|▌         | 841/16104 [3:57:49<68:58:00, 16.27s/it]

  5%|▌         | 842/16104 [3:58:11<76:40:30, 18.09s/it]


  5%|▌         | 844/16104 [3:58:38<65:30:56, 15.46s/it]

  5%|▌         | 845/16104 [3:58:59<71:38:56, 16.90s/it]
{'loss': 0.5213, 'learning_rate': 1.9973652992427153e-06, 'rewards/chosen': -0.07695311307907104, 'rewards/rejected': -0.6323860287666321, 'rewards/accuracies': 0.75, 'rewards/margins': 0.555432915687561, 'policy_logps/rejected': -440.7523498535156, 'policy_logps/chosen': -572.482421875, 'referece_logps/rejected': -434.42852783203125, 'referece_logps/chosen': -571.712890625, 'logits/rejected': -0.15113848447799683, 'logits/chosen': -0.22500735521316528, 'epoch': 0.31}

  5%|▌         | 846/16104 [3:59:20<77:00:04, 18.17s/it]
[2024-04-05 19:33:36,442] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  5%|▌         | 848/16104 [4:00:01<82:47:31, 19.54s/it]

  5%|▌         | 849/16104 [4:00:12<72:30:12, 17.11s/it]

  5%|▌         | 850/16104 [4:00:27<69:23:48, 16.38s/it]
{'loss': 0.6265, 'learning_rate': 1.9972918436046334e-06, 'rewards/chosen': 0.4233783781528473, 'rewards/rejected': 0.029864132404327393, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3935142755508423, 'policy_logps/rejected': -498.059326171875, 'policy_logps/chosen': -488.3482666015625, 'referece_logps/rejected': -498.35797119140625, 'referece_logps/chosen': -492.58203125, 'logits/rejected': -0.17053429782390594, 'logits/chosen': -0.14408543705940247, 'epoch': 0.32}

  5%|▌         | 851/16104 [4:00:40<65:06:36, 15.37s/it]

  5%|▌         | 852/16104 [4:00:55<65:07:48, 15.37s/it]

  5%|▌         | 853/16104 [4:01:12<66:39:24, 15.73s/it]


  5%|▌         | 855/16104 [4:01:47<70:23:03, 16.62s/it]
[2024-04-05 19:35:44,244] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6288, 'learning_rate': 1.997217379410765e-06, 'rewards/chosen': 0.26085397601127625, 'rewards/rejected': -0.06031857430934906, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3211725354194641, 'policy_logps/rejected': -506.0113830566406, 'policy_logps/chosen': -519.932861328125, 'referece_logps/rejected': -505.40826416015625, 'referece_logps/chosen': -522.5414428710938, 'logits/rejected': 0.3230675160884857, 'logits/chosen': 0.3051842749118805, 'epoch': 0.32}

  5%|▌         | 856/16104 [4:02:04<70:32:49, 16.66s/it]


  5%|▌         | 858/16104 [4:02:29<61:17:32, 14.47s/it]

  5%|▌         | 859/16104 [4:02:47<65:29:52, 15.47s/it]

  5%|▌         | 860/16104 [4:03:03<66:22:13, 15.67s/it]

  5%|▌         | 861/16104 [4:03:17<63:51:02, 15.08s/it]

  5%|▌         | 862/16104 [4:03:29<59:48:12, 14.12s/it]

  5%|▌         | 863/16104 [4:03:47<65:13:02, 15.40s/it]

  5%|▌         | 864/16104 [4:03:59<61:03:44, 14.42s/it]

  5%|▌         | 865/16104 [4:04:19<68:24:20, 16.16s/it]

  5%|▌         | 866/16104 [4:04:31<62:51:04, 14.85s/it]

  5%|▌         | 867/16104 [4:04:45<61:07:57, 14.44s/it]

  5%|▌         | 868/16104 [4:05:03<65:38:37, 15.51s/it]
{'loss': 0.527, 'learning_rate': 1.9970190530089426e-06, 'rewards/chosen': 0.025855720043182373, 'rewards/rejected': -0.22120784223079681, 'rewards/accuracies': 0.75, 'rewards/margins': 0.247063547372818, 'policy_logps/rejected': -449.970458984375, 'policy_logps/chosen': -474.37042236328125, 'referece_logps/rejected': -447.7583923339844, 'referece_logps/chosen': -474.62896728515625, 'logits/rejected': -0.227366104722023, 'logits/chosen': -0.2701864540576935, 'epoch': 0.32}

  5%|▌         | 869/16104 [4:05:21<68:42:29, 16.24s/it]


  5%|▌         | 871/16104 [4:05:55<72:30:28, 17.14s/it]
{'loss': 0.67, 'learning_rate': 1.996972317379188e-06, 'rewards/chosen': 0.04203491657972336, 'rewards/rejected': -0.043743133544921875, 'rewards/accuracies': 0.375, 'rewards/margins': 0.08577805012464523, 'policy_logps/rejected': -429.5148010253906, 'policy_logps/chosen': -515.1239013671875, 'referece_logps/rejected': -429.077392578125, 'referece_logps/chosen': -515.5443115234375, 'logits/rejected': -0.5079385638237, 'logits/chosen': -0.3675559461116791, 'epoch': 0.32}


  5%|▌         | 873/16104 [4:06:27<70:55:01, 16.76s/it]
{'loss': 0.6046, 'learning_rate': 1.9969409586450876e-06, 'rewards/chosen': 0.11550389230251312, 'rewards/rejected': -0.6312911510467529, 'rewards/accuracies': 0.75, 'rewards/margins': 0.746795117855072, 'policy_logps/rejected': -438.2391662597656, 'policy_logps/chosen': -481.16351318359375, 'referece_logps/rejected': -431.92633056640625, 'referece_logps/chosen': -482.31854248046875, 'logits/rejected': -0.4917762279510498, 'logits/chosen': -0.5742952227592468, 'epoch': 0.33}
[2024-04-05 19:40:42,773] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▌         | 874/16104 [4:06:45<72:41:13, 17.18s/it]


  5%|▌         | 876/16104 [4:07:22<73:14:40, 17.32s/it]
{'loss': 0.5942, 'learning_rate': 1.996893618085227e-06, 'rewards/chosen': -0.0011677681468427181, 'rewards/rejected': -0.2257196456193924, 'rewards/accuracies': 0.625, 'rewards/margins': 0.22455188632011414, 'policy_logps/rejected': -413.2569274902344, 'policy_logps/chosen': -388.20513916015625, 'referece_logps/rejected': -410.999755859375, 'referece_logps/chosen': -388.1934509277344, 'logits/rejected': 0.5557346343994141, 'logits/chosen': 0.5216863751411438, 'epoch': 0.33}

  5%|▌         | 877/16104 [4:07:43<78:04:11, 18.46s/it]

  5%|▌         | 878/16104 [4:08:04<81:46:40, 19.34s/it]
[2024-04-05 19:42:19,790] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▌         | 879/16104 [4:08:23<80:42:47, 19.08s/it]

  5%|▌         | 880/16104 [4:08:38<76:28:55, 18.09s/it]


  5%|▌         | 882/16104 [4:09:07<69:24:17, 16.41s/it]
{'loss': 0.5572, 'learning_rate': 1.9967978481775063e-06, 'rewards/chosen': 0.620006799697876, 'rewards/rejected': 0.3770930767059326, 'rewards/accuracies': 0.75, 'rewards/margins': 0.24291367828845978, 'policy_logps/rejected': -402.0443115234375, 'policy_logps/chosen': -608.3073120117188, 'referece_logps/rejected': -405.8152770996094, 'referece_logps/chosen': -614.50732421875, 'logits/rejected': -0.11549697816371918, 'logits/chosen': -0.07822224497795105, 'epoch': 0.33}

  5%|▌         | 883/16104 [4:09:27<73:38:19, 17.42s/it]


  5%|▌         | 885/16104 [4:09:53<65:38:22, 15.53s/it]
{'loss': 0.7166, 'learning_rate': 1.996749418864512e-06, 'rewards/chosen': -0.3252790570259094, 'rewards/rejected': 0.08236046880483627, 'rewards/accuracies': 0.375, 'rewards/margins': -0.4076395034790039, 'policy_logps/rejected': -536.5975952148438, 'policy_logps/chosen': -368.4472961425781, 'referece_logps/rejected': -537.4212036132812, 'referece_logps/chosen': -365.19451904296875, 'logits/rejected': -0.1720622181892395, 'logits/chosen': -0.07573816180229187, 'epoch': 0.33}
[2024-04-05 19:44:11,969] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  6%|▌         | 887/16104 [4:10:31<72:17:52, 17.10s/it]

  6%|▌         | 888/16104 [4:10:48<71:06:41, 16.82s/it]
{'loss': 0.6407, 'learning_rate': 1.996700626668894e-06, 'rewards/chosen': 0.26134300231933594, 'rewards/rejected': -0.2186639904975891, 'rewards/accuracies': 0.625, 'rewards/margins': 0.48000699281692505, 'policy_logps/rejected': -303.183837890625, 'policy_logps/chosen': -380.1412048339844, 'referece_logps/rejected': -300.9972229003906, 'referece_logps/chosen': -382.75457763671875, 'logits/rejected': 0.18994936347007751, 'logits/chosen': 0.24619118869304657, 'epoch': 0.33}

  6%|▌         | 889/16104 [4:11:04<71:04:31, 16.82s/it]


  6%|▌         | 891/16104 [4:11:35<67:33:53, 15.99s/it]
{'loss': 0.6948, 'learning_rate': 1.996651471608415e-06, 'rewards/chosen': -0.03642311692237854, 'rewards/rejected': -0.27760574221611023, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2411825954914093, 'policy_logps/rejected': -345.53436279296875, 'policy_logps/chosen': -564.076171875, 'referece_logps/rejected': -342.7582702636719, 'referece_logps/chosen': -563.7119140625, 'logits/rejected': -0.9599214792251587, 'logits/chosen': -0.9648035764694214, 'epoch': 0.33}


  6%|▌         | 893/16104 [4:12:12<74:10:22, 17.55s/it]

  6%|▌         | 894/16104 [4:12:33<79:06:59, 18.73s/it]

  6%|▌         | 895/16104 [4:12:53<81:00:31, 19.17s/it]
{'loss': 0.555, 'learning_rate': 1.9965853671022763e-06, 'rewards/chosen': -0.2514811158180237, 'rewards/rejected': -0.7690055966377258, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5175245404243469, 'policy_logps/rejected': -384.0321350097656, 'policy_logps/chosen': -415.42132568359375, 'referece_logps/rejected': -376.34210205078125, 'referece_logps/chosen': -412.906494140625, 'logits/rejected': -0.8041541576385498, 'logits/chosen': -0.8826768398284912, 'epoch': 0.33}

  6%|▌         | 896/16104 [4:13:11<79:08:46, 18.74s/it]

  6%|▌         | 897/16104 [4:13:30<79:41:13, 18.86s/it]


  6%|▌         | 899/16104 [4:13:59<71:37:25, 16.96s/it]

  6%|▌         | 900/16104 [4:14:21<78:06:37, 18.49s/it]
[2024-04-05 19:48:18,541] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5971, 'learning_rate': 1.9965018294174306e-06, 'rewards/chosen': 0.19044038653373718, 'rewards/rejected': -0.6581368446350098, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8485772013664246, 'policy_logps/rejected': -354.57867431640625, 'policy_logps/chosen': -620.0034790039062, 'referece_logps/rejected': -347.997314453125, 'referece_logps/chosen': -621.907958984375, 'logits/rejected': 0.5919292569160461, 'logits/chosen': 0.48843103647232056, 'epoch': 0.34}

  6%|▌         | 901/16104 [4:14:41<79:20:54, 18.79s/it]


  6%|▌         | 903/16104 [4:15:16<76:02:16, 18.01s/it]
{'loss': 0.5404, 'learning_rate': 1.9964512230777865e-06, 'rewards/chosen': 0.13155804574489594, 'rewards/rejected': -0.03590316325426102, 'rewards/accuracies': 0.5, 'rewards/margins': 0.16746120154857635, 'policy_logps/rejected': -427.67498779296875, 'policy_logps/chosen': -509.3622131347656, 'referece_logps/rejected': -427.31597900390625, 'referece_logps/chosen': -510.6778259277344, 'logits/rejected': 0.07754135131835938, 'logits/chosen': 0.06281472742557526, 'epoch': 0.34}


  6%|▌         | 905/16104 [4:15:52<76:32:32, 18.13s/it]
{'loss': 0.5577, 'learning_rate': 1.996417283975736e-06, 'rewards/chosen': 0.36455509066581726, 'rewards/rejected': -0.5288181304931641, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8933733105659485, 'policy_logps/rejected': -555.8384399414062, 'policy_logps/chosen': -514.994873046875, 'referece_logps/rejected': -550.55029296875, 'referece_logps/chosen': -518.6404418945312, 'logits/rejected': -0.1439078003168106, 'logits/chosen': -0.2521284222602844, 'epoch': 0.34}

  6%|▌         | 906/16104 [4:16:07<72:32:40, 17.18s/it]

  6%|▌         | 907/16104 [4:16:27<76:27:32, 18.11s/it]

  6%|▌         | 908/16104 [4:16:40<70:29:28, 16.70s/it]

  6%|▌         | 909/16104 [4:16:53<64:46:18, 15.35s/it]


  6%|▌         | 911/16104 [4:17:30<72:22:11, 17.15s/it]
{'loss': 0.5675, 'learning_rate': 1.9963144993271165e-06, 'rewards/chosen': -0.13456973433494568, 'rewards/rejected': -0.38743236660957336, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2528626322746277, 'policy_logps/rejected': -320.19683837890625, 'policy_logps/chosen': -284.85479736328125, 'referece_logps/rejected': -316.322509765625, 'referece_logps/chosen': -283.5091247558594, 'logits/rejected': -0.2630113959312439, 'logits/chosen': -0.27225860953330994, 'epoch': 0.34}

  6%|▌         | 912/16104 [4:17:50<75:32:15, 17.90s/it]

  6%|▌         | 913/16104 [4:18:00<66:19:00, 15.72s/it]

  6%|▌         | 914/16104 [4:18:21<72:34:54, 17.20s/it]

  6%|▌         | 915/16104 [4:18:32<65:03:41, 15.42s/it]

  6%|▌         | 916/16104 [4:18:44<60:34:36, 14.36s/it]

  6%|▌         | 917/16104 [4:19:01<63:28:56, 15.05s/it]

  6%|▌         | 918/16104 [4:19:21<69:44:50, 16.53s/it]

  6%|▌         | 919/16104 [4:19:41<75:09:12, 17.82s/it]

  6%|▌         | 920/16104 [4:20:03<80:24:14, 19.06s/it]

  6%|▌         | 921/16104 [4:20:20<77:42:30, 18.43s/it]

  6%|▌         | 922/16104 [4:20:41<80:24:47, 19.07s/it]

  6%|▌         | 923/16104 [4:21:00<80:10:51, 19.01s/it]


  6%|▌         | 925/16104 [4:21:34<74:40:52, 17.71s/it]

  6%|▌         | 926/16104 [4:21:46<67:37:39, 16.04s/it]
{'loss': 0.6812, 'learning_rate': 1.9960511903637875e-06, 'rewards/chosen': -0.15941409766674042, 'rewards/rejected': -0.6915724277496338, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5321582555770874, 'policy_logps/rejected': -417.57879638671875, 'policy_logps/chosen': -413.8616638183594, 'referece_logps/rejected': -410.66302490234375, 'referece_logps/chosen': -412.2675476074219, 'logits/rejected': 0.015849262475967407, 'logits/chosen': 0.004663929343223572, 'epoch': 0.35}

  6%|▌         | 927/16104 [4:22:03<68:02:37, 16.14s/it]

  6%|▌         | 928/16104 [4:22:16<64:09:40, 15.22s/it]


  6%|▌         | 930/16104 [4:22:46<64:45:42, 15.36s/it]
{'loss': 0.6356, 'learning_rate': 1.9959794434426926e-06, 'rewards/chosen': -0.039686497300863266, 'rewards/rejected': -0.4583473205566406, 'rewards/accuracies': 0.75, 'rewards/margins': 0.41866081953048706, 'policy_logps/rejected': -548.1266479492188, 'policy_logps/chosen': -478.8771057128906, 'referece_logps/rejected': -543.5431518554688, 'referece_logps/chosen': -478.4802551269531, 'logits/rejected': -0.4907661974430084, 'logits/chosen': -0.5576364398002625, 'epoch': 0.35}


  6%|▌         | 932/16104 [4:23:21<68:55:45, 16.36s/it]
{'loss': 0.5361, 'learning_rate': 1.9959433282443638e-06, 'rewards/chosen': 0.04005478695034981, 'rewards/rejected': -0.047959424555301666, 'rewards/accuracies': 0.75, 'rewards/margins': 0.08801424503326416, 'policy_logps/rejected': -535.0252685546875, 'policy_logps/chosen': -473.1632080078125, 'referece_logps/rejected': -534.545654296875, 'referece_logps/chosen': -473.56378173828125, 'logits/rejected': -0.5225001573562622, 'logits/chosen': -0.4277011752128601, 'epoch': 0.35}


  6%|▌         | 934/16104 [4:23:45<60:04:58, 14.26s/it]
{'loss': 0.605, 'learning_rate': 1.995907051895297e-06, 'rewards/chosen': 0.09903594106435776, 'rewards/rejected': -0.33160606026649475, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4306420385837555, 'policy_logps/rejected': -260.65936279296875, 'policy_logps/chosen': -387.925537109375, 'referece_logps/rejected': -257.34332275390625, 'referece_logps/chosen': -388.9158630371094, 'logits/rejected': -0.7103381156921387, 'logits/chosen': -0.5416053533554077, 'epoch': 0.35}

  6%|▌         | 935/16104 [4:23:55<54:50:19, 13.01s/it]

  6%|▌         | 936/16104 [4:24:14<63:02:31, 14.96s/it]

  6%|▌         | 937/16104 [4:24:34<68:47:38, 16.33s/it]


  6%|▌         | 939/16104 [4:25:08<72:21:45, 17.18s/it]
{'loss': 0.6084, 'learning_rate': 1.9958156560267367e-06, 'rewards/chosen': 0.44051456451416016, 'rewards/rejected': -0.07152194529771805, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5120365619659424, 'policy_logps/rejected': -402.1792907714844, 'policy_logps/chosen': -480.39141845703125, 'referece_logps/rejected': -401.4640197753906, 'referece_logps/chosen': -484.7966003417969, 'logits/rejected': -1.3104952573776245, 'logits/chosen': -1.2895218133926392, 'epoch': 0.35}

  6%|▌         | 940/16104 [4:25:19<64:12:32, 15.24s/it]

  6%|▌         | 941/16104 [4:25:32<61:40:30, 14.64s/it]

  6%|▌         | 942/16104 [4:25:48<63:16:12, 15.02s/it]

  6%|▌         | 943/16104 [4:26:03<62:40:03, 14.88s/it]

  6%|▌         | 944/16104 [4:26:16<59:51:31, 14.21s/it]

  6%|▌         | 945/16104 [4:26:27<56:50:19, 13.50s/it]

  6%|▌         | 946/16104 [4:26:47<64:26:26, 15.30s/it]

  6%|▌         | 947/16104 [4:27:10<74:40:12, 17.74s/it]

  6%|▌         | 948/16104 [4:27:21<66:11:10, 15.72s/it]


  6%|▌         | 950/16104 [4:27:51<62:48:14, 14.92s/it]
{'loss': 0.5951, 'learning_rate': 1.995611040386048e-06, 'rewards/chosen': 0.10831347107887268, 'rewards/rejected': -0.3948904573917389, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5032039880752563, 'policy_logps/rejected': -438.39495849609375, 'policy_logps/chosen': -479.1739807128906, 'referece_logps/rejected': -434.446044921875, 'referece_logps/chosen': -480.2571105957031, 'logits/rejected': 0.37109485268592834, 'logits/chosen': 0.30615726113319397, 'epoch': 0.35}

  6%|▌         | 951/16104 [4:28:11<69:24:24, 16.49s/it]

  6%|▌         | 952/16104 [4:28:32<75:36:04, 17.96s/it]

  6%|▌         | 953/16104 [4:28:53<79:01:03, 18.78s/it]
[2024-04-05 20:03:10,674] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 954/16104 [4:29:13<81:08:41, 19.28s/it]

  6%|▌         | 955/16104 [4:29:24<70:33:54, 16.77s/it]

  6%|▌         | 956/16104 [4:29:38<67:05:20, 15.94s/it]

  6%|▌         | 957/16104 [4:29:54<67:03:45, 15.94s/it]

  6%|▌         | 958/16104 [4:30:16<73:56:46, 17.58s/it]

  6%|▌         | 959/16104 [4:30:29<69:00:20, 16.40s/it]

  6%|▌         | 960/16104 [4:30:48<72:15:21, 17.18s/it]


  6%|▌         | 962/16104 [4:31:25<73:42:11, 17.52s/it]

  6%|▌         | 963/16104 [4:31:48<80:41:12, 19.18s/it]

  6%|▌         | 964/16104 [4:32:04<75:39:18, 17.99s/it]

  6%|▌         | 965/16104 [4:32:22<76:35:28, 18.21s/it]

  6%|▌         | 966/16104 [4:32:40<76:03:57, 18.09s/it]

  6%|▌         | 967/16104 [4:33:01<79:04:27, 18.81s/it]

  6%|▌         | 968/16104 [4:33:20<79:19:58, 18.87s/it]

  6%|▌         | 969/16104 [4:33:32<70:38:08, 16.80s/it]

  6%|▌         | 970/16104 [4:33:54<77:35:40, 18.46s/it]

  6%|▌         | 971/16104 [4:34:11<76:08:36, 18.11s/it]

  6%|▌         | 972/16104 [4:34:24<68:56:18, 16.40s/it]

  6%|▌         | 973/16104 [4:34:36<64:14:54, 15.29s/it]

  6%|▌         | 974/16104 [4:34:52<64:28:13, 15.34s/it]

  6%|▌         | 975/16104 [4:35:12<70:21:37, 16.74s/it]

  6%|▌         | 976/16104 [4:35:25<66:06:43, 15.73s/it]

  6%|▌         | 977/16104 [4:35:44<69:50:43, 16.62s/it]

  6%|▌         | 978/16104 [4:35:56<64:00:16, 15.23s/it]

  6%|▌         | 979/16104 [4:36:09<61:02:21, 14.53s/it]

  6%|▌         | 980/16104 [4:36:31<70:18:03, 16.73s/it]
[2024-04-05 20:10:27,923] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 981/16104 [4:36:50<73:12:15, 17.43s/it]
[2024-04-05 20:10:46,964] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 982/16104 [4:37:01<65:00:32, 15.48s/it]

  6%|▌         | 983/16104 [4:37:14<62:11:07, 14.81s/it]
{'loss': 0.5652, 'learning_rate': 1.994967958500574e-06, 'rewards/chosen': -0.045941442251205444, 'rewards/rejected': -0.5712471604347229, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5253057479858398, 'policy_logps/rejected': -285.27301025390625, 'policy_logps/chosen': -365.3915710449219, 'referece_logps/rejected': -279.5605163574219, 'referece_logps/chosen': -364.93212890625, 'logits/rejected': 0.15273690223693848, 'logits/chosen': 0.19462263584136963, 'epoch': 0.37}


  6%|▌         | 985/16104 [4:37:47<66:12:43, 15.77s/it]

  6%|▌         | 986/16104 [4:38:00<62:14:06, 14.82s/it]

  6%|▌         | 987/16104 [4:38:13<60:15:33, 14.35s/it]

  6%|▌         | 988/16104 [4:38:33<67:28:16, 16.07s/it]

  6%|▌         | 989/16104 [4:38:44<60:36:35, 14.44s/it]

  6%|▌         | 990/16104 [4:38:55<55:55:41, 13.32s/it]

  6%|▌         | 991/16104 [4:39:12<60:50:04, 14.49s/it]

  6%|▌         | 992/16104 [4:39:30<64:46:24, 15.43s/it]

  6%|▌         | 993/16104 [4:39:44<63:19:15, 15.09s/it]
{'loss': 0.5428, 'learning_rate': 1.9947644305139816e-06, 'rewards/chosen': -0.051209837198257446, 'rewards/rejected': -0.5905107259750366, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5393009185791016, 'policy_logps/rejected': -462.955078125, 'policy_logps/chosen': -457.4886474609375, 'referece_logps/rejected': -457.04998779296875, 'referece_logps/chosen': -456.9765625, 'logits/rejected': -0.3111858069896698, 'logits/chosen': -0.2415665239095688, 'epoch': 0.37}


  6%|▌         | 995/16104 [4:40:22<73:49:42, 17.59s/it]

  6%|▌         | 996/16104 [4:40:39<71:56:15, 17.14s/it]
{'loss': 0.5721, 'learning_rate': 1.994702587400451e-06, 'rewards/chosen': 0.35782358050346375, 'rewards/rejected': -0.17988453805446625, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5377081036567688, 'policy_logps/rejected': -668.60693359375, 'policy_logps/chosen': -544.0595703125, 'referece_logps/rejected': -666.80810546875, 'referece_logps/chosen': -547.6378784179688, 'logits/rejected': -0.666720986366272, 'logits/chosen': -0.3420177698135376, 'epoch': 0.37}


  6%|▌         | 998/16104 [4:41:14<73:24:13, 17.49s/it]

  6%|▌         | 999/16104 [4:41:36<78:43:16, 18.76s/it]

  6%|▌         | 1000/16104 [4:41:58<82:30:10, 19.66s/it]
[2024-04-05 20:15:55,255] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 1001/16104 [4:42:26<92:47:33, 22.12s/it]

  6%|▌         | 1002/16104 [4:42:39<81:35:00, 19.45s/it]

  6%|▌         | 1003/16104 [4:42:54<76:02:48, 18.13s/it]

  6%|▌         | 1004/16104 [4:43:05<66:55:12, 15.95s/it]

  6%|▌         | 1005/16104 [4:43:18<63:37:29, 15.17s/it]

  6%|▌         | 1006/16104 [4:43:31<60:44:58, 14.49s/it]

  6%|▋         | 1007/16104 [4:43:42<56:04:50, 13.37s/it]

  6%|▋         | 1008/16104 [4:43:53<53:26:14, 12.74s/it]

  6%|▋         | 1009/16104 [4:44:16<66:29:51, 15.86s/it]
[2024-04-05 20:18:13,655] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1010/16104 [4:44:33<67:32:50, 16.11s/it]
{'loss': 0.5773, 'learning_rate': 1.994409198309636e-06, 'rewards/chosen': -0.08568917214870453, 'rewards/rejected': 0.082855224609375, 'rewards/accuracies': 0.375, 'rewards/margins': -0.16854439675807953, 'policy_logps/rejected': -412.5118103027344, 'policy_logps/chosen': -354.92437744140625, 'referece_logps/rejected': -413.3403625488281, 'referece_logps/chosen': -354.0675048828125, 'logits/rejected': 0.3484185039997101, 'logits/chosen': 0.43478071689605713, 'epoch': 0.38}


  6%|▋         | 1012/16104 [4:45:07<70:36:37, 16.84s/it]

  6%|▋         | 1013/16104 [4:45:21<67:28:35, 16.10s/it]
{'loss': 0.5617, 'learning_rate': 1.994345303385502e-06, 'rewards/chosen': 0.1988758146762848, 'rewards/rejected': -0.4609432518482208, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6598190665245056, 'policy_logps/rejected': -323.435546875, 'policy_logps/chosen': -392.3117370605469, 'referece_logps/rejected': -318.82611083984375, 'referece_logps/chosen': -394.30047607421875, 'logits/rejected': -0.4686623811721802, 'logits/chosen': -0.3796378970146179, 'epoch': 0.38}


  6%|▋         | 1015/16104 [4:45:56<70:26:14, 16.81s/it]

  6%|▋         | 1016/16104 [4:46:14<71:56:33, 17.17s/it]
{'loss': 0.5924, 'learning_rate': 1.994281046454001e-06, 'rewards/chosen': -0.40108397603034973, 'rewards/rejected': -0.6500186920166016, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2489347606897354, 'policy_logps/rejected': -319.84423828125, 'policy_logps/chosen': -439.3219299316406, 'referece_logps/rejected': -313.3440856933594, 'referece_logps/chosen': -435.31109619140625, 'logits/rejected': 1.165345311164856, 'logits/chosen': 0.9593328237533569, 'epoch': 0.38}
[2024-04-05 20:20:22,818] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  6%|▋         | 1018/16104 [4:46:36<58:30:31, 13.96s/it]
{'loss': 0.6677, 'learning_rate': 1.9942380073960097e-06, 'rewards/chosen': -0.013855180703103542, 'rewards/rejected': -0.2797192931175232, 'rewards/accuracies': 0.75, 'rewards/margins': 0.26586416363716125, 'policy_logps/rejected': -357.40313720703125, 'policy_logps/chosen': -558.1051025390625, 'referece_logps/rejected': -354.6059265136719, 'referece_logps/chosen': -557.9666137695312, 'logits/rejected': -0.3577249348163605, 'logits/chosen': -0.5345014929771423, 'epoch': 0.38}


  6%|▋         | 1020/16104 [4:47:00<53:58:07, 12.88s/it]

  6%|▋         | 1021/16104 [4:47:20<62:38:34, 14.95s/it]
[2024-04-05 20:21:17,454] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1022/16104 [4:47:32<59:15:48, 14.15s/it]
{'loss': 0.6328, 'learning_rate': 1.9941514466626027e-06, 'rewards/chosen': 0.11762047559022903, 'rewards/rejected': 0.06901473551988602, 'rewards/accuracies': 0.5, 'rewards/margins': 0.04860573261976242, 'policy_logps/rejected': -479.8504943847656, 'policy_logps/chosen': -382.49505615234375, 'referece_logps/rejected': -480.5406799316406, 'referece_logps/chosen': -383.6712646484375, 'logits/rejected': -0.886888861656189, 'logits/chosen': -0.8320050835609436, 'epoch': 0.38}

  6%|▋         | 1023/16104 [4:47:44<55:35:21, 13.27s/it]


  6%|▋         | 1025/16104 [4:48:21<65:10:22, 15.56s/it]
{'loss': 0.613, 'learning_rate': 1.9940861038498885e-06, 'rewards/chosen': 0.0922330766916275, 'rewards/rejected': -0.44958651065826416, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5418195724487305, 'policy_logps/rejected': -573.352783203125, 'policy_logps/chosen': -552.481689453125, 'referece_logps/rejected': -568.8568725585938, 'referece_logps/chosen': -553.404052734375, 'logits/rejected': 1.0003986358642578, 'logits/chosen': 0.938396692276001, 'epoch': 0.38}


  6%|▋         | 1027/16104 [4:48:53<68:52:48, 16.45s/it]

  6%|▋         | 1028/16104 [4:49:09<68:00:22, 16.24s/it]
{'loss': 0.5594, 'learning_rate': 1.9940203991241728e-06, 'rewards/chosen': 0.16651278734207153, 'rewards/rejected': -0.7426193952560425, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9091320633888245, 'policy_logps/rejected': -409.5869445800781, 'policy_logps/chosen': -328.5608215332031, 'referece_logps/rejected': -402.16070556640625, 'referece_logps/chosen': -330.2259216308594, 'logits/rejected': -0.7722376585006714, 'logits/chosen': -0.7442501783370972, 'epoch': 0.38}


  6%|▋         | 1030/16104 [4:49:43<70:43:00, 16.89s/it]

  6%|▋         | 1031/16104 [4:49:56<65:00:57, 15.53s/it]

  6%|▋         | 1032/16104 [4:50:11<64:16:41, 15.35s/it]
{'loss': 0.5582, 'learning_rate': 1.9939322298888014e-06, 'rewards/chosen': 0.4518314599990845, 'rewards/rejected': 0.2765918970108032, 'rewards/accuracies': 0.75, 'rewards/margins': 0.17523956298828125, 'policy_logps/rejected': -506.6813659667969, 'policy_logps/chosen': -508.89093017578125, 'referece_logps/rejected': -509.44732666015625, 'referece_logps/chosen': -513.4092407226562, 'logits/rejected': -0.5424531102180481, 'logits/chosen': -0.3570377826690674, 'epoch': 0.38}

  6%|▋         | 1033/16104 [4:50:28<67:32:30, 16.13s/it]


  6%|▋         | 1035/16104 [4:51:05<72:46:38, 17.39s/it]

  6%|▋         | 1036/16104 [4:51:25<76:32:27, 18.29s/it]

  6%|▋         | 1037/16104 [4:51:45<78:34:52, 18.78s/it]
[2024-04-05 20:25:42,413] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1038/16104 [4:52:07<82:49:21, 19.79s/it]
{'loss': 0.6088, 'learning_rate': 1.993798769863781e-06, 'rewards/chosen': 0.13224995136260986, 'rewards/rejected': -0.37496691942214966, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5072168707847595, 'policy_logps/rejected': -287.87652587890625, 'policy_logps/chosen': -324.5792236328125, 'referece_logps/rejected': -284.1268615722656, 'referece_logps/chosen': -325.9017333984375, 'logits/rejected': -0.4619539976119995, 'logits/chosen': -0.5982676148414612, 'epoch': 0.39}

  6%|▋         | 1039/16104 [4:52:28<84:05:01, 20.09s/it]


  6%|▋         | 1041/16104 [4:53:07<81:40:54, 19.52s/it]

  6%|▋         | 1042/16104 [4:53:23<77:21:16, 18.49s/it]

  6%|▋         | 1043/16104 [4:53:40<75:09:15, 17.96s/it]

  6%|▋         | 1044/16104 [4:54:04<82:17:33, 19.67s/it]
[2024-04-05 20:28:00,819] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1045/16104 [4:54:18<75:40:27, 18.09s/it]

  6%|▋         | 1046/16104 [4:54:35<74:25:29, 17.79s/it]

  7%|▋         | 1047/16104 [4:54:50<70:51:09, 16.94s/it]
{'loss': 0.6074, 'learning_rate': 1.9935958663248603e-06, 'rewards/chosen': -0.4949834942817688, 'rewards/rejected': -0.6911625266075134, 'rewards/accuracies': 0.5, 'rewards/margins': 0.19617897272109985, 'policy_logps/rejected': -301.3493347167969, 'policy_logps/chosen': -318.31512451171875, 'referece_logps/rejected': -294.437744140625, 'referece_logps/chosen': -313.36529541015625, 'logits/rejected': -0.4759383797645569, 'logits/chosen': -0.553577184677124, 'epoch': 0.39}


  7%|▋         | 1049/16104 [4:55:30<77:27:27, 18.52s/it]
{'loss': 0.5728, 'learning_rate': 1.993550334506063e-06, 'rewards/chosen': 0.44118520617485046, 'rewards/rejected': -0.24672144651412964, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6879066824913025, 'policy_logps/rejected': -348.9889221191406, 'policy_logps/chosen': -623.2242431640625, 'referece_logps/rejected': -346.52166748046875, 'referece_logps/chosen': -627.6360473632812, 'logits/rejected': 0.5742051601409912, 'logits/chosen': 0.4987035393714905, 'epoch': 0.39}

  7%|▋         | 1050/16104 [4:55:53<83:25:31, 19.95s/it]


  7%|▋         | 1052/16104 [4:56:30<78:44:15, 18.83s/it]

  7%|▋         | 1053/16104 [4:56:49<79:42:55, 19.07s/it]
{'loss': 0.5364, 'learning_rate': 1.9934587885852596e-06, 'rewards/chosen': -0.1771254539489746, 'rewards/rejected': -0.4941750168800354, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3170495629310608, 'policy_logps/rejected': -267.6174011230469, 'policy_logps/chosen': -300.8349609375, 'referece_logps/rejected': -262.6756286621094, 'referece_logps/chosen': -299.0636901855469, 'logits/rejected': -0.9992913603782654, 'logits/chosen': -0.76584792137146, 'epoch': 0.39}


  7%|▋         | 1055/16104 [4:57:25<78:24:27, 18.76s/it]

  7%|▋         | 1056/16104 [4:57:38<71:01:55, 16.99s/it]
[2024-04-05 20:31:35,284] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.607, 'learning_rate': 1.9933897071760235e-06, 'rewards/chosen': 0.26983243227005005, 'rewards/rejected': -0.2759707570075989, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5458031892776489, 'policy_logps/rejected': -345.03955078125, 'policy_logps/chosen': -522.4384155273438, 'referece_logps/rejected': -342.27978515625, 'referece_logps/chosen': -525.13671875, 'logits/rejected': -0.10589411854743958, 'logits/chosen': 0.05880178511142731, 'epoch': 0.39}

  7%|▋         | 1057/16104 [4:57:57<73:12:32, 17.52s/it]


  7%|▋         | 1059/16104 [4:58:31<73:48:28, 17.66s/it]

  7%|▋         | 1060/16104 [4:58:49<74:09:00, 17.74s/it]
{'loss': 0.562, 'learning_rate': 1.9932970360533473e-06, 'rewards/chosen': -0.6474730968475342, 'rewards/rejected': -0.8964367508888245, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24896357953548431, 'policy_logps/rejected': -345.8630065917969, 'policy_logps/chosen': -288.5178527832031, 'referece_logps/rejected': -336.898681640625, 'referece_logps/chosen': -282.0430908203125, 'logits/rejected': -0.09463703632354736, 'logits/chosen': -0.04719734936952591, 'epoch': 0.39}

  7%|▋         | 1061/16104 [4:59:02<68:35:23, 16.41s/it]

  7%|▋         | 1062/16104 [4:59:15<63:29:01, 15.19s/it]


  7%|▋         | 1064/16104 [4:59:49<66:12:00, 15.85s/it]

  7%|▋         | 1065/16104 [5:00:08<70:05:16, 16.78s/it]
{'loss': 0.5534, 'learning_rate': 1.99318029309277e-06, 'rewards/chosen': 0.08123921602964401, 'rewards/rejected': -0.43795108795166016, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5191903114318848, 'policy_logps/rejected': -288.9065856933594, 'policy_logps/chosen': -365.54156494140625, 'referece_logps/rejected': -284.5270690917969, 'referece_logps/chosen': -366.3539123535156, 'logits/rejected': -0.4879074692726135, 'logits/chosen': -0.5872219800949097, 'epoch': 0.4}


  7%|▋         | 1067/16104 [5:00:44<72:26:36, 17.34s/it]

  7%|▋         | 1068/16104 [5:01:00<70:40:45, 16.92s/it]

  7%|▋         | 1069/16104 [5:01:19<73:32:36, 17.61s/it]
{'loss': 0.5818, 'learning_rate': 1.9930861755521917e-06, 'rewards/chosen': 0.4320095181465149, 'rewards/rejected': -0.04282837733626366, 'rewards/accuracies': 0.875, 'rewards/margins': 0.47483792901039124, 'policy_logps/rejected': -409.1927795410156, 'policy_logps/chosen': -488.45001220703125, 'referece_logps/rejected': -408.76446533203125, 'referece_logps/chosen': -492.7701110839844, 'logits/rejected': 0.10313218086957932, 'logits/chosen': 0.14249439537525177, 'epoch': 0.4}


  7%|▋         | 1071/16104 [5:02:00<79:07:00, 18.95s/it]

  7%|▋         | 1072/16104 [5:02:16<75:00:20, 17.96s/it]

  7%|▋         | 1073/16104 [5:02:37<78:19:32, 18.76s/it]
{'loss': 0.5558, 'learning_rate': 1.992991415257919e-06, 'rewards/chosen': 0.08154917508363724, 'rewards/rejected': -1.0770114660263062, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1585606336593628, 'policy_logps/rejected': -391.9737854003906, 'policy_logps/chosen': -479.0652770996094, 'referece_logps/rejected': -381.2036437988281, 'referece_logps/chosen': -479.8807678222656, 'logits/rejected': -0.4448421001434326, 'logits/chosen': -0.4419618844985962, 'epoch': 0.4}

  7%|▋         | 1074/16104 [5:02:53<75:04:11, 17.98s/it]

  7%|▋         | 1075/16104 [5:03:11<74:56:35, 17.95s/it]


  7%|▋         | 1077/16104 [5:03:48<75:29:19, 18.08s/it]

  7%|▋         | 1078/16104 [5:04:08<78:36:24, 18.83s/it]

  7%|▋         | 1079/16104 [5:04:22<72:31:36, 17.38s/it]
{'loss': 0.6023, 'learning_rate': 1.992848069787609e-06, 'rewards/chosen': 0.027404433116316795, 'rewards/rejected': -0.5745028257369995, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6019072532653809, 'policy_logps/rejected': -397.20001220703125, 'policy_logps/chosen': -426.773193359375, 'referece_logps/rejected': -391.4549560546875, 'referece_logps/chosen': -427.0472412109375, 'logits/rejected': 0.09423606097698212, 'logits/chosen': 0.21213629841804504, 'epoch': 0.4}


  7%|▋         | 1081/16104 [5:04:53<67:01:46, 16.06s/it]

  7%|▋         | 1082/16104 [5:05:06<63:44:07, 15.27s/it]
{'loss': 0.6572, 'learning_rate': 1.992775854845961e-06, 'rewards/chosen': 0.1823677122592926, 'rewards/rejected': -0.3577207922935486, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5400884747505188, 'policy_logps/rejected': -339.947998046875, 'policy_logps/chosen': -374.75, 'referece_logps/rejected': -336.3708190917969, 'referece_logps/chosen': -376.57366943359375, 'logits/rejected': -0.4084813594818115, 'logits/chosen': -0.4305880665779114, 'epoch': 0.4}


  7%|▋         | 1084/16104 [5:05:44<70:34:37, 16.92s/it]

  7%|▋         | 1085/16104 [5:06:05<75:41:19, 18.14s/it]

  7%|▋         | 1086/16104 [5:06:24<77:16:03, 18.52s/it]

  7%|▋         | 1087/16104 [5:06:42<76:28:49, 18.33s/it]

  7%|▋         | 1088/16104 [5:06:53<67:25:09, 16.16s/it]

  7%|▋         | 1089/16104 [5:07:05<61:41:52, 14.79s/it]
{'loss': 0.583, 'learning_rate': 1.992605947776752e-06, 'rewards/chosen': 0.1906055510044098, 'rewards/rejected': -0.24574890732765198, 'rewards/accuracies': 0.75, 'rewards/margins': 0.43635445833206177, 'policy_logps/rejected': -501.8819580078125, 'policy_logps/chosen': -521.7219848632812, 'referece_logps/rejected': -499.4244689941406, 'referece_logps/chosen': -523.6280517578125, 'logits/rejected': -0.20537666976451874, 'logits/chosen': -0.3359518051147461, 'epoch': 0.41}


  7%|▋         | 1091/16104 [5:07:48<75:49:40, 18.18s/it]

  7%|▋         | 1092/16104 [5:07:59<66:52:33, 16.04s/it]

  7%|▋         | 1093/16104 [5:08:12<63:16:49, 15.18s/it]

  7%|▋         | 1094/16104 [5:08:34<71:16:40, 17.10s/it]

  7%|▋         | 1095/16104 [5:08:54<75:06:21, 18.01s/it]

  7%|▋         | 1096/16104 [5:09:11<74:09:12, 17.79s/it]

  7%|▋         | 1097/16104 [5:09:27<71:23:09, 17.12s/it]

  7%|▋         | 1098/16104 [5:09:50<79:05:52, 18.98s/it]
[2024-04-05 20:43:47,367] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.577, 'learning_rate': 1.9923846048855753e-06, 'rewards/chosen': -0.1924985945224762, 'rewards/rejected': -0.8226078152656555, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6301091909408569, 'policy_logps/rejected': -618.7064208984375, 'policy_logps/chosen': -541.002685546875, 'referece_logps/rejected': -610.4803466796875, 'referece_logps/chosen': -539.0777587890625, 'logits/rejected': 0.1948206126689911, 'logits/chosen': 0.2607596814632416, 'epoch': 0.41}

  7%|▋         | 1099/16104 [5:10:04<72:25:48, 17.38s/it]


  7%|▋         | 1101/16104 [5:10:39<71:28:22, 17.15s/it]
{'loss': 0.5929, 'learning_rate': 1.9923101012988164e-06, 'rewards/chosen': 0.210357666015625, 'rewards/rejected': -0.6618174314498901, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8721751570701599, 'policy_logps/rejected': -394.6043395996094, 'policy_logps/chosen': -532.4172973632812, 'referece_logps/rejected': -387.9861755371094, 'referece_logps/chosen': -534.5208740234375, 'logits/rejected': 0.12930573523044586, 'logits/chosen': 0.20290076732635498, 'epoch': 0.41}


  7%|▋         | 1103/16104 [5:11:11<66:38:50, 15.99s/it]
{'loss': 0.5974, 'learning_rate': 1.9922602315357304e-06, 'rewards/chosen': 0.7517181038856506, 'rewards/rejected': -0.5406932830810547, 'rewards/accuracies': 0.875, 'rewards/margins': 1.29241144657135, 'policy_logps/rejected': -486.96405029296875, 'policy_logps/chosen': -511.5334167480469, 'referece_logps/rejected': -481.55712890625, 'referece_logps/chosen': -519.0505981445312, 'logits/rejected': -0.49496281147003174, 'logits/chosen': -0.48363757133483887, 'epoch': 0.41}

  7%|▋         | 1104/16104 [5:11:22<60:45:54, 14.58s/it]


  7%|▋         | 1106/16104 [5:11:48<58:15:32, 13.98s/it]
{'loss': 0.5966, 'learning_rate': 1.9921851258534055e-06, 'rewards/chosen': 0.01625537872314453, 'rewards/rejected': -0.4190466105937958, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4353019595146179, 'policy_logps/rejected': -354.9741516113281, 'policy_logps/chosen': -426.5419921875, 'referece_logps/rejected': -350.7837219238281, 'referece_logps/chosen': -426.70452880859375, 'logits/rejected': 0.25476324558258057, 'logits/chosen': 0.368064820766449, 'epoch': 0.41}


  7%|▋         | 1108/16104 [5:12:16<57:38:39, 13.84s/it]

  7%|▋         | 1109/16104 [5:12:34<63:59:01, 15.36s/it]

  7%|▋         | 1110/16104 [5:12:53<68:31:13, 16.45s/it]

  7%|▋         | 1111/16104 [5:13:08<66:44:15, 16.02s/it]
[2024-04-05 20:47:05,758] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5884, 'learning_rate': 1.9920591470166045e-06, 'rewards/chosen': 0.02536182850599289, 'rewards/rejected': -0.09506397694349289, 'rewards/accuracies': 0.5, 'rewards/margins': 0.12042580544948578, 'policy_logps/rejected': -396.13232421875, 'policy_logps/chosen': -451.3948059082031, 'referece_logps/rejected': -395.18170166015625, 'referece_logps/chosen': -451.64837646484375, 'logits/rejected': -1.3090908527374268, 'logits/chosen': -1.143521785736084, 'epoch': 0.41}


  7%|▋         | 1113/16104 [5:13:35<59:41:23, 14.33s/it]
{'loss': 0.605, 'learning_rate': 1.9920084745607983e-06, 'rewards/chosen': -0.28797051310539246, 'rewards/rejected': -1.0574588775634766, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7694883346557617, 'policy_logps/rejected': -365.7414245605469, 'policy_logps/chosen': -445.9846496582031, 'referece_logps/rejected': -355.1668395996094, 'referece_logps/chosen': -443.10491943359375, 'logits/rejected': -0.9705010652542114, 'logits/chosen': -0.9821109771728516, 'epoch': 0.41}

  7%|▋         | 1114/16104 [5:13:50<60:56:05, 14.63s/it]


  7%|▋         | 1116/16104 [5:14:15<56:01:53, 13.46s/it]
{'loss': 0.5602, 'learning_rate': 1.9919321649158134e-06, 'rewards/chosen': 0.2986418902873993, 'rewards/rejected': -0.1211962178349495, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4198381006717682, 'policy_logps/rejected': -356.41217041015625, 'policy_logps/chosen': -478.77752685546875, 'referece_logps/rejected': -355.2001953125, 'referece_logps/chosen': -481.7639465332031, 'logits/rejected': 0.5184791088104248, 'logits/chosen': 0.447672039270401, 'epoch': 0.42}


  7%|▋         | 1118/16104 [5:14:37<50:52:46, 12.22s/it]

  7%|▋         | 1119/16104 [5:14:54<56:43:31, 13.63s/it]

  7%|▋         | 1120/16104 [5:15:08<57:07:43, 13.73s/it]

  7%|▋         | 1121/16104 [5:15:26<63:26:54, 15.24s/it]
[2024-04-05 20:49:23,693] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5969, 'learning_rate': 1.99180417967945e-06, 'rewards/chosen': -0.043530650436878204, 'rewards/rejected': -0.3587673306465149, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3152366578578949, 'policy_logps/rejected': -430.7244873046875, 'policy_logps/chosen': -451.21923828125, 'referece_logps/rejected': -427.1368408203125, 'referece_logps/chosen': -450.78387451171875, 'logits/rejected': 0.34110695123672485, 'logits/chosen': 0.23096659779548645, 'epoch': 0.42}
[2024-04-05 20:49:45,384] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  7%|▋         | 1123/16104 [5:16:09<76:40:13, 18.42s/it]

  7%|▋         | 1124/16104 [5:16:28<76:41:50, 18.43s/it]

  7%|▋         | 1125/16104 [5:16:51<82:58:56, 19.94s/it]

  7%|▋         | 1126/16104 [5:17:14<86:14:23, 20.73s/it]
{'loss': 0.5112, 'learning_rate': 1.9916751914369443e-06, 'rewards/chosen': 0.0492621511220932, 'rewards/rejected': -0.19330863654613495, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24257077276706696, 'policy_logps/rejected': -443.88507080078125, 'policy_logps/chosen': -493.3895263671875, 'referece_logps/rejected': -441.9519958496094, 'referece_logps/chosen': -493.8821105957031, 'logits/rejected': 0.13515202701091766, 'logits/chosen': 0.17401695251464844, 'epoch': 0.42}


  7%|▋         | 1128/16104 [5:17:55<84:46:48, 20.38s/it]

  7%|▋         | 1129/16104 [5:18:07<74:33:41, 17.92s/it]

  7%|▋         | 1130/16104 [5:18:22<70:37:58, 16.98s/it]
{'loss': 0.6289, 'learning_rate': 1.9915712787661425e-06, 'rewards/chosen': 0.18636342883110046, 'rewards/rejected': -0.19909287989139557, 'rewards/accuracies': 0.875, 'rewards/margins': 0.38545626401901245, 'policy_logps/rejected': -413.2568359375, 'policy_logps/chosen': -317.4013671875, 'referece_logps/rejected': -411.265869140625, 'referece_logps/chosen': -319.2650451660156, 'logits/rejected': -0.8895584344863892, 'logits/chosen': -0.7362893223762512, 'epoch': 0.42}

  7%|▋         | 1131/16104 [5:18:38<69:56:41, 16.82s/it]


  7%|▋         | 1133/16104 [5:19:02<58:45:41, 14.13s/it]
{'loss': 0.5631, 'learning_rate': 1.991492923095678e-06, 'rewards/chosen': -0.1629558652639389, 'rewards/rejected': -0.14365063607692719, 'rewards/accuracies': 0.625, 'rewards/margins': -0.01930522546172142, 'policy_logps/rejected': -448.69012451171875, 'policy_logps/chosen': -513.70166015625, 'referece_logps/rejected': -447.25360107421875, 'referece_logps/chosen': -512.0721435546875, 'logits/rejected': 0.10274728387594223, 'logits/chosen': 0.1762627810239792, 'epoch': 0.42}

  7%|▋         | 1134/16104 [5:19:12<54:32:08, 13.11s/it]


  7%|▋         | 1136/16104 [5:19:36<51:02:39, 12.28s/it]

  7%|▋         | 1137/16104 [5:19:47<50:27:13, 12.14s/it]

  7%|▋         | 1138/16104 [5:20:10<63:31:44, 15.28s/it]

  7%|▋         | 1139/16104 [5:20:24<62:01:23, 14.92s/it]

  7%|▋         | 1140/16104 [5:20:39<62:34:26, 15.05s/it]

  7%|▋         | 1141/16104 [5:20:51<58:55:11, 14.18s/it]

  7%|▋         | 1142/16104 [5:21:14<69:19:06, 16.68s/it]

  7%|▋         | 1143/16104 [5:21:30<68:14:38, 16.42s/it]

  7%|▋         | 1144/16104 [5:21:44<65:05:51, 15.67s/it]
{'loss': 0.4843, 'learning_rate': 1.9912025308994145e-06, 'rewards/chosen': 0.15622615814208984, 'rewards/rejected': -0.5690916776657104, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7253178358078003, 'policy_logps/rejected': -325.68572998046875, 'policy_logps/chosen': -417.106201171875, 'referece_logps/rejected': -319.99481201171875, 'referece_logps/chosen': -418.66845703125, 'logits/rejected': -0.8769534826278687, 'logits/chosen': -0.7467649579048157, 'epoch': 0.43}

  7%|▋         | 1145/16104 [5:21:56<61:22:18, 14.77s/it]


  7%|▋         | 1147/16104 [5:22:28<62:01:39, 14.93s/it]

  7%|▋         | 1148/16104 [5:22:46<66:03:03, 15.90s/it]

  7%|▋         | 1149/16104 [5:23:07<73:23:53, 17.67s/it]

  7%|▋         | 1150/16104 [5:23:19<66:12:19, 15.94s/it]
{'loss': 0.6668, 'learning_rate': 1.9910420901736194e-06, 'rewards/chosen': 0.1145099550485611, 'rewards/rejected': -0.48602867126464844, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6005386710166931, 'policy_logps/rejected': -373.1829528808594, 'policy_logps/chosen': -458.55291748046875, 'referece_logps/rejected': -368.3226623535156, 'referece_logps/chosen': -459.697998046875, 'logits/rejected': -1.154929280281067, 'logits/chosen': -0.8767915964126587, 'epoch': 0.43}


  7%|▋         | 1152/16104 [5:23:57<71:48:01, 17.29s/it]
{'loss': 0.6058, 'learning_rate': 1.9909882892047586e-06, 'rewards/chosen': 0.17583894729614258, 'rewards/rejected': -0.5076894760131836, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6835284233093262, 'policy_logps/rejected': -275.4386901855469, 'policy_logps/chosen': -381.0625, 'referece_logps/rejected': -270.36181640625, 'referece_logps/chosen': -382.8209228515625, 'logits/rejected': -0.17936037480831146, 'logits/chosen': -0.2375715672969818, 'epoch': 0.43}
[2024-04-05 20:58:16,459] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1153/16104 [5:24:19<77:19:35, 18.62s/it]
[2024-04-05 20:58:27,843] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1154/16104 [5:24:31<68:18:24, 16.45s/it]


  7%|▋         | 1156/16104 [5:25:02<66:54:48, 16.12s/it]

  7%|▋         | 1157/16104 [5:25:12<60:03:45, 14.47s/it]
{'loss': 0.5812, 'learning_rate': 1.9908530852749382e-06, 'rewards/chosen': 0.4815584421157837, 'rewards/rejected': -0.05906180664896965, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5406202077865601, 'policy_logps/rejected': -392.7956237792969, 'policy_logps/chosen': -369.4912109375, 'referece_logps/rejected': -392.2049865722656, 'referece_logps/chosen': -374.3067626953125, 'logits/rejected': 0.17552396655082703, 'logits/chosen': 0.23580288887023926, 'epoch': 0.43}


  7%|▋         | 1159/16104 [5:25:46<65:28:46, 15.77s/it]

  7%|▋         | 1160/16104 [5:26:04<67:34:43, 16.28s/it]

  7%|▋         | 1161/16104 [5:26:24<73:00:44, 17.59s/it]
{'loss': 0.6369, 'learning_rate': 1.9907442006525843e-06, 'rewards/chosen': -0.15418869256973267, 'rewards/rejected': -0.9299494028091431, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7757606506347656, 'policy_logps/rejected': -274.736328125, 'policy_logps/chosen': -377.2469787597656, 'referece_logps/rejected': -265.43682861328125, 'referece_logps/chosen': -375.7051086425781, 'logits/rejected': -0.17395587265491486, 'logits/chosen': -0.15015298128128052, 'epoch': 0.43}

  7%|▋         | 1162/16104 [5:26:41<72:27:58, 17.46s/it]

  7%|▋         | 1163/16104 [5:26:53<65:45:49, 15.85s/it]

  7%|▋         | 1164/16104 [5:27:09<65:56:06, 15.89s/it]

  7%|▋         | 1165/16104 [5:27:25<65:50:20, 15.87s/it]
[2024-04-05 21:01:46,005] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1166/16104 [5:27:49<75:20:44, 18.16s/it]
[2024-04-05 21:01:58,831] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  7%|▋         | 1168/16104 [5:28:18<68:35:45, 16.53s/it]

  7%|▋         | 1169/16104 [5:28:33<66:09:05, 15.95s/it]

  7%|▋         | 1170/16104 [5:28:52<70:37:16, 17.02s/it]

  7%|▋         | 1171/16104 [5:29:12<74:40:48, 18.00s/it]

  7%|▋         | 1172/16104 [5:29:33<77:14:45, 18.62s/it]
[2024-04-05 21:03:29,780] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1173/16104 [5:29:48<73:38:44, 17.76s/it]
{'loss': 0.6162, 'learning_rate': 1.990413699642081e-06, 'rewards/chosen': 0.04113826900720596, 'rewards/rejected': -0.2729266285896301, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3140648603439331, 'policy_logps/rejected': -297.3811950683594, 'policy_logps/chosen': -387.195556640625, 'referece_logps/rejected': -294.65191650390625, 'referece_logps/chosen': -387.6069030761719, 'logits/rejected': -0.10044088214635849, 'logits/chosen': 0.1560245156288147, 'epoch': 0.44}
[2024-04-05 21:04:04,246] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1174/16104 [5:30:07<74:51:12, 18.05s/it]

  7%|▋         | 1175/16104 [5:30:19<67:25:10, 16.26s/it]

  7%|▋         | 1176/16104 [5:30:33<64:30:47, 15.56s/it]

  7%|▋         | 1177/16104 [5:30:53<70:41:18, 17.05s/it]

  7%|▋         | 1178/16104 [5:31:08<67:03:40, 16.17s/it]

  7%|▋         | 1179/16104 [5:31:22<64:31:45, 15.56s/it]

  7%|▋         | 1180/16104 [5:31:34<59:45:34, 14.42s/it]


  7%|▋         | 1182/16104 [5:32:06<65:35:04, 15.82s/it]
{'loss': 0.5303, 'learning_rate': 1.990162037731336e-06, 'rewards/chosen': 0.06275805830955505, 'rewards/rejected': -0.5145550966262817, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5773131847381592, 'policy_logps/rejected': -441.36407470703125, 'policy_logps/chosen': -482.51300048828125, 'referece_logps/rejected': -436.218505859375, 'referece_logps/chosen': -483.1405944824219, 'logits/rejected': -0.476482093334198, 'logits/chosen': -0.2386479675769806, 'epoch': 0.44}


  7%|▋         | 1184/16104 [5:32:32<60:09:29, 14.52s/it]

  7%|▋         | 1185/16104 [5:32:47<59:50:08, 14.44s/it]
{'loss': 0.5426, 'learning_rate': 1.9900774294181374e-06, 'rewards/chosen': -0.028238678351044655, 'rewards/rejected': -0.762212336063385, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7339736819267273, 'policy_logps/rejected': -376.4407043457031, 'policy_logps/chosen': -484.1177062988281, 'referece_logps/rejected': -368.818603515625, 'referece_logps/chosen': -483.8353271484375, 'logits/rejected': -0.47546377778053284, 'logits/chosen': -0.45782941579818726, 'epoch': 0.44}

  7%|▋         | 1186/16104 [5:33:04<63:21:02, 15.29s/it]


  7%|▋         | 1188/16104 [5:33:37<67:41:06, 16.34s/it]
{'loss': 0.521, 'learning_rate': 1.989992460651359e-06, 'rewards/chosen': 0.20638960599899292, 'rewards/rejected': -0.2096477448940277, 'rewards/accuracies': 0.625, 'rewards/margins': 0.41603732109069824, 'policy_logps/rejected': -365.8965148925781, 'policy_logps/chosen': -430.23028564453125, 'referece_logps/rejected': -363.8000793457031, 'referece_logps/chosen': -432.294189453125, 'logits/rejected': 0.1747770458459854, 'logits/chosen': 0.2113334834575653, 'epoch': 0.44}

  7%|▋         | 1189/16104 [5:33:52<66:05:31, 15.95s/it]

  7%|▋         | 1190/16104 [5:34:05<63:03:53, 15.22s/it]


  7%|▋         | 1192/16104 [5:34:35<61:35:56, 14.87s/it]
{'loss': 0.5384, 'learning_rate': 1.989878608310239e-06, 'rewards/chosen': -0.206730455160141, 'rewards/rejected': -0.5673193335533142, 'rewards/accuracies': 0.625, 'rewards/margins': 0.36058884859085083, 'policy_logps/rejected': -432.962646484375, 'policy_logps/chosen': -386.3150329589844, 'referece_logps/rejected': -427.2894592285156, 'referece_logps/chosen': -384.24774169921875, 'logits/rejected': -0.6224546432495117, 'logits/chosen': -0.6088621616363525, 'epoch': 0.44}

  7%|▋         | 1193/16104 [5:34:55<68:26:14, 16.52s/it]
[2024-04-05 21:09:13,094] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  7%|▋         | 1195/16104 [5:35:35<75:03:48, 18.13s/it]
[2024-04-05 21:09:32,213] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1196/16104 [5:35:56<79:15:02, 19.14s/it]

  7%|▋         | 1197/16104 [5:36:14<77:29:23, 18.71s/it]

  7%|▋         | 1198/16104 [5:36:30<74:16:38, 17.94s/it]
{'loss': 0.5413, 'learning_rate': 1.9897066285510768e-06, 'rewards/chosen': 0.32423263788223267, 'rewards/rejected': 0.05854054540395737, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2656920850276947, 'policy_logps/rejected': -365.78753662109375, 'policy_logps/chosen': -348.2349853515625, 'referece_logps/rejected': -366.3729553222656, 'referece_logps/chosen': -351.477294921875, 'logits/rejected': 0.14644600450992584, 'logits/chosen': 0.057256974279880524, 'epoch': 0.45}

  7%|▋         | 1199/16104 [5:36:50<75:59:13, 18.35s/it]


  7%|▋         | 1201/16104 [5:37:20<68:47:09, 16.62s/it]
{'loss': 0.5334, 'learning_rate': 1.9896200981779343e-06, 'rewards/chosen': -0.0010576248168945312, 'rewards/rejected': -0.2706901431083679, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2696325182914734, 'policy_logps/rejected': -329.4942932128906, 'policy_logps/chosen': -519.6607055664062, 'referece_logps/rejected': -326.78741455078125, 'referece_logps/chosen': -519.650146484375, 'logits/rejected': -0.30046766996383667, 'logits/chosen': -0.3157448172569275, 'epoch': 0.45}

  7%|▋         | 1202/16104 [5:37:31<61:28:10, 14.85s/it]


  7%|▋         | 1204/16104 [5:38:07<65:04:23, 15.72s/it]
{'loss': 0.5152, 'learning_rate': 1.9895332075177112e-06, 'rewards/chosen': 0.2913348972797394, 'rewards/rejected': -0.6937349438667297, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9850698709487915, 'policy_logps/rejected': -447.5668029785156, 'policy_logps/chosen': -377.84857177734375, 'referece_logps/rejected': -440.62939453125, 'referece_logps/chosen': -380.7619323730469, 'logits/rejected': -0.4310467541217804, 'logits/chosen': -0.24660176038742065, 'epoch': 0.45}

  7%|▋         | 1205/16104 [5:38:23<66:14:41, 16.01s/it]

  7%|▋         | 1206/16104 [5:38:34<59:46:22, 14.44s/it]

  7%|▋         | 1207/16104 [5:38:50<61:23:12, 14.83s/it]


  8%|▊         | 1209/16104 [5:39:15<55:30:23, 13.42s/it]

  8%|▊         | 1210/16104 [5:39:30<58:35:04, 14.16s/it]

  8%|▊         | 1211/16104 [5:39:47<61:16:38, 14.81s/it]
{'loss': 0.56, 'learning_rate': 1.9893290617053748e-06, 'rewards/chosen': -0.08391895145177841, 'rewards/rejected': -0.35035622119903564, 'rewards/accuracies': 0.625, 'rewards/margins': 0.266437292098999, 'policy_logps/rejected': -321.99468994140625, 'policy_logps/chosen': -332.2410888671875, 'referece_logps/rejected': -318.4911193847656, 'referece_logps/chosen': -331.40191650390625, 'logits/rejected': -1.0561872720718384, 'logits/chosen': -0.995177149772644, 'epoch': 0.45}

  8%|▊         | 1212/16104 [5:39:58<56:46:13, 13.72s/it]

  8%|▊         | 1213/16104 [5:40:13<59:00:53, 14.27s/it]

  8%|▊         | 1214/16104 [5:40:30<61:35:45, 14.89s/it]

  8%|▊         | 1215/16104 [5:40:43<60:02:41, 14.52s/it]


  8%|▊         | 1217/16104 [5:41:21<68:14:25, 16.50s/it]

  8%|▊         | 1218/16104 [5:41:33<62:38:28, 15.15s/it]
{'loss': 0.6806, 'learning_rate': 1.9891229549071822e-06, 'rewards/chosen': -0.132210373878479, 'rewards/rejected': -0.26451951265335083, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13230915367603302, 'policy_logps/rejected': -191.22805786132812, 'policy_logps/chosen': -455.97967529296875, 'referece_logps/rejected': -188.58287048339844, 'referece_logps/chosen': -454.65753173828125, 'logits/rejected': -0.3531263470649719, 'logits/chosen': -0.4279232621192932, 'epoch': 0.45}


  8%|▊         | 1220/16104 [5:42:01<59:41:39, 14.44s/it]

  8%|▊         | 1221/16104 [5:42:19<63:12:11, 15.29s/it]

  8%|▊         | 1222/16104 [5:42:29<57:34:59, 13.93s/it]
{'loss': 0.6486, 'learning_rate': 1.9890042993083585e-06, 'rewards/chosen': 0.2570335268974304, 'rewards/rejected': -0.5042648315429688, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7612983584403992, 'policy_logps/rejected': -308.75732421875, 'policy_logps/chosen': -440.5651550292969, 'referece_logps/rejected': -303.71466064453125, 'referece_logps/chosen': -443.1355285644531, 'logits/rejected': -0.21901048719882965, 'logits/chosen': -0.34639233350753784, 'epoch': 0.46}


  8%|▊         | 1224/16104 [5:42:57<58:15:15, 14.09s/it]

  8%|▊         | 1225/16104 [5:43:13<61:13:03, 14.81s/it]

  8%|▊         | 1226/16104 [5:43:30<63:05:01, 15.26s/it]

  8%|▊         | 1227/16104 [5:43:46<63:59:55, 15.49s/it]

  8%|▊         | 1228/16104 [5:43:59<61:03:44, 14.78s/it]

  8%|▊         | 1229/16104 [5:44:13<60:55:45, 14.75s/it]
{'loss': 0.6021, 'learning_rate': 1.9887951117878597e-06, 'rewards/chosen': 0.04271315038204193, 'rewards/rejected': -0.3458670675754547, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3885802626609802, 'policy_logps/rejected': -303.5491027832031, 'policy_logps/chosen': -286.1197204589844, 'referece_logps/rejected': -300.0904235839844, 'referece_logps/chosen': -286.5468444824219, 'logits/rejected': -0.7449832558631897, 'logits/chosen': -0.6558439135551453, 'epoch': 0.46}


  8%|▊         | 1231/16104 [5:44:43<60:11:35, 14.57s/it]

  8%|▊         | 1232/16104 [5:45:01<64:21:53, 15.58s/it]

  8%|▊         | 1233/16104 [5:45:21<70:01:26, 16.95s/it]
{'loss': 0.5554, 'learning_rate': 1.9886746960676587e-06, 'rewards/chosen': 0.16221578419208527, 'rewards/rejected': -0.4219311773777008, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5841469764709473, 'policy_logps/rejected': -442.0986633300781, 'policy_logps/chosen': -416.84967041015625, 'referece_logps/rejected': -437.87933349609375, 'referece_logps/chosen': -418.4718017578125, 'logits/rejected': -0.5402112603187561, 'logits/chosen': -0.47160404920578003, 'epoch': 0.46}

  8%|▊         | 1234/16104 [5:45:41<73:18:21, 17.75s/it]

  8%|▊         | 1235/16104 [5:45:56<71:02:31, 17.20s/it]


  8%|▊         | 1237/16104 [5:46:41<81:32:21, 19.74s/it]
[2024-04-05 21:20:38,694] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1238/16104 [5:47:05<86:06:15, 20.85s/it]

  8%|▊         | 1239/16104 [5:47:23<83:09:45, 20.14s/it]

  8%|▊         | 1240/16104 [5:47:41<80:15:51, 19.44s/it]

  8%|▊         | 1241/16104 [5:47:53<70:47:47, 17.15s/it]
{'loss': 0.5845, 'learning_rate': 1.9884319450102292e-06, 'rewards/chosen': 0.035813525319099426, 'rewards/rejected': -0.5040612816810608, 'rewards/accuracies': 0.75, 'rewards/margins': 0.539874792098999, 'policy_logps/rejected': -293.19879150390625, 'policy_logps/chosen': -540.0958862304688, 'referece_logps/rejected': -288.1581726074219, 'referece_logps/chosen': -540.4539794921875, 'logits/rejected': -0.8107448220252991, 'logits/chosen': -1.0836107730865479, 'epoch': 0.46}

  8%|▊         | 1242/16104 [5:48:11<71:47:42, 17.39s/it]


  8%|▊         | 1244/16104 [5:48:38<64:00:20, 15.51s/it]

  8%|▊         | 1245/16104 [5:48:57<69:08:04, 16.75s/it]
{'loss': 0.6016, 'learning_rate': 1.988309609830116e-06, 'rewards/chosen': 0.14528390765190125, 'rewards/rejected': 0.21118105947971344, 'rewards/accuracies': 0.375, 'rewards/margins': -0.06589718163013458, 'policy_logps/rejected': -371.0791320800781, 'policy_logps/chosen': -398.28369140625, 'referece_logps/rejected': -373.1909484863281, 'referece_logps/chosen': -399.73651123046875, 'logits/rejected': -0.09117956459522247, 'logits/chosen': -0.18388397991657257, 'epoch': 0.46}


  8%|▊         | 1247/16104 [5:49:38<76:57:50, 18.65s/it]
{'loss': 0.6924, 'learning_rate': 1.9882482023617826e-06, 'rewards/chosen': 0.008190538734197617, 'rewards/rejected': -0.27329176664352417, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2814823091030121, 'policy_logps/rejected': -509.0028076171875, 'policy_logps/chosen': -745.2291870117188, 'referece_logps/rejected': -506.2698974609375, 'referece_logps/chosen': -745.3110961914062, 'logits/rejected': 0.1483944207429886, 'logits/chosen': 0.1650841385126114, 'epoch': 0.46}

  8%|▊         | 1248/16104 [5:49:51<70:27:32, 17.07s/it]

  8%|▊         | 1249/16104 [5:50:09<70:46:39, 17.15s/it]

  8%|▊         | 1250/16104 [5:50:31<77:02:16, 18.67s/it]

  8%|▊         | 1251/16104 [5:50:52<80:31:12, 19.52s/it]

  8%|▊         | 1252/16104 [5:51:09<77:16:07, 18.73s/it]


  8%|▊         | 1254/16104 [5:51:42<71:55:08, 17.43s/it]
{'loss': 0.5188, 'learning_rate': 1.9880320170313638e-06, 'rewards/chosen': 0.24934369325637817, 'rewards/rejected': -0.4682968258857727, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7176405191421509, 'policy_logps/rejected': -332.81097412109375, 'policy_logps/chosen': -482.8194274902344, 'referece_logps/rejected': -328.1280212402344, 'referece_logps/chosen': -485.3128967285156, 'logits/rejected': -0.9138949513435364, 'logits/chosen': -0.9520224332809448, 'epoch': 0.47}

  8%|▊         | 1255/16104 [5:51:56<68:06:48, 16.51s/it]

  8%|▊         | 1256/16104 [5:52:17<73:48:40, 17.90s/it]

  8%|▊         | 1257/16104 [5:52:38<76:38:30, 18.58s/it]

  8%|▊         | 1258/16104 [5:52:58<78:37:36, 19.07s/it]


  8%|▊         | 1260/16104 [5:53:34<76:46:48, 18.62s/it]

  8%|▊         | 1261/16104 [5:53:46<68:39:23, 16.65s/it]
{'loss': 0.6236, 'learning_rate': 1.9878138732860092e-06, 'rewards/chosen': 0.4322500228881836, 'rewards/rejected': -0.3593672215938568, 'rewards/accuracies': 0.625, 'rewards/margins': 0.791617214679718, 'policy_logps/rejected': -357.1457214355469, 'policy_logps/chosen': -372.88287353515625, 'referece_logps/rejected': -353.5520324707031, 'referece_logps/chosen': -377.20538330078125, 'logits/rejected': 0.1313490867614746, 'logits/chosen': 0.0802660658955574, 'epoch': 0.47}

  8%|▊         | 1262/16104 [5:53:59<64:29:34, 15.64s/it]


  8%|▊         | 1264/16104 [5:54:38<71:22:28, 17.31s/it]
{'loss': 0.6235, 'learning_rate': 1.987719783701667e-06, 'rewards/chosen': -0.1011778861284256, 'rewards/rejected': -0.1383645087480545, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03718661516904831, 'policy_logps/rejected': -350.2464599609375, 'policy_logps/chosen': -365.8428649902344, 'referece_logps/rejected': -348.86279296875, 'referece_logps/chosen': -364.8310546875, 'logits/rejected': 0.08056847751140594, 'logits/chosen': 0.14300286769866943, 'epoch': 0.47}

  8%|▊         | 1265/16104 [5:54:49<64:10:21, 15.57s/it]

  8%|▊         | 1266/16104 [5:55:05<64:38:26, 15.68s/it]

  8%|▊         | 1267/16104 [5:55:23<66:39:25, 16.17s/it]

  8%|▊         | 1268/16104 [5:55:38<65:13:18, 15.83s/it]

  8%|▊         | 1269/16104 [5:55:55<67:08:22, 16.29s/it]


  8%|▊         | 1271/16104 [5:56:24<64:07:44, 15.56s/it]
{'loss': 0.5548, 'learning_rate': 1.9874988429717173e-06, 'rewards/chosen': -0.36490434408187866, 'rewards/rejected': -1.0061286687850952, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6412243247032166, 'policy_logps/rejected': -347.8363952636719, 'policy_logps/chosen': -532.8408813476562, 'referece_logps/rejected': -337.7751159667969, 'referece_logps/chosen': -529.19189453125, 'logits/rejected': -0.6969531178474426, 'logits/chosen': -0.7018152475357056, 'epoch': 0.47}


  8%|▊         | 1273/16104 [5:56:56<65:04:40, 15.80s/it]
{'loss': 0.6543, 'learning_rate': 1.9874353575148703e-06, 'rewards/chosen': 0.14545594155788422, 'rewards/rejected': -0.4732641577720642, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6187200546264648, 'policy_logps/rejected': -343.701416015625, 'policy_logps/chosen': -342.791259765625, 'referece_logps/rejected': -338.9687805175781, 'referece_logps/chosen': -344.2458190917969, 'logits/rejected': -0.3199973404407501, 'logits/chosen': -0.4454858899116516, 'epoch': 0.47}

  8%|▊         | 1274/16104 [5:57:11<63:39:58, 15.46s/it]

  8%|▊         | 1275/16104 [5:57:33<71:05:30, 17.26s/it]

  8%|▊         | 1276/16104 [5:57:50<70:58:33, 17.23s/it]

  8%|▊         | 1277/16104 [5:58:06<69:46:51, 16.94s/it]

  8%|▊         | 1278/16104 [5:58:19<64:54:21, 15.76s/it]


  8%|▊         | 1280/16104 [5:58:58<72:39:23, 17.64s/it]
{'loss': 0.5609, 'learning_rate': 1.9872119002626134e-06, 'rewards/chosen': -0.23805677890777588, 'rewards/rejected': -0.7762464880943298, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5381897687911987, 'policy_logps/rejected': -363.9222717285156, 'policy_logps/chosen': -378.1556396484375, 'referece_logps/rejected': -356.1598205566406, 'referece_logps/chosen': -375.7750244140625, 'logits/rejected': -0.5185756683349609, 'logits/chosen': -0.37611833214759827, 'epoch': 0.48}

  8%|▊         | 1281/16104 [5:59:13<68:29:03, 16.63s/it]


  8%|▊         | 1283/16104 [5:59:44<65:59:36, 16.03s/it]
{'loss': 0.582, 'learning_rate': 1.9871155338256766e-06, 'rewards/chosen': -1.9263476133346558e-05, 'rewards/rejected': -0.37517204880714417, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3751527965068817, 'policy_logps/rejected': -419.57440185546875, 'policy_logps/chosen': -422.89739990234375, 'referece_logps/rejected': -415.8226623535156, 'referece_logps/chosen': -422.897216796875, 'logits/rejected': -0.6422734260559082, 'logits/chosen': -0.6721188426017761, 'epoch': 0.48}


  8%|▊         | 1285/16104 [6:00:16<67:57:01, 16.51s/it]
{'loss': 0.5633, 'learning_rate': 1.9870510898792955e-06, 'rewards/chosen': -0.43515855073928833, 'rewards/rejected': -0.9259828329086304, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4908241629600525, 'policy_logps/rejected': -619.2896728515625, 'policy_logps/chosen': -586.4990234375, 'referece_logps/rejected': -610.0299072265625, 'referece_logps/chosen': -582.1473999023438, 'logits/rejected': -0.34749141335487366, 'logits/chosen': -0.21969369053840637, 'epoch': 0.48}

  8%|▊         | 1286/16104 [6:00:35<70:18:19, 17.08s/it]

  8%|▊         | 1287/16104 [6:00:46<62:36:45, 15.21s/it]

  8%|▊         | 1288/16104 [6:01:00<61:21:03, 14.91s/it]


  8%|▊         | 1290/16104 [6:01:29<60:27:57, 14.69s/it]
{'loss': 0.5273, 'learning_rate': 1.9868892812966097e-06, 'rewards/chosen': -0.022791285067796707, 'rewards/rejected': -0.39438632130622864, 'rewards/accuracies': 0.75, 'rewards/margins': 0.37159502506256104, 'policy_logps/rejected': -353.5289001464844, 'policy_logps/chosen': -521.0638427734375, 'referece_logps/rejected': -349.58502197265625, 'referece_logps/chosen': -520.8359375, 'logits/rejected': 0.7721080183982849, 'logits/chosen': 0.6126478314399719, 'epoch': 0.48}

  8%|▊         | 1291/16104 [6:01:41<57:51:38, 14.06s/it]
[2024-04-05 21:36:00,348] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1292/16104 [6:02:03<67:23:05, 16.38s/it]
[2024-04-05 21:36:12,649] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1293/16104 [6:02:15<62:20:55, 15.15s/it]

  8%|▊         | 1294/16104 [6:02:26<57:06:03, 13.88s/it]
[2024-04-05 21:36:43,440] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1295/16104 [6:02:46<64:30:29, 15.68s/it]

  8%|▊         | 1296/16104 [6:02:59<61:23:00, 14.92s/it]
[2024-04-05 21:37:17,182] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1297/16104 [6:03:20<68:22:10, 16.62s/it]

  8%|▊         | 1298/16104 [6:03:36<68:12:06, 16.58s/it]

  8%|▊         | 1299/16104 [6:03:47<60:51:38, 14.80s/it]

  8%|▊         | 1300/16104 [6:04:03<62:54:16, 15.30s/it]


  8%|▊         | 1302/16104 [6:04:41<69:47:19, 16.97s/it]
{'loss': 0.5483, 'learning_rate': 1.9864968690260517e-06, 'rewards/chosen': -0.16436167061328888, 'rewards/rejected': -0.5810148119926453, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4166531562805176, 'policy_logps/rejected': -375.2771301269531, 'policy_logps/chosen': -460.7515869140625, 'referece_logps/rejected': -369.46697998046875, 'referece_logps/chosen': -459.10797119140625, 'logits/rejected': -0.33469316363334656, 'logits/chosen': -0.40641093254089355, 'epoch': 0.49}

  8%|▊         | 1303/16104 [6:04:54<65:59:20, 16.05s/it]


  8%|▊         | 1305/16104 [6:05:25<63:35:26, 15.47s/it]
{'loss': 0.6873, 'learning_rate': 1.9863978679937477e-06, 'rewards/chosen': -0.27059584856033325, 'rewards/rejected': -0.5429357290267944, 'rewards/accuracies': 0.75, 'rewards/margins': 0.27233994007110596, 'policy_logps/rejected': -344.24713134765625, 'policy_logps/chosen': -355.64202880859375, 'referece_logps/rejected': -338.81781005859375, 'referece_logps/chosen': -352.9360046386719, 'logits/rejected': -0.46868911385536194, 'logits/chosen': -0.3981574773788452, 'epoch': 0.49}

  8%|▊         | 1306/16104 [6:05:36<57:47:27, 14.06s/it]

  8%|▊         | 1307/16104 [6:05:48<55:10:14, 13.42s/it]

  8%|▊         | 1308/16104 [6:06:02<57:05:06, 13.89s/it]

  8%|▊         | 1309/16104 [6:06:23<65:30:04, 15.94s/it]

  8%|▊         | 1310/16104 [6:06:39<65:40:48, 15.98s/it]

  8%|▊         | 1311/16104 [6:06:51<60:35:24, 14.75s/it]

  8%|▊         | 1312/16104 [6:07:06<60:25:31, 14.71s/it]

  8%|▊         | 1313/16104 [6:07:22<62:24:29, 15.19s/it]


  8%|▊         | 1315/16104 [6:07:51<61:31:48, 14.98s/it]

  8%|▊         | 1316/16104 [6:08:03<57:58:38, 14.11s/it]
{'loss': 0.6519, 'learning_rate': 1.9860317920645725e-06, 'rewards/chosen': -0.6922771334648132, 'rewards/rejected': -0.40300682187080383, 'rewards/accuracies': 0.25, 'rewards/margins': -0.2892703115940094, 'policy_logps/rejected': -482.972900390625, 'policy_logps/chosen': -559.6123046875, 'referece_logps/rejected': -478.9428405761719, 'referece_logps/chosen': -552.6895751953125, 'logits/rejected': 0.39402949810028076, 'logits/chosen': 0.47577065229415894, 'epoch': 0.49}

  8%|▊         | 1317/16104 [6:08:25<67:05:26, 16.33s/it]

  8%|▊         | 1318/16104 [6:08:48<75:46:54, 18.45s/it]

  8%|▊         | 1319/16104 [6:09:08<77:36:33, 18.90s/it]


  8%|▊         | 1321/16104 [6:09:41<72:41:07, 17.70s/it]
{'loss': 0.5614, 'learning_rate': 1.9858637983372018e-06, 'rewards/chosen': -0.3088918626308441, 'rewards/rejected': -0.44587239623069763, 'rewards/accuracies': 0.25, 'rewards/margins': 0.13698053359985352, 'policy_logps/rejected': -521.9602661132812, 'policy_logps/chosen': -465.15240478515625, 'referece_logps/rejected': -517.5015258789062, 'referece_logps/chosen': -462.0635070800781, 'logits/rejected': -0.102179154753685, 'logits/chosen': -0.06409725546836853, 'epoch': 0.49}

  8%|▊         | 1322/16104 [6:10:01<75:02:45, 18.28s/it]

  8%|▊         | 1323/16104 [6:10:22<78:30:10, 19.12s/it]

  8%|▊         | 1324/16104 [6:10:36<72:26:18, 17.64s/it]


  8%|▊         | 1326/16104 [6:11:09<71:03:21, 17.31s/it]
{'loss': 0.6053, 'learning_rate': 1.985694807611164e-06, 'rewards/chosen': -0.0024585798382759094, 'rewards/rejected': -0.0672454908490181, 'rewards/accuracies': 0.625, 'rewards/margins': 0.06478692591190338, 'policy_logps/rejected': -470.7213439941406, 'policy_logps/chosen': -374.6160583496094, 'referece_logps/rejected': -470.04888916015625, 'referece_logps/chosen': -374.5914611816406, 'logits/rejected': 0.00018660910427570343, 'logits/chosen': 0.004726077429950237, 'epoch': 0.49}

  8%|▊         | 1327/16104 [6:11:24<67:40:30, 16.49s/it]

  8%|▊         | 1328/16104 [6:11:37<63:41:22, 15.52s/it]

  8%|▊         | 1329/16104 [6:11:57<69:15:31, 16.88s/it]

  8%|▊         | 1330/16104 [6:12:18<74:06:35, 18.06s/it]

  8%|▊         | 1331/16104 [6:12:39<77:48:15, 18.96s/it]


  8%|▊         | 1333/16104 [6:13:05<66:08:36, 16.12s/it]
{'loss': 0.608, 'learning_rate': 1.985456545962535e-06, 'rewards/chosen': -0.24780437350273132, 'rewards/rejected': -0.6169764995574951, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3691721558570862, 'policy_logps/rejected': -327.53448486328125, 'policy_logps/chosen': -332.3849182128906, 'referece_logps/rejected': -321.36474609375, 'referece_logps/chosen': -329.9068908691406, 'logits/rejected': -0.17057685554027557, 'logits/chosen': -0.18010888993740082, 'epoch': 0.5}

  8%|▊         | 1334/16104 [6:13:24<68:38:13, 16.73s/it]

  8%|▊         | 1335/16104 [6:13:44<73:09:59, 17.83s/it]

  8%|▊         | 1336/16104 [6:14:06<78:22:16, 19.10s/it]

  8%|▊         | 1337/16104 [6:14:30<83:56:13, 20.46s/it]

  8%|▊         | 1338/16104 [6:14:48<81:03:55, 19.76s/it]

  8%|▊         | 1339/16104 [6:15:09<83:08:18, 20.27s/it]
{'loss': 0.5034, 'learning_rate': 1.9852507669989714e-06, 'rewards/chosen': -0.4856489598751068, 'rewards/rejected': -1.4420015811920166, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9563525915145874, 'policy_logps/rejected': -484.2828674316406, 'policy_logps/chosen': -532.6680908203125, 'referece_logps/rejected': -469.86285400390625, 'referece_logps/chosen': -527.8115844726562, 'logits/rejected': 0.10295668244361877, 'logits/chosen': -0.01948520354926586, 'epoch': 0.5}
[2024-04-05 21:49:23,231] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  8%|▊         | 1341/16104 [6:15:49<83:52:02, 20.45s/it]

  8%|▊         | 1342/16104 [6:16:10<84:26:48, 20.59s/it]

  8%|▊         | 1343/16104 [6:16:28<81:15:12, 19.82s/it]

  8%|▊         | 1344/16104 [6:16:48<81:08:51, 19.79s/it]

  8%|▊         | 1345/16104 [6:17:02<73:46:05, 17.99s/it]

  8%|▊         | 1346/16104 [6:17:16<69:22:41, 16.92s/it]

  8%|▊         | 1347/16104 [6:17:27<62:27:16, 15.24s/it]

  8%|▊         | 1348/16104 [6:17:41<59:55:56, 14.62s/it]

  8%|▊         | 1349/16104 [6:17:55<59:16:35, 14.46s/it]

  8%|▊         | 1350/16104 [6:18:06<54:46:38, 13.37s/it]

  8%|▊         | 1351/16104 [6:18:26<63:00:01, 15.37s/it]

  8%|▊         | 1352/16104 [6:18:37<57:28:56, 14.03s/it]

  8%|▊         | 1353/16104 [6:18:47<53:32:18, 13.07s/it]

  8%|▊         | 1354/16104 [6:18:58<50:45:10, 12.39s/it]

  8%|▊         | 1355/16104 [6:19:16<57:53:55, 14.13s/it]
[2024-04-05 21:53:13,620] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1356/16104 [6:19:37<66:13:43, 16.17s/it]

  8%|▊         | 1357/16104 [6:19:57<70:12:11, 17.14s/it]

  8%|▊         | 1358/16104 [6:20:17<74:25:18, 18.17s/it]

  8%|▊         | 1359/16104 [6:20:33<71:56:48, 17.57s/it]

  8%|▊         | 1360/16104 [6:20:51<72:21:04, 17.67s/it]

  8%|▊         | 1361/16104 [6:21:11<75:09:57, 18.35s/it]

  8%|▊         | 1362/16104 [6:21:32<78:38:34, 19.20s/it]

  8%|▊         | 1363/16104 [6:21:53<80:33:03, 19.67s/it]

  8%|▊         | 1364/16104 [6:22:13<80:22:57, 19.63s/it]

  8%|▊         | 1365/16104 [6:22:24<69:53:54, 17.07s/it]

  8%|▊         | 1366/16104 [6:22:43<72:28:01, 17.70s/it]

  8%|▊         | 1367/16104 [6:23:05<77:23:37, 18.91s/it]

  8%|▊         | 1368/16104 [6:23:25<79:07:06, 19.33s/it]
[2024-04-05 21:57:22,321] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▊         | 1369/16104 [6:23:46<80:33:22, 19.68s/it]

  9%|▊         | 1370/16104 [6:24:04<79:36:25, 19.45s/it]

  9%|▊         | 1371/16104 [6:24:21<76:11:39, 18.62s/it]

  9%|▊         | 1372/16104 [6:24:44<80:47:03, 19.74s/it]

  9%|▊         | 1373/16104 [6:25:03<80:22:22, 19.64s/it]

  9%|▊         | 1374/16104 [6:25:27<85:53:11, 20.99s/it]

  9%|▊         | 1375/16104 [6:25:48<85:23:08, 20.87s/it]

  9%|▊         | 1376/16104 [6:26:02<77:38:00, 18.98s/it]

  9%|▊         | 1377/16104 [6:26:24<80:53:46, 19.78s/it]
[2024-04-05 22:00:21,107] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▊         | 1378/16104 [6:26:45<82:51:03, 20.25s/it]
[2024-04-05 22:00:42,479] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▊         | 1379/16104 [6:27:07<84:13:39, 20.59s/it]

  9%|▊         | 1380/16104 [6:27:28<85:35:47, 20.93s/it]

  9%|▊         | 1381/16104 [6:27:49<85:36:00, 20.93s/it]

  9%|▊         | 1382/16104 [6:28:02<75:04:38, 18.36s/it]

  9%|▊         | 1383/16104 [6:28:20<75:19:21, 18.42s/it]

  9%|▊         | 1384/16104 [6:28:35<71:07:46, 17.40s/it]

  9%|▊         | 1385/16104 [6:28:52<70:51:31, 17.33s/it]

  9%|▊         | 1386/16104 [6:29:14<75:34:59, 18.49s/it]

  9%|▊         | 1387/16104 [6:29:31<74:24:26, 18.20s/it]

  9%|▊         | 1388/16104 [6:29:46<70:18:40, 17.20s/it]

  9%|▊         | 1389/16104 [6:30:07<75:02:00, 18.36s/it]
[2024-04-05 22:04:04,254] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5707, 'learning_rate': 1.9834801740968028e-06, 'rewards/chosen': -0.25069019198417664, 'rewards/rejected': -0.6592512130737305, 'rewards/accuracies': 0.625, 'rewards/margins': 0.40856099128723145, 'policy_logps/rejected': -380.8822937011719, 'policy_logps/chosen': -603.1547241210938, 'referece_logps/rejected': -374.289794921875, 'referece_logps/chosen': -600.6477661132812, 'logits/rejected': 0.5779432654380798, 'logits/chosen': 0.6459024548530579, 'epoch': 0.52}
[2024-04-05 22:04:17,895] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  9%|▊         | 1391/16104 [6:30:41<73:34:09, 18.00s/it]

  9%|▊         | 1392/16104 [6:31:02<76:48:05, 18.79s/it]

  9%|▊         | 1393/16104 [6:31:18<74:04:01, 18.13s/it]

  9%|▊         | 1394/16104 [6:31:35<72:43:37, 17.80s/it]

  9%|▊         | 1395/16104 [6:31:57<78:02:33, 19.10s/it]

  9%|▊         | 1396/16104 [6:32:17<77:57:56, 19.08s/it]

  9%|▊         | 1397/16104 [6:32:29<69:58:46, 17.13s/it]

  9%|▊         | 1398/16104 [6:32:42<64:18:19, 15.74s/it]

  9%|▊         | 1399/16104 [6:32:56<62:17:42, 15.25s/it]

  9%|▊         | 1400/16104 [6:33:06<56:39:12, 13.87s/it]

  9%|▊         | 1401/16104 [6:33:28<65:46:00, 16.10s/it]

  9%|▊         | 1402/16104 [6:33:49<72:20:07, 17.71s/it]

  9%|▊         | 1403/16104 [6:34:05<70:12:48, 17.19s/it]

  9%|▊         | 1404/16104 [6:34:26<75:12:40, 18.42s/it]

  9%|▊         | 1405/16104 [6:34:41<70:53:34, 17.36s/it]

  9%|▊         | 1406/16104 [6:35:01<73:28:30, 18.00s/it]

  9%|▊         | 1407/16104 [6:35:18<72:02:30, 17.65s/it]

  9%|▊         | 1408/16104 [6:35:38<75:14:37, 18.43s/it]

  9%|▊         | 1409/16104 [6:35:54<72:52:17, 17.85s/it]

  9%|▉         | 1410/16104 [6:36:08<67:31:44, 16.54s/it]

  9%|▉         | 1411/16104 [6:36:30<74:12:14, 18.18s/it]

  9%|▉         | 1412/16104 [6:36:50<76:57:17, 18.86s/it]

  9%|▉         | 1413/16104 [6:37:08<75:25:57, 18.48s/it]

  9%|▉         | 1414/16104 [6:37:25<74:20:24, 18.22s/it]
{'loss': 0.5917, 'learning_rate': 1.98255756931815e-06, 'rewards/chosen': -0.11739310622215271, 'rewards/rejected': -1.3140803575515747, 'rewards/accuracies': 0.875, 'rewards/margins': 1.19668710231781, 'policy_logps/rejected': -266.9112548828125, 'policy_logps/chosen': -421.40423583984375, 'referece_logps/rejected': -253.77044677734375, 'referece_logps/chosen': -420.2303161621094, 'logits/rejected': -0.5278871655464172, 'logits/chosen': -0.4147753119468689, 'epoch': 0.53}


  9%|▉         | 1416/16104 [6:38:11<83:00:29, 20.35s/it]

  9%|▉         | 1417/16104 [6:38:33<85:08:55, 20.87s/it]

  9%|▉         | 1418/16104 [6:38:45<75:00:46, 18.39s/it]

  9%|▉         | 1419/16104 [6:39:06<77:57:07, 19.11s/it]
[2024-04-05 22:13:03,404] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1420/16104 [6:39:21<72:26:02, 17.76s/it]

  9%|▉         | 1421/16104 [6:39:32<64:23:23, 15.79s/it]

  9%|▉         | 1422/16104 [6:39:42<57:59:54, 14.22s/it]

  9%|▉         | 1423/16104 [6:39:58<59:14:05, 14.53s/it]

  9%|▉         | 1424/16104 [6:40:13<59:48:17, 14.67s/it]

  9%|▉         | 1425/16104 [6:40:34<67:43:04, 16.61s/it]

  9%|▉         | 1426/16104 [6:40:55<73:22:23, 18.00s/it]

  9%|▉         | 1427/16104 [6:41:17<78:02:51, 19.14s/it]

  9%|▉         | 1428/16104 [6:41:33<74:28:29, 18.27s/it]

  9%|▉         | 1429/16104 [6:41:52<75:37:58, 18.55s/it]

  9%|▉         | 1430/16104 [6:42:13<78:30:49, 19.26s/it]

  9%|▉         | 1431/16104 [6:42:28<72:46:16, 17.85s/it]

  9%|▉         | 1432/16104 [6:42:47<74:29:50, 18.28s/it]
{'loss': 0.5295, 'learning_rate': 1.9818779107550297e-06, 'rewards/chosen': -0.030891820788383484, 'rewards/rejected': -0.30039721727371216, 'rewards/accuracies': 0.375, 'rewards/margins': 0.26950544118881226, 'policy_logps/rejected': -608.85888671875, 'policy_logps/chosen': -542.689453125, 'referece_logps/rejected': -605.8548583984375, 'referece_logps/chosen': -542.3804931640625, 'logits/rejected': 0.3811933100223541, 'logits/chosen': 0.3813157081604004, 'epoch': 0.53}


  9%|▉         | 1434/16104 [6:43:29<80:35:05, 19.78s/it]

  9%|▉         | 1435/16104 [6:43:51<83:08:59, 20.41s/it]
{'loss': 0.5324, 'learning_rate': 1.9817633829466908e-06, 'rewards/chosen': -1.0658715963363647, 'rewards/rejected': -2.3867006301879883, 'rewards/accuracies': 0.875, 'rewards/margins': 1.320829153060913, 'policy_logps/rejected': -637.2728881835938, 'policy_logps/chosen': -556.4100341796875, 'referece_logps/rejected': -613.40576171875, 'referece_logps/chosen': -545.7512817382812, 'logits/rejected': -0.1405925303697586, 'logits/chosen': -0.1932351440191269, 'epoch': 0.53}


  9%|▉         | 1437/16104 [6:44:31<82:18:08, 20.20s/it]

  9%|▉         | 1438/16104 [6:44:51<82:07:04, 20.16s/it]

  9%|▉         | 1439/16104 [6:45:14<84:47:13, 20.81s/it]

  9%|▉         | 1440/16104 [6:45:29<78:34:49, 19.29s/it]

  9%|▉         | 1441/16104 [6:45:49<78:43:35, 19.33s/it]

  9%|▉         | 1442/16104 [6:46:01<70:30:01, 17.31s/it]

  9%|▉         | 1443/16104 [6:46:16<66:30:02, 16.33s/it]

  9%|▉         | 1444/16104 [6:46:30<64:15:46, 15.78s/it]

  9%|▉         | 1445/16104 [6:46:52<71:52:09, 17.65s/it]
{'loss': 0.6164, 'learning_rate': 1.98137904240557e-06, 'rewards/chosen': -0.3171085715293884, 'rewards/rejected': -0.8317886590957642, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5146801471710205, 'policy_logps/rejected': -395.1205749511719, 'policy_logps/chosen': -430.8819274902344, 'referece_logps/rejected': -386.8027038574219, 'referece_logps/chosen': -427.71087646484375, 'logits/rejected': -0.36405420303344727, 'logits/chosen': -0.36501696705818176, 'epoch': 0.54}


  9%|▉         | 1447/16104 [6:47:21<65:06:11, 15.99s/it]

  9%|▉         | 1448/16104 [6:47:37<64:40:46, 15.89s/it]

  9%|▉         | 1449/16104 [6:47:58<70:33:15, 17.33s/it]

  9%|▉         | 1450/16104 [6:48:21<77:57:48, 19.15s/it]

  9%|▉         | 1451/16104 [6:48:37<74:31:46, 18.31s/it]

  9%|▉         | 1452/16104 [6:48:57<76:42:59, 18.85s/it]

  9%|▉         | 1453/16104 [6:49:12<71:52:26, 17.66s/it]

  9%|▉         | 1454/16104 [6:49:32<74:31:23, 18.31s/it]
{'loss': 0.5123, 'learning_rate': 1.981029741650436e-06, 'rewards/chosen': 0.24568748474121094, 'rewards/rejected': -0.3924995958805084, 'rewards/accuracies': 0.75, 'rewards/margins': 0.638187050819397, 'policy_logps/rejected': -374.1968994140625, 'policy_logps/chosen': -335.33648681640625, 'referece_logps/rejected': -370.2718505859375, 'referece_logps/chosen': -337.7933654785156, 'logits/rejected': -0.8164865374565125, 'logits/chosen': -0.9473777413368225, 'epoch': 0.54}


  9%|▉         | 1456/16104 [6:50:03<68:51:58, 16.93s/it]
{'loss': 0.6716, 'learning_rate': 1.9809516826915817e-06, 'rewards/chosen': -0.43212494254112244, 'rewards/rejected': -0.41979849338531494, 'rewards/accuracies': 0.625, 'rewards/margins': -0.012326464056968689, 'policy_logps/rejected': -305.6620788574219, 'policy_logps/chosen': -179.79962158203125, 'referece_logps/rejected': -301.464111328125, 'referece_logps/chosen': -175.47837829589844, 'logits/rejected': -0.21424640715122223, 'logits/chosen': -0.33993133902549744, 'epoch': 0.54}

  9%|▉         | 1457/16104 [6:50:24<73:24:39, 18.04s/it]


  9%|▉         | 1459/16104 [6:51:06<79:40:58, 19.59s/it]

  9%|▉         | 1460/16104 [6:51:27<81:23:15, 20.01s/it]

  9%|▉         | 1461/16104 [6:51:44<77:28:45, 19.05s/it]

  9%|▉         | 1462/16104 [6:51:59<71:47:32, 17.65s/it]

  9%|▉         | 1463/16104 [6:52:21<77:06:56, 18.96s/it]

  9%|▉         | 1464/16104 [6:52:41<78:41:58, 19.35s/it]
{'loss': 0.6134, 'learning_rate': 1.9806378597330256e-06, 'rewards/chosen': -0.22812797129154205, 'rewards/rejected': -0.7919423580169678, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5638143420219421, 'policy_logps/rejected': -310.82147216796875, 'policy_logps/chosen': -459.866455078125, 'referece_logps/rejected': -302.9020690917969, 'referece_logps/chosen': -457.5851745605469, 'logits/rejected': -0.07119143754243851, 'logits/chosen': 0.003212973475456238, 'epoch': 0.55}


  9%|▉         | 1466/16104 [6:53:11<69:40:43, 17.14s/it]

  9%|▉         | 1467/16104 [6:53:27<67:57:03, 16.71s/it]

  9%|▉         | 1468/16104 [6:53:39<62:22:55, 15.34s/it]

  9%|▉         | 1469/16104 [6:53:58<66:46:42, 16.43s/it]

  9%|▉         | 1470/16104 [6:54:11<62:41:43, 15.42s/it]

  9%|▉         | 1471/16104 [6:54:22<57:05:38, 14.05s/it]

  9%|▉         | 1472/16104 [6:54:40<62:18:07, 15.33s/it]

  9%|▉         | 1473/16104 [6:54:51<56:42:57, 13.96s/it]

  9%|▉         | 1474/16104 [6:55:02<53:07:39, 13.07s/it]

  9%|▉         | 1475/16104 [6:55:13<50:50:38, 12.51s/it]

  9%|▉         | 1476/16104 [6:55:24<48:34:38, 11.96s/it]
{'loss': 0.5645, 'learning_rate': 1.980162365325731e-06, 'rewards/chosen': -0.08733043074607849, 'rewards/rejected': -0.3724810779094696, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2851506471633911, 'policy_logps/rejected': -248.5011444091797, 'policy_logps/chosen': -423.0206298828125, 'referece_logps/rejected': -244.7763214111328, 'referece_logps/chosen': -422.1473388671875, 'logits/rejected': -0.2321787029504776, 'logits/chosen': -0.28447216749191284, 'epoch': 0.55}

  9%|▉         | 1477/16104 [6:55:44<59:16:32, 14.59s/it]


  9%|▉         | 1479/16104 [6:56:09<55:06:25, 13.56s/it]

  9%|▉         | 1480/16104 [6:56:20<51:42:20, 12.73s/it]

  9%|▉         | 1481/16104 [6:56:40<60:20:10, 14.85s/it]

  9%|▉         | 1482/16104 [6:56:54<59:06:16, 14.55s/it]

  9%|▉         | 1483/16104 [6:57:09<59:56:46, 14.76s/it]

  9%|▉         | 1484/16104 [6:57:26<62:14:14, 15.33s/it]
{'loss': 0.4861, 'learning_rate': 1.9798421969380456e-06, 'rewards/chosen': 0.1919689178466797, 'rewards/rejected': -0.8009679317474365, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9929369688034058, 'policy_logps/rejected': -438.87200927734375, 'policy_logps/chosen': -337.5954895019531, 'referece_logps/rejected': -430.86236572265625, 'referece_logps/chosen': -339.51519775390625, 'logits/rejected': 0.09383763372898102, 'logits/chosen': -0.03691977262496948, 'epoch': 0.55}


  9%|▉         | 1486/16104 [6:57:47<53:09:20, 13.09s/it]

  9%|▉         | 1487/16104 [6:58:02<54:49:50, 13.50s/it]
{'loss': 0.6479, 'learning_rate': 1.9797214797480436e-06, 'rewards/chosen': 0.058141887187957764, 'rewards/rejected': -0.4842185378074646, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5423604249954224, 'policy_logps/rejected': -302.9911193847656, 'policy_logps/chosen': -518.8749389648438, 'referece_logps/rejected': -298.14892578125, 'referece_logps/chosen': -519.4563598632812, 'logits/rejected': -0.39899441599845886, 'logits/chosen': -0.44446319341659546, 'epoch': 0.55}

  9%|▉         | 1488/16104 [6:58:23<63:29:50, 15.64s/it]

  9%|▉         | 1489/16104 [6:58:38<63:49:33, 15.72s/it]


  9%|▉         | 1491/16104 [6:59:11<64:24:20, 15.87s/it]

  9%|▉         | 1492/16104 [6:59:22<58:05:38, 14.31s/it]

  9%|▉         | 1493/16104 [6:59:42<65:04:17, 16.03s/it]
{'loss': 0.5895, 'learning_rate': 1.9794789753621294e-06, 'rewards/chosen': 0.4067796766757965, 'rewards/rejected': -0.279727578163147, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6865072250366211, 'policy_logps/rejected': -478.51690673828125, 'policy_logps/chosen': -507.20709228515625, 'referece_logps/rejected': -475.7196350097656, 'referece_logps/chosen': -511.27490234375, 'logits/rejected': 0.09988723695278168, 'logits/chosen': 0.11520502716302872, 'epoch': 0.56}


  9%|▉         | 1495/16104 [7:00:20<72:16:35, 17.81s/it]

  9%|▉         | 1496/16104 [7:00:40<74:11:25, 18.28s/it]
{'loss': 0.611, 'learning_rate': 1.9793571882545048e-06, 'rewards/chosen': 0.4156523048877716, 'rewards/rejected': -0.43803372979164124, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8536859750747681, 'policy_logps/rejected': -369.09295654296875, 'policy_logps/chosen': -559.9868774414062, 'referece_logps/rejected': -364.71258544921875, 'referece_logps/chosen': -564.1434326171875, 'logits/rejected': 0.14346951246261597, 'logits/chosen': 0.19373206794261932, 'epoch': 0.56}


  9%|▉         | 1498/16104 [7:01:10<65:50:06, 16.23s/it]

  9%|▉         | 1499/16104 [7:01:32<72:51:52, 17.96s/it]

  9%|▉         | 1500/16104 [7:01:52<75:45:48, 18.68s/it]

  9%|▉         | 1501/16104 [7:02:26<94:51:14, 23.38s/it]
{'loss': 0.606, 'learning_rate': 1.9791534174288544e-06, 'rewards/chosen': -0.3850346505641937, 'rewards/rejected': -0.8189407587051392, 'rewards/accuracies': 0.625, 'rewards/margins': 0.43390610814094543, 'policy_logps/rejected': -489.1219177246094, 'policy_logps/chosen': -373.9880065917969, 'referece_logps/rejected': -480.9325256347656, 'referece_logps/chosen': -370.13763427734375, 'logits/rejected': -0.34979599714279175, 'logits/chosen': -0.3921428918838501, 'epoch': 0.56}


  9%|▉         | 1503/16104 [7:02:58<80:55:34, 19.95s/it]
{'loss': 0.6478, 'learning_rate': 1.9790716318275215e-06, 'rewards/chosen': 0.05276966467499733, 'rewards/rejected': -0.378302663564682, 'rewards/accuracies': 0.75, 'rewards/margins': 0.43107232451438904, 'policy_logps/rejected': -428.7190856933594, 'policy_logps/chosen': -418.12835693359375, 'referece_logps/rejected': -424.9360656738281, 'referece_logps/chosen': -418.6560974121094, 'logits/rejected': -0.8035534024238586, 'logits/chosen': -0.7982714772224426, 'epoch': 0.56}


  9%|▉         | 1505/16104 [7:03:28<69:21:00, 17.10s/it]
{'loss': 0.4607, 'learning_rate': 1.978989687805412e-06, 'rewards/chosen': -0.09477291256189346, 'rewards/rejected': -0.7989459037780762, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7041729688644409, 'policy_logps/rejected': -341.25970458984375, 'policy_logps/chosen': -386.1209716796875, 'referece_logps/rejected': -333.270263671875, 'referece_logps/chosen': -385.1732482910156, 'logits/rejected': -0.2849123775959015, 'logits/chosen': -0.23575186729431152, 'epoch': 0.56}


  9%|▉         | 1507/16104 [7:04:06<74:21:18, 18.34s/it]
{'loss': 0.48, 'learning_rate': 1.978907585375784e-06, 'rewards/chosen': -0.9295239448547363, 'rewards/rejected': -1.6685596704483032, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7390357851982117, 'policy_logps/rejected': -484.208251953125, 'policy_logps/chosen': -411.7611083984375, 'referece_logps/rejected': -467.52264404296875, 'referece_logps/chosen': -402.46588134765625, 'logits/rejected': 0.0045190900564193726, 'logits/chosen': 0.17460158467292786, 'epoch': 0.56}

  9%|▉         | 1508/16104 [7:04:27<77:45:21, 19.18s/it]


  9%|▉         | 1510/16104 [7:05:10<82:18:20, 20.30s/it]
{'loss': 0.4454, 'learning_rate': 1.9787841347463142e-06, 'rewards/chosen': 0.194620281457901, 'rewards/rejected': -0.6986926794052124, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8933130502700806, 'policy_logps/rejected': -294.83673095703125, 'policy_logps/chosen': -332.8863220214844, 'referece_logps/rejected': -287.84979248046875, 'referece_logps/chosen': -334.83251953125, 'logits/rejected': -0.2651708722114563, 'logits/chosen': -0.26267483830451965, 'epoch': 0.56}


  9%|▉         | 1512/16104 [7:05:50<81:45:51, 20.17s/it]

  9%|▉         | 1513/16104 [7:06:02<71:57:12, 17.75s/it]
{'loss': 0.6343, 'learning_rate': 1.97866032777477e-06, 'rewards/chosen': 0.3140356242656708, 'rewards/rejected': -0.4889141023159027, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8029496669769287, 'policy_logps/rejected': -596.9378051757812, 'policy_logps/chosen': -633.195068359375, 'referece_logps/rejected': -592.0487060546875, 'referece_logps/chosen': -636.33544921875, 'logits/rejected': 0.4454580545425415, 'logits/chosen': 0.6009527444839478, 'epoch': 0.56}

  9%|▉         | 1514/16104 [7:06:19<71:01:55, 17.53s/it]


  9%|▉         | 1516/16104 [7:06:55<72:46:34, 17.96s/it]
{'loss': 0.5416, 'learning_rate': 1.9785361645062255e-06, 'rewards/chosen': 0.0587138757109642, 'rewards/rejected': -0.5589455962181091, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6176594495773315, 'policy_logps/rejected': -447.7301330566406, 'policy_logps/chosen': -420.49261474609375, 'referece_logps/rejected': -442.14068603515625, 'referece_logps/chosen': -421.0798034667969, 'logits/rejected': 0.2882212996482849, 'logits/chosen': 0.2695619463920593, 'epoch': 0.56}


  9%|▉         | 1518/16104 [7:07:28<68:52:07, 17.00s/it]

  9%|▉         | 1519/16104 [7:07:40<62:38:03, 15.46s/it]

  9%|▉         | 1520/16104 [7:08:00<68:14:43, 16.85s/it]

  9%|▉         | 1521/16104 [7:08:12<62:27:53, 15.42s/it]

  9%|▉         | 1522/16104 [7:08:24<58:17:03, 14.39s/it]

  9%|▉         | 1523/16104 [7:08:38<58:18:01, 14.39s/it]

  9%|▉         | 1524/16104 [7:08:50<55:20:35, 13.66s/it]

  9%|▉         | 1525/16104 [7:09:03<53:38:32, 13.25s/it]

  9%|▉         | 1526/16104 [7:09:17<54:47:28, 13.53s/it]

  9%|▉         | 1527/16104 [7:09:30<54:30:43, 13.46s/it]

  9%|▉         | 1528/16104 [7:09:51<62:56:58, 15.55s/it]
{'loss': 0.6155, 'learning_rate': 1.9780359493680606e-06, 'rewards/chosen': -0.18052808940410614, 'rewards/rejected': -0.24001042544841766, 'rewards/accuracies': 0.5, 'rewards/margins': 0.05948233604431152, 'policy_logps/rejected': -358.7272644042969, 'policy_logps/chosen': -328.4879455566406, 'referece_logps/rejected': -356.3271484375, 'referece_logps/chosen': -326.68267822265625, 'logits/rejected': -0.1591011881828308, 'logits/chosen': -0.01940864324569702, 'epoch': 0.57}


 10%|▉         | 1530/16104 [7:10:13<53:59:14, 13.34s/it]
{'loss': 0.5925, 'learning_rate': 1.9779520262132657e-06, 'rewards/chosen': -0.050333421677351, 'rewards/rejected': -0.268222451210022, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21788904070854187, 'policy_logps/rejected': -310.6908874511719, 'policy_logps/chosen': -511.16815185546875, 'referece_logps/rejected': -308.0086669921875, 'referece_logps/chosen': -510.6648254394531, 'logits/rejected': -0.5668467879295349, 'logits/chosen': -0.5264847278594971, 'epoch': 0.57}


 10%|▉         | 1532/16104 [7:10:41<55:32:54, 13.72s/it]

 10%|▉         | 1533/16104 [7:10:59<61:01:12, 15.08s/it]

 10%|▉         | 1534/16104 [7:11:16<63:32:20, 15.70s/it]
{'loss': 0.5996, 'learning_rate': 1.97778370519843e-06, 'rewards/chosen': -0.3173728883266449, 'rewards/rejected': -0.16601872444152832, 'rewards/accuracies': 0.5, 'rewards/margins': -0.15135417878627777, 'policy_logps/rejected': -340.3425598144531, 'policy_logps/chosen': -666.28125, 'referece_logps/rejected': -338.682373046875, 'referece_logps/chosen': -663.1074829101562, 'logits/rejected': -0.1557314395904541, 'logits/chosen': -0.26599061489105225, 'epoch': 0.57}


 10%|▉         | 1536/16104 [7:11:52<68:45:32, 16.99s/it]
{'loss': 0.6161, 'learning_rate': 1.9776993073656254e-06, 'rewards/chosen': -0.46682944893836975, 'rewards/rejected': -0.35227203369140625, 'rewards/accuracies': 0.25, 'rewards/margins': -0.11455745995044708, 'policy_logps/rejected': -281.87335205078125, 'policy_logps/chosen': -334.3426513671875, 'referece_logps/rejected': -278.35064697265625, 'referece_logps/chosen': -329.6743469238281, 'logits/rejected': -0.02894400618970394, 'logits/chosen': 0.027344804257154465, 'epoch': 0.57}

 10%|▉         | 1537/16104 [7:12:12<71:38:53, 17.71s/it]

 10%|▉         | 1538/16104 [7:12:32<74:26:36, 18.40s/it]

 10%|▉         | 1539/16104 [7:12:44<66:38:35, 16.47s/it]


 10%|▉         | 1541/16104 [7:13:19<67:34:59, 16.71s/it]
{'loss': 0.5945, 'learning_rate': 1.9774876206941267e-06, 'rewards/chosen': 0.08408232033252716, 'rewards/rejected': -0.5991270542144775, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6832093596458435, 'policy_logps/rejected': -501.8769836425781, 'policy_logps/chosen': -371.8441162109375, 'referece_logps/rejected': -495.8857116699219, 'referece_logps/chosen': -372.6849670410156, 'logits/rejected': -0.19095969200134277, 'logits/chosen': -0.10751327872276306, 'epoch': 0.57}


 10%|▉         | 1543/16104 [7:14:03<77:53:09, 19.26s/it]

 10%|▉         | 1544/16104 [7:14:17<71:37:56, 17.71s/it]

 10%|▉         | 1545/16104 [7:14:35<72:29:32, 17.93s/it]

 10%|▉         | 1546/16104 [7:14:53<72:05:00, 17.83s/it]
{'loss': 0.524, 'learning_rate': 1.9772749454947432e-06, 'rewards/chosen': 0.11553019285202026, 'rewards/rejected': -0.5925063490867615, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7080365419387817, 'policy_logps/rejected': -522.6607055664062, 'policy_logps/chosen': -538.9174194335938, 'referece_logps/rejected': -516.735595703125, 'referece_logps/chosen': -540.07275390625, 'logits/rejected': 0.1759905070066452, 'logits/chosen': 0.2183716893196106, 'epoch': 0.58}

 10%|▉         | 1547/16104 [7:15:16<78:07:17, 19.32s/it]


 10%|▉         | 1549/16104 [7:15:53<75:38:08, 18.71s/it]

 10%|▉         | 1550/16104 [7:16:06<69:32:23, 17.20s/it]

 10%|▉         | 1551/16104 [7:16:23<69:28:06, 17.18s/it]

 10%|▉         | 1552/16104 [7:16:41<69:33:26, 17.21s/it]
{'loss': 0.5347, 'learning_rate': 1.977018430701575e-06, 'rewards/chosen': 0.3801025152206421, 'rewards/rejected': -0.09756212681531906, 'rewards/accuracies': 0.625, 'rewards/margins': 0.47766467928886414, 'policy_logps/rejected': -438.3796081542969, 'policy_logps/chosen': -487.8629150390625, 'referece_logps/rejected': -437.4039001464844, 'referece_logps/chosen': -491.6639404296875, 'logits/rejected': 0.03662673011422157, 'logits/chosen': 0.2045551836490631, 'epoch': 0.58}

 10%|▉         | 1553/16104 [7:17:00<72:26:07, 17.92s/it]

 10%|▉         | 1554/16104 [7:17:16<69:36:24, 17.22s/it]


 10%|▉         | 1556/16104 [7:17:49<70:01:20, 17.33s/it]
{'loss': 0.7555, 'learning_rate': 1.9768466303736324e-06, 'rewards/chosen': -0.7633438110351562, 'rewards/rejected': -0.22512245178222656, 'rewards/accuracies': 0.5, 'rewards/margins': -0.5382213592529297, 'policy_logps/rejected': -333.489501953125, 'policy_logps/chosen': -433.0035705566406, 'referece_logps/rejected': -331.2383117675781, 'referece_logps/chosen': -425.3701171875, 'logits/rejected': -0.10711106657981873, 'logits/chosen': -0.16772021353244781, 'epoch': 0.58}


 10%|▉         | 1558/16104 [7:18:25<72:43:23, 18.00s/it]

 10%|▉         | 1559/16104 [7:18:46<75:36:38, 18.71s/it]
{'loss': 0.6877, 'learning_rate': 1.9767173652121113e-06, 'rewards/chosen': -0.006993670016527176, 'rewards/rejected': -1.0339564085006714, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0269627571105957, 'policy_logps/rejected': -341.0848388671875, 'policy_logps/chosen': -319.1680908203125, 'referece_logps/rejected': -330.7452697753906, 'referece_logps/chosen': -319.09814453125, 'logits/rejected': -0.20359046757221222, 'logits/chosen': -0.18224534392356873, 'epoch': 0.58}

 10%|▉         | 1560/16104 [7:19:00<70:31:51, 17.46s/it]


 10%|▉         | 1562/16104 [7:19:35<70:21:27, 17.42s/it]
{'loss': 0.5519, 'learning_rate': 1.9765877444609565e-06, 'rewards/chosen': 0.05397719144821167, 'rewards/rejected': -0.343010276556015, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3969874083995819, 'policy_logps/rejected': -491.07177734375, 'policy_logps/chosen': -315.97186279296875, 'referece_logps/rejected': -487.64166259765625, 'referece_logps/chosen': -316.5116271972656, 'logits/rejected': -0.6300783157348633, 'logits/chosen': -0.441095232963562, 'epoch': 0.58}


 10%|▉         | 1564/16104 [7:20:03<63:45:08, 15.78s/it]
{'loss': 0.5144, 'learning_rate': 1.9765011331003554e-06, 'rewards/chosen': 0.1784074753522873, 'rewards/rejected': -0.3745662271976471, 'rewards/accuracies': 0.625, 'rewards/margins': 0.552973747253418, 'policy_logps/rejected': -355.3614807128906, 'policy_logps/chosen': -360.5235595703125, 'referece_logps/rejected': -351.6158447265625, 'referece_logps/chosen': -362.30767822265625, 'logits/rejected': -0.14375941455364227, 'logits/chosen': -0.09926171600818634, 'epoch': 0.58}

 10%|▉         | 1565/16104 [7:20:14<57:46:57, 14.31s/it]

 10%|▉         | 1566/16104 [7:20:34<65:15:14, 16.16s/it]

 10%|▉         | 1567/16104 [7:20:50<64:56:33, 16.08s/it]

 10%|▉         | 1568/16104 [7:21:12<72:02:57, 17.84s/it]


 10%|▉         | 1570/16104 [7:21:36<59:46:20, 14.81s/it]
{'loss': 0.5128, 'learning_rate': 1.976240351045626e-06, 'rewards/chosen': -0.03676033020019531, 'rewards/rejected': -0.21771544218063354, 'rewards/accuracies': 0.625, 'rewards/margins': 0.18095512688159943, 'policy_logps/rejected': -533.1116333007812, 'policy_logps/chosen': -482.4129638671875, 'referece_logps/rejected': -530.9345092773438, 'referece_logps/chosen': -482.0453186035156, 'logits/rejected': -0.48179149627685547, 'logits/chosen': -0.4766664505004883, 'epoch': 0.58}

 10%|▉         | 1571/16104 [7:21:46<54:47:00, 13.57s/it]


 10%|▉         | 1573/16104 [7:22:13<53:14:22, 13.19s/it]

 10%|▉         | 1574/16104 [7:22:35<63:46:07, 15.80s/it]
{'loss': 0.5949, 'learning_rate': 1.9760657065057527e-06, 'rewards/chosen': 0.3676563501358032, 'rewards/rejected': -0.14599305391311646, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5136494040489197, 'policy_logps/rejected': -531.5513305664062, 'policy_logps/chosen': -486.8854675292969, 'referece_logps/rejected': -530.0914306640625, 'referece_logps/chosen': -490.56201171875, 'logits/rejected': 0.21503128111362457, 'logits/chosen': 0.3730630874633789, 'epoch': 0.59}


 10%|▉         | 1576/16104 [7:23:07<62:07:45, 15.40s/it]

 10%|▉         | 1577/16104 [7:23:29<70:28:49, 17.47s/it]

 10%|▉         | 1578/16104 [7:23:45<68:28:14, 16.97s/it]

 10%|▉         | 1579/16104 [7:24:03<69:55:10, 17.33s/it]
{'loss': 0.5773, 'learning_rate': 1.9758465124632503e-06, 'rewards/chosen': -0.3261793255805969, 'rewards/rejected': -0.9135035276412964, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5873242020606995, 'policy_logps/rejected': -388.9541320800781, 'policy_logps/chosen': -398.50640869140625, 'referece_logps/rejected': -379.819091796875, 'referece_logps/chosen': -395.24462890625, 'logits/rejected': -0.8828837871551514, 'logits/chosen': -0.7770716547966003, 'epoch': 0.59}

 10%|▉         | 1580/16104 [7:24:16<65:13:00, 16.16s/it]


 10%|▉         | 1582/16104 [7:24:45<61:12:46, 15.17s/it]
{'loss': 0.5419, 'learning_rate': 1.9757145223267645e-06, 'rewards/chosen': -0.29162609577178955, 'rewards/rejected': -1.4891927242279053, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1975666284561157, 'policy_logps/rejected': -384.4147033691406, 'policy_logps/chosen': -466.25677490234375, 'referece_logps/rejected': -369.5227966308594, 'referece_logps/chosen': -463.3405456542969, 'logits/rejected': 0.17196352779865265, 'logits/chosen': 0.09001995623111725, 'epoch': 0.59}

 10%|▉         | 1583/16104 [7:25:07<69:26:13, 17.21s/it]


 10%|▉         | 1585/16104 [7:25:45<74:28:11, 18.46s/it]

 10%|▉         | 1586/16104 [7:26:01<71:03:52, 17.62s/it]
{'loss': 0.5097, 'learning_rate': 1.9755379829149463e-06, 'rewards/chosen': 0.10572567582130432, 'rewards/rejected': -0.3528404235839844, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4585661292076111, 'policy_logps/rejected': -591.0985717773438, 'policy_logps/chosen': -667.6217041015625, 'referece_logps/rejected': -587.570068359375, 'referece_logps/chosen': -668.678955078125, 'logits/rejected': -0.8465113639831543, 'logits/chosen': -0.8612927794456482, 'epoch': 0.59}

 10%|▉         | 1587/16104 [7:26:16<67:59:49, 16.86s/it]

 10%|▉         | 1588/16104 [7:26:31<65:09:40, 16.16s/it]

 10%|▉         | 1589/16104 [7:26:49<67:35:37, 16.76s/it]


 10%|▉         | 1591/16104 [7:27:30<75:15:32, 18.67s/it]

 10%|▉         | 1592/16104 [7:27:50<76:50:14, 19.06s/it]
{'loss': 0.4952, 'learning_rate': 1.9752719899655294e-06, 'rewards/chosen': -0.40272828936576843, 'rewards/rejected': -1.7505176067352295, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3477892875671387, 'policy_logps/rejected': -475.9591369628906, 'policy_logps/chosen': -460.90447998046875, 'referece_logps/rejected': -458.4539794921875, 'referece_logps/chosen': -456.877197265625, 'logits/rejected': -0.42584285140037537, 'logits/chosen': -0.31286123394966125, 'epoch': 0.59}

 10%|▉         | 1593/16104 [7:28:11<79:06:50, 19.63s/it]


 10%|▉         | 1595/16104 [7:28:44<73:45:42, 18.30s/it]
{'loss': 0.6132, 'learning_rate': 1.9751384608714463e-06, 'rewards/chosen': -0.16780567169189453, 'rewards/rejected': -0.2147693634033203, 'rewards/accuracies': 0.625, 'rewards/margins': 0.04696367681026459, 'policy_logps/rejected': -410.12591552734375, 'policy_logps/chosen': -356.3303527832031, 'referece_logps/rejected': -407.97821044921875, 'referece_logps/chosen': -354.65228271484375, 'logits/rejected': -0.3111305832862854, 'logits/chosen': -0.25661501288414, 'epoch': 0.59}

 10%|▉         | 1596/16104 [7:29:05<76:54:41, 19.08s/it]


 10%|▉         | 1598/16104 [7:29:40<72:36:51, 18.02s/it]
{'loss': 0.5901, 'learning_rate': 1.975004576762555e-06, 'rewards/chosen': -0.191766157746315, 'rewards/rejected': -0.9264750480651855, 'rewards/accuracies': 0.625, 'rewards/margins': 0.734708845615387, 'policy_logps/rejected': -397.1305847167969, 'policy_logps/chosen': -317.1527404785156, 'referece_logps/rejected': -387.8658752441406, 'referece_logps/chosen': -315.2350769042969, 'logits/rejected': 0.6456173658370972, 'logits/chosen': 0.5967128276824951, 'epoch': 0.6}

 10%|▉         | 1599/16104 [7:30:01<75:55:09, 18.84s/it]

 10%|▉         | 1600/16104 [7:30:23<79:39:31, 19.77s/it]


 10%|▉         | 1602/16104 [7:31:02<78:29:07, 19.48s/it]

 10%|▉         | 1603/16104 [7:31:14<69:34:57, 17.27s/it]
{'loss': 0.5488, 'learning_rate': 1.97478064779172e-06, 'rewards/chosen': 0.3535892367362976, 'rewards/rejected': -0.20590877532958984, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5594980120658875, 'policy_logps/rejected': -315.22784423828125, 'policy_logps/chosen': -440.72430419921875, 'referece_logps/rejected': -313.1687316894531, 'referece_logps/chosen': -444.2602233886719, 'logits/rejected': 0.012353174388408661, 'logits/chosen': 0.005320180207490921, 'epoch': 0.6}


 10%|▉         | 1605/16104 [7:31:38<59:34:48, 14.79s/it]

 10%|▉         | 1606/16104 [7:31:54<60:23:21, 15.00s/it]
{'loss': 0.593, 'learning_rate': 1.974645817215322e-06, 'rewards/chosen': 0.3736785054206848, 'rewards/rejected': -0.18670590221881866, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5603843927383423, 'policy_logps/rejected': -408.71026611328125, 'policy_logps/chosen': -565.0819702148438, 'referece_logps/rejected': -406.8431396484375, 'referece_logps/chosen': -568.8187255859375, 'logits/rejected': 0.19881108403205872, 'logits/chosen': -0.01270604133605957, 'epoch': 0.6}

 10%|▉         | 1607/16104 [7:32:05<55:09:05, 13.70s/it]


 10%|▉         | 1609/16104 [7:32:38<61:15:33, 15.21s/it]
{'loss': 0.6195, 'learning_rate': 1.9745106318034705e-06, 'rewards/chosen': 0.21894627809524536, 'rewards/rejected': -0.20737983286380768, 'rewards/accuracies': 0.625, 'rewards/margins': 0.42632609605789185, 'policy_logps/rejected': -360.5691223144531, 'policy_logps/chosen': -409.0083312988281, 'referece_logps/rejected': -358.49530029296875, 'referece_logps/chosen': -411.19781494140625, 'logits/rejected': -0.7018913626670837, 'logits/chosen': -0.6712468862533569, 'epoch': 0.6}

 10%|▉         | 1610/16104 [7:32:49<56:12:01, 13.96s/it]

 10%|█         | 1611/16104 [7:33:04<56:27:55, 14.03s/it]

 10%|█         | 1612/16104 [7:33:15<52:44:44, 13.10s/it]


 10%|█         | 1614/16104 [7:33:50<62:41:48, 15.58s/it]
{'loss': 0.5602, 'learning_rate': 1.974284534394221e-06, 'rewards/chosen': -0.5437559485435486, 'rewards/rejected': -0.8771529197692871, 'rewards/accuracies': 0.375, 'rewards/margins': 0.33339694142341614, 'policy_logps/rejected': -455.4643859863281, 'policy_logps/chosen': -438.128662109375, 'referece_logps/rejected': -446.69287109375, 'referece_logps/chosen': -432.69110107421875, 'logits/rejected': 0.3036583364009857, 'logits/chosen': 0.24653683602809906, 'epoch': 0.6}


 10%|█         | 1616/16104 [7:34:20<62:25:04, 15.51s/it]
{'loss': 0.5024, 'learning_rate': 1.974193819536869e-06, 'rewards/chosen': -0.4315626323223114, 'rewards/rejected': -0.6132369637489319, 'rewards/accuracies': 0.625, 'rewards/margins': 0.18167440593242645, 'policy_logps/rejected': -363.67864990234375, 'policy_logps/chosen': -492.98895263671875, 'referece_logps/rejected': -357.5462341308594, 'referece_logps/chosen': -488.6733093261719, 'logits/rejected': -0.44329091906547546, 'logits/chosen': -0.6408408284187317, 'epoch': 0.6}

 10%|█         | 1617/16104 [7:34:38<64:46:58, 16.10s/it]

 10%|█         | 1618/16104 [7:34:52<61:50:47, 15.37s/it]

 10%|█         | 1619/16104 [7:35:04<58:08:13, 14.45s/it]

 10%|█         | 1620/16104 [7:35:20<59:41:59, 14.84s/it]


 10%|█         | 1622/16104 [7:35:55<63:44:53, 15.85s/it]
{'loss': 0.5613, 'learning_rate': 1.9739207292345824e-06, 'rewards/chosen': 0.10886888951063156, 'rewards/rejected': -1.3396806716918945, 'rewards/accuracies': 0.875, 'rewards/margins': 1.448549509048462, 'policy_logps/rejected': -535.5106811523438, 'policy_logps/chosen': -422.2274169921875, 'referece_logps/rejected': -522.1138916015625, 'referece_logps/chosen': -423.3161315917969, 'logits/rejected': 0.10353914648294449, 'logits/chosen': 0.36270779371261597, 'epoch': 0.6}

 10%|█         | 1623/16104 [7:36:06<58:02:20, 14.43s/it]

 10%|█         | 1624/16104 [7:36:23<62:08:53, 15.45s/it]


 10%|█         | 1626/16104 [7:37:01<70:29:32, 17.53s/it]
{'loss': 0.6442, 'learning_rate': 1.973737881071888e-06, 'rewards/chosen': -0.04617498442530632, 'rewards/rejected': -0.12631568312644958, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08014070987701416, 'policy_logps/rejected': -414.3853454589844, 'policy_logps/chosen': -616.9180297851562, 'referece_logps/rejected': -413.1222229003906, 'referece_logps/chosen': -616.4562377929688, 'logits/rejected': -0.3003360629081726, 'logits/chosen': -0.4739740490913391, 'epoch': 0.61}


 10%|█         | 1628/16104 [7:37:30<63:31:31, 15.80s/it]
{'loss': 0.5903, 'learning_rate': 1.973646220646531e-06, 'rewards/chosen': 0.4956645369529724, 'rewards/rejected': -0.1719476878643036, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6676121950149536, 'policy_logps/rejected': -446.2829895019531, 'policy_logps/chosen': -492.9080810546875, 'referece_logps/rejected': -444.5635070800781, 'referece_logps/chosen': -497.8646545410156, 'logits/rejected': -0.6527482271194458, 'logits/chosen': -0.6890237927436829, 'epoch': 0.61}


 10%|█         | 1630/16104 [7:37:55<56:16:32, 14.00s/it]

 10%|█         | 1631/16104 [7:38:06<53:40:19, 13.35s/it]
{'loss': 0.6796, 'learning_rate': 1.9735084346201862e-06, 'rewards/chosen': -0.006769947707653046, 'rewards/rejected': 0.04165066033601761, 'rewards/accuracies': 0.25, 'rewards/margins': -0.048420608043670654, 'policy_logps/rejected': -360.9125061035156, 'policy_logps/chosen': -382.708251953125, 'referece_logps/rejected': -361.3290100097656, 'referece_logps/chosen': -382.6405029296875, 'logits/rejected': -0.0634952262043953, 'logits/chosen': -0.01733396016061306, 'epoch': 0.61}


 10%|█         | 1633/16104 [7:38:34<55:12:53, 13.74s/it]

 10%|█         | 1634/16104 [7:38:55<63:10:26, 15.72s/it]

 10%|█         | 1635/16104 [7:39:11<63:30:19, 15.80s/it]

 10%|█         | 1636/16104 [7:39:26<63:15:12, 15.74s/it]
{'loss': 0.5357, 'learning_rate': 1.9732780036647296e-06, 'rewards/chosen': -0.11975345015525818, 'rewards/rejected': -0.6080389022827148, 'rewards/accuracies': 0.625, 'rewards/margins': 0.48828545212745667, 'policy_logps/rejected': -513.1552734375, 'policy_logps/chosen': -481.69610595703125, 'referece_logps/rejected': -507.0749206542969, 'referece_logps/chosen': -480.4985046386719, 'logits/rejected': -0.10198350995779037, 'logits/chosen': 0.10830511152744293, 'epoch': 0.61}

 10%|█         | 1637/16104 [7:39:48<70:15:35, 17.48s/it]

 10%|█         | 1638/16104 [7:40:00<63:22:18, 15.77s/it]


 10%|█         | 1640/16104 [7:40:28<61:30:05, 15.31s/it]
{'loss': 0.5181, 'learning_rate': 1.9730929502142255e-06, 'rewards/chosen': 0.009277526289224625, 'rewards/rejected': -0.722915768623352, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7321932911872864, 'policy_logps/rejected': -599.5135498046875, 'policy_logps/chosen': -465.21337890625, 'referece_logps/rejected': -592.2843627929688, 'referece_logps/chosen': -465.30615234375, 'logits/rejected': 0.3580229878425598, 'logits/chosen': 0.4438437819480896, 'epoch': 0.61}


 10%|█         | 1642/16104 [7:41:02<66:44:51, 16.62s/it]

 10%|█         | 1643/16104 [7:41:19<66:38:15, 16.59s/it]
{'loss': 0.5904, 'learning_rate': 1.9729537468046666e-06, 'rewards/chosen': -0.07403335720300674, 'rewards/rejected': -0.2757086753845215, 'rewards/accuracies': 0.375, 'rewards/margins': 0.20167529582977295, 'policy_logps/rejected': -295.12451171875, 'policy_logps/chosen': -344.3360900878906, 'referece_logps/rejected': -292.3674011230469, 'referece_logps/chosen': -343.59576416015625, 'logits/rejected': -0.38408783078193665, 'logits/chosen': -0.34119150042533875, 'epoch': 0.61}


 10%|█         | 1645/16104 [7:41:55<69:16:34, 17.25s/it]

 10%|█         | 1646/16104 [7:42:15<72:28:35, 18.05s/it]

 10%|█         | 1647/16104 [7:42:37<77:09:43, 19.21s/it]
{'loss': 0.4052, 'learning_rate': 1.9727675912593673e-06, 'rewards/chosen': -0.20192545652389526, 'rewards/rejected': -1.7338981628417969, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5319726467132568, 'policy_logps/rejected': -493.0443115234375, 'policy_logps/chosen': -340.2506103515625, 'referece_logps/rejected': -475.705322265625, 'referece_logps/chosen': -338.2313232421875, 'logits/rejected': 0.3900710940361023, 'logits/chosen': 0.25216686725616455, 'epoch': 0.61}


 10%|█         | 1649/16104 [7:43:11<73:10:15, 18.22s/it]

 10%|█         | 1650/16104 [7:43:33<77:07:19, 19.21s/it]

 10%|█         | 1651/16104 [7:43:45<68:50:11, 17.15s/it]

 10%|█         | 1652/16104 [7:44:03<69:52:45, 17.41s/it]

 10%|█         | 1653/16104 [7:44:21<70:24:17, 17.54s/it]
{'loss': 0.5767, 'learning_rate': 1.972487177473692e-06, 'rewards/chosen': -0.19514790177345276, 'rewards/rejected': -0.3992540240287781, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2041061520576477, 'policy_logps/rejected': -293.88092041015625, 'policy_logps/chosen': -287.4034423828125, 'referece_logps/rejected': -289.8883361816406, 'referece_logps/chosen': -285.4519348144531, 'logits/rejected': 0.1555606722831726, 'logits/chosen': 0.18637023866176605, 'epoch': 0.62}

 10%|█         | 1654/16104 [7:44:33<64:38:14, 16.10s/it]


 10%|█         | 1656/16104 [7:45:17<76:40:24, 19.10s/it]

 10%|█         | 1657/16104 [7:45:37<77:31:40, 19.32s/it]
{'loss': 0.5378, 'learning_rate': 1.9722994481478744e-06, 'rewards/chosen': 0.21161556243896484, 'rewards/rejected': -0.5411382913589478, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7527538537979126, 'policy_logps/rejected': -464.40545654296875, 'policy_logps/chosen': -449.7481994628906, 'referece_logps/rejected': -458.99407958984375, 'referece_logps/chosen': -451.86431884765625, 'logits/rejected': -0.457999587059021, 'logits/chosen': -0.35073912143707275, 'epoch': 0.62}

 10%|█         | 1658/16104 [7:45:54<75:14:45, 18.75s/it]


 10%|█         | 1660/16104 [7:46:21<65:32:48, 16.34s/it]
{'loss': 0.5661, 'learning_rate': 1.9721582381687707e-06, 'rewards/chosen': -0.6597399711608887, 'rewards/rejected': -1.0797101259231567, 'rewards/accuracies': 0.625, 'rewards/margins': 0.41997015476226807, 'policy_logps/rejected': -405.33416748046875, 'policy_logps/chosen': -415.95086669921875, 'referece_logps/rejected': -394.5370788574219, 'referece_logps/chosen': -409.3534851074219, 'logits/rejected': 0.13570111989974976, 'logits/chosen': 0.045673917979002, 'epoch': 0.62}

 10%|█         | 1661/16104 [7:46:36<63:56:36, 15.94s/it]

 10%|█         | 1662/16104 [7:46:47<58:19:49, 14.54s/it]

 10%|█         | 1663/16104 [7:46:59<54:27:08, 13.57s/it]

 10%|█         | 1664/16104 [7:47:23<66:52:12, 16.67s/it]

 10%|█         | 1665/16104 [7:47:36<63:27:32, 15.82s/it]

 10%|█         | 1666/16104 [7:47:54<65:26:25, 16.32s/it]

 10%|█         | 1667/16104 [7:48:12<67:00:06, 16.71s/it]

 10%|█         | 1668/16104 [7:48:26<64:11:30, 16.01s/it]

 10%|█         | 1669/16104 [7:48:46<69:23:00, 17.30s/it]


 10%|█         | 1671/16104 [7:49:25<73:56:27, 18.44s/it]

 10%|█         | 1672/16104 [7:49:37<65:54:46, 16.44s/it]

 10%|█         | 1673/16104 [7:49:49<60:21:51, 15.06s/it]
{'loss': 0.6501, 'learning_rate': 1.971542239066432e-06, 'rewards/chosen': 0.2964435815811157, 'rewards/rejected': -0.0011542215943336487, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2975977957248688, 'policy_logps/rejected': -489.6434631347656, 'policy_logps/chosen': -371.089111328125, 'referece_logps/rejected': -489.6319274902344, 'referece_logps/chosen': -374.0535583496094, 'logits/rejected': -0.5758655071258545, 'logits/chosen': -0.4230928421020508, 'epoch': 0.62}

 10%|█         | 1674/16104 [7:50:00<55:10:39, 13.77s/it]

 10%|█         | 1675/16104 [7:50:10<51:28:21, 12.84s/it]


 10%|█         | 1677/16104 [7:50:33<48:03:45, 11.99s/it]
{'loss': 0.5943, 'learning_rate': 1.9713513644641373e-06, 'rewards/chosen': -0.14480096101760864, 'rewards/rejected': 0.2189074605703354, 'rewards/accuracies': 0.25, 'rewards/margins': -0.3637084364891052, 'policy_logps/rejected': -408.1329345703125, 'policy_logps/chosen': -571.6146850585938, 'referece_logps/rejected': -410.322021484375, 'referece_logps/chosen': -570.1666259765625, 'logits/rejected': 0.21600386500358582, 'logits/chosen': 0.2736469507217407, 'epoch': 0.62}

 10%|█         | 1678/16104 [7:50:44<46:34:49, 11.62s/it]


 10%|█         | 1680/16104 [7:51:09<48:12:59, 12.03s/it]
{'loss': 0.6025, 'learning_rate': 1.971207795930257e-06, 'rewards/chosen': 0.2049744427204132, 'rewards/rejected': -0.482321560382843, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6872960329055786, 'policy_logps/rejected': -491.16473388671875, 'policy_logps/chosen': -522.0816040039062, 'referece_logps/rejected': -486.3415222167969, 'referece_logps/chosen': -524.1312866210938, 'logits/rejected': -0.5762350559234619, 'logits/chosen': -0.6426363587379456, 'epoch': 0.63}

 10%|█         | 1681/16104 [7:51:20<46:37:41, 11.64s/it]

 10%|█         | 1682/16104 [7:51:31<45:13:06, 11.29s/it]


 10%|█         | 1684/16104 [7:52:02<52:06:07, 13.01s/it]

 10%|█         | 1685/16104 [7:52:20<58:04:53, 14.50s/it]
{'loss': 0.614, 'learning_rate': 1.970967729324579e-06, 'rewards/chosen': -0.18178938329219818, 'rewards/rejected': 0.02605421096086502, 'rewards/accuracies': 0.5, 'rewards/margins': -0.2078436017036438, 'policy_logps/rejected': -426.9990234375, 'policy_logps/chosen': -478.9461669921875, 'referece_logps/rejected': -427.25958251953125, 'referece_logps/chosen': -477.1282958984375, 'logits/rejected': 0.00013715028762817383, 'logits/chosen': -0.07537412643432617, 'epoch': 0.63}

 10%|█         | 1686/16104 [7:52:41<66:07:19, 16.51s/it]


 10%|█         | 1688/16104 [7:53:12<62:59:45, 15.73s/it]

 10%|█         | 1689/16104 [7:53:31<67:50:48, 16.94s/it]
{'loss': 0.5833, 'learning_rate': 1.970774969035615e-06, 'rewards/chosen': 0.05104713886976242, 'rewards/rejected': 0.17733190953731537, 'rewards/accuracies': 0.25, 'rewards/margins': -0.12628477811813354, 'policy_logps/rejected': -505.61895751953125, 'policy_logps/chosen': -473.9805603027344, 'referece_logps/rejected': -507.39227294921875, 'referece_logps/chosen': -474.49102783203125, 'logits/rejected': -0.1364259123802185, 'logits/chosen': -0.22633567452430725, 'epoch': 0.63}

 10%|█         | 1690/16104 [7:53:52<72:15:58, 18.05s/it]

 11%|█         | 1691/16104 [7:54:07<68:22:33, 17.08s/it]

 11%|█         | 1692/16104 [7:54:23<67:23:42, 16.83s/it]

 11%|█         | 1693/16104 [7:54:44<72:34:56, 18.13s/it]

 11%|█         | 1694/16104 [7:55:03<73:10:43, 18.28s/it]

 11%|█         | 1695/16104 [7:55:21<72:26:40, 18.10s/it]


 11%|█         | 1697/16104 [7:55:53<70:40:07, 17.66s/it]
{'loss': 0.5385, 'learning_rate': 1.9703875636431167e-06, 'rewards/chosen': 0.06357783079147339, 'rewards/rejected': -0.4723074436187744, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5358852744102478, 'policy_logps/rejected': -633.49755859375, 'policy_logps/chosen': -515.08984375, 'referece_logps/rejected': -628.7744140625, 'referece_logps/chosen': -515.7255859375, 'logits/rejected': -0.6320720911026001, 'logits/chosen': -0.4908519983291626, 'epoch': 0.63}

 11%|█         | 1698/16104 [7:56:07<65:41:50, 16.42s/it]

 11%|█         | 1699/16104 [7:56:29<72:19:15, 18.07s/it]

 11%|█         | 1700/16104 [7:56:52<78:43:07, 19.67s/it]

 11%|█         | 1701/16104 [7:57:07<72:44:09, 18.18s/it]


 11%|█         | 1703/16104 [7:57:44<74:27:29, 18.61s/it]
{'loss': 0.5288, 'learning_rate': 1.9700953608798378e-06, 'rewards/chosen': 0.07108499854803085, 'rewards/rejected': -0.22301356494426727, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2940985858440399, 'policy_logps/rejected': -544.8756103515625, 'policy_logps/chosen': -545.8057861328125, 'referece_logps/rejected': -542.6454467773438, 'referece_logps/chosen': -546.5166625976562, 'logits/rejected': -0.2673545479774475, 'logits/chosen': -0.3738600015640259, 'epoch': 0.63}

 11%|█         | 1704/16104 [7:57:58<69:25:27, 17.36s/it]

 11%|█         | 1705/16104 [7:58:17<71:18:42, 17.83s/it]

 11%|█         | 1706/16104 [7:58:37<73:06:13, 18.28s/it]

 11%|█         | 1707/16104 [7:59:01<80:05:38, 20.03s/it]

 11%|█         | 1708/16104 [7:59:19<78:19:26, 19.59s/it]

 11%|█         | 1709/16104 [7:59:35<73:12:54, 18.31s/it]

 11%|█         | 1710/16104 [7:59:54<74:32:11, 18.64s/it]

 11%|█         | 1711/16104 [8:00:06<66:11:37, 16.56s/it]

 11%|█         | 1712/16104 [8:00:24<68:10:15, 17.05s/it]

 11%|█         | 1713/16104 [8:00:43<70:27:02, 17.62s/it]

 11%|█         | 1714/16104 [8:01:01<70:57:57, 17.75s/it]

 11%|█         | 1715/16104 [8:01:13<63:35:46, 15.91s/it]

 11%|█         | 1716/16104 [8:01:33<69:21:15, 17.35s/it]

 11%|█         | 1717/16104 [8:01:50<68:44:39, 17.20s/it]

 11%|█         | 1718/16104 [8:02:06<67:24:23, 16.87s/it]

 11%|█         | 1719/16104 [8:02:18<60:58:56, 15.26s/it]


 11%|█         | 1721/16104 [8:03:02<75:38:27, 18.93s/it]
{'loss': 0.5479, 'learning_rate': 1.969210278012275e-06, 'rewards/chosen': -0.30460095405578613, 'rewards/rejected': -1.0577919483184814, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7531909346580505, 'policy_logps/rejected': -398.3953857421875, 'policy_logps/chosen': -393.9158935546875, 'referece_logps/rejected': -387.8174133300781, 'referece_logps/chosen': -390.869873046875, 'logits/rejected': -0.19936919212341309, 'logits/chosen': -0.17405997216701508, 'epoch': 0.64}


 11%|█         | 1723/16104 [8:03:34<69:34:59, 17.42s/it]

 11%|█         | 1724/16104 [8:03:51<69:43:27, 17.46s/it]

 11%|█         | 1725/16104 [8:04:07<67:14:18, 16.83s/it]

 11%|█         | 1726/16104 [8:04:25<69:02:56, 17.29s/it]

 11%|█         | 1727/16104 [8:04:45<71:57:22, 18.02s/it]

 11%|█         | 1728/16104 [8:04:57<64:56:04, 16.26s/it]

 11%|█         | 1729/16104 [8:05:18<70:48:24, 17.73s/it]

 11%|█         | 1730/16104 [8:05:36<70:18:06, 17.61s/it]

 11%|█         | 1731/16104 [8:05:54<71:36:36, 17.94s/it]

 11%|█         | 1732/16104 [8:06:10<69:08:14, 17.32s/it]

 11%|█         | 1733/16104 [8:06:23<63:49:48, 15.99s/it]

 11%|█         | 1734/16104 [8:06:41<65:58:09, 16.53s/it]

 11%|█         | 1735/16104 [8:06:53<61:02:49, 15.29s/it]

 11%|█         | 1736/16104 [8:07:04<55:34:41, 13.93s/it]

 11%|█         | 1737/16104 [8:07:23<61:32:00, 15.42s/it]

 11%|█         | 1738/16104 [8:07:46<71:12:46, 17.85s/it]

 11%|█         | 1739/16104 [8:07:57<63:03:29, 15.80s/it]

 11%|█         | 1740/16104 [8:08:13<62:36:29, 15.69s/it]

 11%|█         | 1741/16104 [8:08:26<59:47:37, 14.99s/it]

 11%|█         | 1742/16104 [8:08:43<61:24:13, 15.39s/it]

 11%|█         | 1743/16104 [8:08:55<57:48:14, 14.49s/it]

 11%|█         | 1744/16104 [8:09:13<62:18:10, 15.62s/it]

 11%|█         | 1745/16104 [8:09:27<60:24:16, 15.14s/it]

 11%|█         | 1746/16104 [8:09:42<59:41:29, 14.97s/it]

 11%|█         | 1747/16104 [8:09:55<57:22:31, 14.39s/it]

 11%|█         | 1748/16104 [8:10:05<52:54:44, 13.27s/it]

 11%|█         | 1749/16104 [8:10:26<61:36:12, 15.45s/it]

 11%|█         | 1750/16104 [8:10:41<61:29:22, 15.42s/it]

 11%|█         | 1751/16104 [8:11:01<67:05:08, 16.83s/it]

 11%|█         | 1752/16104 [8:11:24<73:31:27, 18.44s/it]

 11%|█         | 1753/16104 [8:11:35<64:30:23, 16.18s/it]

 11%|█         | 1754/16104 [8:11:51<64:27:17, 16.17s/it]

 11%|█         | 1755/16104 [8:12:12<70:54:07, 17.79s/it]

 11%|█         | 1756/16104 [8:12:29<69:02:39, 17.32s/it]

 11%|█         | 1757/16104 [8:12:44<66:51:27, 16.78s/it]

 11%|█         | 1758/16104 [8:13:05<72:02:45, 18.08s/it]

 11%|█         | 1759/16104 [8:13:28<78:20:25, 19.66s/it]

 11%|█         | 1760/16104 [8:13:46<75:32:40, 18.96s/it]

 11%|█         | 1761/16104 [8:14:04<74:32:41, 18.71s/it]

 11%|█         | 1762/16104 [8:14:23<75:28:46, 18.95s/it]

 11%|█         | 1763/16104 [8:14:42<74:51:49, 18.79s/it]

 11%|█         | 1764/16104 [8:15:02<76:26:45, 19.19s/it]

 11%|█         | 1765/16104 [8:15:17<71:48:50, 18.03s/it]

 11%|█         | 1766/16104 [8:15:29<63:59:32, 16.07s/it]

 11%|█         | 1767/16104 [8:15:44<63:12:38, 15.87s/it]

 11%|█         | 1768/16104 [8:15:55<57:29:36, 14.44s/it]

 11%|█         | 1769/16104 [8:16:17<66:30:22, 16.70s/it]

 11%|█         | 1770/16104 [8:16:30<62:13:38, 15.63s/it]

 11%|█         | 1771/16104 [8:16:43<58:33:01, 14.71s/it]

 11%|█         | 1772/16104 [8:17:03<65:13:43, 16.38s/it]

 11%|█         | 1773/16104 [8:17:27<74:04:05, 18.61s/it]

 11%|█         | 1774/16104 [8:17:44<71:58:22, 18.08s/it]

 11%|█         | 1775/16104 [8:18:06<76:30:43, 19.22s/it]

 11%|█         | 1776/16104 [8:18:22<72:56:34, 18.33s/it]

 11%|█         | 1777/16104 [8:18:40<72:17:27, 18.16s/it]

 11%|█         | 1778/16104 [8:18:58<72:06:01, 18.12s/it]

 11%|█         | 1779/16104 [8:19:10<65:12:46, 16.39s/it]

 11%|█         | 1780/16104 [8:19:30<69:48:44, 17.55s/it]

 11%|█         | 1781/16104 [8:19:47<68:48:41, 17.30s/it]

 11%|█         | 1782/16104 [8:19:58<60:57:08, 15.32s/it]

 11%|█         | 1783/16104 [8:20:17<65:56:26, 16.58s/it]

 11%|█         | 1784/16104 [8:20:28<58:55:55, 14.82s/it]

 11%|█         | 1785/16104 [8:20:43<58:47:34, 14.78s/it]

 11%|█         | 1786/16104 [8:20:55<55:13:25, 13.89s/it]

 11%|█         | 1787/16104 [8:21:17<64:54:18, 16.32s/it]

 11%|█         | 1788/16104 [8:21:33<65:08:56, 16.38s/it]

 11%|█         | 1789/16104 [8:21:45<60:09:46, 15.13s/it]

 11%|█         | 1790/16104 [8:22:00<59:40:46, 15.01s/it]

 11%|█         | 1791/16104 [8:22:19<64:18:55, 16.18s/it]

 11%|█         | 1792/16104 [8:22:41<71:29:09, 17.98s/it]

 11%|█         | 1793/16104 [8:22:52<63:11:37, 15.90s/it]

 11%|█         | 1794/16104 [8:23:16<72:19:11, 18.19s/it]

 11%|█         | 1795/16104 [8:23:34<72:14:33, 18.18s/it]

 11%|█         | 1796/16104 [8:23:52<72:01:28, 18.12s/it]

 11%|█         | 1797/16104 [8:24:07<68:38:55, 17.27s/it]

 11%|█         | 1798/16104 [8:24:28<73:08:58, 18.41s/it]

 11%|█         | 1799/16104 [8:24:51<78:17:56, 19.70s/it]

 11%|█         | 1800/16104 [8:25:07<73:35:02, 18.52s/it]

 11%|█         | 1801/16104 [8:25:21<68:25:11, 17.22s/it]

 11%|█         | 1802/16104 [8:25:43<74:07:29, 18.66s/it]

 11%|█         | 1803/16104 [8:26:01<73:11:02, 18.42s/it]

 11%|█         | 1804/16104 [8:26:12<64:21:57, 16.20s/it]

 11%|█         | 1805/16104 [8:26:23<58:48:25, 14.81s/it]

 11%|█         | 1806/16104 [8:26:38<58:36:48, 14.76s/it]

 11%|█         | 1807/16104 [8:26:56<62:40:24, 15.78s/it]

 11%|█         | 1808/16104 [8:27:13<64:06:59, 16.15s/it]

 11%|█         | 1809/16104 [8:27:33<69:01:32, 17.38s/it]

 11%|█         | 1810/16104 [8:27:45<62:37:57, 15.77s/it]

 11%|█         | 1811/16104 [8:27:58<58:38:26, 14.77s/it]

 11%|█▏        | 1812/16104 [8:28:09<54:40:31, 13.77s/it]

 11%|█▏        | 1813/16104 [8:28:32<64:52:40, 16.34s/it]

 11%|█▏        | 1814/16104 [8:28:51<68:22:37, 17.23s/it]

 11%|█▏        | 1815/16104 [8:29:11<71:23:13, 17.99s/it]

 11%|█▏        | 1816/16104 [8:29:31<74:07:46, 18.68s/it]

 11%|█▏        | 1817/16104 [8:29:53<78:03:38, 19.67s/it]

 11%|█▏        | 1818/16104 [8:30:06<70:29:35, 17.76s/it]

 11%|█▏        | 1819/16104 [8:30:22<67:47:55, 17.09s/it]

 11%|█▏        | 1820/16104 [8:30:44<74:04:00, 18.67s/it]

 11%|█▏        | 1821/16104 [8:31:05<76:41:19, 19.33s/it]
{'loss': 0.4921, 'learning_rate': 1.9640621635987024e-06, 'rewards/chosen': -0.11170883476734161, 'rewards/rejected': -0.8410221338272095, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7293132543563843, 'policy_logps/rejected': -412.63995361328125, 'policy_logps/chosen': -769.15673828125, 'referece_logps/rejected': -404.2297058105469, 'referece_logps/chosen': -768.0396118164062, 'logits/rejected': -0.020731627941131592, 'logits/chosen': -0.140960693359375, 'epoch': 0.68}

 11%|█▏        | 1822/16104 [8:31:22<74:13:23, 18.71s/it]


 11%|█▏        | 1824/16104 [8:32:00<74:38:54, 18.82s/it]

 11%|█▏        | 1825/16104 [8:32:16<70:57:13, 17.89s/it]
{'loss': 0.4788, 'learning_rate': 1.963848113307001e-06, 'rewards/chosen': -0.21316421031951904, 'rewards/rejected': -0.7487162947654724, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5355520248413086, 'policy_logps/rejected': -278.626953125, 'policy_logps/chosen': -280.63140869140625, 'referece_logps/rejected': -271.1397705078125, 'referece_logps/chosen': -278.4997863769531, 'logits/rejected': -0.475578635931015, 'logits/chosen': -0.5047773718833923, 'epoch': 0.68}


 11%|█▏        | 1827/16104 [8:32:58<77:12:43, 19.47s/it]

 11%|█▏        | 1828/16104 [8:33:20<80:43:22, 20.36s/it]

 11%|█▏        | 1829/16104 [8:33:35<74:47:33, 18.86s/it]

 11%|█▏        | 1830/16104 [8:33:55<75:50:28, 19.13s/it]

 11%|█▏        | 1831/16104 [8:34:16<78:15:11, 19.74s/it]
{'loss': 0.5758, 'learning_rate': 1.963525868231626e-06, 'rewards/chosen': 0.5974181890487671, 'rewards/rejected': -1.4400590658187866, 'rewards/accuracies': 1.0, 'rewards/margins': 2.037477493286133, 'policy_logps/rejected': -254.94467163085938, 'policy_logps/chosen': -456.9734802246094, 'referece_logps/rejected': -240.54408264160156, 'referece_logps/chosen': -462.9476318359375, 'logits/rejected': -0.4503631889820099, 'logits/chosen': -0.5170248746871948, 'epoch': 0.68}


 11%|█▏        | 1833/16104 [8:34:50<71:58:02, 18.15s/it]

 11%|█▏        | 1834/16104 [8:35:14<78:10:29, 19.72s/it]

 11%|█▏        | 1835/16104 [8:35:30<73:54:28, 18.65s/it]

 11%|█▏        | 1836/16104 [8:35:50<76:10:23, 19.22s/it]

 11%|█▏        | 1837/16104 [8:36:06<72:40:00, 18.34s/it]

 11%|█▏        | 1838/16104 [8:36:24<71:11:50, 17.97s/it]

 11%|█▏        | 1839/16104 [8:36:34<62:22:58, 15.74s/it]

 11%|█▏        | 1840/16104 [8:36:46<58:05:42, 14.66s/it]

 11%|█▏        | 1841/16104 [8:36:58<54:36:29, 13.78s/it]

 11%|█▏        | 1842/16104 [8:37:13<55:29:48, 14.01s/it]

 11%|█▏        | 1843/16104 [8:37:24<52:20:44, 13.21s/it]
{'loss': 0.6478, 'learning_rate': 1.9628771691078874e-06, 'rewards/chosen': -0.5458122491836548, 'rewards/rejected': -0.5004966259002686, 'rewards/accuracies': 0.5, 'rewards/margins': -0.04531564563512802, 'policy_logps/rejected': -369.9192199707031, 'policy_logps/chosen': -521.4060668945312, 'referece_logps/rejected': -364.9142761230469, 'referece_logps/chosen': -515.9479370117188, 'logits/rejected': -0.05061221867799759, 'logits/chosen': 0.004455782473087311, 'epoch': 0.69}


 11%|█▏        | 1845/16104 [8:37:49<51:02:48, 12.89s/it]

 11%|█▏        | 1846/16104 [8:38:05<55:27:29, 14.00s/it]
{'loss': 0.5606, 'learning_rate': 1.9627141178018075e-06, 'rewards/chosen': 0.1472025066614151, 'rewards/rejected': -0.6585919857025146, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8057944774627686, 'policy_logps/rejected': -309.9640808105469, 'policy_logps/chosen': -480.3800048828125, 'referece_logps/rejected': -303.3781433105469, 'referece_logps/chosen': -481.8520202636719, 'logits/rejected': -0.0499691516160965, 'logits/chosen': 0.07822057604789734, 'epoch': 0.69}


 11%|█▏        | 1848/16104 [8:38:31<52:46:15, 13.33s/it]
{'loss': 0.5087, 'learning_rate': 1.962605222209903e-06, 'rewards/chosen': 0.0686165988445282, 'rewards/rejected': -0.3084906339645386, 'rewards/accuracies': 0.75, 'rewards/margins': 0.377107173204422, 'policy_logps/rejected': -287.7762145996094, 'policy_logps/chosen': -421.7480773925781, 'referece_logps/rejected': -284.6913146972656, 'referece_logps/chosen': -422.43426513671875, 'logits/rejected': -0.2760334014892578, 'logits/chosen': 0.03621181845664978, 'epoch': 0.69}


 11%|█▏        | 1850/16104 [8:39:14<68:48:03, 17.38s/it]
{'loss': 0.483, 'learning_rate': 1.962496170861604e-06, 'rewards/chosen': 0.20306023955345154, 'rewards/rejected': -0.4302636384963989, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6333238482475281, 'policy_logps/rejected': -375.211669921875, 'policy_logps/chosen': -425.9617004394531, 'referece_logps/rejected': -370.9090270996094, 'referece_logps/chosen': -427.9922790527344, 'logits/rejected': -0.09179937839508057, 'logits/chosen': 0.02276623249053955, 'epoch': 0.69}


 12%|█▏        | 1852/16104 [8:39:39<59:16:07, 14.97s/it]
{'loss': 0.5568, 'learning_rate': 1.962386963774556e-06, 'rewards/chosen': 0.4952457547187805, 'rewards/rejected': -0.47976016998291016, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9750059247016907, 'policy_logps/rejected': -569.245849609375, 'policy_logps/chosen': -496.41259765625, 'referece_logps/rejected': -564.4482421875, 'referece_logps/chosen': -501.3651123046875, 'logits/rejected': -0.10261527448892593, 'logits/chosen': -0.11437583714723587, 'epoch': 0.69}


 12%|█▏        | 1854/16104 [8:40:12<60:37:14, 15.31s/it]

 12%|█▏        | 1855/16104 [8:40:30<63:05:12, 15.94s/it]

 12%|█▏        | 1856/16104 [8:40:53<71:17:11, 18.01s/it]

 12%|█▏        | 1857/16104 [8:41:03<62:41:43, 15.84s/it]
{'loss': 0.5617, 'learning_rate': 1.9621132648159334e-06, 'rewards/chosen': 0.06694520264863968, 'rewards/rejected': -0.47889745235443115, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5458425879478455, 'policy_logps/rejected': -414.29290771484375, 'policy_logps/chosen': -404.9967041015625, 'referece_logps/rejected': -409.5039367675781, 'referece_logps/chosen': -405.6661682128906, 'logits/rejected': -0.8654996156692505, 'logits/chosen': -0.7620421648025513, 'epoch': 0.69}


 12%|█▏        | 1859/16104 [8:41:32<58:02:39, 14.67s/it]

 12%|█▏        | 1860/16104 [8:41:46<57:04:25, 14.42s/it]

 12%|█▏        | 1861/16104 [8:42:07<64:53:38, 16.40s/it]

 12%|█▏        | 1862/16104 [8:42:25<66:46:05, 16.88s/it]

 12%|█▏        | 1863/16104 [8:42:46<71:41:44, 18.12s/it]

 12%|█▏        | 1864/16104 [8:43:06<74:18:59, 18.79s/it]

 12%|█▏        | 1865/16104 [8:43:23<71:35:02, 18.10s/it]

 12%|█▏        | 1866/16104 [8:43:45<76:26:39, 19.33s/it]

 12%|█▏        | 1867/16104 [8:44:02<74:11:45, 18.76s/it]

 12%|█▏        | 1868/16104 [8:44:20<73:25:41, 18.57s/it]

 12%|█▏        | 1869/16104 [8:44:37<71:02:23, 17.97s/it]

 12%|█▏        | 1870/16104 [8:44:59<75:40:39, 19.14s/it]

 12%|█▏        | 1871/16104 [8:45:18<75:40:03, 19.14s/it]

 12%|█▏        | 1872/16104 [8:45:38<76:56:12, 19.46s/it]

 12%|█▏        | 1873/16104 [8:45:51<69:12:57, 17.51s/it]

 12%|█▏        | 1874/16104 [8:46:12<73:21:14, 18.56s/it]

 12%|█▏        | 1875/16104 [8:46:29<71:03:01, 17.98s/it]
{'loss': 0.4779, 'learning_rate': 1.961119894287596e-06, 'rewards/chosen': 0.2645602226257324, 'rewards/rejected': -0.8960726261138916, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1606329679489136, 'policy_logps/rejected': -569.779052734375, 'policy_logps/chosen': -487.8865966796875, 'referece_logps/rejected': -560.818359375, 'referece_logps/chosen': -490.5321960449219, 'logits/rejected': 0.38425391912460327, 'logits/chosen': 0.44199472665786743, 'epoch': 0.7}


 12%|█▏        | 1877/16104 [8:47:10<77:17:19, 19.56s/it]

 12%|█▏        | 1878/16104 [8:47:28<75:32:50, 19.12s/it]

 12%|█▏        | 1879/16104 [8:47:40<67:02:06, 16.96s/it]
{'loss': 0.5685, 'learning_rate': 1.9608974341448883e-06, 'rewards/chosen': 0.2976865768432617, 'rewards/rejected': -1.089648723602295, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3873353004455566, 'policy_logps/rejected': -369.0708312988281, 'policy_logps/chosen': -378.5034484863281, 'referece_logps/rejected': -358.1743469238281, 'referece_logps/chosen': -381.48028564453125, 'logits/rejected': -0.22094711661338806, 'logits/chosen': 0.03280949592590332, 'epoch': 0.7}


 12%|█▏        | 1881/16104 [8:48:11<64:13:14, 16.25s/it]

 12%|█▏        | 1882/16104 [8:48:29<65:45:15, 16.64s/it]

 12%|█▏        | 1883/16104 [8:48:44<64:19:43, 16.28s/it]

 12%|█▏        | 1884/16104 [8:49:02<66:36:41, 16.86s/it]

 12%|█▏        | 1885/16104 [8:49:18<65:40:24, 16.63s/it]
{'loss': 0.531, 'learning_rate': 1.9605625778755127e-06, 'rewards/chosen': -0.027088358998298645, 'rewards/rejected': -0.30416393280029297, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2770755887031555, 'policy_logps/rejected': -347.93414306640625, 'policy_logps/chosen': -449.8508605957031, 'referece_logps/rejected': -344.8924865722656, 'referece_logps/chosen': -449.5799560546875, 'logits/rejected': -0.5829226970672607, 'logits/chosen': -0.6963960528373718, 'epoch': 0.7}


 12%|█▏        | 1887/16104 [8:49:50<64:19:54, 16.29s/it]

 12%|█▏        | 1888/16104 [8:50:09<67:00:22, 16.97s/it]

 12%|█▏        | 1889/16104 [8:50:23<63:22:59, 16.05s/it]

 12%|█▏        | 1890/16104 [8:50:39<63:17:13, 16.03s/it]
{'loss': 0.5471, 'learning_rate': 1.9602824624108006e-06, 'rewards/chosen': 0.18948593735694885, 'rewards/rejected': -0.3393547236919403, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5288406014442444, 'policy_logps/rejected': -467.3270263671875, 'policy_logps/chosen': -426.0513916015625, 'referece_logps/rejected': -463.9334716796875, 'referece_logps/chosen': -427.94622802734375, 'logits/rejected': -0.4822772145271301, 'logits/chosen': -0.3834848999977112, 'epoch': 0.7}

 12%|█▏        | 1891/16104 [8:50:52<60:01:51, 15.21s/it]


 12%|█▏        | 1893/16104 [8:51:25<60:47:06, 15.40s/it]
{'loss': 0.4981, 'learning_rate': 1.9601139269721698e-06, 'rewards/chosen': -0.1254030168056488, 'rewards/rejected': -0.7020766735076904, 'rewards/accuracies': 0.75, 'rewards/margins': 0.576673686504364, 'policy_logps/rejected': -413.28094482421875, 'policy_logps/chosen': -453.1059265136719, 'referece_logps/rejected': -406.26019287109375, 'referece_logps/chosen': -451.851806640625, 'logits/rejected': 0.11021239310503006, 'logits/chosen': 0.2038581371307373, 'epoch': 0.71}


 12%|█▏        | 1895/16104 [8:51:54<60:12:44, 15.26s/it]

 12%|█▏        | 1896/16104 [8:52:11<62:17:26, 15.78s/it]

 12%|█▏        | 1897/16104 [8:52:31<66:57:42, 16.97s/it]

 12%|█▏        | 1898/16104 [8:52:46<64:31:08, 16.35s/it]
{'loss': 0.5051, 'learning_rate': 1.959832257838397e-06, 'rewards/chosen': 0.167725071310997, 'rewards/rejected': -0.6522274017333984, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8199524879455566, 'policy_logps/rejected': -467.93157958984375, 'policy_logps/chosen': -509.9645690917969, 'referece_logps/rejected': -461.4092712402344, 'referece_logps/chosen': -511.6418762207031, 'logits/rejected': 0.8042450547218323, 'logits/chosen': 0.8078696131706238, 'epoch': 0.71}


 12%|█▏        | 1900/16104 [8:53:13<59:37:04, 15.11s/it]

 12%|█▏        | 1901/16104 [8:53:29<60:01:38, 15.21s/it]
{'loss': 0.5723, 'learning_rate': 1.959662790416768e-06, 'rewards/chosen': -0.27778396010398865, 'rewards/rejected': -0.5111376047134399, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2333536148071289, 'policy_logps/rejected': -547.4966430664062, 'policy_logps/chosen': -538.9610595703125, 'referece_logps/rejected': -542.3853149414062, 'referece_logps/chosen': -536.1831665039062, 'logits/rejected': -0.023410171270370483, 'logits/chosen': -0.17729836702346802, 'epoch': 0.71}


 12%|█▏        | 1903/16104 [8:54:05<65:53:55, 16.71s/it]

 12%|█▏        | 1904/16104 [8:54:27<71:29:08, 18.12s/it]
{'loss': 0.5377, 'learning_rate': 1.9594929736144973e-06, 'rewards/chosen': 0.2355949580669403, 'rewards/rejected': -0.25189530849456787, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4874902665615082, 'policy_logps/rejected': -388.73992919921875, 'policy_logps/chosen': -553.4000854492188, 'referece_logps/rejected': -386.220947265625, 'referece_logps/chosen': -555.7560424804688, 'logits/rejected': -0.49816879630088806, 'logits/chosen': -0.4475632905960083, 'epoch': 0.71}

 12%|█▏        | 1905/16104 [8:54:48<75:24:31, 19.12s/it]

 12%|█▏        | 1906/16104 [8:55:02<69:19:26, 17.58s/it]


 12%|█▏        | 1908/16104 [8:55:35<67:37:40, 17.15s/it]
{'loss': 0.5562, 'learning_rate': 1.9592660078373463e-06, 'rewards/chosen': -0.4525189697742462, 'rewards/rejected': -0.4935748875141144, 'rewards/accuracies': 0.375, 'rewards/margins': 0.04105598106980324, 'policy_logps/rejected': -363.17901611328125, 'policy_logps/chosen': -290.1342468261719, 'referece_logps/rejected': -358.2432861328125, 'referece_logps/chosen': -285.6091003417969, 'logits/rejected': -0.6428782343864441, 'logits/chosen': -0.5542839765548706, 'epoch': 0.71}


 12%|█▏        | 1910/16104 [8:56:16<73:02:46, 18.53s/it]

 12%|█▏        | 1911/16104 [8:56:37<76:12:55, 19.33s/it]

 12%|█▏        | 1912/16104 [8:56:57<77:07:25, 19.56s/it]

 12%|█▏        | 1913/16104 [8:57:15<74:46:00, 18.97s/it]

 12%|█▏        | 1914/16104 [8:57:34<75:42:01, 19.21s/it]

 12%|█▏        | 1915/16104 [8:57:51<72:28:51, 18.39s/it]

 12%|█▏        | 1916/16104 [8:58:13<76:19:59, 19.37s/it]
{'loss': 0.544, 'learning_rate': 1.958810213837392e-06, 'rewards/chosen': -0.2962731420993805, 'rewards/rejected': -0.5048565864562988, 'rewards/accuracies': 0.5, 'rewards/margins': 0.20858344435691833, 'policy_logps/rejected': -317.8890075683594, 'policy_logps/chosen': -335.845947265625, 'referece_logps/rejected': -312.84039306640625, 'referece_logps/chosen': -332.88323974609375, 'logits/rejected': -0.6911579370498657, 'logits/chosen': -0.7109931707382202, 'epoch': 0.71}


 12%|█▏        | 1918/16104 [8:58:50<74:22:28, 18.87s/it]
{'loss': 0.5298, 'learning_rate': 1.958695877435409e-06, 'rewards/chosen': -0.011809535324573517, 'rewards/rejected': -0.5329124927520752, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5211029648780823, 'policy_logps/rejected': -447.0570068359375, 'policy_logps/chosen': -398.75006103515625, 'referece_logps/rejected': -441.72784423828125, 'referece_logps/chosen': -398.6319885253906, 'logits/rejected': 0.261997252702713, 'logits/chosen': 0.18417175114154816, 'epoch': 0.71}


 12%|█▏        | 1920/16104 [8:59:23<70:02:26, 17.78s/it]
{'loss': 0.4825, 'learning_rate': 1.9585813859095913e-06, 'rewards/chosen': -0.4851115345954895, 'rewards/rejected': -1.0512243509292603, 'rewards/accuracies': 0.875, 'rewards/margins': 0.566112756729126, 'policy_logps/rejected': -380.3007507324219, 'policy_logps/chosen': -329.1938781738281, 'referece_logps/rejected': -369.7884826660156, 'referece_logps/chosen': -324.3427734375, 'logits/rejected': 0.31046319007873535, 'logits/chosen': 0.20900602638721466, 'epoch': 0.72}

 12%|█▏        | 1921/16104 [8:59:40<69:18:01, 17.59s/it]


 12%|█▏        | 1923/16104 [9:00:18<70:38:27, 17.93s/it]
{'loss': 0.5096, 'learning_rate': 1.958409357804207e-06, 'rewards/chosen': -0.5474399328231812, 'rewards/rejected': -0.5808889865875244, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03344917669892311, 'policy_logps/rejected': -332.3649597167969, 'policy_logps/chosen': -375.8656921386719, 'referece_logps/rejected': -326.55609130859375, 'referece_logps/chosen': -370.39129638671875, 'logits/rejected': -0.410136878490448, 'logits/chosen': -0.49801766872406006, 'epoch': 0.72}

 12%|█▏        | 1924/16104 [9:00:36<71:46:46, 18.22s/it]


 12%|█▏        | 1926/16104 [9:01:03<62:43:16, 15.93s/it]

 12%|█▏        | 1927/16104 [9:01:24<68:08:40, 17.30s/it]

 12%|█▏        | 1928/16104 [9:01:40<66:29:01, 16.88s/it]
{'loss': 0.5325, 'learning_rate': 1.9581218689388632e-06, 'rewards/chosen': -0.3022037744522095, 'rewards/rejected': -0.8896934390068054, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5874897241592407, 'policy_logps/rejected': -325.27386474609375, 'policy_logps/chosen': -438.95587158203125, 'referece_logps/rejected': -316.3769226074219, 'referece_logps/chosen': -435.933837890625, 'logits/rejected': -0.3966604173183441, 'logits/chosen': -0.30440860986709595, 'epoch': 0.72}

 12%|█▏        | 1929/16104 [9:02:01<71:43:40, 18.22s/it]


 12%|█▏        | 1931/16104 [9:02:36<69:44:50, 17.72s/it]
{'loss': 0.5522, 'learning_rate': 1.9579489105081746e-06, 'rewards/chosen': -0.19594459235668182, 'rewards/rejected': 0.03379786014556885, 'rewards/accuracies': 0.375, 'rewards/margins': -0.22974246740341187, 'policy_logps/rejected': -538.3721923828125, 'policy_logps/chosen': -417.2147216796875, 'referece_logps/rejected': -538.710205078125, 'referece_logps/chosen': -415.2552490234375, 'logits/rejected': -0.32733431458473206, 'logits/chosen': -0.2192533016204834, 'epoch': 0.72}

 12%|█▏        | 1932/16104 [9:02:48<63:41:30, 16.18s/it]

 12%|█▏        | 1933/16104 [9:03:09<69:01:32, 17.54s/it]

 12%|█▏        | 1934/16104 [9:03:20<61:40:40, 15.67s/it]


 12%|█▏        | 1936/16104 [9:04:03<73:12:33, 18.60s/it]
{'loss': 0.5606, 'learning_rate': 1.957659871473343e-06, 'rewards/chosen': 0.35385826230049133, 'rewards/rejected': -0.1072486937046051, 'rewards/accuracies': 0.75, 'rewards/margins': 0.46110692620277405, 'policy_logps/rejected': -487.6668395996094, 'policy_logps/chosen': -440.56488037109375, 'referece_logps/rejected': -486.5943603515625, 'referece_logps/chosen': -444.10345458984375, 'logits/rejected': -0.32736602425575256, 'logits/chosen': -0.285414457321167, 'epoch': 0.72}

 12%|█▏        | 1937/16104 [9:04:19<69:21:34, 17.63s/it]

 12%|█▏        | 1938/16104 [9:04:36<69:23:02, 17.63s/it]

 12%|█▏        | 1939/16104 [9:04:53<68:02:57, 17.29s/it]


 12%|█▏        | 1941/16104 [9:05:32<72:55:58, 18.54s/it]

 12%|█▏        | 1942/16104 [9:05:54<76:24:00, 19.42s/it]

 12%|█▏        | 1943/16104 [9:06:06<68:08:27, 17.32s/it]
{'loss': 0.5873, 'learning_rate': 1.957253589850242e-06, 'rewards/chosen': -0.7960712313652039, 'rewards/rejected': -1.388216495513916, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5921453237533569, 'policy_logps/rejected': -572.465087890625, 'policy_logps/chosen': -383.00604248046875, 'referece_logps/rejected': -558.5828857421875, 'referece_logps/chosen': -375.04534912109375, 'logits/rejected': -0.24472615122795105, 'logits/chosen': -0.09798114746809006, 'epoch': 0.72}


 12%|█▏        | 1945/16104 [9:06:30<56:48:11, 14.44s/it]
{'loss': 0.5957, 'learning_rate': 1.9571371608477004e-06, 'rewards/chosen': -0.3432893753051758, 'rewards/rejected': -1.0771484375, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7338590621948242, 'policy_logps/rejected': -654.3101806640625, 'policy_logps/chosen': -538.0443115234375, 'referece_logps/rejected': -643.5387573242188, 'referece_logps/chosen': -534.6113891601562, 'logits/rejected': 0.25418588519096375, 'logits/chosen': 0.4021187722682953, 'epoch': 0.72}

 12%|█▏        | 1946/16104 [9:06:53<66:33:11, 16.92s/it]

 12%|█▏        | 1947/16104 [9:07:13<70:39:51, 17.97s/it]


 12%|█▏        | 1949/16104 [9:07:56<77:31:53, 19.72s/it]
{'loss': 0.4709, 'learning_rate': 1.9569038382466124e-06, 'rewards/chosen': 0.09482099115848541, 'rewards/rejected': -1.625060796737671, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7198817729949951, 'policy_logps/rejected': -411.6819763183594, 'policy_logps/chosen': -591.9940795898438, 'referece_logps/rejected': -395.4313659667969, 'referece_logps/chosen': -592.9423217773438, 'logits/rejected': 0.06595472991466522, 'logits/chosen': -0.06909681856632233, 'epoch': 0.73}


 12%|█▏        | 1951/16104 [9:08:20<61:51:37, 15.73s/it]
{'loss': 0.5357, 'learning_rate': 1.956786944685819e-06, 'rewards/chosen': -0.0013309032656252384, 'rewards/rejected': -0.2677827775478363, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2664518356323242, 'policy_logps/rejected': -377.6008605957031, 'policy_logps/chosen': -481.9455871582031, 'referece_logps/rejected': -374.9229736328125, 'referece_logps/chosen': -481.9322509765625, 'logits/rejected': 0.3280072510242462, 'logits/chosen': 0.2984691262245178, 'epoch': 0.73}


 12%|█▏        | 1953/16104 [9:08:56<67:07:33, 17.08s/it]

 12%|█▏        | 1954/16104 [9:09:16<70:23:34, 17.91s/it]

 12%|█▏        | 1955/16104 [9:09:36<72:49:27, 18.53s/it]
{'loss': 0.5348, 'learning_rate': 1.9565526931383047e-06, 'rewards/chosen': -0.1106475368142128, 'rewards/rejected': -0.3363873362541199, 'rewards/accuracies': 0.5, 'rewards/margins': 0.22573977708816528, 'policy_logps/rejected': -261.12646484375, 'policy_logps/chosen': -288.83319091796875, 'referece_logps/rejected': -257.7625732421875, 'referece_logps/chosen': -287.7266845703125, 'logits/rejected': -0.6467889547348022, 'logits/chosen': -0.682365894317627, 'epoch': 0.73}

 12%|█▏        | 1956/16104 [9:09:54<71:33:54, 18.21s/it]

 12%|█▏        | 1957/16104 [9:10:13<73:11:31, 18.63s/it]

 12%|█▏        | 1958/16104 [9:10:32<73:00:28, 18.58s/it]


 12%|█▏        | 1960/16104 [9:11:03<67:51:10, 17.27s/it]
{'loss': 0.5477, 'learning_rate': 1.9562590081008352e-06, 'rewards/chosen': -0.42447108030319214, 'rewards/rejected': -0.9898015856742859, 'rewards/accuracies': 0.625, 'rewards/margins': 0.565330445766449, 'policy_logps/rejected': -242.4134521484375, 'policy_logps/chosen': -271.494873046875, 'referece_logps/rejected': -232.51544189453125, 'referece_logps/chosen': -267.2501525878906, 'logits/rejected': -0.15352794528007507, 'logits/chosen': -0.2987469434738159, 'epoch': 0.73}


 12%|█▏        | 1962/16104 [9:11:40<69:09:01, 17.60s/it]

 12%|█▏        | 1963/16104 [9:11:54<65:40:13, 16.72s/it]
{'loss': 0.6127, 'learning_rate': 1.9560823328707423e-06, 'rewards/chosen': -0.15889833867549896, 'rewards/rejected': -0.7220096588134766, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5631113052368164, 'policy_logps/rejected': -389.64044189453125, 'policy_logps/chosen': -559.4498901367188, 'referece_logps/rejected': -382.42034912109375, 'referece_logps/chosen': -557.8609619140625, 'logits/rejected': -0.2159033566713333, 'logits/chosen': -0.44111165404319763, 'epoch': 0.73}


 12%|█▏        | 1966/16104 [9:12:34<56:55:35, 14.50s/it]
{'loss': 0.6652, 'learning_rate': 1.9559643560038606e-06, 'rewards/chosen': -0.10289430618286133, 'rewards/rejected': -0.5087974071502686, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4059031307697296, 'policy_logps/rejected': -310.699462890625, 'policy_logps/chosen': -283.481689453125, 'referece_logps/rejected': -305.6114807128906, 'referece_logps/chosen': -282.4527282714844, 'logits/rejected': -0.008220132440328598, 'logits/chosen': 0.03759618476033211, 'epoch': 0.73}
{'loss': 0.6507, 'learning_rate': 1.955905309563531e-06, 'rewards/chosen': 0.06508903950452805, 'rewards/rejected': -0.8896806240081787, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9547697305679321, 'policy_logps/rejected': -223.95701599121094, 'policy_logps/chosen': -309.973876953125, 'referece_logps/rejected': -215.06019592285156, 'referece_logps/chosen': -310.624755859375, 'logits/rejected': -0.8102408647537231, 'logits/chosen': -0.647221028804779, 'epoch': 0.73}


 12%|█▏        | 1968/16104 [9:13:06<61:17:07, 15.61s/it]

 12%|█▏        | 1969/16104 [9:13:22<62:16:56, 15.86s/it]
{'loss': 0.5009, 'learning_rate': 1.955727938243648e-06, 'rewards/chosen': 0.06745871156454086, 'rewards/rejected': -0.6315605044364929, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6990192532539368, 'policy_logps/rejected': -613.0989990234375, 'policy_logps/chosen': -463.48663330078125, 'referece_logps/rejected': -606.7835083007812, 'referece_logps/chosen': -464.1611633300781, 'logits/rejected': -0.07563666999340057, 'logits/chosen': 0.0244956836104393, 'epoch': 0.73}


 12%|█▏        | 1971/16104 [9:13:50<57:11:34, 14.57s/it]
{'loss': 0.5638, 'learning_rate': 1.9556094973885704e-06, 'rewards/chosen': -0.18452510237693787, 'rewards/rejected': -0.47645020484924316, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2919250428676605, 'policy_logps/rejected': -375.588134765625, 'policy_logps/chosen': -378.8241882324219, 'referece_logps/rejected': -370.82366943359375, 'referece_logps/chosen': -376.9789123535156, 'logits/rejected': -0.5925887823104858, 'logits/chosen': -0.582065999507904, 'epoch': 0.73}

 12%|█▏        | 1972/16104 [9:14:05<57:25:17, 14.63s/it]


 12%|█▏        | 1974/16104 [9:14:36<60:06:56, 15.32s/it]
{'loss': 0.5044, 'learning_rate': 1.955431546191132e-06, 'rewards/chosen': 0.24742525815963745, 'rewards/rejected': -0.09638175368309021, 'rewards/accuracies': 0.875, 'rewards/margins': 0.34380704164505005, 'policy_logps/rejected': -482.1124267578125, 'policy_logps/chosen': -437.89715576171875, 'referece_logps/rejected': -481.1485900878906, 'referece_logps/chosen': -440.37139892578125, 'logits/rejected': -0.3693769574165344, 'logits/chosen': -0.38917046785354614, 'epoch': 0.74}


 12%|█▏        | 1976/16104 [9:15:04<56:46:11, 14.47s/it]
{'loss': 0.6073, 'learning_rate': 1.9553127188109526e-06, 'rewards/chosen': -0.45468443632125854, 'rewards/rejected': -0.6738038063049316, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2191193550825119, 'policy_logps/rejected': -457.07769775390625, 'policy_logps/chosen': -530.3234252929688, 'referece_logps/rejected': -450.33966064453125, 'referece_logps/chosen': -525.776611328125, 'logits/rejected': -1.1705609560012817, 'logits/chosen': -1.0804253816604614, 'epoch': 0.74}


 12%|█▏        | 1978/16104 [9:15:34<58:21:25, 14.87s/it]
{'loss': 0.5636, 'learning_rate': 1.9551937368543573e-06, 'rewards/chosen': -0.26763877272605896, 'rewards/rejected': -1.0743978023529053, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8067591190338135, 'policy_logps/rejected': -482.3912048339844, 'policy_logps/chosen': -546.3946533203125, 'referece_logps/rejected': -471.647216796875, 'referece_logps/chosen': -543.71826171875, 'logits/rejected': -0.9496726393699646, 'logits/chosen': -0.5000556707382202, 'epoch': 0.74}

 12%|█▏        | 1979/16104 [9:15:52<61:39:34, 15.72s/it]


 12%|█▏        | 1981/16104 [9:16:29<67:07:05, 17.11s/it]

 12%|█▏        | 1982/16104 [9:16:46<67:54:33, 17.31s/it]

 12%|█▏        | 1983/16104 [9:16:58<61:30:52, 15.68s/it]
{'loss': 0.5008, 'learning_rate': 1.9548956058174564e-06, 'rewards/chosen': -0.4163424074649811, 'rewards/rejected': -0.9164400100708008, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5000975131988525, 'policy_logps/rejected': -387.39862060546875, 'policy_logps/chosen': -387.9440612792969, 'referece_logps/rejected': -378.2342224121094, 'referece_logps/chosen': -383.7806701660156, 'logits/rejected': -0.4480452537536621, 'logits/chosen': -0.4805038571357727, 'epoch': 0.74}

 12%|█▏        | 1984/16104 [9:17:18<66:04:36, 16.85s/it]


 12%|█▏        | 1986/16104 [9:17:48<62:45:50, 16.00s/it]
{'loss': 0.5384, 'learning_rate': 1.954716263649242e-06, 'rewards/chosen': -0.23285198211669922, 'rewards/rejected': -0.9968494176864624, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7639973163604736, 'policy_logps/rejected': -259.3409423828125, 'policy_logps/chosen': -321.55792236328125, 'referece_logps/rejected': -249.37245178222656, 'referece_logps/chosen': -319.22943115234375, 'logits/rejected': -0.5718861818313599, 'logits/chosen': -0.47723785042762756, 'epoch': 0.74}

 12%|█▏        | 1987/16104 [9:18:06<64:05:39, 16.34s/it]

 12%|█▏        | 1988/16104 [9:18:22<64:24:12, 16.42s/it]

 12%|█▏        | 1989/16104 [9:18:34<58:47:07, 14.99s/it]


 12%|█▏        | 1991/16104 [9:19:11<65:30:01, 16.71s/it]
{'loss': 0.439, 'learning_rate': 1.954416587668341e-06, 'rewards/chosen': 0.34161508083343506, 'rewards/rejected': -0.2578875422477722, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5995026230812073, 'policy_logps/rejected': -396.11175537109375, 'policy_logps/chosen': -421.9345703125, 'referece_logps/rejected': -393.53289794921875, 'referece_logps/chosen': -425.35076904296875, 'logits/rejected': 0.42767786979675293, 'logits/chosen': 0.3372574746608734, 'epoch': 0.74}

 12%|█▏        | 1992/16104 [9:19:28<66:17:48, 16.91s/it]

 12%|█▏        | 1993/16104 [9:19:48<69:28:05, 17.72s/it]


 12%|█▏        | 1995/16104 [9:20:25<71:19:52, 18.20s/it]

 12%|█▏        | 1996/16104 [9:20:41<68:31:28, 17.49s/it]

 12%|█▏        | 1997/16104 [9:21:01<71:15:04, 18.18s/it]
{'loss': 0.5747, 'learning_rate': 1.9540557024589158e-06, 'rewards/chosen': 0.24382686614990234, 'rewards/rejected': -0.27434635162353516, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5181732177734375, 'policy_logps/rejected': -441.06451416015625, 'policy_logps/chosen': -403.740966796875, 'referece_logps/rejected': -438.321044921875, 'referece_logps/chosen': -406.17926025390625, 'logits/rejected': -0.5438842177391052, 'logits/chosen': -0.49351879954338074, 'epoch': 0.74}

 12%|█▏        | 1998/16104 [9:21:21<74:19:22, 18.97s/it]


 12%|█▏        | 2000/16104 [9:21:57<72:13:38, 18.44s/it]

 12%|█▏        | 2001/16104 [9:22:25<83:36:39, 21.34s/it]
{'loss': 0.5702, 'learning_rate': 1.953814340421752e-06, 'rewards/chosen': -0.4837661385536194, 'rewards/rejected': -0.8349434733390808, 'rewards/accuracies': 0.625, 'rewards/margins': 0.35117724537849426, 'policy_logps/rejected': -420.3430480957031, 'policy_logps/chosen': -364.69775390625, 'referece_logps/rejected': -411.99365234375, 'referece_logps/chosen': -359.860107421875, 'logits/rejected': -0.1969006359577179, 'logits/chosen': -0.07473376393318176, 'epoch': 0.75}


 12%|█▏        | 2003/16104 [9:22:59<75:06:22, 19.17s/it]

 12%|█▏        | 2004/16104 [9:23:11<66:22:48, 16.95s/it]
{'loss': 0.5615, 'learning_rate': 1.953632913758674e-06, 'rewards/chosen': -0.4133756756782532, 'rewards/rejected': -0.4465968906879425, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03322122246026993, 'policy_logps/rejected': -334.1986083984375, 'policy_logps/chosen': -381.1833801269531, 'referece_logps/rejected': -329.732666015625, 'referece_logps/chosen': -377.0496520996094, 'logits/rejected': 0.6045132875442505, 'logits/chosen': 0.5069934129714966, 'epoch': 0.75}

 12%|█▏        | 2005/16104 [9:23:22<59:35:57, 15.22s/it]


 12%|█▏        | 2007/16104 [9:23:47<54:17:20, 13.86s/it]

 12%|█▏        | 2008/16104 [9:23:59<52:16:49, 13.35s/it]
{'loss': 0.6495, 'learning_rate': 1.953390471486542e-06, 'rewards/chosen': 0.04645231366157532, 'rewards/rejected': -0.1634971797466278, 'rewards/accuracies': 0.75, 'rewards/margins': 0.20994949340820312, 'policy_logps/rejected': -565.7911987304688, 'policy_logps/chosen': -511.8741149902344, 'referece_logps/rejected': -564.15625, 'referece_logps/chosen': -512.338623046875, 'logits/rejected': -0.3285830020904541, 'logits/chosen': -0.22851763665676117, 'epoch': 0.75}

 12%|█▏        | 2009/16104 [9:24:10<49:32:10, 12.65s/it]

 12%|█▏        | 2010/16104 [9:24:22<48:33:47, 12.40s/it]

 12%|█▏        | 2011/16104 [9:24:36<50:16:23, 12.84s/it]

 12%|█▏        | 2012/16104 [9:24:58<61:01:35, 15.59s/it]


 13%|█▎        | 2014/16104 [9:25:27<58:48:45, 15.03s/it]
{'loss': 0.6162, 'learning_rate': 1.953025651137172e-06, 'rewards/chosen': -0.12984143197536469, 'rewards/rejected': -0.674471378326416, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5446299910545349, 'policy_logps/rejected': -387.9331970214844, 'policy_logps/chosen': -587.068603515625, 'referece_logps/rejected': -381.1885070800781, 'referece_logps/chosen': -585.7702026367188, 'logits/rejected': -0.9796356558799744, 'logits/chosen': -0.9345585703849792, 'epoch': 0.75}


 13%|█▎        | 2016/16104 [9:25:49<50:35:58, 12.93s/it]
{'loss': 0.6241, 'learning_rate': 1.952903735915085e-06, 'rewards/chosen': 0.2589317262172699, 'rewards/rejected': 0.2796659469604492, 'rewards/accuracies': 0.625, 'rewards/margins': -0.020734228193759918, 'policy_logps/rejected': -560.6962890625, 'policy_logps/chosen': -537.8209228515625, 'referece_logps/rejected': -563.492919921875, 'referece_logps/chosen': -540.4102783203125, 'logits/rejected': -0.39684009552001953, 'logits/chosen': -0.33626240491867065, 'epoch': 0.75}

 13%|█▎        | 2017/16104 [9:26:02<50:02:13, 12.79s/it]


 13%|█▎        | 2019/16104 [9:26:39<62:54:25, 16.08s/it]

 13%|█▎        | 2020/16104 [9:26:51<57:51:54, 14.79s/it]
{'loss': 0.5218, 'learning_rate': 1.9526594429307884e-06, 'rewards/chosen': 0.31335002183914185, 'rewards/rejected': -0.3694121241569519, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6827621459960938, 'policy_logps/rejected': -383.48321533203125, 'policy_logps/chosen': -582.4169921875, 'referece_logps/rejected': -379.78912353515625, 'referece_logps/chosen': -585.550537109375, 'logits/rejected': -0.5925500392913818, 'logits/chosen': -0.3941916227340698, 'epoch': 0.75}

 13%|█▎        | 2021/16104 [9:27:04<55:47:17, 14.26s/it]

 13%|█▎        | 2022/16104 [9:27:22<60:12:20, 15.39s/it]


 13%|█▎        | 2024/16104 [9:27:47<54:46:11, 14.00s/it]
{'loss': 0.4656, 'learning_rate': 1.9524145333581313e-06, 'rewards/chosen': 0.18196994066238403, 'rewards/rejected': -0.06816253811120987, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2501324713230133, 'policy_logps/rejected': -332.0582275390625, 'policy_logps/chosen': -349.11639404296875, 'referece_logps/rejected': -331.3765869140625, 'referece_logps/chosen': -350.9361267089844, 'logits/rejected': -0.43217071890830994, 'logits/chosen': -0.3912273943424225, 'epoch': 0.75}

 13%|█▎        | 2025/16104 [9:28:07<60:52:19, 15.57s/it]


 13%|█▎        | 2027/16104 [9:28:47<70:44:42, 18.09s/it]
{'loss': 0.5326, 'learning_rate': 1.9522304466378673e-06, 'rewards/chosen': -0.12833824753761292, 'rewards/rejected': -0.9156002402305603, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7872620820999146, 'policy_logps/rejected': -366.49163818359375, 'policy_logps/chosen': -375.6100158691406, 'referece_logps/rejected': -357.3356628417969, 'referece_logps/chosen': -374.3266296386719, 'logits/rejected': 0.2469123899936676, 'logits/chosen': 0.28302139043807983, 'epoch': 0.76}

 13%|█▎        | 2028/16104 [9:29:08<74:14:11, 18.99s/it]

 13%|█▎        | 2029/16104 [9:29:28<74:56:06, 19.17s/it]

 13%|█▎        | 2030/16104 [9:29:47<74:29:43, 19.06s/it]

 13%|█▎        | 2031/16104 [9:30:03<71:39:51, 18.33s/it]

 13%|█▎        | 2032/16104 [9:30:22<72:01:54, 18.43s/it]

 13%|█▎        | 2033/16104 [9:30:37<67:56:53, 17.38s/it]


 13%|█▎        | 2035/16104 [9:31:22<77:14:24, 19.76s/it]
{'loss': 0.4702, 'learning_rate': 1.951737854045121e-06, 'rewards/chosen': 0.028677567839622498, 'rewards/rejected': -0.3583005666732788, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3869781494140625, 'policy_logps/rejected': -487.00750732421875, 'policy_logps/chosen': -610.1565551757812, 'referece_logps/rejected': -483.4245300292969, 'referece_logps/chosen': -610.443359375, 'logits/rejected': 0.6376152038574219, 'logits/chosen': 0.6237348914146423, 'epoch': 0.76}


 13%|█▎        | 2037/16104 [9:31:54<71:35:27, 18.32s/it]
{'loss': 0.4622, 'learning_rate': 1.951614320852115e-06, 'rewards/chosen': -0.5838972926139832, 'rewards/rejected': -1.4523869752883911, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8684895038604736, 'policy_logps/rejected': -418.023681640625, 'policy_logps/chosen': -317.3432312011719, 'referece_logps/rejected': -403.4998474121094, 'referece_logps/chosen': -311.5042724609375, 'logits/rejected': -1.0758799314498901, 'logits/chosen': -0.6784268617630005, 'epoch': 0.76}

 13%|█▎        | 2038/16104 [9:32:08<67:00:43, 17.15s/it]


 13%|█▎        | 2040/16104 [9:32:48<71:41:09, 18.35s/it]

 13%|█▎        | 2041/16104 [9:33:06<71:17:35, 18.25s/it]
{'loss': 0.5603, 'learning_rate': 1.951366792552152e-06, 'rewards/chosen': 0.16121253371238708, 'rewards/rejected': -0.4429108798503876, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6041234135627747, 'policy_logps/rejected': -263.7565612792969, 'policy_logps/chosen': -393.1580810546875, 'referece_logps/rejected': -259.32745361328125, 'referece_logps/chosen': -394.77020263671875, 'logits/rejected': -0.31977877020835876, 'logits/chosen': -0.354397177696228, 'epoch': 0.76}

 13%|█▎        | 2042/16104 [9:33:23<69:28:24, 17.79s/it]


 13%|█▎        | 2044/16104 [9:34:00<72:22:01, 18.53s/it]
{'loss': 0.5836, 'learning_rate': 1.951180742231337e-06, 'rewards/chosen': -0.5391260385513306, 'rewards/rejected': -0.7862328290939331, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24710685014724731, 'policy_logps/rejected': -334.8450927734375, 'policy_logps/chosen': -399.51513671875, 'referece_logps/rejected': -326.9827575683594, 'referece_logps/chosen': -394.1238708496094, 'logits/rejected': -0.246751606464386, 'logits/chosen': -0.47209206223487854, 'epoch': 0.76}


 13%|█▎        | 2046/16104 [9:34:28<63:48:15, 16.34s/it]
{'loss': 0.5646, 'learning_rate': 1.9510565162951534e-06, 'rewards/chosen': 0.20076106488704681, 'rewards/rejected': -0.028882499784231186, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2296435534954071, 'policy_logps/rejected': -401.8391418457031, 'policy_logps/chosen': -472.3918151855469, 'referece_logps/rejected': -401.55035400390625, 'referece_logps/chosen': -474.3994445800781, 'logits/rejected': -0.29197660088539124, 'logits/chosen': -0.31043124198913574, 'epoch': 0.76}

 13%|█▎        | 2047/16104 [9:34:49<69:12:34, 17.72s/it]

 13%|█▎        | 2048/16104 [9:35:00<61:41:07, 15.80s/it]

 13%|█▎        | 2049/16104 [9:35:18<63:32:28, 16.28s/it]

 13%|█▎        | 2050/16104 [9:35:34<63:08:09, 16.17s/it]

 13%|█▎        | 2051/16104 [9:35:55<69:33:08, 17.82s/it]


 13%|█▎        | 2053/16104 [9:36:26<64:37:30, 16.56s/it]
{'loss': 0.5495, 'learning_rate': 1.9506205137847627e-06, 'rewards/chosen': -0.33808058500289917, 'rewards/rejected': -1.0622807741165161, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7242001295089722, 'policy_logps/rejected': -558.9472045898438, 'policy_logps/chosen': -534.6860961914062, 'referece_logps/rejected': -548.3243408203125, 'referece_logps/chosen': -531.3052978515625, 'logits/rejected': -0.5629260540008545, 'logits/chosen': -0.2831610441207886, 'epoch': 0.76}


 13%|█▎        | 2055/16104 [9:37:00<64:49:17, 16.61s/it]
{'loss': 0.4221, 'learning_rate': 1.95049559551244e-06, 'rewards/chosen': -0.8271322250366211, 'rewards/rejected': -1.5848937034606934, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7577614784240723, 'policy_logps/rejected': -408.347900390625, 'policy_logps/chosen': -619.2848510742188, 'referece_logps/rejected': -392.4989318847656, 'referece_logps/chosen': -611.0135498046875, 'logits/rejected': -0.39828938245773315, 'logits/chosen': -0.32962191104888916, 'epoch': 0.77}

 13%|█▎        | 2056/16104 [9:37:18<65:54:59, 16.89s/it]

 13%|█▎        | 2057/16104 [9:37:38<69:44:24, 17.87s/it]

 13%|█▎        | 2058/16104 [9:37:59<73:55:19, 18.95s/it]

 13%|█▎        | 2059/16104 [9:38:16<71:06:05, 18.22s/it]

 13%|█▎        | 2060/16104 [9:38:31<66:59:07, 17.17s/it]


 13%|█▎        | 2062/16104 [9:39:06<68:41:19, 17.61s/it]
{'loss': 0.4808, 'learning_rate': 1.9500571705410402e-06, 'rewards/chosen': -0.21929818391799927, 'rewards/rejected': -0.9582129716873169, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7389147877693176, 'policy_logps/rejected': -417.6663513183594, 'policy_logps/chosen': -492.47381591796875, 'referece_logps/rejected': -408.0841979980469, 'referece_logps/chosen': -490.2807922363281, 'logits/rejected': 0.33460429310798645, 'logits/chosen': 0.4483673572540283, 'epoch': 0.77}

 13%|█▎        | 2063/16104 [9:39:23<67:38:29, 17.34s/it]

 13%|█▎        | 2064/16104 [9:39:45<72:41:51, 18.64s/it]

 13%|█▎        | 2065/16104 [9:40:06<76:09:35, 19.53s/it]


 13%|█▎        | 2067/16104 [9:40:34<65:12:11, 16.72s/it]
{'loss': 0.5192, 'learning_rate': 1.949742856851312e-06, 'rewards/chosen': 0.09551446884870529, 'rewards/rejected': -0.7232215404510498, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8187360763549805, 'policy_logps/rejected': -418.1280212402344, 'policy_logps/chosen': -368.15911865234375, 'referece_logps/rejected': -410.89581298828125, 'referece_logps/chosen': -369.1142578125, 'logits/rejected': 0.29506105184555054, 'logits/chosen': 0.2052641659975052, 'epoch': 0.77}

 13%|█▎        | 2068/16104 [9:40:48<61:21:59, 15.74s/it]

 13%|█▎        | 2069/16104 [9:41:10<68:48:49, 17.65s/it]


 13%|█▎        | 2071/16104 [9:41:39<60:58:54, 15.64s/it]
{'loss': 0.5997, 'learning_rate': 1.9494907143460156e-06, 'rewards/chosen': -0.00918484479188919, 'rewards/rejected': -0.5417923331260681, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5326074361801147, 'policy_logps/rejected': -526.7490234375, 'policy_logps/chosen': -428.4635314941406, 'referece_logps/rejected': -521.3311157226562, 'referece_logps/chosen': -428.3717041015625, 'logits/rejected': 0.5916855335235596, 'logits/chosen': 0.5351365208625793, 'epoch': 0.77}

 13%|█▎        | 2072/16104 [9:41:55<62:19:26, 15.99s/it]

 13%|█▎        | 2073/16104 [9:42:14<64:59:32, 16.68s/it]

 13%|█▎        | 2074/16104 [9:42:25<58:38:10, 15.05s/it]


 13%|█▎        | 2076/16104 [9:42:58<62:32:02, 16.05s/it]
{'loss': 0.5552, 'learning_rate': 1.9491746720402408e-06, 'rewards/chosen': -0.5261638164520264, 'rewards/rejected': -1.029500126838684, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5033362507820129, 'policy_logps/rejected': -348.2022399902344, 'policy_logps/chosen': -312.9820861816406, 'referece_logps/rejected': -337.9072265625, 'referece_logps/chosen': -307.720458984375, 'logits/rejected': -0.6072508692741394, 'logits/chosen': -0.6916373372077942, 'epoch': 0.77}

 13%|█▎        | 2077/16104 [9:43:19<68:25:15, 17.56s/it]

 13%|█▎        | 2078/16104 [9:43:39<71:00:32, 18.23s/it]

 13%|█▎        | 2079/16104 [9:43:57<70:36:06, 18.12s/it]

 13%|█▎        | 2080/16104 [9:44:19<75:02:14, 19.26s/it]

 13%|█▎        | 2081/16104 [9:44:30<65:35:20, 16.84s/it]

 13%|█▎        | 2082/16104 [9:44:42<60:06:14, 15.43s/it]

 13%|█▎        | 2083/16104 [9:44:53<54:50:59, 14.08s/it]

 13%|█▎        | 2084/16104 [9:45:14<62:25:19, 16.03s/it]

 13%|█▎        | 2085/16104 [9:45:33<65:59:03, 16.94s/it]

 13%|█▎        | 2086/16104 [9:45:49<64:49:30, 16.65s/it]

 13%|█▎        | 2087/16104 [9:46:04<63:13:59, 16.24s/it]

 13%|█▎        | 2088/16104 [9:46:16<58:19:12, 14.98s/it]

 13%|█▎        | 2089/16104 [9:46:32<59:23:38, 15.26s/it]

 13%|█▎        | 2090/16104 [9:46:49<61:45:32, 15.87s/it]

 13%|█▎        | 2091/16104 [9:47:04<60:13:23, 15.47s/it]

 13%|█▎        | 2092/16104 [9:47:19<59:07:58, 15.19s/it]

 13%|█▎        | 2093/16104 [9:47:29<53:55:06, 13.85s/it]

 13%|█▎        | 2094/16104 [9:47:49<60:14:26, 15.48s/it]

 13%|█▎        | 2095/16104 [9:48:07<64:16:35, 16.52s/it]


 13%|█▎        | 2097/16104 [9:48:41<66:17:55, 17.04s/it]
{'loss': 0.453, 'learning_rate': 1.9478368160412653e-06, 'rewards/chosen': 0.3005926311016083, 'rewards/rejected': -0.9480682611465454, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2486608028411865, 'policy_logps/rejected': -380.95391845703125, 'policy_logps/chosen': -391.11541748046875, 'referece_logps/rejected': -371.4732360839844, 'referece_logps/chosen': -394.1213073730469, 'logits/rejected': 0.20751047134399414, 'logits/chosen': 0.39125239849090576, 'epoch': 0.78}

 13%|█▎        | 2098/16104 [9:48:59<67:00:59, 17.23s/it]

 13%|█▎        | 2099/16104 [9:49:18<68:49:50, 17.69s/it]

 13%|█▎        | 2100/16104 [9:49:38<71:31:40, 18.39s/it]

 13%|█▎        | 2101/16104 [9:49:57<72:59:36, 18.77s/it]

 13%|█▎        | 2102/16104 [9:50:14<71:15:33, 18.32s/it]


 13%|█▎        | 2104/16104 [9:50:51<71:58:15, 18.51s/it]

 13%|█▎        | 2105/16104 [9:51:11<73:58:27, 19.02s/it]

 13%|█▎        | 2106/16104 [9:51:32<75:49:31, 19.50s/it]

 13%|█▎        | 2107/16104 [9:51:44<67:13:20, 17.29s/it]

 13%|█▎        | 2108/16104 [9:51:55<60:25:11, 15.54s/it]

 13%|█▎        | 2109/16104 [9:52:16<66:12:47, 17.03s/it]

 13%|█▎        | 2110/16104 [9:52:36<70:14:03, 18.07s/it]

 13%|█▎        | 2111/16104 [9:52:55<70:24:38, 18.11s/it]

 13%|█▎        | 2112/16104 [9:53:08<65:01:16, 16.73s/it]

 13%|█▎        | 2113/16104 [9:53:29<70:04:18, 18.03s/it]

 13%|█▎        | 2114/16104 [9:53:46<68:53:14, 17.73s/it]

 13%|█▎        | 2115/16104 [9:54:06<71:11:17, 18.32s/it]
[2024-04-06 01:28:03,141] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2116/16104 [9:54:21<67:41:19, 17.42s/it]

 13%|█▎        | 2117/16104 [9:54:42<71:21:07, 18.36s/it]

 13%|█▎        | 2118/16104 [9:55:02<73:06:05, 18.82s/it]

 13%|█▎        | 2119/16104 [9:55:18<69:58:56, 18.01s/it]

 13%|█▎        | 2120/16104 [9:55:32<65:28:35, 16.86s/it]

 13%|█▎        | 2121/16104 [9:55:51<67:48:34, 17.46s/it]

 13%|█▎        | 2122/16104 [9:56:08<67:49:52, 17.46s/it]

 13%|█▎        | 2123/16104 [9:56:24<65:44:55, 16.93s/it]

 13%|█▎        | 2124/16104 [9:56:41<65:56:45, 16.98s/it]

 13%|█▎        | 2125/16104 [9:57:01<69:13:29, 17.83s/it]

 13%|█▎        | 2126/16104 [9:57:23<74:40:35, 19.23s/it]

 13%|█▎        | 2127/16104 [9:57:46<79:06:04, 20.37s/it]

 13%|█▎        | 2128/16104 [9:57:59<70:25:04, 18.14s/it]

 13%|█▎        | 2129/16104 [9:58:11<63:01:17, 16.23s/it]

 13%|█▎        | 2130/16104 [9:58:31<67:31:21, 17.40s/it]

 13%|█▎        | 2131/16104 [9:58:44<61:52:22, 15.94s/it]

 13%|█▎        | 2132/16104 [9:58:57<59:12:06, 15.25s/it]

 13%|█▎        | 2133/16104 [9:59:10<56:27:12, 14.55s/it]

 13%|█▎        | 2134/16104 [9:59:29<60:45:27, 15.66s/it]

 13%|█▎        | 2135/16104 [9:59:44<61:04:28, 15.74s/it]

 13%|█▎        | 2136/16104 [10:00:01<61:54:31, 15.96s/it]

 13%|█▎        | 2137/16104 [10:00:18<62:42:57, 16.17s/it]

 13%|█▎        | 2138/16104 [10:00:28<56:23:37, 14.54s/it]

 13%|█▎        | 2139/16104 [10:00:49<63:55:22, 16.48s/it]

 13%|█▎        | 2140/16104 [10:01:02<59:42:06, 15.39s/it]

 13%|█▎        | 2141/16104 [10:01:14<55:34:40, 14.33s/it]

 13%|█▎        | 2142/16104 [10:01:34<62:20:04, 16.07s/it]

 13%|█▎        | 2143/16104 [10:01:52<64:45:01, 16.70s/it]

 13%|█▎        | 2144/16104 [10:02:11<67:33:44, 17.42s/it]

 13%|█▎        | 2145/16104 [10:02:24<61:36:22, 15.89s/it]
[2024-04-06 01:36:21,051] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2146/16104 [10:02:42<63:53:35, 16.48s/it]

 13%|█▎        | 2147/16104 [10:03:03<69:47:38, 18.00s/it]

 13%|█▎        | 2148/16104 [10:03:23<72:08:17, 18.61s/it]

 13%|█▎        | 2149/16104 [10:03:35<64:26:31, 16.62s/it]

 13%|█▎        | 2150/16104 [10:03:55<68:15:45, 17.61s/it]

 13%|█▎        | 2151/16104 [10:04:08<62:36:18, 16.15s/it]
{'loss': 0.532, 'learning_rate': 1.944319031326083e-06, 'rewards/chosen': 0.19991910457611084, 'rewards/rejected': -0.40598100423812866, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6059001088142395, 'policy_logps/rejected': -335.945556640625, 'policy_logps/chosen': -371.494140625, 'referece_logps/rejected': -331.8858337402344, 'referece_logps/chosen': -373.4932861328125, 'logits/rejected': -0.216914564371109, 'logits/chosen': -0.2118716984987259, 'epoch': 0.8}
[2024-04-06 01:38:27,452] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2152/16104 [10:04:30<69:45:19, 18.00s/it]


 13%|█▎        | 2154/16104 [10:05:00<62:29:19, 16.13s/it]

 13%|█▎        | 2155/16104 [10:05:21<67:51:44, 17.51s/it]
{'loss': 0.4316, 'learning_rate': 1.944054018416388e-06, 'rewards/chosen': -0.28877580165863037, 'rewards/rejected': -1.1515268087387085, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8627508878707886, 'policy_logps/rejected': -186.51612854003906, 'policy_logps/chosen': -383.056640625, 'referece_logps/rejected': -175.0008544921875, 'referece_logps/chosen': -380.16888427734375, 'logits/rejected': -0.351369708776474, 'logits/chosen': -0.1699056774377823, 'epoch': 0.8}


 13%|█▎        | 2157/16104 [10:05:59<71:22:51, 18.42s/it]

 13%|█▎        | 2158/16104 [10:06:19<72:49:09, 18.80s/it]

 13%|█▎        | 2159/16104 [10:06:35<69:03:54, 17.83s/it]

 13%|█▎        | 2160/16104 [10:06:51<67:51:32, 17.52s/it]

 13%|█▎        | 2161/16104 [10:07:12<71:41:27, 18.51s/it]
[2024-04-06 01:41:09,467] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2162/16104 [10:07:25<65:30:26, 16.91s/it]
[2024-04-06 01:41:22,659] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2163/16104 [10:07:38<60:21:33, 15.59s/it]

 13%|█▎        | 2164/16104 [10:07:58<65:18:08, 16.86s/it]
{'loss': 0.5567, 'learning_rate': 1.9434555055944557e-06, 'rewards/chosen': 0.19378195703029633, 'rewards/rejected': -0.750683069229126, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9444650411605835, 'policy_logps/rejected': -440.35565185546875, 'policy_logps/chosen': -512.0164794921875, 'referece_logps/rejected': -432.8487854003906, 'referece_logps/chosen': -513.954345703125, 'logits/rejected': -0.136165052652359, 'logits/chosen': -0.12767183780670166, 'epoch': 0.81}

 13%|█▎        | 2165/16104 [10:08:14<65:03:32, 16.80s/it]


 13%|█▎        | 2167/16104 [10:08:48<64:59:24, 16.79s/it]

 13%|█▎        | 2168/16104 [10:09:01<60:45:06, 15.69s/it]

 13%|█▎        | 2169/16104 [10:09:17<61:19:57, 15.84s/it]

 13%|█▎        | 2170/16104 [10:09:31<59:03:48, 15.26s/it]

 13%|█▎        | 2171/16104 [10:09:43<55:27:23, 14.33s/it]
{'loss': 0.5472, 'learning_rate': 1.9429878583119356e-06, 'rewards/chosen': 0.036114126443862915, 'rewards/rejected': -0.5350112318992615, 'rewards/accuracies': 0.75, 'rewards/margins': 0.571125328540802, 'policy_logps/rejected': -526.8225708007812, 'policy_logps/chosen': -582.96875, 'referece_logps/rejected': -521.472412109375, 'referece_logps/chosen': -583.3299560546875, 'logits/rejected': -0.6841046810150146, 'logits/chosen': -0.6793761849403381, 'epoch': 0.81}


 13%|█▎        | 2173/16104 [10:10:09<52:45:26, 13.63s/it]

 13%|█▎        | 2174/16104 [10:10:30<61:20:19, 15.85s/it]

 14%|█▎        | 2175/16104 [10:10:52<68:43:03, 17.76s/it]
[2024-04-06 01:44:49,660] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▎        | 2176/16104 [10:11:12<71:07:23, 18.38s/it]

 14%|█▎        | 2177/16104 [10:11:26<65:33:18, 16.95s/it]

 14%|█▎        | 2178/16104 [10:11:45<68:28:31, 17.70s/it]

 14%|█▎        | 2179/16104 [10:12:05<70:36:15, 18.25s/it]

 14%|█▎        | 2180/16104 [10:12:20<67:00:38, 17.33s/it]

 14%|█▎        | 2181/16104 [10:12:36<65:39:45, 16.98s/it]

 14%|█▎        | 2182/16104 [10:12:57<70:35:31, 18.25s/it]

 14%|█▎        | 2183/16104 [10:13:21<76:15:14, 19.72s/it]

 14%|█▎        | 2184/16104 [10:13:34<68:31:40, 17.72s/it]

 14%|█▎        | 2185/16104 [10:13:52<68:54:53, 17.82s/it]

 14%|█▎        | 2186/16104 [10:14:02<60:37:50, 15.68s/it]

 14%|█▎        | 2187/16104 [10:14:19<61:59:46, 16.04s/it]

 14%|█▎        | 2188/16104 [10:14:34<60:04:16, 15.54s/it]

 14%|█▎        | 2189/16104 [10:14:52<63:35:17, 16.45s/it]

 14%|█▎        | 2190/16104 [10:15:13<68:10:34, 17.64s/it]
[2024-04-06 01:49:09,836] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▎        | 2191/16104 [10:15:31<69:12:34, 17.91s/it]
{'loss': 0.5071, 'learning_rate': 1.941641427101662e-06, 'rewards/chosen': -0.2315068244934082, 'rewards/rejected': -1.0918288230895996, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8603220582008362, 'policy_logps/rejected': -305.70849609375, 'policy_logps/chosen': -357.3454895019531, 'referece_logps/rejected': -294.7901916503906, 'referece_logps/chosen': -355.0304260253906, 'logits/rejected': -0.09936463832855225, 'logits/chosen': 0.06102980673313141, 'epoch': 0.82}


 14%|█▎        | 2193/16104 [10:16:04<66:52:59, 17.31s/it]

 14%|█▎        | 2194/16104 [10:16:27<72:46:15, 18.83s/it]
[2024-04-06 01:50:23,945] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▎        | 2195/16104 [10:16:45<72:33:12, 18.78s/it]

 14%|█▎        | 2196/16104 [10:17:06<74:20:05, 19.24s/it]
{'loss': 0.5297, 'learning_rate': 1.9413024377535982e-06, 'rewards/chosen': -0.17772264778614044, 'rewards/rejected': -0.6682913899421692, 'rewards/accuracies': 0.5, 'rewards/margins': 0.49056869745254517, 'policy_logps/rejected': -298.04547119140625, 'policy_logps/chosen': -510.3734130859375, 'referece_logps/rejected': -291.3625793457031, 'referece_logps/chosen': -508.59619140625, 'logits/rejected': 0.18371771275997162, 'logits/chosen': 0.35335206985473633, 'epoch': 0.82}
[2024-04-06 01:51:16,145] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 14%|█▎        | 2198/16104 [10:17:39<70:15:37, 18.19s/it]
{'loss': 0.5756, 'learning_rate': 1.9411665754536206e-06, 'rewards/chosen': 0.1436329036951065, 'rewards/rejected': -0.14003565907478333, 'rewards/accuracies': 0.5, 'rewards/margins': 0.283668577671051, 'policy_logps/rejected': -636.7403564453125, 'policy_logps/chosen': -319.3896484375, 'referece_logps/rejected': -635.3399658203125, 'referece_logps/chosen': -320.82598876953125, 'logits/rejected': -1.029733419418335, 'logits/chosen': -0.8674150705337524, 'epoch': 0.82}


 14%|█▎        | 2200/16104 [10:18:11<65:43:07, 17.02s/it]

 14%|█▎        | 2201/16104 [10:18:29<66:56:53, 17.34s/it]
{'loss': 0.5888, 'learning_rate': 1.9409624964715276e-06, 'rewards/chosen': 0.21882398426532745, 'rewards/rejected': -0.45226380228996277, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6710878610610962, 'policy_logps/rejected': -681.9190673828125, 'policy_logps/chosen': -557.1774291992188, 'referece_logps/rejected': -677.396484375, 'referece_logps/chosen': -559.36572265625, 'logits/rejected': -0.6394796967506409, 'logits/chosen': -0.6175004839897156, 'epoch': 0.82}
[2024-04-06 01:52:46,351] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 14%|█▎        | 2203/16104 [10:19:00<62:17:21, 16.13s/it]

 14%|█▎        | 2204/16104 [10:19:22<68:40:26, 17.79s/it]

 14%|█▎        | 2205/16104 [10:19:33<60:32:09, 15.68s/it]

 14%|█▎        | 2206/16104 [10:19:53<65:45:45, 17.03s/it]
[2024-04-06 01:53:50,186] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▎        | 2207/16104 [10:20:07<62:03:39, 16.08s/it]
{'loss': 0.5161, 'learning_rate': 1.940553310864265e-06, 'rewards/chosen': 0.04936103895306587, 'rewards/rejected': -0.5066044330596924, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5559654831886292, 'policy_logps/rejected': -282.679931640625, 'policy_logps/chosen': -625.1622924804688, 'referece_logps/rejected': -277.6138916015625, 'referece_logps/chosen': -625.6559448242188, 'logits/rejected': -0.6051269769668579, 'logits/chosen': -0.5649428963661194, 'epoch': 0.82}


 14%|█▎        | 2209/16104 [10:20:38<62:52:13, 16.29s/it]

 14%|█▎        | 2210/16104 [10:20:55<62:33:34, 16.21s/it]

 14%|█▎        | 2211/16104 [10:21:16<68:59:41, 17.88s/it]
[2024-04-06 01:55:13,571] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▎        | 2212/16104 [10:21:27<61:14:33, 15.87s/it]

 14%|█▎        | 2213/16104 [10:21:44<61:53:46, 16.04s/it]

 14%|█▎        | 2214/16104 [10:22:04<66:44:55, 17.30s/it]
{'loss': 0.5987, 'learning_rate': 1.940074196556725e-06, 'rewards/chosen': -0.11910438537597656, 'rewards/rejected': -1.0065417289733887, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8874373435974121, 'policy_logps/rejected': -581.505859375, 'policy_logps/chosen': -631.1524658203125, 'referece_logps/rejected': -571.4404907226562, 'referece_logps/chosen': -629.96142578125, 'logits/rejected': 0.19594165682792664, 'logits/chosen': 0.28546738624572754, 'epoch': 0.82}
[2024-04-06 01:56:24,493] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 14%|█▍        | 2216/16104 [10:22:48<75:18:28, 19.52s/it]
[2024-04-06 01:56:45,166] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2217/16104 [10:23:06<73:11:51, 18.98s/it]

 14%|█▍        | 2218/16104 [10:23:18<66:04:37, 17.13s/it]

 14%|█▍        | 2219/16104 [10:23:31<60:49:34, 15.77s/it]

 14%|█▍        | 2220/16104 [10:23:45<58:32:28, 15.18s/it]

 14%|█▍        | 2221/16104 [10:23:57<55:02:29, 14.27s/it]

 14%|█▍        | 2222/16104 [10:24:09<52:25:33, 13.60s/it]

 14%|█▍        | 2223/16104 [10:24:29<59:20:19, 15.39s/it]
{'loss': 0.5384, 'learning_rate': 1.939455454587923e-06, 'rewards/chosen': 0.030108854174613953, 'rewards/rejected': -1.3387489318847656, 'rewards/accuracies': 0.875, 'rewards/margins': 1.368857741355896, 'policy_logps/rejected': -466.158203125, 'policy_logps/chosen': -475.072998046875, 'referece_logps/rejected': -452.77069091796875, 'referece_logps/chosen': -475.3741149902344, 'logits/rejected': -0.7001931071281433, 'logits/chosen': -0.7877455949783325, 'epoch': 0.83}


 14%|█▍        | 2225/16104 [10:25:02<60:49:36, 15.78s/it]

 14%|█▍        | 2226/16104 [10:25:20<63:45:34, 16.54s/it]

 14%|█▍        | 2227/16104 [10:25:32<58:06:44, 15.08s/it]

 14%|█▍        | 2228/16104 [10:25:49<60:48:31, 15.78s/it]

 14%|█▍        | 2229/16104 [10:26:07<62:50:30, 16.30s/it]

 14%|█▍        | 2230/16104 [10:26:20<59:30:37, 15.44s/it]

 14%|█▍        | 2231/16104 [10:26:41<65:53:12, 17.10s/it]

 14%|█▍        | 2232/16104 [10:26:56<63:47:49, 16.56s/it]

 14%|█▍        | 2233/16104 [10:27:07<57:01:20, 14.80s/it]

 14%|█▍        | 2234/16104 [10:27:26<62:20:18, 16.18s/it]
{'loss': 0.536, 'learning_rate': 1.9386950343182635e-06, 'rewards/chosen': 0.4456268548965454, 'rewards/rejected': -0.18848498165607452, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6341118216514587, 'policy_logps/rejected': -504.2080078125, 'policy_logps/chosen': -647.9185791015625, 'referece_logps/rejected': -502.3231506347656, 'referece_logps/chosen': -652.3749389648438, 'logits/rejected': -0.01882205903530121, 'logits/chosen': 0.22798268496990204, 'epoch': 0.83}


 14%|█▍        | 2236/16104 [10:27:53<56:58:41, 14.79s/it]

 14%|█▍        | 2237/16104 [10:28:10<60:20:27, 15.67s/it]

 14%|█▍        | 2238/16104 [10:28:28<62:49:06, 16.31s/it]

 14%|█▍        | 2239/16104 [10:28:47<65:59:37, 17.14s/it]

 14%|█▍        | 2240/16104 [10:28:58<59:00:57, 15.32s/it]

 14%|█▍        | 2241/16104 [10:29:10<55:16:54, 14.36s/it]

 14%|█▍        | 2242/16104 [10:29:25<55:57:54, 14.53s/it]

 14%|█▍        | 2243/16104 [10:29:46<62:34:27, 16.25s/it]
{'loss': 0.4502, 'learning_rate': 1.9380694546423047e-06, 'rewards/chosen': -0.3658079504966736, 'rewards/rejected': -1.0978997945785522, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7320919036865234, 'policy_logps/rejected': -334.3332214355469, 'policy_logps/chosen': -389.3553161621094, 'referece_logps/rejected': -323.354248046875, 'referece_logps/chosen': -385.69720458984375, 'logits/rejected': -0.4343918263912201, 'logits/chosen': -0.5760767459869385, 'epoch': 0.84}
[2024-04-06 02:04:01,085] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 14%|█▍        | 2245/16104 [10:30:17<60:59:14, 15.84s/it]
{'loss': 0.5415, 'learning_rate': 1.937930019451866e-06, 'rewards/chosen': 0.5412779450416565, 'rewards/rejected': -0.6398385167121887, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1811165809631348, 'policy_logps/rejected': -336.2745361328125, 'policy_logps/chosen': -446.00054931640625, 'referece_logps/rejected': -329.87615966796875, 'referece_logps/chosen': -451.41339111328125, 'logits/rejected': -0.2786083221435547, 'logits/chosen': -0.3772871494293213, 'epoch': 0.84}


 14%|█▍        | 2247/16104 [10:30:45<57:42:01, 14.99s/it]

 14%|█▍        | 2248/16104 [10:30:57<54:24:35, 14.14s/it]

 14%|█▍        | 2249/16104 [10:31:16<60:36:31, 15.75s/it]

 14%|█▍        | 2250/16104 [10:31:37<66:53:19, 17.38s/it]

 14%|█▍        | 2251/16104 [10:31:58<71:01:40, 18.46s/it]

 14%|█▍        | 2252/16104 [10:32:18<72:26:00, 18.82s/it]

 14%|█▍        | 2253/16104 [10:32:37<73:03:12, 18.99s/it]

 14%|█▍        | 2254/16104 [10:32:57<73:26:02, 19.09s/it]

 14%|█▍        | 2255/16104 [10:33:09<65:13:28, 16.95s/it]

 14%|█▍        | 2256/16104 [10:33:27<66:43:48, 17.35s/it]

 14%|█▍        | 2257/16104 [10:33:41<62:16:51, 16.19s/it]
{'loss': 0.5224, 'learning_rate': 1.9370902220614255e-06, 'rewards/chosen': 0.4896295368671417, 'rewards/rejected': -0.4493688941001892, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9389984607696533, 'policy_logps/rejected': -560.9312133789062, 'policy_logps/chosen': -512.809814453125, 'referece_logps/rejected': -556.4375610351562, 'referece_logps/chosen': -517.7061157226562, 'logits/rejected': -0.35861003398895264, 'logits/chosen': -0.3204992115497589, 'epoch': 0.84}


 14%|█▍        | 2259/16104 [10:34:15<63:05:43, 16.41s/it]

 14%|█▍        | 2260/16104 [10:34:29<60:28:13, 15.72s/it]

 14%|█▍        | 2261/16104 [10:34:39<54:39:28, 14.21s/it]
{'loss': 0.5648, 'learning_rate': 1.936809076332946e-06, 'rewards/chosen': 0.13660544157028198, 'rewards/rejected': -1.0660640001296997, 'rewards/accuracies': 0.875, 'rewards/margins': 1.202669382095337, 'policy_logps/rejected': -722.7302856445312, 'policy_logps/chosen': -403.04779052734375, 'referece_logps/rejected': -712.069580078125, 'referece_logps/chosen': -404.4138488769531, 'logits/rejected': 0.0771004855632782, 'logits/chosen': 0.29960453510284424, 'epoch': 0.84}


 14%|█▍        | 2263/16104 [10:35:03<50:19:21, 13.09s/it]

 14%|█▍        | 2264/16104 [10:35:21<56:10:17, 14.61s/it]

 14%|█▍        | 2265/16104 [10:35:39<60:12:52, 15.66s/it]

 14%|█▍        | 2266/16104 [10:36:00<65:39:26, 17.08s/it]

 14%|█▍        | 2267/16104 [10:36:14<62:04:31, 16.15s/it]

 14%|█▍        | 2268/16104 [10:36:27<58:37:16, 15.25s/it]
{'loss': 0.4322, 'learning_rate': 1.936315612437308e-06, 'rewards/chosen': 0.23301909863948822, 'rewards/rejected': -1.075553297996521, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3085724115371704, 'policy_logps/rejected': -410.6806335449219, 'policy_logps/chosen': -373.6497497558594, 'referece_logps/rejected': -399.92510986328125, 'referece_logps/chosen': -375.9799499511719, 'logits/rejected': -0.2822800576686859, 'logits/chosen': -0.27276256680488586, 'epoch': 0.85}


 14%|█▍        | 2270/16104 [10:36:58<57:25:18, 14.94s/it]

 14%|█▍        | 2271/16104 [10:37:20<65:34:45, 17.07s/it]

 14%|█▍        | 2272/16104 [10:37:31<59:05:07, 15.38s/it]

 14%|█▍        | 2273/16104 [10:37:52<65:18:52, 17.00s/it]
{'loss': 0.5191, 'learning_rate': 1.935962001900023e-06, 'rewards/chosen': -0.2040889859199524, 'rewards/rejected': -0.3814353942871094, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17734640836715698, 'policy_logps/rejected': -417.4307861328125, 'policy_logps/chosen': -405.633544921875, 'referece_logps/rejected': -413.616455078125, 'referece_logps/chosen': -403.5926513671875, 'logits/rejected': -0.2871016263961792, 'logits/chosen': -0.06301024556159973, 'epoch': 0.85}

 14%|█▍        | 2274/16104 [10:38:02<57:51:46, 15.06s/it]

 14%|█▍        | 2275/16104 [10:38:20<61:19:51, 15.97s/it]

 14%|█▍        | 2276/16104 [10:38:41<66:25:46, 17.29s/it]


 14%|█▍        | 2278/16104 [10:39:07<58:46:01, 15.30s/it]

 14%|█▍        | 2279/16104 [10:39:28<64:50:49, 16.89s/it]

 14%|█▍        | 2280/16104 [10:39:41<60:56:06, 15.87s/it]

 14%|█▍        | 2281/16104 [10:40:03<67:46:48, 17.65s/it]
{'loss': 0.5002, 'learning_rate': 1.9353942564003222e-06, 'rewards/chosen': -0.2092410922050476, 'rewards/rejected': -1.4339733123779297, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2247322797775269, 'policy_logps/rejected': -303.15570068359375, 'policy_logps/chosen': -351.26348876953125, 'referece_logps/rejected': -288.8159484863281, 'referece_logps/chosen': -349.1710510253906, 'logits/rejected': -0.1965293437242508, 'logits/chosen': -0.232096865773201, 'epoch': 0.85}

 14%|█▍        | 2282/16104 [10:40:23<70:21:55, 18.33s/it]


 14%|█▍        | 2284/16104 [10:41:04<74:34:03, 19.42s/it]
{'loss': 0.4608, 'learning_rate': 1.9351807274258663e-06, 'rewards/chosen': -0.6539543867111206, 'rewards/rejected': -1.15626060962677, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5023062229156494, 'policy_logps/rejected': -435.425537109375, 'policy_logps/chosen': -422.15472412109375, 'referece_logps/rejected': -423.86297607421875, 'referece_logps/chosen': -415.61517333984375, 'logits/rejected': -0.6552350521087646, 'logits/chosen': -0.6376183032989502, 'epoch': 0.85}
[2024-04-06 02:15:24,154] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 14%|█▍        | 2286/16104 [10:41:42<71:56:06, 18.74s/it]

 14%|█▍        | 2287/16104 [10:41:55<65:48:22, 17.15s/it]
{'loss': 0.4571, 'learning_rate': 1.934966857983857e-06, 'rewards/chosen': 0.33564871549606323, 'rewards/rejected': -0.33281269669532776, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6684613823890686, 'policy_logps/rejected': -475.0529479980469, 'policy_logps/chosen': -574.3896484375, 'referece_logps/rejected': -471.7248229980469, 'referece_logps/chosen': -577.74609375, 'logits/rejected': 0.15015213191509247, 'logits/chosen': 0.38162457942962646, 'epoch': 0.85}

 14%|█▍        | 2288/16104 [10:42:17<71:20:34, 18.59s/it]

 14%|█▍        | 2289/16104 [10:42:37<72:41:19, 18.94s/it]

 14%|█▍        | 2290/16104 [10:42:51<67:07:18, 17.49s/it]

 14%|█▍        | 2291/16104 [10:43:05<63:13:35, 16.48s/it]


 14%|█▍        | 2293/16104 [10:43:38<64:13:04, 16.74s/it]
[2024-04-06 02:17:35,425] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2294/16104 [10:43:56<65:20:53, 17.03s/it]
{'loss': 0.509, 'learning_rate': 1.9344665056829553e-06, 'rewards/chosen': 0.20348484814167023, 'rewards/rejected': -0.5289289355278015, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7324137687683105, 'policy_logps/rejected': -523.637451171875, 'policy_logps/chosen': -436.73797607421875, 'referece_logps/rejected': -518.34814453125, 'referece_logps/chosen': -438.7727966308594, 'logits/rejected': 0.6065317988395691, 'logits/chosen': 0.598901093006134, 'epoch': 0.85}

 14%|█▍        | 2295/16104 [10:44:15<67:22:11, 17.56s/it]

 14%|█▍        | 2296/16104 [10:44:33<68:10:47, 17.78s/it]


 14%|█▍        | 2298/16104 [10:45:04<62:32:14, 16.31s/it]

 14%|█▍        | 2299/16104 [10:45:17<58:36:10, 15.28s/it]
{'loss': 0.4876, 'learning_rate': 1.93410797709939e-06, 'rewards/chosen': -0.17427244782447815, 'rewards/rejected': -1.7679234743118286, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5936510562896729, 'policy_logps/rejected': -472.2255554199219, 'policy_logps/chosen': -369.5555419921875, 'referece_logps/rejected': -454.54632568359375, 'referece_logps/chosen': -367.81280517578125, 'logits/rejected': -0.4479036331176758, 'logits/chosen': -0.356272429227829, 'epoch': 0.86}


 14%|█▍        | 2301/16104 [10:45:48<58:02:56, 15.14s/it]

 14%|█▍        | 2302/16104 [10:46:09<64:37:42, 16.86s/it]
{'loss': 0.551, 'learning_rate': 1.933892406490027e-06, 'rewards/chosen': 0.0009428039193153381, 'rewards/rejected': -0.8100053668022156, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8109481334686279, 'policy_logps/rejected': -457.9803771972656, 'policy_logps/chosen': -509.93182373046875, 'referece_logps/rejected': -449.8802795410156, 'referece_logps/chosen': -509.9412841796875, 'logits/rejected': -0.45197343826293945, 'logits/chosen': -0.4305107593536377, 'epoch': 0.86}


 14%|█▍        | 2304/16104 [10:46:44<67:39:38, 17.65s/it]
{'loss': 0.5201, 'learning_rate': 1.933748503857536e-06, 'rewards/chosen': 0.21027205884456635, 'rewards/rejected': -1.260371208190918, 'rewards/accuracies': 0.875, 'rewards/margins': 1.470643401145935, 'policy_logps/rejected': -386.1119384765625, 'policy_logps/chosen': -396.9224853515625, 'referece_logps/rejected': -373.50823974609375, 'referece_logps/chosen': -399.0251770019531, 'logits/rejected': -0.24497929215431213, 'logits/chosen': -0.20691977441310883, 'epoch': 0.86}


 14%|█▍        | 2306/16104 [10:47:19<68:50:21, 17.96s/it]

 14%|█▍        | 2307/16104 [10:47:34<66:06:44, 17.25s/it]

 14%|█▍        | 2308/16104 [10:47:52<66:20:01, 17.31s/it]
{'loss': 0.4156, 'learning_rate': 1.9334602453543476e-06, 'rewards/chosen': -0.24389535188674927, 'rewards/rejected': -0.5179810523986816, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2740857005119324, 'policy_logps/rejected': -463.646484375, 'policy_logps/chosen': -475.1757507324219, 'referece_logps/rejected': -458.4666442871094, 'referece_logps/chosen': -472.7367858886719, 'logits/rejected': -0.5750251412391663, 'logits/chosen': -0.1869255006313324, 'epoch': 0.86}


 14%|█▍        | 2310/16104 [10:48:29<69:39:22, 18.18s/it]

 14%|█▍        | 2311/16104 [10:48:46<68:48:40, 17.96s/it]
{'loss': 0.5558, 'learning_rate': 1.933243654985366e-06, 'rewards/chosen': 0.22668398916721344, 'rewards/rejected': -0.6808178424835205, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9075018167495728, 'policy_logps/rejected': -347.5619201660156, 'policy_logps/chosen': -434.2533874511719, 'referece_logps/rejected': -340.75372314453125, 'referece_logps/chosen': -436.52020263671875, 'logits/rejected': 0.11436766386032104, 'logits/chosen': 0.14821608364582062, 'epoch': 0.86}

 14%|█▍        | 2312/16104 [10:49:07<72:00:45, 18.80s/it]

 14%|█▍        | 2313/16104 [10:49:19<64:40:35, 16.88s/it]

 14%|█▍        | 2314/16104 [10:49:31<58:50:00, 15.36s/it]


 14%|█▍        | 2316/16104 [10:50:10<67:36:12, 17.65s/it]

 14%|█▍        | 2317/16104 [10:50:27<66:04:21, 17.25s/it]

 14%|█▍        | 2318/16104 [10:50:44<65:55:54, 17.22s/it]
{'loss': 0.5527, 'learning_rate': 1.932736956296306e-06, 'rewards/chosen': 0.0221562497317791, 'rewards/rejected': -0.7827742099761963, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8049304485321045, 'policy_logps/rejected': -376.4037780761719, 'policy_logps/chosen': -386.31011962890625, 'referece_logps/rejected': -368.5760498046875, 'referece_logps/chosen': -386.5317077636719, 'logits/rejected': -0.43237972259521484, 'logits/chosen': -0.5520521998405457, 'epoch': 0.86}

 14%|█▍        | 2319/16104 [10:51:05<70:51:40, 18.51s/it]


 14%|█▍        | 2321/16104 [10:51:36<64:34:30, 16.87s/it]

 14%|█▍        | 2322/16104 [10:51:58<70:35:13, 18.44s/it]

 14%|█▍        | 2323/16104 [10:52:17<70:50:35, 18.51s/it]
{'loss': 0.5197, 'learning_rate': 1.9323738966765084e-06, 'rewards/chosen': -0.302381306886673, 'rewards/rejected': -1.4282467365264893, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1258654594421387, 'policy_logps/rejected': -565.69970703125, 'policy_logps/chosen': -504.141845703125, 'referece_logps/rejected': -551.4171752929688, 'referece_logps/chosen': -501.1180725097656, 'logits/rejected': 0.4036623239517212, 'logits/chosen': 0.4742274284362793, 'epoch': 0.87}


 14%|█▍        | 2325/16104 [10:52:51<65:32:23, 17.12s/it]
{'loss': 0.5982, 'learning_rate': 1.932228408794702e-06, 'rewards/chosen': 0.33878248929977417, 'rewards/rejected': -0.4291994273662567, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7679818868637085, 'policy_logps/rejected': -444.1809997558594, 'policy_logps/chosen': -697.8209228515625, 'referece_logps/rejected': -439.8890380859375, 'referece_logps/chosen': -701.208740234375, 'logits/rejected': -0.18784788250923157, 'logits/chosen': -0.12584540247917175, 'epoch': 0.87}


 14%|█▍        | 2327/16104 [10:53:22<64:48:11, 16.93s/it]

 14%|█▍        | 2328/16104 [10:53:37<62:24:06, 16.31s/it]

 14%|█▍        | 2329/16104 [10:54:01<70:37:41, 18.46s/it]
[2024-04-06 02:27:57,893] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2330/16104 [10:54:18<69:54:41, 18.27s/it]
[2024-04-06 02:28:15,731] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2331/16104 [10:54:31<63:27:41, 16.59s/it]

 14%|█▍        | 2332/16104 [10:54:47<62:44:51, 16.40s/it]
{'loss': 0.4503, 'learning_rate': 1.9317180134885657e-06, 'rewards/chosen': 0.23690204322338104, 'rewards/rejected': -0.4464399516582489, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6833419799804688, 'policy_logps/rejected': -444.5262145996094, 'policy_logps/chosen': -587.7987060546875, 'referece_logps/rejected': -440.0617980957031, 'referece_logps/chosen': -590.167724609375, 'logits/rejected': -0.6041602492332458, 'logits/chosen': -0.4485214352607727, 'epoch': 0.87}
[2024-04-06 02:29:05,263] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2333/16104 [10:55:08<67:54:37, 17.75s/it]

 14%|█▍        | 2334/16104 [10:55:22<63:14:40, 16.53s/it]

 14%|█▍        | 2335/16104 [10:55:40<65:23:23, 17.10s/it]


 15%|█▍        | 2337/16104 [10:56:15<66:46:45, 17.46s/it]

 15%|█▍        | 2338/16104 [10:56:30<64:12:35, 16.79s/it]
{'loss': 0.5777, 'learning_rate': 1.9312790618627918e-06, 'rewards/chosen': -0.045689016580581665, 'rewards/rejected': -0.9955378770828247, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9498487710952759, 'policy_logps/rejected': -460.3846130371094, 'policy_logps/chosen': -372.70819091796875, 'referece_logps/rejected': -450.42926025390625, 'referece_logps/chosen': -372.2513122558594, 'logits/rejected': -0.3195132613182068, 'logits/chosen': -0.22515538334846497, 'epoch': 0.87}


 15%|█▍        | 2340/16104 [10:56:57<58:30:44, 15.30s/it]
{'loss': 0.6026, 'learning_rate': 1.9311324432474133e-06, 'rewards/chosen': -0.2778192460536957, 'rewards/rejected': -1.3093699216842651, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0315507650375366, 'policy_logps/rejected': -537.9645385742188, 'policy_logps/chosen': -522.2883911132812, 'referece_logps/rejected': -524.8709106445312, 'referece_logps/chosen': -519.5101928710938, 'logits/rejected': -0.11066219955682755, 'logits/chosen': -0.12659701704978943, 'epoch': 0.87}

 15%|█▍        | 2341/16104 [10:57:08<53:13:39, 13.92s/it]


 15%|█▍        | 2343/16104 [10:57:47<63:50:22, 16.70s/it]
{'loss': 0.624, 'learning_rate': 1.930912232837001e-06, 'rewards/chosen': -0.09869284927845001, 'rewards/rejected': -0.1258724331855774, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0271795392036438, 'policy_logps/rejected': -369.3580322265625, 'policy_logps/chosen': -443.1971130371094, 'referece_logps/rejected': -368.09930419921875, 'referece_logps/chosen': -442.210205078125, 'logits/rejected': 0.05024357885122299, 'logits/chosen': -0.06964479386806488, 'epoch': 0.87}


 15%|█▍        | 2345/16104 [10:58:09<53:16:18, 13.94s/it]
{'loss': 0.5914, 'learning_rate': 1.930765237606473e-06, 'rewards/chosen': 0.3314233720302582, 'rewards/rejected': -0.36984121799468994, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7012646198272705, 'policy_logps/rejected': -490.69024658203125, 'policy_logps/chosen': -452.2693786621094, 'referece_logps/rejected': -486.9918518066406, 'referece_logps/chosen': -455.5836181640625, 'logits/rejected': 0.32058992981910706, 'logits/chosen': 0.42602553963661194, 'epoch': 0.87}


 15%|█▍        | 2347/16104 [10:58:31<47:05:10, 12.32s/it]
{'loss': 0.5652, 'learning_rate': 1.9306180917714864e-06, 'rewards/chosen': 0.14560239017009735, 'rewards/rejected': -0.6036356091499329, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7492380142211914, 'policy_logps/rejected': -398.91607666015625, 'policy_logps/chosen': -323.0780029296875, 'referece_logps/rejected': -392.87969970703125, 'referece_logps/chosen': -324.5340576171875, 'logits/rejected': -0.3004412055015564, 'logits/chosen': -0.1800389289855957, 'epoch': 0.87}


 15%|█▍        | 2349/16104 [10:59:05<57:40:29, 15.09s/it]
{'loss': 0.5814, 'learning_rate': 1.9304707953558517e-06, 'rewards/chosen': -0.05935516580939293, 'rewards/rejected': -0.9784579873085022, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9191028475761414, 'policy_logps/rejected': -427.21832275390625, 'policy_logps/chosen': -480.9917297363281, 'referece_logps/rejected': -417.4337463378906, 'referece_logps/chosen': -480.398193359375, 'logits/rejected': -0.4192413091659546, 'logits/chosen': -0.4698389768600464, 'epoch': 0.88}
[2024-04-06 02:33:23,219] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2350/16104 [10:59:26<64:27:20, 16.87s/it]


 15%|█▍        | 2352/16104 [11:00:03<66:05:24, 17.30s/it]
[2024-04-06 02:33:59,993] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.566, 'learning_rate': 1.9302495684458265e-06, 'rewards/chosen': -0.08296623080968857, 'rewards/rejected': -0.8996185064315796, 'rewards/accuracies': 0.75, 'rewards/margins': 0.816652238368988, 'policy_logps/rejected': -508.55133056640625, 'policy_logps/chosen': -496.1719970703125, 'referece_logps/rejected': -499.55517578125, 'referece_logps/chosen': -495.3423156738281, 'logits/rejected': -0.32930007576942444, 'logits/chosen': -0.2675461173057556, 'epoch': 0.88}
[2024-04-06 02:34:18,896] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2353/16104 [11:00:22<67:55:12, 17.78s/it]

 15%|█▍        | 2354/16104 [11:00:36<63:46:57, 16.70s/it]

 15%|█▍        | 2355/16104 [11:00:50<60:55:20, 15.95s/it]

 15%|█▍        | 2356/16104 [11:01:10<65:43:17, 17.21s/it]

 15%|█▍        | 2357/16104 [11:01:30<68:59:48, 18.07s/it]

 15%|█▍        | 2358/16104 [11:01:50<70:40:22, 18.51s/it]

 15%|█▍        | 2359/16104 [11:02:10<72:34:33, 19.01s/it]


 15%|█▍        | 2361/16104 [11:02:51<75:36:53, 19.81s/it]
{'loss': 0.5311, 'learning_rate': 1.9295838560048137e-06, 'rewards/chosen': -0.19263362884521484, 'rewards/rejected': -0.9678030610084534, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7751693725585938, 'policy_logps/rejected': -369.88134765625, 'policy_logps/chosen': -228.32244873046875, 'referece_logps/rejected': -360.2033386230469, 'referece_logps/chosen': -226.39610290527344, 'logits/rejected': -0.10785559564828873, 'logits/chosen': -0.07962025701999664, 'epoch': 0.88}


 15%|█▍        | 2363/16104 [11:03:29<73:51:13, 19.35s/it]
{'loss': 0.5507, 'learning_rate': 1.929435506193345e-06, 'rewards/chosen': -0.613650918006897, 'rewards/rejected': -1.041341781616211, 'rewards/accuracies': 0.625, 'rewards/margins': 0.42769092321395874, 'policy_logps/rejected': -522.1055297851562, 'policy_logps/chosen': -473.5015563964844, 'referece_logps/rejected': -511.692138671875, 'referece_logps/chosen': -467.36505126953125, 'logits/rejected': -0.1670273244380951, 'logits/chosen': -0.21028301119804382, 'epoch': 0.88}

 15%|█▍        | 2364/16104 [11:03:49<75:10:46, 19.70s/it]


 15%|█▍        | 2366/16104 [11:04:11<58:11:13, 15.25s/it]
{'loss': 0.5215, 'learning_rate': 1.9292126995037166e-06, 'rewards/chosen': -0.10560674965381622, 'rewards/rejected': -0.9601562023162842, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8545494079589844, 'policy_logps/rejected': -220.3001708984375, 'policy_logps/chosen': -255.16448974609375, 'referece_logps/rejected': -210.6986083984375, 'referece_logps/chosen': -254.10841369628906, 'logits/rejected': -0.5940679311752319, 'logits/chosen': -0.5876133441925049, 'epoch': 0.88}

 15%|█▍        | 2367/16104 [11:04:22<53:24:18, 14.00s/it]


 15%|█▍        | 2369/16104 [11:04:47<50:11:48, 13.16s/it]
{'loss': 0.5307, 'learning_rate': 1.928989554519291e-06, 'rewards/chosen': 0.1518438160419464, 'rewards/rejected': -0.4160648584365845, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5679086446762085, 'policy_logps/rejected': -470.4736328125, 'policy_logps/chosen': -400.9268798828125, 'referece_logps/rejected': -466.31298828125, 'referece_logps/chosen': -402.4453125, 'logits/rejected': 0.1966944932937622, 'logits/chosen': 0.28705379366874695, 'epoch': 0.88}

 15%|█▍        | 2370/16104 [11:05:00<50:22:25, 13.20s/it]

 15%|█▍        | 2371/16104 [11:05:19<57:03:30, 14.96s/it]

 15%|█▍        | 2372/16104 [11:05:41<64:31:46, 16.92s/it]

 15%|█▍        | 2373/16104 [11:05:57<63:07:05, 16.55s/it]

 15%|█▍        | 2374/16104 [11:06:15<65:07:25, 17.08s/it]
[2024-04-06 02:40:34,264] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2375/16104 [11:06:37<70:47:34, 18.56s/it]
[2024-04-06 02:40:47,781] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 15%|█▍        | 2377/16104 [11:07:01<58:04:59, 15.23s/it]
{'loss': 0.5491, 'learning_rate': 1.9283928479600225e-06, 'rewards/chosen': 0.3480902314186096, 'rewards/rejected': -0.01592903956770897, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3640192449092865, 'policy_logps/rejected': -411.37713623046875, 'policy_logps/chosen': -472.0437316894531, 'referece_logps/rejected': -411.2178039550781, 'referece_logps/chosen': -475.5246276855469, 'logits/rejected': 0.5999834537506104, 'logits/chosen': 0.6130275130271912, 'epoch': 0.89}

 15%|█▍        | 2378/16104 [11:07:18<59:42:59, 15.66s/it]

 15%|█▍        | 2379/16104 [11:07:29<54:08:15, 14.20s/it]

 15%|█▍        | 2380/16104 [11:07:40<50:10:11, 13.16s/it]

 15%|█▍        | 2381/16104 [11:07:53<49:58:01, 13.11s/it]

 15%|█▍        | 2382/16104 [11:08:15<60:11:30, 15.79s/it]
[2024-04-06 02:42:29,486] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2383/16104 [11:08:32<62:07:24, 16.30s/it]

 15%|█▍        | 2384/16104 [11:08:50<64:18:01, 16.87s/it]


 15%|█▍        | 2386/16104 [11:09:20<59:55:16, 15.73s/it]
{'loss': 0.5266, 'learning_rate': 1.927718680189861e-06, 'rewards/chosen': -0.34057995676994324, 'rewards/rejected': -1.7567020654678345, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4161221981048584, 'policy_logps/rejected': -404.8304138183594, 'policy_logps/chosen': -501.1165771484375, 'referece_logps/rejected': -387.263427734375, 'referece_logps/chosen': -497.7107849121094, 'logits/rejected': -0.5881781578063965, 'logits/chosen': -0.8017382025718689, 'epoch': 0.89}

 15%|█▍        | 2387/16104 [11:09:31<54:56:41, 14.42s/it]

 15%|█▍        | 2388/16104 [11:09:52<62:32:09, 16.41s/it]

 15%|█▍        | 2389/16104 [11:10:11<64:44:33, 16.99s/it]


 15%|█▍        | 2391/16104 [11:10:52<71:39:23, 18.81s/it]

 15%|█▍        | 2392/16104 [11:11:10<71:08:52, 18.68s/it]
{'loss': 0.4562, 'learning_rate': 1.9272675461190166e-06, 'rewards/chosen': -0.48534703254699707, 'rewards/rejected': -1.1216652393341064, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6363182067871094, 'policy_logps/rejected': -319.0230407714844, 'policy_logps/chosen': -386.0934753417969, 'referece_logps/rejected': -307.8063659667969, 'referece_logps/chosen': -381.2399597167969, 'logits/rejected': -1.022010087966919, 'logits/chosen': -0.8124378323554993, 'epoch': 0.89}

 15%|█▍        | 2393/16104 [11:11:29<71:26:00, 18.76s/it]

 15%|█▍        | 2394/16104 [11:11:47<69:57:17, 18.37s/it]


 15%|█▍        | 2396/16104 [11:12:24<71:35:14, 18.80s/it]
[2024-04-06 02:46:21,536] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3993, 'learning_rate': 1.926966039838702e-06, 'rewards/chosen': -0.45609110593795776, 'rewards/rejected': -1.8113975524902344, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3553063869476318, 'policy_logps/rejected': -362.2779846191406, 'policy_logps/chosen': -478.5889892578125, 'referece_logps/rejected': -344.1640319824219, 'referece_logps/chosen': -474.0281066894531, 'logits/rejected': 0.6156939268112183, 'logits/chosen': 0.6254791021347046, 'epoch': 0.89}

 15%|█▍        | 2397/16104 [11:12:45<73:49:26, 19.39s/it]

 15%|█▍        | 2398/16104 [11:13:06<75:08:07, 19.74s/it]


 15%|█▍        | 2400/16104 [11:13:38<69:37:02, 18.29s/it]
[2024-04-06 02:47:35,447] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.482, 'learning_rate': 1.9266639335995304e-06, 'rewards/chosen': 0.06424999237060547, 'rewards/rejected': -1.1670968532562256, 'rewards/accuracies': 0.75, 'rewards/margins': 1.231346845626831, 'policy_logps/rejected': -399.3175048828125, 'policy_logps/chosen': -643.0498657226562, 'referece_logps/rejected': -387.6465148925781, 'referece_logps/chosen': -643.6923828125, 'logits/rejected': -0.022895842790603638, 'logits/chosen': 0.03312155604362488, 'epoch': 0.89}

 15%|█▍        | 2401/16104 [11:13:57<69:51:10, 18.35s/it]

 15%|█▍        | 2402/16104 [11:14:11<65:39:03, 17.25s/it]

 15%|█▍        | 2403/16104 [11:14:29<65:44:32, 17.27s/it]

 15%|█▍        | 2404/16104 [11:14:45<64:11:04, 16.87s/it]

 15%|█▍        | 2405/16104 [11:14:57<59:08:07, 15.54s/it]
[2024-04-06 02:49:17,178] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2406/16104 [11:15:20<67:29:17, 17.74s/it]

 15%|█▍        | 2407/16104 [11:15:37<67:10:30, 17.66s/it]

 15%|█▍        | 2408/16104 [11:15:53<64:59:27, 17.08s/it]

 15%|█▍        | 2409/16104 [11:16:05<59:13:49, 15.57s/it]

 15%|█▍        | 2410/16104 [11:16:27<66:03:29, 17.37s/it]


 15%|█▍        | 2412/16104 [11:17:00<64:48:39, 17.04s/it]
{'loss': 0.5755, 'learning_rate': 1.9257540170861308e-06, 'rewards/chosen': -0.5475174784660339, 'rewards/rejected': -0.7257139086723328, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17819643020629883, 'policy_logps/rejected': -340.16180419921875, 'policy_logps/chosen': -354.199951171875, 'referece_logps/rejected': -332.9046630859375, 'referece_logps/chosen': -348.72479248046875, 'logits/rejected': 0.017824634909629822, 'logits/chosen': -0.024517722427845, 'epoch': 0.9}

 15%|█▍        | 2413/16104 [11:17:21<68:49:47, 18.10s/it]

 15%|█▍        | 2414/16104 [11:17:41<71:25:46, 18.78s/it]


 15%|█▌        | 2416/16104 [11:18:11<64:15:45, 16.90s/it]
{'loss': 0.5021, 'learning_rate': 1.925449512970729e-06, 'rewards/chosen': 0.10307179391384125, 'rewards/rejected': -1.2244415283203125, 'rewards/accuracies': 0.875, 'rewards/margins': 1.327513337135315, 'policy_logps/rejected': -371.93914794921875, 'policy_logps/chosen': -431.0911865234375, 'referece_logps/rejected': -359.69476318359375, 'referece_logps/chosen': -432.1219177246094, 'logits/rejected': 0.0068471189588308334, 'logits/chosen': 0.050298742949962616, 'epoch': 0.9}

 15%|█▌        | 2417/16104 [11:18:32<69:28:14, 18.27s/it]

 15%|█▌        | 2418/16104 [11:18:47<65:59:30, 17.36s/it]

 15%|█▌        | 2419/16104 [11:19:02<63:08:26, 16.61s/it]

 15%|█▌        | 2420/16104 [11:19:15<59:26:10, 15.64s/it]

 15%|█▌        | 2421/16104 [11:19:30<58:00:33, 15.26s/it]

 15%|█▌        | 2422/16104 [11:19:43<55:43:52, 14.66s/it]


 15%|█▌        | 2424/16104 [11:20:17<58:12:47, 15.32s/it]
{'loss': 0.6739, 'learning_rate': 1.9248387080054435e-06, 'rewards/chosen': -0.05613423511385918, 'rewards/rejected': -0.49958547949790955, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4434511959552765, 'policy_logps/rejected': -262.9551696777344, 'policy_logps/chosen': -280.9206237792969, 'referece_logps/rejected': -257.9593200683594, 'referece_logps/chosen': -280.3592834472656, 'logits/rejected': -0.5568620562553406, 'logits/chosen': -0.5843459963798523, 'epoch': 0.9}


 15%|█▌        | 2426/16104 [11:20:47<56:55:47, 14.98s/it]
{'loss': 0.6028, 'learning_rate': 1.9246856325885337e-06, 'rewards/chosen': -0.349382221698761, 'rewards/rejected': -0.3682518005371094, 'rewards/accuracies': 0.5, 'rewards/margins': 0.018869608640670776, 'policy_logps/rejected': -425.376953125, 'policy_logps/chosen': -338.71661376953125, 'referece_logps/rejected': -421.6944885253906, 'referece_logps/chosen': -335.2227783203125, 'logits/rejected': 0.09508326649665833, 'logits/chosen': 0.23433515429496765, 'epoch': 0.9}


 15%|█▌        | 2428/16104 [11:21:21<59:08:42, 15.57s/it]
{'loss': 0.5875, 'learning_rate': 1.92453240755089e-06, 'rewards/chosen': -0.5844709277153015, 'rewards/rejected': -1.3388218879699707, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7543510794639587, 'policy_logps/rejected': -512.8214111328125, 'policy_logps/chosen': -442.38226318359375, 'referece_logps/rejected': -499.4332275390625, 'referece_logps/chosen': -436.5375671386719, 'logits/rejected': -1.107086420059204, 'logits/chosen': -1.0712265968322754, 'epoch': 0.9}


 15%|█▌        | 2430/16104 [11:21:53<61:41:52, 16.24s/it]
[2024-04-06 02:55:49,899] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4908, 'learning_rate': 1.9243790329173052e-06, 'rewards/chosen': -0.04689083993434906, 'rewards/rejected': -0.6130309700965881, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5661401748657227, 'policy_logps/rejected': -472.4374084472656, 'policy_logps/chosen': -518.8524169921875, 'referece_logps/rejected': -466.3070983886719, 'referece_logps/chosen': -518.3834838867188, 'logits/rejected': -0.04859637841582298, 'logits/chosen': 0.04353421553969383, 'epoch': 0.91}
[2024-04-06 02:56:05,536] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2431/16104 [11:22:08<61:00:09, 16.06s/it]

 15%|█▌        | 2432/16104 [11:22:28<64:57:08, 17.10s/it]

 15%|█▌        | 2433/16104 [11:22:42<62:04:21, 16.35s/it]

 15%|█▌        | 2434/16104 [11:23:02<65:54:07, 17.36s/it]

 15%|█▌        | 2435/16104 [11:23:17<63:36:26, 16.75s/it]


 15%|█▌        | 2437/16104 [11:23:49<62:36:52, 16.49s/it]
{'loss': 0.6105, 'learning_rate': 1.923841043990235e-06, 'rewards/chosen': -0.06907766312360764, 'rewards/rejected': -0.3038698434829712, 'rewards/accuracies': 0.625, 'rewards/margins': 0.23479215800762177, 'policy_logps/rejected': -405.4239501953125, 'policy_logps/chosen': -491.004150390625, 'referece_logps/rejected': -402.3852844238281, 'referece_logps/chosen': -490.3133850097656, 'logits/rejected': -0.5410606861114502, 'logits/chosen': -0.5545089840888977, 'epoch': 0.91}

 15%|█▌        | 2438/16104 [11:24:10<68:33:29, 18.06s/it]


 15%|█▌        | 2440/16104 [11:24:51<72:30:08, 19.10s/it]

 15%|█▌        | 2441/16104 [11:25:07<69:00:00, 18.18s/it]
{'loss': 0.4452, 'learning_rate': 1.923532799515368e-06, 'rewards/chosen': 0.2842595875263214, 'rewards/rejected': -2.1098215579986572, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3940813541412354, 'policy_logps/rejected': -543.0651245117188, 'policy_logps/chosen': -402.67108154296875, 'referece_logps/rejected': -521.9668579101562, 'referece_logps/chosen': -405.5136413574219, 'logits/rejected': -0.34338241815567017, 'logits/chosen': -0.12836642563343048, 'epoch': 0.91}
[2024-04-06 02:59:21,402] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 15%|█▌        | 2443/16104 [11:25:45<71:00:11, 18.71s/it]
{'loss': 0.5627, 'learning_rate': 1.9233784531141624e-06, 'rewards/chosen': -0.6765665411949158, 'rewards/rejected': -1.0390849113464355, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3625184893608093, 'policy_logps/rejected': -332.1183166503906, 'policy_logps/chosen': -291.47161865234375, 'referece_logps/rejected': -321.7274475097656, 'referece_logps/chosen': -284.7059326171875, 'logits/rejected': -0.8835256695747375, 'logits/chosen': -0.7623900771141052, 'epoch': 0.91}

 15%|█▌        | 2444/16104 [11:26:04<71:24:08, 18.82s/it]


 15%|█▌        | 2446/16104 [11:26:31<60:51:57, 16.04s/it]
{'loss': 0.6254, 'learning_rate': 1.9231466533778724e-06, 'rewards/chosen': -0.15703411400318146, 'rewards/rejected': -0.5437120795249939, 'rewards/accuracies': 0.5, 'rewards/margins': 0.38667795062065125, 'policy_logps/rejected': -403.79339599609375, 'policy_logps/chosen': -299.2231140136719, 'referece_logps/rejected': -398.3562927246094, 'referece_logps/chosen': -297.6528015136719, 'logits/rejected': -0.7826271653175354, 'logits/chosen': -0.7739266157150269, 'epoch': 0.91}

 15%|█▌        | 2447/16104 [11:26:42<55:03:47, 14.51s/it]

 15%|█▌        | 2448/16104 [11:26:56<53:51:01, 14.20s/it]

 15%|█▌        | 2449/16104 [11:27:16<60:47:46, 16.03s/it]

 15%|█▌        | 2450/16104 [11:27:32<60:44:09, 16.01s/it]

 15%|█▌        | 2451/16104 [11:27:52<65:47:21, 17.35s/it]

 15%|█▌        | 2452/16104 [11:28:12<68:10:07, 17.98s/it]

 15%|█▌        | 2453/16104 [11:28:28<66:37:10, 17.57s/it]

 15%|█▌        | 2454/16104 [11:28:44<64:05:35, 16.90s/it]

 15%|█▌        | 2455/16104 [11:29:02<65:16:03, 17.21s/it]


 15%|█▌        | 2457/16104 [11:29:29<59:34:02, 15.71s/it]
{'loss': 0.5522, 'learning_rate': 1.9222938462490846e-06, 'rewards/chosen': -0.2704164683818817, 'rewards/rejected': -1.2814531326293945, 'rewards/accuracies': 0.875, 'rewards/margins': 1.01103675365448, 'policy_logps/rejected': -321.6845703125, 'policy_logps/chosen': -313.869873046875, 'referece_logps/rejected': -308.8700256347656, 'referece_logps/chosen': -311.1656494140625, 'logits/rejected': -0.48694533109664917, 'logits/chosen': -0.4527038633823395, 'epoch': 0.92}

 15%|█▌        | 2458/16104 [11:29:40<53:52:17, 14.21s/it]

 15%|█▌        | 2459/16104 [11:29:58<57:53:54, 15.28s/it]

 15%|█▌        | 2460/16104 [11:30:08<52:45:36, 13.92s/it]

 15%|█▌        | 2461/16104 [11:30:29<60:19:15, 15.92s/it]
{'loss': 0.5953, 'learning_rate': 1.9219826150931682e-06, 'rewards/chosen': -0.006814196705818176, 'rewards/rejected': -0.7991687655448914, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7923545837402344, 'policy_logps/rejected': -448.5368957519531, 'policy_logps/chosen': -447.7637939453125, 'referece_logps/rejected': -440.54522705078125, 'referece_logps/chosen': -447.6956481933594, 'logits/rejected': 0.6081774234771729, 'logits/chosen': 0.7118216753005981, 'epoch': 0.92}


 15%|█▌        | 2463/16104 [11:31:10<68:13:38, 18.01s/it]
{'loss': 0.5051, 'learning_rate': 1.921826775727564e-06, 'rewards/chosen': 0.32713568210601807, 'rewards/rejected': -0.3886757791042328, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7158114314079285, 'policy_logps/rejected': -402.3253173828125, 'policy_logps/chosen': -418.60430908203125, 'referece_logps/rejected': -398.4385986328125, 'referece_logps/chosen': -421.87567138671875, 'logits/rejected': 0.46319204568862915, 'logits/chosen': 0.4897967278957367, 'epoch': 0.92}


 15%|█▌        | 2465/16104 [11:31:43<65:33:36, 17.30s/it]

 15%|█▌        | 2466/16104 [11:32:03<68:10:18, 18.00s/it]

 15%|█▌        | 2467/16104 [11:32:21<68:34:29, 18.10s/it]
{'loss': 0.5491, 'learning_rate': 1.9215146495471433e-06, 'rewards/chosen': -0.11624106764793396, 'rewards/rejected': -1.0685999393463135, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9523587822914124, 'policy_logps/rejected': -445.1622619628906, 'policy_logps/chosen': -440.5397033691406, 'referece_logps/rejected': -434.47625732421875, 'referece_logps/chosen': -439.3773193359375, 'logits/rejected': -0.03138244152069092, 'logits/chosen': 0.03315797448158264, 'epoch': 0.92}

 15%|█▌        | 2468/16104 [11:32:40<69:32:40, 18.36s/it]

 15%|█▌        | 2469/16104 [11:32:53<62:37:21, 16.53s/it]

 15%|█▌        | 2470/16104 [11:33:11<64:19:27, 16.98s/it]

 15%|█▌        | 2471/16104 [11:33:30<67:20:48, 17.78s/it]

 15%|█▌        | 2472/16104 [11:33:41<59:16:47, 15.65s/it]

 15%|█▌        | 2473/16104 [11:33:57<59:07:59, 15.62s/it]

 15%|█▌        | 2474/16104 [11:34:13<59:55:30, 15.83s/it]

 15%|█▌        | 2475/16104 [11:34:27<57:32:34, 15.20s/it]


 15%|█▌        | 2477/16104 [11:35:01<60:14:52, 15.92s/it]
{'loss': 0.52, 'learning_rate': 1.9207317251552445e-06, 'rewards/chosen': -0.2890002429485321, 'rewards/rejected': -0.8694899678230286, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5804896950721741, 'policy_logps/rejected': -418.2090148925781, 'policy_logps/chosen': -404.393798828125, 'referece_logps/rejected': -409.51416015625, 'referece_logps/chosen': -401.50384521484375, 'logits/rejected': 0.31716230511665344, 'logits/chosen': 0.20932242274284363, 'epoch': 0.92}


 15%|█▌        | 2479/16104 [11:35:38<65:02:16, 17.18s/it]

 15%|█▌        | 2480/16104 [11:35:53<63:11:19, 16.70s/it]

 15%|█▌        | 2481/16104 [11:36:14<67:28:14, 17.83s/it]
{'loss': 0.5756, 'learning_rate': 1.920417512354214e-06, 'rewards/chosen': -0.33426299691200256, 'rewards/rejected': -0.5817394256591797, 'rewards/accuracies': 0.375, 'rewards/margins': 0.24747638404369354, 'policy_logps/rejected': -438.2747802734375, 'policy_logps/chosen': -355.2067565917969, 'referece_logps/rejected': -432.4573669433594, 'referece_logps/chosen': -351.8641052246094, 'logits/rejected': 1.0404785871505737, 'logits/chosen': 1.206438422203064, 'epoch': 0.92}

 15%|█▌        | 2482/16104 [11:36:27<62:11:29, 16.44s/it]

 15%|█▌        | 2483/16104 [11:36:46<65:18:07, 17.26s/it]

 15%|█▌        | 2484/16104 [11:36:59<60:14:36, 15.92s/it]

 15%|█▌        | 2485/16104 [11:37:10<54:28:06, 14.40s/it]

 15%|█▌        | 2486/16104 [11:37:29<59:42:37, 15.78s/it]

 15%|█▌        | 2487/16104 [11:37:49<64:55:57, 17.17s/it]

 15%|█▌        | 2488/16104 [11:38:10<68:48:33, 18.19s/it]

 15%|█▌        | 2489/16104 [11:38:24<63:39:37, 16.83s/it]

 15%|█▌        | 2490/16104 [11:38:38<61:19:26, 16.22s/it]


 15%|█▌        | 2492/16104 [11:39:04<54:31:32, 14.42s/it]

 15%|█▌        | 2493/16104 [11:39:22<59:14:26, 15.67s/it]

 15%|█▌        | 2494/16104 [11:39:37<58:09:18, 15.38s/it]

 15%|█▌        | 2495/16104 [11:39:48<53:27:57, 14.14s/it]

 15%|█▌        | 2496/16104 [11:40:09<61:07:22, 16.17s/it]

 16%|█▌        | 2497/16104 [11:40:27<62:45:12, 16.60s/it]

 16%|█▌        | 2498/16104 [11:40:40<59:01:33, 15.62s/it]

 16%|█▌        | 2499/16104 [11:41:02<65:47:12, 17.41s/it]
[2024-04-06 03:14:59,144] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2500/16104 [11:41:16<61:54:46, 16.38s/it]
[2024-04-06 03:15:13,139] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2501/16104 [11:41:51<83:24:33, 22.07s/it]
[2024-04-06 03:15:48,489] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2502/16104 [11:42:14<83:59:54, 22.23s/it]
[2024-04-06 03:16:11,090] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2503/16104 [11:42:36<83:47:30, 22.18s/it]

 16%|█▌        | 2504/16104 [11:42:52<76:34:36, 20.27s/it]

 16%|█▌        | 2505/16104 [11:43:10<74:07:38, 19.62s/it]
[2024-04-06 03:17:07,075] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2506/16104 [11:43:30<74:54:53, 19.83s/it]

 16%|█▌        | 2507/16104 [11:43:49<73:47:51, 19.54s/it]

 16%|█▌        | 2508/16104 [11:44:06<71:05:30, 18.82s/it]

 16%|█▌        | 2509/16104 [11:44:27<73:31:39, 19.47s/it]

 16%|█▌        | 2510/16104 [11:44:39<65:13:46, 17.27s/it]

 16%|█▌        | 2511/16104 [11:44:53<61:26:14, 16.27s/it]

 16%|█▌        | 2512/16104 [11:45:12<63:46:24, 16.89s/it]

 16%|█▌        | 2513/16104 [11:45:26<60:30:36, 16.03s/it]

 16%|█▌        | 2514/16104 [11:45:41<60:06:41, 15.92s/it]

 16%|█▌        | 2515/16104 [11:45:57<59:51:01, 15.86s/it]

 16%|█▌        | 2516/16104 [11:46:09<56:04:50, 14.86s/it]

 16%|█▌        | 2517/16104 [11:46:29<61:02:50, 16.18s/it]

 16%|█▌        | 2518/16104 [11:46:52<68:40:02, 18.20s/it]

 16%|█▌        | 2519/16104 [11:47:04<62:35:38, 16.59s/it]

 16%|█▌        | 2520/16104 [11:47:24<65:38:50, 17.40s/it]

 16%|█▌        | 2521/16104 [11:47:36<60:01:14, 15.91s/it]

 16%|█▌        | 2522/16104 [11:47:53<61:07:28, 16.20s/it]

 16%|█▌        | 2523/16104 [11:48:16<69:05:02, 18.31s/it]

 16%|█▌        | 2524/16104 [11:48:30<63:55:31, 16.95s/it]

 16%|█▌        | 2525/16104 [11:48:51<67:54:36, 18.00s/it]

 16%|█▌        | 2526/16104 [11:49:10<69:53:46, 18.53s/it]

 16%|█▌        | 2527/16104 [11:49:32<73:03:42, 19.37s/it]

 16%|█▌        | 2528/16104 [11:49:44<65:10:15, 17.28s/it]

 16%|█▌        | 2529/16104 [11:50:00<64:09:52, 17.02s/it]

 16%|█▌        | 2530/16104 [11:50:20<66:53:54, 17.74s/it]

 16%|█▌        | 2531/16104 [11:50:31<59:25:27, 15.76s/it]

 16%|█▌        | 2532/16104 [11:50:49<62:05:46, 16.47s/it]

 16%|█▌        | 2533/16104 [11:51:02<57:47:16, 15.33s/it]

 16%|█▌        | 2534/16104 [11:51:12<52:31:52, 13.94s/it]

 16%|█▌        | 2535/16104 [11:51:35<62:09:42, 16.49s/it]

 16%|█▌        | 2536/16104 [11:51:54<65:33:10, 17.39s/it]

 16%|█▌        | 2537/16104 [11:52:13<67:24:56, 17.89s/it]

 16%|█▌        | 2538/16104 [11:52:31<66:40:11, 17.69s/it]

 16%|█▌        | 2539/16104 [11:52:47<65:18:30, 17.33s/it]

 16%|█▌        | 2540/16104 [11:53:01<61:29:57, 16.32s/it]

 16%|█▌        | 2541/16104 [11:53:12<55:13:31, 14.66s/it]

 16%|█▌        | 2542/16104 [11:53:28<57:11:34, 15.18s/it]

 16%|█▌        | 2543/16104 [11:53:45<58:36:30, 15.56s/it]

 16%|█▌        | 2544/16104 [11:54:06<65:05:44, 17.28s/it]
[2024-04-06 03:28:03,351] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2545/16104 [11:54:25<67:22:28, 17.89s/it]
[2024-04-06 03:28:22,656] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2546/16104 [11:54:39<62:53:54, 16.70s/it]

 16%|█▌        | 2547/16104 [11:55:00<67:49:30, 18.01s/it]
[2024-04-06 03:28:57,653] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2548/16104 [11:55:20<69:27:43, 18.45s/it]

 16%|█▌        | 2549/16104 [11:55:31<61:25:36, 16.31s/it]

 16%|█▌        | 2550/16104 [11:55:51<65:00:06, 17.26s/it]

 16%|█▌        | 2551/16104 [11:56:10<67:33:22, 17.94s/it]

 16%|█▌        | 2552/16104 [11:56:28<66:55:18, 17.78s/it]

 16%|█▌        | 2553/16104 [11:56:47<68:56:18, 18.31s/it]

 16%|█▌        | 2554/16104 [11:57:05<68:20:13, 18.16s/it]
{'loss': 0.4662, 'learning_rate': 1.9145786940879676e-06, 'rewards/chosen': -0.7330961227416992, 'rewards/rejected': -1.7654956579208374, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0323994159698486, 'policy_logps/rejected': -453.23529052734375, 'policy_logps/chosen': -498.232666015625, 'referece_logps/rejected': -435.580322265625, 'referece_logps/chosen': -490.9017333984375, 'logits/rejected': -0.20807567238807678, 'logits/chosen': -0.07848288863897324, 'epoch': 0.95}


 16%|█▌        | 2556/16104 [11:57:44<70:10:25, 18.65s/it]

 16%|█▌        | 2557/16104 [11:58:02<70:16:10, 18.67s/it]

 16%|█▌        | 2558/16104 [11:58:21<70:18:00, 18.68s/it]

 16%|█▌        | 2559/16104 [11:58:40<70:16:02, 18.68s/it]

 16%|█▌        | 2560/16104 [11:59:00<72:26:07, 19.25s/it]

 16%|█▌        | 2561/16104 [11:59:20<72:52:34, 19.37s/it]

 16%|█▌        | 2562/16104 [11:59:40<73:24:50, 19.52s/it]

 16%|█▌        | 2563/16104 [12:00:00<74:15:38, 19.74s/it]

 16%|█▌        | 2564/16104 [12:00:18<71:47:25, 19.09s/it]

 16%|█▌        | 2565/16104 [12:00:29<62:36:39, 16.65s/it]

 16%|█▌        | 2566/16104 [12:00:47<65:11:21, 17.33s/it]

 16%|█▌        | 2567/16104 [12:01:09<69:33:08, 18.50s/it]
{'loss': 0.5417, 'learning_rate': 1.9135181871122153e-06, 'rewards/chosen': 0.007786387577652931, 'rewards/rejected': -0.8942790627479553, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9020655155181885, 'policy_logps/rejected': -358.5774841308594, 'policy_logps/chosen': -430.49639892578125, 'referece_logps/rejected': -349.6346435546875, 'referece_logps/chosen': -430.57421875, 'logits/rejected': -0.3663286566734314, 'logits/chosen': -0.35446566343307495, 'epoch': 0.96}


 16%|█▌        | 2569/16104 [12:01:46<70:06:03, 18.65s/it]

 16%|█▌        | 2570/16104 [12:02:09<75:01:50, 19.96s/it]
[2024-04-06 03:36:06,557] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2571/16104 [12:02:30<75:27:02, 20.07s/it]

 16%|█▌        | 2572/16104 [12:02:41<65:24:29, 17.40s/it]

 16%|█▌        | 2573/16104 [12:02:56<63:06:20, 16.79s/it]

 16%|█▌        | 2574/16104 [12:03:09<58:38:06, 15.60s/it]
[2024-04-06 03:37:06,255] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2575/16104 [12:03:26<60:15:00, 16.03s/it]

 16%|█▌        | 2576/16104 [12:03:44<62:41:37, 16.68s/it]

 16%|█▌        | 2577/16104 [12:03:57<58:29:04, 15.56s/it]

 16%|█▌        | 2578/16104 [12:04:18<64:41:53, 17.22s/it]

 16%|█▌        | 2579/16104 [12:04:31<60:05:18, 15.99s/it]

 16%|█▌        | 2580/16104 [12:04:51<63:45:34, 16.97s/it]

 16%|█▌        | 2581/16104 [12:05:04<60:05:29, 16.00s/it]

 16%|█▌        | 2582/16104 [12:05:20<59:26:20, 15.82s/it]

 16%|█▌        | 2583/16104 [12:05:33<56:45:48, 15.11s/it]

 16%|█▌        | 2584/16104 [12:05:45<52:44:16, 14.04s/it]

 16%|█▌        | 2585/16104 [12:05:59<52:47:55, 14.06s/it]

 16%|█▌        | 2586/16104 [12:06:18<58:23:47, 15.55s/it]

 16%|█▌        | 2587/16104 [12:06:34<58:48:00, 15.66s/it]

 16%|█▌        | 2588/16104 [12:06:52<61:17:38, 16.33s/it]

 16%|█▌        | 2589/16104 [12:07:02<54:57:08, 14.64s/it]

 16%|█▌        | 2590/16104 [12:07:16<53:30:05, 14.25s/it]

 16%|█▌        | 2591/16104 [12:07:32<55:50:14, 14.88s/it]

 16%|█▌        | 2592/16104 [12:07:44<52:59:35, 14.12s/it]

 16%|█▌        | 2593/16104 [12:07:55<49:12:27, 13.11s/it]

 16%|█▌        | 2594/16104 [12:08:13<54:05:16, 14.41s/it]
[2024-04-06 03:42:09,932] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2595/16104 [12:08:29<56:02:56, 14.94s/it]

 16%|█▌        | 2596/16104 [12:08:40<52:21:05, 13.95s/it]
{'loss': 0.574, 'learning_rate': 1.911129946933968e-06, 'rewards/chosen': -0.14795610308647156, 'rewards/rejected': -0.7632301449775696, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6152741312980652, 'policy_logps/rejected': -423.0742492675781, 'policy_logps/chosen': -371.2329406738281, 'referece_logps/rejected': -415.44195556640625, 'referece_logps/chosen': -369.75335693359375, 'logits/rejected': -0.803260087966919, 'logits/chosen': -0.8050167560577393, 'epoch': 0.97}

 16%|█▌        | 2597/16104 [12:08:52<49:58:45, 13.32s/it]


 16%|█▌        | 2599/16104 [12:09:23<54:51:51, 14.63s/it]

 16%|█▌        | 2600/16104 [12:09:40<57:30:56, 15.33s/it]
[2024-04-06 03:43:37,079] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2601/16104 [12:10:01<63:43:51, 16.99s/it]
[2024-04-06 03:43:57,940] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2602/16104 [12:10:16<61:34:24, 16.42s/it]
[2024-04-06 03:44:13,018] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2603/16104 [12:10:28<56:26:31, 15.05s/it]

 16%|█▌        | 2604/16104 [12:10:39<51:58:28, 13.86s/it]

 16%|█▌        | 2605/16104 [12:10:49<48:22:03, 12.90s/it]

 16%|█▌        | 2606/16104 [12:11:03<49:36:55, 13.23s/it]
{'loss': 0.5839, 'learning_rate': 1.9102992246305714e-06, 'rewards/chosen': 0.19200973212718964, 'rewards/rejected': -0.13330668210983276, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3253163993358612, 'policy_logps/rejected': -452.8753967285156, 'policy_logps/chosen': -357.5941467285156, 'referece_logps/rejected': -451.54229736328125, 'referece_logps/chosen': -359.51422119140625, 'logits/rejected': -0.691257655620575, 'logits/chosen': -0.5825822949409485, 'epoch': 0.97}


 16%|█▌        | 2608/16104 [12:11:33<52:21:19, 13.97s/it]
{'loss': 0.6568, 'learning_rate': 1.9101326381835073e-06, 'rewards/chosen': 0.08456173539161682, 'rewards/rejected': -0.22844946384429932, 'rewards/accuracies': 0.5, 'rewards/margins': 0.31301116943359375, 'policy_logps/rejected': -495.1155700683594, 'policy_logps/chosen': -527.1529541015625, 'referece_logps/rejected': -492.83111572265625, 'referece_logps/chosen': -527.9986572265625, 'logits/rejected': 0.34550556540489197, 'logits/chosen': 0.3094630837440491, 'epoch': 0.97}

 16%|█▌        | 2609/16104 [12:11:51<56:39:59, 15.12s/it]
[2024-04-06 03:46:07,582] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▌        | 2611/16104 [12:12:30<65:08:51, 17.38s/it]
{'loss': 0.5621, 'learning_rate': 1.909882482397674e-06, 'rewards/chosen': -0.13934630155563354, 'rewards/rejected': -1.6670055389404297, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5276591777801514, 'policy_logps/rejected': -631.8729858398438, 'policy_logps/chosen': -659.2080078125, 'referece_logps/rejected': -615.202880859375, 'referece_logps/chosen': -657.8145751953125, 'logits/rejected': -0.02513306401669979, 'logits/chosen': 0.033205874264240265, 'epoch': 0.97}

 16%|█▌        | 2612/16104 [12:12:51<69:09:18, 18.45s/it]
[2024-04-06 03:47:05,527] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▌        | 2614/16104 [12:13:23<64:26:39, 17.20s/it]
{'loss': 0.6171, 'learning_rate': 1.9096319953545185e-06, 'rewards/chosen': -0.0001415163278579712, 'rewards/rejected': -0.2677723169326782, 'rewards/accuracies': 0.625, 'rewards/margins': 0.26763075590133667, 'policy_logps/rejected': -530.061767578125, 'policy_logps/chosen': -443.9750061035156, 'referece_logps/rejected': -527.3840942382812, 'referece_logps/chosen': -443.9735412597656, 'logits/rejected': 0.15507474541664124, 'logits/chosen': 0.34585344791412354, 'epoch': 0.97}


 16%|█▌        | 2616/16104 [12:14:00<66:58:12, 17.87s/it]

 16%|█▋        | 2617/16104 [12:14:19<68:46:57, 18.36s/it]
{'loss': 0.5745, 'learning_rate': 1.909381177145235e-06, 'rewards/chosen': -0.6103013753890991, 'rewards/rejected': -1.6532318592071533, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0429303646087646, 'policy_logps/rejected': -421.934814453125, 'policy_logps/chosen': -487.8638916015625, 'referece_logps/rejected': -405.4024658203125, 'referece_logps/chosen': -481.7608642578125, 'logits/rejected': 0.15651440620422363, 'logits/chosen': 0.09783714264631271, 'epoch': 0.98}
[2024-04-06 03:48:38,031] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▋        | 2619/16104 [12:14:56<67:13:20, 17.95s/it]
[2024-04-06 03:48:52,823] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2620/16104 [12:15:09<62:34:58, 16.71s/it]

 16%|█▋        | 2621/16104 [12:15:30<67:13:46, 17.95s/it]
{'loss': 0.6274, 'learning_rate': 1.9090462378767246e-06, 'rewards/chosen': -0.3416450619697571, 'rewards/rejected': -0.493912011384964, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1522669494152069, 'policy_logps/rejected': -464.909423828125, 'policy_logps/chosen': -456.1562194824219, 'referece_logps/rejected': -459.97027587890625, 'referece_logps/chosen': -452.73980712890625, 'logits/rejected': 0.6441272497177124, 'logits/chosen': 0.7131955027580261, 'epoch': 0.98}


 16%|█▋        | 2623/16104 [12:16:09<71:07:37, 18.99s/it]
[2024-04-06 03:50:06,494] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2624/16104 [12:16:25<68:01:15, 18.17s/it]
[2024-04-06 03:50:22,728] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2625/16104 [12:16:42<66:25:35, 17.74s/it]
{'loss': 0.5945, 'learning_rate': 1.9087107102475637e-06, 'rewards/chosen': -0.5421674847602844, 'rewards/rejected': -0.6677309274673462, 'rewards/accuracies': 0.5, 'rewards/margins': 0.12556341290473938, 'policy_logps/rejected': -475.18023681640625, 'policy_logps/chosen': -403.7338562011719, 'referece_logps/rejected': -468.5028991699219, 'referece_logps/chosen': -398.3121643066406, 'logits/rejected': -0.29598310589790344, 'logits/chosen': -0.2660478353500366, 'epoch': 0.98}


 16%|█▋        | 2627/16104 [12:17:23<71:54:40, 19.21s/it]
[2024-04-06 03:51:20,641] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2628/16104 [12:17:40<68:53:20, 18.40s/it]

 16%|█▋        | 2629/16104 [12:17:58<68:51:50, 18.40s/it]

 16%|█▋        | 2630/16104 [12:18:14<65:17:54, 17.45s/it]

 16%|█▋        | 2631/16104 [12:18:32<66:08:17, 17.67s/it]

 16%|█▋        | 2632/16104 [12:18:44<60:18:14, 16.11s/it]

 16%|█▋        | 2633/16104 [12:19:04<64:56:42, 17.36s/it]

 16%|█▋        | 2634/16104 [12:19:18<60:19:37, 16.12s/it]

 16%|█▋        | 2635/16104 [12:19:37<64:17:12, 17.18s/it]
{'loss': 0.5932, 'learning_rate': 1.9078693185228864e-06, 'rewards/chosen': -0.313267320394516, 'rewards/rejected': -0.807087242603302, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4938199520111084, 'policy_logps/rejected': -450.0270690917969, 'policy_logps/chosen': -481.79779052734375, 'referece_logps/rejected': -441.9561767578125, 'referece_logps/chosen': -478.6651611328125, 'logits/rejected': -0.12020646780729294, 'logits/chosen': -0.0290400218218565, 'epoch': 0.98}

 16%|█▋        | 2636/16104 [12:19:49<57:53:38, 15.48s/it]
[2024-04-06 03:54:10,255] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2637/16104 [12:20:13<67:37:49, 18.08s/it]
[2024-04-06 03:54:22,006] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▋        | 2639/16104 [12:20:42<62:01:06, 16.58s/it]

 16%|█▋        | 2640/16104 [12:20:59<61:44:53, 16.51s/it]

 16%|█▋        | 2641/16104 [12:21:18<65:23:11, 17.48s/it]
{'loss': 0.625, 'learning_rate': 1.9073627204733885e-06, 'rewards/chosen': -0.34150540828704834, 'rewards/rejected': -0.9808383584022522, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6393330097198486, 'policy_logps/rejected': -359.2909851074219, 'policy_logps/chosen': -418.9427185058594, 'referece_logps/rejected': -349.48260498046875, 'referece_logps/chosen': -415.52764892578125, 'logits/rejected': -0.06676417589187622, 'logits/chosen': -0.0018811896443367004, 'epoch': 0.98}


 16%|█▋        | 2643/16104 [12:21:46<57:45:39, 15.45s/it]
{'loss': 0.5625, 'learning_rate': 1.9071935607849068e-06, 'rewards/chosen': 0.6690860986709595, 'rewards/rejected': -0.20057085156440735, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8696569800376892, 'policy_logps/rejected': -520.8613891601562, 'policy_logps/chosen': -465.60479736328125, 'referece_logps/rejected': -518.8556518554688, 'referece_logps/chosen': -472.29571533203125, 'logits/rejected': -0.4973798394203186, 'logits/chosen': -0.4286985993385315, 'epoch': 0.98}


 16%|█▋        | 2645/16104 [12:22:15<55:01:14, 14.72s/it]
{'loss': 0.6173, 'learning_rate': 1.9070242543060328e-06, 'rewards/chosen': -0.40544593334198, 'rewards/rejected': -1.086432695388794, 'rewards/accuracies': 0.625, 'rewards/margins': 0.680986762046814, 'policy_logps/rejected': -511.49127197265625, 'policy_logps/chosen': -493.1640319824219, 'referece_logps/rejected': -500.626953125, 'referece_logps/chosen': -489.109619140625, 'logits/rejected': -0.625373363494873, 'logits/chosen': -0.7120707631111145, 'epoch': 0.99}


 16%|█▋        | 2647/16104 [12:22:52<63:39:04, 17.03s/it]

 16%|█▋        | 2648/16104 [12:23:12<66:55:03, 17.90s/it]

 16%|█▋        | 2649/16104 [12:23:32<68:58:53, 18.46s/it]

 16%|█▋        | 2650/16104 [12:23:54<73:15:01, 19.60s/it]
[2024-04-06 03:57:51,562] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2651/16104 [12:24:08<67:00:44, 17.93s/it]

 16%|█▋        | 2652/16104 [12:24:26<67:00:24, 17.93s/it]

 16%|█▋        | 2653/16104 [12:24:44<67:05:19, 17.96s/it]
{'loss': 0.5014, 'learning_rate': 1.9063455610348722e-06, 'rewards/chosen': -0.06662407517433167, 'rewards/rejected': -1.3114641904830933, 'rewards/accuracies': 1.0, 'rewards/margins': 1.244840145111084, 'policy_logps/rejected': -537.60009765625, 'policy_logps/chosen': -421.5173034667969, 'referece_logps/rejected': -524.4854125976562, 'referece_logps/chosen': -420.8510437011719, 'logits/rejected': -0.16250395774841309, 'logits/chosen': -0.13098770380020142, 'epoch': 0.99}


 16%|█▋        | 2655/16104 [12:25:22<69:38:23, 18.64s/it]

 16%|█▋        | 2656/16104 [12:25:40<68:38:48, 18.38s/it]
{'loss': 0.4774, 'learning_rate': 1.9060904460193745e-06, 'rewards/chosen': -0.010789014399051666, 'rewards/rejected': -1.3204255104064941, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3096364736557007, 'policy_logps/rejected': -275.8053894042969, 'policy_logps/chosen': -382.6748962402344, 'referece_logps/rejected': -262.6011047363281, 'referece_logps/chosen': -382.5669860839844, 'logits/rejected': -0.2568388879299164, 'logits/chosen': -0.29296597838401794, 'epoch': 0.99}

 16%|█▋        | 2657/16104 [12:25:54<63:22:39, 16.97s/it]

 17%|█▋        | 2658/16104 [12:26:16<69:08:21, 18.51s/it]

 17%|█▋        | 2659/16104 [12:26:35<69:46:28, 18.68s/it]
[2024-04-06 04:00:32,028] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6251, 'learning_rate': 1.9058350011271069e-06, 'rewards/chosen': -0.242161363363266, 'rewards/rejected': -0.9865062236785889, 'rewards/accuracies': 0.5, 'rewards/margins': 0.74434494972229, 'policy_logps/rejected': -514.3114013671875, 'policy_logps/chosen': -360.51873779296875, 'referece_logps/rejected': -504.44635009765625, 'referece_logps/chosen': -358.0970764160156, 'logits/rejected': 0.6101418733596802, 'logits/chosen': 0.591631293296814, 'epoch': 0.99}


 17%|█▋        | 2661/16104 [12:27:08<67:37:47, 18.11s/it]

 17%|█▋        | 2662/16104 [12:27:22<62:24:24, 16.71s/it]

 17%|█▋        | 2663/16104 [12:27:46<70:26:16, 18.87s/it]

 17%|█▋        | 2664/16104 [12:28:00<65:05:48, 17.44s/it]

 17%|█▋        | 2665/16104 [12:28:17<64:20:01, 17.23s/it]

 17%|█▋        | 2666/16104 [12:28:37<67:59:19, 18.21s/it]

 17%|█▋        | 2667/16104 [12:28:50<62:23:47, 16.72s/it]

 17%|█▋        | 2668/16104 [12:29:04<59:24:30, 15.92s/it]
{'loss': 0.6055, 'learning_rate': 1.9050666881202715e-06, 'rewards/chosen': -0.02620849758386612, 'rewards/rejected': -0.5462245941162109, 'rewards/accuracies': 0.625, 'rewards/margins': 0.520016074180603, 'policy_logps/rejected': -442.4484558105469, 'policy_logps/chosen': -570.0479125976562, 'referece_logps/rejected': -436.9862365722656, 'referece_logps/chosen': -569.7858276367188, 'logits/rejected': -0.04879995062947273, 'logits/chosen': 0.07591430842876434, 'epoch': 0.99}

 17%|█▋        | 2669/16104 [12:29:19<58:23:37, 15.65s/it]
[2024-04-06 04:03:40,745] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2670/16104 [12:29:43<67:47:34, 18.17s/it]


 17%|█▋        | 2672/16104 [12:30:17<63:24:19, 16.99s/it]
[2024-04-06 04:04:14,287] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2673/16104 [12:30:38<68:08:25, 18.26s/it]

 17%|█▋        | 2674/16104 [12:30:57<68:07:52, 18.26s/it]
{'loss': 0.509, 'learning_rate': 1.904552831773376e-06, 'rewards/chosen': -0.3505072593688965, 'rewards/rejected': -0.9897453784942627, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6392381191253662, 'policy_logps/rejected': -370.0419921875, 'policy_logps/chosen': -359.35906982421875, 'referece_logps/rejected': -360.14459228515625, 'referece_logps/chosen': -355.8539733886719, 'logits/rejected': -0.8623526096343994, 'logits/chosen': -0.5088684558868408, 'epoch': 1.0}


 17%|█▋        | 2676/16104 [12:31:31<65:21:16, 17.52s/it]

 17%|█▋        | 2677/16104 [12:31:52<69:58:17, 18.76s/it]
{'loss': 0.446, 'learning_rate': 1.9042954095776637e-06, 'rewards/chosen': -0.640617311000824, 'rewards/rejected': -1.6343623399734497, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9937451481819153, 'policy_logps/rejected': -293.9592590332031, 'policy_logps/chosen': -319.6678771972656, 'referece_logps/rejected': -277.61566162109375, 'referece_logps/chosen': -313.2616882324219, 'logits/rejected': -0.2284364253282547, 'logits/chosen': -0.26946112513542175, 'epoch': 1.0}

 17%|█▋        | 2678/16104 [12:32:10<68:26:47, 18.35s/it]


 17%|█▋        | 2680/16104 [12:32:43<66:07:39, 17.73s/it]

 17%|█▋        | 2681/16104 [12:32:55<60:27:48, 16.22s/it]
{'loss': 0.5449, 'learning_rate': 1.9039516678745272e-06, 'rewards/chosen': 0.18955650925636292, 'rewards/rejected': -0.3638988435268402, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5534553527832031, 'policy_logps/rejected': -674.9085693359375, 'policy_logps/chosen': -760.0938720703125, 'referece_logps/rejected': -671.26953125, 'referece_logps/chosen': -761.9894409179688, 'logits/rejected': 0.734087347984314, 'logits/chosen': 0.5335081815719604, 'epoch': 1.0}


 17%|█▋        | 2683/16104 [12:33:23<56:04:18, 15.04s/it]

 17%|█▋        | 2684/16104 [12:33:47<65:19:33, 17.52s/it]
{'loss': 0.5095, 'learning_rate': 1.9036934776372039e-06, 'rewards/chosen': -0.619523286819458, 'rewards/rejected': -1.5597527027130127, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9402294158935547, 'policy_logps/rejected': -259.25494384765625, 'policy_logps/chosen': -261.53875732421875, 'referece_logps/rejected': -243.6574249267578, 'referece_logps/chosen': -255.3435516357422, 'logits/rejected': 0.41340041160583496, 'logits/chosen': 0.5153952240943909, 'epoch': 1.0}

 17%|█▋        | 2685/16104 [12:34:00<60:25:56, 16.21s/it]
[2024-04-06 04:08:17,461] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2686/16104 [12:34:20<65:03:53, 17.46s/it]

 17%|█▋        | 2687/16104 [12:34:30<56:49:47, 15.25s/it]

 17%|█▋        | 2688/16104 [12:34:50<61:35:53, 16.53s/it]

 17%|█▋        | 2689/16104 [12:35:10<65:35:30, 17.60s/it]


 17%|█▋        | 2691/16104 [12:35:43<62:25:26, 16.75s/it]
{'loss': 0.4848, 'learning_rate': 1.9030897544523575e-06, 'rewards/chosen': -0.3955393135547638, 'rewards/rejected': -0.9067611694335938, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5112218260765076, 'policy_logps/rejected': -413.39794921875, 'policy_logps/chosen': -275.53985595703125, 'referece_logps/rejected': -404.33038330078125, 'referece_logps/chosen': -271.58447265625, 'logits/rejected': -0.20716524124145508, 'logits/chosen': -0.22927775979042053, 'epoch': 1.0}


 17%|█▋        | 2693/16104 [12:36:15<59:10:25, 15.88s/it]

 17%|█▋        | 2694/16104 [12:36:27<54:31:17, 14.64s/it]

 17%|█▋        | 2695/16104 [12:36:38<50:24:08, 13.53s/it]
{'loss': 0.5119, 'learning_rate': 1.9027439660035057e-06, 'rewards/chosen': -0.032258033752441406, 'rewards/rejected': -0.38960495591163635, 'rewards/accuracies': 0.625, 'rewards/margins': 0.35734689235687256, 'policy_logps/rejected': -328.749755859375, 'policy_logps/chosen': -445.1305847167969, 'referece_logps/rejected': -324.85369873046875, 'referece_logps/chosen': -444.8080139160156, 'logits/rejected': 0.09667858481407166, 'logits/chosen': 0.2107280194759369, 'epoch': 1.0}


 17%|█▋        | 2697/16104 [12:37:05<51:49:24, 13.92s/it]

 17%|█▋        | 2698/16104 [12:37:20<52:27:20, 14.09s/it]

 17%|█▋        | 2699/16104 [12:37:36<54:26:30, 14.62s/it]
{'loss': 0.5461, 'learning_rate': 1.9023975932730134e-06, 'rewards/chosen': -0.5507031083106995, 'rewards/rejected': -1.1386409997940063, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5879378914833069, 'policy_logps/rejected': -408.24859619140625, 'policy_logps/chosen': -445.1422119140625, 'referece_logps/rejected': -396.8621826171875, 'referece_logps/chosen': -439.6352233886719, 'logits/rejected': -0.463024765253067, 'logits/chosen': -0.5608494281768799, 'epoch': 1.01}

 17%|█▋        | 2700/16104 [12:37:48<51:50:36, 13.92s/it]


 17%|█▋        | 2702/16104 [12:38:11<47:41:45, 12.81s/it]

 17%|█▋        | 2703/16104 [12:38:31<55:30:32, 14.91s/it]
{'loss': 0.5171, 'learning_rate': 1.9020506364850632e-06, 'rewards/chosen': -0.20618000626564026, 'rewards/rejected': -0.9347392320632935, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7285591959953308, 'policy_logps/rejected': -477.106689453125, 'policy_logps/chosen': -376.34759521484375, 'referece_logps/rejected': -467.75927734375, 'referece_logps/chosen': -374.28582763671875, 'logits/rejected': 0.10369116067886353, 'logits/chosen': 0.2924400568008423, 'epoch': 1.01}


 17%|█▋        | 2705/16104 [12:38:53<48:13:21, 12.96s/it]

 17%|█▋        | 2706/16104 [12:39:15<58:06:55, 15.62s/it]
[2024-04-06 04:13:12,448] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2707/16104 [12:39:32<59:02:19, 15.86s/it]
[2024-04-06 04:13:28,894] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5654, 'learning_rate': 1.9017030958642155e-06, 'rewards/chosen': -0.15464305877685547, 'rewards/rejected': -0.4816626310348511, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3270195722579956, 'policy_logps/rejected': -418.9427795410156, 'policy_logps/chosen': -526.3182983398438, 'referece_logps/rejected': -414.1261291503906, 'referece_logps/chosen': -524.7719116210938, 'logits/rejected': 0.38255414366722107, 'logits/chosen': 0.5591186881065369, 'epoch': 1.01}


 17%|█▋        | 2709/16104 [12:40:00<56:49:18, 15.27s/it]
{'loss': 0.5313, 'learning_rate': 1.9015291066867335e-06, 'rewards/chosen': -0.23378677666187286, 'rewards/rejected': -0.9355036020278931, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7017168402671814, 'policy_logps/rejected': -366.4530334472656, 'policy_logps/chosen': -378.7065734863281, 'referece_logps/rejected': -357.0979919433594, 'referece_logps/chosen': -376.36865234375, 'logits/rejected': -0.3537767827510834, 'logits/chosen': -0.18986748158931732, 'epoch': 1.01}

 17%|█▋        | 2710/16104 [12:40:22<64:48:11, 17.42s/it]


 17%|█▋        | 2712/16104 [12:41:00<67:38:14, 18.18s/it]

 17%|█▋        | 2713/16104 [12:41:16<65:15:33, 17.54s/it]
{'loss': 0.5912, 'learning_rate': 1.9011806907384162e-06, 'rewards/chosen': -0.04270801693201065, 'rewards/rejected': -1.0111339092254639, 'rewards/accuracies': 0.875, 'rewards/margins': 0.968425989151001, 'policy_logps/rejected': -528.4033813476562, 'policy_logps/chosen': -489.06304931640625, 'referece_logps/rejected': -518.2919921875, 'referece_logps/chosen': -488.635986328125, 'logits/rejected': 0.46345019340515137, 'logits/chosen': 0.3267830014228821, 'epoch': 1.01}


 17%|█▋        | 2715/16104 [12:41:50<63:38:39, 17.11s/it]

 17%|█▋        | 2716/16104 [12:42:03<59:33:09, 16.01s/it]
{'loss': 0.5967, 'learning_rate': 1.900918995993997e-06, 'rewards/chosen': -0.8277705907821655, 'rewards/rejected': -1.6064256429672241, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7786548733711243, 'policy_logps/rejected': -393.14764404296875, 'policy_logps/chosen': -438.4339904785156, 'referece_logps/rejected': -377.0833435058594, 'referece_logps/chosen': -430.15631103515625, 'logits/rejected': -0.3059130907058716, 'logits/chosen': -0.37103578448295593, 'epoch': 1.01}


 17%|█▋        | 2718/16104 [12:42:33<56:24:53, 15.17s/it]
{'loss': 0.4956, 'learning_rate': 1.9007443506062643e-06, 'rewards/chosen': 0.08794212341308594, 'rewards/rejected': -0.5281373858451843, 'rewards/accuracies': 0.75, 'rewards/margins': 0.616079568862915, 'policy_logps/rejected': -494.0783996582031, 'policy_logps/chosen': -341.408447265625, 'referece_logps/rejected': -488.7970275878906, 'referece_logps/chosen': -342.2878723144531, 'logits/rejected': -0.23288890719413757, 'logits/chosen': -0.19737669825553894, 'epoch': 1.01}


 17%|█▋        | 2720/16104 [12:43:03<57:29:26, 15.46s/it]

 17%|█▋        | 2721/16104 [12:43:16<54:36:07, 14.69s/it]

 17%|█▋        | 2722/16104 [12:43:34<58:01:01, 15.61s/it]

 17%|█▋        | 2723/16104 [12:43:47<55:23:59, 14.90s/it]
{'loss': 0.6047, 'learning_rate': 1.9003070995562773e-06, 'rewards/chosen': 0.022625911980867386, 'rewards/rejected': 0.244376540184021, 'rewards/accuracies': 0.375, 'rewards/margins': -0.22175061702728271, 'policy_logps/rejected': -463.5156555175781, 'policy_logps/chosen': -524.890869140625, 'referece_logps/rejected': -465.9594421386719, 'referece_logps/chosen': -525.1171264648438, 'logits/rejected': 0.43064314126968384, 'logits/chosen': 0.24731816351413727, 'epoch': 1.01}


 17%|█▋        | 2725/16104 [12:44:19<56:40:03, 15.25s/it]
{'loss': 0.5566, 'learning_rate': 1.9001319441783081e-06, 'rewards/chosen': 0.31216126680374146, 'rewards/rejected': -0.33438050746917725, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6465417742729187, 'policy_logps/rejected': -455.3773193359375, 'policy_logps/chosen': -339.1702575683594, 'referece_logps/rejected': -452.0335388183594, 'referece_logps/chosen': -342.2918701171875, 'logits/rejected': 0.1868935227394104, 'logits/chosen': 0.3918049931526184, 'epoch': 1.02}

 17%|█▋        | 2726/16104 [12:44:37<59:15:35, 15.95s/it]

 17%|█▋        | 2727/16104 [12:44:54<60:59:18, 16.41s/it]

 17%|█▋        | 2728/16104 [12:45:11<60:47:03, 16.36s/it]


 17%|█▋        | 2730/16104 [12:45:43<60:55:19, 16.40s/it]
{'loss': 0.5645, 'learning_rate': 1.8996934185864365e-06, 'rewards/chosen': -0.0027757640928030014, 'rewards/rejected': 0.16689321398735046, 'rewards/accuracies': 0.375, 'rewards/margins': -0.16966897249221802, 'policy_logps/rejected': -385.2710876464844, 'policy_logps/chosen': -489.225341796875, 'referece_logps/rejected': -386.94000244140625, 'referece_logps/chosen': -489.19757080078125, 'logits/rejected': 0.5072588324546814, 'logits/chosen': 0.617620050907135, 'epoch': 1.02}
[2024-04-06 04:20:01,970] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2731/16104 [12:46:05<66:18:39, 17.85s/it]

 17%|█▋        | 2732/16104 [12:46:17<59:53:57, 16.13s/it]
[2024-04-06 04:20:25,663] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2734/16104 [12:46:42<53:52:10, 14.50s/it]

 17%|█▋        | 2735/16104 [12:47:02<59:39:08, 16.06s/it]
{'loss': 0.6245, 'learning_rate': 1.899253983139532e-06, 'rewards/chosen': 0.4365471303462982, 'rewards/rejected': 0.1707862913608551, 'rewards/accuracies': 0.625, 'rewards/margins': 0.26576077938079834, 'policy_logps/rejected': -420.9343566894531, 'policy_logps/chosen': -445.53521728515625, 'referece_logps/rejected': -422.6422119140625, 'referece_logps/chosen': -449.900634765625, 'logits/rejected': -0.10089219361543655, 'logits/chosen': -0.322877436876297, 'epoch': 1.02}


 17%|█▋        | 2737/16104 [12:47:34<61:09:17, 16.47s/it]
{'loss': 0.5312, 'learning_rate': 1.8990779543008752e-06, 'rewards/chosen': 0.3061050772666931, 'rewards/rejected': -0.10923139750957489, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4153365194797516, 'policy_logps/rejected': -407.6151428222656, 'policy_logps/chosen': -481.5822448730469, 'referece_logps/rejected': -406.5228271484375, 'referece_logps/chosen': -484.64324951171875, 'logits/rejected': 0.44024232029914856, 'logits/chosen': 0.5054060220718384, 'epoch': 1.02}


 17%|█▋        | 2739/16104 [12:48:00<54:46:37, 14.75s/it]

 17%|█▋        | 2740/16104 [12:48:14<54:25:58, 14.66s/it]
{'loss': 0.5694, 'learning_rate': 1.8988136382819926e-06, 'rewards/chosen': -0.5278303623199463, 'rewards/rejected': -0.6722833514213562, 'rewards/accuracies': 0.75, 'rewards/margins': 0.14445307850837708, 'policy_logps/rejected': -369.8109130859375, 'policy_logps/chosen': -360.60211181640625, 'referece_logps/rejected': -363.08807373046875, 'referece_logps/chosen': -355.32379150390625, 'logits/rejected': -0.12179054319858551, 'logits/chosen': -0.19124743342399597, 'epoch': 1.02}

 17%|█▋        | 2741/16104 [12:48:29<54:15:54, 14.62s/it]


 17%|█▋        | 2743/16104 [12:49:02<58:38:18, 15.80s/it]

 17%|█▋        | 2744/16104 [12:49:16<56:08:57, 15.13s/it]
{'loss': 0.4746, 'learning_rate': 1.898460707919527e-06, 'rewards/chosen': -0.014934629201889038, 'rewards/rejected': -1.012597918510437, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9976632595062256, 'policy_logps/rejected': -401.903076171875, 'policy_logps/chosen': -366.409912109375, 'referece_logps/rejected': -391.7770690917969, 'referece_logps/chosen': -366.26055908203125, 'logits/rejected': -0.607978105545044, 'logits/chosen': -0.5988340377807617, 'epoch': 1.02}

 17%|█▋        | 2745/16104 [12:49:33<57:47:28, 15.57s/it]
[2024-04-06 04:23:50,035] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2747/16104 [12:50:06<58:44:20, 15.83s/it]
{'loss': 0.5484, 'learning_rate': 1.8981956285196326e-06, 'rewards/chosen': -0.035627927631139755, 'rewards/rejected': -1.1109739542007446, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0753459930419922, 'policy_logps/rejected': -486.011474609375, 'policy_logps/chosen': -577.6721801757812, 'referece_logps/rejected': -474.9017333984375, 'referece_logps/chosen': -577.3159790039062, 'logits/rejected': 0.06269605457782745, 'logits/chosen': -0.0018554367125034332, 'epoch': 1.02}


 17%|█▋        | 2749/16104 [12:50:32<52:13:47, 14.08s/it]

 17%|█▋        | 2750/16104 [12:50:42<48:31:06, 13.08s/it]
{'loss': 0.5236, 'learning_rate': 1.8979302221172027e-06, 'rewards/chosen': 0.024789605289697647, 'rewards/rejected': -0.6923913955688477, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7171809673309326, 'policy_logps/rejected': -371.5980529785156, 'policy_logps/chosen': -534.7467651367188, 'referece_logps/rejected': -364.67413330078125, 'referece_logps/chosen': -534.99462890625, 'logits/rejected': -0.519205629825592, 'logits/chosen': -0.475417822599411, 'epoch': 1.02}

 17%|█▋        | 2751/16104 [12:50:53<45:52:01, 12.37s/it]

 17%|█▋        | 2752/16104 [12:51:04<43:58:10, 11.86s/it]

 17%|█▋        | 2753/16104 [12:51:21<49:59:12, 13.48s/it]

 17%|█▋        | 2754/16104 [12:51:35<50:28:52, 13.61s/it]


 17%|█▋        | 2756/16104 [12:52:10<57:26:01, 15.49s/it]

 17%|█▋        | 2757/16104 [12:52:30<62:15:39, 16.79s/it]

 17%|█▋        | 2758/16104 [12:52:52<68:22:53, 18.45s/it]
{'loss': 0.5552, 'learning_rate': 1.8972208737668702e-06, 'rewards/chosen': -0.5977414846420288, 'rewards/rejected': -1.4002798795700073, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8025381565093994, 'policy_logps/rejected': -442.17388916015625, 'policy_logps/chosen': -411.5048522949219, 'referece_logps/rejected': -428.17108154296875, 'referece_logps/chosen': -405.5274353027344, 'logits/rejected': -0.8656948804855347, 'logits/chosen': -0.816675066947937, 'epoch': 1.03}

 17%|█▋        | 2759/16104 [12:53:05<61:57:59, 16.72s/it]
[2024-04-06 04:27:26,191] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2760/16104 [12:53:29<69:51:22, 18.85s/it]
[2024-04-06 04:27:41,193] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2761/16104 [12:53:44<65:34:37, 17.69s/it]


 17%|█▋        | 2763/16104 [12:54:15<62:19:04, 16.82s/it]
{'loss': 0.4655, 'learning_rate': 1.8967763513703148e-06, 'rewards/chosen': -0.010231122374534607, 'rewards/rejected': -1.1830291748046875, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1727981567382812, 'policy_logps/rejected': -459.92169189453125, 'policy_logps/chosen': -455.9727783203125, 'referece_logps/rejected': -448.09136962890625, 'referece_logps/chosen': -455.8704528808594, 'logits/rejected': -0.9595202803611755, 'logits/chosen': -0.6894068121910095, 'epoch': 1.03}

 17%|█▋        | 2764/16104 [12:54:35<66:13:29, 17.87s/it]

 17%|█▋        | 2765/16104 [12:54:47<59:53:22, 16.16s/it]


 17%|█▋        | 2767/16104 [12:55:20<61:57:52, 16.73s/it]
[2024-04-06 04:29:17,708] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2768/16104 [12:55:35<59:05:43, 15.95s/it]
{'loss': 0.4974, 'learning_rate': 1.8963309220687404e-06, 'rewards/chosen': -0.09979306161403656, 'rewards/rejected': -0.7781437635421753, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6783506274223328, 'policy_logps/rejected': -297.2470397949219, 'policy_logps/chosen': -367.2430419921875, 'referece_logps/rejected': -289.465576171875, 'referece_logps/chosen': -366.2451171875, 'logits/rejected': -0.7970595359802246, 'logits/chosen': -0.6194902062416077, 'epoch': 1.03}

 17%|█▋        | 2769/16104 [12:55:45<53:04:50, 14.33s/it]


 17%|█▋        | 2771/16104 [12:56:07<46:20:02, 12.51s/it]

 17%|█▋        | 2772/16104 [12:56:22<49:58:08, 13.49s/it]
{'loss': 0.6107, 'learning_rate': 1.8959739259585454e-06, 'rewards/chosen': -0.3171769976615906, 'rewards/rejected': -0.6207509636878967, 'rewards/accuracies': 0.625, 'rewards/margins': 0.30357399582862854, 'policy_logps/rejected': -378.21142578125, 'policy_logps/chosen': -338.2040710449219, 'referece_logps/rejected': -372.0038757324219, 'referece_logps/chosen': -335.03228759765625, 'logits/rejected': -0.6737261414527893, 'logits/chosen': -0.571797788143158, 'epoch': 1.03}


 17%|█▋        | 2774/16104 [12:56:55<56:06:51, 15.15s/it]
{'loss': 0.6073, 'learning_rate': 1.8957952104265384e-06, 'rewards/chosen': -0.4079429507255554, 'rewards/rejected': -0.6152116656303406, 'rewards/accuracies': 0.5, 'rewards/margins': 0.20726872980594635, 'policy_logps/rejected': -381.05316162109375, 'policy_logps/chosen': -367.6484680175781, 'referece_logps/rejected': -374.9010314941406, 'referece_logps/chosen': -363.5690002441406, 'logits/rejected': 0.20079082250595093, 'logits/chosen': 0.27877384424209595, 'epoch': 1.03}

 17%|█▋        | 2775/16104 [12:57:12<58:14:25, 15.73s/it]

 17%|█▋        | 2776/16104 [12:57:31<62:14:53, 16.81s/it]

 17%|█▋        | 2777/16104 [12:57:52<66:47:37, 18.04s/it]

 17%|█▋        | 2778/16104 [12:58:14<71:03:48, 19.20s/it]


 17%|█▋        | 2780/16104 [12:58:49<66:55:09, 18.08s/it]
{'loss': 0.5242, 'learning_rate': 1.8952581942699575e-06, 'rewards/chosen': -0.27110156416893005, 'rewards/rejected': -1.2175639867782593, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9464624524116516, 'policy_logps/rejected': -337.2046813964844, 'policy_logps/chosen': -390.7994384765625, 'referece_logps/rejected': -325.0290222167969, 'referece_logps/chosen': -388.08843994140625, 'logits/rejected': -0.22179001569747925, 'logits/chosen': -0.2176528424024582, 'epoch': 1.04}

 17%|█▋        | 2781/16104 [12:59:03<62:42:02, 16.94s/it]

 17%|█▋        | 2782/16104 [12:59:16<57:32:14, 15.55s/it]


 17%|█▋        | 2784/16104 [12:59:47<55:56:50, 15.12s/it]
{'loss': 0.5447, 'learning_rate': 1.894899459154806e-06, 'rewards/chosen': 0.09623528271913528, 'rewards/rejected': -0.5007730722427368, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5970082879066467, 'policy_logps/rejected': -349.559814453125, 'policy_logps/chosen': -502.05487060546875, 'referece_logps/rejected': -344.5520935058594, 'referece_logps/chosen': -503.0172424316406, 'logits/rejected': 0.0007570385932922363, 'logits/chosen': 0.2257809191942215, 'epoch': 1.04}


 17%|█▋        | 2786/16104 [13:00:15<54:08:17, 14.63s/it]
[2024-04-06 04:34:12,204] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2787/16104 [13:00:31<55:46:35, 15.08s/it]

 17%|█▋        | 2788/16104 [13:00:53<63:38:37, 17.21s/it]
{'loss': 0.523, 'learning_rate': 1.894540144835203e-06, 'rewards/chosen': -0.3768492639064789, 'rewards/rejected': -0.7075598239898682, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3307105302810669, 'policy_logps/rejected': -308.18487548828125, 'policy_logps/chosen': -429.48516845703125, 'referece_logps/rejected': -301.10931396484375, 'referece_logps/chosen': -425.7167053222656, 'logits/rejected': -0.0030022934079170227, 'logits/chosen': -0.055527716875076294, 'epoch': 1.04}


 17%|█▋        | 2790/16104 [13:01:23<59:38:17, 16.13s/it]

 17%|█▋        | 2791/16104 [13:01:35<55:24:13, 14.98s/it]
{'loss': 0.5209, 'learning_rate': 1.8942702791324638e-06, 'rewards/chosen': -0.12125568091869354, 'rewards/rejected': -0.613547146320343, 'rewards/accuracies': 0.625, 'rewards/margins': 0.49229153990745544, 'policy_logps/rejected': -580.0393676757812, 'policy_logps/chosen': -613.102294921875, 'referece_logps/rejected': -573.9038696289062, 'referece_logps/chosen': -611.8897094726562, 'logits/rejected': -0.626049816608429, 'logits/chosen': -0.6247854828834534, 'epoch': 1.04}

 17%|█▋        | 2792/16104 [13:01:50<55:44:47, 15.08s/it]


 17%|█▋        | 2794/16104 [13:02:19<55:01:55, 14.88s/it]
{'loss': 0.5091, 'learning_rate': 1.8940000878562755e-06, 'rewards/chosen': 0.15731465816497803, 'rewards/rejected': -1.2148573398590088, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3721719980239868, 'policy_logps/rejected': -537.1220703125, 'policy_logps/chosen': -555.258056640625, 'referece_logps/rejected': -524.9735107421875, 'referece_logps/chosen': -556.8311767578125, 'logits/rejected': -0.40593594312667847, 'logits/chosen': -0.36447784304618835, 'epoch': 1.04}


 17%|█▋        | 2796/16104 [13:02:51<58:19:58, 15.78s/it]
{'loss': 0.426, 'learning_rate': 1.8938197795132503e-06, 'rewards/chosen': 0.5692428946495056, 'rewards/rejected': -0.914517879486084, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4837607145309448, 'policy_logps/rejected': -411.2945251464844, 'policy_logps/chosen': -415.76226806640625, 'referece_logps/rejected': -402.1493225097656, 'referece_logps/chosen': -421.4547424316406, 'logits/rejected': -0.5267470479011536, 'logits/chosen': -0.4594327211380005, 'epoch': 1.04}

 17%|█▋        | 2797/16104 [13:03:09<61:04:47, 16.52s/it]

 17%|█▋        | 2798/16104 [13:03:23<57:23:18, 15.53s/it]

 17%|█▋        | 2799/16104 [13:03:38<56:42:39, 15.34s/it]
[2024-04-06 04:37:55,542] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2800/16104 [13:03:58<62:35:18, 16.94s/it]


 17%|█▋        | 2802/16104 [13:04:39<68:43:56, 18.60s/it]
{'loss': 0.4864, 'learning_rate': 1.893277986842479e-06, 'rewards/chosen': -0.3507446348667145, 'rewards/rejected': -1.9503211975097656, 'rewards/accuracies': 0.875, 'rewards/margins': 1.599576473236084, 'policy_logps/rejected': -497.1199951171875, 'policy_logps/chosen': -431.55767822265625, 'referece_logps/rejected': -477.61676025390625, 'referece_logps/chosen': -428.05023193359375, 'logits/rejected': 0.42490261793136597, 'logits/chosen': 0.4805382490158081, 'epoch': 1.04}
[2024-04-06 04:38:57,498] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2804/16104 [13:05:23<75:36:11, 20.46s/it]
[2024-04-06 04:39:20,536] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4314, 'learning_rate': 1.8930971001690631e-06, 'rewards/chosen': -0.5312962532043457, 'rewards/rejected': -2.0875489711761475, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5562525987625122, 'policy_logps/rejected': -449.6939392089844, 'policy_logps/chosen': -439.5386962890625, 'referece_logps/rejected': -428.8184509277344, 'referece_logps/chosen': -434.22576904296875, 'logits/rejected': 0.5731104016304016, 'logits/chosen': 0.5830816030502319, 'epoch': 1.04}

 17%|█▋        | 2805/16104 [13:05:42<73:49:17, 19.98s/it]

 17%|█▋        | 2806/16104 [13:05:59<70:06:13, 18.98s/it]

 17%|█▋        | 2807/16104 [13:06:19<71:12:46, 19.28s/it]

 17%|█▋        | 2808/16104 [13:06:34<67:17:48, 18.22s/it]

 17%|█▋        | 2809/16104 [13:06:53<67:13:11, 18.20s/it]

 17%|█▋        | 2810/16104 [13:07:07<62:58:41, 17.05s/it]
[2024-04-06 04:41:27,008] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2812/16104 [13:07:52<72:44:33, 19.70s/it]
[2024-04-06 04:41:48,929] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4458, 'learning_rate': 1.8923721086735959e-06, 'rewards/chosen': -0.8070158958435059, 'rewards/rejected': -1.5594489574432373, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7524330019950867, 'policy_logps/rejected': -314.429931640625, 'policy_logps/chosen': -410.75482177734375, 'referece_logps/rejected': -298.8354187011719, 'referece_logps/chosen': -402.6846618652344, 'logits/rejected': -0.34966883063316345, 'logits/chosen': -0.3421263098716736, 'epoch': 1.05}
[2024-04-06 04:42:03,632] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2813/16104 [13:08:06<67:12:03, 18.20s/it]

 17%|█▋        | 2814/16104 [13:08:22<64:43:09, 17.53s/it]

 17%|█▋        | 2815/16104 [13:08:36<60:40:32, 16.44s/it]
[2024-04-06 04:42:53,557] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2816/16104 [13:08:56<64:41:57, 17.53s/it]

 17%|█▋        | 2817/16104 [13:09:18<69:44:59, 18.90s/it]

 17%|█▋        | 2818/16104 [13:09:35<66:50:17, 18.11s/it]

 18%|█▊        | 2819/16104 [13:09:53<66:40:28, 18.07s/it]

 18%|█▊        | 2820/16104 [13:10:10<66:27:11, 18.01s/it]

 18%|█▊        | 2821/16104 [13:10:25<62:53:17, 17.04s/it]
[2024-04-06 04:44:45,565] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2822/16104 [13:10:48<69:29:04, 18.83s/it]

 18%|█▊        | 2823/16104 [13:11:02<63:48:17, 17.30s/it]

 18%|█▊        | 2824/16104 [13:11:21<65:25:19, 17.73s/it]


 18%|█▊        | 2826/16104 [13:11:51<59:32:00, 16.14s/it]
{'loss': 0.6205, 'learning_rate': 1.8910978155913683e-06, 'rewards/chosen': -0.07573983073234558, 'rewards/rejected': 0.057443805038928986, 'rewards/accuracies': 0.5, 'rewards/margins': -0.13318367302417755, 'policy_logps/rejected': -598.9136352539062, 'policy_logps/chosen': -497.423828125, 'referece_logps/rejected': -599.4880981445312, 'referece_logps/chosen': -496.66644287109375, 'logits/rejected': 0.2626187205314636, 'logits/chosen': 0.2869180142879486, 'epoch': 1.05}

 18%|█▊        | 2827/16104 [13:12:13<65:28:58, 17.76s/it]

 18%|█▊        | 2828/16104 [13:12:30<65:08:16, 17.66s/it]


 18%|█▊        | 2830/16104 [13:13:10<68:12:44, 18.50s/it]

 18%|█▊        | 2831/16104 [13:13:32<72:00:35, 19.53s/it]

 18%|█▊        | 2832/16104 [13:13:48<68:02:37, 18.46s/it]
[2024-04-06 04:47:45,017] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5618, 'learning_rate': 1.890549526605216e-06, 'rewards/chosen': -0.155979722738266, 'rewards/rejected': -0.9390240907669067, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7830443382263184, 'policy_logps/rejected': -274.9542236328125, 'policy_logps/chosen': -365.532470703125, 'referece_logps/rejected': -265.56402587890625, 'referece_logps/chosen': -363.9726867675781, 'logits/rejected': -0.38558077812194824, 'logits/chosen': -0.24995353817939758, 'epoch': 1.06}

 18%|█▊        | 2833/16104 [13:14:05<66:16:21, 17.98s/it]
[2024-04-06 04:48:21,775] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2834/16104 [13:14:24<68:23:33, 18.55s/it]


 18%|█▊        | 2836/16104 [13:14:48<55:07:11, 14.96s/it]

 18%|█▊        | 2837/16104 [13:15:02<54:13:08, 14.71s/it]
{'loss': 0.5094, 'learning_rate': 1.890091628414199e-06, 'rewards/chosen': 0.20344239473342896, 'rewards/rejected': -0.4202725291252136, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6237149238586426, 'policy_logps/rejected': -331.4031066894531, 'policy_logps/chosen': -399.4466552734375, 'referece_logps/rejected': -327.20037841796875, 'referece_logps/chosen': -401.4810791015625, 'logits/rejected': 0.14598670601844788, 'logits/chosen': 0.33144402503967285, 'epoch': 1.06}

 18%|█▊        | 2838/16104 [13:15:21<59:26:02, 16.13s/it]

 18%|█▊        | 2839/16104 [13:15:39<61:13:20, 16.62s/it]
[2024-04-06 04:49:55,775] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2840/16104 [13:15:58<64:27:00, 17.49s/it]


 18%|█▊        | 2842/16104 [13:16:30<61:12:37, 16.62s/it]

 18%|█▊        | 2843/16104 [13:16:52<66:56:31, 18.17s/it]
[2024-04-06 04:50:49,177] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4601, 'learning_rate': 1.8895409624346628e-06, 'rewards/chosen': 0.13211707770824432, 'rewards/rejected': -1.0835342407226562, 'rewards/accuracies': 0.875, 'rewards/margins': 1.215651273727417, 'policy_logps/rejected': -419.2060241699219, 'policy_logps/chosen': -606.5594482421875, 'referece_logps/rejected': -408.3706970214844, 'referece_logps/chosen': -607.8806762695312, 'logits/rejected': 0.0022250115871429443, 'logits/chosen': -0.10527142882347107, 'epoch': 1.06}

 18%|█▊        | 2844/16104 [13:17:13<70:38:03, 19.18s/it]


 18%|█▊        | 2846/16104 [13:17:42<60:15:31, 16.36s/it]
{'loss': 0.6775, 'learning_rate': 1.8892651436172483e-06, 'rewards/chosen': 0.035744667053222656, 'rewards/rejected': -0.2209712266921997, 'rewards/accuracies': 0.625, 'rewards/margins': 0.25671589374542236, 'policy_logps/rejected': -355.9529724121094, 'policy_logps/chosen': -328.1581115722656, 'referece_logps/rejected': -353.7432556152344, 'referece_logps/chosen': -328.51556396484375, 'logits/rejected': 0.20325243473052979, 'logits/chosen': 0.1697285920381546, 'epoch': 1.06}

 18%|█▊        | 2847/16104 [13:17:58<59:25:25, 16.14s/it]

 18%|█▊        | 2848/16104 [13:18:13<59:06:08, 16.05s/it]


 18%|█▊        | 2850/16104 [13:18:54<67:09:51, 18.24s/it]

 18%|█▊        | 2851/16104 [13:19:12<67:15:24, 18.27s/it]
{'loss': 0.578, 'learning_rate': 1.8888047261906457e-06, 'rewards/chosen': -0.057230375707149506, 'rewards/rejected': -0.6326031684875488, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5753728151321411, 'policy_logps/rejected': -490.5740966796875, 'policy_logps/chosen': -401.2185363769531, 'referece_logps/rejected': -484.248046875, 'referece_logps/chosen': -400.646240234375, 'logits/rejected': 0.1548144370317459, 'logits/chosen': 0.182755708694458, 'epoch': 1.06}

 18%|█▊        | 2852/16104 [13:19:26<61:53:49, 16.81s/it]

 18%|█▊        | 2853/16104 [13:19:38<56:38:32, 15.39s/it]


 18%|█▊        | 2855/16104 [13:20:00<48:59:41, 13.31s/it]
{'loss': 0.6708, 'learning_rate': 1.8884357450597655e-06, 'rewards/chosen': 0.3264734745025635, 'rewards/rejected': -0.3238452672958374, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6503186821937561, 'policy_logps/rejected': -455.8096923828125, 'policy_logps/chosen': -388.9326171875, 'referece_logps/rejected': -452.5712585449219, 'referece_logps/chosen': -392.197265625, 'logits/rejected': -0.27596190571784973, 'logits/chosen': 0.01569288969039917, 'epoch': 1.06}

 18%|█▊        | 2856/16104 [13:20:11<46:01:33, 12.51s/it]

 18%|█▊        | 2857/16104 [13:20:26<48:51:12, 13.28s/it]

 18%|█▊        | 2858/16104 [13:20:40<49:29:17, 13.45s/it]

 18%|█▊        | 2859/16104 [13:20:53<49:25:06, 13.43s/it]

 18%|█▊        | 2860/16104 [13:21:08<50:56:59, 13.85s/it]

 18%|█▊        | 2861/16104 [13:21:21<50:05:45, 13.62s/it]

 18%|█▊        | 2862/16104 [13:21:32<46:57:11, 12.76s/it]

 18%|█▊        | 2863/16104 [13:21:49<51:59:13, 14.13s/it]

 18%|█▊        | 2864/16104 [13:22:03<51:53:19, 14.11s/it]

 18%|█▊        | 2865/16104 [13:22:15<48:57:54, 13.31s/it]

 18%|█▊        | 2866/16104 [13:22:33<54:29:51, 14.82s/it]

 18%|█▊        | 2867/16104 [13:22:44<50:05:30, 13.62s/it]

 18%|█▊        | 2868/16104 [13:22:59<52:09:13, 14.19s/it]

 18%|█▊        | 2869/16104 [13:23:15<53:35:36, 14.58s/it]

 18%|█▊        | 2870/16104 [13:23:35<59:40:25, 16.23s/it]

 18%|█▊        | 2871/16104 [13:23:55<64:11:45, 17.46s/it]

 18%|█▊        | 2872/16104 [13:24:11<62:02:10, 16.88s/it]

 18%|█▊        | 2873/16104 [13:24:22<55:18:35, 15.05s/it]

 18%|█▊        | 2874/16104 [13:24:34<52:44:51, 14.35s/it]

 18%|█▊        | 2875/16104 [13:24:48<51:34:40, 14.04s/it]

 18%|█▊        | 2876/16104 [13:25:03<53:19:24, 14.51s/it]

 18%|█▊        | 2877/16104 [13:25:23<58:50:54, 16.02s/it]


 18%|█▊        | 2879/16104 [13:25:58<62:28:29, 17.01s/it]

 18%|█▊        | 2880/16104 [13:26:10<57:30:56, 15.66s/it]

 18%|█▊        | 2881/16104 [13:26:22<52:59:22, 14.43s/it]

 18%|█▊        | 2882/16104 [13:26:36<52:05:15, 14.18s/it]

 18%|█▊        | 2883/16104 [13:26:51<53:53:12, 14.67s/it]

 18%|█▊        | 2884/16104 [13:27:06<53:15:27, 14.50s/it]

 18%|█▊        | 2885/16104 [13:27:26<60:17:17, 16.42s/it]

 18%|█▊        | 2886/16104 [13:27:37<53:59:57, 14.71s/it]

 18%|█▊        | 2887/16104 [13:28:00<62:52:23, 17.13s/it]

 18%|█▊        | 2888/16104 [13:28:12<57:21:31, 15.62s/it]

 18%|█▊        | 2889/16104 [13:28:23<52:07:15, 14.20s/it]

 18%|█▊        | 2890/16104 [13:28:41<56:24:47, 15.37s/it]

 18%|█▊        | 2891/16104 [13:29:00<60:26:29, 16.47s/it]

 18%|█▊        | 2892/16104 [13:29:17<60:31:31, 16.49s/it]

 18%|█▊        | 2893/16104 [13:29:38<65:30:38, 17.85s/it]

 18%|█▊        | 2894/16104 [13:29:51<60:30:36, 16.49s/it]

 18%|█▊        | 2895/16104 [13:30:12<65:20:25, 17.81s/it]

 18%|█▊        | 2896/16104 [13:30:29<64:53:03, 17.68s/it]

 18%|█▊        | 2897/16104 [13:30:42<59:15:41, 16.15s/it]

 18%|█▊        | 2898/16104 [13:30:53<53:24:04, 14.56s/it]

 18%|█▊        | 2899/16104 [13:31:13<60:16:53, 16.43s/it]

 18%|█▊        | 2900/16104 [13:31:35<66:26:46, 18.12s/it]

 18%|█▊        | 2901/16104 [13:31:46<58:16:58, 15.89s/it]

 18%|█▊        | 2902/16104 [13:31:58<53:31:56, 14.60s/it]

 18%|█▊        | 2903/16104 [13:32:13<54:42:32, 14.92s/it]

 18%|█▊        | 2904/16104 [13:32:34<60:32:29, 16.51s/it]

 18%|█▊        | 2905/16104 [13:32:54<64:35:29, 17.62s/it]

 18%|█▊        | 2906/16104 [13:33:17<70:30:47, 19.23s/it]

 18%|█▊        | 2907/16104 [13:33:29<63:15:51, 17.26s/it]

 18%|█▊        | 2908/16104 [13:33:47<63:05:26, 17.21s/it]

 18%|█▊        | 2909/16104 [13:34:02<60:31:22, 16.51s/it]

 18%|█▊        | 2910/16104 [13:34:14<56:16:57, 15.36s/it]

 18%|█▊        | 2911/16104 [13:34:26<52:36:18, 14.35s/it]

 18%|█▊        | 2912/16104 [13:34:46<58:14:09, 15.89s/it]

 18%|█▊        | 2913/16104 [13:35:01<57:47:35, 15.77s/it]

 18%|█▊        | 2914/16104 [13:35:13<53:05:02, 14.49s/it]

 18%|█▊        | 2915/16104 [13:35:27<52:33:43, 14.35s/it]

 18%|█▊        | 2916/16104 [13:35:42<53:45:07, 14.67s/it]

 18%|█▊        | 2917/16104 [13:36:05<62:18:39, 17.01s/it]

 18%|█▊        | 2918/16104 [13:36:25<66:23:28, 18.13s/it]

 18%|█▊        | 2919/16104 [13:36:45<68:29:19, 18.70s/it]

 18%|█▊        | 2920/16104 [13:36:56<60:04:40, 16.40s/it]

 18%|█▊        | 2921/16104 [13:37:14<61:46:35, 16.87s/it]

 18%|█▊        | 2922/16104 [13:37:35<66:03:30, 18.04s/it]

 18%|█▊        | 2923/16104 [13:37:55<68:00:06, 18.57s/it]

 18%|█▊        | 2924/16104 [13:38:18<72:42:12, 19.86s/it]

 18%|█▊        | 2925/16104 [13:38:35<69:43:48, 19.05s/it]

 18%|█▊        | 2926/16104 [13:38:55<70:21:49, 19.22s/it]

 18%|█▊        | 2927/16104 [13:39:12<68:43:36, 18.78s/it]

 18%|█▊        | 2928/16104 [13:39:27<64:06:05, 17.51s/it]

 18%|█▊        | 2929/16104 [13:39:38<56:42:32, 15.50s/it]

 18%|█▊        | 2930/16104 [13:39:48<51:27:55, 14.06s/it]

 18%|█▊        | 2931/16104 [13:39:59<47:49:09, 13.07s/it]

 18%|█▊        | 2932/16104 [13:40:22<59:08:27, 16.16s/it]
[2024-04-06 05:14:19,748] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2933/16104 [13:40:40<61:05:54, 16.70s/it]
[2024-04-06 05:14:37,699] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2934/16104 [13:40:51<54:27:31, 14.89s/it]

 18%|█▊        | 2935/16104 [13:41:07<55:45:01, 15.24s/it]

 18%|█▊        | 2936/16104 [13:41:18<51:01:21, 13.95s/it]

 18%|█▊        | 2937/16104 [13:41:35<53:54:27, 14.74s/it]

 18%|█▊        | 2938/16104 [13:41:52<56:41:38, 15.50s/it]
{'loss': 0.4467, 'learning_rate': 1.8806499874386341e-06, 'rewards/chosen': -0.5165109634399414, 'rewards/rejected': -1.1432323455810547, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6267213821411133, 'policy_logps/rejected': -406.3143005371094, 'policy_logps/chosen': -315.4949645996094, 'referece_logps/rejected': -394.8819885253906, 'referece_logps/chosen': -310.3298645019531, 'logits/rejected': 0.0956217423081398, 'logits/chosen': 0.08317641913890839, 'epoch': 1.09}
[2024-04-06 05:16:11,137] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 18%|█▊        | 2940/16104 [13:42:34<66:19:41, 18.14s/it]

 18%|█▊        | 2941/16104 [13:42:54<68:42:37, 18.79s/it]

 18%|█▊        | 2942/16104 [13:43:12<68:13:35, 18.66s/it]

 18%|█▊        | 2943/16104 [13:43:32<69:16:20, 18.95s/it]

 18%|█▊        | 2944/16104 [13:43:51<69:15:42, 18.95s/it]

 18%|█▊        | 2945/16104 [13:44:11<70:05:12, 19.17s/it]

 18%|█▊        | 2946/16104 [13:44:32<72:30:24, 19.84s/it]

 18%|█▊        | 2947/16104 [13:44:51<72:06:33, 19.73s/it]
{'loss': 0.4313, 'learning_rate': 1.8797909613283455e-06, 'rewards/chosen': -0.441602885723114, 'rewards/rejected': -1.364164113998413, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9225611686706543, 'policy_logps/rejected': -429.025634765625, 'policy_logps/chosen': -387.453125, 'referece_logps/rejected': -415.38397216796875, 'referece_logps/chosen': -383.037109375, 'logits/rejected': -0.11231765151023865, 'logits/chosen': -0.18335139751434326, 'epoch': 1.1}


 18%|█▊        | 2949/16104 [13:45:23<64:22:40, 17.62s/it]

 18%|█▊        | 2950/16104 [13:45:35<58:09:01, 15.91s/it]

 18%|█▊        | 2951/16104 [13:45:47<53:46:12, 14.72s/it]

 18%|█▊        | 2952/16104 [13:46:00<51:55:35, 14.21s/it]

 18%|█▊        | 2953/16104 [13:46:16<53:52:20, 14.75s/it]

 18%|█▊        | 2954/16104 [13:46:28<50:54:37, 13.94s/it]

 18%|█▊        | 2955/16104 [13:46:45<54:54:35, 15.03s/it]

 18%|█▊        | 2956/16104 [13:47:02<56:22:36, 15.44s/it]

 18%|█▊        | 2957/16104 [13:47:14<52:37:01, 14.41s/it]

 18%|█▊        | 2958/16104 [13:47:33<58:10:21, 15.93s/it]

 18%|█▊        | 2959/16104 [13:47:49<57:40:14, 15.79s/it]

 18%|█▊        | 2960/16104 [13:48:12<65:25:07, 17.92s/it]

 18%|█▊        | 2961/16104 [13:48:29<65:12:30, 17.86s/it]

 18%|█▊        | 2962/16104 [13:48:48<65:32:46, 17.96s/it]

 18%|█▊        | 2963/16104 [13:49:06<65:38:07, 17.98s/it]

 18%|█▊        | 2964/16104 [13:49:17<58:04:32, 15.91s/it]

 18%|█▊        | 2965/16104 [13:49:36<61:30:39, 16.85s/it]

 18%|█▊        | 2966/16104 [13:49:47<54:47:45, 15.01s/it]

 18%|█▊        | 2967/16104 [13:50:07<60:44:24, 16.64s/it]

 18%|█▊        | 2968/16104 [13:50:29<66:09:06, 18.13s/it]

 18%|█▊        | 2969/16104 [13:50:50<69:28:57, 19.04s/it]

 18%|█▊        | 2970/16104 [13:51:11<72:25:02, 19.85s/it]

 18%|█▊        | 2971/16104 [13:51:31<72:08:30, 19.78s/it]

 18%|█▊        | 2972/16104 [13:51:53<74:22:39, 20.39s/it]

 18%|█▊        | 2973/16104 [13:52:16<76:58:23, 21.10s/it]

 18%|█▊        | 2974/16104 [13:52:35<75:28:33, 20.69s/it]

 18%|█▊        | 2975/16104 [13:52:58<77:54:10, 21.36s/it]
[2024-04-06 05:26:55,573] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 18%|█▊        | 2976/16104 [13:53:11<68:34:45, 18.81s/it]

 18%|█▊        | 2977/16104 [13:53:23<60:54:48, 16.71s/it]

 18%|█▊        | 2978/16104 [13:53:35<55:33:10, 15.24s/it]

 18%|█▊        | 2979/16104 [13:53:53<58:41:22, 16.10s/it]

 19%|█▊        | 2980/16104 [13:54:08<57:23:17, 15.74s/it]

 19%|█▊        | 2981/16104 [13:54:21<54:29:40, 14.95s/it]

 19%|█▊        | 2982/16104 [13:54:34<52:53:21, 14.51s/it]

 19%|█▊        | 2983/16104 [13:54:54<58:27:40, 16.04s/it]

 19%|█▊        | 2984/16104 [13:55:11<60:04:33, 16.48s/it]

 19%|█▊        | 2985/16104 [13:55:26<57:54:39, 15.89s/it]

 19%|█▊        | 2986/16104 [13:55:42<57:29:58, 15.78s/it]

 19%|█▊        | 2987/16104 [13:56:02<63:01:09, 17.30s/it]

 19%|█▊        | 2988/16104 [13:56:22<65:29:46, 17.98s/it]

 19%|█▊        | 2989/16104 [13:56:38<63:45:42, 17.50s/it]

 19%|█▊        | 2990/16104 [13:56:51<58:01:28, 15.93s/it]

 19%|█▊        | 2991/16104 [13:57:04<55:28:23, 15.23s/it]

 19%|█▊        | 2992/16104 [13:57:24<60:42:25, 16.67s/it]

 19%|█▊        | 2993/16104 [13:57:41<60:29:22, 16.61s/it]

 19%|█▊        | 2994/16104 [13:58:01<64:01:14, 17.58s/it]
{'loss': 0.4349, 'learning_rate': 1.875258165574109e-06, 'rewards/chosen': -0.08145825564861298, 'rewards/rejected': -0.6858758330345154, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6044175624847412, 'policy_logps/rejected': -307.2654724121094, 'policy_logps/chosen': -349.8057861328125, 'referece_logps/rejected': -300.40673828125, 'referece_logps/chosen': -348.9911804199219, 'logits/rejected': -0.5511974692344666, 'logits/chosen': -0.315032422542572, 'epoch': 1.12}

 19%|█▊        | 2995/16104 [13:58:19<65:18:13, 17.93s/it]


 19%|█▊        | 2997/16104 [13:58:56<66:00:37, 18.13s/it]
{'loss': 0.4861, 'learning_rate': 1.8749661784440578e-06, 'rewards/chosen': -0.30342066287994385, 'rewards/rejected': -1.1958824396133423, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8924617767333984, 'policy_logps/rejected': -601.9725341796875, 'policy_logps/chosen': -510.43414306640625, 'referece_logps/rejected': -590.013671875, 'referece_logps/chosen': -507.3999328613281, 'logits/rejected': 0.6742730140686035, 'logits/chosen': 1.047418475151062, 'epoch': 1.12}


 19%|█▊        | 2999/16104 [13:59:34<67:02:48, 18.42s/it]

 19%|█▊        | 3000/16104 [13:59:48<61:25:21, 16.87s/it]
{'loss': 0.4804, 'learning_rate': 1.8746738727685254e-06, 'rewards/chosen': 0.2523941099643707, 'rewards/rejected': -1.010340690612793, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2627348899841309, 'policy_logps/rejected': -303.8891296386719, 'policy_logps/chosen': -408.8586120605469, 'referece_logps/rejected': -293.78570556640625, 'referece_logps/chosen': -411.38250732421875, 'logits/rejected': -0.32093140482902527, 'logits/chosen': -0.3099885880947113, 'epoch': 1.12}


 19%|█▊        | 3002/16104 [14:00:32<67:45:42, 18.62s/it]

 19%|█▊        | 3003/16104 [14:00:49<66:00:17, 18.14s/it]
{'loss': 0.6464, 'learning_rate': 1.8743812486539308e-06, 'rewards/chosen': 0.30917516350746155, 'rewards/rejected': 0.28990790247917175, 'rewards/accuracies': 0.625, 'rewards/margins': 0.0192672461271286, 'policy_logps/rejected': -532.0067138671875, 'policy_logps/chosen': -525.8237915039062, 'referece_logps/rejected': -534.90576171875, 'referece_logps/chosen': -528.9154663085938, 'logits/rejected': 0.824022650718689, 'logits/chosen': 0.7354182600975037, 'epoch': 1.12}


 19%|█▊        | 3005/16104 [14:01:21<63:33:13, 17.47s/it]

 19%|█▊        | 3006/16104 [14:01:40<65:52:05, 18.10s/it]

 19%|█▊        | 3007/16104 [14:02:00<67:51:29, 18.65s/it]
{'loss': 0.487, 'learning_rate': 1.8739905880023024e-06, 'rewards/chosen': -0.6543209552764893, 'rewards/rejected': -1.5126465559005737, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8583256006240845, 'policy_logps/rejected': -373.248779296875, 'policy_logps/chosen': -409.8875732421875, 'referece_logps/rejected': -358.122314453125, 'referece_logps/chosen': -403.3443603515625, 'logits/rejected': 0.06139346957206726, 'logits/chosen': 0.036517899483442307, 'epoch': 1.12}

 19%|█▊        | 3008/16104 [14:02:17<66:10:28, 18.19s/it]


 19%|█▊        | 3010/16104 [14:02:45<58:55:41, 16.20s/it]

 19%|█▊        | 3011/16104 [14:03:07<65:20:00, 17.96s/it]

 19%|█▊        | 3012/16104 [14:03:24<64:31:36, 17.74s/it]

 19%|█▊        | 3013/16104 [14:03:42<64:46:57, 17.82s/it]

 19%|█▊        | 3014/16104 [14:04:02<67:49:04, 18.65s/it]
[2024-04-06 05:37:59,755] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▊        | 3015/16104 [14:04:19<65:06:30, 17.91s/it]

 19%|█▊        | 3016/16104 [14:04:38<66:35:25, 18.32s/it]

 19%|█▊        | 3017/16104 [14:05:00<71:04:09, 19.55s/it]

 19%|█▊        | 3018/16104 [14:05:14<64:34:06, 17.76s/it]

 19%|█▊        | 3019/16104 [14:05:35<67:39:13, 18.61s/it]
{'loss': 0.708, 'learning_rate': 1.8728152130308302e-06, 'rewards/chosen': -0.6566243171691895, 'rewards/rejected': -0.6894999742507935, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03287559747695923, 'policy_logps/rejected': -378.5072937011719, 'policy_logps/chosen': -396.599853515625, 'referece_logps/rejected': -371.6123046875, 'referece_logps/chosen': -390.0335693359375, 'logits/rejected': -0.16499720513820648, 'logits/chosen': -0.12798109650611877, 'epoch': 1.12}


 19%|█▉        | 3021/16104 [14:06:05<60:29:42, 16.65s/it]

 19%|█▉        | 3022/16104 [14:06:23<62:10:33, 17.11s/it]

 19%|█▉        | 3023/16104 [14:06:43<64:55:35, 17.87s/it]

 19%|█▉        | 3024/16104 [14:06:59<63:29:02, 17.47s/it]

 19%|█▉        | 3025/16104 [14:07:13<59:10:51, 16.29s/it]

 19%|█▉        | 3026/16104 [14:07:35<65:34:33, 18.05s/it]

 19%|█▉        | 3027/16104 [14:07:54<67:13:30, 18.51s/it]

 19%|█▉        | 3028/16104 [14:08:13<67:16:04, 18.52s/it]

 19%|█▉        | 3029/16104 [14:08:24<59:19:18, 16.33s/it]
{'loss': 0.6084, 'learning_rate': 1.8718318498357406e-06, 'rewards/chosen': -0.8642629384994507, 'rewards/rejected': -1.1421828269958496, 'rewards/accuracies': 0.5, 'rewards/margins': 0.27791979908943176, 'policy_logps/rejected': -404.0391845703125, 'policy_logps/chosen': -448.43402099609375, 'referece_logps/rejected': -392.6173400878906, 'referece_logps/chosen': -439.7913818359375, 'logits/rejected': -0.724818229675293, 'logits/chosen': -0.6903315186500549, 'epoch': 1.13}


 19%|█▉        | 3031/16104 [14:09:00<61:07:41, 16.83s/it]

 19%|█▉        | 3032/16104 [14:09:14<58:45:29, 16.18s/it]
{'loss': 0.504, 'learning_rate': 1.8715361529865717e-06, 'rewards/chosen': 0.1337393820285797, 'rewards/rejected': -0.823538601398468, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9572780132293701, 'policy_logps/rejected': -414.6492919921875, 'policy_logps/chosen': -430.2251892089844, 'referece_logps/rejected': -406.4139099121094, 'referece_logps/chosen': -431.5626220703125, 'logits/rejected': -0.5753289461135864, 'logits/chosen': -0.5829623937606812, 'epoch': 1.13}

 19%|█▉        | 3033/16104 [14:09:36<64:57:11, 17.89s/it]


 19%|█▉        | 3035/16104 [14:10:07<62:03:25, 17.09s/it]

 19%|█▉        | 3036/16104 [14:10:23<60:46:05, 16.74s/it]

 19%|█▉        | 3037/16104 [14:10:38<59:02:01, 16.26s/it]

 19%|█▉        | 3038/16104 [14:10:56<60:50:10, 16.76s/it]

 19%|█▉        | 3039/16104 [14:11:07<54:38:15, 15.06s/it]
{'loss': 0.5747, 'learning_rate': 1.8708449599264182e-06, 'rewards/chosen': -0.6913810968399048, 'rewards/rejected': -1.0072811841964722, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3159000277519226, 'policy_logps/rejected': -487.16839599609375, 'policy_logps/chosen': -469.44427490234375, 'referece_logps/rejected': -477.0956115722656, 'referece_logps/chosen': -462.5304870605469, 'logits/rejected': 0.376629501581192, 'logits/chosen': 0.18141232430934906, 'epoch': 1.13}


 19%|█▉        | 3041/16104 [14:11:40<56:27:18, 15.56s/it]

 19%|█▉        | 3042/16104 [14:11:53<53:46:09, 14.82s/it]

 19%|█▉        | 3043/16104 [14:12:10<56:05:45, 15.46s/it]

 19%|█▉        | 3044/16104 [14:12:32<62:58:03, 17.36s/it]

 19%|█▉        | 3045/16104 [14:12:45<59:17:47, 16.35s/it]
{'loss': 0.5858, 'learning_rate': 1.8702511348181319e-06, 'rewards/chosen': -0.4695191979408264, 'rewards/rejected': -0.8990606069564819, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4295414984226227, 'policy_logps/rejected': -326.16094970703125, 'policy_logps/chosen': -422.4726867675781, 'referece_logps/rejected': -317.17034912109375, 'referece_logps/chosen': -417.7774963378906, 'logits/rejected': -0.648318886756897, 'logits/chosen': -0.5989736318588257, 'epoch': 1.13}

 19%|█▉        | 3046/16104 [14:12:58<55:21:39, 15.26s/it]


 19%|█▉        | 3048/16104 [14:13:37<63:17:37, 17.45s/it]
{'loss': 0.4812, 'learning_rate': 1.8699537469665713e-06, 'rewards/chosen': -0.3864527642726898, 'rewards/rejected': -0.6717108488082886, 'rewards/accuracies': 0.75, 'rewards/margins': 0.28525811433792114, 'policy_logps/rejected': -361.9936218261719, 'policy_logps/chosen': -443.3993225097656, 'referece_logps/rejected': -355.2765197753906, 'referece_logps/chosen': -439.5347900390625, 'logits/rejected': -0.5444638133049011, 'logits/chosen': -0.743162214756012, 'epoch': 1.14}


 19%|█▉        | 3050/16104 [14:14:15<67:06:11, 18.51s/it]

 19%|█▉        | 3051/16104 [14:14:30<63:13:18, 17.44s/it]

 19%|█▉        | 3052/16104 [14:14:49<65:25:27, 18.05s/it]
{'loss': 0.529, 'learning_rate': 1.8695567371733596e-06, 'rewards/chosen': -0.6096243262290955, 'rewards/rejected': -1.6633079051971436, 'rewards/accuracies': 0.5, 'rewards/margins': 1.0536836385726929, 'policy_logps/rejected': -353.76556396484375, 'policy_logps/chosen': -432.84698486328125, 'referece_logps/rejected': -337.1324462890625, 'referece_logps/chosen': -426.7507629394531, 'logits/rejected': -1.0179132223129272, 'logits/chosen': -1.1180939674377441, 'epoch': 1.14}


 19%|█▉        | 3054/16104 [14:15:19<60:13:49, 16.62s/it]

 19%|█▉        | 3055/16104 [14:15:35<59:31:10, 16.42s/it]

 19%|█▉        | 3056/16104 [14:15:49<57:31:28, 15.87s/it]

 19%|█▉        | 3057/16104 [14:16:01<52:40:30, 14.53s/it]
{'loss': 0.479, 'learning_rate': 1.8690596835217926e-06, 'rewards/chosen': 0.1710563749074936, 'rewards/rejected': -1.1545896530151367, 'rewards/accuracies': 0.875, 'rewards/margins': 1.325646162033081, 'policy_logps/rejected': -381.47967529296875, 'policy_logps/chosen': -509.0080871582031, 'referece_logps/rejected': -369.93377685546875, 'referece_logps/chosen': -510.7186279296875, 'logits/rejected': -0.5541549324989319, 'logits/chosen': -0.4260505437850952, 'epoch': 1.14}


 19%|█▉        | 3059/16104 [14:16:34<54:41:02, 15.09s/it]

 19%|█▉        | 3060/16104 [14:16:51<56:47:33, 15.67s/it]

 19%|█▉        | 3061/16104 [14:17:10<59:54:42, 16.54s/it]

 19%|█▉        | 3062/16104 [14:17:29<63:25:29, 17.51s/it]
{'loss': 0.5843, 'learning_rate': 1.868561750994921e-06, 'rewards/chosen': 0.1333419531583786, 'rewards/rejected': -1.0315498113632202, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1648918390274048, 'policy_logps/rejected': -505.91461181640625, 'policy_logps/chosen': -606.072265625, 'referece_logps/rejected': -495.5991516113281, 'referece_logps/chosen': -607.4056396484375, 'logits/rejected': -0.028603412210941315, 'logits/chosen': -0.11505022644996643, 'epoch': 1.14}


 19%|█▉        | 3064/16104 [14:18:10<68:10:02, 18.82s/it]

 19%|█▉        | 3065/16104 [14:18:28<67:15:05, 18.57s/it]

 19%|█▉        | 3066/16104 [14:18:49<70:22:21, 19.43s/it]

 19%|█▉        | 3067/16104 [14:19:07<68:57:50, 19.04s/it]

 19%|█▉        | 3068/16104 [14:19:25<67:36:57, 18.67s/it]

 19%|█▉        | 3069/16104 [14:19:38<60:54:03, 16.82s/it]

 19%|█▉        | 3070/16104 [14:20:01<68:27:48, 18.91s/it]
[2024-04-06 05:53:58,662] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4881, 'learning_rate': 1.8677632321485026e-06, 'rewards/chosen': -0.11462424695491791, 'rewards/rejected': -1.6983243227005005, 'rewards/accuracies': 0.625, 'rewards/margins': 1.583700180053711, 'policy_logps/rejected': -395.87359619140625, 'policy_logps/chosen': -585.8517456054688, 'referece_logps/rejected': -378.890380859375, 'referece_logps/chosen': -584.70556640625, 'logits/rejected': 0.1169375479221344, 'logits/chosen': 0.0024448633193969727, 'epoch': 1.14}


 19%|█▉        | 3072/16104 [14:20:38<68:17:40, 18.87s/it]
[2024-04-06 05:54:35,191] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▉        | 3073/16104 [14:20:51<62:29:40, 17.27s/it]
[2024-04-06 05:54:48,720] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 19%|█▉        | 3074/16104 [14:21:04<56:50:32, 15.70s/it]
{'loss': 0.5396, 'learning_rate': 1.8673631301343288e-06, 'rewards/chosen': -0.5944404602050781, 'rewards/rejected': -1.3671238422393799, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7726833820343018, 'policy_logps/rejected': -319.4798889160156, 'policy_logps/chosen': -322.29937744140625, 'referece_logps/rejected': -305.80865478515625, 'referece_logps/chosen': -316.35491943359375, 'logits/rejected': -0.26615583896636963, 'logits/chosen': -0.267513632774353, 'epoch': 1.15}


 19%|█▉        | 3076/16104 [14:21:28<50:41:31, 14.01s/it]

 19%|█▉        | 3077/16104 [14:21:42<50:43:15, 14.02s/it]

 19%|█▉        | 3078/16104 [14:21:58<53:07:54, 14.68s/it]

 19%|█▉        | 3079/16104 [14:22:16<56:35:31, 15.64s/it]

 19%|█▉        | 3080/16104 [14:22:35<60:40:43, 16.77s/it]

 19%|█▉        | 3081/16104 [14:22:56<64:16:38, 17.77s/it]
{'loss': 0.4044, 'learning_rate': 1.8666616009397004e-06, 'rewards/chosen': -0.06106968969106674, 'rewards/rejected': -1.0579173564910889, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9968475103378296, 'policy_logps/rejected': -207.47637939453125, 'policy_logps/chosen': -294.7403869628906, 'referece_logps/rejected': -196.897216796875, 'referece_logps/chosen': -294.1296691894531, 'logits/rejected': -0.24557563662528992, 'logits/chosen': -0.38251781463623047, 'epoch': 1.15}
[2024-04-06 05:57:08,046] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 19%|█▉        | 3083/16104 [14:23:30<63:32:50, 17.57s/it]

 19%|█▉        | 3084/16104 [14:23:50<66:06:39, 18.28s/it]
{'loss': 0.4291, 'learning_rate': 1.8663604196193333e-06, 'rewards/chosen': -0.6773788332939148, 'rewards/rejected': -1.5206879377365112, 'rewards/accuracies': 0.875, 'rewards/margins': 0.843309223651886, 'policy_logps/rejected': -189.40501403808594, 'policy_logps/chosen': -304.1818542480469, 'referece_logps/rejected': -174.19815063476562, 'referece_logps/chosen': -297.4080810546875, 'logits/rejected': -0.7146753072738647, 'logits/chosen': -0.8302379250526428, 'epoch': 1.15}

 19%|█▉        | 3085/16104 [14:24:05<62:29:24, 17.28s/it]


 19%|█▉        | 3087/16104 [14:24:42<64:39:09, 17.88s/it]
{'loss': 0.5379, 'learning_rate': 1.86605892288655e-06, 'rewards/chosen': 0.31448936462402344, 'rewards/rejected': -0.10432718694210052, 'rewards/accuracies': 0.75, 'rewards/margins': 0.41881656646728516, 'policy_logps/rejected': -452.0830078125, 'policy_logps/chosen': -481.85137939453125, 'referece_logps/rejected': -451.0396728515625, 'referece_logps/chosen': -484.99627685546875, 'logits/rejected': -0.16735005378723145, 'logits/chosen': -0.16714343428611755, 'epoch': 1.15}
[2024-04-06 05:58:59,874] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 19%|█▉        | 3089/16104 [14:25:20<66:42:42, 18.45s/it]
{'loss': 0.6279, 'learning_rate': 1.8658577498897744e-06, 'rewards/chosen': -0.5358679294586182, 'rewards/rejected': -0.694627583026886, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1587596833705902, 'policy_logps/rejected': -337.70404052734375, 'policy_logps/chosen': -387.971435546875, 'referece_logps/rejected': -330.7577819824219, 'referece_logps/chosen': -382.6127624511719, 'logits/rejected': -0.45460546016693115, 'logits/chosen': -0.3788679838180542, 'epoch': 1.15}


 19%|█▉        | 3091/16104 [14:25:54<63:04:04, 17.45s/it]

 19%|█▉        | 3092/16104 [14:26:08<59:15:06, 16.39s/it]
{'loss': 0.575, 'learning_rate': 1.8655557277136085e-06, 'rewards/chosen': -0.32935523986816406, 'rewards/rejected': -0.9482917785644531, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6189365983009338, 'policy_logps/rejected': -451.9473876953125, 'policy_logps/chosen': -481.021728515625, 'referece_logps/rejected': -442.46441650390625, 'referece_logps/chosen': -477.7281494140625, 'logits/rejected': 0.2100473940372467, 'logits/chosen': 0.22419460117816925, 'epoch': 1.15}

 19%|█▉        | 3093/16104 [14:26:25<59:40:25, 16.51s/it]

 19%|█▉        | 3094/16104 [14:26:37<54:53:22, 15.19s/it]


 19%|█▉        | 3096/16104 [14:27:14<60:46:12, 16.82s/it]

 19%|█▉        | 3097/16104 [14:27:28<58:07:39, 16.09s/it]
{'loss': 0.4899, 'learning_rate': 1.8650516572088938e-06, 'rewards/chosen': -0.2149963527917862, 'rewards/rejected': -0.627223014831543, 'rewards/accuracies': 0.625, 'rewards/margins': 0.41222670674324036, 'policy_logps/rejected': -282.3816223144531, 'policy_logps/chosen': -320.7455139160156, 'referece_logps/rejected': -276.109375, 'referece_logps/chosen': -318.5954895019531, 'logits/rejected': -0.06269175559282303, 'logits/chosen': -0.11229117214679718, 'epoch': 1.15}

 19%|█▉        | 3098/16104 [14:27:46<59:46:56, 16.55s/it]


 19%|█▉        | 3100/16104 [14:28:18<60:20:28, 16.70s/it]
[2024-04-06 06:02:15,585] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4308, 'learning_rate': 1.864748794958839e-06, 'rewards/chosen': -0.18097327649593353, 'rewards/rejected': -1.2306549549102783, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0496817827224731, 'policy_logps/rejected': -434.24468994140625, 'policy_logps/chosen': -507.34051513671875, 'referece_logps/rejected': -421.93817138671875, 'referece_logps/chosen': -505.53076171875, 'logits/rejected': 0.4896176755428314, 'logits/chosen': 0.3873758018016815, 'epoch': 1.15}


 19%|█▉        | 3102/16104 [14:28:46<54:19:09, 15.04s/it]
{'loss': 0.5688, 'learning_rate': 1.8645467118821698e-06, 'rewards/chosen': 0.09355201572179794, 'rewards/rejected': -0.7905322313308716, 'rewards/accuracies': 0.625, 'rewards/margins': 0.884084165096283, 'policy_logps/rejected': -316.1203308105469, 'policy_logps/chosen': -582.2472534179688, 'referece_logps/rejected': -308.2149963378906, 'referece_logps/chosen': -583.1828002929688, 'logits/rejected': -0.24865248799324036, 'logits/chosen': -0.561904788017273, 'epoch': 1.16}

 19%|█▉        | 3103/16104 [14:28:57<49:36:55, 13.74s/it]

 19%|█▉        | 3104/16104 [14:29:09<47:45:36, 13.23s/it]

 19%|█▉        | 3105/16104 [14:29:26<51:35:49, 14.29s/it]

 19%|█▉        | 3106/16104 [14:29:46<57:53:56, 16.04s/it]

 19%|█▉        | 3107/16104 [14:30:08<63:55:48, 17.71s/it]


 19%|█▉        | 3109/16104 [14:30:32<53:59:11, 14.96s/it]

 19%|█▉        | 3110/16104 [14:30:43<49:22:39, 13.68s/it]

 19%|█▉        | 3111/16104 [14:31:00<53:36:28, 14.85s/it]
{'loss': 0.4736, 'learning_rate': 1.863635607373157e-06, 'rewards/chosen': -0.29581910371780396, 'rewards/rejected': -1.0440435409545898, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7482246160507202, 'policy_logps/rejected': -272.7547607421875, 'policy_logps/chosen': -309.3816833496094, 'referece_logps/rejected': -262.3143310546875, 'referece_logps/chosen': -306.4234924316406, 'logits/rejected': 0.6997725963592529, 'logits/chosen': 0.7416655421257019, 'epoch': 1.16}


 19%|█▉        | 3113/16104 [14:31:33<57:00:29, 15.80s/it]

 19%|█▉        | 3114/16104 [14:31:46<54:34:00, 15.12s/it]
{'loss': 0.5467, 'learning_rate': 1.8633312768818055e-06, 'rewards/chosen': -0.08423042297363281, 'rewards/rejected': -0.9018202424049377, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8175897002220154, 'policy_logps/rejected': -451.12158203125, 'policy_logps/chosen': -464.1749267578125, 'referece_logps/rejected': -442.1033935546875, 'referece_logps/chosen': -463.3326110839844, 'logits/rejected': -0.25020721554756165, 'logits/chosen': -0.3270086348056793, 'epoch': 1.16}

 19%|█▉        | 3115/16104 [14:32:08<61:34:48, 17.07s/it]


 19%|█▉        | 3117/16104 [14:32:37<57:09:32, 15.84s/it]

 19%|█▉        | 3118/16104 [14:32:57<61:22:03, 17.01s/it]

 19%|█▉        | 3119/16104 [14:33:16<64:16:42, 17.82s/it]

 19%|█▉        | 3120/16104 [14:33:37<67:09:29, 18.62s/it]
{'loss': 0.498, 'learning_rate': 1.8627216730811882e-06, 'rewards/chosen': -0.5665113925933838, 'rewards/rejected': -0.8534160852432251, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2869047224521637, 'policy_logps/rejected': -310.21405029296875, 'policy_logps/chosen': -326.1812438964844, 'referece_logps/rejected': -301.67987060546875, 'referece_logps/chosen': -320.5160827636719, 'logits/rejected': -0.3235477805137634, 'logits/chosen': -0.3846679627895355, 'epoch': 1.16}

 19%|█▉        | 3121/16104 [14:33:53<64:59:08, 18.02s/it]


 19%|█▉        | 3123/16104 [14:34:30<65:59:16, 18.30s/it]
{'loss': 0.5505, 'learning_rate': 1.8624163999938587e-06, 'rewards/chosen': 0.08178215473890305, 'rewards/rejected': -0.8217685222625732, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9035508632659912, 'policy_logps/rejected': -436.4410705566406, 'policy_logps/chosen': -380.6981201171875, 'referece_logps/rejected': -428.223388671875, 'referece_logps/chosen': -381.51593017578125, 'logits/rejected': 0.3417208790779114, 'logits/chosen': 0.33663225173950195, 'epoch': 1.16}

 19%|█▉        | 3124/16104 [14:34:48<64:40:57, 17.94s/it]

 19%|█▉        | 3125/16104 [14:35:00<58:38:09, 16.26s/it]

 19%|█▉        | 3126/16104 [14:35:11<53:16:28, 14.78s/it]


 19%|█▉        | 3128/16104 [14:35:33<45:54:34, 12.74s/it]
{'loss': 0.5382, 'learning_rate': 1.8619069138442834e-06, 'rewards/chosen': 0.5788850784301758, 'rewards/rejected': -0.9772686958312988, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5561537742614746, 'policy_logps/rejected': -340.27508544921875, 'policy_logps/chosen': -559.4276123046875, 'referece_logps/rejected': -330.50244140625, 'referece_logps/chosen': -565.2164306640625, 'logits/rejected': 0.42959296703338623, 'logits/chosen': 0.6760994791984558, 'epoch': 1.17}

 19%|█▉        | 3129/16104 [14:35:48<48:19:17, 13.41s/it]

 19%|█▉        | 3130/16104 [14:36:07<55:00:22, 15.26s/it]

 19%|█▉        | 3131/16104 [14:36:18<50:02:05, 13.88s/it]

 19%|█▉        | 3132/16104 [14:36:30<48:12:24, 13.38s/it]


 19%|█▉        | 3134/16104 [14:37:05<54:40:19, 15.18s/it]
{'loss': 0.5114, 'learning_rate': 1.861294379943089e-06, 'rewards/chosen': -0.6743152141571045, 'rewards/rejected': -1.0443581342697144, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3700428605079651, 'policy_logps/rejected': -562.0951538085938, 'policy_logps/chosen': -730.7750854492188, 'referece_logps/rejected': -551.6514892578125, 'referece_logps/chosen': -724.0319213867188, 'logits/rejected': -1.0397484302520752, 'logits/chosen': -1.1720761060714722, 'epoch': 1.17}

 19%|█▉        | 3135/16104 [14:37:26<60:33:48, 16.81s/it]


 19%|█▉        | 3137/16104 [14:37:53<53:37:33, 14.89s/it]

 19%|█▉        | 3138/16104 [14:38:11<57:16:18, 15.90s/it]
{'loss': 0.5267, 'learning_rate': 1.8608853271360111e-06, 'rewards/chosen': 0.295162558555603, 'rewards/rejected': -0.5002377033233643, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7954001426696777, 'policy_logps/rejected': -328.77978515625, 'policy_logps/chosen': -429.5268249511719, 'referece_logps/rejected': -323.77740478515625, 'referece_logps/chosen': -432.4784851074219, 'logits/rejected': -0.6843129396438599, 'logits/chosen': -0.5384478569030762, 'epoch': 1.17}

 19%|█▉        | 3139/16104 [14:38:22<52:30:22, 14.58s/it]

 19%|█▉        | 3140/16104 [14:38:42<57:53:20, 16.08s/it]

 20%|█▉        | 3141/16104 [14:39:00<60:16:49, 16.74s/it]

 20%|█▉        | 3142/16104 [14:39:14<57:22:12, 15.93s/it]


 20%|█▉        | 3144/16104 [14:39:55<64:57:55, 18.05s/it]
{'loss': 0.5342, 'learning_rate': 1.8602707032778492e-06, 'rewards/chosen': -0.5414575338363647, 'rewards/rejected': -0.7842180728912354, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24276047945022583, 'policy_logps/rejected': -467.7442626953125, 'policy_logps/chosen': -412.67254638671875, 'referece_logps/rejected': -459.9021301269531, 'referece_logps/chosen': -407.25799560546875, 'logits/rejected': 0.5403522849082947, 'logits/chosen': 0.5186222195625305, 'epoch': 1.17}

 20%|█▉        | 3145/16104 [14:40:12<64:05:23, 17.80s/it]


 20%|█▉        | 3147/16104 [14:40:43<59:20:34, 16.49s/it]
{'loss': 0.4491, 'learning_rate': 1.8599629214997624e-06, 'rewards/chosen': 0.0896238312125206, 'rewards/rejected': -0.5448135137557983, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6344373822212219, 'policy_logps/rejected': -489.09722900390625, 'policy_logps/chosen': -495.4681396484375, 'referece_logps/rejected': -483.649169921875, 'referece_logps/chosen': -496.36431884765625, 'logits/rejected': 0.070152148604393, 'logits/chosen': -0.009508863091468811, 'epoch': 1.17}

 20%|█▉        | 3148/16104 [14:41:02<62:05:15, 17.25s/it]

 20%|█▉        | 3149/16104 [14:41:22<64:54:22, 18.04s/it]

 20%|█▉        | 3150/16104 [14:41:34<58:32:30, 16.27s/it]
[2024-04-06 06:15:55,527] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|█▉        | 3151/16104 [14:41:58<67:08:20, 18.66s/it]


 20%|█▉        | 3153/16104 [14:42:23<55:59:15, 15.56s/it]
{'loss': 0.536, 'learning_rate': 1.8593464188058423e-06, 'rewards/chosen': -0.2481878250837326, 'rewards/rejected': -1.2882139682769775, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0400261878967285, 'policy_logps/rejected': -474.9020690917969, 'policy_logps/chosen': -418.38836669921875, 'referece_logps/rejected': -462.0198974609375, 'referece_logps/chosen': -415.906494140625, 'logits/rejected': -0.5966607928276062, 'logits/chosen': -0.6659611463546753, 'epoch': 1.17}

 20%|█▉        | 3154/16104 [14:42:43<60:19:30, 16.77s/it]

 20%|█▉        | 3155/16104 [14:43:01<61:38:14, 17.14s/it]

 20%|█▉        | 3156/16104 [14:43:15<57:57:52, 16.12s/it]

 20%|█▉        | 3157/16104 [14:43:33<60:07:09, 16.72s/it]

 20%|█▉        | 3158/16104 [14:43:50<61:07:05, 17.00s/it]

 20%|█▉        | 3159/16104 [14:44:06<60:09:32, 16.73s/it]

 20%|█▉        | 3160/16104 [14:44:24<61:32:57, 17.12s/it]

 20%|█▉        | 3161/16104 [14:44:42<62:07:42, 17.28s/it]

 20%|█▉        | 3162/16104 [14:44:56<58:57:17, 16.40s/it]

 20%|█▉        | 3163/16104 [14:45:18<64:54:28, 18.06s/it]


 20%|█▉        | 3165/16104 [14:45:55<67:06:55, 18.67s/it]
[2024-04-06 06:19:52,760] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.553, 'learning_rate': 1.858109660011676e-06, 'rewards/chosen': 0.009244341403245926, 'rewards/rejected': -0.5682366490364075, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5774809718132019, 'policy_logps/rejected': -579.8623657226562, 'policy_logps/chosen': -458.3990478515625, 'referece_logps/rejected': -574.1799926757812, 'referece_logps/chosen': -458.49151611328125, 'logits/rejected': 0.157507985830307, 'logits/chosen': 0.29749470949172974, 'epoch': 1.18}


 20%|█▉        | 3167/16104 [14:46:27<60:17:40, 16.78s/it]

 20%|█▉        | 3168/16104 [14:46:45<61:53:17, 17.22s/it]
{'loss': 0.4651, 'learning_rate': 1.8577996890099489e-06, 'rewards/chosen': -0.21202602982521057, 'rewards/rejected': -0.9276847243309021, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7156586050987244, 'policy_logps/rejected': -360.834228515625, 'policy_logps/chosen': -492.6175537109375, 'referece_logps/rejected': -351.5573425292969, 'referece_logps/chosen': -490.4972839355469, 'logits/rejected': -0.022052913904190063, 'logits/chosen': -0.16255365312099457, 'epoch': 1.18}


 20%|█▉        | 3170/16104 [14:47:15<56:26:50, 15.71s/it]

 20%|█▉        | 3171/16104 [14:47:34<59:21:49, 16.52s/it]

 20%|█▉        | 3172/16104 [14:47:53<62:38:04, 17.44s/it]

 20%|█▉        | 3173/16104 [14:48:12<63:46:42, 17.76s/it]

 20%|█▉        | 3174/16104 [14:48:34<67:54:28, 18.91s/it]

 20%|█▉        | 3175/16104 [14:48:54<69:11:05, 19.26s/it]

 20%|█▉        | 3176/16104 [14:49:08<63:35:23, 17.71s/it]

 20%|█▉        | 3177/16104 [14:49:30<68:34:44, 19.10s/it]

 20%|█▉        | 3178/16104 [14:49:46<64:41:44, 18.02s/it]

 20%|█▉        | 3179/16104 [14:50:04<64:43:28, 18.03s/it]
{'loss': 0.4076, 'learning_rate': 1.8566604576661287e-06, 'rewards/chosen': -0.5828825235366821, 'rewards/rejected': -2.3917183876037598, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8088359832763672, 'policy_logps/rejected': -541.906005859375, 'policy_logps/chosen': -351.4753723144531, 'referece_logps/rejected': -517.98876953125, 'referece_logps/chosen': -345.6465148925781, 'logits/rejected': 0.4696267247200012, 'logits/chosen': 0.5250169634819031, 'epoch': 1.18}

 20%|█▉        | 3180/16104 [14:50:23<66:19:02, 18.47s/it]

 20%|█▉        | 3181/16104 [14:50:40<65:03:46, 18.12s/it]

 20%|█▉        | 3182/16104 [14:50:53<58:46:00, 16.37s/it]

 20%|█▉        | 3183/16104 [14:51:03<52:34:56, 14.65s/it]


 20%|█▉        | 3185/16104 [14:51:46<64:53:51, 18.08s/it]
{'loss': 0.5005, 'learning_rate': 1.85603729106944e-06, 'rewards/chosen': -0.25405368208885193, 'rewards/rejected': -1.009839415550232, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7557858228683472, 'policy_logps/rejected': -258.27392578125, 'policy_logps/chosen': -366.7344970703125, 'referece_logps/rejected': -248.175537109375, 'referece_logps/chosen': -364.1939697265625, 'logits/rejected': -0.2695348560810089, 'logits/chosen': -0.04283084720373154, 'epoch': 1.19}

 20%|█▉        | 3186/16104 [14:51:59<60:08:18, 16.76s/it]


 20%|█▉        | 3188/16104 [14:52:36<63:57:32, 17.83s/it]
[2024-04-06 06:26:33,109] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5684, 'learning_rate': 1.8557252402331752e-06, 'rewards/chosen': -0.37244775891304016, 'rewards/rejected': -1.58941650390625, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2169687747955322, 'policy_logps/rejected': -401.98675537109375, 'policy_logps/chosen': -576.598876953125, 'referece_logps/rejected': -386.0925598144531, 'referece_logps/chosen': -572.8743896484375, 'logits/rejected': 0.4196282625198364, 'logits/chosen': 0.5624236464500427, 'epoch': 1.19}
[2024-04-06 06:26:50,081] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|█▉        | 3189/16104 [14:52:53<63:02:02, 17.57s/it]

 20%|█▉        | 3190/16104 [14:53:12<65:10:13, 18.17s/it]


 20%|█▉        | 3192/16104 [14:53:50<66:38:31, 18.58s/it]
{'loss': 0.5428, 'learning_rate': 1.855308687852572e-06, 'rewards/chosen': 0.11432762444019318, 'rewards/rejected': -1.2544721364974976, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3687996864318848, 'policy_logps/rejected': -381.14300537109375, 'policy_logps/chosen': -336.0370178222656, 'referece_logps/rejected': -368.5982360839844, 'referece_logps/chosen': -337.1802978515625, 'logits/rejected': -0.7370941638946533, 'logits/chosen': -0.3855254650115967, 'epoch': 1.19}


 20%|█▉        | 3194/16104 [14:54:22<61:51:04, 17.25s/it]
{'loss': 0.4486, 'learning_rate': 1.8551002040528406e-06, 'rewards/chosen': -0.5443662405014038, 'rewards/rejected': -1.3278870582580566, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7835207581520081, 'policy_logps/rejected': -299.85235595703125, 'policy_logps/chosen': -376.326904296875, 'referece_logps/rejected': -286.573486328125, 'referece_logps/chosen': -370.8832092285156, 'logits/rejected': -1.0741775035858154, 'logits/chosen': -0.8533121347427368, 'epoch': 1.19}
[2024-04-06 06:28:40,748] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|█▉        | 3195/16104 [14:54:43<66:20:15, 18.50s/it]
[2024-04-06 06:28:54,076] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|█▉        | 3196/16104 [14:54:57<60:46:13, 16.95s/it]

 20%|█▉        | 3197/16104 [14:55:16<62:42:03, 17.49s/it]

 20%|█▉        | 3198/16104 [14:55:26<55:38:33, 15.52s/it]


 20%|█▉        | 3200/16104 [14:55:52<51:15:03, 14.30s/it]
{'loss': 0.4734, 'learning_rate': 1.8544739226208024e-06, 'rewards/chosen': -0.332768052816391, 'rewards/rejected': -1.0829665660858154, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7501985430717468, 'policy_logps/rejected': -408.55047607421875, 'policy_logps/chosen': -326.234130859375, 'referece_logps/rejected': -397.72076416015625, 'referece_logps/chosen': -322.906494140625, 'logits/rejected': -0.18984368443489075, 'logits/chosen': -0.2641887068748474, 'epoch': 1.19}

 20%|█▉        | 3201/16104 [14:56:06<51:26:58, 14.35s/it]


 20%|█▉        | 3203/16104 [14:56:48<62:47:19, 17.52s/it]
{'loss': 0.4448, 'learning_rate': 1.8541603152203335e-06, 'rewards/chosen': 0.24524268507957458, 'rewards/rejected': -0.702117919921875, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9473605751991272, 'policy_logps/rejected': -435.7293701171875, 'policy_logps/chosen': -457.342041015625, 'referece_logps/rejected': -428.70819091796875, 'referece_logps/chosen': -459.79449462890625, 'logits/rejected': 0.9530624151229858, 'logits/chosen': 0.9947699308395386, 'epoch': 1.19}

 20%|█▉        | 3204/16104 [14:57:08<65:10:56, 18.19s/it]

 20%|█▉        | 3205/16104 [14:57:26<64:50:17, 18.10s/it]

 20%|█▉        | 3206/16104 [14:57:47<68:15:16, 19.05s/it]
[2024-04-06 06:32:04,880] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|█▉        | 3207/16104 [14:58:08<69:56:10, 19.52s/it]

 20%|█▉        | 3208/16104 [14:58:23<65:08:59, 18.19s/it]

 20%|█▉        | 3209/16104 [14:58:40<64:24:43, 17.98s/it]

 20%|█▉        | 3210/16104 [14:58:59<65:14:08, 18.21s/it]

 20%|█▉        | 3211/16104 [14:59:17<65:08:28, 18.19s/it]

 20%|█▉        | 3212/16104 [14:59:34<63:28:12, 17.72s/it]

 20%|█▉        | 3213/16104 [14:59:48<59:27:31, 16.60s/it]

 20%|█▉        | 3214/16104 [15:00:08<63:51:12, 17.83s/it]

 20%|█▉        | 3215/16104 [15:00:20<57:32:35, 16.07s/it]

 20%|█▉        | 3216/16104 [15:00:31<51:54:55, 14.50s/it]

 20%|█▉        | 3217/16104 [15:00:51<57:42:23, 16.12s/it]

 20%|█▉        | 3218/16104 [15:01:13<63:46:58, 17.82s/it]

 20%|█▉        | 3219/16104 [15:01:29<61:47:36, 17.26s/it]

 20%|█▉        | 3220/16104 [15:01:47<63:11:19, 17.66s/it]

 20%|██        | 3221/16104 [15:02:00<57:26:00, 16.05s/it]

 20%|██        | 3222/16104 [15:02:14<55:30:34, 15.51s/it]
[2024-04-06 06:36:33,311] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 3223/16104 [15:02:36<62:31:41, 17.48s/it]
[2024-04-06 06:36:49,851] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 3224/16104 [15:02:53<61:31:09, 17.19s/it]

 20%|██        | 3225/16104 [15:03:10<62:05:49, 17.36s/it]

 20%|██        | 3226/16104 [15:03:30<64:28:47, 18.03s/it]

 20%|██        | 3227/16104 [15:03:42<57:39:30, 16.12s/it]

 20%|██        | 3228/16104 [15:04:03<62:57:57, 17.60s/it]

 20%|██        | 3229/16104 [15:04:16<58:35:55, 16.38s/it]

 20%|██        | 3230/16104 [15:04:37<63:00:56, 17.62s/it]

 20%|██        | 3231/16104 [15:04:53<61:55:46, 17.32s/it]

 20%|██        | 3232/16104 [15:05:04<54:45:56, 15.32s/it]
[2024-04-06 06:39:22,049] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 3233/16104 [15:05:25<60:40:35, 16.97s/it]

 20%|██        | 3234/16104 [15:05:48<67:03:56, 18.76s/it]

 20%|██        | 3235/16104 [15:06:08<68:22:51, 19.13s/it]

 20%|██        | 3236/16104 [15:06:22<63:38:38, 17.81s/it]

 20%|██        | 3237/16104 [15:06:39<62:29:21, 17.48s/it]

 20%|██        | 3238/16104 [15:06:55<60:57:53, 17.06s/it]

 20%|██        | 3239/16104 [15:07:06<54:03:29, 15.13s/it]

 20%|██        | 3240/16104 [15:07:20<52:39:40, 14.74s/it]
[2024-04-06 06:41:38,337] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 3241/16104 [15:07:41<59:47:58, 16.74s/it]

 20%|██        | 3242/16104 [15:08:01<63:05:03, 17.66s/it]

 20%|██        | 3243/16104 [15:08:23<67:27:31, 18.88s/it]

 20%|██        | 3244/16104 [15:08:44<70:34:46, 19.76s/it]

 20%|██        | 3245/16104 [15:08:58<63:50:56, 17.88s/it]

 20%|██        | 3246/16104 [15:09:15<62:31:15, 17.50s/it]

 20%|██        | 3247/16104 [15:09:35<65:14:25, 18.27s/it]
[2024-04-06 06:43:53,006] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 3248/16104 [15:09:56<68:19:25, 19.13s/it]

 20%|██        | 3249/16104 [15:10:07<60:09:18, 16.85s/it]
{'loss': 0.5995, 'learning_rate': 1.849312796563545e-06, 'rewards/chosen': -0.126613050699234, 'rewards/rejected': -0.9832884669303894, 'rewards/accuracies': 0.75, 'rewards/margins': 0.856675386428833, 'policy_logps/rejected': -430.2166748046875, 'policy_logps/chosen': -562.7522583007812, 'referece_logps/rejected': -420.3837890625, 'referece_logps/chosen': -561.486083984375, 'logits/rejected': -0.005956366658210754, 'logits/chosen': 0.014639630913734436, 'epoch': 1.21}
[2024-04-06 06:44:24,820] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 3250/16104 [15:10:28<63:51:11, 17.88s/it]


 20%|██        | 3252/16104 [15:11:09<69:51:36, 19.57s/it]
{'loss': 0.5339, 'learning_rate': 1.8489941243526923e-06, 'rewards/chosen': -0.3127996623516083, 'rewards/rejected': -0.5165471434593201, 'rewards/accuracies': 0.625, 'rewards/margins': 0.20374751091003418, 'policy_logps/rejected': -458.13623046875, 'policy_logps/chosen': -395.77398681640625, 'referece_logps/rejected': -452.97076416015625, 'referece_logps/chosen': -392.64599609375, 'logits/rejected': -0.03488343954086304, 'logits/chosen': -0.06938465684652328, 'epoch': 1.21}
[2024-04-06 06:45:23,847] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 3253/16104 [15:11:27<67:18:13, 18.85s/it]

 20%|██        | 3254/16104 [15:11:40<61:03:48, 17.11s/it]


 20%|██        | 3256/16104 [15:12:15<62:07:26, 17.41s/it]
{'loss': 0.5213, 'learning_rate': 1.8485687472850537e-06, 'rewards/chosen': 0.15681268274784088, 'rewards/rejected': -0.9257965087890625, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0826092958450317, 'policy_logps/rejected': -365.7452087402344, 'policy_logps/chosen': -352.058837890625, 'referece_logps/rejected': -356.48724365234375, 'referece_logps/chosen': -353.62701416015625, 'logits/rejected': -0.32182079553604126, 'logits/chosen': -0.21087069809436798, 'epoch': 1.21}


 20%|██        | 3258/16104 [15:12:47<58:41:03, 16.45s/it]

 20%|██        | 3259/16104 [15:13:07<62:33:21, 17.53s/it]

 20%|██        | 3260/16104 [15:13:24<62:43:44, 17.58s/it]

 20%|██        | 3261/16104 [15:13:37<57:33:05, 16.13s/it]

 20%|██        | 3262/16104 [15:13:51<55:01:13, 15.42s/it]

 20%|██        | 3263/16104 [15:14:10<59:06:23, 16.57s/it]

 20%|██        | 3264/16104 [15:14:30<62:41:55, 17.58s/it]

 20%|██        | 3265/16104 [15:14:49<64:11:00, 18.00s/it]

 20%|██        | 3266/16104 [15:15:09<65:52:04, 18.47s/it]

 20%|██        | 3267/16104 [15:15:28<66:25:52, 18.63s/it]

 20%|██        | 3268/16104 [15:15:46<66:04:07, 18.53s/it]

 20%|██        | 3269/16104 [15:16:00<61:32:18, 17.26s/it]

 20%|██        | 3270/16104 [15:16:21<65:15:47, 18.31s/it]

 20%|██        | 3271/16104 [15:16:41<66:41:33, 18.71s/it]

 20%|██        | 3272/16104 [15:17:01<67:58:08, 19.07s/it]

 20%|██        | 3273/16104 [15:17:17<64:59:07, 18.23s/it]

 20%|██        | 3274/16104 [15:17:37<66:50:34, 18.76s/it]

 20%|██        | 3275/16104 [15:17:58<69:47:06, 19.58s/it]

 20%|██        | 3276/16104 [15:18:14<65:24:35, 18.36s/it]

 20%|██        | 3277/16104 [15:18:32<65:14:20, 18.31s/it]

 20%|██        | 3278/16104 [15:18:48<62:36:16, 17.57s/it]

 20%|██        | 3279/16104 [15:19:08<65:41:53, 18.44s/it]

 20%|██        | 3280/16104 [15:19:27<66:19:59, 18.62s/it]

 20%|██        | 3281/16104 [15:19:40<59:35:43, 16.73s/it]

 20%|██        | 3282/16104 [15:19:57<59:57:41, 16.84s/it]

 20%|██        | 3283/16104 [15:20:10<55:37:33, 15.62s/it]

 20%|██        | 3284/16104 [15:20:27<57:35:25, 16.17s/it]

 20%|██        | 3285/16104 [15:20:48<62:14:51, 17.48s/it]

 20%|██        | 3286/16104 [15:21:00<56:54:32, 15.98s/it]

 20%|██        | 3287/16104 [15:21:14<54:09:51, 15.21s/it]

 20%|██        | 3288/16104 [15:21:32<57:53:34, 16.26s/it]

 20%|██        | 3289/16104 [15:21:53<63:12:20, 17.76s/it]
[2024-04-06 06:55:50,769] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 20%|██        | 3290/16104 [15:22:10<62:18:08, 17.50s/it]

 20%|██        | 3291/16104 [15:22:29<63:16:30, 17.78s/it]

 20%|██        | 3292/16104 [15:22:49<66:03:42, 18.56s/it]

 20%|██        | 3293/16104 [15:23:06<64:12:54, 18.05s/it]

 20%|██        | 3294/16104 [15:23:27<67:23:24, 18.94s/it]

 20%|██        | 3295/16104 [15:23:49<70:20:40, 19.77s/it]

 20%|██        | 3296/16104 [15:24:03<64:33:21, 18.15s/it]

 20%|██        | 3297/16104 [15:24:19<62:37:09, 17.60s/it]

 20%|██        | 3298/16104 [15:24:40<66:06:10, 18.58s/it]

 20%|██        | 3299/16104 [15:25:00<66:49:50, 18.79s/it]

 20%|██        | 3300/16104 [15:25:16<64:37:28, 18.17s/it]

 20%|██        | 3301/16104 [15:25:32<61:54:01, 17.41s/it]

 21%|██        | 3302/16104 [15:25:47<59:46:09, 16.81s/it]

 21%|██        | 3303/16104 [15:26:04<59:35:59, 16.76s/it]

 21%|██        | 3304/16104 [15:26:23<61:35:03, 17.32s/it]

 21%|██        | 3305/16104 [15:26:42<64:13:26, 18.06s/it]

 21%|██        | 3306/16104 [15:27:01<64:32:57, 18.16s/it]

 21%|██        | 3307/16104 [15:27:16<61:02:44, 17.17s/it]
{'loss': 0.5706, 'learning_rate': 1.84309714226284e-06, 'rewards/chosen': -0.6544898152351379, 'rewards/rejected': -1.360864281654358, 'rewards/accuracies': 0.625, 'rewards/margins': 0.70637446641922, 'policy_logps/rejected': -506.1932373046875, 'policy_logps/chosen': -409.14642333984375, 'referece_logps/rejected': -492.5845642089844, 'referece_logps/chosen': -402.6015625, 'logits/rejected': -0.2358528971672058, 'logits/chosen': -0.2959437966346741, 'epoch': 1.23}


 21%|██        | 3309/16104 [15:27:52<62:10:31, 17.49s/it]

 21%|██        | 3310/16104 [15:28:03<55:41:51, 15.67s/it]

 21%|██        | 3311/16104 [15:28:24<61:42:14, 17.36s/it]
[2024-04-06 07:02:21,650] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 21%|██        | 3312/16104 [15:28:40<60:15:16, 16.96s/it]

 21%|██        | 3313/16104 [15:28:51<53:30:38, 15.06s/it]

 21%|██        | 3314/16104 [15:29:04<50:45:37, 14.29s/it]

 21%|██        | 3315/16104 [15:29:20<53:33:59, 15.08s/it]

 21%|██        | 3316/16104 [15:29:37<55:12:53, 15.54s/it]

 21%|██        | 3317/16104 [15:29:50<52:27:25, 14.77s/it]

 21%|██        | 3318/16104 [15:30:10<57:37:12, 16.22s/it]

 21%|██        | 3319/16104 [15:30:26<57:55:49, 16.31s/it]

 21%|██        | 3320/16104 [15:30:45<60:50:38, 17.13s/it]
{'loss': 0.5596, 'learning_rate': 1.8416882088704978e-06, 'rewards/chosen': -0.12380686402320862, 'rewards/rejected': -1.6168230772018433, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4930164813995361, 'policy_logps/rejected': -311.36614990234375, 'policy_logps/chosen': -316.1166687011719, 'referece_logps/rejected': -295.19793701171875, 'referece_logps/chosen': -314.87860107421875, 'logits/rejected': -0.5708397626876831, 'logits/chosen': -0.5242587327957153, 'epoch': 1.24}


 21%|██        | 3322/16104 [15:31:19<60:29:51, 17.04s/it]

 21%|██        | 3323/16104 [15:31:34<58:09:18, 16.38s/it]

 21%|██        | 3324/16104 [15:31:51<59:04:12, 16.64s/it]

 21%|██        | 3325/16104 [15:32:11<62:35:04, 17.63s/it]
{'loss': 0.4243, 'learning_rate': 1.8411447787348422e-06, 'rewards/chosen': -0.7124066948890686, 'rewards/rejected': -1.5584875345230103, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8460808992385864, 'policy_logps/rejected': -477.29742431640625, 'policy_logps/chosen': -499.5021667480469, 'referece_logps/rejected': -461.7125549316406, 'referece_logps/chosen': -492.37811279296875, 'logits/rejected': -0.28436923027038574, 'logits/chosen': -0.46464961767196655, 'epoch': 1.24}


 21%|██        | 3327/16104 [15:32:44<58:48:03, 16.57s/it]
{'loss': 0.4931, 'learning_rate': 1.8409271684691437e-06, 'rewards/chosen': 0.011290464550256729, 'rewards/rejected': -1.093834400177002, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1051249504089355, 'policy_logps/rejected': -440.1623840332031, 'policy_logps/chosen': -393.1540832519531, 'referece_logps/rejected': -429.2240295410156, 'referece_logps/chosen': -393.2669677734375, 'logits/rejected': -0.09221534430980682, 'logits/chosen': -0.14461416006088257, 'epoch': 1.24}


 21%|██        | 3329/16104 [15:33:19<60:41:59, 17.11s/it]

 21%|██        | 3330/16104 [15:33:32<55:23:31, 15.61s/it]
{'loss': 0.4698, 'learning_rate': 1.8406004979540727e-06, 'rewards/chosen': 0.13853131234645844, 'rewards/rejected': -1.491163969039917, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6296952962875366, 'policy_logps/rejected': -512.5387573242188, 'policy_logps/chosen': -463.733154296875, 'referece_logps/rejected': -497.62713623046875, 'referece_logps/chosen': -465.118408203125, 'logits/rejected': -0.2455928772687912, 'logits/chosen': -0.07541577517986298, 'epoch': 1.24}


 21%|██        | 3332/16104 [15:34:01<54:26:52, 15.35s/it]
{'loss': 0.427, 'learning_rate': 1.8403825475844e-06, 'rewards/chosen': -0.35440921783447266, 'rewards/rejected': -1.000000238418579, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6455910205841064, 'policy_logps/rejected': -450.3593444824219, 'policy_logps/chosen': -434.44305419921875, 'referece_logps/rejected': -440.35931396484375, 'referece_logps/chosen': -430.89898681640625, 'logits/rejected': 0.0028317421674728394, 'logits/chosen': -0.18376271426677704, 'epoch': 1.24}


 21%|██        | 3334/16104 [15:34:45<66:35:46, 18.77s/it]

 21%|██        | 3335/16104 [15:35:01<64:15:01, 18.11s/it]

 21%|██        | 3336/16104 [15:35:18<62:37:06, 17.66s/it]

 21%|██        | 3337/16104 [15:35:35<62:22:35, 17.59s/it]

 21%|██        | 3338/16104 [15:35:56<65:04:07, 18.35s/it]

 21%|██        | 3339/16104 [15:36:16<67:02:46, 18.91s/it]

 21%|██        | 3340/16104 [15:36:34<66:14:12, 18.68s/it]

 21%|██        | 3341/16104 [15:36:54<67:53:01, 19.15s/it]
[2024-04-06 07:10:51,496] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 21%|██        | 3342/16104 [15:37:14<69:04:14, 19.48s/it]

 21%|██        | 3343/16104 [15:37:34<69:36:58, 19.64s/it]

 21%|██        | 3344/16104 [15:37:47<61:37:48, 17.39s/it]

 21%|██        | 3345/16104 [15:38:04<62:08:12, 17.53s/it]
{'loss': 0.5451, 'learning_rate': 1.8389625572496597e-06, 'rewards/chosen': -0.8600620031356812, 'rewards/rejected': -1.3146700859069824, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4546080231666565, 'policy_logps/rejected': -298.3262023925781, 'policy_logps/chosen': -289.45294189453125, 'referece_logps/rejected': -285.1794738769531, 'referece_logps/chosen': -280.8523254394531, 'logits/rejected': -1.0511072874069214, 'logits/chosen': -1.1286917924880981, 'epoch': 1.25}


 21%|██        | 3347/16104 [15:38:44<65:33:35, 18.50s/it]

 21%|██        | 3348/16104 [15:39:07<70:37:59, 19.93s/it]
{'loss': 0.4232, 'learning_rate': 1.8386340523178111e-06, 'rewards/chosen': -0.5833921432495117, 'rewards/rejected': -2.0264651775360107, 'rewards/accuracies': 1.0, 'rewards/margins': 1.443073034286499, 'policy_logps/rejected': -287.4621276855469, 'policy_logps/chosen': -271.5450134277344, 'referece_logps/rejected': -267.1974792480469, 'referece_logps/chosen': -265.7110900878906, 'logits/rejected': -0.14200085401535034, 'logits/chosen': -0.17046421766281128, 'epoch': 1.25}


 21%|██        | 3350/16104 [15:39:40<64:39:18, 18.25s/it]

 21%|██        | 3351/16104 [15:39:59<64:47:10, 18.29s/it]

 21%|██        | 3352/16104 [15:40:14<62:00:04, 17.50s/it]
{'loss': 0.5948, 'learning_rate': 1.8381955708232977e-06, 'rewards/chosen': 0.3756282329559326, 'rewards/rejected': -0.06639803946018219, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4420263171195984, 'policy_logps/rejected': -474.29608154296875, 'policy_logps/chosen': -568.4930419921875, 'referece_logps/rejected': -473.632080078125, 'referece_logps/chosen': -572.249267578125, 'logits/rejected': 0.0698443278670311, 'logits/chosen': 0.14849887788295746, 'epoch': 1.25}

 21%|██        | 3353/16104 [15:40:36<65:55:46, 18.61s/it]


 21%|██        | 3355/16104 [15:41:12<65:03:19, 18.37s/it]

 21%|██        | 3356/16104 [15:41:25<58:33:23, 16.54s/it]

 21%|██        | 3357/16104 [15:41:38<55:14:01, 15.60s/it]

 21%|██        | 3358/16104 [15:41:54<55:47:55, 15.76s/it]
{'loss': 0.5142, 'learning_rate': 1.8375368314751642e-06, 'rewards/chosen': -0.9340773224830627, 'rewards/rejected': -1.465152621269226, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5310754179954529, 'policy_logps/rejected': -359.7660217285156, 'policy_logps/chosen': -400.6967468261719, 'referece_logps/rejected': -345.1144714355469, 'referece_logps/chosen': -391.3559875488281, 'logits/rejected': -0.7281132936477661, 'logits/chosen': -0.4979091286659241, 'epoch': 1.25}

 21%|██        | 3359/16104 [15:42:14<59:37:48, 16.84s/it]

 21%|██        | 3360/16104 [15:42:29<58:37:27, 16.56s/it]


 21%|██        | 3362/16104 [15:43:03<57:49:54, 16.34s/it]

 21%|██        | 3363/16104 [15:43:23<62:11:17, 17.57s/it]

 21%|██        | 3364/16104 [15:43:41<62:22:29, 17.63s/it]

 21%|██        | 3365/16104 [15:43:53<56:48:41, 16.05s/it]

 21%|██        | 3366/16104 [15:44:11<57:52:55, 16.36s/it]

 21%|██        | 3367/16104 [15:44:31<62:31:37, 17.67s/it]

 21%|██        | 3368/16104 [15:44:48<61:42:54, 17.44s/it]

 21%|██        | 3369/16104 [15:45:11<67:38:38, 19.12s/it]

 21%|██        | 3370/16104 [15:45:29<66:01:06, 18.66s/it]

 21%|██        | 3371/16104 [15:45:49<67:08:24, 18.98s/it]

 21%|██        | 3372/16104 [15:46:07<66:24:02, 18.77s/it]
{'loss': 0.4564, 'learning_rate': 1.8359950314778009e-06, 'rewards/chosen': -0.24040371179580688, 'rewards/rejected': -1.0690425634384155, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8286389112472534, 'policy_logps/rejected': -365.4071044921875, 'policy_logps/chosen': -390.40191650390625, 'referece_logps/rejected': -354.7166748046875, 'referece_logps/chosen': -387.9978942871094, 'logits/rejected': -0.33049434423446655, 'logits/chosen': -0.4184252619743347, 'epoch': 1.26}


 21%|██        | 3374/16104 [15:46:43<64:34:58, 18.26s/it]

 21%|██        | 3375/16104 [15:47:02<66:01:00, 18.67s/it]

 21%|██        | 3376/16104 [15:47:20<65:17:59, 18.47s/it]

 21%|██        | 3377/16104 [15:47:32<58:14:16, 16.47s/it]

 21%|██        | 3378/16104 [15:47:44<53:45:45, 15.21s/it]

 21%|██        | 3379/16104 [15:48:02<55:42:41, 15.76s/it]
{'loss': 0.5655, 'learning_rate': 1.8352216451291072e-06, 'rewards/chosen': -0.42599907517433167, 'rewards/rejected': -1.4219344854354858, 'rewards/accuracies': 0.875, 'rewards/margins': 0.995935320854187, 'policy_logps/rejected': -402.0539245605469, 'policy_logps/chosen': -382.0802917480469, 'referece_logps/rejected': -387.83453369140625, 'referece_logps/chosen': -377.8202819824219, 'logits/rejected': -0.3670268952846527, 'logits/chosen': -0.2846073806285858, 'epoch': 1.26}


 21%|██        | 3381/16104 [15:48:27<50:43:01, 14.35s/it]

 21%|██        | 3382/16104 [15:48:49<57:58:54, 16.41s/it]

 21%|██        | 3383/16104 [15:49:04<57:17:19, 16.21s/it]

 21%|██        | 3384/16104 [15:49:18<54:57:05, 15.55s/it]
{'loss': 0.4316, 'learning_rate': 1.834668212633081e-06, 'rewards/chosen': -0.11226978152990341, 'rewards/rejected': -1.800146460533142, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6878767013549805, 'policy_logps/rejected': -454.43646240234375, 'policy_logps/chosen': -391.3864440917969, 'referece_logps/rejected': -436.4349670410156, 'referece_logps/chosen': -390.2637634277344, 'logits/rejected': -0.11827534437179565, 'logits/chosen': -0.1450287252664566, 'epoch': 1.26}


 21%|██        | 3386/16104 [15:49:54<58:43:23, 16.62s/it]
{'loss': 0.4641, 'learning_rate': 1.834446603256588e-06, 'rewards/chosen': -0.04929886385798454, 'rewards/rejected': -1.3282887935638428, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2789900302886963, 'policy_logps/rejected': -551.70068359375, 'policy_logps/chosen': -586.32958984375, 'referece_logps/rejected': -538.4178466796875, 'referece_logps/chosen': -585.8366088867188, 'logits/rejected': 0.3859303891658783, 'logits/chosen': 0.4980733394622803, 'epoch': 1.26}


 21%|██        | 3388/16104 [15:50:29<61:59:43, 17.55s/it]

 21%|██        | 3389/16104 [15:50:44<58:38:03, 16.60s/it]

 21%|██        | 3390/16104 [15:50:56<53:38:57, 15.19s/it]

 21%|██        | 3391/16104 [15:51:11<53:30:50, 15.15s/it]
{'loss': 0.4891, 'learning_rate': 1.8338919891839067e-06, 'rewards/chosen': -0.32880303263664246, 'rewards/rejected': -0.8221333026885986, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4933302402496338, 'policy_logps/rejected': -320.64007568359375, 'policy_logps/chosen': -382.3080139160156, 'referece_logps/rejected': -312.4187316894531, 'referece_logps/chosen': -379.0199890136719, 'logits/rejected': 0.5850728154182434, 'logits/chosen': 0.6474683880805969, 'epoch': 1.26}


 21%|██        | 3393/16104 [15:51:34<47:07:07, 13.34s/it]
{'loss': 0.457, 'learning_rate': 1.8336699073964823e-06, 'rewards/chosen': 0.3409813344478607, 'rewards/rejected': -1.1416175365447998, 'rewards/accuracies': 0.875, 'rewards/margins': 1.482598900794983, 'policy_logps/rejected': -400.690673828125, 'policy_logps/chosen': -461.16619873046875, 'referece_logps/rejected': -389.27447509765625, 'referece_logps/chosen': -464.5760192871094, 'logits/rejected': -0.18332909047603607, 'logits/chosen': -0.17391632497310638, 'epoch': 1.26}


 21%|██        | 3395/16104 [15:51:55<42:03:26, 11.91s/it]
{'loss': 0.5213, 'learning_rate': 1.8334476907153175e-06, 'rewards/chosen': -0.17716634273529053, 'rewards/rejected': -1.0607291460037231, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8835628628730774, 'policy_logps/rejected': -272.0683898925781, 'policy_logps/chosen': -429.7554016113281, 'referece_logps/rejected': -261.4610900878906, 'referece_logps/chosen': -427.98370361328125, 'logits/rejected': -0.24294516444206238, 'logits/chosen': -0.43259596824645996, 'epoch': 1.26}


 21%|██        | 3397/16104 [15:52:32<53:58:55, 15.29s/it]

 21%|██        | 3398/16104 [15:52:44<50:23:40, 14.28s/it]

 21%|██        | 3399/16104 [15:53:05<57:52:12, 16.40s/it]

 21%|██        | 3400/16104 [15:53:21<57:37:00, 16.33s/it]
{'loss': 0.4217, 'learning_rate': 1.832891559088308e-06, 'rewards/chosen': 0.20394203066825867, 'rewards/rejected': -1.6836011409759521, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8875432014465332, 'policy_logps/rejected': -281.1752014160156, 'policy_logps/chosen': -559.713134765625, 'referece_logps/rejected': -264.33917236328125, 'referece_logps/chosen': -561.7525634765625, 'logits/rejected': -0.3087330758571625, 'logits/chosen': -0.443889319896698, 'epoch': 1.27}


 21%|██        | 3402/16104 [15:53:56<60:37:36, 17.18s/it]

 21%|██        | 3403/16104 [15:54:15<63:15:15, 17.93s/it]

 21%|██        | 3404/16104 [15:54:33<63:13:13, 17.92s/it]

 21%|██        | 3405/16104 [15:54:45<56:29:13, 16.01s/it]
{'loss': 0.4444, 'learning_rate': 1.8323345851626204e-06, 'rewards/chosen': -0.4417116641998291, 'rewards/rejected': -1.371439814567566, 'rewards/accuracies': 0.625, 'rewards/margins': 0.929728090763092, 'policy_logps/rejected': -400.392822265625, 'policy_logps/chosen': -318.4181213378906, 'referece_logps/rejected': -386.678466796875, 'referece_logps/chosen': -314.0009765625, 'logits/rejected': -0.8343300819396973, 'logits/chosen': -0.7769281268119812, 'epoch': 1.27}


 21%|██        | 3407/16104 [15:55:23<63:03:01, 17.88s/it]

 21%|██        | 3408/16104 [15:55:46<68:41:43, 19.48s/it]

 21%|██        | 3409/16104 [15:56:05<68:16:34, 19.36s/it]
{'loss': 0.5458, 'learning_rate': 1.8318883999455072e-06, 'rewards/chosen': -0.6043440103530884, 'rewards/rejected': -1.5427465438842773, 'rewards/accuracies': 0.875, 'rewards/margins': 0.938402533531189, 'policy_logps/rejected': -454.98480224609375, 'policy_logps/chosen': -357.62103271484375, 'referece_logps/rejected': -439.5573425292969, 'referece_logps/chosen': -351.57757568359375, 'logits/rejected': -0.3984553813934326, 'logits/chosen': -0.3067525327205658, 'epoch': 1.27}


 21%|██        | 3411/16104 [15:56:39<63:47:06, 18.09s/it]
{'loss': 0.5649, 'learning_rate': 1.8316651054106766e-06, 'rewards/chosen': 0.025385960936546326, 'rewards/rejected': -0.8480226993560791, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8734085559844971, 'policy_logps/rejected': -343.935791015625, 'policy_logps/chosen': -441.5744934082031, 'referece_logps/rejected': -335.45556640625, 'referece_logps/chosen': -441.828369140625, 'logits/rejected': -0.15964779257774353, 'logits/chosen': 0.04722852259874344, 'epoch': 1.27}
[2024-04-06 07:30:57,651] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 21%|██        | 3413/16104 [15:57:16<63:02:09, 17.88s/it]
[2024-04-06 07:31:12,862] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 21%|██        | 3414/16104 [15:57:37<66:40:46, 18.92s/it]

 21%|██        | 3415/16104 [15:57:49<59:42:34, 16.94s/it]

 21%|██        | 3416/16104 [15:58:01<54:08:36, 15.36s/it]

 21%|██        | 3417/16104 [15:58:12<49:11:28, 13.96s/it]

 21%|██        | 3418/16104 [15:58:22<45:48:32, 13.00s/it]
{'loss': 0.4969, 'learning_rate': 1.8308825150424494e-06, 'rewards/chosen': 0.16807657480239868, 'rewards/rejected': -0.9272831678390503, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0953596830368042, 'policy_logps/rejected': -329.7547607421875, 'policy_logps/chosen': -424.17547607421875, 'referece_logps/rejected': -320.48193359375, 'referece_logps/chosen': -425.8562316894531, 'logits/rejected': 0.7824065685272217, 'logits/chosen': 0.8504303097724915, 'epoch': 1.27}


 21%|██        | 3420/16104 [15:58:54<49:39:06, 14.09s/it]
{'loss': 0.5473, 'learning_rate': 1.8306586152303909e-06, 'rewards/chosen': -0.2074655443429947, 'rewards/rejected': -1.213426113128662, 'rewards/accuracies': 0.875, 'rewards/margins': 1.005960464477539, 'policy_logps/rejected': -384.43463134765625, 'policy_logps/chosen': -417.9246826171875, 'referece_logps/rejected': -372.3003845214844, 'referece_logps/chosen': -415.8499755859375, 'logits/rejected': -0.32277411222457886, 'logits/chosen': -0.17341899871826172, 'epoch': 1.27}


 21%|██        | 3422/16104 [15:59:28<56:02:44, 15.91s/it]
{'loss': 0.4197, 'learning_rate': 1.8304345810118407e-06, 'rewards/chosen': -0.1330781877040863, 'rewards/rejected': -0.719738245010376, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5866600275039673, 'policy_logps/rejected': -373.3851623535156, 'policy_logps/chosen': -466.1422119140625, 'referece_logps/rejected': -366.18780517578125, 'referece_logps/chosen': -464.81146240234375, 'logits/rejected': 0.35574695467948914, 'logits/chosen': 0.1757630705833435, 'epoch': 1.27}

 21%|██▏       | 3423/16104 [15:59:47<59:45:54, 16.97s/it]


 21%|██▏       | 3425/16104 [16:00:20<60:50:02, 17.27s/it]
[2024-04-06 07:34:17,610] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.3808, 'learning_rate': 1.830098277751147e-06, 'rewards/chosen': -0.28365573287010193, 'rewards/rejected': -1.4940886497497559, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2104328870773315, 'policy_logps/rejected': -486.39501953125, 'policy_logps/chosen': -519.8804321289062, 'referece_logps/rejected': -471.4541320800781, 'referece_logps/chosen': -517.0438842773438, 'logits/rejected': 0.3784319758415222, 'logits/chosen': 0.45475971698760986, 'epoch': 1.28}

 21%|██▏       | 3426/16104 [16:00:43<66:17:32, 18.82s/it]


 21%|██▏       | 3428/16104 [16:01:21<66:36:41, 18.92s/it]

 21%|██▏       | 3429/16104 [16:01:42<69:40:06, 19.79s/it]
[2024-04-06 07:35:39,645] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5646, 'learning_rate': 1.8296494033193528e-06, 'rewards/chosen': 0.17934876680374146, 'rewards/rejected': -1.0262610912322998, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2056100368499756, 'policy_logps/rejected': -486.99176025390625, 'policy_logps/chosen': -592.3377685546875, 'referece_logps/rejected': -476.7291564941406, 'referece_logps/chosen': -594.1312866210938, 'logits/rejected': 0.6214680075645447, 'logits/chosen': 0.5949351191520691, 'epoch': 1.28}
[2024-04-06 07:35:56,503] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 21%|██▏       | 3431/16104 [16:02:12<60:00:20, 17.05s/it]
{'loss': 0.6451, 'learning_rate': 1.8294247647205015e-06, 'rewards/chosen': 0.30138343572616577, 'rewards/rejected': -0.44685548543930054, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7482388615608215, 'policy_logps/rejected': -461.6834716796875, 'policy_logps/chosen': -426.75762939453125, 'referece_logps/rejected': -457.21490478515625, 'referece_logps/chosen': -429.7714538574219, 'logits/rejected': -0.9226679801940918, 'logits/chosen': -0.8845819234848022, 'epoch': 1.28}

 21%|██▏       | 3432/16104 [16:02:23<53:54:21, 15.31s/it]

 21%|██▏       | 3433/16104 [16:02:39<54:10:24, 15.39s/it]

 21%|██▏       | 3434/16104 [16:02:51<50:47:28, 14.43s/it]

 21%|██▏       | 3435/16104 [16:03:11<57:11:24, 16.25s/it]


 21%|██▏       | 3437/16104 [16:03:42<54:55:39, 15.61s/it]
{'loss': 0.6054, 'learning_rate': 1.8287500438283723e-06, 'rewards/chosen': -0.6488693952560425, 'rewards/rejected': -0.8930047750473022, 'rewards/accuracies': 0.5, 'rewards/margins': 0.24413540959358215, 'policy_logps/rejected': -318.5198059082031, 'policy_logps/chosen': -416.2602844238281, 'referece_logps/rejected': -309.58978271484375, 'referece_logps/chosen': -409.7716064453125, 'logits/rejected': -0.767524242401123, 'logits/chosen': -0.7907494902610779, 'epoch': 1.28}


 21%|██▏       | 3439/16104 [16:04:12<54:40:14, 15.54s/it]

 21%|██▏       | 3440/16104 [16:04:29<55:35:15, 15.80s/it]
{'loss': 0.6269, 'learning_rate': 1.8284122307412365e-06, 'rewards/chosen': 0.06840667128562927, 'rewards/rejected': -0.43994832038879395, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5083549618721008, 'policy_logps/rejected': -404.78631591796875, 'policy_logps/chosen': -502.1546325683594, 'referece_logps/rejected': -400.3868103027344, 'referece_logps/chosen': -502.8387451171875, 'logits/rejected': 0.725202739238739, 'logits/chosen': 0.6006179451942444, 'epoch': 1.28}


 21%|██▏       | 3442/16104 [16:05:00<55:33:46, 15.80s/it]

 21%|██▏       | 3443/16104 [16:05:12<51:13:25, 14.56s/it]

 21%|██▏       | 3444/16104 [16:05:32<57:07:05, 16.24s/it]

 21%|██▏       | 3445/16104 [16:05:45<53:02:09, 15.08s/it]
{'loss': 0.4302, 'learning_rate': 1.8278485387750845e-06, 'rewards/chosen': -0.16776028275489807, 'rewards/rejected': -0.9886797666549683, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8209194540977478, 'policy_logps/rejected': -326.8863220214844, 'policy_logps/chosen': -296.5384521484375, 'referece_logps/rejected': -316.99951171875, 'referece_logps/chosen': -294.86083984375, 'logits/rejected': -0.6934358477592468, 'logits/chosen': -0.7988109588623047, 'epoch': 1.28}


 21%|██▏       | 3447/16104 [16:06:18<56:12:36, 15.99s/it]

 21%|██▏       | 3448/16104 [16:06:31<52:20:29, 14.89s/it]
{'loss': 0.5097, 'learning_rate': 1.8275099217034985e-06, 'rewards/chosen': -0.32524383068084717, 'rewards/rejected': -0.6141766309738159, 'rewards/accuracies': 0.625, 'rewards/margins': 0.28893280029296875, 'policy_logps/rejected': -441.6535339355469, 'policy_logps/chosen': -361.9881896972656, 'referece_logps/rejected': -435.51177978515625, 'referece_logps/chosen': -358.7357482910156, 'logits/rejected': -0.14523787796497345, 'logits/chosen': -0.003592986613512039, 'epoch': 1.28}


 21%|██▏       | 3450/16104 [16:07:11<62:16:07, 17.72s/it]

 21%|██▏       | 3451/16104 [16:07:25<58:03:46, 16.52s/it]
{'loss': 0.545, 'learning_rate': 1.8271710033636437e-06, 'rewards/chosen': 0.31485843658447266, 'rewards/rejected': -0.8021133542060852, 'rewards/accuracies': 0.75, 'rewards/margins': 1.116971731185913, 'policy_logps/rejected': -504.7166748046875, 'policy_logps/chosen': -543.7967529296875, 'referece_logps/rejected': -496.69549560546875, 'referece_logps/chosen': -546.9453735351562, 'logits/rejected': -0.6760494112968445, 'logits/chosen': -0.751987874507904, 'epoch': 1.29}

 21%|██▏       | 3452/16104 [16:07:40<56:25:06, 16.05s/it]
[2024-04-06 07:41:55,309] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 21%|██▏       | 3453/16104 [16:07:58<58:56:26, 16.77s/it]


 21%|██▏       | 3455/16104 [16:08:29<56:42:31, 16.14s/it]

 21%|██▏       | 3456/16104 [16:08:48<59:50:12, 17.03s/it]
{'loss': 0.4177, 'learning_rate': 1.826605470314023e-06, 'rewards/chosen': -0.011107441037893295, 'rewards/rejected': -1.8379688262939453, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8268613815307617, 'policy_logps/rejected': -278.1125183105469, 'policy_logps/chosen': -341.6864318847656, 'referece_logps/rejected': -259.7328186035156, 'referece_logps/chosen': -341.5753173828125, 'logits/rejected': -0.4889034032821655, 'logits/chosen': -0.40442416071891785, 'epoch': 1.29}


 21%|██▏       | 3458/16104 [16:09:26<64:02:27, 18.23s/it]

 21%|██▏       | 3459/16104 [16:09:37<56:09:10, 15.99s/it]
{'loss': 0.4592, 'learning_rate': 1.8262657491956487e-06, 'rewards/chosen': 0.306440532207489, 'rewards/rejected': -0.182896226644516, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4893367290496826, 'policy_logps/rejected': -552.133056640625, 'policy_logps/chosen': -515.3895263671875, 'referece_logps/rejected': -550.3041381835938, 'referece_logps/chosen': -518.4539184570312, 'logits/rejected': 0.1251114010810852, 'logits/chosen': 0.1089758351445198, 'epoch': 1.29}


 21%|██▏       | 3461/16104 [16:10:18<64:37:19, 18.40s/it]

 21%|██▏       | 3462/16104 [16:10:38<66:11:02, 18.85s/it]
{'loss': 0.5275, 'learning_rate': 1.8259257272619661e-06, 'rewards/chosen': -0.7994999289512634, 'rewards/rejected': -0.8784765005111694, 'rewards/accuracies': 0.75, 'rewards/margins': 0.07897654175758362, 'policy_logps/rejected': -263.7585754394531, 'policy_logps/chosen': -311.6162109375, 'referece_logps/rejected': -254.9738006591797, 'referece_logps/chosen': -303.6212158203125, 'logits/rejected': -0.6051595211029053, 'logits/chosen': -0.5029971599578857, 'epoch': 1.29}


 22%|██▏       | 3464/16104 [16:11:12<63:36:02, 18.11s/it]
{'loss': 0.5601, 'learning_rate': 1.8256988789143554e-06, 'rewards/chosen': 0.04326321929693222, 'rewards/rejected': -0.7806034088134766, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8238667249679565, 'policy_logps/rejected': -357.52410888671875, 'policy_logps/chosen': -394.57769775390625, 'referece_logps/rejected': -349.7180480957031, 'referece_logps/chosen': -395.0103454589844, 'logits/rejected': -0.5850036144256592, 'logits/chosen': -0.6341614723205566, 'epoch': 1.29}


 22%|██▏       | 3466/16104 [16:11:45<61:01:14, 17.38s/it]
{'loss': 0.519, 'learning_rate': 1.825471896962774e-06, 'rewards/chosen': -0.5437440872192383, 'rewards/rejected': -0.7261964082717896, 'rewards/accuracies': 0.625, 'rewards/margins': 0.18245241045951843, 'policy_logps/rejected': -379.33984375, 'policy_logps/chosen': -396.6858825683594, 'referece_logps/rejected': -372.077880859375, 'referece_logps/chosen': -391.2484436035156, 'logits/rejected': 0.4552571773529053, 'logits/chosen': 0.2586003839969635, 'epoch': 1.29}


 22%|██▏       | 3468/16104 [16:12:23<63:33:17, 18.11s/it]
{'loss': 0.4608, 'learning_rate': 1.8252447814439484e-06, 'rewards/chosen': -0.39093971252441406, 'rewards/rejected': -1.4992696046829224, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1083297729492188, 'policy_logps/rejected': -597.7604370117188, 'policy_logps/chosen': -420.7103576660156, 'referece_logps/rejected': -582.7677612304688, 'referece_logps/chosen': -416.801025390625, 'logits/rejected': -0.38874536752700806, 'logits/chosen': -0.17560160160064697, 'epoch': 1.29}

 22%|██▏       | 3469/16104 [16:12:36<57:46:32, 16.46s/it]


 22%|██▏       | 3471/16104 [16:13:09<58:58:57, 16.81s/it]
{'loss': 0.5545, 'learning_rate': 1.8249038578075225e-06, 'rewards/chosen': -0.2102351188659668, 'rewards/rejected': -1.3318504095077515, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1216151714324951, 'policy_logps/rejected': -299.24591064453125, 'policy_logps/chosen': -432.7693176269531, 'referece_logps/rejected': -285.92742919921875, 'referece_logps/chosen': -430.6669921875, 'logits/rejected': -0.5827851295471191, 'logits/chosen': -0.5840017199516296, 'epoch': 1.29}


 22%|██▏       | 3473/16104 [16:13:49<64:01:43, 18.25s/it]
{'loss': 0.4366, 'learning_rate': 1.8246764085314114e-06, 'rewards/chosen': -0.24920770525932312, 'rewards/rejected': -1.0569946765899658, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8077870607376099, 'policy_logps/rejected': -379.2731628417969, 'policy_logps/chosen': -402.29376220703125, 'referece_logps/rejected': -368.7032470703125, 'referece_logps/chosen': -399.80169677734375, 'logits/rejected': 0.33227935433387756, 'logits/chosen': 0.30825531482696533, 'epoch': 1.29}

 22%|██▏       | 3474/16104 [16:14:05<62:32:04, 17.82s/it]

 22%|██▏       | 3475/16104 [16:14:18<56:51:18, 16.21s/it]

 22%|██▏       | 3476/16104 [16:14:37<60:26:24, 17.23s/it]


 22%|██▏       | 3478/16104 [16:15:07<54:27:07, 15.53s/it]

 22%|██▏       | 3479/16104 [16:15:19<51:04:08, 14.56s/it]
{'loss': 0.4206, 'learning_rate': 1.8239932602192294e-06, 'rewards/chosen': 0.3027421832084656, 'rewards/rejected': -0.958599328994751, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2613415718078613, 'policy_logps/rejected': -454.77569580078125, 'policy_logps/chosen': -533.0026245117188, 'referece_logps/rejected': -445.1896667480469, 'referece_logps/chosen': -536.0300903320312, 'logits/rejected': -0.43187734484672546, 'logits/chosen': -0.43155086040496826, 'epoch': 1.3}
[2024-04-06 07:49:36,995] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 22%|██▏       | 3480/16104 [16:15:40<57:39:49, 16.44s/it]


 22%|██▏       | 3482/16104 [16:16:13<58:27:00, 16.67s/it]
{'loss': 0.5589, 'learning_rate': 1.8236512360189754e-06, 'rewards/chosen': 0.39284229278564453, 'rewards/rejected': -0.4789499342441559, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8717922568321228, 'policy_logps/rejected': -523.934326171875, 'policy_logps/chosen': -578.33154296875, 'referece_logps/rejected': -519.144775390625, 'referece_logps/chosen': -582.260009765625, 'logits/rejected': 0.06023666262626648, 'logits/chosen': 0.038739338517189026, 'epoch': 1.3}


 22%|██▏       | 3484/16104 [16:16:51<63:28:02, 18.10s/it]
{'loss': 0.4955, 'learning_rate': 1.8234230532869748e-06, 'rewards/chosen': 0.32850417494773865, 'rewards/rejected': -0.6267678737640381, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9552720785140991, 'policy_logps/rejected': -498.2022705078125, 'policy_logps/chosen': -493.4481506347656, 'referece_logps/rejected': -491.93463134765625, 'referece_logps/chosen': -496.7331237792969, 'logits/rejected': -0.07447189837694168, 'logits/chosen': -0.13535667955875397, 'epoch': 1.3}

 22%|██▏       | 3485/16104 [16:17:12<66:50:26, 19.07s/it]

 22%|██▏       | 3486/16104 [16:17:32<67:30:32, 19.26s/it]

 22%|██▏       | 3487/16104 [16:17:50<66:36:58, 19.01s/it]

 22%|██▏       | 3488/16104 [16:18:02<58:22:22, 16.66s/it]


 22%|██▏       | 3490/16104 [16:18:27<51:30:48, 14.70s/it]

 22%|██▏       | 3491/16104 [16:18:43<52:41:27, 15.04s/it]
{'loss': 0.49, 'learning_rate': 1.8226233647361214e-06, 'rewards/chosen': -0.5279407501220703, 'rewards/rejected': -1.7042458057403564, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1763051748275757, 'policy_logps/rejected': -232.7386932373047, 'policy_logps/chosen': -254.82467651367188, 'referece_logps/rejected': -215.69625854492188, 'referece_logps/chosen': -249.54525756835938, 'logits/rejected': -0.5213791131973267, 'logits/chosen': -0.5240709185600281, 'epoch': 1.3}

 22%|██▏       | 3492/16104 [16:18:54<48:15:00, 13.77s/it]


 22%|██▏       | 3494/16104 [16:19:19<46:17:32, 13.22s/it]

 22%|██▏       | 3495/16104 [16:19:31<44:57:29, 12.84s/it]

 22%|██▏       | 3496/16104 [16:19:49<50:22:35, 14.38s/it]
{'loss': 0.5236, 'learning_rate': 1.822051160238485e-06, 'rewards/chosen': -0.7086963653564453, 'rewards/rejected': -0.7157859802246094, 'rewards/accuracies': 0.625, 'rewards/margins': 0.007089570164680481, 'policy_logps/rejected': -393.94061279296875, 'policy_logps/chosen': -531.7049560546875, 'referece_logps/rejected': -386.7827453613281, 'referece_logps/chosen': -524.6179809570312, 'logits/rejected': 0.604130744934082, 'logits/chosen': 0.7493261098861694, 'epoch': 1.3}

 22%|██▏       | 3497/16104 [16:20:08<54:57:49, 15.70s/it]

 22%|██▏       | 3498/16104 [16:20:20<51:29:39, 14.71s/it]


 22%|██▏       | 3500/16104 [16:21:01<61:19:56, 17.52s/it]
{'loss': 0.5628, 'learning_rate': 1.8215927980507656e-06, 'rewards/chosen': -0.17444640398025513, 'rewards/rejected': -0.29953059554100037, 'rewards/accuracies': 0.5, 'rewards/margins': 0.12508420646190643, 'policy_logps/rejected': -289.88519287109375, 'policy_logps/chosen': -319.5642395019531, 'referece_logps/rejected': -286.889892578125, 'referece_logps/chosen': -317.8197937011719, 'logits/rejected': -0.30856966972351074, 'logits/chosen': -0.342732697725296, 'epoch': 1.3}

 22%|██▏       | 3501/16104 [16:21:37<80:14:54, 22.92s/it]


 22%|██▏       | 3503/16104 [16:22:11<68:29:37, 19.57s/it]

 22%|██▏       | 3504/16104 [16:22:30<67:38:48, 19.33s/it]
[2024-04-06 07:56:27,051] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4973, 'learning_rate': 1.821133904104756e-06, 'rewards/chosen': -0.40376681089401245, 'rewards/rejected': -0.6844897866249084, 'rewards/accuracies': 0.625, 'rewards/margins': 0.28072303533554077, 'policy_logps/rejected': -437.70233154296875, 'policy_logps/chosen': -546.2086181640625, 'referece_logps/rejected': -430.85748291015625, 'referece_logps/chosen': -542.1709594726562, 'logits/rejected': -0.25377175211906433, 'logits/chosen': -0.20236383378505707, 'epoch': 1.31}


 22%|██▏       | 3506/16104 [16:23:00<59:30:23, 17.00s/it]
{'loss': 0.4924, 'learning_rate': 1.8209042578151946e-06, 'rewards/chosen': 0.17813177406787872, 'rewards/rejected': -0.5303304195404053, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7084622383117676, 'policy_logps/rejected': -298.8471984863281, 'policy_logps/chosen': -361.8618469238281, 'referece_logps/rejected': -293.5439147949219, 'referece_logps/chosen': -363.6431579589844, 'logits/rejected': -0.2540574073791504, 'logits/chosen': -0.370576411485672, 'epoch': 1.31}

 22%|██▏       | 3507/16104 [16:23:15<57:22:32, 16.40s/it]


 22%|██▏       | 3509/16104 [16:23:41<50:44:26, 14.50s/it]
{'loss': 0.4849, 'learning_rate': 1.8205595393396567e-06, 'rewards/chosen': 0.14876098930835724, 'rewards/rejected': -0.5406137704849243, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6893748044967651, 'policy_logps/rejected': -311.7979736328125, 'policy_logps/chosen': -426.5384826660156, 'referece_logps/rejected': -306.3918151855469, 'referece_logps/chosen': -428.026123046875, 'logits/rejected': -0.5049623250961304, 'logits/chosen': -0.4112818241119385, 'epoch': 1.31}
[2024-04-06 07:57:59,401] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 22%|██▏       | 3510/16104 [16:24:02<57:34:49, 16.46s/it]

 22%|██▏       | 3511/16104 [16:24:13<51:31:27, 14.73s/it]

 22%|██▏       | 3512/16104 [16:24:32<56:37:32, 16.19s/it]

 22%|██▏       | 3513/16104 [16:24:45<52:53:03, 15.12s/it]


 22%|██▏       | 3515/16104 [16:25:16<51:41:17, 14.78s/it]

 22%|██▏       | 3516/16104 [16:25:35<56:57:49, 16.29s/it]

 22%|██▏       | 3517/16104 [16:25:56<61:15:36, 17.52s/it]
{'loss': 0.4941, 'learning_rate': 1.8196388299165081e-06, 'rewards/chosen': 0.09505519270896912, 'rewards/rejected': -0.6454776525497437, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7405328750610352, 'policy_logps/rejected': -467.8526916503906, 'policy_logps/chosen': -465.71514892578125, 'referece_logps/rejected': -461.3978576660156, 'referece_logps/chosen': -466.6657409667969, 'logits/rejected': -0.5307655334472656, 'logits/chosen': -0.3981347680091858, 'epoch': 1.31}


 22%|██▏       | 3519/16104 [16:26:27<57:50:00, 16.54s/it]
{'loss': 0.5575, 'learning_rate': 1.8194083209090269e-06, 'rewards/chosen': -0.33087122440338135, 'rewards/rejected': -1.1192944049835205, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7884231209754944, 'policy_logps/rejected': -391.4114685058594, 'policy_logps/chosen': -286.1202392578125, 'referece_logps/rejected': -380.2185363769531, 'referece_logps/chosen': -282.8115234375, 'logits/rejected': -0.07345572113990784, 'logits/chosen': -0.14061866700649261, 'epoch': 1.31}


 22%|██▏       | 3521/16104 [16:27:05<61:21:47, 17.56s/it]
{'loss': 0.5059, 'learning_rate': 1.8191776793154316e-06, 'rewards/chosen': -0.4476804733276367, 'rewards/rejected': -0.787207841873169, 'rewards/accuracies': 0.5, 'rewards/margins': 0.33952733874320984, 'policy_logps/rejected': -312.799560546875, 'policy_logps/chosen': -403.4718322753906, 'referece_logps/rejected': -304.927490234375, 'referece_logps/chosen': -398.99505615234375, 'logits/rejected': -1.0272388458251953, 'logits/chosen': -0.8728369474411011, 'epoch': 1.31}

 22%|██▏       | 3522/16104 [16:27:20<58:37:15, 16.77s/it]


 22%|██▏       | 3524/16104 [16:27:50<56:06:51, 16.06s/it]
{'loss': 0.4115, 'learning_rate': 1.8188314684077173e-06, 'rewards/chosen': 0.005772598087787628, 'rewards/rejected': -1.3732954263687134, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3790680170059204, 'policy_logps/rejected': -391.22125244140625, 'policy_logps/chosen': -590.0885620117188, 'referece_logps/rejected': -377.4883117675781, 'referece_logps/chosen': -590.1463012695312, 'logits/rejected': -0.4785693883895874, 'logits/chosen': -0.5443289875984192, 'epoch': 1.31}


 22%|██▏       | 3526/16104 [16:28:22<57:06:36, 16.35s/it]
{'loss': 0.4783, 'learning_rate': 1.818600495512157e-06, 'rewards/chosen': 0.12544454634189606, 'rewards/rejected': -0.7338464856147766, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8592910170555115, 'policy_logps/rejected': -417.95404052734375, 'policy_logps/chosen': -473.60992431640625, 'referece_logps/rejected': -410.6155700683594, 'referece_logps/chosen': -474.8643798828125, 'logits/rejected': 0.11345234513282776, 'logits/chosen': 0.11756426095962524, 'epoch': 1.31}

 22%|██▏       | 3527/16104 [16:28:38<57:01:11, 16.32s/it]

 22%|██▏       | 3528/16104 [16:28:51<53:26:48, 15.30s/it]


 22%|██▏       | 3530/16104 [16:29:26<57:00:38, 16.32s/it]
{'loss': 0.4862, 'learning_rate': 1.8181381523922249e-06, 'rewards/chosen': -0.366942822933197, 'rewards/rejected': -1.3918449878692627, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0249022245407104, 'policy_logps/rejected': -440.2635803222656, 'policy_logps/chosen': -423.4779357910156, 'referece_logps/rejected': -426.3451232910156, 'referece_logps/chosen': -419.8085021972656, 'logits/rejected': -0.08921230584383011, 'logits/chosen': -0.2107260823249817, 'epoch': 1.32}

 22%|██▏       | 3531/16104 [16:29:47<61:42:51, 17.67s/it]

 22%|██▏       | 3532/16104 [16:30:07<64:50:32, 18.57s/it]

 22%|██▏       | 3533/16104 [16:30:19<58:00:41, 16.61s/it]
[2024-04-06 08:04:37,932] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 22%|██▏       | 3535/16104 [16:30:52<56:15:04, 16.11s/it]
{'loss': 0.5371, 'learning_rate': 1.817559478886612e-06, 'rewards/chosen': -0.3033011555671692, 'rewards/rejected': -0.29592838883399963, 'rewards/accuracies': 0.75, 'rewards/margins': -0.007372770458459854, 'policy_logps/rejected': -347.3998107910156, 'policy_logps/chosen': -325.797119140625, 'referece_logps/rejected': -344.4405822753906, 'referece_logps/chosen': -322.76409912109375, 'logits/rejected': -0.41058582067489624, 'logits/chosen': -0.6203781366348267, 'epoch': 1.32}

 22%|██▏       | 3536/16104 [16:31:12<59:41:01, 17.10s/it]

 22%|██▏       | 3537/16104 [16:31:27<57:23:33, 16.44s/it]
[2024-04-06 08:05:38,646] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 22%|██▏       | 3539/16104 [16:31:52<50:18:21, 14.41s/it]
{'loss': 0.5469, 'learning_rate': 1.8170959447627346e-06, 'rewards/chosen': 0.44296637177467346, 'rewards/rejected': -0.229923814535141, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6728901267051697, 'policy_logps/rejected': -388.5257263183594, 'policy_logps/chosen': -409.9508056640625, 'referece_logps/rejected': -386.22650146484375, 'referece_logps/chosen': -414.3804931640625, 'logits/rejected': -0.3189695477485657, 'logits/chosen': -0.12685012817382812, 'epoch': 1.32}

 22%|██▏       | 3540/16104 [16:32:05<48:35:17, 13.92s/it]

 22%|██▏       | 3541/16104 [16:32:16<45:08:52, 12.94s/it]

 22%|██▏       | 3542/16104 [16:32:34<50:42:08, 14.53s/it]

 22%|██▏       | 3543/16104 [16:32:53<55:09:03, 15.81s/it]

 22%|██▏       | 3544/16104 [16:33:05<51:40:36, 14.81s/it]


 22%|██▏       | 3546/16104 [16:33:29<45:46:25, 13.12s/it]
{'loss': 0.5689, 'learning_rate': 1.8162834876866039e-06, 'rewards/chosen': -0.611686110496521, 'rewards/rejected': -0.5830072164535522, 'rewards/accuracies': 0.375, 'rewards/margins': -0.02867887169122696, 'policy_logps/rejected': -359.593994140625, 'policy_logps/chosen': -319.1662902832031, 'referece_logps/rejected': -353.76397705078125, 'referece_logps/chosen': -313.0494079589844, 'logits/rejected': -0.5733509659767151, 'logits/chosen': -0.6467272043228149, 'epoch': 1.32}

 22%|██▏       | 3547/16104 [16:33:39<43:24:40, 12.45s/it]

 22%|██▏       | 3548/16104 [16:33:54<45:54:27, 13.16s/it]

 22%|██▏       | 3549/16104 [16:34:05<43:24:31, 12.45s/it]

 22%|██▏       | 3550/16104 [16:34:22<47:43:00, 13.68s/it]

 22%|██▏       | 3551/16104 [16:34:41<53:54:18, 15.46s/it]

 22%|██▏       | 3552/16104 [16:34:52<49:00:25, 14.06s/it]

 22%|██▏       | 3553/16104 [16:35:13<56:13:14, 16.13s/it]

 22%|██▏       | 3554/16104 [16:35:30<56:43:39, 16.27s/it]


 22%|██▏       | 3556/16104 [16:36:09<62:59:04, 18.07s/it]
{'loss': 0.6037, 'learning_rate': 1.8151200284104002e-06, 'rewards/chosen': -0.04886990040540695, 'rewards/rejected': -0.27912747859954834, 'rewards/accuracies': 0.5, 'rewards/margins': 0.23025760054588318, 'policy_logps/rejected': -375.6058349609375, 'policy_logps/chosen': -333.67535400390625, 'referece_logps/rejected': -372.8145446777344, 'referece_logps/chosen': -333.1866149902344, 'logits/rejected': 0.389297753572464, 'logits/chosen': 0.29763782024383545, 'epoch': 1.32}

 22%|██▏       | 3557/16104 [16:36:22<57:36:50, 16.53s/it]
[2024-04-06 08:10:36,430] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 22%|██▏       | 3558/16104 [16:36:39<58:43:04, 16.85s/it]

 22%|██▏       | 3559/16104 [16:36:54<56:14:35, 16.14s/it]

 22%|██▏       | 3560/16104 [16:37:13<59:53:41, 17.19s/it]


 22%|██▏       | 3562/16104 [16:37:55<65:23:51, 18.77s/it]
{'loss': 0.4018, 'learning_rate': 1.814420369836575e-06, 'rewards/chosen': 0.1793554127216339, 'rewards/rejected': -1.5457172393798828, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7250727415084839, 'policy_logps/rejected': -288.1432189941406, 'policy_logps/chosen': -273.09466552734375, 'referece_logps/rejected': -272.68603515625, 'referece_logps/chosen': -274.8882141113281, 'logits/rejected': -0.39961546659469604, 'logits/chosen': -0.2770354449748993, 'epoch': 1.33}

 22%|██▏       | 3563/16104 [16:38:16<67:47:28, 19.46s/it]

 22%|██▏       | 3564/16104 [16:38:36<68:03:14, 19.54s/it]

 22%|██▏       | 3565/16104 [16:38:52<64:23:25, 18.49s/it]
[2024-04-06 08:13:08,492] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 22%|██▏       | 3567/16104 [16:39:27<62:19:05, 17.89s/it]
{'loss': 0.5731, 'learning_rate': 1.8138364150010437e-06, 'rewards/chosen': -0.4309360384941101, 'rewards/rejected': -1.0071519613265991, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5762158632278442, 'policy_logps/rejected': -411.63037109375, 'policy_logps/chosen': -379.47320556640625, 'referece_logps/rejected': -401.558837890625, 'referece_logps/chosen': -375.16387939453125, 'logits/rejected': -1.0088626146316528, 'logits/chosen': -0.8800289034843445, 'epoch': 1.33}

 22%|██▏       | 3568/16104 [16:39:38<54:51:30, 15.75s/it]


 22%|██▏       | 3570/16104 [16:40:01<47:02:18, 13.51s/it]
{'loss': 0.6075, 'learning_rate': 1.8134856470083037e-06, 'rewards/chosen': 0.09439736604690552, 'rewards/rejected': -0.339420348405838, 'rewards/accuracies': 0.5, 'rewards/margins': 0.43381768465042114, 'policy_logps/rejected': -311.6229553222656, 'policy_logps/chosen': -382.8419189453125, 'referece_logps/rejected': -308.228759765625, 'referece_logps/chosen': -383.785888671875, 'logits/rejected': -0.9018725752830505, 'logits/chosen': -1.06436288356781, 'epoch': 1.33}

 22%|██▏       | 3571/16104 [16:40:21<54:21:41, 15.61s/it]

 22%|██▏       | 3572/16104 [16:40:32<49:12:42, 14.14s/it]

 22%|██▏       | 3573/16104 [16:40:45<47:46:40, 13.73s/it]

 22%|██▏       | 3574/16104 [16:41:06<55:26:32, 15.93s/it]

 22%|██▏       | 3575/16104 [16:41:21<54:53:25, 15.77s/it]
[2024-04-06 08:15:39,653] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 22%|██▏       | 3576/16104 [16:41:42<60:35:51, 17.41s/it]

 22%|██▏       | 3577/16104 [16:42:02<63:11:34, 18.16s/it]

 22%|██▏       | 3578/16104 [16:42:22<65:18:58, 18.77s/it]

 22%|██▏       | 3579/16104 [16:42:42<66:02:02, 18.98s/it]

 22%|██▏       | 3580/16104 [16:42:58<63:13:29, 18.17s/it]

 22%|██▏       | 3581/16104 [16:43:13<59:58:01, 17.24s/it]

 22%|██▏       | 3582/16104 [16:43:34<63:15:45, 18.19s/it]

 22%|██▏       | 3583/16104 [16:43:44<55:27:40, 15.95s/it]

 22%|██▏       | 3584/16104 [16:43:57<51:42:19, 14.87s/it]


 22%|██▏       | 3586/16104 [16:44:39<63:02:42, 18.13s/it]
{'loss': 0.4681, 'learning_rate': 1.8116098856448251e-06, 'rewards/chosen': 0.4895271360874176, 'rewards/rejected': -0.1923639178276062, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6818910241127014, 'policy_logps/rejected': -491.8642272949219, 'policy_logps/chosen': -532.4636840820312, 'referece_logps/rejected': -489.9405517578125, 'referece_logps/chosen': -537.3589477539062, 'logits/rejected': -0.07973542809486389, 'logits/chosen': -0.006813302636146545, 'epoch': 1.34}


 22%|██▏       | 3588/16104 [16:45:09<57:58:47, 16.68s/it]
{'loss': 0.544, 'learning_rate': 1.8113748241163634e-06, 'rewards/chosen': 0.19812947511672974, 'rewards/rejected': -0.3867506980895996, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5848801136016846, 'policy_logps/rejected': -406.3266296386719, 'policy_logps/chosen': -500.2132873535156, 'referece_logps/rejected': -402.4591064453125, 'referece_logps/chosen': -502.194580078125, 'logits/rejected': -0.33543863892555237, 'logits/chosen': -0.34459567070007324, 'epoch': 1.34}

 22%|██▏       | 3589/16104 [16:45:22<54:21:08, 15.63s/it]

 22%|██▏       | 3590/16104 [16:45:42<58:08:17, 16.73s/it]

 22%|██▏       | 3591/16104 [16:46:00<60:03:44, 17.28s/it]

 22%|██▏       | 3592/16104 [16:46:21<63:23:03, 18.24s/it]

 22%|██▏       | 3593/16104 [16:46:32<55:35:42, 16.00s/it]

 22%|██▏       | 3594/16104 [16:46:47<54:46:47, 15.76s/it]

 22%|██▏       | 3595/16104 [16:47:00<51:51:21, 14.92s/it]

 22%|██▏       | 3596/16104 [16:47:13<49:52:32, 14.35s/it]

 22%|██▏       | 3597/16104 [16:47:26<48:31:59, 13.97s/it]

 22%|██▏       | 3598/16104 [16:47:36<45:05:06, 12.98s/it]

 22%|██▏       | 3599/16104 [16:47:58<53:44:07, 15.47s/it]

 22%|██▏       | 3600/16104 [16:48:15<55:46:10, 16.06s/it]

 22%|██▏       | 3601/16104 [16:48:34<58:35:51, 16.87s/it]

 22%|██▏       | 3602/16104 [16:48:49<56:40:33, 16.32s/it]

 22%|██▏       | 3603/16104 [16:49:04<55:48:44, 16.07s/it]

 22%|██▏       | 3604/16104 [16:49:19<53:48:28, 15.50s/it]

 22%|██▏       | 3605/16104 [16:49:39<58:45:22, 16.92s/it]

 22%|██▏       | 3606/16104 [16:49:52<54:42:33, 15.76s/it]

 22%|██▏       | 3607/16104 [16:50:13<59:48:04, 17.23s/it]

 22%|██▏       | 3608/16104 [16:50:35<65:00:20, 18.73s/it]

 22%|██▏       | 3609/16104 [16:50:55<66:50:11, 19.26s/it]

 22%|██▏       | 3610/16104 [16:51:15<67:28:58, 19.44s/it]

 22%|██▏       | 3611/16104 [16:51:30<62:55:31, 18.13s/it]

 22%|██▏       | 3612/16104 [16:51:47<60:58:16, 17.57s/it]


 22%|██▏       | 3614/16104 [16:52:14<53:54:43, 15.54s/it]

 22%|██▏       | 3615/16104 [16:52:36<60:31:49, 17.45s/it]
{'loss': 0.4092, 'learning_rate': 1.8081886593862504e-06, 'rewards/chosen': -0.08060626685619354, 'rewards/rejected': -1.1006650924682617, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0200587511062622, 'policy_logps/rejected': -306.6876220703125, 'policy_logps/chosen': -359.39501953125, 'referece_logps/rejected': -295.6809997558594, 'referece_logps/chosen': -358.5888977050781, 'logits/rejected': -0.5750924348831177, 'logits/chosen': -0.4630759060382843, 'epoch': 1.35}

 22%|██▏       | 3616/16104 [16:52:52<59:31:06, 17.16s/it]

 22%|██▏       | 3617/16104 [16:53:08<58:37:55, 16.90s/it]

 22%|██▏       | 3618/16104 [16:53:29<62:18:01, 17.96s/it]

 22%|██▏       | 3619/16104 [16:53:49<64:38:26, 18.64s/it]


 22%|██▏       | 3621/16104 [16:54:20<59:29:09, 17.16s/it]
{'loss': 0.4621, 'learning_rate': 1.8074773828909935e-06, 'rewards/chosen': 0.23000794649124146, 'rewards/rejected': -0.19978782534599304, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4297958016395569, 'policy_logps/rejected': -437.1941833496094, 'policy_logps/chosen': -672.3540649414062, 'referece_logps/rejected': -435.1962890625, 'referece_logps/chosen': -674.6541137695312, 'logits/rejected': 0.012901872396469116, 'logits/chosen': -0.11453559994697571, 'epoch': 1.35}

 22%|██▏       | 3622/16104 [16:54:38<60:57:10, 17.58s/it]

 22%|██▏       | 3623/16104 [16:54:49<53:36:40, 15.46s/it]


 23%|██▎       | 3625/16104 [16:55:18<52:01:58, 15.01s/it]
{'loss': 0.454, 'learning_rate': 1.807002545218869e-06, 'rewards/chosen': 0.02323685586452484, 'rewards/rejected': -1.3313738107681274, 'rewards/accuracies': 0.75, 'rewards/margins': 1.354610562324524, 'policy_logps/rejected': -501.326416015625, 'policy_logps/chosen': -442.7467041015625, 'referece_logps/rejected': -488.0126953125, 'referece_logps/chosen': -442.97906494140625, 'logits/rejected': -0.6201837658882141, 'logits/chosen': -0.4966469407081604, 'epoch': 1.35}

 23%|██▎       | 3626/16104 [16:55:32<51:24:47, 14.83s/it]

 23%|██▎       | 3627/16104 [16:55:44<48:28:03, 13.98s/it]

 23%|██▎       | 3628/16104 [16:56:04<53:58:44, 15.58s/it]


 23%|██▎       | 3630/16104 [16:56:28<47:42:38, 13.77s/it]
{'loss': 0.464, 'learning_rate': 1.806408263659204e-06, 'rewards/chosen': -0.04514302313327789, 'rewards/rejected': -1.7767711877822876, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7316280603408813, 'policy_logps/rejected': -414.98944091796875, 'policy_logps/chosen': -677.1476440429688, 'referece_logps/rejected': -397.2216796875, 'referece_logps/chosen': -676.6962280273438, 'logits/rejected': -0.6639542579650879, 'logits/chosen': -0.6517727375030518, 'epoch': 1.35}

 23%|██▎       | 3631/16104 [16:56:47<52:43:29, 15.22s/it]

 23%|██▎       | 3632/16104 [16:56:57<47:53:08, 13.82s/it]

 23%|██▎       | 3633/16104 [16:57:15<51:57:30, 15.00s/it]

 23%|██▎       | 3634/16104 [16:57:35<56:40:58, 16.36s/it]

 23%|██▎       | 3635/16104 [16:57:51<56:48:52, 16.40s/it]

 23%|██▎       | 3636/16104 [16:58:03<51:46:54, 14.95s/it]

 23%|██▎       | 3637/16104 [16:58:23<57:15:27, 16.53s/it]

 23%|██▎       | 3638/16104 [16:58:36<54:11:27, 15.65s/it]

 23%|██▎       | 3639/16104 [16:58:57<59:45:14, 17.26s/it]

 23%|██▎       | 3640/16104 [16:59:09<53:25:29, 15.43s/it]


 23%|██▎       | 3642/16104 [16:59:38<51:49:45, 14.97s/it]

 23%|██▎       | 3643/16104 [16:59:59<57:31:14, 16.62s/it]

 23%|██▎       | 3644/16104 [17:00:17<59:35:03, 17.22s/it]

 23%|██▎       | 3645/16104 [17:00:35<60:36:59, 17.52s/it]

 23%|██▎       | 3646/16104 [17:00:50<57:52:57, 16.73s/it]

 23%|██▎       | 3647/16104 [17:01:12<62:34:17, 18.08s/it]

 23%|██▎       | 3648/16104 [17:01:30<62:40:47, 18.12s/it]

 23%|██▎       | 3649/16104 [17:01:53<67:49:07, 19.60s/it]
[2024-04-06 08:35:50,059] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 3650/16104 [17:02:05<60:17:21, 17.43s/it]

 23%|██▎       | 3651/16104 [17:02:27<64:25:46, 18.63s/it]
[2024-04-06 08:36:23,833] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 3652/16104 [17:02:44<63:23:55, 18.33s/it]

 23%|██▎       | 3653/16104 [17:03:00<60:40:39, 17.54s/it]

 23%|██▎       | 3654/16104 [17:03:17<60:18:52, 17.44s/it]

 23%|██▎       | 3655/16104 [17:03:32<57:52:14, 16.74s/it]

 23%|██▎       | 3656/16104 [17:03:47<55:41:32, 16.11s/it]
{'loss': 0.5194, 'learning_rate': 1.8033048670234447e-06, 'rewards/chosen': -0.8035116195678711, 'rewards/rejected': -1.0251274108886719, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2216157168149948, 'policy_logps/rejected': -451.94146728515625, 'policy_logps/chosen': -475.6488037109375, 'referece_logps/rejected': -441.690185546875, 'referece_logps/chosen': -467.6136474609375, 'logits/rejected': 0.037038654088974, 'logits/chosen': 0.10323147475719452, 'epoch': 1.36}


 23%|██▎       | 3658/16104 [17:04:16<52:46:40, 15.27s/it]

 23%|██▎       | 3659/16104 [17:04:36<57:42:58, 16.70s/it]

 23%|██▎       | 3660/16104 [17:04:55<60:43:15, 17.57s/it]

 23%|██▎       | 3661/16104 [17:05:06<53:37:14, 15.51s/it]

 23%|██▎       | 3662/16104 [17:05:19<51:24:44, 14.88s/it]
{'loss': 0.4299, 'learning_rate': 1.8025855759426898e-06, 'rewards/chosen': 0.2707657217979431, 'rewards/rejected': -1.0832233428955078, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3539891242980957, 'policy_logps/rejected': -417.50390625, 'policy_logps/chosen': -429.6916198730469, 'referece_logps/rejected': -406.671630859375, 'referece_logps/chosen': -432.3993225097656, 'logits/rejected': 0.487574964761734, 'logits/chosen': 0.4219123125076294, 'epoch': 1.36}


 23%|██▎       | 3664/16104 [17:05:51<53:38:24, 15.52s/it]

 23%|██▎       | 3665/16104 [17:06:06<52:16:18, 15.13s/it]

 23%|██▎       | 3666/16104 [17:06:25<56:51:22, 16.46s/it]

 23%|██▎       | 3667/16104 [17:06:37<52:23:48, 15.17s/it]
{'loss': 0.4524, 'learning_rate': 1.8019852738488127e-06, 'rewards/chosen': -0.35661250352859497, 'rewards/rejected': -0.9658060073852539, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6091935634613037, 'policy_logps/rejected': -286.8860778808594, 'policy_logps/chosen': -367.01190185546875, 'referece_logps/rejected': -277.22802734375, 'referece_logps/chosen': -363.4458312988281, 'logits/rejected': -0.010800160467624664, 'logits/chosen': -0.012653641402721405, 'epoch': 1.37}
[2024-04-06 08:40:46,096] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 23%|██▎       | 3669/16104 [17:07:08<53:31:34, 15.50s/it]

 23%|██▎       | 3670/16104 [17:07:24<54:29:40, 15.78s/it]

 23%|██▎       | 3671/16104 [17:07:37<51:41:41, 14.97s/it]

 23%|██▎       | 3672/16104 [17:07:56<56:04:05, 16.24s/it]
[2024-04-06 08:41:53,622] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 3673/16104 [17:08:11<53:57:00, 15.62s/it]

 23%|██▎       | 3674/16104 [17:08:21<48:43:37, 14.11s/it]

 23%|██▎       | 3675/16104 [17:08:33<46:03:59, 13.34s/it]

 23%|██▎       | 3676/16104 [17:08:49<49:33:27, 14.36s/it]

 23%|██▎       | 3677/16104 [17:09:01<47:12:10, 13.67s/it]

 23%|██▎       | 3678/16104 [17:09:21<53:44:46, 15.57s/it]

 23%|██▎       | 3679/16104 [17:09:38<54:37:56, 15.83s/it]

 23%|██▎       | 3680/16104 [17:09:53<54:12:54, 15.71s/it]

 23%|██▎       | 3681/16104 [17:10:13<58:44:21, 17.02s/it]

 23%|██▎       | 3682/16104 [17:10:27<54:41:49, 15.85s/it]

 23%|██▎       | 3683/16104 [17:10:46<58:30:36, 16.96s/it]

 23%|██▎       | 3684/16104 [17:10:58<53:44:48, 15.58s/it]

 23%|██▎       | 3685/16104 [17:11:17<57:05:31, 16.55s/it]

 23%|██▎       | 3686/16104 [17:11:28<50:53:07, 14.75s/it]

 23%|██▎       | 3687/16104 [17:11:47<55:24:31, 16.06s/it]

 23%|██▎       | 3688/16104 [17:12:03<55:25:04, 16.07s/it]

 23%|██▎       | 3689/16104 [17:12:22<58:39:31, 17.01s/it]
{'loss': 0.5894, 'learning_rate': 1.7993343176325184e-06, 'rewards/chosen': -0.0256221741437912, 'rewards/rejected': -0.2928813695907593, 'rewards/accuracies': 0.625, 'rewards/margins': 0.26725924015045166, 'policy_logps/rejected': -509.17047119140625, 'policy_logps/chosen': -464.17413330078125, 'referece_logps/rejected': -506.24169921875, 'referece_logps/chosen': -463.91790771484375, 'logits/rejected': 0.9485544562339783, 'logits/chosen': 0.9106265902519226, 'epoch': 1.37}


 23%|██▎       | 3691/16104 [17:13:02<64:19:22, 18.65s/it]

 23%|██▎       | 3692/16104 [17:13:17<60:06:07, 17.43s/it]

 23%|██▎       | 3693/16104 [17:13:39<64:31:10, 18.71s/it]
[2024-04-06 08:47:35,842] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 3694/16104 [17:13:54<61:15:36, 17.77s/it]

 23%|██▎       | 3695/16104 [17:14:14<63:15:12, 18.35s/it]

 23%|██▎       | 3696/16104 [17:14:37<68:08:10, 19.77s/it]
[2024-04-06 08:48:34,191] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 3697/16104 [17:14:50<61:16:41, 17.78s/it]
{'loss': 0.4538, 'learning_rate': 1.7983664506810677e-06, 'rewards/chosen': -0.2422257661819458, 'rewards/rejected': -1.5033257007598877, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2610998153686523, 'policy_logps/rejected': -345.04156494140625, 'policy_logps/chosen': -468.76715087890625, 'referece_logps/rejected': -330.0082702636719, 'referece_logps/chosen': -466.34490966796875, 'logits/rejected': -0.7513409852981567, 'logits/chosen': -0.8363441228866577, 'epoch': 1.38}
[2024-04-06 08:49:08,719] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 3698/16104 [17:15:11<65:00:05, 18.86s/it]
[2024-04-06 08:49:20,760] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 23%|██▎       | 3700/16104 [17:15:39<56:18:37, 16.34s/it]

 23%|██▎       | 3701/16104 [17:15:53<54:17:10, 15.76s/it]

 23%|██▎       | 3702/16104 [17:16:05<50:30:49, 14.66s/it]

 23%|██▎       | 3703/16104 [17:16:16<46:28:55, 13.49s/it]

 23%|██▎       | 3704/16104 [17:16:34<50:57:37, 14.79s/it]

 23%|██▎       | 3705/16104 [17:16:50<52:34:54, 15.27s/it]

 23%|██▎       | 3706/16104 [17:17:12<59:41:03, 17.33s/it]

 23%|██▎       | 3707/16104 [17:17:33<62:48:08, 18.24s/it]
[2024-04-06 08:51:29,960] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 3708/16104 [17:17:46<57:46:02, 16.78s/it]

 23%|██▎       | 3709/16104 [17:17:59<54:01:06, 15.69s/it]

 23%|██▎       | 3710/16104 [17:18:14<53:21:32, 15.50s/it]

 23%|██▎       | 3711/16104 [17:18:26<49:32:46, 14.39s/it]

 23%|██▎       | 3712/16104 [17:18:45<54:26:29, 15.82s/it]
{'loss': 0.5265, 'learning_rate': 1.7965461311747256e-06, 'rewards/chosen': -0.059469133615493774, 'rewards/rejected': -1.197736382484436, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1382672786712646, 'policy_logps/rejected': -309.6334228515625, 'policy_logps/chosen': -370.5250549316406, 'referece_logps/rejected': -297.6560363769531, 'referece_logps/chosen': -369.93035888671875, 'logits/rejected': 0.014921635389328003, 'logits/chosen': -0.08707407116889954, 'epoch': 1.38}


 23%|██▎       | 3714/16104 [17:19:22<59:04:27, 17.16s/it]

 23%|██▎       | 3715/16104 [17:19:40<59:55:48, 17.41s/it]

 23%|██▎       | 3716/16104 [17:19:58<60:54:53, 17.70s/it]

 23%|██▎       | 3717/16104 [17:20:17<61:20:50, 17.83s/it]

 23%|██▎       | 3718/16104 [17:20:35<62:17:00, 18.10s/it]

 23%|██▎       | 3719/16104 [17:20:50<59:13:10, 17.21s/it]

 23%|██▎       | 3720/16104 [17:21:09<60:07:52, 17.48s/it]

 23%|██▎       | 3721/16104 [17:21:28<62:15:13, 18.10s/it]

 23%|██▎       | 3722/16104 [17:21:49<65:13:58, 18.97s/it]
{'loss': 0.4751, 'learning_rate': 1.7953285561007243e-06, 'rewards/chosen': -0.3317662477493286, 'rewards/rejected': -1.3736298084259033, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0418635606765747, 'policy_logps/rejected': -463.3107604980469, 'policy_logps/chosen': -311.3829345703125, 'referece_logps/rejected': -449.574462890625, 'referece_logps/chosen': -308.0652770996094, 'logits/rejected': 0.10127289593219757, 'logits/chosen': 0.19100406765937805, 'epoch': 1.39}


 23%|██▎       | 3724/16104 [17:22:30<68:23:34, 19.89s/it]

 23%|██▎       | 3725/16104 [17:22:50<68:10:07, 19.82s/it]

 23%|██▎       | 3726/16104 [17:23:10<68:20:26, 19.88s/it]

 23%|██▎       | 3727/16104 [17:23:27<65:46:43, 19.13s/it]

 23%|██▎       | 3728/16104 [17:23:49<69:02:38, 20.08s/it]

 23%|██▎       | 3729/16104 [17:24:03<62:51:06, 18.28s/it]

 23%|██▎       | 3730/16104 [17:24:21<61:55:54, 18.02s/it]

 23%|██▎       | 3731/16104 [17:24:41<64:28:40, 18.76s/it]

 23%|██▎       | 3732/16104 [17:25:01<65:32:49, 19.07s/it]

 23%|██▎       | 3733/16104 [17:25:15<60:05:55, 17.49s/it]

 23%|██▎       | 3734/16104 [17:25:35<63:07:04, 18.37s/it]

 23%|██▎       | 3735/16104 [17:25:53<62:43:39, 18.26s/it]
{'loss': 0.4692, 'learning_rate': 1.7937408994613936e-06, 'rewards/chosen': 0.5765394568443298, 'rewards/rejected': -0.727525532245636, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3040649890899658, 'policy_logps/rejected': -425.4957275390625, 'policy_logps/chosen': -508.68994140625, 'referece_logps/rejected': -418.220458984375, 'referece_logps/chosen': -514.455322265625, 'logits/rejected': -0.35272014141082764, 'logits/chosen': -0.20036515593528748, 'epoch': 1.39}

 23%|██▎       | 3736/16104 [17:26:14<65:05:59, 18.95s/it]


 23%|██▎       | 3738/16104 [17:26:43<58:03:03, 16.90s/it]
{'loss': 0.4888, 'learning_rate': 1.7933737461668112e-06, 'rewards/chosen': -0.25051891803741455, 'rewards/rejected': -1.2357934713363647, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9852745532989502, 'policy_logps/rejected': -478.6034240722656, 'policy_logps/chosen': -528.3013916015625, 'referece_logps/rejected': -466.2455139160156, 'referece_logps/chosen': -525.7962036132812, 'logits/rejected': -0.41614991426467896, 'logits/chosen': -0.332733154296875, 'epoch': 1.39}


 23%|██▎       | 3740/16104 [17:27:12<53:25:50, 15.56s/it]

 23%|██▎       | 3741/16104 [17:27:25<50:42:29, 14.77s/it]

 23%|██▎       | 3742/16104 [17:27:45<56:00:20, 16.31s/it]

 23%|██▎       | 3743/16104 [17:28:01<55:53:45, 16.28s/it]

 23%|██▎       | 3744/16104 [17:28:23<60:51:59, 17.73s/it]

 23%|██▎       | 3745/16104 [17:28:45<65:27:52, 19.07s/it]

 23%|██▎       | 3746/16104 [17:28:57<58:50:02, 17.14s/it]

 23%|██▎       | 3747/16104 [17:29:13<57:32:47, 16.77s/it]

 23%|██▎       | 3748/16104 [17:29:27<54:32:48, 15.89s/it]
{'loss': 0.4416, 'learning_rate': 1.7921478165332845e-06, 'rewards/chosen': -0.32349836826324463, 'rewards/rejected': -0.5171010494232178, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1936027556657791, 'policy_logps/rejected': -351.4029235839844, 'policy_logps/chosen': -462.76153564453125, 'referece_logps/rejected': -346.23187255859375, 'referece_logps/chosen': -459.5265197753906, 'logits/rejected': -0.35035958886146545, 'logits/chosen': -0.348158597946167, 'epoch': 1.4}

 23%|██▎       | 3749/16104 [17:29:48<59:55:56, 17.46s/it]


 23%|██▎       | 3751/16104 [17:30:27<62:47:26, 18.30s/it]

 23%|██▎       | 3752/16104 [17:30:47<64:23:03, 18.76s/it]

 23%|██▎       | 3753/16104 [17:31:09<68:12:31, 19.88s/it]
[2024-04-06 09:05:06,365] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 3754/16104 [17:31:26<65:12:59, 19.01s/it]
[2024-04-06 09:05:23,344] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 23%|██▎       | 3755/16104 [17:31:40<59:30:56, 17.35s/it]

 23%|██▎       | 3756/16104 [17:31:59<61:43:57, 18.00s/it]

 23%|██▎       | 3757/16104 [17:32:13<57:56:41, 16.89s/it]

 23%|██▎       | 3758/16104 [17:32:32<59:22:50, 17.31s/it]

 23%|██▎       | 3759/16104 [17:32:43<53:36:09, 15.63s/it]
{'loss': 0.5629, 'learning_rate': 1.7907955930708893e-06, 'rewards/chosen': -0.4771730899810791, 'rewards/rejected': -1.1166999340057373, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6395268440246582, 'policy_logps/rejected': -353.04364013671875, 'policy_logps/chosen': -312.4859619140625, 'referece_logps/rejected': -341.8766174316406, 'referece_logps/chosen': -307.7142333984375, 'logits/rejected': -0.17288050055503845, 'logits/chosen': -0.1319049745798111, 'epoch': 1.4}
[2024-04-06 09:06:59,763] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 23%|██▎       | 3761/16104 [17:33:21<59:01:03, 17.21s/it]

 23%|██▎       | 3762/16104 [17:33:32<52:29:51, 15.31s/it]
{'loss': 0.6886, 'learning_rate': 1.790426132804268e-06, 'rewards/chosen': -0.8223951458930969, 'rewards/rejected': -0.5932367444038391, 'rewards/accuracies': 0.75, 'rewards/margins': -0.22915847599506378, 'policy_logps/rejected': -404.8052673339844, 'policy_logps/chosen': -493.7507019042969, 'referece_logps/rejected': -398.8729248046875, 'referece_logps/chosen': -485.5267333984375, 'logits/rejected': -0.6189088225364685, 'logits/chosen': -0.5872861742973328, 'epoch': 1.4}

 23%|██▎       | 3763/16104 [17:33:47<52:27:23, 15.30s/it]


 23%|██▎       | 3765/16104 [17:34:22<55:12:49, 16.11s/it]

 23%|██▎       | 3766/16104 [17:34:40<57:34:00, 16.80s/it]
{'loss': 0.4739, 'learning_rate': 1.789933071500649e-06, 'rewards/chosen': -0.49454376101493835, 'rewards/rejected': -1.4144961833953857, 'rewards/accuracies': 0.75, 'rewards/margins': 0.919952392578125, 'policy_logps/rejected': -226.2301788330078, 'policy_logps/chosen': -344.31842041015625, 'referece_logps/rejected': -212.08523559570312, 'referece_logps/chosen': -339.37298583984375, 'logits/rejected': -0.31487107276916504, 'logits/chosen': -0.3732173442840576, 'epoch': 1.4}


 23%|██▎       | 3768/16104 [17:35:10<54:57:01, 16.04s/it]

 23%|██▎       | 3769/16104 [17:35:28<56:52:41, 16.60s/it]

 23%|██▎       | 3770/16104 [17:35:46<58:15:09, 17.00s/it]

 23%|██▎       | 3771/16104 [17:36:00<54:40:11, 15.96s/it]

 23%|██▎       | 3772/16104 [17:36:16<54:24:11, 15.88s/it]
{'loss': 0.5378, 'learning_rate': 1.7891925210190144e-06, 'rewards/chosen': -0.4839065372943878, 'rewards/rejected': -1.3632934093475342, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8793869018554688, 'policy_logps/rejected': -484.93597412109375, 'policy_logps/chosen': -528.425048828125, 'referece_logps/rejected': -471.3030090332031, 'referece_logps/chosen': -523.5859375, 'logits/rejected': -0.15911200642585754, 'logits/chosen': -0.13334950804710388, 'epoch': 1.41}


 23%|██▎       | 3774/16104 [17:36:45<51:27:29, 15.02s/it]
{'loss': 0.553, 'learning_rate': 1.7889454154112288e-06, 'rewards/chosen': -0.2612934112548828, 'rewards/rejected': -1.0227644443511963, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7614710330963135, 'policy_logps/rejected': -416.7414245605469, 'policy_logps/chosen': -342.496826171875, 'referece_logps/rejected': -406.5137939453125, 'referece_logps/chosen': -339.8839111328125, 'logits/rejected': -0.7679551243782043, 'logits/chosen': -0.717050313949585, 'epoch': 1.41}


 23%|██▎       | 3776/16104 [17:37:16<52:00:55, 15.19s/it]
{'loss': 0.4655, 'learning_rate': 1.7886981821464451e-06, 'rewards/chosen': -0.10862770676612854, 'rewards/rejected': -0.8710570931434631, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7624292969703674, 'policy_logps/rejected': -376.0208740234375, 'policy_logps/chosen': -524.5618286132812, 'referece_logps/rejected': -367.310302734375, 'referece_logps/chosen': -523.4755249023438, 'logits/rejected': 0.2517430782318115, 'logits/chosen': 0.2070729285478592, 'epoch': 1.41}


 23%|██▎       | 3778/16104 [17:37:52<58:05:42, 16.97s/it]

 23%|██▎       | 3779/16104 [17:38:04<52:31:26, 15.34s/it]
{'loss': 0.5587, 'learning_rate': 1.7883270929799124e-06, 'rewards/chosen': -0.08091869950294495, 'rewards/rejected': -1.399120807647705, 'rewards/accuracies': 0.875, 'rewards/margins': 1.318202018737793, 'policy_logps/rejected': -342.0398254394531, 'policy_logps/chosen': -418.4603576660156, 'referece_logps/rejected': -328.0486145019531, 'referece_logps/chosen': -417.6511535644531, 'logits/rejected': -0.5831295847892761, 'logits/chosen': -0.46025508642196655, 'epoch': 1.41}

 23%|██▎       | 3780/16104 [17:38:23<57:12:03, 16.71s/it]


 23%|██▎       | 3782/16104 [17:38:52<51:53:57, 15.16s/it]

 23%|██▎       | 3783/16104 [17:39:12<56:51:18, 16.61s/it]
{'loss': 0.4782, 'learning_rate': 1.7878318609985854e-06, 'rewards/chosen': -0.1787298023700714, 'rewards/rejected': -1.1202995777130127, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9415698051452637, 'policy_logps/rejected': -405.8175048828125, 'policy_logps/chosen': -320.388916015625, 'referece_logps/rejected': -394.614501953125, 'referece_logps/chosen': -318.60162353515625, 'logits/rejected': -0.651874303817749, 'logits/chosen': -0.36993208527565, 'epoch': 1.41}

 23%|██▎       | 3784/16104 [17:39:27<54:56:50, 16.06s/it]

 24%|██▎       | 3785/16104 [17:39:38<49:28:41, 14.46s/it]

 24%|██▎       | 3786/16104 [17:39:52<48:57:50, 14.31s/it]


 24%|██▎       | 3788/16104 [17:40:18<46:53:09, 13.70s/it]
{'loss': 0.5862, 'learning_rate': 1.7872121040024516e-06, 'rewards/chosen': -0.4668165445327759, 'rewards/rejected': -0.9364395141601562, 'rewards/accuracies': 0.625, 'rewards/margins': 0.46962299942970276, 'policy_logps/rejected': -366.6593322753906, 'policy_logps/chosen': -321.2453918457031, 'referece_logps/rejected': -357.294921875, 'referece_logps/chosen': -316.5772399902344, 'logits/rejected': -0.41304150223731995, 'logits/chosen': -0.3266289234161377, 'epoch': 1.41}

 24%|██▎       | 3789/16104 [17:40:33<48:42:36, 14.24s/it]


 24%|██▎       | 3791/16104 [17:41:02<49:51:06, 14.58s/it]

 24%|██▎       | 3792/16104 [17:41:17<49:33:00, 14.49s/it]
{'loss': 0.5421, 'learning_rate': 1.7867157251810609e-06, 'rewards/chosen': -0.23919564485549927, 'rewards/rejected': -0.6005200743675232, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3613244295120239, 'policy_logps/rejected': -367.76495361328125, 'policy_logps/chosen': -413.5130920410156, 'referece_logps/rejected': -361.759765625, 'referece_logps/chosen': -411.12115478515625, 'logits/rejected': -0.19147884845733643, 'logits/chosen': -0.1361880898475647, 'epoch': 1.41}


 24%|██▎       | 3794/16104 [17:41:50<52:40:56, 15.41s/it]

 24%|██▎       | 3795/16104 [17:42:08<55:26:18, 16.21s/it]
{'loss': 0.6028, 'learning_rate': 1.7863431068948755e-06, 'rewards/chosen': -0.4624662399291992, 'rewards/rejected': -1.0173031091690063, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5548368096351624, 'policy_logps/rejected': -562.9442138671875, 'policy_logps/chosen': -562.3563232421875, 'referece_logps/rejected': -552.7711791992188, 'referece_logps/chosen': -557.731689453125, 'logits/rejected': -0.49546462297439575, 'logits/chosen': -0.5472711324691772, 'epoch': 1.41}


 24%|██▎       | 3797/16104 [17:42:39<52:40:41, 15.41s/it]
{'loss': 0.5346, 'learning_rate': 1.7860945356508022e-06, 'rewards/chosen': 0.2824589014053345, 'rewards/rejected': -0.6806381344795227, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9630970358848572, 'policy_logps/rejected': -281.5935974121094, 'policy_logps/chosen': -372.757080078125, 'referece_logps/rejected': -274.7872314453125, 'referece_logps/chosen': -375.5816345214844, 'logits/rejected': -0.11287729442119598, 'logits/chosen': -0.21160997450351715, 'epoch': 1.41}


 24%|██▎       | 3799/16104 [17:43:09<52:56:05, 15.49s/it]
{'loss': 0.5518, 'learning_rate': 1.7858458372110229e-06, 'rewards/chosen': 0.03788526728749275, 'rewards/rejected': -0.22682590782642365, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2647112011909485, 'policy_logps/rejected': -378.83905029296875, 'policy_logps/chosen': -373.61376953125, 'referece_logps/rejected': -376.5708312988281, 'referece_logps/chosen': -373.99261474609375, 'logits/rejected': -0.5350215435028076, 'logits/chosen': -0.5132198333740234, 'epoch': 1.42}


 24%|██▎       | 3801/16104 [17:43:45<57:52:20, 16.93s/it]

 24%|██▎       | 3802/16104 [17:43:59<54:49:40, 16.04s/it]
{'loss': 0.5531, 'learning_rate': 1.7854725511474387e-06, 'rewards/chosen': -0.08193368464708328, 'rewards/rejected': -0.4898395240306854, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4079059064388275, 'policy_logps/rejected': -406.46136474609375, 'policy_logps/chosen': -476.6910095214844, 'referece_logps/rejected': -401.5630187988281, 'referece_logps/chosen': -475.8716125488281, 'logits/rejected': -0.3082852065563202, 'logits/chosen': -0.30089935660362244, 'epoch': 1.42}


 24%|██▎       | 3804/16104 [17:44:22<47:49:10, 14.00s/it]
{'loss': 0.5023, 'learning_rate': 1.7852235348944955e-06, 'rewards/chosen': 0.29652178287506104, 'rewards/rejected': -0.9342899918556213, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2308118343353271, 'policy_logps/rejected': -447.3384704589844, 'policy_logps/chosen': -680.6900634765625, 'referece_logps/rejected': -437.9955749511719, 'referece_logps/chosen': -683.6552734375, 'logits/rejected': -0.6969007253646851, 'logits/chosen': -0.6101768612861633, 'epoch': 1.42}


 24%|██▎       | 3806/16104 [17:44:54<51:18:04, 15.02s/it]

 24%|██▎       | 3807/16104 [17:45:15<57:07:08, 16.72s/it]

 24%|██▎       | 3808/16104 [17:45:27<52:13:56, 15.29s/it]

 24%|██▎       | 3809/16104 [17:45:46<56:48:44, 16.63s/it]

 24%|██▎       | 3810/16104 [17:46:11<64:23:50, 18.86s/it]
[2024-04-06 09:20:07,766] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 24%|██▎       | 3811/16104 [17:46:29<63:33:11, 18.61s/it]
[2024-04-06 09:20:25,804] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4957, 'learning_rate': 1.7843509777174735e-06, 'rewards/chosen': 0.3455149829387665, 'rewards/rejected': -0.6696394681930542, 'rewards/accuracies': 0.875, 'rewards/margins': 1.015154480934143, 'policy_logps/rejected': -322.7505798339844, 'policy_logps/chosen': -575.9090576171875, 'referece_logps/rejected': -316.05419921875, 'referece_logps/chosen': -579.3641967773438, 'logits/rejected': -0.007256209850311279, 'logits/chosen': -0.004130087792873383, 'epoch': 1.42}

 24%|██▎       | 3812/16104 [17:46:43<59:36:24, 17.46s/it]

 24%|██▎       | 3813/16104 [17:46:54<52:37:21, 15.41s/it]


 24%|██▎       | 3815/16104 [17:47:25<51:02:26, 14.95s/it]

 24%|██▎       | 3816/16104 [17:47:36<47:49:34, 14.01s/it]

 24%|██▎       | 3817/16104 [17:47:47<44:31:51, 13.05s/it]

 24%|██▎       | 3818/16104 [17:48:00<44:40:05, 13.09s/it]

 24%|██▎       | 3819/16104 [17:48:11<42:17:49, 12.39s/it]

 24%|██▎       | 3820/16104 [17:48:23<41:35:31, 12.19s/it]
{'loss': 0.5646, 'learning_rate': 1.7832268342880673e-06, 'rewards/chosen': -0.044915568083524704, 'rewards/rejected': -0.5970457196235657, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5521301627159119, 'policy_logps/rejected': -459.4262390136719, 'policy_logps/chosen': -493.5127868652344, 'referece_logps/rejected': -453.455810546875, 'referece_logps/chosen': -493.0636291503906, 'logits/rejected': -0.4565994143486023, 'logits/chosen': -0.4568837285041809, 'epoch': 1.42}

 24%|██▎       | 3821/16104 [17:48:44<50:56:42, 14.93s/it]


 24%|██▎       | 3823/16104 [17:49:15<51:36:20, 15.13s/it]

 24%|██▎       | 3824/16104 [17:49:37<58:33:48, 17.17s/it]
{'loss': 0.4442, 'learning_rate': 1.7827263910110777e-06, 'rewards/chosen': -0.061350807547569275, 'rewards/rejected': -1.0727479457855225, 'rewards/accuracies': 1.0, 'rewards/margins': 1.011397123336792, 'policy_logps/rejected': -222.67218017578125, 'policy_logps/chosen': -318.79742431640625, 'referece_logps/rejected': -211.94468688964844, 'referece_logps/chosen': -318.1839294433594, 'logits/rejected': -0.4918123781681061, 'logits/chosen': -0.381622314453125, 'epoch': 1.42}


 24%|██▍       | 3826/16104 [17:50:15<61:27:50, 18.02s/it]
[2024-04-06 09:24:11,984] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4802, 'learning_rate': 1.7824759793762602e-06, 'rewards/chosen': -0.17520542442798615, 'rewards/rejected': -1.298893928527832, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1236886978149414, 'policy_logps/rejected': -270.6309814453125, 'policy_logps/chosen': -468.7738037109375, 'referece_logps/rejected': -257.64202880859375, 'referece_logps/chosen': -467.0217590332031, 'logits/rejected': 0.6988027095794678, 'logits/chosen': 0.8400049805641174, 'epoch': 1.43}

 24%|██▍       | 3827/16104 [17:50:30<58:19:24, 17.10s/it]

 24%|██▍       | 3828/16104 [17:50:52<63:20:50, 18.58s/it]


 24%|██▍       | 3830/16104 [17:51:33<67:00:59, 19.66s/it]
[2024-04-06 09:25:30,314] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4582, 'learning_rate': 1.7819747763165718e-06, 'rewards/chosen': -0.7575728893280029, 'rewards/rejected': -1.6915652751922607, 'rewards/accuracies': 1.0, 'rewards/margins': 0.933992326259613, 'policy_logps/rejected': -556.4990844726562, 'policy_logps/chosen': -490.1917724609375, 'referece_logps/rejected': -539.5834350585938, 'referece_logps/chosen': -482.6160583496094, 'logits/rejected': -0.34040942788124084, 'logits/chosen': -0.3858833909034729, 'epoch': 1.43}
[2024-04-06 09:25:49,079] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 24%|██▍       | 3832/16104 [17:52:11<66:14:49, 19.43s/it]

 24%|██▍       | 3833/16104 [17:52:23<58:38:47, 17.21s/it]

 24%|██▍       | 3834/16104 [17:52:35<52:52:46, 15.51s/it]

 24%|██▍       | 3835/16104 [17:52:55<57:37:09, 16.91s/it]
[2024-04-06 09:26:52,348] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.4225, 'learning_rate': 1.7813475608038528e-06, 'rewards/chosen': 0.00811939500272274, 'rewards/rejected': -0.8784140348434448, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8865333795547485, 'policy_logps/rejected': -405.8197937011719, 'policy_logps/chosen': -441.90911865234375, 'referece_logps/rejected': -397.03564453125, 'referece_logps/chosen': -441.99029541015625, 'logits/rejected': -0.07474077492952347, 'logits/chosen': -0.0857124999165535, 'epoch': 1.43}


 24%|██▍       | 3837/16104 [17:53:23<53:15:14, 15.63s/it]
{'loss': 0.4316, 'learning_rate': 1.7810964533149132e-06, 'rewards/chosen': -0.21405059099197388, 'rewards/rejected': -0.9709232449531555, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7568725943565369, 'policy_logps/rejected': -287.985595703125, 'policy_logps/chosen': -434.2057189941406, 'referece_logps/rejected': -278.2763977050781, 'referece_logps/chosen': -432.0652160644531, 'logits/rejected': 0.8058484792709351, 'logits/chosen': 0.6611005663871765, 'epoch': 1.43}


 24%|██▍       | 3839/16104 [17:53:57<57:21:43, 16.84s/it]

 24%|██▍       | 3840/16104 [17:54:17<59:51:51, 17.57s/it]
{'loss': 0.489, 'learning_rate': 1.780719555118619e-06, 'rewards/chosen': 0.46460187435150146, 'rewards/rejected': -0.8995674252510071, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3641692399978638, 'policy_logps/rejected': -491.1021728515625, 'policy_logps/chosen': -554.3379516601562, 'referece_logps/rejected': -482.1064453125, 'referece_logps/chosen': -558.9839477539062, 'logits/rejected': 0.5191349983215332, 'logits/chosen': 0.3731151223182678, 'epoch': 1.43}


 24%|██▍       | 3842/16104 [17:54:44<51:59:16, 15.26s/it]
{'loss': 0.451, 'learning_rate': 1.7804681317384567e-06, 'rewards/chosen': 0.1446884274482727, 'rewards/rejected': -0.8311747312545776, 'rewards/accuracies': 0.75, 'rewards/margins': 0.975862979888916, 'policy_logps/rejected': -401.2022705078125, 'policy_logps/chosen': -491.5649719238281, 'referece_logps/rejected': -392.8905029296875, 'referece_logps/chosen': -493.0118408203125, 'logits/rejected': -0.015776660293340683, 'logits/chosen': -0.02855166420340538, 'epoch': 1.43}


 24%|██▍       | 3844/16104 [17:55:14<51:03:37, 14.99s/it]

 24%|██▍       | 3845/16104 [17:55:31<53:24:13, 15.68s/it]
{'loss': 0.4946, 'learning_rate': 1.7800907598959694e-06, 'rewards/chosen': 0.0343044251203537, 'rewards/rejected': -0.9868304133415222, 'rewards/accuracies': 0.625, 'rewards/margins': 1.021134853363037, 'policy_logps/rejected': -502.9798889160156, 'policy_logps/chosen': -362.4736633300781, 'referece_logps/rejected': -493.111572265625, 'referece_logps/chosen': -362.81671142578125, 'logits/rejected': 0.45898354053497314, 'logits/chosen': 0.31376707553863525, 'epoch': 1.43}

 24%|██▍       | 3846/16104 [17:55:46<52:42:38, 15.48s/it]


 24%|██▍       | 3848/16104 [17:56:17<52:58:01, 15.56s/it]

 24%|██▍       | 3849/16104 [17:56:35<54:49:59, 16.11s/it]
{'loss': 0.4426, 'learning_rate': 1.7795871556782065e-06, 'rewards/chosen': -0.18580399453639984, 'rewards/rejected': -1.142765760421753, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9569618701934814, 'policy_logps/rejected': -432.19000244140625, 'policy_logps/chosen': -355.74188232421875, 'referece_logps/rejected': -420.7623596191406, 'referece_logps/chosen': -353.8838195800781, 'logits/rejected': -0.34470993280410767, 'logits/chosen': -0.04824294149875641, 'epoch': 1.43}


 24%|██▍       | 3851/16104 [17:57:01<49:13:01, 14.46s/it]

 24%|██▍       | 3852/16104 [17:57:20<53:09:19, 15.62s/it]

 24%|██▍       | 3853/16104 [17:57:32<49:38:06, 14.59s/it]

 24%|██▍       | 3854/16104 [17:57:49<52:23:39, 15.40s/it]
{'loss': 0.5815, 'learning_rate': 1.7789569408912052e-06, 'rewards/chosen': 0.19509050250053406, 'rewards/rejected': -0.8829224109649658, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0780129432678223, 'policy_logps/rejected': -394.185302734375, 'policy_logps/chosen': -498.4242248535156, 'referece_logps/rejected': -385.3560791015625, 'referece_logps/chosen': -500.3751220703125, 'logits/rejected': 0.5339738130569458, 'logits/chosen': 0.5347184538841248, 'epoch': 1.44}


 24%|██▍       | 3856/16104 [17:58:24<56:51:27, 16.71s/it]
{'loss': 0.475, 'learning_rate': 1.778704634369317e-06, 'rewards/chosen': 0.4522949457168579, 'rewards/rejected': -0.730110228061676, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1824052333831787, 'policy_logps/rejected': -311.0519714355469, 'policy_logps/chosen': -394.94122314453125, 'referece_logps/rejected': -303.7508239746094, 'referece_logps/chosen': -399.46417236328125, 'logits/rejected': -0.6191672086715698, 'logits/chosen': -0.5200209617614746, 'epoch': 1.44}

 24%|██▍       | 3857/16104 [17:58:39<55:02:19, 16.18s/it]

 24%|██▍       | 3858/16104 [17:58:56<56:37:31, 16.65s/it]

 24%|██▍       | 3859/16104 [17:59:16<59:56:09, 17.62s/it]


 24%|██▍       | 3861/16104 [17:59:56<62:36:30, 18.41s/it]
{'loss': 0.45, 'learning_rate': 1.7780733169040962e-06, 'rewards/chosen': 0.3754458427429199, 'rewards/rejected': -0.9093572497367859, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2848031520843506, 'policy_logps/rejected': -379.3995056152344, 'policy_logps/chosen': -427.0687561035156, 'referece_logps/rejected': -370.305908203125, 'referece_logps/chosen': -430.8232421875, 'logits/rejected': -0.3700035512447357, 'logits/chosen': -0.17135030031204224, 'epoch': 1.44}

 24%|██▍       | 3862/16104 [18:00:11<59:08:42, 17.39s/it]

 24%|██▍       | 3863/16104 [18:00:25<55:55:27, 16.45s/it]


 24%|██▍       | 3865/16104 [18:01:00<58:57:41, 17.34s/it]

 24%|██▍       | 3866/16104 [18:01:16<57:37:48, 16.95s/it]

 24%|██▍       | 3867/16104 [18:01:31<55:48:50, 16.42s/it]

 24%|██▍       | 3868/16104 [18:01:49<57:33:16, 16.93s/it]

 24%|██▍       | 3869/16104 [18:02:01<52:38:22, 15.49s/it]
{'loss': 0.5217, 'learning_rate': 1.7770615725541527e-06, 'rewards/chosen': -0.5919513702392578, 'rewards/rejected': -1.1163862943649292, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5244347453117371, 'policy_logps/rejected': -494.54388427734375, 'policy_logps/chosen': -393.1136779785156, 'referece_logps/rejected': -483.3800048828125, 'referece_logps/chosen': -387.1941833496094, 'logits/rejected': 0.7951531410217285, 'logits/chosen': 0.8183103799819946, 'epoch': 1.44}

 24%|██▍       | 3870/16104 [18:02:23<59:01:41, 17.37s/it]


 24%|██▍       | 3872/16104 [18:03:00<61:21:17, 18.06s/it]

 24%|██▍       | 3873/16104 [18:03:16<59:13:40, 17.43s/it]
{'loss': 0.3776, 'learning_rate': 1.7765549458107757e-06, 'rewards/chosen': 0.19824466109275818, 'rewards/rejected': -1.089841604232788, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2880862951278687, 'policy_logps/rejected': -433.0143737792969, 'policy_logps/chosen': -390.22442626953125, 'referece_logps/rejected': -422.1159362792969, 'referece_logps/chosen': -392.20684814453125, 'logits/rejected': 0.5877037644386292, 'logits/chosen': 0.5973976850509644, 'epoch': 1.44}

 24%|██▍       | 3874/16104 [18:03:32<58:30:46, 17.22s/it]


 24%|██▍       | 3876/16104 [18:04:14<64:44:52, 19.06s/it]
{'loss': 0.3251, 'learning_rate': 1.7761746458984657e-06, 'rewards/chosen': 0.10430040955543518, 'rewards/rejected': -1.222775936126709, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3270764350891113, 'policy_logps/rejected': -397.9295654296875, 'policy_logps/chosen': -425.658447265625, 'referece_logps/rejected': -385.7017822265625, 'referece_logps/chosen': -426.7013854980469, 'logits/rejected': -0.5954573154449463, 'logits/chosen': -0.5467784404754639, 'epoch': 1.44}


 24%|██▍       | 3878/16104 [18:04:46<60:00:40, 17.67s/it]

 24%|██▍       | 3879/16104 [18:05:04<60:15:11, 17.74s/it]
{'loss': 0.5171, 'learning_rate': 1.7757940634073174e-06, 'rewards/chosen': -0.23829157650470734, 'rewards/rejected': -1.4081261157989502, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1698346138000488, 'policy_logps/rejected': -397.5214538574219, 'policy_logps/chosen': -341.5269470214844, 'referece_logps/rejected': -383.440185546875, 'referece_logps/chosen': -339.14404296875, 'logits/rejected': -0.2878583073616028, 'logits/chosen': -0.20783235132694244, 'epoch': 1.45}


 24%|██▍       | 3881/16104 [18:05:42<62:52:12, 18.52s/it]
{'loss': 0.5464, 'learning_rate': 1.775540184826728e-06, 'rewards/chosen': -0.2995040714740753, 'rewards/rejected': -0.7787344455718994, 'rewards/accuracies': 0.75, 'rewards/margins': 0.47923028469085693, 'policy_logps/rejected': -342.7969055175781, 'policy_logps/chosen': -293.19097900390625, 'referece_logps/rejected': -335.0095520019531, 'referece_logps/chosen': -290.1959533691406, 'logits/rejected': -0.7301440238952637, 'logits/chosen': -0.7086907625198364, 'epoch': 1.45}

 24%|██▍       | 3882/16104 [18:05:55<56:50:26, 16.74s/it]


 24%|██▍       | 3884/16104 [18:06:24<52:15:19, 15.39s/it]

 24%|██▍       | 3885/16104 [18:06:43<56:21:21, 16.60s/it]
{'loss': 0.6032, 'learning_rate': 1.775032051242839e-06, 'rewards/chosen': -0.49627965688705444, 'rewards/rejected': -0.2193688452243805, 'rewards/accuracies': 0.5, 'rewards/margins': -0.27691078186035156, 'policy_logps/rejected': -395.96588134765625, 'policy_logps/chosen': -499.3247375488281, 'referece_logps/rejected': -393.77215576171875, 'referece_logps/chosen': -494.3619384765625, 'logits/rejected': -0.17460307478904724, 'logits/chosen': -0.24573040008544922, 'epoch': 1.45}

 24%|██▍       | 3886/16104 [18:07:03<59:27:44, 17.52s/it]

 24%|██▍       | 3887/16104 [18:07:23<61:40:24, 18.17s/it]


 24%|██▍       | 3889/16104 [18:07:48<52:45:12, 15.55s/it]
{'loss': 0.5003, 'learning_rate': 1.774523416036103e-06, 'rewards/chosen': -0.19136273860931396, 'rewards/rejected': -1.351677656173706, 'rewards/accuracies': 0.75, 'rewards/margins': 1.160314917564392, 'policy_logps/rejected': -371.3414001464844, 'policy_logps/chosen': -507.0570373535156, 'referece_logps/rejected': -357.8246154785156, 'referece_logps/chosen': -505.1434326171875, 'logits/rejected': -0.4893648624420166, 'logits/chosen': -0.46345821022987366, 'epoch': 1.45}

 24%|██▍       | 3890/16104 [18:08:08<57:01:30, 16.81s/it]

 24%|██▍       | 3891/16104 [18:08:28<60:20:36, 17.79s/it]

 24%|██▍       | 3892/16104 [18:08:49<63:45:47, 18.80s/it]

 24%|██▍       | 3893/16104 [18:09:02<57:28:15, 16.94s/it]

 24%|██▍       | 3894/16104 [18:09:21<60:08:05, 17.73s/it]


 24%|██▍       | 3896/16104 [18:09:44<49:07:40, 14.49s/it]
{'loss': 0.5964, 'learning_rate': 1.7736320983847052e-06, 'rewards/chosen': 0.012898240238428116, 'rewards/rejected': -0.1529380828142166, 'rewards/accuracies': 0.625, 'rewards/margins': 0.16583634912967682, 'policy_logps/rejected': -519.5184936523438, 'policy_logps/chosen': -567.5131225585938, 'referece_logps/rejected': -517.9891357421875, 'referece_logps/chosen': -567.64208984375, 'logits/rejected': 0.14224472641944885, 'logits/chosen': 0.1329842209815979, 'epoch': 1.45}


 24%|██▍       | 3898/16104 [18:10:23<58:05:01, 17.13s/it]
{'loss': 0.4788, 'learning_rate': 1.7733771544681093e-06, 'rewards/chosen': -0.2884540557861328, 'rewards/rejected': -1.371574878692627, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0831208229064941, 'policy_logps/rejected': -358.06427001953125, 'policy_logps/chosen': -399.9407043457031, 'referece_logps/rejected': -344.3485412597656, 'referece_logps/chosen': -397.0561828613281, 'logits/rejected': 0.1476251184940338, 'logits/chosen': 0.14977480471134186, 'epoch': 1.45}


 24%|██▍       | 3900/16104 [18:11:01<62:02:59, 18.30s/it]
{'loss': 0.4751, 'learning_rate': 1.7731220854135706e-06, 'rewards/chosen': -0.4436527490615845, 'rewards/rejected': -1.8799418210983276, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4362891912460327, 'policy_logps/rejected': -563.2576904296875, 'policy_logps/chosen': -512.6372680664062, 'referece_logps/rejected': -544.458251953125, 'referece_logps/chosen': -508.2007751464844, 'logits/rejected': -0.018917083740234375, 'logits/chosen': 0.03355443477630615, 'epoch': 1.45}

 24%|██▍       | 3901/16104 [18:11:15<57:45:41, 17.04s/it]

 24%|██▍       | 3902/16104 [18:11:26<51:31:27, 15.20s/it]

 24%|██▍       | 3903/16104 [18:11:40<50:51:29, 15.01s/it]

 24%|██▍       | 3904/16104 [18:11:59<54:56:31, 16.21s/it]

 24%|██▍       | 3905/16104 [18:12:19<58:46:21, 17.34s/it]

 24%|██▍       | 3906/16104 [18:12:40<62:32:07, 18.46s/it]

 24%|██▍       | 3907/16104 [18:12:55<58:59:26, 17.41s/it]

 24%|██▍       | 3908/16104 [18:13:06<52:16:53, 15.43s/it]

 24%|██▍       | 3909/16104 [18:13:25<56:10:51, 16.58s/it]

 24%|██▍       | 3910/16104 [18:13:45<59:34:03, 17.59s/it]


 24%|██▍       | 3912/16104 [18:14:13<53:34:35, 15.82s/it]
{'loss': 0.5206, 'learning_rate': 1.7715890455021913e-06, 'rewards/chosen': -0.392974853515625, 'rewards/rejected': -1.337938904762268, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9449640512466431, 'policy_logps/rejected': -273.55322265625, 'policy_logps/chosen': -339.9382629394531, 'referece_logps/rejected': -260.1737976074219, 'referece_logps/chosen': -336.008544921875, 'logits/rejected': -0.14081884920597076, 'logits/chosen': -0.10482095181941986, 'epoch': 1.46}

 24%|██▍       | 3913/16104 [18:14:36<60:35:52, 17.89s/it]


 24%|██▍       | 3915/16104 [18:15:07<57:12:42, 16.90s/it]
{'loss': 0.4567, 'learning_rate': 1.7712050829018196e-06, 'rewards/chosen': -0.37302514910697937, 'rewards/rejected': -0.9638385772705078, 'rewards/accuracies': 0.75, 'rewards/margins': 0.590813398361206, 'policy_logps/rejected': -564.2052612304688, 'policy_logps/chosen': -523.8771362304688, 'referece_logps/rejected': -554.56689453125, 'referece_logps/chosen': -520.1468505859375, 'logits/rejected': -0.12458282709121704, 'logits/chosen': -0.017324842512607574, 'epoch': 1.46}

 24%|██▍       | 3916/16104 [18:15:25<58:35:56, 17.31s/it]

 24%|██▍       | 3917/16104 [18:15:42<57:36:44, 17.02s/it]

 24%|██▍       | 3918/16104 [18:16:00<58:35:59, 17.31s/it]

 24%|██▍       | 3919/16104 [18:16:12<53:36:21, 15.84s/it]

 24%|██▍       | 3920/16104 [18:16:25<51:16:02, 15.15s/it]

 24%|██▍       | 3921/16104 [18:16:37<47:54:35, 14.16s/it]

 24%|██▍       | 3922/16104 [18:16:54<50:32:43, 14.94s/it]


 24%|██▍       | 3924/16104 [18:17:35<60:31:51, 17.89s/it]

 24%|██▍       | 3925/16104 [18:17:55<62:32:18, 18.49s/it]

 24%|██▍       | 3926/16104 [18:18:09<57:53:38, 17.11s/it]

 24%|██▍       | 3927/16104 [18:18:27<58:56:00, 17.42s/it]

 24%|██▍       | 3928/16104 [18:18:45<59:21:51, 17.55s/it]
{'loss': 0.5221, 'learning_rate': 1.769538002315177e-06, 'rewards/chosen': -0.42524242401123047, 'rewards/rejected': -1.1790075302124023, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7537650465965271, 'policy_logps/rejected': -332.29632568359375, 'policy_logps/chosen': -310.5817565917969, 'referece_logps/rejected': -320.5062255859375, 'referece_logps/chosen': -306.329345703125, 'logits/rejected': 0.06754538416862488, 'logits/chosen': 0.05206013470888138, 'epoch': 1.46}

 24%|██▍       | 3929/16104 [18:18:56<52:47:48, 15.61s/it]

 24%|██▍       | 3930/16104 [18:19:13<53:59:41, 15.97s/it]

 24%|██▍       | 3931/16104 [18:19:28<52:48:15, 15.62s/it]

 24%|██▍       | 3932/16104 [18:19:47<57:11:51, 16.92s/it]

 24%|██▍       | 3933/16104 [18:20:08<60:42:32, 17.96s/it]

 24%|██▍       | 3934/16104 [18:20:29<64:25:30, 19.06s/it]

 24%|██▍       | 3935/16104 [18:20:48<63:29:29, 18.78s/it]


 24%|██▍       | 3937/16104 [18:21:19<58:17:15, 17.25s/it]
{'loss': 0.4339, 'learning_rate': 1.7683807871275422e-06, 'rewards/chosen': 0.04967782273888588, 'rewards/rejected': -0.7570865154266357, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8067644834518433, 'policy_logps/rejected': -657.0986938476562, 'policy_logps/chosen': -429.636962890625, 'referece_logps/rejected': -649.5277709960938, 'referece_logps/chosen': -430.1337585449219, 'logits/rejected': -0.4431418776512146, 'logits/chosen': 0.12076748162508011, 'epoch': 1.47}

 24%|██▍       | 3938/16104 [18:21:30<51:41:52, 15.30s/it]


 24%|██▍       | 3940/16104 [18:22:03<52:59:10, 15.68s/it]

 24%|██▍       | 3941/16104 [18:22:19<53:02:36, 15.70s/it]
{'loss': 0.5762, 'learning_rate': 1.7678656608991771e-06, 'rewards/chosen': -0.15832625329494476, 'rewards/rejected': -0.7680931091308594, 'rewards/accuracies': 0.75, 'rewards/margins': 0.609766960144043, 'policy_logps/rejected': -448.7327880859375, 'policy_logps/chosen': -467.0008544921875, 'referece_logps/rejected': -441.0518493652344, 'referece_logps/chosen': -465.4176025390625, 'logits/rejected': -0.9516955614089966, 'logits/chosen': -0.8519296050071716, 'epoch': 1.47}

 24%|██▍       | 3942/16104 [18:22:30<48:03:38, 14.23s/it]

 24%|██▍       | 3943/16104 [18:22:50<53:57:01, 15.97s/it]


 24%|██▍       | 3945/16104 [18:23:25<55:23:27, 16.40s/it]
{'loss': 0.7407, 'learning_rate': 1.7673500376862571e-06, 'rewards/chosen': -0.7334898114204407, 'rewards/rejected': -0.3997358977794647, 'rewards/accuracies': 0.5, 'rewards/margins': -0.33375391364097595, 'policy_logps/rejected': -471.6591796875, 'policy_logps/chosen': -504.1889953613281, 'referece_logps/rejected': -467.6617736816406, 'referece_logps/chosen': -496.8541259765625, 'logits/rejected': -0.7116415500640869, 'logits/chosen': -0.5813396573066711, 'epoch': 1.47}

 25%|██▍       | 3946/16104 [18:23:45<58:46:18, 17.40s/it]

 25%|██▍       | 3947/16104 [18:24:07<63:19:00, 18.75s/it]

 25%|██▍       | 3948/16104 [18:24:19<56:18:29, 16.68s/it]

 25%|██▍       | 3949/16104 [18:24:38<59:26:19, 17.60s/it]

 25%|██▍       | 3950/16104 [18:24:51<54:34:19, 16.16s/it]

 25%|██▍       | 3951/16104 [18:25:10<57:38:50, 17.08s/it]

 25%|██▍       | 3952/16104 [18:25:22<52:11:57, 15.46s/it]

 25%|██▍       | 3953/16104 [18:25:39<53:33:36, 15.87s/it]

 25%|██▍       | 3954/16104 [18:25:57<55:39:14, 16.49s/it]


 25%|██▍       | 3956/16104 [18:26:31<58:09:50, 17.24s/it]
{'loss': 0.5478, 'learning_rate': 1.765929513999826e-06, 'rewards/chosen': -0.20692235231399536, 'rewards/rejected': -1.2214823961257935, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0145601034164429, 'policy_logps/rejected': -315.7524108886719, 'policy_logps/chosen': -265.6070556640625, 'referece_logps/rejected': -303.5376281738281, 'referece_logps/chosen': -263.5378112792969, 'logits/rejected': 0.19276900589466095, 'logits/chosen': 0.2545686364173889, 'epoch': 1.47}

 25%|██▍       | 3957/16104 [18:26:53<62:34:39, 18.55s/it]

 25%|██▍       | 3958/16104 [18:27:11<61:56:56, 18.36s/it]

 25%|██▍       | 3959/16104 [18:27:26<59:02:42, 17.50s/it]

 25%|██▍       | 3960/16104 [18:27:45<60:06:32, 17.82s/it]

 25%|██▍       | 3961/16104 [18:27:57<54:14:52, 16.08s/it]


 25%|██▍       | 3963/16104 [18:28:36<59:58:45, 17.78s/it]

 25%|██▍       | 3964/16104 [18:28:56<62:01:55, 18.40s/it]

 25%|██▍       | 3965/16104 [18:29:13<61:30:23, 18.24s/it]
{'loss': 0.4543, 'learning_rate': 1.7647644785449966e-06, 'rewards/chosen': -0.24210579693317413, 'rewards/rejected': -1.1677875518798828, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9256817102432251, 'policy_logps/rejected': -302.1752014160156, 'policy_logps/chosen': -472.0915222167969, 'referece_logps/rejected': -290.4973449707031, 'referece_logps/chosen': -469.67047119140625, 'logits/rejected': -0.17620623111724854, 'logits/chosen': -0.2317446768283844, 'epoch': 1.48}

 25%|██▍       | 3966/16104 [18:29:26<55:56:04, 16.59s/it]

 25%|██▍       | 3967/16104 [18:29:44<57:27:46, 17.04s/it]

 25%|██▍       | 3968/16104 [18:29:59<55:18:00, 16.40s/it]

 25%|██▍       | 3969/16104 [18:30:12<52:03:16, 15.44s/it]


 25%|██▍       | 3971/16104 [18:30:46<54:46:24, 16.25s/it]
{'loss': 0.561, 'learning_rate': 1.7639863958822213e-06, 'rewards/chosen': -0.0021841004490852356, 'rewards/rejected': -0.876939594745636, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8747554421424866, 'policy_logps/rejected': -409.9656982421875, 'policy_logps/chosen': -443.9481506347656, 'referece_logps/rejected': -401.1962585449219, 'referece_logps/chosen': -443.92626953125, 'logits/rejected': -0.08750364184379578, 'logits/chosen': -0.11958187073469162, 'epoch': 1.48}

 25%|██▍       | 3972/16104 [18:30:56<48:56:59, 14.53s/it]


 25%|██▍       | 3974/16104 [18:31:34<56:01:53, 16.63s/it]
{'loss': 0.5237, 'learning_rate': 1.7635969372677252e-06, 'rewards/chosen': -0.1861141175031662, 'rewards/rejected': -0.2781173586845398, 'rewards/accuracies': 0.375, 'rewards/margins': 0.09200327098369598, 'policy_logps/rejected': -363.2001647949219, 'policy_logps/chosen': -452.4660949707031, 'referece_logps/rejected': -360.4190368652344, 'referece_logps/chosen': -450.6050109863281, 'logits/rejected': -0.2893621027469635, 'logits/chosen': -0.21563784778118134, 'epoch': 1.48}

 25%|██▍       | 3975/16104 [18:31:45<50:32:20, 15.00s/it]

 25%|██▍       | 3976/16104 [18:32:01<52:14:44, 15.51s/it]

 25%|██▍       | 3977/16104 [18:32:17<51:47:45, 15.38s/it]

 25%|██▍       | 3978/16104 [18:32:32<52:15:53, 15.52s/it]

 25%|██▍       | 3979/16104 [18:32:43<47:21:50, 14.06s/it]

 25%|██▍       | 3980/16104 [18:33:01<51:17:31, 15.23s/it]

 25%|██▍       | 3981/16104 [18:33:21<55:46:44, 16.56s/it]

 25%|██▍       | 3982/16104 [18:33:34<52:45:39, 15.67s/it]

 25%|██▍       | 3983/16104 [18:33:45<47:56:49, 14.24s/it]

 25%|██▍       | 3984/16104 [18:34:05<53:40:43, 15.94s/it]


 25%|██▍       | 3986/16104 [18:34:36<53:27:28, 15.88s/it]

 25%|██▍       | 3987/16104 [18:34:48<49:06:21, 14.59s/it]

 25%|██▍       | 3988/16104 [18:35:08<54:53:58, 16.31s/it]
{'loss': 0.5348, 'learning_rate': 1.7617757902534186e-06, 'rewards/chosen': 0.3226776123046875, 'rewards/rejected': -0.6291935443878174, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9518711566925049, 'policy_logps/rejected': -467.9385070800781, 'policy_logps/chosen': -435.74310302734375, 'referece_logps/rejected': -461.6465759277344, 'referece_logps/chosen': -438.96990966796875, 'logits/rejected': -0.5961175560951233, 'logits/chosen': -0.5565879940986633, 'epoch': 1.49}

 25%|██▍       | 3989/16104 [18:35:26<56:14:27, 16.71s/it]

 25%|██▍       | 3990/16104 [18:35:45<59:01:52, 17.54s/it]


 25%|██▍       | 3992/16104 [18:36:18<56:04:24, 16.67s/it]
{'loss': 0.4322, 'learning_rate': 1.7612543525562882e-06, 'rewards/chosen': -0.4351096749305725, 'rewards/rejected': -1.4462999105453491, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0111902952194214, 'policy_logps/rejected': -444.28619384765625, 'policy_logps/chosen': -505.46697998046875, 'referece_logps/rejected': -429.8232727050781, 'referece_logps/chosen': -501.11590576171875, 'logits/rejected': -0.366499125957489, 'logits/chosen': -0.3284968137741089, 'epoch': 1.49}

 25%|██▍       | 3993/16104 [18:36:32<52:51:26, 15.71s/it]

 25%|██▍       | 3994/16104 [18:36:43<48:49:32, 14.51s/it]


 25%|██▍       | 3996/16104 [18:37:10<46:39:27, 13.87s/it]
{'loss': 0.5093, 'learning_rate': 1.7607324221536306e-06, 'rewards/chosen': 0.07673128694295883, 'rewards/rejected': -0.5917743444442749, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6685056686401367, 'policy_logps/rejected': -602.3316650390625, 'policy_logps/chosen': -484.5168151855469, 'referece_logps/rejected': -596.413818359375, 'referece_logps/chosen': -485.2841491699219, 'logits/rejected': -0.2051098495721817, 'logits/chosen': -0.02652713656425476, 'epoch': 1.49}

 25%|██▍       | 3997/16104 [18:37:27<49:30:43, 14.72s/it]

 25%|██▍       | 3998/16104 [18:37:42<50:00:23, 14.87s/it]

 25%|██▍       | 3999/16104 [18:37:54<47:24:37, 14.10s/it]

 25%|██▍       | 4000/16104 [18:38:14<52:40:47, 15.67s/it]

 25%|██▍       | 4001/16104 [18:38:42<65:39:54, 19.53s/it]

 25%|██▍       | 4002/16104 [18:39:02<65:47:08, 19.57s/it]

 25%|██▍       | 4003/16104 [18:39:20<64:10:20, 19.09s/it]

 25%|██▍       | 4004/16104 [18:39:38<63:03:40, 18.76s/it]

 25%|██▍       | 4005/16104 [18:39:59<65:11:41, 19.40s/it]

 25%|██▍       | 4006/16104 [18:40:11<58:25:21, 17.38s/it]

 25%|██▍       | 4007/16104 [18:40:28<57:30:18, 17.11s/it]

 25%|██▍       | 4008/16104 [18:40:46<58:34:19, 17.43s/it]

 25%|██▍       | 4009/16104 [18:41:05<59:46:38, 17.79s/it]

 25%|██▍       | 4010/16104 [18:41:24<61:25:34, 18.28s/it]

 25%|██▍       | 4011/16104 [18:41:41<60:11:15, 17.92s/it]

 25%|██▍       | 4012/16104 [18:42:02<62:46:57, 18.69s/it]

 25%|██▍       | 4013/16104 [18:42:14<56:13:14, 16.74s/it]

 25%|██▍       | 4014/16104 [18:42:25<50:18:56, 14.98s/it]

 25%|██▍       | 4015/16104 [18:42:38<48:39:40, 14.49s/it]

 25%|██▍       | 4016/16104 [18:42:51<47:33:33, 14.16s/it]

 25%|██▍       | 4017/16104 [18:43:10<51:39:22, 15.39s/it]

 25%|██▍       | 4018/16104 [18:43:25<51:22:53, 15.30s/it]

 25%|██▍       | 4019/16104 [18:43:43<54:09:20, 16.13s/it]

 25%|██▍       | 4020/16104 [18:44:01<56:25:05, 16.81s/it]

 25%|██▍       | 4021/16104 [18:44:22<60:10:46, 17.93s/it]

 25%|██▍       | 4022/16104 [18:44:43<63:19:54, 18.87s/it]

 25%|██▍       | 4023/16104 [18:45:05<66:09:23, 19.71s/it]

 25%|██▍       | 4024/16104 [18:45:23<64:49:19, 19.32s/it]

 25%|██▍       | 4025/16104 [18:45:35<57:19:22, 17.08s/it]

 25%|██▌       | 4026/16104 [18:45:55<60:13:14, 17.95s/it]

 25%|██▌       | 4027/16104 [18:46:13<60:39:08, 18.08s/it]

 25%|██▌       | 4028/16104 [18:46:34<63:15:42, 18.86s/it]

 25%|██▌       | 4029/16104 [18:46:50<60:46:36, 18.12s/it]

 25%|██▌       | 4030/16104 [18:47:02<54:46:39, 16.33s/it]


 25%|██▌       | 4032/16104 [18:47:31<52:01:09, 15.51s/it]

 25%|██▌       | 4033/16104 [18:47:44<49:51:17, 14.87s/it]

 25%|██▌       | 4034/16104 [18:47:55<45:41:57, 13.63s/it]

 25%|██▌       | 4035/16104 [18:48:09<46:15:16, 13.80s/it]
{'loss': 0.5541, 'learning_rate': 1.7556178493593927e-06, 'rewards/chosen': -0.04577236995100975, 'rewards/rejected': -0.5116803050041199, 'rewards/accuracies': 0.5, 'rewards/margins': 0.46590790152549744, 'policy_logps/rejected': -322.86260986328125, 'policy_logps/chosen': -343.8918151855469, 'referece_logps/rejected': -317.745849609375, 'referece_logps/chosen': -343.43408203125, 'logits/rejected': -0.0362795926630497, 'logits/chosen': -0.07592637091875076, 'epoch': 1.5}


 25%|██▌       | 4037/16104 [18:48:42<50:36:21, 15.10s/it]

 25%|██▌       | 4038/16104 [18:49:01<54:41:20, 16.32s/it]

 25%|██▌       | 4039/16104 [18:49:13<50:07:45, 14.96s/it]

 25%|██▌       | 4040/16104 [18:49:24<46:03:42, 13.75s/it]

 25%|██▌       | 4041/16104 [18:49:40<48:13:57, 14.39s/it]

 25%|██▌       | 4042/16104 [18:49:54<47:53:08, 14.29s/it]

 25%|██▌       | 4043/16104 [18:50:11<50:10:51, 14.98s/it]

 25%|██▌       | 4044/16104 [18:50:29<53:33:55, 15.99s/it]

 25%|██▌       | 4045/16104 [18:50:48<56:51:59, 16.98s/it]

 25%|██▌       | 4046/16104 [18:51:04<55:58:34, 16.71s/it]

 25%|██▌       | 4047/16104 [18:51:24<59:02:15, 17.63s/it]

 25%|██▌       | 4048/16104 [18:51:44<61:41:49, 18.42s/it]

 25%|██▌       | 4049/16104 [18:52:06<65:17:39, 19.50s/it]

 25%|██▌       | 4050/16104 [18:52:25<63:55:41, 19.09s/it]
{'loss': 0.5454, 'learning_rate': 1.7536383094924707e-06, 'rewards/chosen': 0.18288783729076385, 'rewards/rejected': -0.3413364291191101, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5242242813110352, 'policy_logps/rejected': -439.38360595703125, 'policy_logps/chosen': -364.724609375, 'referece_logps/rejected': -435.9702453613281, 'referece_logps/chosen': -366.55352783203125, 'logits/rejected': 0.06543035805225372, 'logits/chosen': 0.1777123212814331, 'epoch': 1.51}


 25%|██▌       | 4052/16104 [18:53:00<61:16:43, 18.30s/it]

 25%|██▌       | 4053/16104 [18:53:20<62:38:35, 18.71s/it]

 25%|██▌       | 4054/16104 [18:53:38<61:48:25, 18.47s/it]

 25%|██▌       | 4055/16104 [18:53:57<62:44:14, 18.74s/it]

 25%|██▌       | 4056/16104 [18:54:12<59:25:24, 17.76s/it]

 25%|██▌       | 4057/16104 [18:54:32<61:09:23, 18.28s/it]

 25%|██▌       | 4058/16104 [18:54:46<57:05:58, 17.06s/it]

 25%|██▌       | 4059/16104 [18:55:03<56:40:52, 16.94s/it]

 25%|██▌       | 4060/16104 [18:55:20<56:35:31, 16.92s/it]

 25%|██▌       | 4061/16104 [18:55:41<61:10:42, 18.29s/it]

 25%|██▌       | 4062/16104 [18:56:01<62:45:51, 18.76s/it]

 25%|██▌       | 4063/16104 [18:56:18<61:20:08, 18.34s/it]

 25%|██▌       | 4064/16104 [18:56:38<63:05:54, 18.87s/it]

 25%|██▌       | 4065/16104 [18:56:58<63:57:53, 19.13s/it]

 25%|██▌       | 4066/16104 [18:57:18<65:05:48, 19.47s/it]

 25%|██▌       | 4067/16104 [18:57:36<63:14:43, 18.92s/it]

 25%|██▌       | 4068/16104 [18:57:56<63:51:44, 19.10s/it]

 25%|██▌       | 4069/16104 [18:58:17<65:46:19, 19.67s/it]

 25%|██▌       | 4070/16104 [18:58:31<59:58:16, 17.94s/it]

 25%|██▌       | 4071/16104 [18:58:51<62:14:42, 18.62s/it]

 25%|██▌       | 4072/16104 [18:59:10<63:16:20, 18.93s/it]

 25%|██▌       | 4073/16104 [18:59:31<64:35:21, 19.33s/it]

 25%|██▌       | 4074/16104 [18:59:42<57:00:13, 17.06s/it]

 25%|██▌       | 4075/16104 [19:00:00<57:47:23, 17.30s/it]

 25%|██▌       | 4076/16104 [19:00:17<57:31:38, 17.22s/it]

 25%|██▌       | 4077/16104 [19:00:31<54:16:52, 16.25s/it]

 25%|██▌       | 4078/16104 [19:00:51<57:49:20, 17.31s/it]

 25%|██▌       | 4079/16104 [19:01:10<58:56:34, 17.65s/it]

 25%|██▌       | 4080/16104 [19:01:22<53:52:41, 16.13s/it]

 25%|██▌       | 4081/16104 [19:01:42<57:35:31, 17.24s/it]

 25%|██▌       | 4082/16104 [19:01:57<54:54:04, 16.44s/it]

 25%|██▌       | 4083/16104 [19:02:12<53:47:24, 16.11s/it]

 25%|██▌       | 4084/16104 [19:02:29<54:53:38, 16.44s/it]

 25%|██▌       | 4085/16104 [19:02:49<58:12:12, 17.43s/it]

 25%|██▌       | 4086/16104 [19:03:08<59:51:16, 17.93s/it]

 25%|██▌       | 4087/16104 [19:03:21<54:33:00, 16.34s/it]

 25%|██▌       | 4088/16104 [19:03:39<57:08:10, 17.12s/it]

 25%|██▌       | 4089/16104 [19:03:59<59:30:16, 17.83s/it]

 25%|██▌       | 4090/16104 [19:04:17<59:17:04, 17.76s/it]

 25%|██▌       | 4091/16104 [19:04:39<63:57:53, 19.17s/it]

 25%|██▌       | 4092/16104 [19:04:56<61:50:33, 18.53s/it]

 25%|██▌       | 4093/16104 [19:05:16<63:04:36, 18.91s/it]

 25%|██▌       | 4094/16104 [19:05:37<65:40:08, 19.68s/it]

 25%|██▌       | 4095/16104 [19:05:55<63:51:03, 19.14s/it]

 25%|██▌       | 4096/16104 [19:06:15<64:12:59, 19.25s/it]

 25%|██▌       | 4097/16104 [19:06:32<62:10:40, 18.64s/it]

 25%|██▌       | 4098/16104 [19:06:49<60:22:20, 18.10s/it]

 25%|██▌       | 4099/16104 [19:07:11<64:27:27, 19.33s/it]

 25%|██▌       | 4100/16104 [19:07:25<59:15:03, 17.77s/it]

 25%|██▌       | 4101/16104 [19:07:38<54:39:03, 16.39s/it]

 25%|██▌       | 4102/16104 [19:08:00<59:33:58, 17.87s/it]

 25%|██▌       | 4103/16104 [19:08:18<59:40:42, 17.90s/it]

 25%|██▌       | 4104/16104 [19:08:38<62:16:11, 18.68s/it]

 25%|██▌       | 4105/16104 [19:08:54<59:26:27, 17.83s/it]
{'loss': 0.5446, 'learning_rate': 1.746321448804247e-06, 'rewards/chosen': -0.029871558770537376, 'rewards/rejected': -1.5334831476211548, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5036115646362305, 'policy_logps/rejected': -513.0843505859375, 'policy_logps/chosen': -478.81488037109375, 'referece_logps/rejected': -497.7495422363281, 'referece_logps/chosen': -478.51611328125, 'logits/rejected': -0.3691762685775757, 'logits/chosen': -0.2846049964427948, 'epoch': 1.53}

 25%|██▌       | 4106/16104 [19:09:13<60:19:38, 18.10s/it]

 26%|██▌       | 4107/16104 [19:09:31<60:28:45, 18.15s/it]


 26%|██▌       | 4109/16104 [19:10:10<62:56:11, 18.89s/it]

 26%|██▌       | 4110/16104 [19:10:33<67:20:02, 20.21s/it]

 26%|██▌       | 4111/16104 [19:10:53<67:07:57, 20.15s/it]
{'loss': 0.5579, 'learning_rate': 1.74551770490884e-06, 'rewards/chosen': -0.05940324068069458, 'rewards/rejected': -1.5737963914871216, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5143932104110718, 'policy_logps/rejected': -372.06842041015625, 'policy_logps/chosen': -534.0830688476562, 'referece_logps/rejected': -356.3304443359375, 'referece_logps/chosen': -533.489013671875, 'logits/rejected': -0.08299532532691956, 'logits/chosen': -0.14890068769454956, 'epoch': 1.53}


 26%|██▌       | 4113/16104 [19:11:34<67:37:01, 20.30s/it]

 26%|██▌       | 4114/16104 [19:11:56<68:45:10, 20.64s/it]
{'loss': 0.4653, 'learning_rate': 1.7451154257614284e-06, 'rewards/chosen': -0.6134585738182068, 'rewards/rejected': -0.980643630027771, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3671850860118866, 'policy_logps/rejected': -327.3956604003906, 'policy_logps/chosen': -348.1439208984375, 'referece_logps/rejected': -317.5892333984375, 'referece_logps/chosen': -342.00933837890625, 'logits/rejected': 0.603525698184967, 'logits/chosen': 0.7661200761795044, 'epoch': 1.53}


 26%|██▌       | 4116/16104 [19:12:31<63:22:01, 19.03s/it]

 26%|██▌       | 4117/16104 [19:12:48<61:18:11, 18.41s/it]
{'loss': 0.4507, 'learning_rate': 1.7447128753427864e-06, 'rewards/chosen': -0.22508087754249573, 'rewards/rejected': -1.7758021354675293, 'rewards/accuracies': 0.875, 'rewards/margins': 1.550721287727356, 'policy_logps/rejected': -472.3334045410156, 'policy_logps/chosen': -394.3571472167969, 'referece_logps/rejected': -454.57537841796875, 'referece_logps/chosen': -392.1063232421875, 'logits/rejected': -0.31833773851394653, 'logits/chosen': -0.12729093432426453, 'epoch': 1.53}

 26%|██▌       | 4118/16104 [19:13:07<62:26:48, 18.76s/it]


 26%|██▌       | 4120/16104 [19:13:44<62:34:10, 18.80s/it]

 26%|██▌       | 4121/16104 [19:14:04<63:08:36, 18.97s/it]
{'loss': 0.5142, 'learning_rate': 1.7441757197271133e-06, 'rewards/chosen': 0.18315696716308594, 'rewards/rejected': -0.7571926116943359, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9403495788574219, 'policy_logps/rejected': -514.5054321289062, 'policy_logps/chosen': -583.0337524414062, 'referece_logps/rejected': -506.9335021972656, 'referece_logps/chosen': -584.8652954101562, 'logits/rejected': 0.1992948055267334, 'logits/chosen': 0.18782903254032135, 'epoch': 1.54}


 26%|██▌       | 4123/16104 [19:14:37<59:05:46, 17.76s/it]

 26%|██▌       | 4124/16104 [19:14:50<54:20:24, 16.33s/it]

 26%|██▌       | 4125/16104 [19:15:03<51:05:57, 15.36s/it]
{'loss': 0.4967, 'learning_rate': 1.7436380824596913e-06, 'rewards/chosen': -0.024386227130889893, 'rewards/rejected': -0.9840580224990845, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9596717953681946, 'policy_logps/rejected': -382.0727844238281, 'policy_logps/chosen': -494.560791015625, 'referece_logps/rejected': -372.232177734375, 'referece_logps/chosen': -494.3169250488281, 'logits/rejected': -0.4839187562465668, 'logits/chosen': -0.5110070705413818, 'epoch': 1.54}


 26%|██▌       | 4127/16104 [19:15:44<60:14:19, 18.11s/it]

 26%|██▌       | 4128/16104 [19:16:04<61:36:14, 18.52s/it]

 26%|██▌       | 4129/16104 [19:16:20<59:39:00, 17.93s/it]
{'loss': 0.4692, 'learning_rate': 1.7430999638884942e-06, 'rewards/chosen': -0.23963984847068787, 'rewards/rejected': -1.324084997177124, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0844451189041138, 'policy_logps/rejected': -415.86651611328125, 'policy_logps/chosen': -371.853515625, 'referece_logps/rejected': -402.62567138671875, 'referece_logps/chosen': -369.45709228515625, 'logits/rejected': -0.2586697041988373, 'logits/chosen': -0.15233083069324493, 'epoch': 1.54}


 26%|██▌       | 4131/16104 [19:16:56<59:44:45, 17.96s/it]
{'loss': 0.5606, 'learning_rate': 1.7428307242228075e-06, 'rewards/chosen': 0.42706114053726196, 'rewards/rejected': -0.7240872383117676, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1511484384536743, 'policy_logps/rejected': -333.24066162109375, 'policy_logps/chosen': -410.3951721191406, 'referece_logps/rejected': -325.99981689453125, 'referece_logps/chosen': -414.665771484375, 'logits/rejected': 0.7467681169509888, 'logits/chosen': 0.7981720566749573, 'epoch': 1.54}

 26%|██▌       | 4132/16104 [19:17:08<53:32:35, 16.10s/it]


 26%|██▌       | 4134/16104 [19:17:46<59:12:23, 17.81s/it]

 26%|██▌       | 4135/16104 [19:18:08<63:38:38, 19.14s/it]

 26%|██▌       | 4136/16104 [19:18:28<64:18:33, 19.34s/it]
{'loss': 0.4342, 'learning_rate': 1.7421570992994447e-06, 'rewards/chosen': -0.7739248275756836, 'rewards/rejected': -1.4309544563293457, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6570295095443726, 'policy_logps/rejected': -287.7522888183594, 'policy_logps/chosen': -362.51678466796875, 'referece_logps/rejected': -273.4427490234375, 'referece_logps/chosen': -354.77752685546875, 'logits/rejected': 0.4365903437137604, 'logits/chosen': 0.40937554836273193, 'epoch': 1.54}


 26%|██▌       | 4138/16104 [19:19:03<62:16:47, 18.74s/it]

 26%|██▌       | 4139/16104 [19:19:19<59:17:07, 17.84s/it]

 26%|██▌       | 4140/16104 [19:19:37<59:44:49, 17.98s/it]
{'loss': 0.6983, 'learning_rate': 1.7416176589396514e-06, 'rewards/chosen': -1.0055078268051147, 'rewards/rejected': -1.1161744594573975, 'rewards/accuracies': 0.5, 'rewards/margins': 0.11066660284996033, 'policy_logps/rejected': -517.7317504882812, 'policy_logps/chosen': -623.3873291015625, 'referece_logps/rejected': -506.57000732421875, 'referece_logps/chosen': -613.332275390625, 'logits/rejected': 0.5493407845497131, 'logits/chosen': 0.5362544655799866, 'epoch': 1.54}


 26%|██▌       | 4142/16104 [19:20:07<55:05:02, 16.58s/it]

 26%|██▌       | 4143/16104 [19:20:18<50:10:21, 15.10s/it]

 26%|██▌       | 4144/16104 [19:20:38<54:36:21, 16.44s/it]

 26%|██▌       | 4145/16104 [19:20:54<54:40:19, 16.46s/it]
{'loss': 0.5012, 'learning_rate': 1.7409426835363394e-06, 'rewards/chosen': 0.013628758490085602, 'rewards/rejected': -1.1974503993988037, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2110791206359863, 'policy_logps/rejected': -423.53460693359375, 'policy_logps/chosen': -549.3212890625, 'referece_logps/rejected': -411.5600891113281, 'referece_logps/chosen': -549.4575805664062, 'logits/rejected': 0.4864629805088043, 'logits/chosen': 0.3783155083656311, 'epoch': 1.54}

 26%|██▌       | 4146/16104 [19:21:07<51:12:58, 15.42s/it]

 26%|██▌       | 4147/16104 [19:21:23<51:38:53, 15.55s/it]


 26%|██▌       | 4149/16104 [19:22:03<58:48:34, 17.71s/it]

 26%|██▌       | 4150/16104 [19:22:17<54:50:00, 16.51s/it]
{'loss': 0.4942, 'learning_rate': 1.7402669588217442e-06, 'rewards/chosen': -0.259174644947052, 'rewards/rejected': -0.8761262893676758, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6169517040252686, 'policy_logps/rejected': -688.6954345703125, 'policy_logps/chosen': -599.8772583007812, 'referece_logps/rejected': -679.9341430664062, 'referece_logps/chosen': -597.2854614257812, 'logits/rejected': -0.5110850930213928, 'logits/chosen': -0.39387062191963196, 'epoch': 1.55}


 26%|██▌       | 4152/16104 [19:22:51<55:29:28, 16.71s/it]
{'loss': 0.5041, 'learning_rate': 1.7399964592817935e-06, 'rewards/chosen': 0.05692368745803833, 'rewards/rejected': -0.5331514477729797, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5900751352310181, 'policy_logps/rejected': -481.25775146484375, 'policy_logps/chosen': -504.35577392578125, 'referece_logps/rejected': -475.92620849609375, 'referece_logps/chosen': -504.92498779296875, 'logits/rejected': -0.32646429538726807, 'logits/chosen': -0.26133620738983154, 'epoch': 1.55}


 26%|██▌       | 4154/16104 [19:23:15<47:11:56, 14.22s/it]
{'loss': 0.5452, 'learning_rate': 1.7397258400051347e-06, 'rewards/chosen': -0.37364792823791504, 'rewards/rejected': -1.5832980871200562, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2096502780914307, 'policy_logps/rejected': -291.51171875, 'policy_logps/chosen': -421.6180419921875, 'referece_logps/rejected': -275.6787414550781, 'referece_logps/chosen': -417.88153076171875, 'logits/rejected': -0.12231836467981339, 'logits/chosen': -0.05691847205162048, 'epoch': 1.55}


 26%|██▌       | 4156/16104 [19:23:47<51:20:11, 15.47s/it]
{'loss': 0.4396, 'learning_rate': 1.7394551010355558e-06, 'rewards/chosen': -0.13565406203269958, 'rewards/rejected': -0.9605313539505005, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8248772621154785, 'policy_logps/rejected': -252.46096801757812, 'policy_logps/chosen': -402.7727966308594, 'referece_logps/rejected': -242.85565185546875, 'referece_logps/chosen': -401.41619873046875, 'logits/rejected': -0.5781691074371338, 'logits/chosen': -0.557342529296875, 'epoch': 1.55}


 26%|██▌       | 4158/16104 [19:24:08<43:10:19, 13.01s/it]

 26%|██▌       | 4159/16104 [19:24:19<40:58:07, 12.35s/it]

 26%|██▌       | 4160/16104 [19:24:40<49:49:19, 15.02s/it]

 26%|██▌       | 4161/16104 [19:24:54<49:09:39, 14.82s/it]

 26%|██▌       | 4162/16104 [19:25:11<51:13:13, 15.44s/it]

 26%|██▌       | 4163/16104 [19:25:27<51:43:00, 15.59s/it]
{'loss': 0.4852, 'learning_rate': 1.7385065726929321e-06, 'rewards/chosen': -0.5221953988075256, 'rewards/rejected': -1.351290225982666, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8290948867797852, 'policy_logps/rejected': -489.2778015136719, 'policy_logps/chosen': -414.6915283203125, 'referece_logps/rejected': -475.76495361328125, 'referece_logps/chosen': -409.46954345703125, 'logits/rejected': -0.36811646819114685, 'logits/chosen': -0.17072398960590363, 'epoch': 1.55}

 26%|██▌       | 4164/16104 [19:25:38<46:56:11, 14.15s/it]


 26%|██▌       | 4166/16104 [19:26:01<41:54:11, 12.64s/it]

 26%|██▌       | 4167/16104 [19:26:18<47:01:39, 14.18s/it]
{'loss': 0.517, 'learning_rate': 1.7379638991505514e-06, 'rewards/chosen': -0.2355991154909134, 'rewards/rejected': -1.4554286003112793, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2198294401168823, 'policy_logps/rejected': -338.42266845703125, 'policy_logps/chosen': -419.00408935546875, 'referece_logps/rejected': -323.8683776855469, 'referece_logps/chosen': -416.6480712890625, 'logits/rejected': -0.5168734192848206, 'logits/chosen': -0.5730883479118347, 'epoch': 1.55}


 26%|██▌       | 4169/16104 [19:26:41<41:59:46, 12.67s/it]
{'loss': 0.5709, 'learning_rate': 1.7376923832456663e-06, 'rewards/chosen': 0.3289293348789215, 'rewards/rejected': -0.8465210199356079, 'rewards/accuracies': 0.875, 'rewards/margins': 1.175450325012207, 'policy_logps/rejected': -333.183837890625, 'policy_logps/chosen': -386.2973327636719, 'referece_logps/rejected': -324.7186279296875, 'referece_logps/chosen': -389.586669921875, 'logits/rejected': -0.1539098620414734, 'logits/chosen': -0.2532661557197571, 'epoch': 1.55}


 26%|██▌       | 4171/16104 [19:27:03<39:19:39, 11.86s/it]
{'loss': 0.5521, 'learning_rate': 1.7374207479768895e-06, 'rewards/chosen': 0.40395045280456543, 'rewards/rejected': 0.22999590635299683, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17395459115505219, 'policy_logps/rejected': -417.98175048828125, 'policy_logps/chosen': -570.034423828125, 'referece_logps/rejected': -420.28173828125, 'referece_logps/chosen': -574.0738525390625, 'logits/rejected': 0.4757891297340393, 'logits/chosen': 0.5313348770141602, 'epoch': 1.55}


 26%|██▌       | 4173/16104 [19:27:31<42:46:28, 12.91s/it]
{'loss': 0.5243, 'learning_rate': 1.7371489933881728e-06, 'rewards/chosen': 0.015867426991462708, 'rewards/rejected': -0.6215759515762329, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6374433636665344, 'policy_logps/rejected': -440.4323425292969, 'policy_logps/chosen': -566.6026611328125, 'referece_logps/rejected': -434.216552734375, 'referece_logps/chosen': -566.7612915039062, 'logits/rejected': 0.2550519108772278, 'logits/chosen': 0.15842288732528687, 'epoch': 1.55}

 26%|██▌       | 4174/16104 [19:27:50<48:42:56, 14.70s/it]


 26%|██▌       | 4176/16104 [19:28:33<60:21:41, 18.22s/it]
{'loss': 0.5647, 'learning_rate': 1.7367411378764047e-06, 'rewards/chosen': -0.2991963028907776, 'rewards/rejected': -0.7906593680381775, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4914630055427551, 'policy_logps/rejected': -359.97894287109375, 'policy_logps/chosen': -364.8101501464844, 'referece_logps/rejected': -352.07232666015625, 'referece_logps/chosen': -361.8182067871094, 'logits/rejected': 0.4890543818473816, 'logits/chosen': 0.4977657198905945, 'epoch': 1.56}


 26%|██▌       | 4178/16104 [19:29:07<58:15:52, 17.59s/it]
{'loss': 0.5782, 'learning_rate': 1.7364690851802584e-06, 'rewards/chosen': -0.8121368288993835, 'rewards/rejected': -1.3337942361831665, 'rewards/accuracies': 0.375, 'rewards/margins': 0.5216573476791382, 'policy_logps/rejected': -502.5040283203125, 'policy_logps/chosen': -525.133056640625, 'referece_logps/rejected': -489.1661071777344, 'referece_logps/chosen': -517.01171875, 'logits/rejected': -0.5829793810844421, 'logits/chosen': -0.6117807626724243, 'epoch': 1.56}

 26%|██▌       | 4179/16104 [19:29:24<57:31:26, 17.37s/it]


 26%|██▌       | 4181/16104 [19:30:06<63:30:20, 19.17s/it]

 26%|██▌       | 4182/16104 [19:30:19<58:11:24, 17.57s/it]

 26%|██▌       | 4183/16104 [19:30:33<54:01:07, 16.31s/it]

 26%|██▌       | 4184/16104 [19:30:49<53:57:34, 16.30s/it]

 26%|██▌       | 4185/16104 [19:31:09<57:55:53, 17.50s/it]

 26%|██▌       | 4186/16104 [19:31:30<60:38:48, 18.32s/it]
{'loss': 0.3791, 'learning_rate': 1.7353796831766263e-06, 'rewards/chosen': -0.28377625346183777, 'rewards/rejected': -0.9483826160430908, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6646063327789307, 'policy_logps/rejected': -296.0533142089844, 'policy_logps/chosen': -314.0598449707031, 'referece_logps/rejected': -286.5694885253906, 'referece_logps/chosen': -311.2220764160156, 'logits/rejected': -0.5397229790687561, 'logits/chosen': -0.567747175693512, 'epoch': 1.56}


 26%|██▌       | 4188/16104 [19:32:12<65:31:27, 19.80s/it]

 26%|██▌       | 4189/16104 [19:32:27<60:52:57, 18.40s/it]

 26%|██▌       | 4190/16104 [19:32:43<58:53:36, 17.80s/it]

 26%|██▌       | 4191/16104 [19:33:02<59:37:45, 18.02s/it]

 26%|██▌       | 4192/16104 [19:33:19<59:00:53, 17.84s/it]
{'loss': 0.3498, 'learning_rate': 1.7345613821280836e-06, 'rewards/chosen': -0.18457508087158203, 'rewards/rejected': -2.0222361087799072, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8376612663269043, 'policy_logps/rejected': -480.7894287109375, 'policy_logps/chosen': -448.67413330078125, 'referece_logps/rejected': -460.56707763671875, 'referece_logps/chosen': -446.8283996582031, 'logits/rejected': -0.4487500786781311, 'logits/chosen': -0.3800249695777893, 'epoch': 1.56}


 26%|██▌       | 4194/16104 [19:33:49<53:05:46, 16.05s/it]

 26%|██▌       | 4195/16104 [19:34:07<54:52:27, 16.59s/it]

 26%|██▌       | 4196/16104 [19:34:20<50:44:59, 15.34s/it]
{'loss': 0.5189, 'learning_rate': 1.734015253735794e-06, 'rewards/chosen': -0.30475857853889465, 'rewards/rejected': -1.1236398220062256, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8188813328742981, 'policy_logps/rejected': -322.2922668457031, 'policy_logps/chosen': -406.2798156738281, 'referece_logps/rejected': -311.05584716796875, 'referece_logps/chosen': -403.2322082519531, 'logits/rejected': 0.2242264449596405, 'logits/chosen': 0.1422048658132553, 'epoch': 1.56}


 26%|██▌       | 4198/16104 [19:34:50<51:51:30, 15.68s/it]

 26%|██▌       | 4199/16104 [19:35:03<49:25:00, 14.94s/it]

 26%|██▌       | 4200/16104 [19:35:16<47:15:28, 14.29s/it]
{'loss': 0.4404, 'learning_rate': 1.7334686502678987e-06, 'rewards/chosen': -0.0006481148302555084, 'rewards/rejected': -0.2714384198188782, 'rewards/accuracies': 0.875, 'rewards/margins': 0.2707902789115906, 'policy_logps/rejected': -546.8204956054688, 'policy_logps/chosen': -383.27032470703125, 'referece_logps/rejected': -544.1061401367188, 'referece_logps/chosen': -383.2638244628906, 'logits/rejected': 0.10347163677215576, 'logits/chosen': 0.12337136268615723, 'epoch': 1.56}


 26%|██▌       | 4202/16104 [19:35:49<52:32:02, 15.89s/it]

 26%|██▌       | 4203/16104 [19:36:06<53:06:09, 16.06s/it]

 26%|██▌       | 4204/16104 [19:36:26<56:54:34, 17.22s/it]

 26%|██▌       | 4205/16104 [19:36:48<61:49:05, 18.70s/it]

 26%|██▌       | 4206/16104 [19:37:06<60:49:12, 18.40s/it]

 26%|██▌       | 4207/16104 [19:37:25<61:53:46, 18.73s/it]
{'loss': 0.4383, 'learning_rate': 1.732510952112675e-06, 'rewards/chosen': 0.5353392958641052, 'rewards/rejected': -1.4992315769195557, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0345706939697266, 'policy_logps/rejected': -408.94622802734375, 'policy_logps/chosen': -663.1986083984375, 'referece_logps/rejected': -393.95391845703125, 'referece_logps/chosen': -668.552001953125, 'logits/rejected': -0.12292595207691193, 'logits/chosen': -0.07197877764701843, 'epoch': 1.57}


 26%|██▌       | 4209/16104 [19:37:59<57:32:30, 17.41s/it]

 26%|██▌       | 4210/16104 [19:38:17<58:23:11, 17.67s/it]

 26%|██▌       | 4211/16104 [19:38:28<51:25:11, 15.56s/it]

 26%|██▌       | 4212/16104 [19:38:44<51:52:10, 15.70s/it]
{'loss': 0.5076, 'learning_rate': 1.731825992949888e-06, 'rewards/chosen': -0.3952594995498657, 'rewards/rejected': -1.059942603111267, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6646831035614014, 'policy_logps/rejected': -481.43023681640625, 'policy_logps/chosen': -300.922119140625, 'referece_logps/rejected': -470.83087158203125, 'referece_logps/chosen': -296.9695129394531, 'logits/rejected': -0.8157950639724731, 'logits/chosen': -0.6642213463783264, 'epoch': 1.57}

 26%|██▌       | 4213/16104 [19:39:01<53:19:22, 16.14s/it]

 26%|██▌       | 4214/16104 [19:39:21<57:13:38, 17.33s/it]

 26%|██▌       | 4215/16104 [19:39:41<60:05:53, 18.20s/it]

 26%|██▌       | 4216/16104 [19:39:59<59:37:13, 18.05s/it]


 26%|██▌       | 4218/16104 [19:40:34<58:41:57, 17.78s/it]
{'loss': 0.4759, 'learning_rate': 1.7310030650946106e-06, 'rewards/chosen': -0.12358589470386505, 'rewards/rejected': -1.700580358505249, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5769944190979004, 'policy_logps/rejected': -519.7631225585938, 'policy_logps/chosen': -480.1241455078125, 'referece_logps/rejected': -502.75732421875, 'referece_logps/chosen': -478.8882751464844, 'logits/rejected': 0.10114119946956635, 'logits/chosen': 0.023877114057540894, 'epoch': 1.57}

 26%|██▌       | 4219/16104 [19:40:53<59:08:38, 17.91s/it]

 26%|██▌       | 4220/16104 [19:41:09<57:19:00, 17.36s/it]


 26%|██▌       | 4222/16104 [19:41:40<53:12:48, 16.12s/it]

 26%|██▌       | 4223/16104 [19:42:00<57:04:45, 17.30s/it]
{'loss': 0.4513, 'learning_rate': 1.730316478645663e-06, 'rewards/chosen': -0.012557107955217361, 'rewards/rejected': -0.8956678509712219, 'rewards/accuracies': 0.875, 'rewards/margins': 0.883110761642456, 'policy_logps/rejected': -462.7698974609375, 'policy_logps/chosen': -351.36871337890625, 'referece_logps/rejected': -453.813232421875, 'referece_logps/chosen': -351.2431640625, 'logits/rejected': -0.380033403635025, 'logits/chosen': -0.34585657715797424, 'epoch': 1.57}

 26%|██▌       | 4224/16104 [19:42:15<54:37:53, 16.56s/it]

 26%|██▌       | 4225/16104 [19:42:35<57:44:57, 17.50s/it]

 26%|██▌       | 4226/16104 [19:42:55<60:24:43, 18.31s/it]

 26%|██▌       | 4227/16104 [19:43:07<54:21:44, 16.48s/it]

 26%|██▋       | 4228/16104 [19:43:21<52:07:49, 15.80s/it]


 26%|██▋       | 4230/16104 [19:43:58<55:49:21, 16.92s/it]
{'loss': 0.4591, 'learning_rate': 1.7293540169835096e-06, 'rewards/chosen': 0.11719877272844315, 'rewards/rejected': -0.5811514854431152, 'rewards/accuracies': 0.875, 'rewards/margins': 0.698350191116333, 'policy_logps/rejected': -549.5180053710938, 'policy_logps/chosen': -582.4185791015625, 'referece_logps/rejected': -543.70654296875, 'referece_logps/chosen': -583.590576171875, 'logits/rejected': -0.2397323101758957, 'logits/chosen': -0.25192296504974365, 'epoch': 1.58}

 26%|██▋       | 4231/16104 [19:44:19<59:56:29, 18.17s/it]

 26%|██▋       | 4232/16104 [19:44:39<61:34:40, 18.67s/it]

 26%|██▋       | 4233/16104 [19:44:55<59:12:32, 17.96s/it]

 26%|██▋       | 4234/16104 [19:45:14<59:49:19, 18.14s/it]


 26%|██▋       | 4236/16104 [19:45:47<56:43:13, 17.21s/it]
{'loss': 0.5246, 'learning_rate': 1.728527899129136e-06, 'rewards/chosen': -0.6310293674468994, 'rewards/rejected': -0.5919387936592102, 'rewards/accuracies': 0.25, 'rewards/margins': -0.039090536534786224, 'policy_logps/rejected': -403.5885009765625, 'policy_logps/chosen': -472.1978759765625, 'referece_logps/rejected': -397.66912841796875, 'referece_logps/chosen': -465.8876037597656, 'logits/rejected': 0.2079671323299408, 'logits/chosen': 0.32950276136398315, 'epoch': 1.58}


 26%|██▋       | 4238/16104 [19:46:16<52:34:12, 15.95s/it]
{'loss': 0.5394, 'learning_rate': 1.7282522906895568e-06, 'rewards/chosen': 0.10754565894603729, 'rewards/rejected': 0.0014207884669303894, 'rewards/accuracies': 0.375, 'rewards/margins': 0.1061248928308487, 'policy_logps/rejected': -359.2120361328125, 'policy_logps/chosen': -497.6802978515625, 'referece_logps/rejected': -359.2262268066406, 'referece_logps/chosen': -498.7557373046875, 'logits/rejected': 0.4689009189605713, 'logits/chosen': 0.47878459095954895, 'epoch': 1.58}

 26%|██▋       | 4239/16104 [19:46:38<58:29:29, 17.75s/it]

 26%|██▋       | 4240/16104 [19:46:56<58:36:59, 17.79s/it]

 26%|██▋       | 4241/16104 [19:47:12<56:33:54, 17.17s/it]


 26%|██▋       | 4243/16104 [19:47:48<58:59:43, 17.91s/it]

 26%|██▋       | 4244/16104 [19:48:00<53:10:48, 16.14s/it]
{'loss': 0.4767, 'learning_rate': 1.7274247585307892e-06, 'rewards/chosen': -0.026341617107391357, 'rewards/rejected': -1.1268390417099, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1004974842071533, 'policy_logps/rejected': -432.2401123046875, 'policy_logps/chosen': -408.47442626953125, 'referece_logps/rejected': -420.97174072265625, 'referece_logps/chosen': -408.21099853515625, 'logits/rejected': -0.24952097237110138, 'logits/chosen': 0.04149650037288666, 'epoch': 1.58}


 26%|██▋       | 4246/16104 [19:48:33<54:04:55, 16.42s/it]

 26%|██▋       | 4247/16104 [19:48:45<49:36:57, 15.06s/it]

 26%|██▋       | 4248/16104 [19:48:56<46:31:55, 14.13s/it]
{'loss': 0.5834, 'learning_rate': 1.7268724818379694e-06, 'rewards/chosen': -0.26547184586524963, 'rewards/rejected': -0.03645009547472, 'rewards/accuracies': 0.25, 'rewards/margins': -0.22902175784111023, 'policy_logps/rejected': -384.21124267578125, 'policy_logps/chosen': -391.990966796875, 'referece_logps/rejected': -383.8468017578125, 'referece_logps/chosen': -389.3363037109375, 'logits/rejected': -0.1655876189470291, 'logits/chosen': -0.27147653698921204, 'epoch': 1.58}


 26%|██▋       | 4250/16104 [19:49:27<47:33:28, 14.44s/it]
{'loss': 0.4723, 'learning_rate': 1.7265961670494823e-06, 'rewards/chosen': -0.09124193340539932, 'rewards/rejected': -0.549693763256073, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4584518373012543, 'policy_logps/rejected': -325.2958679199219, 'policy_logps/chosen': -408.91534423828125, 'referece_logps/rejected': -319.7989501953125, 'referece_logps/chosen': -408.0028991699219, 'logits/rejected': 0.09355290234088898, 'logits/chosen': 0.09063775837421417, 'epoch': 1.58}


 26%|██▋       | 4252/16104 [19:49:55<45:49:46, 13.92s/it]

 26%|██▋       | 4253/16104 [19:50:10<47:46:40, 14.51s/it]
{'loss': 0.5622, 'learning_rate': 1.7261814744398939e-06, 'rewards/chosen': 0.06224614381790161, 'rewards/rejected': -0.9087856411933899, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9710317850112915, 'policy_logps/rejected': -410.23272705078125, 'policy_logps/chosen': -592.9985961914062, 'referece_logps/rejected': -401.1448974609375, 'referece_logps/chosen': -593.6210327148438, 'logits/rejected': 0.08162622153759003, 'logits/chosen': 0.09056824445724487, 'epoch': 1.58}

 26%|██▋       | 4254/16104 [19:50:21<44:10:42, 13.42s/it]


 26%|██▋       | 4256/16104 [19:50:57<52:25:33, 15.93s/it]

 26%|██▋       | 4257/16104 [19:51:13<52:47:48, 16.04s/it]
{'loss': 0.5216, 'learning_rate': 1.7256281397318508e-06, 'rewards/chosen': -0.06079483777284622, 'rewards/rejected': -0.5154746770858765, 'rewards/accuracies': 0.625, 'rewards/margins': 0.45467984676361084, 'policy_logps/rejected': -383.9451599121094, 'policy_logps/chosen': -416.2489318847656, 'referece_logps/rejected': -378.7904052734375, 'referece_logps/chosen': -415.6409912109375, 'logits/rejected': -0.4865180552005768, 'logits/chosen': -0.468088299036026, 'epoch': 1.59}


 26%|██▋       | 4259/16104 [19:51:37<45:24:38, 13.80s/it]
{'loss': 0.6249, 'learning_rate': 1.7253512962377244e-06, 'rewards/chosen': 0.5789810419082642, 'rewards/rejected': -0.2580856680870056, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8370667099952698, 'policy_logps/rejected': -422.7985534667969, 'policy_logps/chosen': -407.5144348144531, 'referece_logps/rejected': -420.2176818847656, 'referece_logps/chosen': -413.3042297363281, 'logits/rejected': 0.13931307196617126, 'logits/chosen': 0.20233994722366333, 'epoch': 1.59}


 26%|██▋       | 4261/16104 [19:52:13<52:46:02, 16.04s/it]

 26%|██▋       | 4262/16104 [19:52:25<48:54:50, 14.87s/it]
{'loss': 0.4338, 'learning_rate': 1.7249358109473834e-06, 'rewards/chosen': -0.329815536737442, 'rewards/rejected': -1.0823255777359009, 'rewards/accuracies': 0.75, 'rewards/margins': 0.752510130405426, 'policy_logps/rejected': -390.15191650390625, 'policy_logps/chosen': -475.0951843261719, 'referece_logps/rejected': -379.32867431640625, 'referece_logps/chosen': -471.79705810546875, 'logits/rejected': 0.0883650928735733, 'logits/chosen': 0.06344825029373169, 'epoch': 1.59}

 26%|██▋       | 4263/16104 [19:52:37<46:22:57, 14.10s/it]


 26%|██▋       | 4265/16104 [19:53:15<53:30:09, 16.27s/it]

 26%|██▋       | 4266/16104 [19:53:33<55:00:44, 16.73s/it]
{'loss': 0.7141, 'learning_rate': 1.7243814200371702e-06, 'rewards/chosen': -0.3776484429836273, 'rewards/rejected': -0.5193345546722412, 'rewards/accuracies': 0.625, 'rewards/margins': 0.14168612658977509, 'policy_logps/rejected': -267.209716796875, 'policy_logps/chosen': -304.2010498046875, 'referece_logps/rejected': -262.016357421875, 'referece_logps/chosen': -300.424560546875, 'logits/rejected': -0.6530838012695312, 'logits/chosen': -0.755271315574646, 'epoch': 1.59}


 27%|██▋       | 4268/16104 [19:54:09<58:34:15, 17.81s/it]
{'loss': 0.4399, 'learning_rate': 1.724104048744508e-06, 'rewards/chosen': 0.11614648252725601, 'rewards/rejected': -1.9055501222610474, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0216963291168213, 'policy_logps/rejected': -431.2077331542969, 'policy_logps/chosen': -508.8131103515625, 'referece_logps/rejected': -412.1522216796875, 'referece_logps/chosen': -509.97454833984375, 'logits/rejected': -0.256035178899765, 'logits/chosen': -0.296380877494812, 'epoch': 1.59}


 27%|██▋       | 4270/16104 [19:54:49<62:00:59, 18.87s/it]
{'loss': 0.4463, 'learning_rate': 1.7238265602866435e-06, 'rewards/chosen': -0.9333231449127197, 'rewards/rejected': -1.4476412534713745, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5143179893493652, 'policy_logps/rejected': -512.2825927734375, 'policy_logps/chosen': -481.3878479003906, 'referece_logps/rejected': -497.80621337890625, 'referece_logps/chosen': -472.05462646484375, 'logits/rejected': 0.24964526295661926, 'logits/chosen': 0.11304061114788055, 'epoch': 1.59}

 27%|██▋       | 4271/16104 [19:55:06<60:47:50, 18.50s/it]


 27%|██▋       | 4273/16104 [19:55:39<56:32:17, 17.20s/it]

 27%|██▋       | 4274/16104 [19:55:59<59:14:29, 18.03s/it]

 27%|██▋       | 4275/16104 [19:56:15<57:13:35, 17.42s/it]
{'loss': 0.5018, 'learning_rate': 1.7231323268389214e-06, 'rewards/chosen': 0.3623073101043701, 'rewards/rejected': -0.7960610389709473, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1583685874938965, 'policy_logps/rejected': -549.1763305664062, 'policy_logps/chosen': -624.0259399414062, 'referece_logps/rejected': -541.2156982421875, 'referece_logps/chosen': -627.64892578125, 'logits/rejected': 0.3576054275035858, 'logits/chosen': 0.35412514209747314, 'epoch': 1.59}


 27%|██▋       | 4277/16104 [19:56:37<46:25:26, 14.13s/it]
{'loss': 0.5321, 'learning_rate': 1.7228544286565563e-06, 'rewards/chosen': 0.15345633029937744, 'rewards/rejected': -0.8707073926925659, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0241637229919434, 'policy_logps/rejected': -320.3500061035156, 'policy_logps/chosen': -354.8710632324219, 'referece_logps/rejected': -311.6429443359375, 'referece_logps/chosen': -356.4056091308594, 'logits/rejected': -0.39651745557785034, 'logits/chosen': -0.31794267892837524, 'epoch': 1.59}

 27%|██▋       | 4278/16104 [19:56:58<53:08:20, 16.18s/it]

 27%|██▋       | 4279/16104 [19:57:14<52:54:41, 16.11s/it]

 27%|██▋       | 4280/16104 [19:57:34<57:02:07, 17.37s/it]


 27%|██▋       | 4282/16104 [19:58:15<61:55:36, 18.86s/it]

 27%|██▋       | 4283/16104 [19:58:27<55:01:08, 16.76s/it]
{'loss': 0.4445, 'learning_rate': 1.72202003251139e-06, 'rewards/chosen': 0.4305477440357208, 'rewards/rejected': -1.1344105005264282, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5649582147598267, 'policy_logps/rejected': -421.7341003417969, 'policy_logps/chosen': -410.7583923339844, 'referece_logps/rejected': -410.3899841308594, 'referece_logps/chosen': -415.0638732910156, 'logits/rejected': -0.6825782060623169, 'logits/chosen': -0.811882734298706, 'epoch': 1.6}

 27%|██▋       | 4284/16104 [19:58:42<53:10:19, 16.19s/it]

 27%|██▋       | 4285/16104 [19:59:04<58:59:13, 17.97s/it]


 27%|██▋       | 4287/16104 [19:59:31<52:15:42, 15.92s/it]
{'loss': 0.5521, 'learning_rate': 1.7214631841996372e-06, 'rewards/chosen': -0.26096397638320923, 'rewards/rejected': -0.8868716955184937, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6259077787399292, 'policy_logps/rejected': -552.227783203125, 'policy_logps/chosen': -579.3541870117188, 'referece_logps/rejected': -543.3590698242188, 'referece_logps/chosen': -576.7445678710938, 'logits/rejected': 0.017761260271072388, 'logits/chosen': 0.08256682753562927, 'epoch': 1.6}

 27%|██▋       | 4288/16104 [19:59:53<57:43:55, 17.59s/it]


 27%|██▋       | 4290/16104 [20:00:26<56:06:30, 17.10s/it]
{'loss': 0.4636, 'learning_rate': 1.7210452415091475e-06, 'rewards/chosen': 0.0963122546672821, 'rewards/rejected': -0.7431691884994507, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8394814133644104, 'policy_logps/rejected': -484.9486083984375, 'policy_logps/chosen': -517.7520751953125, 'referece_logps/rejected': -477.51690673828125, 'referece_logps/chosen': -518.7152099609375, 'logits/rejected': 0.12169180810451508, 'logits/chosen': 0.16989916563034058, 'epoch': 1.6}

 27%|██▋       | 4291/16104 [20:00:40<53:28:22, 16.30s/it]


 27%|██▋       | 4293/16104 [20:01:19<59:36:52, 18.17s/it]
{'loss': 0.4971, 'learning_rate': 1.7206270363105645e-06, 'rewards/chosen': 0.022799499332904816, 'rewards/rejected': -1.186303973197937, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2091033458709717, 'policy_logps/rejected': -536.9946899414062, 'policy_logps/chosen': -411.528564453125, 'referece_logps/rejected': -525.1316528320312, 'referece_logps/chosen': -411.7565612792969, 'logits/rejected': -0.259204626083374, 'logits/chosen': -0.048922259360551834, 'epoch': 1.6}

 27%|██▋       | 4294/16104 [20:01:33<54:49:31, 16.71s/it]

 27%|██▋       | 4295/16104 [20:01:52<57:33:08, 17.55s/it]

 27%|██▋       | 4296/16104 [20:02:12<59:49:17, 18.24s/it]


 27%|██▋       | 4298/16104 [20:02:47<58:37:58, 17.88s/it]
{'loss': 0.5423, 'learning_rate': 1.7199294447085148e-06, 'rewards/chosen': -0.2752375304698944, 'rewards/rejected': -1.7067558765411377, 'rewards/accuracies': 1.0, 'rewards/margins': 1.431518316268921, 'policy_logps/rejected': -477.87762451171875, 'policy_logps/chosen': -347.675537109375, 'referece_logps/rejected': -460.8100891113281, 'referece_logps/chosen': -344.9231872558594, 'logits/rejected': -0.16105647385120392, 'logits/chosen': -0.39128774404525757, 'epoch': 1.6}


 27%|██▋       | 4300/16104 [20:03:28<62:46:51, 19.15s/it]

 27%|██▋       | 4301/16104 [20:03:45<61:24:46, 18.73s/it]
{'loss': 0.5305, 'learning_rate': 1.7195105402329632e-06, 'rewards/chosen': -0.2529290020465851, 'rewards/rejected': -1.3049631118774414, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0520341396331787, 'policy_logps/rejected': -292.7259521484375, 'policy_logps/chosen': -312.90087890625, 'referece_logps/rejected': -279.6763610839844, 'referece_logps/chosen': -310.37158203125, 'logits/rejected': 0.28187549114227295, 'logits/chosen': 0.2740754187107086, 'epoch': 1.6}

 27%|██▋       | 4302/16104 [20:04:04<61:37:08, 18.80s/it]

 27%|██▋       | 4303/16104 [20:04:26<64:42:49, 19.74s/it]


 27%|██▋       | 4305/16104 [20:04:56<55:47:53, 17.02s/it]
{'loss': 0.4127, 'learning_rate': 1.7189515934818182e-06, 'rewards/chosen': 0.5913284420967102, 'rewards/rejected': -1.532422661781311, 'rewards/accuracies': 1.0, 'rewards/margins': 2.123751163482666, 'policy_logps/rejected': -647.4434814453125, 'policy_logps/chosen': -500.0663146972656, 'referece_logps/rejected': -632.1192626953125, 'referece_logps/chosen': -505.9796142578125, 'logits/rejected': 0.5833479166030884, 'logits/chosen': 0.5277554988861084, 'epoch': 1.6}


 27%|██▋       | 4307/16104 [20:05:28<55:13:50, 16.85s/it]
{'loss': 0.4874, 'learning_rate': 1.7186719455863824e-06, 'rewards/chosen': -0.8041091561317444, 'rewards/rejected': -1.4499988555908203, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6458896398544312, 'policy_logps/rejected': -578.1022338867188, 'policy_logps/chosen': -375.7359619140625, 'referece_logps/rejected': -563.6022338867188, 'referece_logps/chosen': -367.6948547363281, 'logits/rejected': 0.0849146842956543, 'logits/chosen': 0.4514579772949219, 'epoch': 1.6}

 27%|██▋       | 4308/16104 [20:05:42<53:05:39, 16.20s/it]

 27%|██▋       | 4309/16104 [20:05:57<51:11:24, 15.62s/it]

 27%|██▋       | 4310/16104 [20:06:07<46:23:50, 14.16s/it]

 27%|██▋       | 4311/16104 [20:06:18<43:26:19, 13.26s/it]


 27%|██▋       | 4313/16104 [20:06:50<46:55:18, 14.33s/it]
{'loss': 0.5971, 'learning_rate': 1.7178323043636695e-06, 'rewards/chosen': 0.17711888253688812, 'rewards/rejected': 0.1549490988254547, 'rewards/accuracies': 0.625, 'rewards/margins': 0.02216978371143341, 'policy_logps/rejected': -556.7791748046875, 'policy_logps/chosen': -620.8023681640625, 'referece_logps/rejected': -558.32861328125, 'referece_logps/chosen': -622.5735473632812, 'logits/rejected': 0.4940814971923828, 'logits/chosen': 0.47291579842567444, 'epoch': 1.61}

 27%|██▋       | 4314/16104 [20:07:06<49:01:12, 14.97s/it]

 27%|██▋       | 4315/16104 [20:07:18<46:10:35, 14.10s/it]

 27%|██▋       | 4316/16104 [20:07:36<49:55:55, 15.25s/it]

 27%|██▋       | 4317/16104 [20:07:48<46:47:42, 14.29s/it]

 27%|██▋       | 4318/16104 [20:08:05<48:44:19, 14.89s/it]

 27%|██▋       | 4319/16104 [20:08:24<53:26:55, 16.33s/it]

 27%|██▋       | 4320/16104 [20:08:43<55:28:18, 16.95s/it]

 27%|██▋       | 4321/16104 [20:09:03<58:50:59, 17.98s/it]

 27%|██▋       | 4322/16104 [20:09:22<59:29:29, 18.18s/it]

 27%|██▋       | 4323/16104 [20:09:44<63:01:28, 19.26s/it]

 27%|██▋       | 4324/16104 [20:09:56<56:17:21, 17.20s/it]


 27%|██▋       | 4326/16104 [20:10:28<55:29:49, 16.96s/it]
{'loss': 0.4974, 'learning_rate': 1.7160094972049462e-06, 'rewards/chosen': -0.41901618242263794, 'rewards/rejected': -1.2560640573501587, 'rewards/accuracies': 0.875, 'rewards/margins': 0.837047815322876, 'policy_logps/rejected': -376.7607727050781, 'policy_logps/chosen': -392.6997375488281, 'referece_logps/rejected': -364.2001647949219, 'referece_logps/chosen': -388.5096130371094, 'logits/rejected': -0.1570577174425125, 'logits/chosen': -0.31029391288757324, 'epoch': 1.61}

 27%|██▋       | 4327/16104 [20:10:42<52:29:13, 16.04s/it]

 27%|██▋       | 4328/16104 [20:10:54<48:19:51, 14.78s/it]

 27%|██▋       | 4329/16104 [20:11:10<49:26:49, 15.12s/it]

 27%|██▋       | 4330/16104 [20:11:31<55:07:34, 16.86s/it]

 27%|██▋       | 4331/16104 [20:11:49<56:43:58, 17.35s/it]

 27%|██▋       | 4332/16104 [20:12:07<57:06:07, 17.46s/it]

 27%|██▋       | 4333/16104 [20:12:27<60:03:41, 18.37s/it]

 27%|██▋       | 4334/16104 [20:12:49<63:01:54, 19.28s/it]

 27%|██▋       | 4335/16104 [20:13:10<64:38:02, 19.77s/it]

 27%|██▋       | 4336/16104 [20:13:25<59:58:10, 18.35s/it]

 27%|██▋       | 4337/16104 [20:13:42<58:30:09, 17.90s/it]


 27%|██▋       | 4339/16104 [20:14:14<54:41:24, 16.73s/it]
{'loss': 0.4902, 'learning_rate': 1.7141817951563379e-06, 'rewards/chosen': 0.2819322347640991, 'rewards/rejected': -0.8330623507499695, 'rewards/accuracies': 0.875, 'rewards/margins': 1.114994764328003, 'policy_logps/rejected': -349.0884704589844, 'policy_logps/chosen': -438.8924560546875, 'referece_logps/rejected': -340.7578430175781, 'referece_logps/chosen': -441.7117919921875, 'logits/rejected': 0.14183707535266876, 'logits/chosen': 0.040269359946250916, 'epoch': 1.62}

 27%|██▋       | 4340/16104 [20:14:32<55:26:19, 16.97s/it]

 27%|██▋       | 4341/16104 [20:14:48<54:33:33, 16.70s/it]

 27%|██▋       | 4342/16104 [20:14:59<48:46:39, 14.93s/it]

 27%|██▋       | 4343/16104 [20:15:10<45:33:43, 13.95s/it]

 27%|██▋       | 4344/16104 [20:15:25<46:30:04, 14.24s/it]


 27%|██▋       | 4346/16104 [20:15:59<51:01:35, 15.62s/it]
{'loss': 0.384, 'learning_rate': 1.7131956248080152e-06, 'rewards/chosen': -0.43854641914367676, 'rewards/rejected': -1.3488956689834595, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9103493690490723, 'policy_logps/rejected': -411.28997802734375, 'policy_logps/chosen': -450.4795837402344, 'referece_logps/rejected': -397.8010559082031, 'referece_logps/chosen': -446.0941467285156, 'logits/rejected': 1.0156960487365723, 'logits/chosen': 1.0046249628067017, 'epoch': 1.62}

 27%|██▋       | 4347/16104 [20:16:12<48:31:36, 14.86s/it]

 27%|██▋       | 4348/16104 [20:16:33<54:43:45, 16.76s/it]

 27%|██▋       | 4349/16104 [20:16:48<52:41:24, 16.14s/it]


 27%|██▋       | 4351/16104 [20:17:19<51:25:43, 15.75s/it]
{'loss': 0.4091, 'learning_rate': 1.712490351801336e-06, 'rewards/chosen': -0.06266705691814423, 'rewards/rejected': -0.829702615737915, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7670356631278992, 'policy_logps/rejected': -324.34381103515625, 'policy_logps/chosen': -379.0610656738281, 'referece_logps/rejected': -316.0467834472656, 'referece_logps/chosen': -378.4343566894531, 'logits/rejected': -0.6710618734359741, 'logits/chosen': -0.6907395720481873, 'epoch': 1.62}

 27%|██▋       | 4352/16104 [20:17:39<56:13:57, 17.23s/it]

 27%|██▋       | 4353/16104 [20:17:53<52:39:31, 16.13s/it]

 27%|██▋       | 4354/16104 [20:18:12<55:54:24, 17.13s/it]

 27%|██▋       | 4355/16104 [20:18:25<51:38:12, 15.82s/it]

 27%|██▋       | 4356/16104 [20:18:46<56:07:34, 17.20s/it]


 27%|██▋       | 4358/16104 [20:19:11<48:56:42, 15.00s/it]
{'loss': 0.5121, 'learning_rate': 1.7115017592487278e-06, 'rewards/chosen': 0.2628192901611328, 'rewards/rejected': -0.6104252934455872, 'rewards/accuracies': 0.75, 'rewards/margins': 0.87324458360672, 'policy_logps/rejected': -439.25128173828125, 'policy_logps/chosen': -534.701171875, 'referece_logps/rejected': -433.14703369140625, 'referece_logps/chosen': -537.329345703125, 'logits/rejected': 0.23378688097000122, 'logits/chosen': 0.1595863699913025, 'epoch': 1.62}

 27%|██▋       | 4359/16104 [20:19:23<45:48:17, 14.04s/it]

 27%|██▋       | 4360/16104 [20:19:39<48:26:33, 14.85s/it]

 27%|██▋       | 4361/16104 [20:19:51<45:33:31, 13.97s/it]

 27%|██▋       | 4362/16104 [20:20:07<47:29:49, 14.56s/it]

 27%|██▋       | 4363/16104 [20:20:18<43:45:30, 13.42s/it]

 27%|██▋       | 4364/16104 [20:20:29<41:07:03, 12.61s/it]

 27%|██▋       | 4365/16104 [20:20:39<39:13:06, 12.03s/it]

 27%|██▋       | 4366/16104 [20:20:50<37:47:51, 11.59s/it]

 27%|██▋       | 4367/16104 [20:21:01<37:30:22, 11.50s/it]

 27%|██▋       | 4368/16104 [20:21:12<36:41:56, 11.26s/it]

 27%|██▋       | 4369/16104 [20:21:23<36:58:55, 11.35s/it]

 27%|██▋       | 4370/16104 [20:21:43<44:48:46, 13.75s/it]

 27%|██▋       | 4371/16104 [20:21:59<46:43:40, 14.34s/it]

 27%|██▋       | 4372/16104 [20:22:09<43:11:52, 13.26s/it]

 27%|██▋       | 4373/16104 [20:22:31<51:15:57, 15.73s/it]

 27%|██▋       | 4374/16104 [20:22:48<52:40:48, 16.17s/it]

 27%|██▋       | 4375/16104 [20:23:07<55:49:41, 17.14s/it]

 27%|██▋       | 4376/16104 [20:23:20<51:03:01, 15.67s/it]

 27%|██▋       | 4377/16104 [20:23:36<51:37:50, 15.85s/it]

 27%|██▋       | 4378/16104 [20:23:55<55:11:44, 16.95s/it]

 27%|██▋       | 4379/16104 [20:24:15<58:07:08, 17.84s/it]

 27%|██▋       | 4380/16104 [20:24:28<53:21:14, 16.38s/it]

 27%|██▋       | 4381/16104 [20:24:42<51:00:38, 15.66s/it]

 27%|██▋       | 4382/16104 [20:25:04<57:09:59, 17.56s/it]

 27%|██▋       | 4383/16104 [20:25:27<62:09:18, 19.09s/it]

 27%|██▋       | 4384/16104 [20:25:46<62:02:47, 19.06s/it]

 27%|██▋       | 4385/16104 [20:25:57<53:58:33, 16.58s/it]

 27%|██▋       | 4386/16104 [20:26:18<58:43:05, 18.04s/it]

 27%|██▋       | 4387/16104 [20:26:33<55:56:07, 17.19s/it]

 27%|██▋       | 4388/16104 [20:26:46<51:27:37, 15.81s/it]

 27%|██▋       | 4389/16104 [20:27:06<55:17:31, 16.99s/it]

 27%|██▋       | 4390/16104 [20:27:27<59:18:28, 18.23s/it]

 27%|██▋       | 4391/16104 [20:27:47<60:49:45, 18.70s/it]

 27%|██▋       | 4392/16104 [20:28:06<61:37:26, 18.94s/it]

 27%|██▋       | 4393/16104 [20:28:24<60:57:45, 18.74s/it]

 27%|██▋       | 4394/16104 [20:28:36<53:39:25, 16.50s/it]

 27%|██▋       | 4395/16104 [20:28:57<58:12:53, 17.90s/it]

 27%|██▋       | 4396/16104 [20:29:10<53:15:39, 16.38s/it]

 27%|██▋       | 4397/16104 [20:29:27<54:32:09, 16.77s/it]

 27%|██▋       | 4398/16104 [20:29:43<53:49:13, 16.55s/it]

 27%|██▋       | 4399/16104 [20:29:57<50:45:17, 15.61s/it]

 27%|██▋       | 4400/16104 [20:30:16<54:35:42, 16.79s/it]

 27%|██▋       | 4401/16104 [20:30:29<50:16:58, 15.47s/it]

 27%|██▋       | 4402/16104 [20:30:50<55:46:46, 17.16s/it]

 27%|██▋       | 4403/16104 [20:31:06<54:29:55, 16.77s/it]

 27%|██▋       | 4404/16104 [20:31:18<50:21:03, 15.49s/it]

 27%|██▋       | 4405/16104 [20:31:35<51:28:36, 15.84s/it]

 27%|██▋       | 4406/16104 [20:31:56<56:23:48, 17.36s/it]


 27%|██▋       | 4408/16104 [20:32:30<54:40:21, 16.83s/it]

 27%|██▋       | 4409/16104 [20:32:50<57:41:04, 17.76s/it]

 27%|██▋       | 4410/16104 [20:33:10<60:21:44, 18.58s/it]

 27%|██▋       | 4411/16104 [20:33:22<53:34:05, 16.49s/it]

 27%|██▋       | 4412/16104 [20:33:39<54:16:09, 16.71s/it]

 27%|██▋       | 4413/16104 [20:33:59<56:59:13, 17.55s/it]

 27%|██▋       | 4414/16104 [20:34:11<51:27:13, 15.85s/it]

 27%|██▋       | 4415/16104 [20:34:26<51:30:18, 15.86s/it]

 27%|██▋       | 4416/16104 [20:34:43<51:52:02, 15.98s/it]

 27%|██▋       | 4417/16104 [20:34:55<48:23:30, 14.91s/it]

 27%|██▋       | 4418/16104 [20:35:15<52:47:14, 16.26s/it]

 27%|██▋       | 4419/16104 [20:35:27<49:07:24, 15.13s/it]

 27%|██▋       | 4420/16104 [20:35:40<46:38:49, 14.37s/it]

 27%|██▋       | 4421/16104 [20:35:53<45:56:32, 14.16s/it]

 27%|██▋       | 4422/16104 [20:36:16<53:48:33, 16.58s/it]

 27%|██▋       | 4423/16104 [20:36:33<54:36:05, 16.83s/it]

 27%|██▋       | 4424/16104 [20:36:55<59:40:09, 18.39s/it]

 27%|██▋       | 4425/16104 [20:37:08<54:29:22, 16.80s/it]

 27%|██▋       | 4426/16104 [20:37:30<59:10:36, 18.24s/it]

 27%|██▋       | 4427/16104 [20:37:40<51:52:06, 15.99s/it]

 27%|██▋       | 4428/16104 [20:37:57<52:15:39, 16.11s/it]

 28%|██▊       | 4429/16104 [20:38:19<58:21:54, 18.00s/it]

 28%|██▊       | 4430/16104 [20:38:35<56:06:28, 17.30s/it]

 28%|██▊       | 4431/16104 [20:38:47<51:13:47, 15.80s/it]

 28%|██▊       | 4432/16104 [20:39:07<54:46:42, 16.90s/it]

 28%|██▊       | 4433/16104 [20:39:21<51:56:46, 16.02s/it]

 28%|██▊       | 4434/16104 [20:39:39<54:36:28, 16.85s/it]

 28%|██▊       | 4435/16104 [20:39:51<49:19:38, 15.22s/it]

 28%|██▊       | 4436/16104 [20:40:07<50:20:29, 15.53s/it]

 28%|██▊       | 4437/16104 [20:40:24<51:19:31, 15.84s/it]

 28%|██▊       | 4438/16104 [20:40:40<51:50:57, 16.00s/it]

 28%|██▊       | 4439/16104 [20:40:55<50:29:18, 15.58s/it]

 28%|██▊       | 4440/16104 [20:41:15<55:03:11, 16.99s/it]
{'loss': 0.4551, 'learning_rate': 1.699816603599974e-06, 'rewards/chosen': -0.40154001116752625, 'rewards/rejected': -1.5666892528533936, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1651490926742554, 'policy_logps/rejected': -445.0645751953125, 'policy_logps/chosen': -371.2476806640625, 'referece_logps/rejected': -429.3977355957031, 'referece_logps/chosen': -367.2322998046875, 'logits/rejected': -0.12030916661024094, 'logits/chosen': -0.044398799538612366, 'epoch': 1.65}

 28%|██▊       | 4441/16104 [20:41:36<59:17:26, 18.30s/it]


 28%|██▊       | 4443/16104 [20:42:08<55:22:31, 17.10s/it]

 28%|██▊       | 4444/16104 [20:42:20<50:13:09, 15.51s/it]

 28%|██▊       | 4445/16104 [20:42:41<55:36:02, 17.17s/it]
{'loss': 0.4791, 'learning_rate': 1.6990979046269249e-06, 'rewards/chosen': -0.06978102028369904, 'rewards/rejected': -0.9716010689735413, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9018200635910034, 'policy_logps/rejected': -345.6424255371094, 'policy_logps/chosen': -378.4604187011719, 'referece_logps/rejected': -335.9263916015625, 'referece_logps/chosen': -377.7625732421875, 'logits/rejected': -0.3513568043708801, 'logits/chosen': -0.3196451663970947, 'epoch': 1.66}


 28%|██▊       | 4447/16104 [20:43:17<56:45:30, 17.53s/it]

 28%|██▊       | 4448/16104 [20:43:36<58:12:38, 17.98s/it]

 28%|██▊       | 4449/16104 [20:43:52<55:57:59, 17.29s/it]

 28%|██▊       | 4450/16104 [20:44:10<56:39:05, 17.50s/it]

 28%|██▊       | 4451/16104 [20:44:31<59:56:08, 18.52s/it]

 28%|██▊       | 4452/16104 [20:44:50<60:56:33, 18.83s/it]

 28%|██▊       | 4453/16104 [20:45:01<53:07:45, 16.42s/it]

 28%|██▊       | 4454/16104 [20:45:18<53:09:48, 16.43s/it]

 28%|██▊       | 4455/16104 [20:45:36<55:16:52, 17.08s/it]

 28%|██▊       | 4456/16104 [20:45:56<58:15:51, 18.01s/it]

 28%|██▊       | 4457/16104 [20:46:18<61:29:26, 19.01s/it]

 28%|██▊       | 4458/16104 [20:46:37<61:54:40, 19.14s/it]
{'loss': 0.4424, 'learning_rate': 1.6972259803817904e-06, 'rewards/chosen': -0.12070894241333008, 'rewards/rejected': -0.866573691368103, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7458648681640625, 'policy_logps/rejected': -239.93910217285156, 'policy_logps/chosen': -229.57781982421875, 'referece_logps/rejected': -231.27334594726562, 'referece_logps/chosen': -228.3707275390625, 'logits/rejected': -0.62470543384552, 'logits/chosen': -0.6247320175170898, 'epoch': 1.66}


 28%|██▊       | 4460/16104 [20:47:16<63:03:11, 19.49s/it]

 28%|██▊       | 4461/16104 [20:47:35<61:52:01, 19.13s/it]

 28%|██▊       | 4462/16104 [20:47:52<60:35:21, 18.74s/it]

 28%|██▊       | 4463/16104 [20:48:06<55:42:54, 17.23s/it]

 28%|██▊       | 4464/16104 [20:48:23<55:37:34, 17.20s/it]
{'loss': 0.4275, 'learning_rate': 1.6963604069405684e-06, 'rewards/chosen': -0.23356828093528748, 'rewards/rejected': -0.7839493751525879, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5503811240196228, 'policy_logps/rejected': -417.1532287597656, 'policy_logps/chosen': -608.1863403320312, 'referece_logps/rejected': -409.313720703125, 'referece_logps/chosen': -605.8506469726562, 'logits/rejected': 0.14357969164848328, 'logits/chosen': 0.1610916256904602, 'epoch': 1.66}


 28%|██▊       | 4466/16104 [20:49:02<59:31:49, 18.41s/it]

 28%|██▊       | 4467/16104 [20:49:20<58:58:00, 18.24s/it]

 28%|██▊       | 4468/16104 [20:49:34<55:22:13, 17.13s/it]

 28%|██▊       | 4469/16104 [20:49:51<54:43:35, 16.93s/it]
{'loss': 0.5626, 'learning_rate': 1.695638321038023e-06, 'rewards/chosen': 0.26822322607040405, 'rewards/rejected': -0.7405397891998291, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0087628364562988, 'policy_logps/rejected': -460.9226379394531, 'policy_logps/chosen': -396.60986328125, 'referece_logps/rejected': -453.5172424316406, 'referece_logps/chosen': -399.2920837402344, 'logits/rejected': -0.4027186632156372, 'logits/chosen': -0.3818625509738922, 'epoch': 1.67}


 28%|██▊       | 4471/16104 [20:50:17<48:05:32, 14.88s/it]

 28%|██▊       | 4472/16104 [20:50:32<47:59:14, 14.85s/it]
{'loss': 0.5355, 'learning_rate': 1.6952047317720206e-06, 'rewards/chosen': -0.15738658607006073, 'rewards/rejected': -1.104221224784851, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9468345642089844, 'policy_logps/rejected': -428.051513671875, 'policy_logps/chosen': -392.6141357421875, 'referece_logps/rejected': -417.00933837890625, 'referece_logps/chosen': -391.0402526855469, 'logits/rejected': -0.1819864958524704, 'logits/chosen': -0.008266527205705643, 'epoch': 1.67}


 28%|██▊       | 4474/16104 [20:51:03<49:47:22, 15.41s/it]

 28%|██▊       | 4475/16104 [20:51:18<49:52:14, 15.44s/it]

 28%|██▊       | 4476/16104 [20:51:32<48:05:40, 14.89s/it]

 28%|██▊       | 4477/16104 [20:51:46<47:48:10, 14.80s/it]
{'loss': 0.4548, 'learning_rate': 1.694481520627921e-06, 'rewards/chosen': 0.07766780257225037, 'rewards/rejected': -1.0550576448440552, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1327255964279175, 'policy_logps/rejected': -405.44512939453125, 'policy_logps/chosen': -406.7155456542969, 'referece_logps/rejected': -394.89459228515625, 'referece_logps/chosen': -407.4921875, 'logits/rejected': -0.20433317124843597, 'logits/chosen': -0.13451188802719116, 'epoch': 1.67}

 28%|██▊       | 4478/16104 [20:52:03<49:33:43, 15.35s/it]


 28%|██▊       | 4480/16104 [20:52:31<47:34:21, 14.73s/it]
{'loss': 0.53, 'learning_rate': 1.6940472567784484e-06, 'rewards/chosen': -0.14294572174549103, 'rewards/rejected': -1.2492530345916748, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1063075065612793, 'policy_logps/rejected': -434.87158203125, 'policy_logps/chosen': -530.3764038085938, 'referece_logps/rejected': -422.3790588378906, 'referece_logps/chosen': -528.9469604492188, 'logits/rejected': -0.7366310358047485, 'logits/chosen': -0.5654820203781128, 'epoch': 1.67}

 28%|██▊       | 4481/16104 [20:52:43<45:15:10, 14.02s/it]


 28%|██▊       | 4483/16104 [20:53:08<42:36:26, 13.20s/it]

 28%|██▊       | 4484/16104 [20:53:29<50:11:47, 15.55s/it]

 28%|██▊       | 4485/16104 [20:53:46<52:12:35, 16.18s/it]

 28%|██▊       | 4486/16104 [20:54:01<50:33:33, 15.67s/it]

 28%|██▊       | 4487/16104 [20:54:19<52:47:28, 16.36s/it]

 28%|██▊       | 4488/16104 [20:54:38<55:13:22, 17.11s/it]

 28%|██▊       | 4489/16104 [20:54:58<58:18:11, 18.07s/it]
{'loss': 0.5553, 'learning_rate': 1.692742949788632e-06, 'rewards/chosen': 0.39833757281303406, 'rewards/rejected': -0.12160242348909378, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5199400186538696, 'policy_logps/rejected': -420.8068542480469, 'policy_logps/chosen': -526.7713012695312, 'referece_logps/rejected': -419.5908203125, 'referece_logps/chosen': -530.754638671875, 'logits/rejected': 0.3164697587490082, 'logits/chosen': 0.3155859112739563, 'epoch': 1.67}


 28%|██▊       | 4491/16104 [20:55:32<57:33:50, 17.84s/it]
{'loss': 0.565, 'learning_rate': 1.6924527953907908e-06, 'rewards/chosen': -0.1118311733007431, 'rewards/rejected': -0.2035151571035385, 'rewards/accuracies': 0.625, 'rewards/margins': 0.09168396145105362, 'policy_logps/rejected': -319.5850524902344, 'policy_logps/chosen': -300.9219055175781, 'referece_logps/rejected': -317.5499267578125, 'referece_logps/chosen': -299.8035888671875, 'logits/rejected': -0.8320437073707581, 'logits/chosen': -0.7630928754806519, 'epoch': 1.67}


 28%|██▊       | 4493/16104 [20:56:03<52:38:06, 16.32s/it]

 28%|██▊       | 4494/16104 [20:56:20<52:56:34, 16.42s/it]
{'loss': 0.3923, 'learning_rate': 1.6920173537265734e-06, 'rewards/chosen': -0.031214047223329544, 'rewards/rejected': -1.0921111106872559, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0608969926834106, 'policy_logps/rejected': -354.090087890625, 'policy_logps/chosen': -346.879150390625, 'referece_logps/rejected': -343.1689758300781, 'referece_logps/chosen': -346.5669860839844, 'logits/rejected': -0.32609954476356506, 'logits/chosen': -0.16717948019504547, 'epoch': 1.67}


 28%|██▊       | 4496/16104 [20:56:56<56:18:47, 17.46s/it]
{'loss': 0.547, 'learning_rate': 1.6917269193072919e-06, 'rewards/chosen': -0.13625468313694, 'rewards/rejected': -0.7763673663139343, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6401126384735107, 'policy_logps/rejected': -344.0667724609375, 'policy_logps/chosen': -351.83251953125, 'referece_logps/rejected': -336.3031311035156, 'referece_logps/chosen': -350.4699401855469, 'logits/rejected': -0.3267044126987457, 'logits/chosen': -0.4450422525405884, 'epoch': 1.68}


 28%|██▊       | 4498/16104 [20:57:32<57:29:32, 17.83s/it]
{'loss': 0.4001, 'learning_rate': 1.6914363729616581e-06, 'rewards/chosen': -1.0228593349456787, 'rewards/rejected': -1.6733098030090332, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6504504680633545, 'policy_logps/rejected': -385.1896667480469, 'policy_logps/chosen': -397.34124755859375, 'referece_logps/rejected': -368.4566345214844, 'referece_logps/chosen': -387.1126708984375, 'logits/rejected': 0.45311227440834045, 'logits/chosen': 0.4571300745010376, 'epoch': 1.68}


 28%|██▊       | 4500/16104 [20:58:09<58:27:18, 18.14s/it]

 28%|██▊       | 4501/16104 [20:58:37<68:00:27, 21.10s/it]

 28%|██▊       | 4502/16104 [20:58:57<66:58:24, 20.78s/it]

 28%|██▊       | 4503/16104 [20:59:08<57:50:41, 17.95s/it]

 28%|██▊       | 4504/16104 [20:59:29<60:09:56, 18.67s/it]
{'loss': 0.5228, 'learning_rate': 1.6905640628368612e-06, 'rewards/chosen': -0.431789755821228, 'rewards/rejected': -0.8270605206489563, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3952707052230835, 'policy_logps/rejected': -292.9719543457031, 'policy_logps/chosen': -349.23291015625, 'referece_logps/rejected': -284.7013854980469, 'referece_logps/chosen': -344.9150085449219, 'logits/rejected': 0.11826297640800476, 'logits/chosen': 0.11045297980308533, 'epoch': 1.68}


 28%|██▊       | 4506/16104 [21:00:02<56:05:22, 17.41s/it]
{'loss': 0.5463, 'learning_rate': 1.6902730692561256e-06, 'rewards/chosen': -0.6175214648246765, 'rewards/rejected': -1.3382314443588257, 'rewards/accuracies': 0.625, 'rewards/margins': 0.720710039138794, 'policy_logps/rejected': -456.1114196777344, 'policy_logps/chosen': -595.5302734375, 'referece_logps/rejected': -442.7291259765625, 'referece_logps/chosen': -589.35498046875, 'logits/rejected': -0.5294999480247498, 'logits/chosen': -0.6276850700378418, 'epoch': 1.68}


 28%|██▊       | 4508/16104 [21:00:32<52:33:45, 16.32s/it]

 28%|██▊       | 4509/16104 [21:00:53<57:10:23, 17.75s/it]

 28%|██▊       | 4510/16104 [21:01:11<57:42:42, 17.92s/it]

 28%|██▊       | 4511/16104 [21:01:31<59:08:42, 18.37s/it]

 28%|██▊       | 4512/16104 [21:01:47<56:37:32, 17.59s/it]

 28%|██▊       | 4513/16104 [21:01:59<51:41:28, 16.05s/it]
{'loss': 0.4359, 'learning_rate': 1.6892537124652276e-06, 'rewards/chosen': 0.24248886108398438, 'rewards/rejected': -1.084439992904663, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3269288539886475, 'policy_logps/rejected': -266.27288818359375, 'policy_logps/chosen': -474.404296875, 'referece_logps/rejected': -255.42848205566406, 'referece_logps/chosen': -476.82916259765625, 'logits/rejected': 0.05592503771185875, 'logits/chosen': -0.0610811710357666, 'epoch': 1.68}


 28%|██▊       | 4515/16104 [21:02:30<49:39:30, 15.43s/it]
{'loss': 0.4581, 'learning_rate': 1.6889622166455573e-06, 'rewards/chosen': -0.3106911778450012, 'rewards/rejected': -1.7215685844421387, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4108774662017822, 'policy_logps/rejected': -495.487548828125, 'policy_logps/chosen': -380.429931640625, 'referece_logps/rejected': -478.2718505859375, 'referece_logps/chosen': -377.3230285644531, 'logits/rejected': -0.6022136211395264, 'logits/chosen': -0.47398021817207336, 'epoch': 1.68}


 28%|██▊       | 4517/16104 [21:03:06<54:30:37, 16.94s/it]
{'loss': 0.4791, 'learning_rate': 1.6886706093468837e-06, 'rewards/chosen': 0.034171201288700104, 'rewards/rejected': -1.4560019969940186, 'rewards/accuracies': 0.875, 'rewards/margins': 1.49017333984375, 'policy_logps/rejected': -280.8428955078125, 'policy_logps/chosen': -307.35858154296875, 'referece_logps/rejected': -266.28289794921875, 'referece_logps/chosen': -307.7002868652344, 'logits/rejected': -0.21036911010742188, 'logits/chosen': -0.4461956322193146, 'epoch': 1.68}

 28%|██▊       | 4518/16104 [21:03:28<59:06:00, 18.36s/it]


 28%|██▊       | 4520/16104 [21:04:07<60:26:20, 18.78s/it]

 28%|██▊       | 4521/16104 [21:04:23<58:26:14, 18.16s/it]

 28%|██▊       | 4522/16104 [21:04:40<56:40:31, 17.62s/it]
{'loss': 0.5431, 'learning_rate': 1.68794110368925e-06, 'rewards/chosen': 0.2853989005088806, 'rewards/rejected': -0.8036805987358093, 'rewards/accuracies': 1.0, 'rewards/margins': 1.08907949924469, 'policy_logps/rejected': -404.16375732421875, 'policy_logps/chosen': -366.5137634277344, 'referece_logps/rejected': -396.1269836425781, 'referece_logps/chosen': -369.3677673339844, 'logits/rejected': -0.14546117186546326, 'logits/chosen': -0.0672905296087265, 'epoch': 1.68}


 28%|██▊       | 4524/16104 [21:05:17<58:39:25, 18.24s/it]

 28%|██▊       | 4525/16104 [21:05:35<58:52:00, 18.30s/it]

 28%|██▊       | 4526/16104 [21:05:55<60:10:28, 18.71s/it]
{'loss': 0.4992, 'learning_rate': 1.6873569982157334e-06, 'rewards/chosen': -0.16700440645217896, 'rewards/rejected': -1.0769420862197876, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9099377393722534, 'policy_logps/rejected': -378.1429443359375, 'policy_logps/chosen': -437.8129577636719, 'referece_logps/rejected': -367.3735656738281, 'referece_logps/chosen': -436.1429138183594, 'logits/rejected': -0.45445746183395386, 'logits/chosen': -0.5480681657791138, 'epoch': 1.69}


 28%|██▊       | 4528/16104 [21:06:27<56:44:43, 17.65s/it]

 28%|██▊       | 4529/16104 [21:06:43<54:59:12, 17.10s/it]

 28%|██▊       | 4530/16104 [21:06:54<49:40:05, 15.45s/it]

 28%|██▊       | 4531/16104 [21:07:13<52:51:53, 16.44s/it]

 28%|██▊       | 4532/16104 [21:07:33<55:45:23, 17.35s/it]

 28%|██▊       | 4533/16104 [21:07:49<54:38:40, 17.00s/it]
{'loss': 0.5705, 'learning_rate': 1.6863337433792562e-06, 'rewards/chosen': 0.050619304180145264, 'rewards/rejected': -0.4014788568019867, 'rewards/accuracies': 0.5, 'rewards/margins': 0.45209813117980957, 'policy_logps/rejected': -504.34454345703125, 'policy_logps/chosen': -513.5189208984375, 'referece_logps/rejected': -500.32977294921875, 'referece_logps/chosen': -514.025146484375, 'logits/rejected': -0.040835559368133545, 'logits/chosen': 0.06363729387521744, 'epoch': 1.69}

 28%|██▊       | 4534/16104 [21:08:00<49:09:11, 15.29s/it]


 28%|██▊       | 4536/16104 [21:08:33<52:47:57, 16.43s/it]

 28%|██▊       | 4537/16104 [21:08:47<49:44:41, 15.48s/it]

 28%|██▊       | 4538/16104 [21:09:05<52:33:22, 16.36s/it]

 28%|██▊       | 4539/16104 [21:09:24<54:30:10, 16.97s/it]

 28%|██▊       | 4540/16104 [21:09:45<59:02:36, 18.38s/it]
{'loss': 0.5323, 'learning_rate': 1.6853091281351893e-06, 'rewards/chosen': -0.02282791957259178, 'rewards/rejected': -0.22679978609085083, 'rewards/accuracies': 0.625, 'rewards/margins': 0.20397186279296875, 'policy_logps/rejected': -357.52398681640625, 'policy_logps/chosen': -236.76930236816406, 'referece_logps/rejected': -355.2559814453125, 'referece_logps/chosen': -236.541015625, 'logits/rejected': -0.2402629405260086, 'logits/chosen': -0.34745755791664124, 'epoch': 1.69}


 28%|██▊       | 4542/16104 [21:10:24<60:44:58, 18.92s/it]

 28%|██▊       | 4543/16104 [21:10:36<54:04:23, 16.84s/it]
{'loss': 0.5637, 'learning_rate': 1.684869591368197e-06, 'rewards/chosen': -0.24012452363967896, 'rewards/rejected': -0.4932088851928711, 'rewards/accuracies': 0.75, 'rewards/margins': 0.25308436155319214, 'policy_logps/rejected': -350.33355712890625, 'policy_logps/chosen': -269.8071594238281, 'referece_logps/rejected': -345.4014587402344, 'referece_logps/chosen': -267.4059143066406, 'logits/rejected': -0.4250034987926483, 'logits/chosen': -0.3578876554965973, 'epoch': 1.69}


 28%|██▊       | 4545/16104 [21:11:02<47:58:06, 14.94s/it]

 28%|██▊       | 4546/16104 [21:11:18<48:54:57, 15.24s/it]

 28%|██▊       | 4547/16104 [21:11:29<45:14:55, 14.09s/it]
{'loss': 0.4957, 'learning_rate': 1.6842831545144618e-06, 'rewards/chosen': -0.06039125472307205, 'rewards/rejected': -0.5861578583717346, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5257666110992432, 'policy_logps/rejected': -286.93267822265625, 'policy_logps/chosen': -526.4773559570312, 'referece_logps/rejected': -281.07110595703125, 'referece_logps/chosen': -525.8734130859375, 'logits/rejected': -0.11377045512199402, 'logits/chosen': -0.12193990498781204, 'epoch': 1.69}


 28%|██▊       | 4549/16104 [21:11:54<42:38:55, 13.29s/it]

 28%|██▊       | 4550/16104 [21:12:14<49:19:18, 15.37s/it]
{'loss': 0.4197, 'learning_rate': 1.6838430362084228e-06, 'rewards/chosen': -0.18838921189308167, 'rewards/rejected': -1.8971995115280151, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7088102102279663, 'policy_logps/rejected': -347.50286865234375, 'policy_logps/chosen': -348.3009948730469, 'referece_logps/rejected': -328.5308837890625, 'referece_logps/chosen': -346.4171447753906, 'logits/rejected': 0.43463242053985596, 'logits/chosen': 0.39888614416122437, 'epoch': 1.7}


 28%|██▊       | 4552/16104 [21:12:50<52:40:49, 16.42s/it]

 28%|██▊       | 4553/16104 [21:13:08<54:22:40, 16.95s/it]
{'loss': 0.4176, 'learning_rate': 1.6834026689383507e-06, 'rewards/chosen': -0.028167523443698883, 'rewards/rejected': -1.9780634641647339, 'rewards/accuracies': 0.875, 'rewards/margins': 1.949895977973938, 'policy_logps/rejected': -435.06915283203125, 'policy_logps/chosen': -374.501953125, 'referece_logps/rejected': -415.28857421875, 'referece_logps/chosen': -374.22027587890625, 'logits/rejected': -0.09600621461868286, 'logits/chosen': -0.16466477513313293, 'epoch': 1.7}

 28%|██▊       | 4554/16104 [21:13:21<50:37:49, 15.78s/it]

 28%|██▊       | 4555/16104 [21:13:34<48:15:31, 15.04s/it]


 28%|██▊       | 4557/16104 [21:14:16<57:24:39, 17.90s/it]

 28%|██▊       | 4558/16104 [21:14:30<53:05:00, 16.55s/it]
{'loss': 0.4311, 'learning_rate': 1.6826681706703086e-06, 'rewards/chosen': -0.21208609640598297, 'rewards/rejected': -2.083908796310425, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8718225955963135, 'policy_logps/rejected': -325.4131774902344, 'policy_logps/chosen': -313.38458251953125, 'referece_logps/rejected': -304.5740966796875, 'referece_logps/chosen': -311.26373291015625, 'logits/rejected': -0.33586397767066956, 'logits/chosen': -0.32920512557029724, 'epoch': 1.7}


 28%|██▊       | 4560/16104 [21:15:06<54:58:40, 17.14s/it]
{'loss': 0.5565, 'learning_rate': 1.682374178015467e-06, 'rewards/chosen': 0.2451503872871399, 'rewards/rejected': -0.17155228555202484, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4167026877403259, 'policy_logps/rejected': -432.8451232910156, 'policy_logps/chosen': -431.59503173828125, 'referece_logps/rejected': -431.12957763671875, 'referece_logps/chosen': -434.04656982421875, 'logits/rejected': -0.4397892951965332, 'logits/chosen': -0.5080661177635193, 'epoch': 1.7}

 28%|██▊       | 4561/16104 [21:15:19<50:54:29, 15.88s/it]

 28%|██▊       | 4562/16104 [21:15:39<55:06:22, 17.19s/it]

 28%|██▊       | 4563/16104 [21:15:59<58:12:35, 18.16s/it]


 28%|██▊       | 4565/16104 [21:16:34<58:10:11, 18.15s/it]
{'loss': 0.4588, 'learning_rate': 1.6816387134255416e-06, 'rewards/chosen': -0.01903364434838295, 'rewards/rejected': -0.8482346534729004, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8292010426521301, 'policy_logps/rejected': -401.85455322265625, 'policy_logps/chosen': -499.6873474121094, 'referece_logps/rejected': -393.3721923828125, 'referece_logps/chosen': -499.49700927734375, 'logits/rejected': -0.5731790661811829, 'logits/chosen': -0.8025671243667603, 'epoch': 1.7}


 28%|██▊       | 4567/16104 [21:17:08<55:47:13, 17.41s/it]
{'loss': 0.636, 'learning_rate': 1.681344334533396e-06, 'rewards/chosen': -0.047012533992528915, 'rewards/rejected': -0.7165340185165405, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6695215702056885, 'policy_logps/rejected': -280.534912109375, 'policy_logps/chosen': -334.561767578125, 'referece_logps/rejected': -273.36956787109375, 'referece_logps/chosen': -334.0916442871094, 'logits/rejected': -0.8377503752708435, 'logits/chosen': -0.9605957865715027, 'epoch': 1.7}

 28%|██▊       | 4568/16104 [21:17:27<58:03:28, 18.12s/it]


 28%|██▊       | 4570/16104 [21:17:58<52:33:04, 16.40s/it]
{'loss': 0.5444, 'learning_rate': 1.6809025594981135e-06, 'rewards/chosen': 0.17745135724544525, 'rewards/rejected': 0.00553218275308609, 'rewards/accuracies': 0.5, 'rewards/margins': 0.17191918194293976, 'policy_logps/rejected': -550.5050048828125, 'policy_logps/chosen': -395.4163513183594, 'referece_logps/rejected': -550.560302734375, 'referece_logps/chosen': -397.19085693359375, 'logits/rejected': -0.2996147871017456, 'logits/chosen': -0.3195068836212158, 'epoch': 1.7}

 28%|██▊       | 4571/16104 [21:18:09<47:07:16, 14.71s/it]

 28%|██▊       | 4572/16104 [21:18:21<44:44:25, 13.97s/it]


 28%|██▊       | 4574/16104 [21:19:00<54:02:40, 16.87s/it]

 28%|██▊       | 4575/16104 [21:19:19<55:43:45, 17.40s/it]

 28%|██▊       | 4576/16104 [21:19:30<50:09:24, 15.66s/it]
{'loss': 0.4556, 'learning_rate': 1.6800182659079567e-06, 'rewards/chosen': -0.15404479205608368, 'rewards/rejected': -0.30785617232322693, 'rewards/accuracies': 0.5, 'rewards/margins': 0.15381135046482086, 'policy_logps/rejected': -414.2608642578125, 'policy_logps/chosen': -483.3515319824219, 'referece_logps/rejected': -411.1822814941406, 'referece_logps/chosen': -481.8110656738281, 'logits/rejected': -0.803281843662262, 'logits/chosen': -0.7934156060218811, 'epoch': 1.7}


 28%|██▊       | 4578/16104 [21:20:03<50:07:02, 15.65s/it]

 28%|██▊       | 4579/16104 [21:20:22<53:57:31, 16.85s/it]
{'loss': 0.4941, 'learning_rate': 1.6795757476750238e-06, 'rewards/chosen': -0.25362855195999146, 'rewards/rejected': -0.7679889798164368, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5143604278564453, 'policy_logps/rejected': -414.5282287597656, 'policy_logps/chosen': -414.866943359375, 'referece_logps/rejected': -406.84832763671875, 'referece_logps/chosen': -412.33062744140625, 'logits/rejected': -0.699658215045929, 'logits/chosen': -0.7715367674827576, 'epoch': 1.71}

 28%|██▊       | 4580/16104 [21:20:44<58:16:33, 18.20s/it]


 28%|██▊       | 4582/16104 [21:21:22<60:08:04, 18.79s/it]

 28%|██▊       | 4583/16104 [21:21:44<62:50:34, 19.64s/it]

 28%|██▊       | 4584/16104 [21:21:57<56:22:30, 17.62s/it]
{'loss': 0.4997, 'learning_rate': 1.6788376675653827e-06, 'rewards/chosen': -0.049508482217788696, 'rewards/rejected': -0.6266754269599915, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5771669745445251, 'policy_logps/rejected': -526.1028442382812, 'policy_logps/chosen': -442.7052307128906, 'referece_logps/rejected': -519.8361206054688, 'referece_logps/chosen': -442.2101135253906, 'logits/rejected': -0.42569658160209656, 'logits/chosen': -0.4584137201309204, 'epoch': 1.71}

 28%|██▊       | 4585/16104 [21:22:12<53:46:03, 16.80s/it]


 28%|██▊       | 4587/16104 [21:22:39<47:29:01, 14.84s/it]
{'loss': 0.5021, 'learning_rate': 1.678394489929485e-06, 'rewards/chosen': -0.05437079071998596, 'rewards/rejected': -0.7717331647872925, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7173622846603394, 'policy_logps/rejected': -416.2969970703125, 'policy_logps/chosen': -372.00567626953125, 'referece_logps/rejected': -408.57965087890625, 'referece_logps/chosen': -371.46197509765625, 'logits/rejected': 0.2669878900051117, 'logits/chosen': 0.2839099168777466, 'epoch': 1.71}

 28%|██▊       | 4588/16104 [21:22:53<47:31:11, 14.86s/it]

 28%|██▊       | 4589/16104 [21:23:09<48:05:07, 15.03s/it]

 29%|██▊       | 4590/16104 [21:23:25<49:16:24, 15.41s/it]

 29%|██▊       | 4591/16104 [21:23:42<50:28:26, 15.78s/it]

 29%|██▊       | 4592/16104 [21:23:59<51:53:26, 16.23s/it]

 29%|██▊       | 4593/16104 [21:24:19<55:31:43, 17.37s/it]


 29%|██▊       | 4595/16104 [21:24:58<59:17:53, 18.55s/it]
{'loss': 0.5489, 'learning_rate': 1.6772114758791857e-06, 'rewards/chosen': -0.5445716381072998, 'rewards/rejected': -1.0524433851242065, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5078717470169067, 'policy_logps/rejected': -323.6421813964844, 'policy_logps/chosen': -358.4226989746094, 'referece_logps/rejected': -313.11773681640625, 'referece_logps/chosen': -352.97698974609375, 'logits/rejected': -0.6618920564651489, 'logits/chosen': -0.7480170130729675, 'epoch': 1.71}

 29%|██▊       | 4596/16104 [21:25:19<61:42:41, 19.30s/it]


 29%|██▊       | 4598/16104 [21:25:52<56:23:09, 17.64s/it]

 29%|██▊       | 4599/16104 [21:26:15<61:03:04, 19.10s/it]
{'loss': 0.4256, 'learning_rate': 1.676619311196674e-06, 'rewards/chosen': -0.3821207284927368, 'rewards/rejected': -2.1584205627441406, 'rewards/accuracies': 0.875, 'rewards/margins': 1.776300072669983, 'policy_logps/rejected': -295.6241455078125, 'policy_logps/chosen': -309.0751953125, 'referece_logps/rejected': -274.0399475097656, 'referece_logps/chosen': -305.2540283203125, 'logits/rejected': -0.5483022332191467, 'logits/chosen': -0.6434913277626038, 'epoch': 1.71}


 29%|██▊       | 4601/16104 [21:26:48<57:51:22, 18.11s/it]

 29%|██▊       | 4602/16104 [21:27:03<54:38:12, 17.10s/it]
{'loss': 0.4879, 'learning_rate': 1.6761749002740193e-06, 'rewards/chosen': -0.14635451138019562, 'rewards/rejected': -0.8219031095504761, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6755486130714417, 'policy_logps/rejected': -464.230712890625, 'policy_logps/chosen': -518.8312377929688, 'referece_logps/rejected': -456.01171875, 'referece_logps/chosen': -517.3677978515625, 'logits/rejected': -0.45485636591911316, 'logits/chosen': -0.3922029733657837, 'epoch': 1.71}


 29%|██▊       | 4604/16104 [21:27:33<51:35:22, 16.15s/it]

 29%|██▊       | 4605/16104 [21:27:55<57:03:51, 17.87s/it]

 29%|██▊       | 4606/16104 [21:28:13<57:35:59, 18.03s/it]
{'loss': 0.4197, 'learning_rate': 1.6755819694703957e-06, 'rewards/chosen': 0.02655160427093506, 'rewards/rejected': -1.2903356552124023, 'rewards/accuracies': 0.875, 'rewards/margins': 1.316887378692627, 'policy_logps/rejected': -485.59600830078125, 'policy_logps/chosen': -350.22161865234375, 'referece_logps/rejected': -472.6926574707031, 'referece_logps/chosen': -350.48712158203125, 'logits/rejected': -0.28306978940963745, 'logits/chosen': -0.26485174894332886, 'epoch': 1.72}

 29%|██▊       | 4607/16104 [21:28:35<61:34:31, 19.28s/it]

 29%|██▊       | 4608/16104 [21:28:52<59:10:41, 18.53s/it]


 29%|██▊       | 4610/16104 [21:29:25<54:23:08, 17.03s/it]
{'loss': 0.4109, 'learning_rate': 1.6749886014108539e-06, 'rewards/chosen': -0.9844205975532532, 'rewards/rejected': -1.9285292625427246, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9441086053848267, 'policy_logps/rejected': -356.1483459472656, 'policy_logps/chosen': -305.6314697265625, 'referece_logps/rejected': -336.8630065917969, 'referece_logps/chosen': -295.7872619628906, 'logits/rejected': -0.7040517926216125, 'logits/chosen': -0.6035882830619812, 'epoch': 1.72}

 29%|██▊       | 4611/16104 [21:29:44<56:16:59, 17.63s/it]


 29%|██▊       | 4613/16104 [21:30:13<52:23:09, 16.41s/it]
{'loss': 0.4922, 'learning_rate': 1.6745432886480182e-06, 'rewards/chosen': 0.03685607761144638, 'rewards/rejected': -1.3445736169815063, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3814297914505005, 'policy_logps/rejected': -498.9002990722656, 'policy_logps/chosen': -409.2205810546875, 'referece_logps/rejected': -485.4545593261719, 'referece_logps/chosen': -409.589111328125, 'logits/rejected': 0.039978593587875366, 'logits/chosen': 0.08392152190208435, 'epoch': 1.72}


 29%|██▊       | 4615/16104 [21:30:43<48:39:51, 15.25s/it]

 29%|██▊       | 4616/16104 [21:30:57<47:45:15, 14.96s/it]

 29%|██▊       | 4617/16104 [21:31:17<52:23:31, 16.42s/it]
{'loss': 0.4729, 'learning_rate': 1.6739491563148987e-06, 'rewards/chosen': 0.4167085886001587, 'rewards/rejected': -0.7052451968193054, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1219537258148193, 'policy_logps/rejected': -445.6642150878906, 'policy_logps/chosen': -495.5704345703125, 'referece_logps/rejected': -438.61175537109375, 'referece_logps/chosen': -499.7374572753906, 'logits/rejected': -0.27804455161094666, 'logits/chosen': -0.2287697046995163, 'epoch': 1.72}


 29%|██▊       | 4619/16104 [21:31:51<53:46:46, 16.86s/it]
{'loss': 0.5338, 'learning_rate': 1.6736519265496262e-06, 'rewards/chosen': -0.21500077843666077, 'rewards/rejected': -0.6092674136161804, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3942667245864868, 'policy_logps/rejected': -434.63824462890625, 'policy_logps/chosen': -337.2136535644531, 'referece_logps/rejected': -428.5455322265625, 'referece_logps/chosen': -335.06365966796875, 'logits/rejected': -0.8721520900726318, 'logits/chosen': -0.886891782283783, 'epoch': 1.72}


 29%|██▊       | 4621/16104 [21:32:29<57:54:22, 18.15s/it]
{'loss': 0.4153, 'learning_rate': 1.6733545877826644e-06, 'rewards/chosen': 0.3930801451206207, 'rewards/rejected': -0.8807748556137085, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2738549709320068, 'policy_logps/rejected': -380.85040283203125, 'policy_logps/chosen': -544.796142578125, 'referece_logps/rejected': -372.0426330566406, 'referece_logps/chosen': -548.7269897460938, 'logits/rejected': -0.5339200496673584, 'logits/chosen': -0.492459774017334, 'epoch': 1.72}

 29%|██▊       | 4622/16104 [21:32:40<50:47:32, 15.93s/it]


 29%|██▊       | 4624/16104 [21:33:09<48:51:19, 15.32s/it]
{'loss': 0.5015, 'learning_rate': 1.672908375359304e-06, 'rewards/chosen': -0.18080443143844604, 'rewards/rejected': -0.7551113367080688, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5743069052696228, 'policy_logps/rejected': -374.282958984375, 'policy_logps/chosen': -435.33551025390625, 'referece_logps/rejected': -366.73187255859375, 'referece_logps/chosen': -433.5274658203125, 'logits/rejected': 0.5190500617027283, 'logits/chosen': 0.7179641127586365, 'epoch': 1.72}


 29%|██▊       | 4626/16104 [21:33:51<58:57:24, 18.49s/it]
{'loss': 0.6032, 'learning_rate': 1.6726107642986462e-06, 'rewards/chosen': 0.08549851924180984, 'rewards/rejected': -0.40341833233833313, 'rewards/accuracies': 0.5, 'rewards/margins': 0.48891687393188477, 'policy_logps/rejected': -362.1917724609375, 'policy_logps/chosen': -343.218994140625, 'referece_logps/rejected': -358.1575927734375, 'referece_logps/chosen': -344.073974609375, 'logits/rejected': 0.011972304433584213, 'logits/chosen': -0.514386773109436, 'epoch': 1.72}


 29%|██▊       | 4628/16104 [21:34:30<59:36:19, 18.70s/it]
{'loss': 0.4335, 'learning_rate': 1.6723130444047667e-06, 'rewards/chosen': 0.15068301558494568, 'rewards/rejected': -0.8739977478981018, 'rewards/accuracies': 0.875, 'rewards/margins': 1.024680733680725, 'policy_logps/rejected': -344.9046325683594, 'policy_logps/chosen': -502.69256591796875, 'referece_logps/rejected': -336.1646423339844, 'referece_logps/chosen': -504.1993713378906, 'logits/rejected': -0.632504940032959, 'logits/chosen': -0.8411863446235657, 'epoch': 1.72}


 29%|██▉       | 4630/16104 [21:35:13<64:08:27, 20.12s/it]
{'loss': 0.5044, 'learning_rate': 1.672015215725839e-06, 'rewards/chosen': -0.0009828805923461914, 'rewards/rejected': -0.9514385461807251, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9504556655883789, 'policy_logps/rejected': -479.3776550292969, 'policy_logps/chosen': -339.93389892578125, 'referece_logps/rejected': -469.8633117675781, 'referece_logps/chosen': -339.9240417480469, 'logits/rejected': -0.034537091851234436, 'logits/chosen': -0.011076889932155609, 'epoch': 1.73}

 29%|██▉       | 4631/16104 [21:35:30<61:33:10, 19.31s/it]

 29%|██▉       | 4632/16104 [21:35:42<54:44:13, 17.18s/it]


 29%|██▉       | 4634/16104 [21:36:15<52:34:44, 16.50s/it]
{'loss': 0.5491, 'learning_rate': 1.6714192322056186e-06, 'rewards/chosen': -0.5339180827140808, 'rewards/rejected': -1.072654128074646, 'rewards/accuracies': 0.625, 'rewards/margins': 0.53873610496521, 'policy_logps/rejected': -421.7253723144531, 'policy_logps/chosen': -526.4970703125, 'referece_logps/rejected': -410.99884033203125, 'referece_logps/chosen': -521.1578979492188, 'logits/rejected': 0.4884972870349884, 'logits/chosen': 0.5672388672828674, 'epoch': 1.73}

 29%|██▉       | 4635/16104 [21:36:36<57:04:01, 17.91s/it]

 29%|██▉       | 4636/16104 [21:36:51<53:33:31, 16.81s/it]

 29%|██▉       | 4637/16104 [21:37:12<57:43:01, 18.12s/it]

 29%|██▉       | 4638/16104 [21:37:30<57:42:37, 18.12s/it]


 29%|██▉       | 4640/16104 [21:38:05<56:35:00, 17.77s/it]
{'loss': 0.4312, 'learning_rate': 1.6705244422427667e-06, 'rewards/chosen': 0.016514591872692108, 'rewards/rejected': -0.8723281621932983, 'rewards/accuracies': 0.875, 'rewards/margins': 0.888842761516571, 'policy_logps/rejected': -468.66229248046875, 'policy_logps/chosen': -514.9039306640625, 'referece_logps/rejected': -459.93902587890625, 'referece_logps/chosen': -515.0690307617188, 'logits/rejected': -0.05895078182220459, 'logits/chosen': -0.02104930579662323, 'epoch': 1.73}


 29%|██▉       | 4642/16104 [21:38:47<62:01:46, 19.48s/it]
{'loss': 0.5648, 'learning_rate': 1.6702259618661708e-06, 'rewards/chosen': -0.8110349774360657, 'rewards/rejected': -1.1324939727783203, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3214590847492218, 'policy_logps/rejected': -346.17681884765625, 'policy_logps/chosen': -506.3482666015625, 'referece_logps/rejected': -334.85186767578125, 'referece_logps/chosen': -498.23785400390625, 'logits/rejected': -0.5740000605583191, 'logits/chosen': -0.4343114495277405, 'epoch': 1.73}


 29%|██▉       | 4644/16104 [21:39:27<63:15:28, 19.87s/it]

 29%|██▉       | 4645/16104 [21:39:42<58:15:42, 18.30s/it]

 29%|██▉       | 4646/16104 [21:39:59<57:16:05, 17.99s/it]

 29%|██▉       | 4647/16104 [21:40:15<55:45:07, 17.52s/it]

 29%|██▉       | 4648/16104 [21:40:37<59:49:56, 18.80s/it]

 29%|██▉       | 4649/16104 [21:40:50<53:49:52, 16.92s/it]
{'loss': 0.5384, 'learning_rate': 1.6691804268423565e-06, 'rewards/chosen': -0.12394067645072937, 'rewards/rejected': -0.922695517539978, 'rewards/accuracies': 0.875, 'rewards/margins': 0.798754870891571, 'policy_logps/rejected': -436.86346435546875, 'policy_logps/chosen': -451.84429931640625, 'referece_logps/rejected': -427.636474609375, 'referece_logps/chosen': -450.6048889160156, 'logits/rejected': 0.23182763159275055, 'logits/chosen': 0.3200300931930542, 'epoch': 1.73}


 29%|██▉       | 4651/16104 [21:41:13<45:19:33, 14.25s/it]
{'loss': 0.5607, 'learning_rate': 1.6688814588333005e-06, 'rewards/chosen': -0.6657243967056274, 'rewards/rejected': -1.1830358505249023, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5173115134239197, 'policy_logps/rejected': -393.0597229003906, 'policy_logps/chosen': -303.2378234863281, 'referece_logps/rejected': -381.2293395996094, 'referece_logps/chosen': -296.58056640625, 'logits/rejected': -0.6800646781921387, 'logits/chosen': -0.6846587657928467, 'epoch': 1.73}


 29%|██▉       | 4653/16104 [21:41:37<41:53:12, 13.17s/it]

 29%|██▉       | 4654/16104 [21:41:56<47:12:31, 14.84s/it]
{'loss': 0.4584, 'learning_rate': 1.668432803903976e-06, 'rewards/chosen': -0.03697548434138298, 'rewards/rejected': -0.935139000415802, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8981634378433228, 'policy_logps/rejected': -418.71978759765625, 'policy_logps/chosen': -611.9862060546875, 'referece_logps/rejected': -409.368408203125, 'referece_logps/chosen': -611.6165161132812, 'logits/rejected': -1.0465012788772583, 'logits/chosen': -1.1439043283462524, 'epoch': 1.73}

 29%|██▉       | 4655/16104 [21:42:07<43:16:22, 13.61s/it]

 29%|██▉       | 4656/16104 [21:42:23<45:39:37, 14.36s/it]

 29%|██▉       | 4657/16104 [21:42:42<49:55:42, 15.70s/it]

 29%|██▉       | 4658/16104 [21:42:52<45:09:27, 14.20s/it]


 29%|██▉       | 4660/16104 [21:43:24<46:50:50, 14.74s/it]
{'loss': 0.5099, 'learning_rate': 1.6675347641476832e-06, 'rewards/chosen': -0.11859235167503357, 'rewards/rejected': -0.9715043306350708, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8529119491577148, 'policy_logps/rejected': -482.2821960449219, 'policy_logps/chosen': -709.6007080078125, 'referece_logps/rejected': -472.5671081542969, 'referece_logps/chosen': -708.414794921875, 'logits/rejected': 0.1294974386692047, 'logits/chosen': 0.12032511085271835, 'epoch': 1.74}


 29%|██▉       | 4662/16104 [21:43:52<46:20:18, 14.58s/it]
{'loss': 0.5093, 'learning_rate': 1.6672352014738755e-06, 'rewards/chosen': -0.4975718557834625, 'rewards/rejected': -1.883138656616211, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3855668306350708, 'policy_logps/rejected': -326.15179443359375, 'policy_logps/chosen': -398.0290222167969, 'referece_logps/rejected': -307.3204345703125, 'referece_logps/chosen': -393.0533142089844, 'logits/rejected': -0.1031242161989212, 'logits/chosen': -0.11658826470375061, 'epoch': 1.74}

 29%|██▉       | 4663/16104 [21:44:09<49:10:20, 15.47s/it]

 29%|██▉       | 4664/16104 [21:44:24<48:10:29, 15.16s/it]


 29%|██▉       | 4666/16104 [21:45:00<53:04:59, 16.71s/it]
{'loss': 0.4511, 'learning_rate': 1.6666357522844976e-06, 'rewards/chosen': 0.25362151861190796, 'rewards/rejected': -0.9871622323989868, 'rewards/accuracies': 0.75, 'rewards/margins': 1.24078369140625, 'policy_logps/rejected': -694.3792724609375, 'policy_logps/chosen': -809.6011352539062, 'referece_logps/rejected': -684.5077514648438, 'referece_logps/chosen': -812.1373291015625, 'logits/rejected': 0.021807841956615448, 'logits/chosen': -0.1605163812637329, 'epoch': 1.74}

 29%|██▉       | 4667/16104 [21:45:13<49:45:16, 15.66s/it]

 29%|██▉       | 4668/16104 [21:45:37<57:07:52, 17.98s/it]

 29%|██▉       | 4669/16104 [21:45:57<59:04:57, 18.60s/it]

 29%|██▉       | 4670/16104 [21:46:15<58:46:22, 18.50s/it]

 29%|██▉       | 4671/16104 [21:46:35<60:19:51, 19.00s/it]

 29%|██▉       | 4672/16104 [21:46:57<63:25:03, 19.97s/it]

 29%|██▉       | 4673/16104 [21:47:11<56:55:34, 17.93s/it]


 29%|██▉       | 4675/16104 [21:47:46<56:41:43, 17.86s/it]
{'loss': 0.5017, 'learning_rate': 1.665285414653555e-06, 'rewards/chosen': 0.17153531312942505, 'rewards/rejected': -0.33316880464553833, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5047041177749634, 'policy_logps/rejected': -333.3415222167969, 'policy_logps/chosen': -343.65313720703125, 'referece_logps/rejected': -330.0098571777344, 'referece_logps/chosen': -345.3684997558594, 'logits/rejected': -0.18590007722377777, 'logits/chosen': -0.13149480521678925, 'epoch': 1.74}


 29%|██▉       | 4677/16104 [21:48:28<61:48:08, 19.47s/it]
{'loss': 0.4825, 'learning_rate': 1.6649850434368138e-06, 'rewards/chosen': 0.10386715084314346, 'rewards/rejected': -1.1984732151031494, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3023403882980347, 'policy_logps/rejected': -384.7798156738281, 'policy_logps/chosen': -484.7870178222656, 'referece_logps/rejected': -372.79510498046875, 'referece_logps/chosen': -485.82568359375, 'logits/rejected': -0.4554154872894287, 'logits/chosen': -0.4149589538574219, 'epoch': 1.74}

 29%|██▉       | 4678/16104 [21:48:49<62:58:13, 19.84s/it]

 29%|██▉       | 4679/16104 [21:49:08<61:54:42, 19.51s/it]

 29%|██▉       | 4680/16104 [21:49:25<59:55:16, 18.88s/it]

 29%|██▉       | 4681/16104 [21:49:41<57:14:49, 18.04s/it]

 29%|██▉       | 4682/16104 [21:49:55<53:28:07, 16.85s/it]

 29%|██▉       | 4683/16104 [21:50:16<56:56:09, 17.95s/it]

 29%|██▉       | 4684/16104 [21:50:35<58:38:33, 18.49s/it]

 29%|██▉       | 4685/16104 [21:50:48<52:52:22, 16.67s/it]

 29%|██▉       | 4686/16104 [21:51:00<48:15:18, 15.21s/it]

 29%|██▉       | 4687/16104 [21:51:17<50:29:43, 15.92s/it]


 29%|██▉       | 4689/16104 [21:51:44<46:01:36, 14.52s/it]
{'loss': 0.5505, 'learning_rate': 1.6631805582528258e-06, 'rewards/chosen': -0.5153605937957764, 'rewards/rejected': -0.8333780169487, 'rewards/accuracies': 0.5, 'rewards/margins': 0.31801748275756836, 'policy_logps/rejected': -555.2328491210938, 'policy_logps/chosen': -559.4588623046875, 'referece_logps/rejected': -546.8990478515625, 'referece_logps/chosen': -554.3053588867188, 'logits/rejected': 0.472318172454834, 'logits/chosen': 0.45510849356651306, 'epoch': 1.75}

 29%|██▉       | 4690/16104 [21:51:59<46:22:24, 14.63s/it]


 29%|██▉       | 4692/16104 [21:52:35<51:57:10, 16.39s/it]
{'loss': 0.6236, 'learning_rate': 1.6627288329421973e-06, 'rewards/chosen': 0.3903404474258423, 'rewards/rejected': -0.435678094625473, 'rewards/accuracies': 0.375, 'rewards/margins': 0.8260185718536377, 'policy_logps/rejected': -514.4365844726562, 'policy_logps/chosen': -532.4808349609375, 'referece_logps/rejected': -510.0798034667969, 'referece_logps/chosen': -536.38427734375, 'logits/rejected': 0.08920857310295105, 'logits/chosen': 0.2274189293384552, 'epoch': 1.75}


 29%|██▉       | 4694/16104 [21:52:59<45:11:16, 14.26s/it]
{'loss': 0.561, 'learning_rate': 1.66242754868214e-06, 'rewards/chosen': 0.11410675942897797, 'rewards/rejected': -0.09849970042705536, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21260645985603333, 'policy_logps/rejected': -513.7161865234375, 'policy_logps/chosen': -486.48297119140625, 'referece_logps/rejected': -512.731201171875, 'referece_logps/chosen': -487.6240234375, 'logits/rejected': -0.13284507393836975, 'logits/chosen': -0.10477693378925323, 'epoch': 1.75}


 29%|██▉       | 4696/16104 [21:53:29<45:23:06, 14.32s/it]
{'loss': 0.6817, 'learning_rate': 1.6621261572365783e-06, 'rewards/chosen': -0.15801487863063812, 'rewards/rejected': -0.5858625769615173, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4278477132320404, 'policy_logps/rejected': -419.5425720214844, 'policy_logps/chosen': -513.0249633789062, 'referece_logps/rejected': -413.6839904785156, 'referece_logps/chosen': -511.4448547363281, 'logits/rejected': 1.0052837133407593, 'logits/chosen': 1.051600456237793, 'epoch': 1.75}

 29%|██▉       | 4697/16104 [21:53:42<44:20:25, 13.99s/it]

 29%|██▉       | 4698/16104 [21:54:02<49:43:04, 15.69s/it]

 29%|██▉       | 4699/16104 [21:54:12<44:59:58, 14.20s/it]

 29%|██▉       | 4700/16104 [21:54:24<42:35:42, 13.45s/it]

 29%|██▉       | 4701/16104 [21:54:42<47:13:05, 14.91s/it]

 29%|██▉       | 4702/16104 [21:55:00<49:30:09, 15.63s/it]

 29%|██▉       | 4703/16104 [21:55:13<47:20:21, 14.95s/it]


 29%|██▉       | 4705/16104 [21:55:47<50:57:12, 16.09s/it]

 29%|██▉       | 4706/16104 [21:56:05<53:02:22, 16.75s/it]
{'loss': 0.4058, 'learning_rate': 1.6606175939336611e-06, 'rewards/chosen': -0.22796860337257385, 'rewards/rejected': -1.073872447013855, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8459038138389587, 'policy_logps/rejected': -479.76104736328125, 'policy_logps/chosen': -521.8521728515625, 'referece_logps/rejected': -469.0223388671875, 'referece_logps/chosen': -519.572509765625, 'logits/rejected': 0.7112302184104919, 'logits/chosen': 0.6667786240577698, 'epoch': 1.75}


 29%|██▉       | 4708/16104 [21:56:35<50:02:22, 15.81s/it]
{'loss': 0.4321, 'learning_rate': 1.6603155603997908e-06, 'rewards/chosen': 0.07127523422241211, 'rewards/rejected': -1.1168495416641235, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1881247758865356, 'policy_logps/rejected': -441.443115234375, 'policy_logps/chosen': -417.1701354980469, 'referece_logps/rejected': -430.2746276855469, 'referece_logps/chosen': -417.88287353515625, 'logits/rejected': -0.05968180671334267, 'logits/chosen': -0.11534306406974792, 'epoch': 1.75}

 29%|██▉       | 4709/16104 [21:56:54<53:29:25, 16.90s/it]

 29%|██▉       | 4710/16104 [21:57:10<52:45:18, 16.67s/it]

 29%|██▉       | 4711/16104 [21:57:32<57:19:40, 18.11s/it]

 29%|██▉       | 4712/16104 [21:57:54<60:48:02, 19.21s/it]

 29%|██▉       | 4713/16104 [21:58:14<62:02:05, 19.61s/it]

 29%|██▉       | 4714/16104 [21:58:34<62:05:30, 19.63s/it]

 29%|██▉       | 4715/16104 [21:58:49<58:11:25, 18.39s/it]

 29%|██▉       | 4716/16104 [21:59:02<52:13:03, 16.51s/it]

 29%|██▉       | 4717/16104 [21:59:17<50:58:35, 16.12s/it]

 29%|██▉       | 4718/16104 [21:59:36<53:33:44, 16.94s/it]

 29%|██▉       | 4719/16104 [21:59:52<53:31:46, 16.93s/it]

 29%|██▉       | 4720/16104 [22:00:13<56:29:29, 17.86s/it]

 29%|██▉       | 4721/16104 [22:00:30<56:05:09, 17.74s/it]

 29%|██▉       | 4722/16104 [22:00:45<53:17:10, 16.85s/it]

 29%|██▉       | 4723/16104 [22:01:02<53:18:13, 16.86s/it]

 29%|██▉       | 4724/16104 [22:01:20<54:30:53, 17.25s/it]

 29%|██▉       | 4725/16104 [22:01:39<56:47:46, 17.97s/it]

 29%|██▉       | 4726/16104 [22:01:56<55:12:58, 17.47s/it]

 29%|██▉       | 4727/16104 [22:02:12<53:57:58, 17.08s/it]


 29%|██▉       | 4729/16104 [22:02:43<50:49:13, 16.08s/it]
{'loss': 0.4221, 'learning_rate': 1.6571377669554248e-06, 'rewards/chosen': -0.25871676206588745, 'rewards/rejected': -1.971846342086792, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7131296396255493, 'policy_logps/rejected': -329.33447265625, 'policy_logps/chosen': -367.2012023925781, 'referece_logps/rejected': -309.61602783203125, 'referece_logps/chosen': -364.614013671875, 'logits/rejected': -0.2947040796279907, 'logits/chosen': -0.22993676364421844, 'epoch': 1.76}

 29%|██▉       | 4730/16104 [22:02:58<49:41:52, 15.73s/it]


 29%|██▉       | 4732/16104 [22:03:37<55:30:12, 17.57s/it]
{'loss': 0.5257, 'learning_rate': 1.6566828381737423e-06, 'rewards/chosen': -0.1190626323223114, 'rewards/rejected': -1.1317262649536133, 'rewards/accuracies': 0.875, 'rewards/margins': 1.012663722038269, 'policy_logps/rejected': -347.3642272949219, 'policy_logps/chosen': -382.64495849609375, 'referece_logps/rejected': -336.0469970703125, 'referece_logps/chosen': -381.4543151855469, 'logits/rejected': -0.6603909730911255, 'logits/chosen': -0.5891865491867065, 'epoch': 1.76}

 29%|██▉       | 4733/16104 [22:03:52<52:51:45, 16.74s/it]


 29%|██▉       | 4735/16104 [22:04:25<54:19:34, 17.20s/it]
{'loss': 0.4162, 'learning_rate': 1.6562276703161325e-06, 'rewards/chosen': -0.22405976057052612, 'rewards/rejected': -1.8912990093231201, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6672390699386597, 'policy_logps/rejected': -425.4018249511719, 'policy_logps/chosen': -419.6075744628906, 'referece_logps/rejected': -406.4888916015625, 'referece_logps/chosen': -417.366943359375, 'logits/rejected': -0.028310507535934448, 'logits/chosen': 0.039204761385917664, 'epoch': 1.76}

 29%|██▉       | 4736/16104 [22:04:44<56:13:01, 17.80s/it]

 29%|██▉       | 4737/16104 [22:05:06<60:10:20, 19.06s/it]


 29%|██▉       | 4739/16104 [22:05:37<54:11:52, 17.17s/it]
{'loss': 0.4224, 'learning_rate': 1.6556204082298591e-06, 'rewards/chosen': -0.4740459620952606, 'rewards/rejected': -1.5466465950012207, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0726007223129272, 'policy_logps/rejected': -428.79180908203125, 'policy_logps/chosen': -489.31634521484375, 'referece_logps/rejected': -413.3253479003906, 'referece_logps/chosen': -484.575927734375, 'logits/rejected': 0.5135314464569092, 'logits/chosen': 0.7286207675933838, 'epoch': 1.77}

 29%|██▉       | 4740/16104 [22:05:54<54:14:27, 17.18s/it]


 29%|██▉       | 4742/16104 [22:06:29<54:22:01, 17.23s/it]
{'loss': 0.3935, 'learning_rate': 1.6551646831730013e-06, 'rewards/chosen': -0.774823009967804, 'rewards/rejected': -1.5627851486206055, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7879621386528015, 'policy_logps/rejected': -418.8433532714844, 'policy_logps/chosen': -368.20025634765625, 'referece_logps/rejected': -403.21551513671875, 'referece_logps/chosen': -360.4520263671875, 'logits/rejected': -0.3594586253166199, 'logits/chosen': -0.29432207345962524, 'epoch': 1.77}

 29%|██▉       | 4743/16104 [22:06:50<57:17:04, 18.15s/it]


 29%|██▉       | 4745/16104 [22:07:18<50:16:57, 15.94s/it]
{'loss': 0.5608, 'learning_rate': 1.6547087195929247e-06, 'rewards/chosen': -0.15930108726024628, 'rewards/rejected': -1.0199995040893555, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8606984615325928, 'policy_logps/rejected': -322.3067932128906, 'policy_logps/chosen': -305.2165222167969, 'referece_logps/rejected': -312.10675048828125, 'referece_logps/chosen': -303.62353515625, 'logits/rejected': -0.360268771648407, 'logits/chosen': -0.3082021176815033, 'epoch': 1.77}

 29%|██▉       | 4746/16104 [22:07:33<49:45:59, 15.77s/it]

 29%|██▉       | 4747/16104 [22:07:47<48:03:29, 15.23s/it]

 29%|██▉       | 4748/16104 [22:07:58<44:12:00, 14.01s/it]


 29%|██▉       | 4750/16104 [22:08:32<49:52:55, 15.82s/it]
{'loss': 0.5734, 'learning_rate': 1.653948250692106e-06, 'rewards/chosen': 0.07966364920139313, 'rewards/rejected': -1.4675357341766357, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5471992492675781, 'policy_logps/rejected': -600.7410888671875, 'policy_logps/chosen': -463.40667724609375, 'referece_logps/rejected': -586.065673828125, 'referece_logps/chosen': -464.2032775878906, 'logits/rejected': -0.3692810833454132, 'logits/chosen': -0.24496878683567047, 'epoch': 1.77}


 30%|██▉       | 4752/16104 [22:09:14<58:34:41, 18.58s/it]
{'loss': 0.5012, 'learning_rate': 1.6536438779150878e-06, 'rewards/chosen': -0.12659302353858948, 'rewards/rejected': -1.4932630062103271, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3666698932647705, 'policy_logps/rejected': -634.7176513671875, 'policy_logps/chosen': -471.21954345703125, 'referece_logps/rejected': -619.7849731445312, 'referece_logps/chosen': -469.9535827636719, 'logits/rejected': -0.1573767066001892, 'logits/chosen': 0.055273786187171936, 'epoch': 1.77}

 30%|██▉       | 4753/16104 [22:09:31<57:03:46, 18.10s/it]


 30%|██▉       | 4755/16104 [22:10:10<59:31:24, 18.88s/it]
{'loss': 0.4833, 'learning_rate': 1.6531871204569982e-06, 'rewards/chosen': 0.4654605984687805, 'rewards/rejected': -0.8141727447509766, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2796334028244019, 'policy_logps/rejected': -424.00445556640625, 'policy_logps/chosen': -529.0827026367188, 'referece_logps/rejected': -415.8627624511719, 'referece_logps/chosen': -533.7373046875, 'logits/rejected': 0.30407053232192993, 'logits/chosen': 0.31723517179489136, 'epoch': 1.77}


 30%|██▉       | 4757/16104 [22:10:44<56:30:15, 17.93s/it]
{'loss': 0.3914, 'learning_rate': 1.6528824833617506e-06, 'rewards/chosen': -0.14556904137134552, 'rewards/rejected': -1.7667616605758667, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6211925745010376, 'policy_logps/rejected': -505.4893493652344, 'policy_logps/chosen': -442.23272705078125, 'referece_logps/rejected': -487.82177734375, 'referece_logps/chosen': -440.77703857421875, 'logits/rejected': 0.4593198001384735, 'logits/chosen': 0.5647966861724854, 'epoch': 1.77}

 30%|██▉       | 4758/16104 [22:11:04<58:48:03, 18.66s/it]

 30%|██▉       | 4759/16104 [22:11:18<54:23:06, 17.26s/it]

 30%|██▉       | 4760/16104 [22:11:35<53:40:37, 17.03s/it]

 30%|██▉       | 4761/16104 [22:11:47<49:15:39, 15.63s/it]

 30%|██▉       | 4762/16104 [22:12:03<49:47:33, 15.80s/it]

 30%|██▉       | 4763/16104 [22:12:20<50:36:07, 16.06s/it]

 30%|██▉       | 4764/16104 [22:12:42<56:35:27, 17.97s/it]

 30%|██▉       | 4765/16104 [22:12:56<52:40:28, 16.72s/it]

 30%|██▉       | 4766/16104 [22:13:07<47:23:54, 15.05s/it]

 30%|██▉       | 4767/16104 [22:13:27<51:50:23, 16.46s/it]

 30%|██▉       | 4768/16104 [22:13:46<54:48:30, 17.41s/it]

 30%|██▉       | 4769/16104 [22:14:04<54:40:58, 17.37s/it]

 30%|██▉       | 4770/16104 [22:14:17<51:14:02, 16.27s/it]

 30%|██▉       | 4771/16104 [22:14:28<46:05:30, 14.64s/it]

 30%|██▉       | 4772/16104 [22:14:40<43:44:12, 13.89s/it]

 30%|██▉       | 4773/16104 [22:14:58<47:23:30, 15.06s/it]

 30%|██▉       | 4774/16104 [22:15:09<43:25:05, 13.80s/it]

 30%|██▉       | 4775/16104 [22:15:28<48:05:00, 15.28s/it]

 30%|██▉       | 4776/16104 [22:15:39<43:48:17, 13.92s/it]

 30%|██▉       | 4777/16104 [22:15:57<47:58:43, 15.25s/it]

 30%|██▉       | 4778/16104 [22:16:12<48:03:16, 15.27s/it]

 30%|██▉       | 4779/16104 [22:16:32<52:25:38, 16.67s/it]

 30%|██▉       | 4780/16104 [22:16:47<50:49:04, 16.16s/it]

 30%|██▉       | 4781/16104 [22:16:58<45:28:16, 14.46s/it]

 30%|██▉       | 4782/16104 [22:17:18<50:45:11, 16.14s/it]

 30%|██▉       | 4783/16104 [22:17:32<49:06:51, 15.62s/it]

 30%|██▉       | 4784/16104 [22:17:44<45:10:40, 14.37s/it]

 30%|██▉       | 4785/16104 [22:18:03<50:05:18, 15.93s/it]

 30%|██▉       | 4786/16104 [22:18:20<50:48:16, 16.16s/it]

 30%|██▉       | 4787/16104 [22:18:36<50:30:18, 16.07s/it]

 30%|██▉       | 4788/16104 [22:18:52<50:56:52, 16.21s/it]

 30%|██▉       | 4789/16104 [22:19:10<52:04:10, 16.57s/it]

 30%|██▉       | 4790/16104 [22:19:30<55:24:31, 17.63s/it]

 30%|██▉       | 4791/16104 [22:19:47<54:49:14, 17.44s/it]

 30%|██▉       | 4792/16104 [22:20:05<55:38:40, 17.71s/it]


 30%|██▉       | 4794/16104 [22:20:39<55:07:30, 17.55s/it]

 30%|██▉       | 4795/16104 [22:20:54<52:54:30, 16.84s/it]

 30%|██▉       | 4796/16104 [22:21:15<56:33:02, 18.00s/it]

 30%|██▉       | 4797/16104 [22:21:36<59:24:12, 18.91s/it]

 30%|██▉       | 4798/16104 [22:21:56<60:31:04, 19.27s/it]

 30%|██▉       | 4799/16104 [22:22:17<62:12:55, 19.81s/it]

 30%|██▉       | 4800/16104 [22:22:32<57:41:45, 18.37s/it]

 30%|██▉       | 4801/16104 [22:22:54<60:44:46, 19.35s/it]
{'loss': 0.5718, 'learning_rate': 1.6461538275601532e-06, 'rewards/chosen': 0.10216979682445526, 'rewards/rejected': -0.7122431397438049, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8144130706787109, 'policy_logps/rejected': -270.1134033203125, 'policy_logps/chosen': -346.438232421875, 'referece_logps/rejected': -262.990966796875, 'referece_logps/chosen': -347.45989990234375, 'logits/rejected': -0.5554917454719543, 'logits/chosen': -0.7337307929992676, 'epoch': 1.79}


 30%|██▉       | 4803/16104 [22:23:26<55:16:12, 17.61s/it]

 30%|██▉       | 4804/16104 [22:23:39<51:06:46, 16.28s/it]

 30%|██▉       | 4805/16104 [22:23:55<51:05:57, 16.28s/it]
{'loss': 0.4216, 'learning_rate': 1.6455396143899787e-06, 'rewards/chosen': -0.23891419172286987, 'rewards/rejected': -1.466246247291565, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2273319959640503, 'policy_logps/rejected': -345.8580627441406, 'policy_logps/chosen': -363.87115478515625, 'referece_logps/rejected': -331.19561767578125, 'referece_logps/chosen': -361.4820251464844, 'logits/rejected': -0.07009058445692062, 'logits/chosen': -0.07266577333211899, 'epoch': 1.79}


 30%|██▉       | 4807/16104 [22:24:30<52:41:43, 16.79s/it]

 30%|██▉       | 4808/16104 [22:24:50<55:52:03, 17.80s/it]

 30%|██▉       | 4809/16104 [22:25:12<59:24:30, 18.93s/it]

 30%|██▉       | 4810/16104 [22:25:32<60:34:33, 19.31s/it]

 30%|██▉       | 4811/16104 [22:25:42<52:21:15, 16.69s/it]

 30%|██▉       | 4812/16104 [22:25:59<51:52:52, 16.54s/it]

 30%|██▉       | 4813/16104 [22:26:15<51:20:06, 16.37s/it]

 30%|██▉       | 4814/16104 [22:26:32<52:06:38, 16.62s/it]

 30%|██▉       | 4815/16104 [22:26:48<52:08:50, 16.63s/it]

 30%|██▉       | 4816/16104 [22:27:08<54:42:58, 17.45s/it]

 30%|██▉       | 4817/16104 [22:27:23<52:47:08, 16.84s/it]

 30%|██▉       | 4818/16104 [22:27:34<47:00:01, 14.99s/it]

 30%|██▉       | 4819/16104 [22:27:45<42:55:26, 13.69s/it]

 30%|██▉       | 4820/16104 [22:28:07<51:02:06, 16.28s/it]

 30%|██▉       | 4821/16104 [22:28:18<46:13:53, 14.75s/it]

 30%|██▉       | 4822/16104 [22:28:29<43:01:58, 13.73s/it]

 30%|██▉       | 4823/16104 [22:28:42<42:05:43, 13.43s/it]

 30%|██▉       | 4824/16104 [22:28:53<39:27:33, 12.59s/it]

 30%|██▉       | 4825/16104 [22:29:08<41:28:43, 13.24s/it]

 30%|██▉       | 4826/16104 [22:29:25<45:41:53, 14.59s/it]

 30%|██▉       | 4827/16104 [22:29:36<42:06:04, 13.44s/it]

 30%|██▉       | 4828/16104 [22:29:56<48:05:10, 15.35s/it]

 30%|██▉       | 4829/16104 [22:30:09<45:54:12, 14.66s/it]

 30%|██▉       | 4830/16104 [22:30:24<46:14:42, 14.77s/it]

 30%|██▉       | 4831/16104 [22:30:36<43:34:27, 13.92s/it]

 30%|███       | 4832/16104 [22:30:49<43:12:43, 13.80s/it]

 30%|███       | 4833/16104 [22:31:10<49:20:04, 15.76s/it]

 30%|███       | 4834/16104 [22:31:23<46:48:37, 14.95s/it]

 30%|███       | 4835/16104 [22:31:43<51:55:00, 16.59s/it]

 30%|███       | 4836/16104 [22:32:02<53:47:25, 17.19s/it]

 30%|███       | 4837/16104 [22:32:16<51:22:30, 16.42s/it]
{'loss': 0.3901, 'learning_rate': 1.6406109012590014e-06, 'rewards/chosen': -0.5263558030128479, 'rewards/rejected': -1.2698516845703125, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7434958219528198, 'policy_logps/rejected': -276.5623779296875, 'policy_logps/chosen': -422.0384216308594, 'referece_logps/rejected': -263.8638610839844, 'referece_logps/chosen': -416.77484130859375, 'logits/rejected': -0.8184143900871277, 'logits/chosen': -0.8552806973457336, 'epoch': 1.8}


 30%|███       | 4839/16104 [22:32:57<57:31:03, 18.38s/it]

 30%|███       | 4840/16104 [22:33:10<52:04:27, 16.64s/it]

 30%|███       | 4841/16104 [22:33:30<55:36:12, 17.77s/it]

 30%|███       | 4842/16104 [22:33:52<59:23:37, 18.99s/it]

 30%|███       | 4843/16104 [22:34:06<54:50:59, 17.53s/it]

 30%|███       | 4844/16104 [22:34:27<58:13:21, 18.61s/it]

 30%|███       | 4845/16104 [22:34:49<61:06:25, 19.54s/it]

 30%|███       | 4846/16104 [22:35:10<62:37:58, 20.03s/it]

 30%|███       | 4847/16104 [22:35:28<60:25:19, 19.32s/it]

 30%|███       | 4848/16104 [22:35:44<57:24:23, 18.36s/it]

 30%|███       | 4849/16104 [22:36:01<56:28:26, 18.06s/it]

 30%|███       | 4850/16104 [22:36:12<49:34:43, 15.86s/it]
{'loss': 0.5273, 'learning_rate': 1.63860102019396e-06, 'rewards/chosen': -0.03879013657569885, 'rewards/rejected': -0.3453351855278015, 'rewards/accuracies': 0.625, 'rewards/margins': 0.30654504895210266, 'policy_logps/rejected': -483.62591552734375, 'policy_logps/chosen': -469.1802978515625, 'referece_logps/rejected': -480.1725769042969, 'referece_logps/chosen': -468.79241943359375, 'logits/rejected': -0.15925723314285278, 'logits/chosen': -0.02425508201122284, 'epoch': 1.81}


 30%|███       | 4852/16104 [22:36:45<50:44:57, 16.24s/it]

 30%|███       | 4853/16104 [22:37:00<49:37:38, 15.88s/it]

 30%|███       | 4854/16104 [22:37:19<53:00:03, 16.96s/it]

 30%|███       | 4855/16104 [22:37:33<50:02:12, 16.01s/it]
{'loss': 0.5502, 'learning_rate': 1.6378268257995038e-06, 'rewards/chosen': -0.01189727708697319, 'rewards/rejected': -0.6223015189170837, 'rewards/accuracies': 0.625, 'rewards/margins': 0.610404372215271, 'policy_logps/rejected': -552.8717651367188, 'policy_logps/chosen': -624.3077392578125, 'referece_logps/rejected': -546.648681640625, 'referece_logps/chosen': -624.1887817382812, 'logits/rejected': 0.5241305232048035, 'logits/chosen': 0.6233491897583008, 'epoch': 1.81}


 30%|███       | 4857/16104 [22:38:06<50:08:50, 16.05s/it]
{'loss': 0.4894, 'learning_rate': 1.6375169673892367e-06, 'rewards/chosen': -0.4469638764858246, 'rewards/rejected': -0.8425454497337341, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3955816626548767, 'policy_logps/rejected': -579.7788696289062, 'policy_logps/chosen': -360.87139892578125, 'referece_logps/rejected': -571.3534545898438, 'referece_logps/chosen': -356.40179443359375, 'logits/rejected': -0.6526398658752441, 'logits/chosen': -0.2152175009250641, 'epoch': 1.81}

 30%|███       | 4858/16104 [22:38:24<52:07:29, 16.69s/it]


 30%|███       | 4860/16104 [22:39:05<58:47:59, 18.83s/it]

 30%|███       | 4861/16104 [22:39:24<58:59:35, 18.89s/it]

 30%|███       | 4862/16104 [22:39:45<61:28:19, 19.69s/it]

 30%|███       | 4863/16104 [22:40:03<59:47:54, 19.15s/it]

 30%|███       | 4864/16104 [22:40:20<57:14:44, 18.33s/it]
{'loss': 0.3872, 'learning_rate': 1.6364316509384682e-06, 'rewards/chosen': -0.0022352151572704315, 'rewards/rejected': -1.0669727325439453, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0647374391555786, 'policy_logps/rejected': -472.92901611328125, 'policy_logps/chosen': -506.6224365234375, 'referece_logps/rejected': -462.25927734375, 'referece_logps/chosen': -506.60009765625, 'logits/rejected': 1.3591704368591309, 'logits/chosen': 1.4499155282974243, 'epoch': 1.81}


 30%|███       | 4866/16104 [22:40:53<53:44:27, 17.22s/it]

 30%|███       | 4867/16104 [22:41:15<58:05:47, 18.61s/it]

 30%|███       | 4868/16104 [22:41:33<57:47:47, 18.52s/it]

 30%|███       | 4869/16104 [22:41:53<58:33:58, 18.77s/it]
{'loss': 0.4859, 'learning_rate': 1.6356556524329142e-06, 'rewards/chosen': 0.17559203505516052, 'rewards/rejected': -0.9035947322845459, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0791867971420288, 'policy_logps/rejected': -453.11724853515625, 'policy_logps/chosen': -482.1747131347656, 'referece_logps/rejected': -444.0813293457031, 'referece_logps/chosen': -483.9306335449219, 'logits/rejected': -0.4529562294483185, 'logits/chosen': -0.3690200448036194, 'epoch': 1.81}


 30%|███       | 4871/16104 [22:42:33<60:58:03, 19.54s/it]

 30%|███       | 4872/16104 [22:42:49<56:57:08, 18.25s/it]
{'loss': 0.4402, 'learning_rate': 1.6351897447184894e-06, 'rewards/chosen': -0.2928810119628906, 'rewards/rejected': -1.3541675806045532, 'rewards/accuracies': 0.5, 'rewards/margins': 1.0612868070602417, 'policy_logps/rejected': -406.6171569824219, 'policy_logps/chosen': -341.8564453125, 'referece_logps/rejected': -393.075439453125, 'referece_logps/chosen': -338.9276123046875, 'logits/rejected': 0.2460206001996994, 'logits/chosen': 0.1634630560874939, 'epoch': 1.82}


 30%|███       | 4874/16104 [22:43:23<56:06:15, 17.99s/it]

 30%|███       | 4875/16104 [22:43:43<57:27:41, 18.42s/it]
{'loss': 0.424, 'learning_rate': 1.634723605753043e-06, 'rewards/chosen': 0.1886415332555771, 'rewards/rejected': -0.9795724749565125, 'rewards/accuracies': 0.875, 'rewards/margins': 1.168213963508606, 'policy_logps/rejected': -295.35198974609375, 'policy_logps/chosen': -329.8571472167969, 'referece_logps/rejected': -285.5563049316406, 'referece_logps/chosen': -331.7435302734375, 'logits/rejected': -0.15758973360061646, 'logits/chosen': -0.22938498854637146, 'epoch': 1.82}

 30%|███       | 4876/16104 [22:43:59<54:59:21, 17.63s/it]

 30%|███       | 4877/16104 [22:44:21<58:58:00, 18.91s/it]

 30%|███       | 4878/16104 [22:44:40<59:40:47, 19.14s/it]


 30%|███       | 4880/16104 [22:45:20<60:44:23, 19.48s/it]
{'loss': 0.4015, 'learning_rate': 1.6339461940471054e-06, 'rewards/chosen': -0.8704441785812378, 'rewards/rejected': -2.081490993499756, 'rewards/accuracies': 0.75, 'rewards/margins': 1.211046814918518, 'policy_logps/rejected': -504.69671630859375, 'policy_logps/chosen': -442.806396484375, 'referece_logps/rejected': -483.88177490234375, 'referece_logps/chosen': -434.1019592285156, 'logits/rejected': -0.21890521049499512, 'logits/chosen': -0.09588195383548737, 'epoch': 1.82}


 30%|███       | 4882/16104 [22:45:50<53:21:07, 17.12s/it]

 30%|███       | 4883/16104 [22:46:10<55:55:51, 17.94s/it]

 30%|███       | 4884/16104 [22:46:29<57:20:06, 18.40s/it]

 30%|███       | 4885/16104 [22:46:47<57:11:15, 18.35s/it]

 30%|███       | 4886/16104 [22:47:00<51:55:54, 16.67s/it]

 30%|███       | 4887/16104 [22:47:20<54:38:42, 17.54s/it]
{'loss': 0.5611, 'learning_rate': 1.632856740776408e-06, 'rewards/chosen': -0.12922196090221405, 'rewards/rejected': -0.7601379156112671, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6309159398078918, 'policy_logps/rejected': -407.4849548339844, 'policy_logps/chosen': -348.47412109375, 'referece_logps/rejected': -399.8835754394531, 'referece_logps/chosen': -347.18194580078125, 'logits/rejected': -0.2917037308216095, 'logits/chosen': -0.41586753726005554, 'epoch': 1.82}


 30%|███       | 4889/16104 [22:47:51<51:35:41, 16.56s/it]

 30%|███       | 4890/16104 [22:48:06<50:03:43, 16.07s/it]
{'loss': 0.4688, 'learning_rate': 1.6323894481031153e-06, 'rewards/chosen': 0.43338510394096375, 'rewards/rejected': -0.14754658937454224, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5809317231178284, 'policy_logps/rejected': -423.78802490234375, 'policy_logps/chosen': -584.5432739257812, 'referece_logps/rejected': -422.3125, 'referece_logps/chosen': -588.8770751953125, 'logits/rejected': 0.39375656843185425, 'logits/chosen': 0.45858100056648254, 'epoch': 1.82}

 30%|███       | 4891/16104 [22:48:27<54:29:06, 17.49s/it]


 30%|███       | 4893/16104 [22:48:57<51:59:18, 16.69s/it]
{'loss': 0.4951, 'learning_rate': 1.6319219251982932e-06, 'rewards/chosen': 0.316501259803772, 'rewards/rejected': -0.5847101211547852, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9012113809585571, 'policy_logps/rejected': -412.388916015625, 'policy_logps/chosen': -439.7122802734375, 'referece_logps/rejected': -406.5418395996094, 'referece_logps/chosen': -442.8772888183594, 'logits/rejected': -0.07010005414485931, 'logits/chosen': -0.10978908836841583, 'epoch': 1.82}


 30%|███       | 4895/16104 [22:49:28<48:49:09, 15.68s/it]

 30%|███       | 4896/16104 [22:49:46<50:53:50, 16.35s/it]
{'loss': 0.5078, 'learning_rate': 1.6314541722321518e-06, 'rewards/chosen': -0.1859542578458786, 'rewards/rejected': -0.5893653631210327, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4034111201763153, 'policy_logps/rejected': -411.67645263671875, 'policy_logps/chosen': -418.70941162109375, 'referece_logps/rejected': -405.7828063964844, 'referece_logps/chosen': -416.8498840332031, 'logits/rejected': -0.18031160533428192, 'logits/chosen': -0.27868878841400146, 'epoch': 1.82}


 30%|███       | 4898/16104 [22:50:14<46:55:59, 15.08s/it]

 30%|███       | 4899/16104 [22:50:30<48:00:18, 15.42s/it]

 30%|███       | 4900/16104 [22:50:48<50:34:46, 16.25s/it]

 30%|███       | 4901/16104 [22:51:02<48:29:03, 15.58s/it]

 30%|███       | 4902/16104 [22:51:22<52:12:41, 16.78s/it]

 30%|███       | 4903/16104 [22:51:40<53:18:20, 17.13s/it]

 30%|███       | 4904/16104 [22:51:54<50:38:49, 16.28s/it]

 30%|███       | 4905/16104 [22:52:04<45:15:12, 14.55s/it]

 30%|███       | 4906/16104 [22:52:16<42:47:22, 13.76s/it]
{'loss': 0.577, 'learning_rate': 1.6298933363114767e-06, 'rewards/chosen': 0.1858939230442047, 'rewards/rejected': -0.7090394496917725, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8949334621429443, 'policy_logps/rejected': -335.1817932128906, 'policy_logps/chosen': -418.9024963378906, 'referece_logps/rejected': -328.0914306640625, 'referece_logps/chosen': -420.7614440917969, 'logits/rejected': -0.6735586524009705, 'logits/chosen': -0.7700827121734619, 'epoch': 1.83}


 30%|███       | 4908/16104 [22:52:44<42:57:19, 13.81s/it]

 30%|███       | 4909/16104 [22:53:02<47:21:33, 15.23s/it]
{'loss': 0.5284, 'learning_rate': 1.6294245883818546e-06, 'rewards/chosen': -0.21870052814483643, 'rewards/rejected': -0.11695368587970734, 'rewards/accuracies': 0.375, 'rewards/margins': -0.10174687206745148, 'policy_logps/rejected': -634.9749755859375, 'policy_logps/chosen': -541.8999633789062, 'referece_logps/rejected': -633.805419921875, 'referece_logps/chosen': -539.712890625, 'logits/rejected': 0.07023297250270844, 'logits/chosen': 0.009641915559768677, 'epoch': 1.83}


 30%|███       | 4911/16104 [22:53:34<49:59:56, 16.08s/it]

 31%|███       | 4912/16104 [22:53:56<54:51:19, 17.64s/it]
{'loss': 0.6141, 'learning_rate': 1.6289556113001082e-06, 'rewards/chosen': -0.10365104675292969, 'rewards/rejected': -1.1875768899917603, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0839258432388306, 'policy_logps/rejected': -463.6725158691406, 'policy_logps/chosen': -460.2904052734375, 'referece_logps/rejected': -451.7967834472656, 'referece_logps/chosen': -459.25390625, 'logits/rejected': -0.4876161515712738, 'logits/chosen': -0.615933358669281, 'epoch': 1.83}


 31%|███       | 4914/16104 [22:54:28<52:54:49, 17.02s/it]
{'loss': 0.5514, 'learning_rate': 1.6286428326898536e-06, 'rewards/chosen': -0.5357503890991211, 'rewards/rejected': -1.5667873620986938, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0310369729995728, 'policy_logps/rejected': -396.97625732421875, 'policy_logps/chosen': -224.4854278564453, 'referece_logps/rejected': -381.3083801269531, 'referece_logps/chosen': -219.12791442871094, 'logits/rejected': -0.33472877740859985, 'logits/chosen': -0.06999759376049042, 'epoch': 1.83}


 31%|███       | 4916/16104 [22:54:50<43:14:33, 13.91s/it]
{'loss': 0.5954, 'learning_rate': 1.6283299523607026e-06, 'rewards/chosen': 0.13024893403053284, 'rewards/rejected': -0.26698458194732666, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3972334563732147, 'policy_logps/rejected': -515.2435302734375, 'policy_logps/chosen': -547.4705200195312, 'referece_logps/rejected': -512.57373046875, 'referece_logps/chosen': -548.77294921875, 'logits/rejected': -0.42077240347862244, 'logits/chosen': -0.42512521147727966, 'epoch': 1.83}


 31%|███       | 4918/16104 [22:55:28<51:32:14, 16.59s/it]
{'loss': 0.4433, 'learning_rate': 1.6280169703632813e-06, 'rewards/chosen': -0.2763431668281555, 'rewards/rejected': -0.7478712201118469, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4715281128883362, 'policy_logps/rejected': -275.5431213378906, 'policy_logps/chosen': -423.1600646972656, 'referece_logps/rejected': -268.0644226074219, 'referece_logps/chosen': -420.3966369628906, 'logits/rejected': -0.3204294443130493, 'logits/chosen': -0.26928192377090454, 'epoch': 1.83}


 31%|███       | 4920/16104 [22:55:50<42:13:50, 13.59s/it]

 31%|███       | 4921/16104 [22:56:12<50:48:29, 16.36s/it]

 31%|███       | 4922/16104 [22:56:32<53:57:48, 17.37s/it]

 31%|███       | 4923/16104 [22:56:52<55:55:38, 18.01s/it]

 31%|███       | 4924/16104 [22:57:06<52:17:12, 16.84s/it]

 31%|███       | 4925/16104 [22:57:21<50:31:21, 16.27s/it]

 31%|███       | 4926/16104 [22:57:36<49:44:32, 16.02s/it]

 31%|███       | 4927/16104 [22:57:50<47:47:03, 15.39s/it]

 31%|███       | 4928/16104 [22:58:04<46:31:42, 14.99s/it]

 31%|███       | 4929/16104 [22:58:22<49:26:42, 15.93s/it]
{'loss': 0.4612, 'learning_rate': 1.6262937543210564e-06, 'rewards/chosen': -1.0125041007995605, 'rewards/rejected': -1.6190135478973389, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6065095663070679, 'policy_logps/rejected': -475.1009521484375, 'policy_logps/chosen': -561.1995849609375, 'referece_logps/rejected': -458.91082763671875, 'referece_logps/chosen': -551.0745239257812, 'logits/rejected': 0.361648291349411, 'logits/chosen': 0.3662506639957428, 'epoch': 1.84}


 31%|███       | 4931/16104 [22:58:57<52:11:11, 16.81s/it]
{'loss': 0.4402, 'learning_rate': 1.625980112715029e-06, 'rewards/chosen': -0.13526266813278198, 'rewards/rejected': -1.1432573795318604, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0079948902130127, 'policy_logps/rejected': -402.3732604980469, 'policy_logps/chosen': -326.7318115234375, 'referece_logps/rejected': -390.940673828125, 'referece_logps/chosen': -325.3791809082031, 'logits/rejected': -0.7854104042053223, 'logits/chosen': -0.4933270215988159, 'epoch': 1.84}


 31%|███       | 4933/16104 [22:59:24<47:23:30, 15.27s/it]

 31%|███       | 4934/16104 [22:59:45<52:24:30, 16.89s/it]
{'loss': 0.4725, 'learning_rate': 1.6255094604067594e-06, 'rewards/chosen': 0.048247575759887695, 'rewards/rejected': -1.3166186809539795, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3648661375045776, 'policy_logps/rejected': -386.1383361816406, 'policy_logps/chosen': -591.7396240234375, 'referece_logps/rejected': -372.9721374511719, 'referece_logps/chosen': -592.2220458984375, 'logits/rejected': 0.15453565120697021, 'logits/chosen': 0.050202809274196625, 'epoch': 1.84}


 31%|███       | 4936/16104 [23:00:18<50:51:30, 16.39s/it]

 31%|███       | 4937/16104 [23:00:38<54:01:27, 17.42s/it]

 31%|███       | 4938/16104 [23:00:53<51:49:53, 16.71s/it]

 31%|███       | 4939/16104 [23:01:07<49:17:04, 15.89s/it]
{'loss': 0.391, 'learning_rate': 1.624724533918166e-06, 'rewards/chosen': -0.34989452362060547, 'rewards/rejected': -1.2516155242919922, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9017210006713867, 'policy_logps/rejected': -493.28558349609375, 'policy_logps/chosen': -389.0779724121094, 'referece_logps/rejected': -480.76947021484375, 'referece_logps/chosen': -385.57904052734375, 'logits/rejected': -0.4399421811103821, 'logits/chosen': -0.1090613603591919, 'epoch': 1.84}

 31%|███       | 4940/16104 [23:01:20<46:22:56, 14.96s/it]

 31%|███       | 4941/16104 [23:01:42<52:56:33, 17.07s/it]


 31%|███       | 4943/16104 [23:02:20<56:40:02, 18.28s/it]
{'loss': 0.5276, 'learning_rate': 1.624096137807205e-06, 'rewards/chosen': -0.7676971554756165, 'rewards/rejected': -0.8355192542076111, 'rewards/accuracies': 0.375, 'rewards/margins': 0.06782205402851105, 'policy_logps/rejected': -328.0087585449219, 'policy_logps/chosen': -331.1322021484375, 'referece_logps/rejected': -319.6535949707031, 'referece_logps/chosen': -323.4552307128906, 'logits/rejected': -0.35613542795181274, 'logits/chosen': -0.5920321345329285, 'epoch': 1.84}


 31%|███       | 4945/16104 [23:02:59<58:17:02, 18.80s/it]

 31%|███       | 4946/16104 [23:03:19<59:36:32, 19.23s/it]

 31%|███       | 4947/16104 [23:03:35<56:47:19, 18.32s/it]

 31%|███       | 4948/16104 [23:03:49<52:15:20, 16.86s/it]
{'loss': 0.4242, 'learning_rate': 1.6233100746856635e-06, 'rewards/chosen': 0.28101101517677307, 'rewards/rejected': -1.0236403942108154, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3046513795852661, 'policy_logps/rejected': -293.886962890625, 'policy_logps/chosen': -524.3275756835938, 'referece_logps/rejected': -283.65057373046875, 'referece_logps/chosen': -527.1376953125, 'logits/rejected': -0.5610355138778687, 'logits/chosen': -0.5967440605163574, 'epoch': 1.84}


 31%|███       | 4950/16104 [23:04:19<50:46:29, 16.39s/it]
{'loss': 0.5102, 'learning_rate': 1.6229954728944895e-06, 'rewards/chosen': -0.6385087966918945, 'rewards/rejected': -1.3333625793457031, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6948538422584534, 'policy_logps/rejected': -254.24517822265625, 'policy_logps/chosen': -325.2218017578125, 'referece_logps/rejected': -240.91156005859375, 'referece_logps/chosen': -318.83673095703125, 'logits/rejected': -0.8070545196533203, 'logits/chosen': -0.7704309225082397, 'epoch': 1.84}

 31%|███       | 4951/16104 [23:04:36<51:15:20, 16.54s/it]


 31%|███       | 4953/16104 [23:05:12<53:38:16, 17.32s/it]
{'loss': 0.6039, 'learning_rate': 1.6225233812140528e-06, 'rewards/chosen': -0.4745502471923828, 'rewards/rejected': -0.8891172409057617, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4145669937133789, 'policy_logps/rejected': -444.2696838378906, 'policy_logps/chosen': -340.0501403808594, 'referece_logps/rejected': -435.37847900390625, 'referece_logps/chosen': -335.3046569824219, 'logits/rejected': 0.18687665462493896, 'logits/chosen': 0.14433175325393677, 'epoch': 1.85}

 31%|███       | 4954/16104 [23:05:26<49:59:49, 16.14s/it]


 31%|███       | 4956/16104 [23:06:01<52:36:08, 16.99s/it]

 31%|███       | 4957/16104 [23:06:18<53:01:28, 17.12s/it]

 31%|███       | 4958/16104 [23:06:30<48:27:47, 15.65s/it]

 31%|███       | 4959/16104 [23:06:47<49:00:27, 15.83s/it]

 31%|███       | 4960/16104 [23:07:09<54:36:28, 17.64s/it]

 31%|███       | 4961/16104 [23:07:29<56:51:58, 18.37s/it]

 31%|███       | 4962/16104 [23:07:45<55:21:58, 17.89s/it]
{'loss': 0.5401, 'learning_rate': 1.6211057470228733e-06, 'rewards/chosen': -0.5768485069274902, 'rewards/rejected': -0.8948870897293091, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3180384933948517, 'policy_logps/rejected': -396.00177001953125, 'policy_logps/chosen': -395.84552001953125, 'referece_logps/rejected': -387.0528869628906, 'referece_logps/chosen': -390.07708740234375, 'logits/rejected': 0.044981539249420166, 'logits/chosen': 0.10587454587221146, 'epoch': 1.85}

 31%|███       | 4963/16104 [23:08:04<55:54:27, 18.07s/it]

 31%|███       | 4964/16104 [23:08:26<59:47:17, 19.32s/it]


 31%|███       | 4966/16104 [23:09:01<57:20:02, 18.53s/it]

 31%|███       | 4967/16104 [23:09:21<58:32:32, 18.92s/it]

 31%|███       | 4968/16104 [23:09:44<62:02:19, 20.06s/it]

 31%|███       | 4969/16104 [23:10:05<63:05:38, 20.40s/it]

 31%|███       | 4970/16104 [23:10:19<57:35:10, 18.62s/it]

 31%|███       | 4971/16104 [23:10:41<60:27:48, 19.55s/it]

 31%|███       | 4972/16104 [23:11:03<62:44:52, 20.29s/it]
{'loss': 0.4212, 'learning_rate': 1.6195282112648006e-06, 'rewards/chosen': 0.021721743047237396, 'rewards/rejected': -1.3404512405395508, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3621729612350464, 'policy_logps/rejected': -192.96788024902344, 'policy_logps/chosen': -345.78045654296875, 'referece_logps/rejected': -179.5633544921875, 'referece_logps/chosen': -345.9976501464844, 'logits/rejected': -0.6179679036140442, 'logits/chosen': -0.6205277442932129, 'epoch': 1.85}

 31%|███       | 4973/16104 [23:11:22<61:59:25, 20.05s/it]


 31%|███       | 4975/16104 [23:11:59<58:55:09, 19.06s/it]

 31%|███       | 4976/16104 [23:12:13<54:22:08, 17.59s/it]
{'loss': 0.4252, 'learning_rate': 1.6188964948954985e-06, 'rewards/chosen': -0.6772881746292114, 'rewards/rejected': -1.426682949066162, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7493947744369507, 'policy_logps/rejected': -309.6960144042969, 'policy_logps/chosen': -289.12799072265625, 'referece_logps/rejected': -295.42919921875, 'referece_logps/chosen': -282.3551025390625, 'logits/rejected': 0.39653655886650085, 'logits/chosen': 0.29779455065727234, 'epoch': 1.85}

 31%|███       | 4977/16104 [23:12:30<53:38:47, 17.36s/it]

 31%|███       | 4978/16104 [23:12:46<52:15:29, 16.91s/it]

 31%|███       | 4979/16104 [23:13:06<55:23:46, 17.93s/it]

 31%|███       | 4980/16104 [23:13:28<58:42:15, 19.00s/it]

 31%|███       | 4981/16104 [23:13:43<54:58:28, 17.79s/it]

 31%|███       | 4982/16104 [23:13:59<53:24:32, 17.29s/it]

 31%|███       | 4983/16104 [23:14:19<55:39:11, 18.02s/it]

 31%|███       | 4984/16104 [23:14:34<53:04:07, 17.18s/it]

 31%|███       | 4985/16104 [23:14:55<56:36:09, 18.33s/it]

 31%|███       | 4986/16104 [23:15:07<50:39:40, 16.40s/it]

 31%|███       | 4987/16104 [23:15:27<53:45:59, 17.41s/it]

 31%|███       | 4988/16104 [23:15:37<47:30:52, 15.39s/it]

 31%|███       | 4989/16104 [23:15:49<44:20:00, 14.36s/it]


 31%|███       | 4991/16104 [23:16:19<46:25:50, 15.04s/it]
{'loss': 0.3811, 'learning_rate': 1.6165239942976983e-06, 'rewards/chosen': 0.6028313040733337, 'rewards/rejected': -1.3931620121002197, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9959934949874878, 'policy_logps/rejected': -421.01416015625, 'policy_logps/chosen': -457.91180419921875, 'referece_logps/rejected': -407.08251953125, 'referece_logps/chosen': -463.940185546875, 'logits/rejected': -0.36687836050987244, 'logits/chosen': -0.02703923173248768, 'epoch': 1.86}

 31%|███       | 4992/16104 [23:16:40<52:04:29, 16.87s/it]

 31%|███       | 4993/16104 [23:16:57<51:22:15, 16.64s/it]

 31%|███       | 4994/16104 [23:17:16<54:04:12, 17.52s/it]

 31%|███       | 4995/16104 [23:17:33<53:39:28, 17.39s/it]

 31%|███       | 4996/16104 [23:17:47<50:10:46, 16.26s/it]

 31%|███       | 4997/16104 [23:17:59<46:04:24, 14.93s/it]

 31%|███       | 4998/16104 [23:18:11<43:39:32, 14.15s/it]


 31%|███       | 5000/16104 [23:18:42<44:33:11, 14.44s/it]
{'loss': 0.5407, 'learning_rate': 1.6150977990913897e-06, 'rewards/chosen': 0.4058155417442322, 'rewards/rejected': -1.039162278175354, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4449777603149414, 'policy_logps/rejected': -355.5677490234375, 'policy_logps/chosen': -425.47393798828125, 'referece_logps/rejected': -345.1761169433594, 'referece_logps/chosen': -429.5320739746094, 'logits/rejected': -0.02447301149368286, 'logits/chosen': -0.14289513230323792, 'epoch': 1.86}


 31%|███       | 5002/16104 [23:19:32<59:55:43, 19.43s/it]

 31%|███       | 5003/16104 [23:19:46<55:06:10, 17.87s/it]

 31%|███       | 5004/16104 [23:20:00<51:20:57, 16.65s/it]
{'loss': 0.4304, 'learning_rate': 1.6144632873505165e-06, 'rewards/chosen': -0.3057870864868164, 'rewards/rejected': -1.5271025896072388, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2213155031204224, 'policy_logps/rejected': -708.28564453125, 'policy_logps/chosen': -580.2149658203125, 'referece_logps/rejected': -693.0146484375, 'referece_logps/chosen': -577.1570434570312, 'logits/rejected': 0.1750759482383728, 'logits/chosen': 0.14275847375392914, 'epoch': 1.86}

 31%|███       | 5005/16104 [23:20:22<56:14:40, 18.24s/it]

 31%|███       | 5006/16104 [23:20:38<54:53:59, 17.81s/it]

 31%|███       | 5007/16104 [23:20:59<57:52:31, 18.78s/it]


 31%|███       | 5009/16104 [23:21:34<54:13:04, 17.59s/it]
{'loss': 0.6561, 'learning_rate': 1.6136695884595324e-06, 'rewards/chosen': -0.2728002667427063, 'rewards/rejected': -0.5485261082649231, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2757258415222168, 'policy_logps/rejected': -347.4053955078125, 'policy_logps/chosen': -373.6034240722656, 'referece_logps/rejected': -341.92010498046875, 'referece_logps/chosen': -370.8753967285156, 'logits/rejected': 0.1683758944272995, 'logits/chosen': 0.004946529865264893, 'epoch': 1.87}


 31%|███       | 5011/16104 [23:22:04<48:53:02, 15.86s/it]

 31%|███       | 5012/16104 [23:22:24<53:00:57, 17.21s/it]
{'loss': 0.5618, 'learning_rate': 1.6131930711852101e-06, 'rewards/chosen': -0.3070114552974701, 'rewards/rejected': -0.5067772269248962, 'rewards/accuracies': 0.625, 'rewards/margins': 0.19976578652858734, 'policy_logps/rejected': -467.57879638671875, 'policy_logps/chosen': -377.0247802734375, 'referece_logps/rejected': -462.5110168457031, 'referece_logps/chosen': -373.95465087890625, 'logits/rejected': -0.0251486673951149, 'logits/chosen': -0.09455166757106781, 'epoch': 1.87}

 31%|███       | 5013/16104 [23:22:43<54:44:05, 17.77s/it]

 31%|███       | 5014/16104 [23:23:03<56:09:11, 18.23s/it]

 31%|███       | 5015/16104 [23:23:13<49:19:25, 16.01s/it]

 31%|███       | 5016/16104 [23:23:33<52:53:24, 17.17s/it]


 31%|███       | 5018/16104 [23:24:08<53:50:46, 17.49s/it]
{'loss': 0.5159, 'learning_rate': 1.6122393670817922e-06, 'rewards/chosen': -0.36215856671333313, 'rewards/rejected': -1.6049991846084595, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2428405284881592, 'policy_logps/rejected': -296.5783386230469, 'policy_logps/chosen': -386.23199462890625, 'referece_logps/rejected': -280.5283508300781, 'referece_logps/chosen': -382.6103820800781, 'logits/rejected': 0.21819156408309937, 'logits/chosen': 0.26310092210769653, 'epoch': 1.87}


 31%|███       | 5020/16104 [23:24:52<60:53:49, 19.78s/it]

 31%|███       | 5021/16104 [23:25:08<57:16:05, 18.60s/it]
{'loss': 0.5185, 'learning_rate': 1.6117621805999073e-06, 'rewards/chosen': -0.30891135334968567, 'rewards/rejected': -1.0436886548995972, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7347772121429443, 'policy_logps/rejected': -384.53778076171875, 'policy_logps/chosen': -402.4218444824219, 'referece_logps/rejected': -374.1008605957031, 'referece_logps/chosen': -399.3327331542969, 'logits/rejected': 0.11594415456056595, 'logits/chosen': 0.12114572525024414, 'epoch': 1.87}


 31%|███       | 5023/16104 [23:25:40<53:14:33, 17.30s/it]
{'loss': 0.5922, 'learning_rate': 1.6114439325335673e-06, 'rewards/chosen': -0.22613440454006195, 'rewards/rejected': -0.48852843046188354, 'rewards/accuracies': 0.625, 'rewards/margins': 0.262393981218338, 'policy_logps/rejected': -345.778076171875, 'policy_logps/chosen': -295.9095153808594, 'referece_logps/rejected': -340.892822265625, 'referece_logps/chosen': -293.6481628417969, 'logits/rejected': 0.17111486196517944, 'logits/chosen': 0.2170848548412323, 'epoch': 1.87}

 31%|███       | 5024/16104 [23:25:56<51:23:14, 16.70s/it]


 31%|███       | 5026/16104 [23:26:26<47:55:47, 15.58s/it]
{'loss': 0.5413, 'learning_rate': 1.6109663749451695e-06, 'rewards/chosen': 0.08280639350414276, 'rewards/rejected': -0.32599636912345886, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4088028073310852, 'policy_logps/rejected': -397.3480529785156, 'policy_logps/chosen': -369.6142578125, 'referece_logps/rejected': -394.0880432128906, 'referece_logps/chosen': -370.44232177734375, 'logits/rejected': -0.8085533976554871, 'logits/chosen': -0.837369441986084, 'epoch': 1.87}

 31%|███       | 5027/16104 [23:26:39<45:05:01, 14.65s/it]

 31%|███       | 5028/16104 [23:26:56<47:25:59, 15.42s/it]


 31%|███       | 5030/16104 [23:27:21<42:48:21, 13.92s/it]
{'loss': 0.5421, 'learning_rate': 1.6103292855185217e-06, 'rewards/chosen': -0.42799219489097595, 'rewards/rejected': -1.2751010656356812, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8471088409423828, 'policy_logps/rejected': -487.3758544921875, 'policy_logps/chosen': -349.31903076171875, 'referece_logps/rejected': -474.6248474121094, 'referece_logps/chosen': -345.03912353515625, 'logits/rejected': -0.25771063566207886, 'logits/chosen': -0.23662793636322021, 'epoch': 1.87}

 31%|███       | 5031/16104 [23:27:42<49:33:44, 16.11s/it]

 31%|███       | 5032/16104 [23:27:54<45:59:53, 14.96s/it]

 31%|███▏      | 5033/16104 [23:28:14<50:24:58, 16.39s/it]

 31%|███▏      | 5034/16104 [23:28:31<51:18:16, 16.68s/it]

 31%|███▏      | 5035/16104 [23:28:45<48:35:18, 15.80s/it]

 31%|███▏      | 5036/16104 [23:28:57<45:25:10, 14.77s/it]


 31%|███▏      | 5038/16104 [23:29:36<52:53:39, 17.21s/it]
{'loss': 0.4549, 'learning_rate': 1.6090539220102657e-06, 'rewards/chosen': 0.05674838274717331, 'rewards/rejected': -0.9027937650680542, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9595420956611633, 'policy_logps/rejected': -343.84210205078125, 'policy_logps/chosen': -470.46258544921875, 'referece_logps/rejected': -334.81414794921875, 'referece_logps/chosen': -471.03009033203125, 'logits/rejected': -0.6003875136375427, 'logits/chosen': -0.5976975560188293, 'epoch': 1.88}

 31%|███▏      | 5039/16104 [23:29:56<55:19:17, 18.00s/it]

 31%|███▏      | 5040/16104 [23:30:17<58:03:33, 18.89s/it]


 31%|███▏      | 5042/16104 [23:30:57<59:50:22, 19.47s/it]
{'loss': 0.3935, 'learning_rate': 1.608415648754109e-06, 'rewards/chosen': -0.657034158706665, 'rewards/rejected': -1.4950041770935059, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8379701375961304, 'policy_logps/rejected': -380.2679138183594, 'policy_logps/chosen': -330.03936767578125, 'referece_logps/rejected': -365.3179016113281, 'referece_logps/chosen': -323.4690246582031, 'logits/rejected': -0.6281161308288574, 'logits/chosen': -0.4370300769805908, 'epoch': 1.88}


 31%|███▏      | 5044/16104 [23:31:29<53:47:33, 17.51s/it]
{'loss': 0.4068, 'learning_rate': 1.6080963644312165e-06, 'rewards/chosen': -0.5693727731704712, 'rewards/rejected': -1.334230899810791, 'rewards/accuracies': 0.75, 'rewards/margins': 0.764858067035675, 'policy_logps/rejected': -454.24163818359375, 'policy_logps/chosen': -422.28857421875, 'referece_logps/rejected': -440.89935302734375, 'referece_logps/chosen': -416.5948486328125, 'logits/rejected': 0.41676682233810425, 'logits/chosen': 0.4717451333999634, 'epoch': 1.88}

 31%|███▏      | 5045/16104 [23:31:44<51:33:41, 16.78s/it]


 31%|███▏      | 5047/16104 [23:32:21<54:09:13, 17.63s/it]
{'loss': 0.4204, 'learning_rate': 1.6076172534736556e-06, 'rewards/chosen': -0.2509250342845917, 'rewards/rejected': -1.8173776865005493, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5664526224136353, 'policy_logps/rejected': -534.3324584960938, 'policy_logps/chosen': -421.0086669921875, 'referece_logps/rejected': -516.1586303710938, 'referece_logps/chosen': -418.4993896484375, 'logits/rejected': 0.5898733139038086, 'logits/chosen': 0.8035356998443604, 'epoch': 1.88}

 31%|███▏      | 5048/16104 [23:32:38<54:04:41, 17.61s/it]


 31%|███▏      | 5050/16104 [23:33:07<47:55:07, 15.61s/it]

 31%|███▏      | 5051/16104 [23:33:25<50:15:34, 16.37s/it]
{'loss': 0.492, 'learning_rate': 1.6069780947849126e-06, 'rewards/chosen': -0.007305033504962921, 'rewards/rejected': -0.7793383002281189, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7720332145690918, 'policy_logps/rejected': -378.630126953125, 'policy_logps/chosen': -470.8599853515625, 'referece_logps/rejected': -370.83673095703125, 'referece_logps/chosen': -470.78692626953125, 'logits/rejected': -0.2562524378299713, 'logits/chosen': -0.23717749118804932, 'epoch': 1.88}

 31%|███▏      | 5052/16104 [23:33:44<53:05:38, 17.29s/it]

 31%|███▏      | 5053/16104 [23:34:06<57:01:51, 18.58s/it]


 31%|███▏      | 5055/16104 [23:34:29<45:49:07, 14.93s/it]

 31%|███▏      | 5056/16104 [23:34:49<50:01:07, 16.30s/it]
{'loss': 0.4873, 'learning_rate': 1.6061785940222046e-06, 'rewards/chosen': -0.2697872221469879, 'rewards/rejected': -1.4446396827697754, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1748523712158203, 'policy_logps/rejected': -363.0574951171875, 'policy_logps/chosen': -577.9490966796875, 'referece_logps/rejected': -348.611083984375, 'referece_logps/chosen': -575.251220703125, 'logits/rejected': -0.587297260761261, 'logits/chosen': -0.73503178358078, 'epoch': 1.88}


 31%|███▏      | 5058/16104 [23:35:27<54:22:55, 17.72s/it]
{'loss': 0.516, 'learning_rate': 1.605858622024796e-06, 'rewards/chosen': -0.5361531972885132, 'rewards/rejected': -1.6598865985870361, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1237332820892334, 'policy_logps/rejected': -333.7636413574219, 'policy_logps/chosen': -324.80474853515625, 'referece_logps/rejected': -317.1647644042969, 'referece_logps/chosen': -319.4432373046875, 'logits/rejected': -0.05919675529003143, 'logits/chosen': -0.05670700967311859, 'epoch': 1.88}

 31%|███▏      | 5059/16104 [23:35:39<48:51:12, 15.92s/it]


 31%|███▏      | 5061/16104 [23:36:13<50:45:00, 16.54s/it]

 31%|███▏      | 5062/16104 [23:36:29<50:12:22, 16.37s/it]
{'loss': 0.491, 'learning_rate': 1.6052183839850222e-06, 'rewards/chosen': -0.6044162511825562, 'rewards/rejected': -0.8568168878555298, 'rewards/accuracies': 0.75, 'rewards/margins': 0.25240057706832886, 'policy_logps/rejected': -475.5184020996094, 'policy_logps/chosen': -446.78125, 'referece_logps/rejected': -466.95025634765625, 'referece_logps/chosen': -440.737060546875, 'logits/rejected': -0.3054036796092987, 'logits/chosen': -0.3876323103904724, 'epoch': 1.89}

 31%|███▏      | 5063/16104 [23:36:42<46:49:23, 15.27s/it]

 31%|███▏      | 5064/16104 [23:36:54<43:36:03, 14.22s/it]

 31%|███▏      | 5065/16104 [23:37:07<42:44:47, 13.94s/it]

 31%|███▏      | 5066/16104 [23:37:22<44:14:48, 14.43s/it]

 31%|███▏      | 5067/16104 [23:37:41<47:56:18, 15.64s/it]


 31%|███▏      | 5069/16104 [23:38:13<49:23:31, 16.11s/it]
{'loss': 0.4139, 'learning_rate': 1.6040970251015846e-06, 'rewards/chosen': -0.558764636516571, 'rewards/rejected': -1.2288029193878174, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6700383424758911, 'policy_logps/rejected': -393.8479309082031, 'policy_logps/chosen': -349.4481201171875, 'referece_logps/rejected': -381.5599060058594, 'referece_logps/chosen': -343.8604736328125, 'logits/rejected': -0.0751446783542633, 'logits/chosen': -0.13807553052902222, 'epoch': 1.89}


 31%|███▏      | 5071/16104 [23:38:43<48:40:28, 15.88s/it]
{'loss': 0.5501, 'learning_rate': 1.6037764168207239e-06, 'rewards/chosen': -0.1824125200510025, 'rewards/rejected': -0.5293985605239868, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3469860851764679, 'policy_logps/rejected': -281.04791259765625, 'policy_logps/chosen': -327.41632080078125, 'referece_logps/rejected': -275.7539367675781, 'referece_logps/chosen': -325.5921936035156, 'logits/rejected': -0.8210137486457825, 'logits/chosen': -0.8302470445632935, 'epoch': 1.89}


 32%|███▏      | 5073/16104 [23:39:13<47:20:34, 15.45s/it]
{'loss': 0.4314, 'learning_rate': 1.6034557108445302e-06, 'rewards/chosen': 0.061085715889930725, 'rewards/rejected': -1.002686858177185, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0637723207473755, 'policy_logps/rejected': -440.5704040527344, 'policy_logps/chosen': -685.1458740234375, 'referece_logps/rejected': -430.5435485839844, 'referece_logps/chosen': -685.7567138671875, 'logits/rejected': 0.22660478949546814, 'logits/chosen': 0.23368224501609802, 'epoch': 1.89}

 32%|███▏      | 5074/16104 [23:39:32<50:10:48, 16.38s/it]

 32%|███▏      | 5075/16104 [23:39:52<53:10:03, 17.35s/it]

 32%|███▏      | 5076/16104 [23:40:06<50:19:35, 16.43s/it]


 32%|███▏      | 5078/16104 [23:40:41<52:28:17, 17.13s/it]

 32%|███▏      | 5079/16104 [23:40:57<51:13:30, 16.73s/it]

 32%|███▏      | 5080/16104 [23:41:15<52:34:35, 17.17s/it]
{'loss': 0.4318, 'learning_rate': 1.602332471326446e-06, 'rewards/chosen': -0.38736629486083984, 'rewards/rejected': -0.6390422582626343, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2516759932041168, 'policy_logps/rejected': -312.5189208984375, 'policy_logps/chosen': -476.66461181640625, 'referece_logps/rejected': -306.12847900390625, 'referece_logps/chosen': -472.7909240722656, 'logits/rejected': -0.5747637748718262, 'logits/chosen': -0.6851545572280884, 'epoch': 1.89}

 32%|███▏      | 5081/16104 [23:41:28<48:02:54, 15.69s/it]

 32%|███▏      | 5082/16104 [23:41:44<48:20:56, 15.79s/it]


 32%|███▏      | 5084/16104 [23:42:21<53:02:23, 17.33s/it]
{'loss': 0.5057, 'learning_rate': 1.601690083991129e-06, 'rewards/chosen': -0.05538690462708473, 'rewards/rejected': -0.7245761156082153, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6691892147064209, 'policy_logps/rejected': -313.0111389160156, 'policy_logps/chosen': -378.4178466796875, 'referece_logps/rejected': -305.7654113769531, 'referece_logps/chosen': -377.8639831542969, 'logits/rejected': -0.10189242660999298, 'logits/chosen': 0.11492984741926193, 'epoch': 1.89}


 32%|███▏      | 5086/16104 [23:42:57<53:42:43, 17.55s/it]
{'loss': 0.4978, 'learning_rate': 1.6013687442608569e-06, 'rewards/chosen': -0.4241556227207184, 'rewards/rejected': -1.2023401260375977, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7781845331192017, 'policy_logps/rejected': -280.4677734375, 'policy_logps/chosen': -316.3602294921875, 'referece_logps/rejected': -268.44439697265625, 'referece_logps/chosen': -312.11865234375, 'logits/rejected': -0.5014236569404602, 'logits/chosen': -0.5029168725013733, 'epoch': 1.89}

 32%|███▏      | 5087/16104 [23:43:19<57:18:12, 18.72s/it]

 32%|███▏      | 5088/16104 [23:43:43<62:15:06, 20.34s/it]


 32%|███▏      | 5090/16104 [23:44:13<54:51:00, 17.93s/it]
{'loss': 0.5197, 'learning_rate': 1.6007257729350597e-06, 'rewards/chosen': 0.20099583268165588, 'rewards/rejected': -0.6289802193641663, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8299760818481445, 'policy_logps/rejected': -698.8448486328125, 'policy_logps/chosen': -462.2403869628906, 'referece_logps/rejected': -692.5550537109375, 'referece_logps/chosen': -464.2503967285156, 'logits/rejected': -0.17638538777828217, 'logits/chosen': -0.20773190259933472, 'epoch': 1.9}

 32%|███▏      | 5091/16104 [23:44:24<48:12:19, 15.76s/it]

 32%|███▏      | 5092/16104 [23:44:44<52:26:35, 17.14s/it]

 32%|███▏      | 5093/16104 [23:45:06<56:51:29, 18.59s/it]

 32%|███▏      | 5094/16104 [23:45:19<50:57:07, 16.66s/it]


 32%|███▏      | 5096/16104 [23:45:48<46:41:54, 15.27s/it]
{'loss': 0.5726, 'learning_rate': 1.5997605870636312e-06, 'rewards/chosen': -0.7536758780479431, 'rewards/rejected': -1.2069514989852905, 'rewards/accuracies': 0.625, 'rewards/margins': 0.45327576994895935, 'policy_logps/rejected': -322.0878601074219, 'policy_logps/chosen': -451.2339782714844, 'referece_logps/rejected': -310.0183410644531, 'referece_logps/chosen': -443.6972351074219, 'logits/rejected': -0.22451457381248474, 'logits/chosen': -0.05679786950349808, 'epoch': 1.9}

 32%|███▏      | 5097/16104 [23:46:05<48:36:42, 15.90s/it]

 32%|███▏      | 5098/16104 [23:46:18<45:44:42, 14.96s/it]

 32%|███▏      | 5099/16104 [23:46:40<51:48:49, 16.95s/it]

 32%|███▏      | 5100/16104 [23:46:53<48:28:39, 15.86s/it]

 32%|███▏      | 5101/16104 [23:47:06<46:19:35, 15.16s/it]

 32%|███▏      | 5102/16104 [23:47:17<42:18:37, 13.84s/it]

 32%|███▏      | 5103/16104 [23:47:39<49:14:53, 16.12s/it]

 32%|███▏      | 5104/16104 [23:47:56<50:11:25, 16.43s/it]

 32%|███▏      | 5105/16104 [23:48:07<45:35:49, 14.92s/it]

 32%|███▏      | 5106/16104 [23:48:24<47:12:22, 15.45s/it]

 32%|███▏      | 5107/16104 [23:48:34<42:42:12, 13.98s/it]

 32%|███▏      | 5108/16104 [23:48:51<45:13:05, 14.80s/it]


 32%|███▏      | 5110/16104 [23:49:20<43:39:42, 14.30s/it]
{'loss': 0.4799, 'learning_rate': 1.5975050925350777e-06, 'rewards/chosen': 0.1355815827846527, 'rewards/rejected': -0.6288400888442993, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7644217014312744, 'policy_logps/rejected': -260.8736267089844, 'policy_logps/chosen': -446.741455078125, 'referece_logps/rejected': -254.58523559570312, 'referece_logps/chosen': -448.0972900390625, 'logits/rejected': 0.21344688534736633, 'logits/chosen': 0.053308889269828796, 'epoch': 1.9}

 32%|███▏      | 5111/16104 [23:49:31<40:27:34, 13.25s/it]

 32%|███▏      | 5112/16104 [23:49:42<38:09:20, 12.50s/it]

 32%|███▏      | 5113/16104 [23:49:54<37:39:04, 12.33s/it]

 32%|███▏      | 5114/16104 [23:50:16<46:52:25, 15.35s/it]

 32%|███▏      | 5115/16104 [23:50:27<43:08:07, 14.13s/it]

 32%|███▏      | 5116/16104 [23:50:38<40:04:40, 13.13s/it]

 32%|███▏      | 5117/16104 [23:51:00<47:57:10, 15.71s/it]

 32%|███▏      | 5118/16104 [23:51:18<49:51:50, 16.34s/it]

 32%|███▏      | 5119/16104 [23:51:29<45:19:33, 14.85s/it]

 32%|███▏      | 5120/16104 [23:51:46<47:02:34, 15.42s/it]

 32%|███▏      | 5121/16104 [23:52:03<49:00:25, 16.06s/it]

 32%|███▏      | 5122/16104 [23:52:22<51:24:07, 16.85s/it]

 32%|███▏      | 5123/16104 [23:52:42<54:16:52, 17.80s/it]

 32%|███▏      | 5124/16104 [23:53:00<54:08:03, 17.75s/it]

 32%|███▏      | 5125/16104 [23:53:17<54:06:48, 17.74s/it]

 32%|███▏      | 5126/16104 [23:53:30<49:12:44, 16.14s/it]

 32%|███▏      | 5127/16104 [23:53:50<52:41:45, 17.28s/it]

 32%|███▏      | 5128/16104 [23:54:01<47:36:41, 15.62s/it]

 32%|███▏      | 5129/16104 [23:54:21<51:19:07, 16.83s/it]

 32%|███▏      | 5130/16104 [23:54:35<48:17:18, 15.84s/it]

 32%|███▏      | 5131/16104 [23:54:48<45:49:19, 15.03s/it]

 32%|███▏      | 5132/16104 [23:55:06<48:28:22, 15.90s/it]

 32%|███▏      | 5133/16104 [23:55:17<43:51:46, 14.39s/it]

 32%|███▏      | 5134/16104 [23:55:33<45:45:37, 15.02s/it]

 32%|███▏      | 5135/16104 [23:55:47<44:45:08, 14.69s/it]

 32%|███▏      | 5136/16104 [23:56:02<44:49:29, 14.71s/it]

 32%|███▏      | 5137/16104 [23:56:20<48:22:54, 15.88s/it]

 32%|███▏      | 5138/16104 [23:56:38<49:57:35, 16.40s/it]


 32%|███▏      | 5140/16104 [23:57:07<46:42:46, 15.34s/it]
{'loss': 0.5756, 'learning_rate': 1.5926559606771206e-06, 'rewards/chosen': 0.19575142860412598, 'rewards/rejected': -0.1576664298772812, 'rewards/accuracies': 0.875, 'rewards/margins': 0.35341787338256836, 'policy_logps/rejected': -377.771484375, 'policy_logps/chosen': -466.1233215332031, 'referece_logps/rejected': -376.1948547363281, 'referece_logps/chosen': -468.0808410644531, 'logits/rejected': 0.5040452480316162, 'logits/chosen': 0.546419084072113, 'epoch': 1.92}

 32%|███▏      | 5141/16104 [23:57:26<50:29:52, 16.58s/it]

 32%|███▏      | 5142/16104 [23:57:43<50:22:23, 16.54s/it]

 32%|███▏      | 5143/16104 [23:57:59<50:04:17, 16.45s/it]

 32%|███▏      | 5144/16104 [23:58:14<49:26:40, 16.24s/it]

 32%|███▏      | 5145/16104 [23:58:34<52:24:30, 17.22s/it]

 32%|███▏      | 5146/16104 [23:58:48<49:35:52, 16.29s/it]

 32%|███▏      | 5147/16104 [23:59:09<53:37:10, 17.62s/it]

 32%|███▏      | 5148/16104 [23:59:29<55:53:25, 18.36s/it]

 32%|███▏      | 5149/16104 [23:59:48<56:58:25, 18.72s/it]

 32%|███▏      | 5150/16104 [24:00:02<52:01:27, 17.10s/it]

 32%|███▏      | 5151/16104 [24:00:16<49:06:58, 16.14s/it]

 32%|███▏      | 5152/16104 [24:00:33<50:18:38, 16.54s/it]

 32%|███▏      | 5153/16104 [24:00:50<50:39:20, 16.65s/it]

 32%|███▏      | 5154/16104 [24:01:01<45:10:53, 14.85s/it]

 32%|███▏      | 5155/16104 [24:01:14<44:10:06, 14.52s/it]

 32%|███▏      | 5156/16104 [24:01:31<46:04:45, 15.15s/it]

 32%|███▏      | 5157/16104 [24:01:44<44:03:04, 14.49s/it]

 32%|███▏      | 5158/16104 [24:02:05<49:34:22, 16.30s/it]

 32%|███▏      | 5159/16104 [24:02:26<54:00:06, 17.76s/it]

 32%|███▏      | 5160/16104 [24:02:38<49:04:28, 16.14s/it]

 32%|███▏      | 5161/16104 [24:02:54<48:27:47, 15.94s/it]

 32%|███▏      | 5162/16104 [24:03:13<51:23:15, 16.91s/it]

 32%|███▏      | 5163/16104 [24:03:30<51:59:28, 17.11s/it]


 32%|███▏      | 5165/16104 [24:04:13<59:08:55, 19.47s/it]

 32%|███▏      | 5166/16104 [24:04:28<54:27:28, 17.92s/it]

 32%|███▏      | 5167/16104 [24:04:42<51:16:30, 16.88s/it]

 32%|███▏      | 5168/16104 [24:04:53<46:04:13, 15.17s/it]

 32%|███▏      | 5169/16104 [24:05:13<50:38:42, 16.67s/it]

 32%|███▏      | 5170/16104 [24:05:31<51:28:42, 16.95s/it]

 32%|███▏      | 5171/16104 [24:05:49<52:28:12, 17.28s/it]

 32%|███▏      | 5172/16104 [24:06:06<52:12:52, 17.19s/it]

 32%|███▏      | 5173/16104 [24:06:23<51:36:33, 17.00s/it]

 32%|███▏      | 5174/16104 [24:06:35<47:51:16, 15.76s/it]

 32%|███▏      | 5175/16104 [24:06:46<43:20:28, 14.28s/it]

 32%|███▏      | 5176/16104 [24:07:03<45:51:42, 15.11s/it]

 32%|███▏      | 5177/16104 [24:07:24<50:36:28, 16.67s/it]

 32%|███▏      | 5178/16104 [24:07:36<46:32:45, 15.34s/it]

 32%|███▏      | 5179/16104 [24:07:53<48:02:16, 15.83s/it]

 32%|███▏      | 5180/16104 [24:08:04<43:22:05, 14.29s/it]

 32%|███▏      | 5181/16104 [24:08:27<51:35:34, 17.00s/it]

 32%|███▏      | 5182/16104 [24:08:46<53:56:06, 17.78s/it]

 32%|███▏      | 5183/16104 [24:09:00<49:46:53, 16.41s/it]

 32%|███▏      | 5184/16104 [24:09:13<46:37:25, 15.37s/it]

 32%|███▏      | 5185/16104 [24:09:33<50:51:15, 16.77s/it]

 32%|███▏      | 5186/16104 [24:09:50<51:15:01, 16.90s/it]

 32%|███▏      | 5187/16104 [24:10:04<48:45:08, 16.08s/it]

 32%|███▏      | 5188/16104 [24:10:24<52:15:06, 17.23s/it]

 32%|███▏      | 5189/16104 [24:10:39<49:53:52, 16.46s/it]

 32%|███▏      | 5190/16104 [24:11:00<54:26:37, 17.96s/it]

 32%|███▏      | 5191/16104 [24:11:17<53:27:19, 17.63s/it]

 32%|███▏      | 5192/16104 [24:11:34<52:35:28, 17.35s/it]

 32%|███▏      | 5193/16104 [24:11:50<51:51:08, 17.11s/it]

 32%|███▏      | 5194/16104 [24:12:09<53:01:41, 17.50s/it]

 32%|███▏      | 5195/16104 [24:12:23<50:13:49, 16.58s/it]

 32%|███▏      | 5196/16104 [24:12:38<49:00:55, 16.18s/it]

 32%|███▏      | 5197/16104 [24:12:54<48:52:22, 16.13s/it]

 32%|███▏      | 5198/16104 [24:13:10<48:39:50, 16.06s/it]

 32%|███▏      | 5199/16104 [24:13:27<48:55:04, 16.15s/it]

 32%|███▏      | 5200/16104 [24:13:37<44:08:10, 14.57s/it]
{'loss': 0.5472, 'learning_rate': 1.5828931447065591e-06, 'rewards/chosen': 0.4709951877593994, 'rewards/rejected': -0.3435390591621399, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8145342469215393, 'policy_logps/rejected': -429.163818359375, 'policy_logps/chosen': -415.74273681640625, 'referece_logps/rejected': -425.7283935546875, 'referece_logps/chosen': -420.45269775390625, 'logits/rejected': -0.19394096732139587, 'logits/chosen': -0.020892955362796783, 'epoch': 1.94}


 32%|███▏      | 5202/16104 [24:14:10<47:43:56, 15.76s/it]

 32%|███▏      | 5203/16104 [24:14:22<44:14:49, 14.61s/it]
{'loss': 0.5848, 'learning_rate': 1.5824027638422072e-06, 'rewards/chosen': -0.08183050900697708, 'rewards/rejected': -0.9447180032730103, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8628875017166138, 'policy_logps/rejected': -403.6512145996094, 'policy_logps/chosen': -416.4300231933594, 'referece_logps/rejected': -394.20404052734375, 'referece_logps/chosen': -415.6116943359375, 'logits/rejected': -0.3766319155693054, 'logits/chosen': -0.36201345920562744, 'epoch': 1.94}

 32%|███▏      | 5204/16104 [24:14:34<41:35:35, 13.74s/it]


 32%|███▏      | 5206/16104 [24:15:09<46:10:41, 15.25s/it]
{'loss': 0.6224, 'learning_rate': 1.5819121709447813e-06, 'rewards/chosen': -0.6805169582366943, 'rewards/rejected': -1.2229101657867432, 'rewards/accuracies': 0.5, 'rewards/margins': 0.542393147945404, 'policy_logps/rejected': -428.1761474609375, 'policy_logps/chosen': -411.8545227050781, 'referece_logps/rejected': -415.9470520019531, 'referece_logps/chosen': -405.0493469238281, 'logits/rejected': -0.7508316040039062, 'logits/chosen': -0.6737380027770996, 'epoch': 1.94}


 32%|███▏      | 5208/16104 [24:15:34<41:55:10, 13.85s/it]

 32%|███▏      | 5209/16104 [24:15:46<40:15:12, 13.30s/it]

 32%|███▏      | 5210/16104 [24:15:59<40:29:34, 13.38s/it]

 32%|███▏      | 5211/16104 [24:16:16<43:20:35, 14.32s/it]

 32%|███▏      | 5212/16104 [24:16:37<49:37:58, 16.40s/it]
{'loss': 0.5082, 'learning_rate': 1.5809303497652168e-06, 'rewards/chosen': -0.4943644404411316, 'rewards/rejected': -1.3370200395584106, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8426554799079895, 'policy_logps/rejected': -269.91265869140625, 'policy_logps/chosen': -376.737548828125, 'referece_logps/rejected': -256.5424499511719, 'referece_logps/chosen': -371.79388427734375, 'logits/rejected': 0.4026556611061096, 'logits/chosen': 0.454382061958313, 'epoch': 1.94}


 32%|███▏      | 5214/16104 [24:16:59<40:54:53, 13.53s/it]
{'loss': 0.5621, 'learning_rate': 1.5806028879707207e-06, 'rewards/chosen': -0.5131770968437195, 'rewards/rejected': -0.9081687927246094, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3949916958808899, 'policy_logps/rejected': -424.22998046875, 'policy_logps/chosen': -416.5574645996094, 'referece_logps/rejected': -415.1483459472656, 'referece_logps/chosen': -411.4256591796875, 'logits/rejected': -1.0304547548294067, 'logits/chosen': -0.945225179195404, 'epoch': 1.94}

 32%|███▏      | 5215/16104 [24:17:12<40:56:38, 13.54s/it]

 32%|███▏      | 5216/16104 [24:17:24<39:33:54, 13.08s/it]


 32%|███▏      | 5218/16104 [24:18:01<47:53:05, 15.84s/it]

 32%|███▏      | 5219/16104 [24:18:23<52:46:02, 17.45s/it]

 32%|███▏      | 5220/16104 [24:18:39<51:42:26, 17.10s/it]

 32%|███▏      | 5221/16104 [24:18:55<50:27:14, 16.69s/it]

 32%|███▏      | 5222/16104 [24:19:11<49:40:39, 16.43s/it]
{'loss': 0.4802, 'learning_rate': 1.579292101865914e-06, 'rewards/chosen': -0.6583439111709595, 'rewards/rejected': -0.6505486369132996, 'rewards/accuracies': 0.375, 'rewards/margins': -0.007795225828886032, 'policy_logps/rejected': -364.1058044433594, 'policy_logps/chosen': -358.93438720703125, 'referece_logps/rejected': -357.600341796875, 'referece_logps/chosen': -352.3509521484375, 'logits/rejected': -0.2957002818584442, 'logits/chosen': -0.3571457266807556, 'epoch': 1.95}

 32%|███▏      | 5223/16104 [24:19:30<52:26:01, 17.35s/it]


 32%|███▏      | 5225/16104 [24:20:09<56:11:19, 18.59s/it]

 32%|███▏      | 5226/16104 [24:20:25<54:03:29, 17.89s/it]

 32%|███▏      | 5227/16104 [24:20:43<53:45:25, 17.79s/it]

 32%|███▏      | 5228/16104 [24:20:59<52:34:00, 17.40s/it]

 32%|███▏      | 5229/16104 [24:21:15<51:08:40, 16.93s/it]

 32%|███▏      | 5230/16104 [24:21:36<54:32:04, 18.05s/it]
{'loss': 0.3378, 'learning_rate': 1.5779798160238726e-06, 'rewards/chosen': -0.09776917845010757, 'rewards/rejected': -1.5412064790725708, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4434372186660767, 'policy_logps/rejected': -366.56109619140625, 'policy_logps/chosen': -343.3055419921875, 'referece_logps/rejected': -351.1490478515625, 'referece_logps/chosen': -342.3278503417969, 'logits/rejected': -0.4530206024646759, 'logits/chosen': -0.4236309230327606, 'epoch': 1.95}

 32%|███▏      | 5231/16104 [24:21:56<56:46:37, 18.80s/it]


 32%|███▏      | 5233/16104 [24:22:29<51:46:05, 17.14s/it]

 33%|███▎      | 5234/16104 [24:22:46<51:28:52, 17.05s/it]

 33%|███▎      | 5235/16104 [24:23:00<49:02:20, 16.24s/it]
{'loss': 0.4386, 'learning_rate': 1.5771588772967058e-06, 'rewards/chosen': -0.0697210356593132, 'rewards/rejected': -0.840559184551239, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7708380818367004, 'policy_logps/rejected': -404.9338073730469, 'policy_logps/chosen': -489.04144287109375, 'referece_logps/rejected': -396.5281982421875, 'referece_logps/chosen': -488.3442687988281, 'logits/rejected': 0.2424471378326416, 'logits/chosen': 0.11215215921401978, 'epoch': 1.95}


 33%|███▎      | 5237/16104 [24:23:34<50:01:46, 16.57s/it]

 33%|███▎      | 5238/16104 [24:23:51<50:57:47, 16.88s/it]

 33%|███▎      | 5239/16104 [24:24:08<50:29:20, 16.73s/it]

 33%|███▎      | 5240/16104 [24:24:27<53:02:19, 17.58s/it]

 33%|███▎      | 5241/16104 [24:24:44<52:13:34, 17.31s/it]

 33%|███▎      | 5242/16104 [24:25:00<50:41:13, 16.80s/it]
{'loss': 0.4478, 'learning_rate': 1.5760085826863572e-06, 'rewards/chosen': -0.48543909192085266, 'rewards/rejected': -1.5632957220077515, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0778565406799316, 'policy_logps/rejected': -302.4356689453125, 'policy_logps/chosen': -393.8443603515625, 'referece_logps/rejected': -286.8027038574219, 'referece_logps/chosen': -388.989990234375, 'logits/rejected': -0.15110976994037628, 'logits/chosen': -0.08621283620595932, 'epoch': 1.95}


 33%|███▎      | 5244/16104 [24:25:27<46:51:54, 15.54s/it]

 33%|███▎      | 5245/16104 [24:25:49<52:25:38, 17.38s/it]
{'loss': 0.3728, 'learning_rate': 1.575515249640326e-06, 'rewards/chosen': -0.06457653641700745, 'rewards/rejected': -1.0455026626586914, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9809260964393616, 'policy_logps/rejected': -526.742431640625, 'policy_logps/chosen': -488.4602355957031, 'referece_logps/rejected': -516.2874145507812, 'referece_logps/chosen': -487.8144226074219, 'logits/rejected': 0.16500324010849, 'logits/chosen': 0.18918319046497345, 'epoch': 1.95}

 33%|███▎      | 5246/16104 [24:26:07<52:48:36, 17.51s/it]


 33%|███▎      | 5248/16104 [24:26:44<54:28:12, 18.06s/it]

 33%|███▎      | 5249/16104 [24:26:56<48:52:32, 16.21s/it]
{'loss': 0.4721, 'learning_rate': 1.5748571463480161e-06, 'rewards/chosen': -0.6149316430091858, 'rewards/rejected': -1.064624309539795, 'rewards/accuracies': 0.5, 'rewards/margins': 0.44969266653060913, 'policy_logps/rejected': -336.0625, 'policy_logps/chosen': -448.482666015625, 'referece_logps/rejected': -325.416259765625, 'referece_logps/chosen': -442.3333740234375, 'logits/rejected': -0.42751532793045044, 'logits/chosen': -0.4549422264099121, 'epoch': 1.96}


 33%|███▎      | 5251/16104 [24:27:24<46:13:01, 15.33s/it]
{'loss': 0.5027, 'learning_rate': 1.574527955151253e-06, 'rewards/chosen': -0.09263535588979721, 'rewards/rejected': -1.8395130634307861, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7468777894973755, 'policy_logps/rejected': -423.0301513671875, 'policy_logps/chosen': -380.5633239746094, 'referece_logps/rejected': -404.635009765625, 'referece_logps/chosen': -379.636962890625, 'logits/rejected': 0.14542019367218018, 'logits/chosen': 0.11784441024065018, 'epoch': 1.96}


 33%|███▎      | 5253/16104 [24:28:00<50:28:04, 16.74s/it]

 33%|███▎      | 5254/16104 [24:28:18<51:13:32, 17.00s/it]

 33%|███▎      | 5255/16104 [24:28:38<53:53:54, 17.88s/it]
{'loss': 0.5788, 'learning_rate': 1.5738692939228377e-06, 'rewards/chosen': -0.11115474998950958, 'rewards/rejected': -0.03375731408596039, 'rewards/accuracies': 0.375, 'rewards/margins': -0.0773974359035492, 'policy_logps/rejected': -432.5613708496094, 'policy_logps/chosen': -566.5906982421875, 'referece_logps/rejected': -432.22381591796875, 'referece_logps/chosen': -565.4791259765625, 'logits/rejected': -0.5221965312957764, 'logits/chosen': -0.5579435229301453, 'epoch': 1.96}


 33%|███▎      | 5257/16104 [24:29:10<52:05:42, 17.29s/it]

 33%|███▎      | 5258/16104 [24:29:21<46:48:59, 15.54s/it]

 33%|███▎      | 5259/16104 [24:29:40<50:13:13, 16.67s/it]

 33%|███▎      | 5260/16104 [24:29:54<47:14:20, 15.68s/it]

 33%|███▎      | 5261/16104 [24:30:05<43:34:56, 14.47s/it]

 33%|███▎      | 5262/16104 [24:30:23<45:56:11, 15.25s/it]

 33%|███▎      | 5263/16104 [24:30:34<42:51:52, 14.23s/it]
{'loss': 0.5572, 'learning_rate': 1.5725508576188324e-06, 'rewards/chosen': -0.9991536736488342, 'rewards/rejected': -1.2934284210205078, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2942747175693512, 'policy_logps/rejected': -425.3128662109375, 'policy_logps/chosen': -349.9841613769531, 'referece_logps/rejected': -412.3785705566406, 'referece_logps/chosen': -339.99261474609375, 'logits/rejected': -0.2764783501625061, 'logits/chosen': -0.247124582529068, 'epoch': 1.96}


 33%|███▎      | 5265/16104 [24:31:17<53:34:42, 17.80s/it]

 33%|███▎      | 5266/16104 [24:31:32<51:37:17, 17.15s/it]
{'loss': 0.6073, 'learning_rate': 1.5720560616698422e-06, 'rewards/chosen': -0.45594674348831177, 'rewards/rejected': -0.8710323572158813, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4150856137275696, 'policy_logps/rejected': -287.9492492675781, 'policy_logps/chosen': -381.2008361816406, 'referece_logps/rejected': -279.2389221191406, 'referece_logps/chosen': -376.641357421875, 'logits/rejected': -0.2525002360343933, 'logits/chosen': -0.32442623376846313, 'epoch': 1.96}


 33%|███▎      | 5268/16104 [24:32:01<48:03:28, 15.97s/it]
{'loss': 0.5311, 'learning_rate': 1.5717260819892866e-06, 'rewards/chosen': -0.27723562717437744, 'rewards/rejected': -0.9717061519622803, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6944706439971924, 'policy_logps/rejected': -391.78643798828125, 'policy_logps/chosen': -486.65899658203125, 'referece_logps/rejected': -382.0693664550781, 'referece_logps/chosen': -483.8865966796875, 'logits/rejected': -0.002190530300140381, 'logits/chosen': -0.023692667484283447, 'epoch': 1.96}


 33%|███▎      | 5270/16104 [24:32:25<42:37:29, 14.16s/it]

 33%|███▎      | 5271/16104 [24:32:38<41:07:24, 13.67s/it]

 33%|███▎      | 5272/16104 [24:32:57<45:45:43, 15.21s/it]
{'loss': 0.4797, 'learning_rate': 1.5710658451535029e-06, 'rewards/chosen': -0.34165841341018677, 'rewards/rejected': -1.525640845298767, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1839823722839355, 'policy_logps/rejected': -308.98150634765625, 'policy_logps/chosen': -445.5396728515625, 'referece_logps/rejected': -293.72509765625, 'referece_logps/chosen': -442.123046875, 'logits/rejected': -0.9869486689567566, 'logits/chosen': -0.6710397601127625, 'epoch': 1.96}


 33%|███▎      | 5274/16104 [24:33:32<50:11:39, 16.69s/it]

 33%|███▎      | 5275/16104 [24:33:48<49:22:17, 16.41s/it]

 33%|███▎      | 5276/16104 [24:34:08<52:51:05, 17.57s/it]

 33%|███▎      | 5277/16104 [24:34:24<51:15:54, 17.05s/it]
{'loss': 0.4349, 'learning_rate': 1.570240029394668e-06, 'rewards/chosen': -0.7109395265579224, 'rewards/rejected': -1.5100364685058594, 'rewards/accuracies': 0.875, 'rewards/margins': 0.799096941947937, 'policy_logps/rejected': -376.0456848144531, 'policy_logps/chosen': -331.0278015136719, 'referece_logps/rejected': -360.9452819824219, 'referece_logps/chosen': -323.9184265136719, 'logits/rejected': -0.4739089906215668, 'logits/chosen': -0.5591263175010681, 'epoch': 1.97}


 33%|███▎      | 5279/16104 [24:34:55<47:18:55, 15.74s/it]

 33%|███▎      | 5280/16104 [24:35:14<50:34:47, 16.82s/it]

 33%|███▎      | 5281/16104 [24:35:29<48:32:59, 16.15s/it]

 33%|███▎      | 5282/16104 [24:35:41<44:56:58, 14.95s/it]

 33%|███▎      | 5283/16104 [24:35:54<43:46:51, 14.57s/it]
{'loss': 0.5768, 'learning_rate': 1.569248289339178e-06, 'rewards/chosen': -0.08907148241996765, 'rewards/rejected': -1.0866228342056274, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9975512027740479, 'policy_logps/rejected': -309.5619812011719, 'policy_logps/chosen': -306.9533996582031, 'referece_logps/rejected': -298.6957702636719, 'referece_logps/chosen': -306.0626525878906, 'logits/rejected': -0.5835766792297363, 'logits/chosen': -0.5755653381347656, 'epoch': 1.97}

 33%|███▎      | 5284/16104 [24:36:11<45:58:42, 15.30s/it]


 33%|███▎      | 5286/16104 [24:36:51<53:30:15, 17.81s/it]

 33%|███▎      | 5287/16104 [24:37:02<47:04:23, 15.67s/it]

 33%|███▎      | 5288/16104 [24:37:20<49:35:18, 16.51s/it]

 33%|███▎      | 5289/16104 [24:37:40<52:26:53, 17.46s/it]
{'loss': 0.6074, 'learning_rate': 1.5682557203078573e-06, 'rewards/chosen': 0.20210036635398865, 'rewards/rejected': -0.7064187526702881, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9085191488265991, 'policy_logps/rejected': -427.4647521972656, 'policy_logps/chosen': -357.6302795410156, 'referece_logps/rejected': -420.40057373046875, 'referece_logps/chosen': -359.65130615234375, 'logits/rejected': 0.08008717745542526, 'logits/chosen': 0.06452595442533493, 'epoch': 1.97}

 33%|███▎      | 5290/16104 [24:37:59<54:18:23, 18.08s/it]

 33%|███▎      | 5291/16104 [24:38:13<50:34:38, 16.84s/it]


 33%|███▎      | 5293/16104 [24:38:47<51:46:53, 17.24s/it]
{'loss': 0.5432, 'learning_rate': 1.5675935477919314e-06, 'rewards/chosen': -0.15972575545310974, 'rewards/rejected': -1.5078738927841187, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3481481075286865, 'policy_logps/rejected': -456.1865234375, 'policy_logps/chosen': -365.8742370605469, 'referece_logps/rejected': -441.1078186035156, 'referece_logps/chosen': -364.2769775390625, 'logits/rejected': 0.046276845037937164, 'logits/chosen': 0.003025844693183899, 'epoch': 1.97}

 33%|███▎      | 5294/16104 [24:39:05<52:43:43, 17.56s/it]

 33%|███▎      | 5295/16104 [24:39:19<49:26:56, 16.47s/it]

 33%|███▎      | 5296/16104 [24:39:41<54:35:42, 18.18s/it]


 33%|███▎      | 5298/16104 [24:40:12<49:33:39, 16.51s/it]

 33%|███▎      | 5299/16104 [24:40:29<49:25:59, 16.47s/it]

 33%|███▎      | 5300/16104 [24:40:43<47:51:57, 15.95s/it]
{'loss': 0.4406, 'learning_rate': 1.5664338621804383e-06, 'rewards/chosen': -0.7117977142333984, 'rewards/rejected': -1.1786507368087769, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4668530225753784, 'policy_logps/rejected': -495.2402038574219, 'policy_logps/chosen': -412.9920959472656, 'referece_logps/rejected': -483.4537048339844, 'referece_logps/chosen': -405.8741455078125, 'logits/rejected': -0.1042877584695816, 'logits/chosen': 0.1742781400680542, 'epoch': 1.97}


 33%|███▎      | 5302/16104 [24:41:14<47:16:31, 15.76s/it]
{'loss': 0.6052, 'learning_rate': 1.5661023171144062e-06, 'rewards/chosen': 0.10230541974306107, 'rewards/rejected': -0.011264435946941376, 'rewards/accuracies': 0.375, 'rewards/margins': 0.11356985569000244, 'policy_logps/rejected': -661.7818603515625, 'policy_logps/chosen': -727.7689208984375, 'referece_logps/rejected': -661.6693115234375, 'referece_logps/chosen': -728.7919921875, 'logits/rejected': -0.6288394927978516, 'logits/chosen': -0.39407795667648315, 'epoch': 1.98}


 33%|███▎      | 5304/16104 [24:41:53<53:15:38, 17.75s/it]
{'loss': 0.5248, 'learning_rate': 1.5657706804489792e-06, 'rewards/chosen': -0.44067153334617615, 'rewards/rejected': -1.500016689300537, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0593452453613281, 'policy_logps/rejected': -427.8548278808594, 'policy_logps/chosen': -494.0544128417969, 'referece_logps/rejected': -412.85467529296875, 'referece_logps/chosen': -489.64764404296875, 'logits/rejected': -0.18401217460632324, 'logits/chosen': -0.32388466596603394, 'epoch': 1.98}

 33%|███▎      | 5305/16104 [24:42:12<53:56:46, 17.98s/it]


 33%|███▎      | 5307/16104 [24:42:34<43:31:35, 14.51s/it]

 33%|███▎      | 5308/16104 [24:42:55<49:09:59, 16.39s/it]
{'loss': 0.6337, 'learning_rate': 1.5651071325346003e-06, 'rewards/chosen': -0.165030375123024, 'rewards/rejected': -0.6384332776069641, 'rewards/accuracies': 0.625, 'rewards/margins': 0.47340288758277893, 'policy_logps/rejected': -453.69219970703125, 'policy_logps/chosen': -438.841552734375, 'referece_logps/rejected': -447.3078308105469, 'referece_logps/chosen': -437.1912536621094, 'logits/rejected': 0.3329679071903229, 'logits/chosen': 0.2715868353843689, 'epoch': 1.98}

 33%|███▎      | 5309/16104 [24:43:15<51:55:02, 17.31s/it]

 33%|███▎      | 5310/16104 [24:43:35<54:21:32, 18.13s/it]

 33%|███▎      | 5311/16104 [24:43:51<52:23:37, 17.48s/it]

 33%|███▎      | 5312/16104 [24:44:04<48:39:23, 16.23s/it]

 33%|███▎      | 5313/16104 [24:44:16<45:13:20, 15.09s/it]


 33%|███▎      | 5315/16104 [24:44:41<40:27:19, 13.50s/it]

 33%|███▎      | 5316/16104 [24:44:57<42:48:52, 14.29s/it]

 33%|███▎      | 5317/16104 [24:45:11<42:22:36, 14.14s/it]
{'loss': 0.4696, 'learning_rate': 1.5636128130958369e-06, 'rewards/chosen': 0.7106192111968994, 'rewards/rejected': 0.21846696734428406, 'rewards/accuracies': 0.75, 'rewards/margins': 0.49215221405029297, 'policy_logps/rejected': -526.6842041015625, 'policy_logps/chosen': -538.7447509765625, 'referece_logps/rejected': -528.868896484375, 'referece_logps/chosen': -545.8508911132812, 'logits/rejected': 0.11839459836483002, 'logits/chosen': 0.06017625331878662, 'epoch': 1.98}


 33%|███▎      | 5319/16104 [24:45:41<42:31:29, 14.19s/it]

 33%|███▎      | 5320/16104 [24:46:01<47:42:54, 15.93s/it]

 33%|███▎      | 5321/16104 [24:46:22<52:03:22, 17.38s/it]

 33%|███▎      | 5322/16104 [24:46:39<52:20:49, 17.48s/it]
{'loss': 0.5459, 'learning_rate': 1.5627818373463492e-06, 'rewards/chosen': -0.7716282606124878, 'rewards/rejected': -1.1413615942001343, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3697332739830017, 'policy_logps/rejected': -279.3880310058594, 'policy_logps/chosen': -333.8787841796875, 'referece_logps/rejected': -267.97442626953125, 'referece_logps/chosen': -326.1624755859375, 'logits/rejected': -0.8901354670524597, 'logits/chosen': -0.968999981880188, 'epoch': 1.98}

 33%|███▎      | 5323/16104 [24:46:59<54:02:00, 18.04s/it]

 33%|███▎      | 5324/16104 [24:47:20<56:48:02, 18.97s/it]


 33%|███▎      | 5326/16104 [24:47:51<50:49:53, 16.98s/it]

 33%|███▎      | 5327/16104 [24:48:09<52:05:01, 17.40s/it]

 33%|███▎      | 5328/16104 [24:48:29<54:24:32, 18.18s/it]

 33%|███▎      | 5329/16104 [24:48:49<55:43:17, 18.62s/it]
{'loss': 0.5045, 'learning_rate': 1.5616175153332517e-06, 'rewards/chosen': -0.4274669587612152, 'rewards/rejected': -0.985019862651825, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5575529336929321, 'policy_logps/rejected': -536.928466796875, 'policy_logps/chosen': -455.5989990234375, 'referece_logps/rejected': -527.0782470703125, 'referece_logps/chosen': -451.32427978515625, 'logits/rejected': 0.6234295964241028, 'logits/chosen': 0.6443148255348206, 'epoch': 1.99}

 33%|███▎      | 5330/16104 [24:49:11<58:30:00, 19.55s/it]

 33%|███▎      | 5331/16104 [24:49:30<58:32:09, 19.56s/it]


 33%|███▎      | 5333/16104 [24:50:03<52:52:05, 17.67s/it]

 33%|███▎      | 5334/16104 [24:50:23<54:55:35, 18.36s/it]
{'loss': 0.49, 'learning_rate': 1.5607851750650016e-06, 'rewards/chosen': -0.1411510407924652, 'rewards/rejected': -0.7786784768104553, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6375275254249573, 'policy_logps/rejected': -367.8658447265625, 'policy_logps/chosen': -329.9520568847656, 'referece_logps/rejected': -360.0790710449219, 'referece_logps/chosen': -328.54052734375, 'logits/rejected': 0.18821679055690765, 'logits/chosen': 0.19309455156326294, 'epoch': 1.99}


 33%|███▎      | 5336/16104 [24:50:47<45:19:46, 15.15s/it]

 33%|███▎      | 5337/16104 [24:51:01<44:14:49, 14.79s/it]
{'loss': 0.5373, 'learning_rate': 1.5602854986330454e-06, 'rewards/chosen': 0.01163998618721962, 'rewards/rejected': -0.714829683303833, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7264695763587952, 'policy_logps/rejected': -466.5589599609375, 'policy_logps/chosen': -440.00555419921875, 'referece_logps/rejected': -459.41064453125, 'referece_logps/chosen': -440.1219482421875, 'logits/rejected': 0.15947026014328003, 'logits/chosen': 0.20919232070446014, 'epoch': 1.99}

 33%|███▎      | 5338/16104 [24:51:16<44:36:33, 14.92s/it]


 33%|███▎      | 5340/16104 [24:51:49<45:53:03, 15.35s/it]

 33%|███▎      | 5341/16104 [24:52:07<48:32:47, 16.24s/it]

 33%|███▎      | 5342/16104 [24:52:30<53:44:17, 17.98s/it]
{'loss': 0.412, 'learning_rate': 1.5594522513787012e-06, 'rewards/chosen': 0.3214248716831207, 'rewards/rejected': -1.0534213781356812, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3748462200164795, 'policy_logps/rejected': -429.1939392089844, 'policy_logps/chosen': -680.6881713867188, 'referece_logps/rejected': -418.6597900390625, 'referece_logps/chosen': -683.9024047851562, 'logits/rejected': 0.289718896150589, 'logits/chosen': 0.33042794466018677, 'epoch': 1.99}


 33%|███▎      | 5344/16104 [24:53:00<48:19:23, 16.17s/it]
{'loss': 0.4652, 'learning_rate': 1.5591187940138746e-06, 'rewards/chosen': -0.31803056597709656, 'rewards/rejected': -1.2384830713272095, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9204524755477905, 'policy_logps/rejected': -564.4191284179688, 'policy_logps/chosen': -431.7366638183594, 'referece_logps/rejected': -552.0343017578125, 'referece_logps/chosen': -428.556396484375, 'logits/rejected': -0.9510941505432129, 'logits/chosen': -0.8888847827911377, 'epoch': 1.99}

 33%|███▎      | 5345/16104 [24:53:20<52:27:41, 17.55s/it]


 33%|███▎      | 5347/16104 [24:53:51<48:06:52, 16.10s/it]
{'loss': 0.4789, 'learning_rate': 1.558618438353355e-06, 'rewards/chosen': -0.12080144882202148, 'rewards/rejected': -0.4728972315788269, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3520957827568054, 'policy_logps/rejected': -306.8692321777344, 'policy_logps/chosen': -434.0065612792969, 'referece_logps/rejected': -302.1402893066406, 'referece_logps/chosen': -432.7985534667969, 'logits/rejected': 8.638203144073486e-05, 'logits/chosen': -0.003390863537788391, 'epoch': 1.99}


 33%|███▎      | 5349/16104 [24:54:22<45:52:45, 15.36s/it]
{'loss': 0.4479, 'learning_rate': 1.5582847549162001e-06, 'rewards/chosen': -0.3700498342514038, 'rewards/rejected': -0.8319793343544006, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4619295001029968, 'policy_logps/rejected': -503.8203430175781, 'policy_logps/chosen': -518.8862915039062, 'referece_logps/rejected': -495.5005187988281, 'referece_logps/chosen': -515.185791015625, 'logits/rejected': -0.19858840107917786, 'logits/chosen': -0.12936043739318848, 'epoch': 1.99}

 33%|███▎      | 5350/16104 [24:54:33<42:08:39, 14.11s/it]


 33%|███▎      | 5352/16104 [24:55:10<48:02:46, 16.09s/it]
{'loss': 0.4958, 'learning_rate': 1.5577840604002372e-06, 'rewards/chosen': 0.3626907467842102, 'rewards/rejected': -1.0000314712524414, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3627221584320068, 'policy_logps/rejected': -510.585205078125, 'policy_logps/chosen': -529.1964721679688, 'referece_logps/rejected': -500.5848693847656, 'referece_logps/chosen': -532.8233642578125, 'logits/rejected': 0.3421267867088318, 'logits/chosen': 0.4606732428073883, 'epoch': 1.99}

 33%|███▎      | 5353/16104 [24:55:28<50:22:44, 16.87s/it]


 33%|███▎      | 5355/16104 [24:55:50<41:01:27, 13.74s/it]

 33%|███▎      | 5356/16104 [24:56:06<43:22:45, 14.53s/it]
{'loss': 0.5601, 'learning_rate': 1.5571161518567638e-06, 'rewards/chosen': -0.6069084405899048, 'rewards/rejected': -1.4242222309112549, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8173139095306396, 'policy_logps/rejected': -418.53448486328125, 'policy_logps/chosen': -457.9002380371094, 'referece_logps/rejected': -404.2922668457031, 'referece_logps/chosen': -451.83111572265625, 'logits/rejected': 0.007827267050743103, 'logits/chosen': -0.03324320539832115, 'epoch': 2.0}

 33%|███▎      | 5357/16104 [24:56:17<40:00:12, 13.40s/it]

 33%|███▎      | 5358/16104 [24:56:37<45:37:03, 15.28s/it]

 33%|███▎      | 5359/16104 [24:56:53<46:23:01, 15.54s/it]

 33%|███▎      | 5360/16104 [24:57:05<43:28:13, 14.57s/it]


 33%|███▎      | 5362/16104 [24:57:40<48:30:20, 16.26s/it]

 33%|███▎      | 5363/16104 [24:58:00<51:50:37, 17.38s/it]

 33%|███▎      | 5364/16104 [24:58:18<52:08:44, 17.48s/it]
{'loss': 0.3798, 'learning_rate': 1.555779253457953e-06, 'rewards/chosen': -0.5209476351737976, 'rewards/rejected': -2.0973823070526123, 'rewards/accuracies': 0.875, 'rewards/margins': 1.57643461227417, 'policy_logps/rejected': -431.29058837890625, 'policy_logps/chosen': -554.5148315429688, 'referece_logps/rejected': -410.3167724609375, 'referece_logps/chosen': -549.305419921875, 'logits/rejected': -0.32063621282577515, 'logits/chosen': -0.33758971095085144, 'epoch': 2.0}


 33%|███▎      | 5366/16104 [24:58:50<49:54:45, 16.73s/it]

 33%|███▎      | 5367/16104 [24:59:04<48:08:18, 16.14s/it]

 33%|███▎      | 5368/16104 [24:59:18<45:57:38, 15.41s/it]
{'loss': 0.5115, 'learning_rate': 1.555110264467895e-06, 'rewards/chosen': 0.19429205358028412, 'rewards/rejected': -0.8869173526763916, 'rewards/accuracies': 1.0, 'rewards/margins': 1.081209421157837, 'policy_logps/rejected': -397.87628173828125, 'policy_logps/chosen': -544.3338623046875, 'referece_logps/rejected': -389.0071105957031, 'referece_logps/chosen': -546.2767944335938, 'logits/rejected': 0.3249010443687439, 'logits/chosen': 0.3290787935256958, 'epoch': 2.0}

 33%|███▎      | 5369/16104 [24:59:31<43:37:09, 14.63s/it]


 33%|███▎      | 5371/16104 [25:00:00<43:11:25, 14.49s/it]
{'loss': 0.6105, 'learning_rate': 1.5546082869220673e-06, 'rewards/chosen': 0.13704700767993927, 'rewards/rejected': -0.7903239727020264, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9273709654808044, 'policy_logps/rejected': -345.9486083984375, 'policy_logps/chosen': -396.81591796875, 'referece_logps/rejected': -338.04541015625, 'referece_logps/chosen': -398.1864013671875, 'logits/rejected': -0.18501606583595276, 'logits/chosen': -0.05589954927563667, 'epoch': 2.0}


 33%|███▎      | 5373/16104 [25:00:28<43:27:10, 14.58s/it]
{'loss': 0.509, 'learning_rate': 1.5542735230390936e-06, 'rewards/chosen': -0.13892862200737, 'rewards/rejected': -1.4627994298934937, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3238708972930908, 'policy_logps/rejected': -522.72802734375, 'policy_logps/chosen': -419.6337890625, 'referece_logps/rejected': -508.10009765625, 'referece_logps/chosen': -418.2445373535156, 'logits/rejected': 0.7222435474395752, 'logits/chosen': 0.7562068104743958, 'epoch': 2.0}


 33%|███▎      | 5375/16104 [25:00:50<38:00:52, 12.76s/it]
{'loss': 0.5629, 'learning_rate': 1.5539386694707081e-06, 'rewards/chosen': -0.33583033084869385, 'rewards/rejected': -0.4383338689804077, 'rewards/accuracies': 0.5, 'rewards/margins': 0.10250356793403625, 'policy_logps/rejected': -390.6993408203125, 'policy_logps/chosen': -534.688720703125, 'referece_logps/rejected': -386.31597900390625, 'referece_logps/chosen': -531.3304443359375, 'logits/rejected': -0.5646064281463623, 'logits/chosen': -0.5334886908531189, 'epoch': 2.0}

 33%|███▎      | 5376/16104 [25:01:09<43:02:34, 14.44s/it]


 33%|███▎      | 5378/16104 [25:01:30<37:27:18, 12.57s/it]

 33%|███▎      | 5379/16104 [25:01:50<44:10:20, 14.83s/it]
{'loss': 0.4858, 'learning_rate': 1.5532686934944437e-06, 'rewards/chosen': -0.07738419622182846, 'rewards/rejected': -0.6936006546020508, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6162165403366089, 'policy_logps/rejected': -543.619384765625, 'policy_logps/chosen': -511.73004150390625, 'referece_logps/rejected': -536.6834106445312, 'referece_logps/chosen': -510.9561767578125, 'logits/rejected': -0.18140853941440582, 'logits/chosen': -0.09725334495306015, 'epoch': 2.0}


 33%|███▎      | 5381/16104 [25:02:20<45:08:04, 15.15s/it]

 33%|███▎      | 5382/16104 [25:02:34<44:30:50, 14.95s/it]
{'loss': 0.5889, 'learning_rate': 1.5527659764911224e-06, 'rewards/chosen': -0.22874830663204193, 'rewards/rejected': -1.0961326360702515, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8673843145370483, 'policy_logps/rejected': -499.6131591796875, 'policy_logps/chosen': -492.46636962890625, 'referece_logps/rejected': -488.6518859863281, 'referece_logps/chosen': -490.1788635253906, 'logits/rejected': 0.735936164855957, 'logits/chosen': 0.775402843952179, 'epoch': 2.01}

 33%|███▎      | 5383/16104 [25:02:56<50:10:29, 16.85s/it]

 33%|███▎      | 5384/16104 [25:03:09<46:58:55, 15.78s/it]

 33%|███▎      | 5385/16104 [25:03:25<47:22:35, 15.91s/it]

 33%|███▎      | 5386/16104 [25:03:41<47:22:11, 15.91s/it]


 33%|███▎      | 5388/16104 [25:04:04<40:31:03, 13.61s/it]

 33%|███▎      | 5389/16104 [25:04:17<39:18:30, 13.21s/it]
{'loss': 0.5164, 'learning_rate': 1.5515921878535765e-06, 'rewards/chosen': 0.4002871811389923, 'rewards/rejected': -0.9511669874191284, 'rewards/accuracies': 0.875, 'rewards/margins': 1.351454257965088, 'policy_logps/rejected': -472.30938720703125, 'policy_logps/chosen': -488.3628845214844, 'referece_logps/rejected': -462.7977600097656, 'referece_logps/chosen': -492.3657531738281, 'logits/rejected': 0.43560782074928284, 'logits/chosen': 0.5092914700508118, 'epoch': 2.01}


 33%|███▎      | 5391/16104 [25:04:46<42:33:23, 14.30s/it]
{'loss': 0.4983, 'learning_rate': 1.5512566187536571e-06, 'rewards/chosen': -0.2575151324272156, 'rewards/rejected': -0.8196630477905273, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5621479749679565, 'policy_logps/rejected': -412.69366455078125, 'policy_logps/chosen': -430.9738464355469, 'referece_logps/rejected': -404.4970397949219, 'referece_logps/chosen': -428.398681640625, 'logits/rejected': -0.1688951849937439, 'logits/chosen': -0.23575162887573242, 'epoch': 2.01}

 33%|███▎      | 5392/16104 [25:04:57<39:37:29, 13.32s/it]

 33%|███▎      | 5393/16104 [25:05:17<45:33:51, 15.31s/it]


 34%|███▎      | 5395/16104 [25:05:55<50:44:58, 17.06s/it]
{'loss': 0.3836, 'learning_rate': 1.5505852130163662e-06, 'rewards/chosen': -0.0417197160422802, 'rewards/rejected': -0.7907893061637878, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7490695714950562, 'policy_logps/rejected': -277.98956298828125, 'policy_logps/chosen': -360.2852783203125, 'referece_logps/rejected': -270.0816650390625, 'referece_logps/chosen': -359.8680725097656, 'logits/rejected': -0.43051183223724365, 'logits/chosen': -0.4518550634384155, 'epoch': 2.01}

 34%|███▎      | 5396/16104 [25:06:08<47:16:39, 15.89s/it]


 34%|███▎      | 5398/16104 [25:06:44<50:30:42, 16.99s/it]

 34%|███▎      | 5399/16104 [25:06:57<46:23:56, 15.60s/it]
{'loss': 0.5496, 'learning_rate': 1.5499134509246227e-06, 'rewards/chosen': -0.0627458468079567, 'rewards/rejected': -1.0901844501495361, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0274386405944824, 'policy_logps/rejected': -550.4571533203125, 'policy_logps/chosen': -552.37451171875, 'referece_logps/rejected': -539.5552978515625, 'referece_logps/chosen': -551.7470703125, 'logits/rejected': 0.4473932981491089, 'logits/chosen': 0.5044728517532349, 'epoch': 2.01}


 34%|███▎      | 5401/16104 [25:07:29<45:57:26, 15.46s/it]

 34%|███▎      | 5402/16104 [25:07:50<51:26:07, 17.30s/it]

 34%|███▎      | 5403/16104 [25:08:09<52:06:40, 17.53s/it]
{'loss': 0.4429, 'learning_rate': 1.549241332913211e-06, 'rewards/chosen': -0.4701715409755707, 'rewards/rejected': -1.8072562217712402, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3370846509933472, 'policy_logps/rejected': -370.2720031738281, 'policy_logps/chosen': -340.64117431640625, 'referece_logps/rejected': -352.1994934082031, 'referece_logps/chosen': -335.939453125, 'logits/rejected': -0.1843186914920807, 'logits/chosen': 0.04657511040568352, 'epoch': 2.01}

 34%|███▎      | 5404/16104 [25:08:25<51:15:50, 17.25s/it]

 34%|███▎      | 5405/16104 [25:08:42<50:55:14, 17.13s/it]

 34%|███▎      | 5406/16104 [25:09:04<54:56:05, 18.49s/it]


 34%|███▎      | 5408/16104 [25:09:41<54:58:55, 18.51s/it]
{'loss': 0.4952, 'learning_rate': 1.5484006855496512e-06, 'rewards/chosen': -0.4446258544921875, 'rewards/rejected': -0.6708838939666748, 'rewards/accuracies': 0.5, 'rewards/margins': 0.22625800967216492, 'policy_logps/rejected': -407.478759765625, 'policy_logps/chosen': -363.17510986328125, 'referece_logps/rejected': -400.76995849609375, 'referece_logps/chosen': -358.7288513183594, 'logits/rejected': -0.10455713421106339, 'logits/chosen': -0.11906945705413818, 'epoch': 2.01}


 34%|███▎      | 5410/16104 [25:10:17<53:11:26, 17.91s/it]

 34%|███▎      | 5411/16104 [25:10:37<55:25:38, 18.66s/it]
{'loss': 0.4702, 'learning_rate': 1.5478960308716679e-06, 'rewards/chosen': -0.2752937376499176, 'rewards/rejected': -1.2606407403945923, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9853470325469971, 'policy_logps/rejected': -405.3411560058594, 'policy_logps/chosen': -457.65283203125, 'referece_logps/rejected': -392.7347412109375, 'referece_logps/chosen': -454.89990234375, 'logits/rejected': -0.6383644938468933, 'logits/chosen': -0.35384222865104675, 'epoch': 2.02}

 34%|███▎      | 5412/16104 [25:10:55<55:06:02, 18.55s/it]

 34%|███▎      | 5413/16104 [25:11:16<56:52:13, 19.15s/it]


 34%|███▎      | 5415/16104 [25:11:57<59:34:15, 20.06s/it]

 34%|███▎      | 5416/16104 [25:12:15<57:12:46, 19.27s/it]
{'loss': 0.516, 'learning_rate': 1.5470544965650274e-06, 'rewards/chosen': -0.09960508346557617, 'rewards/rejected': -1.2103954553604126, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1107903718948364, 'policy_logps/rejected': -334.4835205078125, 'policy_logps/chosen': -322.5267639160156, 'referece_logps/rejected': -322.3795471191406, 'referece_logps/chosen': -321.53070068359375, 'logits/rejected': -0.6657241582870483, 'logits/chosen': -0.6945398449897766, 'epoch': 2.02}

 34%|███▎      | 5417/16104 [25:12:31<55:09:02, 18.58s/it]


 34%|███▎      | 5419/16104 [25:12:53<43:20:31, 14.60s/it]
{'loss': 0.4498, 'learning_rate': 1.5465493103746076e-06, 'rewards/chosen': -0.2638385593891144, 'rewards/rejected': -1.2650072574615479, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0011687278747559, 'policy_logps/rejected': -387.7135009765625, 'policy_logps/chosen': -557.6146240234375, 'referece_logps/rejected': -375.0633544921875, 'referece_logps/chosen': -554.9762573242188, 'logits/rejected': 0.7113648056983948, 'logits/chosen': 0.7279982566833496, 'epoch': 2.02}


 34%|███▎      | 5421/16104 [25:13:17<38:53:49, 13.11s/it]
{'loss': 0.4769, 'learning_rate': 1.5462124090251668e-06, 'rewards/chosen': -0.3011927604675293, 'rewards/rejected': -1.3696072101593018, 'rewards/accuracies': 0.875, 'rewards/margins': 1.068414330482483, 'policy_logps/rejected': -453.65130615234375, 'policy_logps/chosen': -413.7987060546875, 'referece_logps/rejected': -439.95526123046875, 'referece_logps/chosen': -410.7867736816406, 'logits/rejected': -0.5062233805656433, 'logits/chosen': -0.8113017678260803, 'epoch': 2.02}

 34%|███▎      | 5422/16104 [25:13:38<45:57:52, 15.49s/it]

 34%|███▎      | 5423/16104 [25:13:59<51:19:49, 17.30s/it]

 34%|███▎      | 5424/16104 [25:14:10<45:20:50, 15.29s/it]

 34%|███▎      | 5425/16104 [25:14:26<45:37:14, 15.38s/it]

 34%|███▎      | 5426/16104 [25:14:42<46:53:01, 15.81s/it]

 34%|███▎      | 5427/16104 [25:15:05<52:49:57, 17.81s/it]

 34%|███▎      | 5428/16104 [25:15:21<50:52:57, 17.16s/it]

 34%|███▎      | 5429/16104 [25:15:33<46:33:08, 15.70s/it]

 34%|███▎      | 5430/16104 [25:15:53<50:29:29, 17.03s/it]

 34%|███▎      | 5431/16104 [25:16:10<50:45:06, 17.12s/it]

 34%|███▎      | 5432/16104 [25:16:28<51:42:10, 17.44s/it]

 34%|███▎      | 5433/16104 [25:16:39<45:43:13, 15.42s/it]

 34%|███▎      | 5434/16104 [25:16:50<41:31:24, 14.01s/it]


 34%|███▍      | 5436/16104 [25:17:11<36:31:16, 12.32s/it]
{'loss': 0.4394, 'learning_rate': 1.5436828355250406e-06, 'rewards/chosen': -0.14207303524017334, 'rewards/rejected': -1.4706059694290161, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3285328149795532, 'policy_logps/rejected': -224.5657501220703, 'policy_logps/chosen': -634.77099609375, 'referece_logps/rejected': -209.8596954345703, 'referece_logps/chosen': -633.3502807617188, 'logits/rejected': -0.13907651603221893, 'logits/chosen': -0.06030839681625366, 'epoch': 2.03}

 34%|███▍      | 5437/16104 [25:17:27<39:10:38, 13.22s/it]

 34%|███▍      | 5438/16104 [25:17:45<43:19:03, 14.62s/it]

 34%|███▍      | 5439/16104 [25:18:05<48:15:33, 16.29s/it]

 34%|███▍      | 5440/16104 [25:18:25<51:45:51, 17.47s/it]

 34%|███▍      | 5441/16104 [25:18:45<54:16:53, 18.33s/it]


 34%|███▍      | 5443/16104 [25:19:22<53:42:48, 18.14s/it]
{'loss': 0.3751, 'learning_rate': 1.5425006730340614e-06, 'rewards/chosen': -0.5300278663635254, 'rewards/rejected': -1.8222397565841675, 'rewards/accuracies': 1.0, 'rewards/margins': 1.292211890220642, 'policy_logps/rejected': -297.6174011230469, 'policy_logps/chosen': -255.56202697753906, 'referece_logps/rejected': -279.3949890136719, 'referece_logps/chosen': -250.2617645263672, 'logits/rejected': 0.0638919547200203, 'logits/chosen': -0.17139576375484467, 'epoch': 2.03}

 34%|███▍      | 5444/16104 [25:19:40<54:01:54, 18.25s/it]

 34%|███▍      | 5445/16104 [25:19:53<49:19:57, 16.66s/it]

 34%|███▍      | 5446/16104 [25:20:11<50:47:54, 17.16s/it]

 34%|███▍      | 5447/16104 [25:20:25<47:33:00, 16.06s/it]

 34%|███▍      | 5448/16104 [25:20:45<50:51:11, 17.18s/it]

 34%|███▍      | 5449/16104 [25:21:04<52:54:26, 17.88s/it]

 34%|███▍      | 5450/16104 [25:21:18<49:23:16, 16.69s/it]

 34%|███▍      | 5451/16104 [25:21:33<47:49:43, 16.16s/it]


 34%|███▍      | 5453/16104 [25:21:56<40:28:46, 13.68s/it]

 34%|███▍      | 5454/16104 [25:22:12<42:38:06, 14.41s/it]
{'loss': 0.5831, 'learning_rate': 1.5406408174555977e-06, 'rewards/chosen': -0.3763394355773926, 'rewards/rejected': -0.6439101696014404, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2675707936286926, 'policy_logps/rejected': -408.5092468261719, 'policy_logps/chosen': -515.39404296875, 'referece_logps/rejected': -402.07012939453125, 'referece_logps/chosen': -511.6306457519531, 'logits/rejected': 0.10655166208744049, 'logits/chosen': -0.21972280740737915, 'epoch': 2.03}

 34%|███▍      | 5455/16104 [25:22:23<39:23:11, 13.31s/it]


 34%|███▍      | 5457/16104 [25:22:50<40:31:40, 13.70s/it]
{'loss': 0.476, 'learning_rate': 1.540133124465278e-06, 'rewards/chosen': 0.1681172251701355, 'rewards/rejected': -1.3016636371612549, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4697808027267456, 'policy_logps/rejected': -488.10186767578125, 'policy_logps/chosen': -393.4968566894531, 'referece_logps/rejected': -475.0851745605469, 'referece_logps/chosen': -395.17803955078125, 'logits/rejected': 0.2552328407764435, 'logits/chosen': 0.3074387013912201, 'epoch': 2.03}

 34%|███▍      | 5458/16104 [25:23:05<41:59:16, 14.20s/it]

 34%|███▍      | 5459/16104 [25:23:17<39:29:29, 13.36s/it]

 34%|███▍      | 5460/16104 [25:23:32<41:24:30, 14.01s/it]

 34%|███▍      | 5461/16104 [25:23:51<46:05:37, 15.59s/it]

 34%|███▍      | 5462/16104 [25:24:10<49:09:41, 16.63s/it]

 34%|███▍      | 5463/16104 [25:24:26<48:22:13, 16.36s/it]

 34%|███▍      | 5464/16104 [25:24:43<49:07:58, 16.62s/it]

 34%|███▍      | 5465/16104 [25:24:57<46:13:43, 15.64s/it]


 34%|███▍      | 5467/16104 [25:25:36<52:12:28, 17.67s/it]
{'loss': 0.4425, 'learning_rate': 1.5384393953287162e-06, 'rewards/chosen': 0.3767387568950653, 'rewards/rejected': -1.2522770166397095, 'rewards/accuracies': 0.875, 'rewards/margins': 1.629015564918518, 'policy_logps/rejected': -547.6609497070312, 'policy_logps/chosen': -506.3931579589844, 'referece_logps/rejected': -535.13818359375, 'referece_logps/chosen': -510.1605529785156, 'logits/rejected': 0.11125621944665909, 'logits/chosen': 0.12067040801048279, 'epoch': 2.04}


 34%|███▍      | 5469/16104 [25:26:00<43:36:08, 14.76s/it]
{'loss': 0.4884, 'learning_rate': 1.5381003879120776e-06, 'rewards/chosen': -0.5165355205535889, 'rewards/rejected': -2.122835159301758, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6062997579574585, 'policy_logps/rejected': -568.5534057617188, 'policy_logps/chosen': -628.540771484375, 'referece_logps/rejected': -547.3250732421875, 'referece_logps/chosen': -623.3754272460938, 'logits/rejected': -0.5119383335113525, 'logits/chosen': -0.4908084273338318, 'epoch': 2.04}

 34%|███▍      | 5470/16104 [25:26:21<48:45:14, 16.51s/it]

 34%|███▍      | 5471/16104 [25:26:36<48:10:39, 16.31s/it]

 34%|███▍      | 5472/16104 [25:26:51<46:48:12, 15.85s/it]

 34%|███▍      | 5473/16104 [25:27:06<46:18:43, 15.68s/it]

 34%|███▍      | 5474/16104 [25:27:27<50:11:38, 17.00s/it]

 34%|███▍      | 5475/16104 [25:27:47<53:05:55, 17.98s/it]

 34%|███▍      | 5476/16104 [25:28:08<56:20:39, 19.09s/it]

 34%|███▍      | 5477/16104 [25:28:24<53:32:19, 18.14s/it]

 34%|███▍      | 5478/16104 [25:28:42<52:40:25, 17.85s/it]

 34%|███▍      | 5479/16104 [25:29:01<54:10:30, 18.36s/it]

 34%|███▍      | 5480/16104 [25:29:23<57:36:18, 19.52s/it]

 34%|███▍      | 5481/16104 [25:29:42<56:23:03, 19.11s/it]

 34%|███▍      | 5482/16104 [25:30:01<56:44:01, 19.23s/it]

 34%|███▍      | 5483/16104 [25:30:17<53:36:12, 18.17s/it]


 34%|███▍      | 5485/16104 [25:30:50<53:11:39, 18.03s/it]
{'loss': 0.4482, 'learning_rate': 1.535385198724262e-06, 'rewards/chosen': -0.2802640199661255, 'rewards/rejected': -1.8725589513778687, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5922949314117432, 'policy_logps/rejected': -420.59527587890625, 'policy_logps/chosen': -452.0739440917969, 'referece_logps/rejected': -401.8697204589844, 'referece_logps/chosen': -449.2712707519531, 'logits/rejected': -0.6243719458580017, 'logits/chosen': -0.6671881675720215, 'epoch': 2.04}


 34%|███▍      | 5487/16104 [25:31:32<57:31:14, 19.50s/it]
{'loss': 0.5076, 'learning_rate': 1.535045409667704e-06, 'rewards/chosen': -0.6981830596923828, 'rewards/rejected': -0.7078555822372437, 'rewards/accuracies': 0.5, 'rewards/margins': 0.009672529995441437, 'policy_logps/rejected': -429.22369384765625, 'policy_logps/chosen': -390.23809814453125, 'referece_logps/rejected': -422.1451416015625, 'referece_logps/chosen': -383.25628662109375, 'logits/rejected': -0.1314801573753357, 'logits/chosen': -0.2605073153972626, 'epoch': 2.04}

 34%|███▍      | 5488/16104 [25:31:56<60:53:54, 20.65s/it]

 34%|███▍      | 5489/16104 [25:32:13<57:40:01, 19.56s/it]


 34%|███▍      | 5491/16104 [25:32:48<53:51:43, 18.27s/it]
{'loss': 0.3755, 'learning_rate': 1.5343655718870853e-06, 'rewards/chosen': -0.6331125497817993, 'rewards/rejected': -1.5451853275299072, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9120727777481079, 'policy_logps/rejected': -366.7584533691406, 'policy_logps/chosen': -440.2994384765625, 'referece_logps/rejected': -351.306640625, 'referece_logps/chosen': -433.9682922363281, 'logits/rejected': -0.38459348678588867, 'logits/chosen': -0.29741141200065613, 'epoch': 2.05}


 34%|███▍      | 5493/16104 [25:33:17<47:43:21, 16.19s/it]
{'loss': 0.4194, 'learning_rate': 1.5340255232730277e-06, 'rewards/chosen': -0.8639075756072998, 'rewards/rejected': -1.8557970523834229, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9918893575668335, 'policy_logps/rejected': -199.38006591796875, 'policy_logps/chosen': -300.3531494140625, 'referece_logps/rejected': -180.82208251953125, 'referece_logps/chosen': -291.71405029296875, 'logits/rejected': 0.29317426681518555, 'logits/chosen': 0.07697227597236633, 'epoch': 2.05}

 34%|███▍      | 5494/16104 [25:33:30<44:57:26, 15.25s/it]

 34%|███▍      | 5495/16104 [25:33:49<48:33:22, 16.48s/it]

 34%|███▍      | 5496/16104 [25:34:09<51:30:35, 17.48s/it]

 34%|███▍      | 5497/16104 [25:34:31<55:26:54, 18.82s/it]

 34%|███▍      | 5498/16104 [25:34:52<57:53:28, 19.65s/it]

 34%|███▍      | 5499/16104 [25:35:08<54:38:57, 18.55s/it]

 34%|███▍      | 5500/16104 [25:35:24<51:54:35, 17.62s/it]

 34%|███▍      | 5501/16104 [25:36:00<68:34:38, 23.28s/it]

 34%|███▍      | 5502/16104 [25:36:13<58:50:55, 19.98s/it]

 34%|███▍      | 5503/16104 [25:36:35<60:56:41, 20.70s/it]


 34%|███▍      | 5505/16104 [25:37:09<54:53:57, 18.65s/it]
{'loss': 0.4135, 'learning_rate': 1.5319834189234862e-06, 'rewards/chosen': -0.29499706625938416, 'rewards/rejected': -2.127096176147461, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8320989608764648, 'policy_logps/rejected': -367.2822570800781, 'policy_logps/chosen': -447.1050109863281, 'referece_logps/rejected': -346.0113220214844, 'referece_logps/chosen': -444.155029296875, 'logits/rejected': -0.4453614056110382, 'logits/chosen': -0.4206199049949646, 'epoch': 2.05}

 34%|███▍      | 5506/16104 [25:37:30<57:03:52, 19.38s/it]

 34%|███▍      | 5507/16104 [25:37:45<53:16:27, 18.10s/it]

 34%|███▍      | 5508/16104 [25:38:01<51:39:32, 17.55s/it]

 34%|███▍      | 5509/16104 [25:38:14<47:48:48, 16.25s/it]


 34%|███▍      | 5511/16104 [25:38:51<51:28:18, 17.49s/it]
{'loss': 0.5359, 'learning_rate': 1.5309612039424637e-06, 'rewards/chosen': 0.07309207320213318, 'rewards/rejected': -0.4137808382511139, 'rewards/accuracies': 0.75, 'rewards/margins': 0.48687297105789185, 'policy_logps/rejected': -494.4693908691406, 'policy_logps/chosen': -474.9573974609375, 'referece_logps/rejected': -490.33160400390625, 'referece_logps/chosen': -475.68829345703125, 'logits/rejected': 0.09399186074733734, 'logits/chosen': 0.07222601771354675, 'epoch': 2.05}

 34%|███▍      | 5512/16104 [25:39:12<54:23:52, 18.49s/it]

 34%|███▍      | 5513/16104 [25:39:32<56:00:01, 19.04s/it]

 34%|███▍      | 5514/16104 [25:39:55<59:22:11, 20.18s/it]

 34%|███▍      | 5515/16104 [25:40:16<60:09:12, 20.45s/it]

 34%|███▍      | 5516/16104 [25:40:38<61:57:25, 21.07s/it]

 34%|███▍      | 5517/16104 [25:40:53<56:33:04, 19.23s/it]

 34%|███▍      | 5518/16104 [25:41:07<51:24:57, 17.49s/it]

 34%|███▍      | 5519/16104 [25:41:23<50:45:45, 17.26s/it]

 34%|███▍      | 5520/16104 [25:41:44<53:30:42, 18.20s/it]

 34%|███▍      | 5521/16104 [25:42:04<54:59:58, 18.71s/it]

 34%|███▍      | 5522/16104 [25:42:23<55:51:56, 19.01s/it]

 34%|███▍      | 5523/16104 [25:42:37<50:47:37, 17.28s/it]

 34%|███▍      | 5524/16104 [25:42:53<49:54:55, 16.98s/it]

 34%|███▍      | 5525/16104 [25:43:14<53:20:35, 18.15s/it]

 34%|███▍      | 5526/16104 [25:43:34<54:55:02, 18.69s/it]

 34%|███▍      | 5527/16104 [25:43:54<56:00:28, 19.06s/it]

 34%|███▍      | 5528/16104 [25:44:06<49:57:57, 17.01s/it]

 34%|███▍      | 5529/16104 [25:44:23<49:41:15, 16.91s/it]

 34%|███▍      | 5530/16104 [25:44:36<46:55:59, 15.98s/it]

 34%|███▍      | 5531/16104 [25:45:00<53:42:53, 18.29s/it]

 34%|███▍      | 5532/16104 [25:45:11<47:28:45, 16.17s/it]

 34%|███▍      | 5533/16104 [25:45:28<48:17:46, 16.45s/it]

 34%|███▍      | 5534/16104 [25:45:40<44:15:36, 15.07s/it]

 34%|███▍      | 5535/16104 [25:45:51<40:30:37, 13.80s/it]

 34%|███▍      | 5536/16104 [25:46:07<42:42:25, 14.55s/it]

 34%|███▍      | 5537/16104 [25:46:19<40:20:44, 13.75s/it]

 34%|███▍      | 5538/16104 [25:46:32<39:12:00, 13.36s/it]

 34%|███▍      | 5539/16104 [25:46:50<43:33:38, 14.84s/it]

 34%|███▍      | 5540/16104 [25:47:04<43:03:17, 14.67s/it]

 34%|███▍      | 5541/16104 [25:47:23<46:51:10, 15.97s/it]

 34%|███▍      | 5542/16104 [25:47:36<44:05:24, 15.03s/it]

 34%|███▍      | 5543/16104 [25:47:49<41:45:44, 14.24s/it]

 34%|███▍      | 5544/16104 [25:48:05<43:50:02, 14.94s/it]

 34%|███▍      | 5545/16104 [25:48:17<41:00:33, 13.98s/it]

 34%|███▍      | 5546/16104 [25:48:35<44:58:39, 15.34s/it]

 34%|███▍      | 5547/16104 [25:48:46<40:54:27, 13.95s/it]

 34%|███▍      | 5548/16104 [25:48:57<38:09:49, 13.02s/it]

 34%|███▍      | 5549/16104 [25:49:08<36:13:44, 12.36s/it]

 34%|███▍      | 5550/16104 [25:49:27<42:01:06, 14.33s/it]

 34%|███▍      | 5551/16104 [25:49:46<46:37:48, 15.91s/it]

 34%|███▍      | 5552/16104 [25:50:03<47:28:02, 16.19s/it]

 34%|███▍      | 5553/16104 [25:50:24<51:37:23, 17.61s/it]

 34%|███▍      | 5554/16104 [25:50:44<53:34:25, 18.28s/it]

 34%|███▍      | 5555/16104 [25:51:04<54:51:14, 18.72s/it]

 35%|███▍      | 5556/16104 [25:51:25<57:07:42, 19.50s/it]


 35%|███▍      | 5558/16104 [25:51:47<44:08:49, 15.07s/it]

 35%|███▍      | 5559/16104 [25:52:07<48:57:20, 16.71s/it]

 35%|███▍      | 5560/16104 [25:52:20<45:10:35, 15.42s/it]
{'loss': 0.5863, 'learning_rate': 1.5225843062503887e-06, 'rewards/chosen': 0.45932769775390625, 'rewards/rejected': 0.05655451864004135, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4027731716632843, 'policy_logps/rejected': -593.8243408203125, 'policy_logps/chosen': -466.3963928222656, 'referece_logps/rejected': -594.389892578125, 'referece_logps/chosen': -470.98968505859375, 'logits/rejected': 0.4682375192642212, 'logits/chosen': 0.49391233921051025, 'epoch': 2.07}


 35%|███▍      | 5562/16104 [25:52:50<44:12:08, 15.09s/it]

 35%|███▍      | 5563/16104 [25:53:07<45:57:13, 15.69s/it]

 35%|███▍      | 5564/16104 [25:53:25<48:23:55, 16.53s/it]

 35%|███▍      | 5565/16104 [25:53:45<51:16:01, 17.51s/it]

 35%|███▍      | 5566/16104 [25:54:07<54:48:16, 18.72s/it]
{'loss': 0.6547, 'learning_rate': 1.5215550592839217e-06, 'rewards/chosen': -0.4096505343914032, 'rewards/rejected': -0.31516018509864807, 'rewards/accuracies': 0.5, 'rewards/margins': -0.09449034929275513, 'policy_logps/rejected': -359.5871887207031, 'policy_logps/chosen': -367.2052001953125, 'referece_logps/rejected': -356.4355773925781, 'referece_logps/chosen': -363.10870361328125, 'logits/rejected': -0.006118267774581909, 'logits/chosen': 0.07288958877325058, 'epoch': 2.07}


 35%|███▍      | 5568/16104 [25:54:46<55:58:31, 19.13s/it]
{'loss': 0.5588, 'learning_rate': 1.5212118081050736e-06, 'rewards/chosen': 0.0296756774187088, 'rewards/rejected': -0.7448551058769226, 'rewards/accuracies': 0.875, 'rewards/margins': 0.774530827999115, 'policy_logps/rejected': -480.4153747558594, 'policy_logps/chosen': -528.1867065429688, 'referece_logps/rejected': -472.9668273925781, 'referece_logps/chosen': -528.4834594726562, 'logits/rejected': -0.07305150479078293, 'logits/chosen': -0.06984766572713852, 'epoch': 2.07}


 35%|███▍      | 5570/16104 [25:55:13<48:03:57, 16.43s/it]

 35%|███▍      | 5571/16104 [25:55:32<50:45:39, 17.35s/it]

 35%|███▍      | 5572/16104 [25:55:45<46:36:09, 15.93s/it]
{'loss': 0.5456, 'learning_rate': 1.5205250527955618e-06, 'rewards/chosen': -0.216391921043396, 'rewards/rejected': -0.9856382608413696, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7692463397979736, 'policy_logps/rejected': -470.5859069824219, 'policy_logps/chosen': -481.8047180175781, 'referece_logps/rejected': -460.7295227050781, 'referece_logps/chosen': -479.6408386230469, 'logits/rejected': -0.04340827465057373, 'logits/chosen': -0.11525822430849075, 'epoch': 2.08}


 35%|███▍      | 5574/16104 [25:56:16<45:44:57, 15.64s/it]

 35%|███▍      | 5575/16104 [25:56:31<45:47:46, 15.66s/it]

 35%|███▍      | 5576/16104 [25:56:51<49:04:59, 16.78s/it]

 35%|███▍      | 5577/16104 [25:57:03<45:16:54, 15.49s/it]
{'loss': 0.5218, 'learning_rate': 1.519666134947041e-06, 'rewards/chosen': -0.45652562379837036, 'rewards/rejected': -0.8800778985023499, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4235522150993347, 'policy_logps/rejected': -382.9332275390625, 'policy_logps/chosen': -375.2514953613281, 'referece_logps/rejected': -374.1324462890625, 'referece_logps/chosen': -370.68621826171875, 'logits/rejected': -0.5575796365737915, 'logits/chosen': -0.6493732929229736, 'epoch': 2.08}

 35%|███▍      | 5578/16104 [25:57:24<50:00:12, 17.10s/it]


 35%|███▍      | 5580/16104 [25:57:56<49:14:14, 16.84s/it]

 35%|███▍      | 5581/16104 [25:58:07<44:01:25, 15.06s/it]
{'loss': 0.4297, 'learning_rate': 1.5189786222409389e-06, 'rewards/chosen': -0.01870909333229065, 'rewards/rejected': -1.0780367851257324, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0593277215957642, 'policy_logps/rejected': -356.843994140625, 'policy_logps/chosen': -405.9841613769531, 'referece_logps/rejected': -346.0636291503906, 'referece_logps/chosen': -405.7970886230469, 'logits/rejected': 0.12754029035568237, 'logits/chosen': 0.15643668174743652, 'epoch': 2.08}


 35%|███▍      | 5583/16104 [25:58:38<44:15:59, 15.15s/it]
{'loss': 0.6109, 'learning_rate': 1.5186347398984062e-06, 'rewards/chosen': -0.37564778327941895, 'rewards/rejected': -1.2196201086044312, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8439723253250122, 'policy_logps/rejected': -660.9021606445312, 'policy_logps/chosen': -570.17236328125, 'referece_logps/rejected': -648.7059936523438, 'referece_logps/chosen': -566.4158935546875, 'logits/rejected': -0.33642488718032837, 'logits/chosen': -0.38379737734794617, 'epoch': 2.08}

 35%|███▍      | 5584/16104 [25:58:57<47:12:34, 16.16s/it]


 35%|███▍      | 5586/16104 [25:59:28<45:15:25, 15.49s/it]

 35%|███▍      | 5587/16104 [25:59:39<41:16:08, 14.13s/it]

 35%|███▍      | 5588/16104 [25:59:50<38:32:40, 13.20s/it]
{'loss': 0.5593, 'learning_rate': 1.5177746670190671e-06, 'rewards/chosen': -0.6922421455383301, 'rewards/rejected': -0.9882875084877014, 'rewards/accuracies': 0.5, 'rewards/margins': 0.29604530334472656, 'policy_logps/rejected': -348.47265625, 'policy_logps/chosen': -291.66650390625, 'referece_logps/rejected': -338.5898132324219, 'referece_logps/chosen': -284.7441101074219, 'logits/rejected': -0.9072575569152832, 'logits/chosen': -0.6593319177627563, 'epoch': 2.08}


 35%|███▍      | 5590/16104 [26:00:17<38:35:45, 13.22s/it]

 35%|███▍      | 5591/16104 [26:00:33<40:54:23, 14.01s/it]

 35%|███▍      | 5592/16104 [26:00:53<45:54:03, 15.72s/it]

 35%|███▍      | 5593/16104 [26:01:03<41:27:25, 14.20s/it]

 35%|███▍      | 5594/16104 [26:01:16<39:43:22, 13.61s/it]

 35%|███▍      | 5595/16104 [26:01:27<38:02:17, 13.03s/it]

 35%|███▍      | 5596/16104 [26:01:42<39:41:14, 13.60s/it]

 35%|███▍      | 5597/16104 [26:01:55<38:53:37, 13.33s/it]

 35%|███▍      | 5598/16104 [26:02:10<40:14:25, 13.79s/it]

 35%|███▍      | 5599/16104 [26:02:26<42:20:03, 14.51s/it]

 35%|███▍      | 5600/16104 [26:02:47<47:59:26, 16.45s/it]
{'loss': 0.4811, 'learning_rate': 1.5157083573852669e-06, 'rewards/chosen': 0.13821154832839966, 'rewards/rejected': -1.3859528303146362, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5241644382476807, 'policy_logps/rejected': -556.0523071289062, 'policy_logps/chosen': -349.6211853027344, 'referece_logps/rejected': -542.1928100585938, 'referece_logps/chosen': -351.0032958984375, 'logits/rejected': 0.02245861291885376, 'logits/chosen': 0.07244768738746643, 'epoch': 2.09}


 35%|███▍      | 5602/16104 [26:03:26<52:30:07, 18.00s/it]

 35%|███▍      | 5603/16104 [26:03:44<52:23:34, 17.96s/it]

 35%|███▍      | 5604/16104 [26:04:01<51:43:29, 17.73s/it]

 35%|███▍      | 5605/16104 [26:04:21<54:00:41, 18.52s/it]

 35%|███▍      | 5606/16104 [26:04:43<57:05:01, 19.58s/it]

 35%|███▍      | 5607/16104 [26:04:59<53:51:08, 18.47s/it]

 35%|███▍      | 5608/16104 [26:05:19<55:16:51, 18.96s/it]

 35%|███▍      | 5609/16104 [26:05:32<49:34:24, 17.00s/it]

 35%|███▍      | 5610/16104 [26:05:50<50:48:49, 17.43s/it]

 35%|███▍      | 5611/16104 [26:06:10<52:37:55, 18.06s/it]

 35%|███▍      | 5612/16104 [26:06:30<54:13:48, 18.61s/it]

 35%|███▍      | 5613/16104 [26:06:49<54:58:32, 18.86s/it]

 35%|███▍      | 5614/16104 [26:07:08<55:00:02, 18.88s/it]
{'loss': 0.5154, 'learning_rate': 1.5132938668996027e-06, 'rewards/chosen': -0.45248734951019287, 'rewards/rejected': -1.169440507888794, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7169532179832458, 'policy_logps/rejected': -316.4656982421875, 'policy_logps/chosen': -415.5791931152344, 'referece_logps/rejected': -304.77130126953125, 'referece_logps/chosen': -411.0543212890625, 'logits/rejected': -0.9057563543319702, 'logits/chosen': -0.93973308801651, 'epoch': 2.09}


 35%|███▍      | 5616/16104 [26:07:35<46:13:16, 15.87s/it]

 35%|███▍      | 5617/16104 [26:07:48<44:20:08, 15.22s/it]

 35%|███▍      | 5618/16104 [26:08:00<41:19:49, 14.19s/it]
{'loss': 0.3734, 'learning_rate': 1.5126032641461324e-06, 'rewards/chosen': 0.01522943377494812, 'rewards/rejected': -1.1586792469024658, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1739085912704468, 'policy_logps/rejected': -436.99188232421875, 'policy_logps/chosen': -487.3465270996094, 'referece_logps/rejected': -425.40509033203125, 'referece_logps/chosen': -487.49884033203125, 'logits/rejected': -0.29539066553115845, 'logits/chosen': -0.17416487634181976, 'epoch': 2.09}


 35%|███▍      | 5620/16104 [26:08:25<38:25:35, 13.19s/it]

 35%|███▍      | 5621/16104 [26:08:45<44:22:15, 15.24s/it]

 35%|███▍      | 5622/16104 [26:09:06<50:00:31, 17.18s/it]

 35%|███▍      | 5623/16104 [26:09:24<50:04:23, 17.20s/it]

 35%|███▍      | 5624/16104 [26:09:37<46:29:25, 15.97s/it]

 35%|███▍      | 5625/16104 [26:09:58<51:06:37, 17.56s/it]

 35%|███▍      | 5626/16104 [26:10:18<53:22:31, 18.34s/it]

 35%|███▍      | 5627/16104 [26:10:34<51:32:37, 17.71s/it]

 35%|███▍      | 5628/16104 [26:10:58<56:18:24, 19.35s/it]

 35%|███▍      | 5629/16104 [26:11:08<48:52:35, 16.80s/it]
{'loss': 0.4459, 'learning_rate': 1.5107023972227344e-06, 'rewards/chosen': -0.13787910342216492, 'rewards/rejected': -1.296818494796753, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1589393615722656, 'policy_logps/rejected': -409.22344970703125, 'policy_logps/chosen': -313.9912109375, 'referece_logps/rejected': -396.2552795410156, 'referece_logps/chosen': -312.6124267578125, 'logits/rejected': -0.5292956233024597, 'logits/chosen': -0.4456724524497986, 'epoch': 2.1}


 35%|███▍      | 5631/16104 [26:11:37<45:04:07, 15.49s/it]
{'loss': 0.528, 'learning_rate': 1.5103565162174317e-06, 'rewards/chosen': -0.14827486872673035, 'rewards/rejected': -0.9110388159751892, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7627639770507812, 'policy_logps/rejected': -280.889892578125, 'policy_logps/chosen': -329.95989990234375, 'referece_logps/rejected': -271.7794494628906, 'referece_logps/chosen': -328.4771423339844, 'logits/rejected': -0.22716718912124634, 'logits/chosen': -0.03303578495979309, 'epoch': 2.1}


 35%|███▍      | 5633/16104 [26:12:04<42:23:18, 14.57s/it]

 35%|███▍      | 5634/16104 [26:12:21<44:21:34, 15.25s/it]

 35%|███▍      | 5635/16104 [26:12:32<41:03:44, 14.12s/it]

 35%|███▍      | 5636/16104 [26:12:55<48:01:12, 16.51s/it]

 35%|███▌      | 5637/16104 [26:13:16<52:02:31, 17.90s/it]

 35%|███▌      | 5638/16104 [26:13:32<50:30:23, 17.37s/it]

 35%|███▌      | 5639/16104 [26:13:51<51:43:24, 17.79s/it]

 35%|███▌      | 5640/16104 [26:14:09<52:20:42, 18.01s/it]

 35%|███▌      | 5641/16104 [26:14:26<51:07:59, 17.59s/it]

 35%|███▌      | 5642/16104 [26:14:38<46:37:34, 16.04s/it]

 35%|███▌      | 5643/16104 [26:14:54<46:01:21, 15.84s/it]

 35%|███▌      | 5644/16104 [26:15:11<47:48:57, 16.46s/it]

 35%|███▌      | 5645/16104 [26:15:26<45:51:51, 15.79s/it]

 35%|███▌      | 5646/16104 [26:15:48<51:13:51, 17.64s/it]

 35%|███▌      | 5647/16104 [26:16:04<50:24:50, 17.36s/it]

 35%|███▌      | 5648/16104 [26:16:24<52:40:11, 18.13s/it]

 35%|███▌      | 5649/16104 [26:16:35<46:05:06, 15.87s/it]

 35%|███▌      | 5650/16104 [26:16:49<44:12:38, 15.22s/it]

 35%|███▌      | 5651/16104 [26:17:00<40:40:50, 14.01s/it]
{'loss': 0.5205, 'learning_rate': 1.5068931735424499e-06, 'rewards/chosen': -0.11715870350599289, 'rewards/rejected': -0.694362998008728, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5772043466567993, 'policy_logps/rejected': -316.10137939453125, 'policy_logps/chosen': -267.1005554199219, 'referece_logps/rejected': -309.1577453613281, 'referece_logps/chosen': -265.928955078125, 'logits/rejected': -0.6999483108520508, 'logits/chosen': -0.540749728679657, 'epoch': 2.11}


 35%|███▌      | 5653/16104 [26:17:30<42:16:15, 14.56s/it]

 35%|███▌      | 5654/16104 [26:17:45<42:34:20, 14.67s/it]

 35%|███▌      | 5655/16104 [26:17:59<42:16:05, 14.56s/it]

 35%|███▌      | 5656/16104 [26:18:19<47:26:47, 16.35s/it]

 35%|███▌      | 5657/16104 [26:18:39<50:11:46, 17.30s/it]
{'loss': 0.3871, 'learning_rate': 1.5058525688196326e-06, 'rewards/chosen': -0.6914698481559753, 'rewards/rejected': -1.7547892332077026, 'rewards/accuracies': 0.625, 'rewards/margins': 1.063319206237793, 'policy_logps/rejected': -398.7601318359375, 'policy_logps/chosen': -425.62469482421875, 'referece_logps/rejected': -381.2122802734375, 'referece_logps/chosen': -418.7099914550781, 'logits/rejected': 0.22938792407512665, 'logits/chosen': 0.21982648968696594, 'epoch': 2.11}

 35%|███▌      | 5658/16104 [26:19:00<53:33:35, 18.46s/it]


 35%|███▌      | 5660/16104 [26:19:41<56:54:04, 19.61s/it]

 35%|███▌      | 5661/16104 [26:19:57<53:10:13, 18.33s/it]
{'loss': 0.569, 'learning_rate': 1.505158422991434e-06, 'rewards/chosen': -0.10238303989171982, 'rewards/rejected': -0.8593456149101257, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7569625973701477, 'policy_logps/rejected': -472.6396484375, 'policy_logps/chosen': -538.3209838867188, 'referece_logps/rejected': -464.0462341308594, 'referece_logps/chosen': -537.2971801757812, 'logits/rejected': 0.12750869989395142, 'logits/chosen': 0.0410553514957428, 'epoch': 2.11}


 35%|███▌      | 5663/16104 [26:20:21<44:45:43, 15.43s/it]
{'loss': 0.5467, 'learning_rate': 1.5048112274418951e-06, 'rewards/chosen': -0.4353647232055664, 'rewards/rejected': -0.5479995012283325, 'rewards/accuracies': 0.5, 'rewards/margins': 0.1126348003745079, 'policy_logps/rejected': -486.28204345703125, 'policy_logps/chosen': -539.8564453125, 'referece_logps/rejected': -480.80206298828125, 'referece_logps/chosen': -535.5028076171875, 'logits/rejected': 0.7621251940727234, 'logits/chosen': 0.6169788837432861, 'epoch': 2.11}

 35%|███▌      | 5664/16104 [26:20:40<47:26:48, 16.36s/it]

 35%|███▌      | 5665/16104 [26:21:00<50:53:50, 17.55s/it]


 35%|███▌      | 5667/16104 [26:21:25<42:50:52, 14.78s/it]
{'loss': 0.5676, 'learning_rate': 1.5041165913528319e-06, 'rewards/chosen': -1.313352108001709, 'rewards/rejected': -1.7340474128723145, 'rewards/accuracies': 0.75, 'rewards/margins': 0.42069530487060547, 'policy_logps/rejected': -341.7806396484375, 'policy_logps/chosen': -409.5791931152344, 'referece_logps/rejected': -324.4401550292969, 'referece_logps/chosen': -396.44561767578125, 'logits/rejected': 0.26206883788108826, 'logits/chosen': 0.2657746970653534, 'epoch': 2.11}


 35%|███▌      | 5669/16104 [26:21:59<45:41:15, 15.76s/it]

 35%|███▌      | 5670/16104 [26:22:15<46:04:10, 15.90s/it]

 35%|███▌      | 5671/16104 [26:22:35<49:31:15, 17.09s/it]
{'loss': 0.481, 'learning_rate': 1.5034216289851338e-06, 'rewards/chosen': -0.30394724011421204, 'rewards/rejected': -1.4151160717010498, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1111688613891602, 'policy_logps/rejected': -497.19268798828125, 'policy_logps/chosen': -426.3049621582031, 'referece_logps/rejected': -483.04150390625, 'referece_logps/chosen': -423.2655334472656, 'logits/rejected': -0.7321661710739136, 'logits/chosen': -0.6764285564422607, 'epoch': 2.11}

 35%|███▌      | 5672/16104 [26:22:50<48:04:00, 16.59s/it]

 35%|███▌      | 5673/16104 [26:23:08<49:10:39, 16.97s/it]


 35%|███▌      | 5675/16104 [26:23:37<44:30:13, 15.36s/it]
{'loss': 0.5063, 'learning_rate': 1.5027263407886005e-06, 'rewards/chosen': 0.3357088565826416, 'rewards/rejected': -0.5573776364326477, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8930864930152893, 'policy_logps/rejected': -499.9196472167969, 'policy_logps/chosen': -637.09912109375, 'referece_logps/rejected': -494.3458557128906, 'referece_logps/chosen': -640.4561767578125, 'logits/rejected': 0.2594755291938782, 'logits/chosen': 0.21676507592201233, 'epoch': 2.11}


 35%|███▌      | 5677/16104 [26:24:15<50:29:26, 17.43s/it]

 35%|███▌      | 5678/16104 [26:24:26<44:59:24, 15.53s/it]
{'loss': 0.5067, 'learning_rate': 1.5022046610867282e-06, 'rewards/chosen': 0.14553377032279968, 'rewards/rejected': -0.9229059219360352, 'rewards/accuracies': 0.5, 'rewards/margins': 1.0684397220611572, 'policy_logps/rejected': -453.57318115234375, 'policy_logps/chosen': -384.5545349121094, 'referece_logps/rejected': -444.34417724609375, 'referece_logps/chosen': -386.0097961425781, 'logits/rejected': 0.2655560076236725, 'logits/chosen': 0.35200929641723633, 'epoch': 2.12}


 35%|███▌      | 5680/16104 [26:25:01<48:50:22, 16.87s/it]
{'loss': 0.481, 'learning_rate': 1.5018567730317165e-06, 'rewards/chosen': -0.9502275586128235, 'rewards/rejected': -2.598191976547241, 'rewards/accuracies': 0.75, 'rewards/margins': 1.647964358329773, 'policy_logps/rejected': -511.8511657714844, 'policy_logps/chosen': -450.0646057128906, 'referece_logps/rejected': -485.8692932128906, 'referece_logps/chosen': -440.56231689453125, 'logits/rejected': -0.5489727258682251, 'logits/chosen': -0.42416805028915405, 'epoch': 2.12}


 35%|███▌      | 5682/16104 [26:25:33<48:35:15, 16.78s/it]
{'loss': 0.4173, 'learning_rate': 1.5015088037726971e-06, 'rewards/chosen': -0.21472246944904327, 'rewards/rejected': -1.482518196105957, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2677958011627197, 'policy_logps/rejected': -291.97564697265625, 'policy_logps/chosen': -304.34893798828125, 'referece_logps/rejected': -277.15045166015625, 'referece_logps/chosen': -302.20172119140625, 'logits/rejected': -0.31800734996795654, 'logits/chosen': -0.24736453592777252, 'epoch': 2.12}


 35%|███▌      | 5684/16104 [26:26:00<43:04:37, 14.88s/it]

 35%|███▌      | 5685/16104 [26:26:15<43:36:55, 15.07s/it]

 35%|███▌      | 5686/16104 [26:26:38<50:09:08, 17.33s/it]

 35%|███▌      | 5687/16104 [26:26:50<45:25:06, 15.70s/it]
{'loss': 0.5488, 'learning_rate': 1.5006385257271437e-06, 'rewards/chosen': 0.20451317727565765, 'rewards/rejected': -0.8726701736450195, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0771832466125488, 'policy_logps/rejected': -423.87542724609375, 'policy_logps/chosen': -514.8365478515625, 'referece_logps/rejected': -415.14874267578125, 'referece_logps/chosen': -516.8816528320312, 'logits/rejected': -0.2686004936695099, 'logits/chosen': -0.4249972105026245, 'epoch': 2.12}


 35%|███▌      | 5689/16104 [26:27:18<43:40:04, 15.09s/it]

 35%|███▌      | 5690/16104 [26:27:38<48:03:24, 16.61s/it]

 35%|███▌      | 5691/16104 [26:27:54<47:39:48, 16.48s/it]

 35%|███▌      | 5692/16104 [26:28:14<50:21:51, 17.41s/it]

 35%|███▌      | 5693/16104 [26:28:34<52:30:54, 18.16s/it]

 35%|███▌      | 5694/16104 [26:28:50<51:18:09, 17.74s/it]

 35%|███▌      | 5695/16104 [26:29:10<53:11:20, 18.40s/it]

 35%|███▌      | 5696/16104 [26:29:24<48:43:58, 16.86s/it]

 35%|███▌      | 5697/16104 [26:29:44<51:22:41, 17.77s/it]

 35%|███▌      | 5698/16104 [26:30:04<53:19:21, 18.45s/it]

 35%|███▌      | 5699/16104 [26:30:24<55:18:29, 19.14s/it]
{'loss': 0.5848, 'learning_rate': 1.4985477944191607e-06, 'rewards/chosen': -0.2104913592338562, 'rewards/rejected': -0.7073373794555664, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4968460500240326, 'policy_logps/rejected': -440.88433837890625, 'policy_logps/chosen': -583.2514038085938, 'referece_logps/rejected': -433.81097412109375, 'referece_logps/chosen': -581.146484375, 'logits/rejected': 0.4193602204322815, 'logits/chosen': 0.2637767791748047, 'epoch': 2.12}


 35%|███▌      | 5701/16104 [26:31:00<53:19:53, 18.46s/it]
{'loss': 0.5986, 'learning_rate': 1.4981990565320825e-06, 'rewards/chosen': -0.719489574432373, 'rewards/rejected': -0.9277965426445007, 'rewards/accuracies': 0.25, 'rewards/margins': 0.20830699801445007, 'policy_logps/rejected': -291.8570251464844, 'policy_logps/chosen': -291.4067077636719, 'referece_logps/rejected': -282.5791015625, 'referece_logps/chosen': -284.2117919921875, 'logits/rejected': -0.7521550059318542, 'logits/chosen': -0.5905770659446716, 'epoch': 2.12}

 35%|███▌      | 5702/16104 [26:31:21<55:32:51, 19.22s/it]


 35%|███▌      | 5704/16104 [26:31:51<49:15:16, 17.05s/it]
{'loss': 0.5244, 'learning_rate': 1.497675798571298e-06, 'rewards/chosen': -0.4684353470802307, 'rewards/rejected': -0.7836801409721375, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3152448832988739, 'policy_logps/rejected': -480.8311767578125, 'policy_logps/chosen': -360.0741882324219, 'referece_logps/rejected': -472.994384765625, 'referece_logps/chosen': -355.38983154296875, 'logits/rejected': 0.5837528109550476, 'logits/chosen': 0.6414989829063416, 'epoch': 2.13}


 35%|███▌      | 5706/16104 [26:32:25<49:29:22, 17.13s/it]

 35%|███▌      | 5707/16104 [26:32:45<51:52:14, 17.96s/it]
{'loss': 0.5123, 'learning_rate': 1.4971523594236509e-06, 'rewards/chosen': -0.6136608123779297, 'rewards/rejected': -2.129577159881592, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5159165859222412, 'policy_logps/rejected': -382.782470703125, 'policy_logps/chosen': -385.6186828613281, 'referece_logps/rejected': -361.4866943359375, 'referece_logps/chosen': -379.4820861816406, 'logits/rejected': -0.5069905519485474, 'logits/chosen': -0.41505247354507446, 'epoch': 2.13}

 35%|███▌      | 5708/16104 [26:33:01<50:39:10, 17.54s/it]


 35%|███▌      | 5710/16104 [26:33:37<51:00:55, 17.67s/it]
{'loss': 0.5281, 'learning_rate': 1.4966287392797076e-06, 'rewards/chosen': 0.18886196613311768, 'rewards/rejected': -1.1474294662475586, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3362913131713867, 'policy_logps/rejected': -428.3604431152344, 'policy_logps/chosen': -446.3603210449219, 'referece_logps/rejected': -416.88616943359375, 'referece_logps/chosen': -448.2489013671875, 'logits/rejected': -0.3611120283603668, 'logits/chosen': -0.3262878656387329, 'epoch': 2.13}


 35%|███▌      | 5712/16104 [26:34:07<45:51:36, 15.89s/it]

 35%|███▌      | 5713/16104 [26:34:26<48:17:23, 16.73s/it]

 35%|███▌      | 5714/16104 [26:34:46<51:15:29, 17.76s/it]

 35%|███▌      | 5715/16104 [26:35:04<52:02:46, 18.04s/it]

 35%|███▌      | 5716/16104 [26:35:18<48:22:40, 16.77s/it]
{'loss': 0.4661, 'learning_rate': 1.4955809567655283e-06, 'rewards/chosen': 0.24144095182418823, 'rewards/rejected': -0.3026718199253082, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5441128611564636, 'policy_logps/rejected': -511.6251525878906, 'policy_logps/chosen': -546.2054443359375, 'referece_logps/rejected': -508.59844970703125, 'referece_logps/chosen': -548.619873046875, 'logits/rejected': -0.025906849652528763, 'logits/chosen': -0.0007004085928201675, 'epoch': 2.13}


 36%|███▌      | 5718/16104 [26:36:02<55:57:06, 19.39s/it]

 36%|███▌      | 5719/16104 [26:36:18<52:22:20, 18.16s/it]

 36%|███▌      | 5720/16104 [26:36:36<52:24:37, 18.17s/it]

 36%|███▌      | 5721/16104 [26:36:56<53:55:52, 18.70s/it]

 36%|███▌      | 5722/16104 [26:37:07<47:20:17, 16.41s/it]

 36%|███▌      | 5723/16104 [26:37:22<46:17:47, 16.06s/it]
{'loss': 0.543, 'learning_rate': 1.4943576317950245e-06, 'rewards/chosen': -0.5237987637519836, 'rewards/rejected': -0.6531311273574829, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1293323040008545, 'policy_logps/rejected': -539.2562255859375, 'policy_logps/chosen': -573.0932006835938, 'referece_logps/rejected': -532.7249755859375, 'referece_logps/chosen': -567.855224609375, 'logits/rejected': -0.1695214956998825, 'logits/chosen': -0.21901461482048035, 'epoch': 2.13}


 36%|███▌      | 5725/16104 [26:38:00<50:18:00, 17.45s/it]

 36%|███▌      | 5726/16104 [26:38:14<47:18:06, 16.41s/it]

 36%|███▌      | 5727/16104 [26:38:36<52:38:48, 18.26s/it]

 36%|███▌      | 5728/16104 [26:38:58<55:43:53, 19.34s/it]

 36%|███▌      | 5729/16104 [26:39:15<53:28:09, 18.55s/it]

 36%|███▌      | 5730/16104 [26:39:35<54:56:35, 19.07s/it]
{'loss': 0.5338, 'learning_rate': 1.4931333269399083e-06, 'rewards/chosen': -1.4065874814987183, 'rewards/rejected': -1.5872423648834229, 'rewards/accuracies': 0.375, 'rewards/margins': 0.18065489828586578, 'policy_logps/rejected': -432.99993896484375, 'policy_logps/chosen': -426.16619873046875, 'referece_logps/rejected': -417.1274719238281, 'referece_logps/chosen': -412.1003112792969, 'logits/rejected': -0.37571918964385986, 'logits/chosen': -0.3068661093711853, 'epoch': 2.13}

 36%|███▌      | 5731/16104 [26:39:55<55:53:26, 19.40s/it]


 36%|███▌      | 5733/16104 [26:40:30<52:13:51, 18.13s/it]
{'loss': 0.4736, 'learning_rate': 1.4926083254957772e-06, 'rewards/chosen': -0.028826899826526642, 'rewards/rejected': -1.5445199012756348, 'rewards/accuracies': 1.0, 'rewards/margins': 1.515692949295044, 'policy_logps/rejected': -641.8106689453125, 'policy_logps/chosen': -579.1841430664062, 'referece_logps/rejected': -626.365478515625, 'referece_logps/chosen': -578.8959350585938, 'logits/rejected': -0.08683882653713226, 'logits/chosen': -0.22029903531074524, 'epoch': 2.14}


 36%|███▌      | 5735/16104 [26:41:10<54:35:45, 18.96s/it]
{'loss': 0.481, 'learning_rate': 1.4922582248867956e-06, 'rewards/chosen': -0.12743261456489563, 'rewards/rejected': -0.891811728477478, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7643791437149048, 'policy_logps/rejected': -670.084716796875, 'policy_logps/chosen': -591.5457153320312, 'referece_logps/rejected': -661.1666259765625, 'referece_logps/chosen': -590.2713012695312, 'logits/rejected': -0.8317505121231079, 'logits/chosen': -0.6231069564819336, 'epoch': 2.14}


 36%|███▌      | 5737/16104 [26:41:45<51:22:56, 17.84s/it]

 36%|███▌      | 5738/16104 [26:41:59<48:09:16, 16.72s/it]
{'loss': 0.4952, 'learning_rate': 1.491732924645604e-06, 'rewards/chosen': -0.7030651569366455, 'rewards/rejected': -0.7559841871261597, 'rewards/accuracies': 0.5, 'rewards/margins': 0.052919045090675354, 'policy_logps/rejected': -477.34442138671875, 'policy_logps/chosen': -409.50244140625, 'referece_logps/rejected': -469.7845458984375, 'referece_logps/chosen': -402.4717712402344, 'logits/rejected': 0.31759113073349, 'logits/chosen': 0.4161848723888397, 'epoch': 2.14}


 36%|███▌      | 5740/16104 [26:42:39<52:45:43, 18.33s/it]

 36%|███▌      | 5741/16104 [26:42:56<51:57:45, 18.05s/it]
{'loss': 0.4221, 'learning_rate': 1.491207445381148e-06, 'rewards/chosen': -0.3257065713405609, 'rewards/rejected': -0.8696668148040771, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5439601540565491, 'policy_logps/rejected': -276.4620666503906, 'policy_logps/chosen': -253.14308166503906, 'referece_logps/rejected': -267.7654113769531, 'referece_logps/chosen': -249.88600158691406, 'logits/rejected': 0.24652895331382751, 'logits/chosen': 0.20088091492652893, 'epoch': 2.14}


 36%|███▌      | 5743/16104 [26:43:32<51:21:28, 17.84s/it]

 36%|███▌      | 5744/16104 [26:43:49<51:00:06, 17.72s/it]
{'loss': 0.4416, 'learning_rate': 1.4906817872847374e-06, 'rewards/chosen': -0.4192766547203064, 'rewards/rejected': -1.1688237190246582, 'rewards/accuracies': 0.75, 'rewards/margins': 0.749547004699707, 'policy_logps/rejected': -435.7660827636719, 'policy_logps/chosen': -606.6685180664062, 'referece_logps/rejected': -424.077880859375, 'referece_logps/chosen': -602.4757690429688, 'logits/rejected': 0.13260938227176666, 'logits/chosen': 0.08118148148059845, 'epoch': 2.14}


 36%|███▌      | 5746/16104 [26:44:22<48:32:27, 16.87s/it]

 36%|███▌      | 5747/16104 [26:44:42<51:13:05, 17.80s/it]
{'loss': 0.496, 'learning_rate': 1.4901559505477468e-06, 'rewards/chosen': -0.31081774830818176, 'rewards/rejected': -0.7833874225616455, 'rewards/accuracies': 0.625, 'rewards/margins': 0.47256970405578613, 'policy_logps/rejected': -429.4818115234375, 'policy_logps/chosen': -355.3050842285156, 'referece_logps/rejected': -421.64788818359375, 'referece_logps/chosen': -352.1968994140625, 'logits/rejected': 0.03370657563209534, 'logits/chosen': 0.04544811695814133, 'epoch': 2.14}


 36%|███▌      | 5749/16104 [26:45:14<48:13:37, 16.77s/it]

 36%|███▌      | 5750/16104 [26:45:31<48:13:27, 16.77s/it]

 36%|███▌      | 5751/16104 [26:45:49<48:48:23, 16.97s/it]

 36%|███▌      | 5752/16104 [26:46:05<48:15:04, 16.78s/it]

 36%|███▌      | 5753/16104 [26:46:23<49:24:55, 17.19s/it]
{'loss': 0.5286, 'learning_rate': 1.4891037419178464e-06, 'rewards/chosen': -0.12222005426883698, 'rewards/rejected': -0.3772292733192444, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2550092339515686, 'policy_logps/rejected': -648.255615234375, 'policy_logps/chosen': -605.9552612304688, 'referece_logps/rejected': -644.4833374023438, 'referece_logps/chosen': -604.7330932617188, 'logits/rejected': 0.5656343698501587, 'logits/chosen': 0.5043734312057495, 'epoch': 2.14}


 36%|███▌      | 5755/16104 [26:47:00<51:29:01, 17.91s/it]
{'loss': 0.5152, 'learning_rate': 1.488752847351246e-06, 'rewards/chosen': -0.31950706243515015, 'rewards/rejected': -1.914531946182251, 'rewards/accuracies': 0.875, 'rewards/margins': 1.595024824142456, 'policy_logps/rejected': -343.34716796875, 'policy_logps/chosen': -473.1910400390625, 'referece_logps/rejected': -324.201904296875, 'referece_logps/chosen': -469.9960021972656, 'logits/rejected': -0.41458508372306824, 'logits/chosen': -0.4577159881591797, 'epoch': 2.14}

 36%|███▌      | 5756/16104 [26:47:15<48:52:04, 17.00s/it]

 36%|███▌      | 5757/16104 [26:47:28<45:45:15, 15.92s/it]

 36%|███▌      | 5758/16104 [26:47:40<42:43:58, 14.87s/it]

 36%|███▌      | 5759/16104 [26:47:57<44:01:04, 15.32s/it]


 36%|███▌      | 5761/16104 [26:48:40<53:04:19, 18.47s/it]
{'loss': 0.4297, 'learning_rate': 1.4876996893764267e-06, 'rewards/chosen': -0.2653934359550476, 'rewards/rejected': -1.7706576585769653, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5052642822265625, 'policy_logps/rejected': -438.0150451660156, 'policy_logps/chosen': -409.1955871582031, 'referece_logps/rejected': -420.3084716796875, 'referece_logps/chosen': -406.54168701171875, 'logits/rejected': -0.3177349269390106, 'logits/chosen': -0.04034930467605591, 'epoch': 2.15}


 36%|███▌      | 5763/16104 [26:49:18<53:13:07, 18.53s/it]

 36%|███▌      | 5764/16104 [26:49:30<47:35:47, 16.57s/it]

 36%|███▌      | 5765/16104 [26:49:47<48:15:31, 16.80s/it]

 36%|███▌      | 5766/16104 [26:50:06<50:01:40, 17.42s/it]

 36%|███▌      | 5767/16104 [26:50:26<52:10:23, 18.17s/it]

 36%|███▌      | 5768/16104 [26:50:46<53:57:41, 18.79s/it]

 36%|███▌      | 5769/16104 [26:51:05<54:29:59, 18.98s/it]

 36%|███▌      | 5770/16104 [26:51:18<48:42:11, 16.97s/it]

 36%|███▌      | 5771/16104 [26:51:34<48:01:47, 16.73s/it]
{'loss': 0.4617, 'learning_rate': 1.4859428485772682e-06, 'rewards/chosen': -0.7629643678665161, 'rewards/rejected': -1.6897603273391724, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9267959594726562, 'policy_logps/rejected': -302.59661865234375, 'policy_logps/chosen': -217.25592041015625, 'referece_logps/rejected': -285.69903564453125, 'referece_logps/chosen': -209.6262969970703, 'logits/rejected': -0.3356761336326599, 'logits/chosen': -0.29244673252105713, 'epoch': 2.15}

 36%|███▌      | 5772/16104 [26:51:47<44:45:58, 15.60s/it]

 36%|███▌      | 5773/16104 [26:52:04<46:20:56, 16.15s/it]

 36%|███▌      | 5774/16104 [26:52:20<46:11:58, 16.10s/it]

 36%|███▌      | 5775/16104 [26:52:37<46:49:39, 16.32s/it]

 36%|███▌      | 5776/16104 [26:52:49<42:55:11, 14.96s/it]

 36%|███▌      | 5777/16104 [26:53:05<43:38:15, 15.21s/it]


 36%|███▌      | 5779/16104 [26:53:45<51:18:06, 17.89s/it]
{'loss': 0.4806, 'learning_rate': 1.4845359602746355e-06, 'rewards/chosen': -0.5426462888717651, 'rewards/rejected': -1.3805222511291504, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8378761410713196, 'policy_logps/rejected': -317.27801513671875, 'policy_logps/chosen': -342.736083984375, 'referece_logps/rejected': -303.4727783203125, 'referece_logps/chosen': -337.30963134765625, 'logits/rejected': -1.0749911069869995, 'logits/chosen': -1.0959444046020508, 'epoch': 2.15}

 36%|███▌      | 5780/16104 [26:54:05<52:30:07, 18.31s/it]


 36%|███▌      | 5782/16104 [26:54:40<52:40:54, 18.37s/it]

 36%|███▌      | 5783/16104 [26:55:03<57:00:03, 19.88s/it]
{'loss': 0.4394, 'learning_rate': 1.483832045487386e-06, 'rewards/chosen': 0.022561833262443542, 'rewards/rejected': -1.685612440109253, 'rewards/accuracies': 1.0, 'rewards/margins': 1.708174228668213, 'policy_logps/rejected': -269.3962707519531, 'policy_logps/chosen': -534.6388549804688, 'referece_logps/rejected': -252.54014587402344, 'referece_logps/chosen': -534.8644409179688, 'logits/rejected': -0.30873560905456543, 'logits/chosen': -0.47017914056777954, 'epoch': 2.15}

 36%|███▌      | 5784/16104 [26:55:21<54:55:45, 19.16s/it]


 36%|███▌      | 5786/16104 [26:56:03<58:16:28, 20.33s/it]
{'loss': 0.584, 'learning_rate': 1.4833039038674046e-06, 'rewards/chosen': 0.0409630686044693, 'rewards/rejected': -0.7557045817375183, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7966676950454712, 'policy_logps/rejected': -418.1141662597656, 'policy_logps/chosen': -350.62091064453125, 'referece_logps/rejected': -410.5571594238281, 'referece_logps/chosen': -351.030517578125, 'logits/rejected': -0.2779980003833771, 'logits/chosen': -0.33687347173690796, 'epoch': 2.16}

 36%|███▌      | 5787/16104 [26:56:21<55:31:22, 19.37s/it]

 36%|███▌      | 5788/16104 [26:56:37<52:41:08, 18.39s/it]


 36%|███▌      | 5790/16104 [26:57:16<53:24:14, 18.64s/it]

 36%|███▌      | 5791/16104 [26:57:33<52:26:51, 18.31s/it]

 36%|███▌      | 5792/16104 [26:57:46<47:39:52, 16.64s/it]
{'loss': 0.4448, 'learning_rate': 1.4822470929561546e-06, 'rewards/chosen': -0.41904717683792114, 'rewards/rejected': -0.9695983529090881, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5505512356758118, 'policy_logps/rejected': -487.0209655761719, 'policy_logps/chosen': -536.7367553710938, 'referece_logps/rejected': -477.3249816894531, 'referece_logps/chosen': -532.5462646484375, 'logits/rejected': 0.1975509226322174, 'logits/chosen': 0.2074742466211319, 'epoch': 2.16}


 36%|███▌      | 5794/16104 [26:58:16<45:29:31, 15.88s/it]
{'loss': 0.3791, 'learning_rate': 1.4818946665143498e-06, 'rewards/chosen': 0.4770437479019165, 'rewards/rejected': -0.6147387027740479, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0917824506759644, 'policy_logps/rejected': -235.4386749267578, 'policy_logps/chosen': -320.8378601074219, 'referece_logps/rejected': -229.29129028320312, 'referece_logps/chosen': -325.6083068847656, 'logits/rejected': 0.3642750680446625, 'logits/chosen': 0.34243494272232056, 'epoch': 2.16}


 36%|███▌      | 5796/16104 [26:58:46<44:41:32, 15.61s/it]

 36%|███▌      | 5797/16104 [26:59:06<48:22:23, 16.90s/it]
{'loss': 0.5497, 'learning_rate': 1.4813658806682243e-06, 'rewards/chosen': 0.6468032598495483, 'rewards/rejected': -0.8009538054466248, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4477568864822388, 'policy_logps/rejected': -487.7506103515625, 'policy_logps/chosen': -433.1978759765625, 'referece_logps/rejected': -479.7410888671875, 'referece_logps/chosen': -439.6658935546875, 'logits/rejected': -0.10958129167556763, 'logits/chosen': -0.13393937051296234, 'epoch': 2.16}

 36%|███▌      | 5798/16104 [26:59:19<45:14:34, 15.80s/it]

 36%|███▌      | 5799/16104 [26:59:38<47:10:55, 16.48s/it]


 36%|███▌      | 5801/16104 [27:00:10<48:23:24, 16.91s/it]

 36%|███▌      | 5802/16104 [27:00:24<45:14:42, 15.81s/it]

 36%|███▌      | 5803/16104 [27:00:40<45:59:03, 16.07s/it]

 36%|███▌      | 5804/16104 [27:01:00<49:24:45, 17.27s/it]

 36%|███▌      | 5805/16104 [27:01:14<46:31:31, 16.26s/it]
{'loss': 0.5554, 'learning_rate': 1.4799549288288656e-06, 'rewards/chosen': -0.8561813235282898, 'rewards/rejected': -0.6877447366714478, 'rewards/accuracies': 0.625, 'rewards/margins': -0.16843654215335846, 'policy_logps/rejected': -590.1419067382812, 'policy_logps/chosen': -460.6484069824219, 'referece_logps/rejected': -583.264404296875, 'referece_logps/chosen': -452.0865783691406, 'logits/rejected': -0.2624695897102356, 'logits/chosen': -0.32985275983810425, 'epoch': 2.16}


 36%|███▌      | 5807/16104 [27:01:52<49:29:21, 17.30s/it]
{'loss': 0.3831, 'learning_rate': 1.4796019965759738e-06, 'rewards/chosen': -0.8182598948478699, 'rewards/rejected': -1.8415138721466064, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0232539176940918, 'policy_logps/rejected': -514.3623657226562, 'policy_logps/chosen': -410.3348693847656, 'referece_logps/rejected': -495.9471435546875, 'referece_logps/chosen': -402.1522521972656, 'logits/rejected': -0.8351512551307678, 'logits/chosen': -0.6855993270874023, 'epoch': 2.16}


 36%|███▌      | 5809/16104 [27:02:25<46:41:50, 16.33s/it]
{'loss': 0.5133, 'learning_rate': 1.4792489867200568e-06, 'rewards/chosen': -0.35721415281295776, 'rewards/rejected': -0.857843279838562, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5006290078163147, 'policy_logps/rejected': -389.45843505859375, 'policy_logps/chosen': -568.4367065429688, 'referece_logps/rejected': -380.8800354003906, 'referece_logps/chosen': -564.864501953125, 'logits/rejected': -0.5478150844573975, 'logits/chosen': -0.5476695895195007, 'epoch': 2.16}


 36%|███▌      | 5811/16104 [27:02:46<38:49:54, 13.58s/it]

 36%|███▌      | 5812/16104 [27:03:00<39:07:16, 13.68s/it]
{'loss': 0.5518, 'learning_rate': 1.4787193265554604e-06, 'rewards/chosen': -0.05991896986961365, 'rewards/rejected': -0.8252250552177429, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7653061151504517, 'policy_logps/rejected': -435.61944580078125, 'policy_logps/chosen': -449.3323059082031, 'referece_logps/rejected': -427.3671875, 'referece_logps/chosen': -448.73309326171875, 'logits/rejected': -0.2142096608877182, 'logits/chosen': -0.10895387828350067, 'epoch': 2.17}


 36%|███▌      | 5814/16104 [27:03:33<41:19:26, 14.46s/it]
{'loss': 0.5213, 'learning_rate': 1.4783661229419047e-06, 'rewards/chosen': 0.2880193889141083, 'rewards/rejected': 0.0158834308385849, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2721359133720398, 'policy_logps/rejected': -522.5328979492188, 'policy_logps/chosen': -529.9955444335938, 'referece_logps/rejected': -522.6917114257812, 'referece_logps/chosen': -532.8757934570312, 'logits/rejected': -0.16063573956489563, 'logits/chosen': -0.20173178613185883, 'epoch': 2.17}


 36%|███▌      | 5816/16104 [27:04:02<41:58:37, 14.69s/it]

 36%|███▌      | 5817/16104 [27:04:16<41:23:34, 14.49s/it]
{'loss': 0.4433, 'learning_rate': 1.4778361724087103e-06, 'rewards/chosen': -0.5745834708213806, 'rewards/rejected': -1.2508970499038696, 'rewards/accuracies': 0.75, 'rewards/margins': 0.676313579082489, 'policy_logps/rejected': -394.62591552734375, 'policy_logps/chosen': -414.3619689941406, 'referece_logps/rejected': -382.116943359375, 'referece_logps/chosen': -408.61614990234375, 'logits/rejected': -0.3280056118965149, 'logits/chosen': -0.27029845118522644, 'epoch': 2.17}

 36%|███▌      | 5818/16104 [27:04:27<38:36:50, 13.51s/it]


 36%|███▌      | 5820/16104 [27:04:54<39:24:22, 13.79s/it]
{'loss': 0.4208, 'learning_rate': 1.4773060479115883e-06, 'rewards/chosen': -0.4675678610801697, 'rewards/rejected': -0.8922948241233826, 'rewards/accuracies': 0.75, 'rewards/margins': 0.42472702264785767, 'policy_logps/rejected': -288.61865234375, 'policy_logps/chosen': -319.7212219238281, 'referece_logps/rejected': -279.6957092285156, 'referece_logps/chosen': -315.0455322265625, 'logits/rejected': -0.17321079969406128, 'logits/chosen': -0.2353138029575348, 'epoch': 2.17}


 36%|███▌      | 5822/16104 [27:05:24<41:11:38, 14.42s/it]
{'loss': 0.5049, 'learning_rate': 1.476952535028853e-06, 'rewards/chosen': -0.47182396054267883, 'rewards/rejected': -1.6612099409103394, 'rewards/accuracies': 0.625, 'rewards/margins': 1.189386010169983, 'policy_logps/rejected': -386.9734802246094, 'policy_logps/chosen': -299.08697509765625, 'referece_logps/rejected': -370.3614196777344, 'referece_logps/chosen': -294.3687438964844, 'logits/rejected': 0.3240077793598175, 'logits/chosen': 0.2833710312843323, 'epoch': 2.17}


 36%|███▌      | 5824/16104 [27:05:59<44:55:18, 15.73s/it]
{'loss': 0.5535, 'learning_rate': 1.4765989449717937e-06, 'rewards/chosen': -0.2506851851940155, 'rewards/rejected': -1.3704895973205566, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1198043823242188, 'policy_logps/rejected': -301.6885681152344, 'policy_logps/chosen': -400.24896240234375, 'referece_logps/rejected': -287.98370361328125, 'referece_logps/chosen': -397.7421569824219, 'logits/rejected': 0.01824425905942917, 'logits/chosen': -0.15719428658485413, 'epoch': 2.17}

 36%|███▌      | 5825/16104 [27:06:11<41:54:58, 14.68s/it]

 36%|███▌      | 5826/16104 [27:06:29<44:46:19, 15.68s/it]

 36%|███▌      | 5827/16104 [27:06:45<45:03:52, 15.79s/it]


 36%|███▌      | 5829/16104 [27:07:24<51:04:25, 17.89s/it]

 36%|███▌      | 5830/16104 [27:07:41<50:01:42, 17.53s/it]

 36%|███▌      | 5831/16104 [27:08:01<51:54:48, 18.19s/it]

 36%|███▌      | 5832/16104 [27:08:18<51:20:59, 18.00s/it]
{'loss': 0.3823, 'learning_rate': 1.4751838141447732e-06, 'rewards/chosen': -0.8108862638473511, 'rewards/rejected': -2.0562517642974854, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2453656196594238, 'policy_logps/rejected': -411.8197937011719, 'policy_logps/chosen': -393.7306823730469, 'referece_logps/rejected': -391.25726318359375, 'referece_logps/chosen': -385.6217956542969, 'logits/rejected': -0.23445402085781097, 'logits/chosen': -0.3114929795265198, 'epoch': 2.17}

 36%|███▌      | 5833/16104 [27:08:29<45:23:09, 15.91s/it]

 36%|███▌      | 5834/16104 [27:08:46<45:35:37, 15.98s/it]


 36%|███▌      | 5836/16104 [27:09:28<54:01:38, 18.94s/it]
{'loss': 0.5212, 'learning_rate': 1.4744757871734605e-06, 'rewards/chosen': -0.08500537276268005, 'rewards/rejected': -1.041154146194458, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9561488032341003, 'policy_logps/rejected': -398.7261047363281, 'policy_logps/chosen': -313.43988037109375, 'referece_logps/rejected': -388.3145751953125, 'referece_logps/chosen': -312.58984375, 'logits/rejected': 0.06431849300861359, 'logits/chosen': 0.0883859246969223, 'epoch': 2.17}

 36%|███▌      | 5837/16104 [27:09:49<55:32:40, 19.48s/it]

 36%|███▋      | 5838/16104 [27:10:10<56:43:41, 19.89s/it]


 36%|███▋      | 5840/16104 [27:10:41<50:54:55, 17.86s/it]

 36%|███▋      | 5841/16104 [27:11:00<52:38:17, 18.46s/it]
{'loss': 0.531, 'learning_rate': 1.4735903216617355e-06, 'rewards/chosen': -0.6262680292129517, 'rewards/rejected': -0.7493242025375366, 'rewards/accuracies': 0.625, 'rewards/margins': 0.12305618077516556, 'policy_logps/rejected': -517.6002807617188, 'policy_logps/chosen': -504.4958801269531, 'referece_logps/rejected': -510.1070556640625, 'referece_logps/chosen': -498.2331848144531, 'logits/rejected': 0.11583485454320908, 'logits/chosen': 0.11461132019758224, 'epoch': 2.18}
[2024-04-06 18:45:20,730] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 36%|███▋      | 5843/16104 [27:11:35<49:33:11, 17.39s/it]

 36%|███▋      | 5844/16104 [27:11:49<46:08:58, 16.19s/it]

 36%|███▋      | 5845/16104 [27:12:05<46:24:28, 16.29s/it]
{'loss': 0.4792, 'learning_rate': 1.4728816043730594e-06, 'rewards/chosen': 0.14507700502872467, 'rewards/rejected': -0.7687195539474487, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9137965440750122, 'policy_logps/rejected': -479.233642578125, 'policy_logps/chosen': -484.92138671875, 'referece_logps/rejected': -471.54638671875, 'referece_logps/chosen': -486.37213134765625, 'logits/rejected': 0.40745049715042114, 'logits/chosen': 0.33033978939056396, 'epoch': 2.18}


 36%|███▋      | 5847/16104 [27:12:43<50:05:26, 17.58s/it]
{'loss': 0.4523, 'learning_rate': 1.4725271309266223e-06, 'rewards/chosen': -0.7686909437179565, 'rewards/rejected': -2.3088955879211426, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5402047634124756, 'policy_logps/rejected': -359.37139892578125, 'policy_logps/chosen': -442.80035400390625, 'referece_logps/rejected': -336.28240966796875, 'referece_logps/chosen': -435.11346435546875, 'logits/rejected': -0.4141077995300293, 'logits/chosen': -0.3341650366783142, 'epoch': 2.18}

 36%|███▋      | 5848/16104 [27:13:02<51:49:43, 18.19s/it]


 36%|███▋      | 5850/16104 [27:13:29<44:33:00, 15.64s/it]
{'loss': 0.5552, 'learning_rate': 1.4719952774156524e-06, 'rewards/chosen': 0.052751172333955765, 'rewards/rejected': -0.404323011636734, 'rewards/accuracies': 0.625, 'rewards/margins': 0.45707419514656067, 'policy_logps/rejected': -442.9720153808594, 'policy_logps/chosen': -569.0784301757812, 'referece_logps/rejected': -438.9287109375, 'referece_logps/chosen': -569.60595703125, 'logits/rejected': 0.1023179218173027, 'logits/chosen': 0.17433452606201172, 'epoch': 2.18}


 36%|███▋      | 5852/16104 [27:13:59<42:41:49, 14.99s/it]
{'loss': 0.3966, 'learning_rate': 1.4716406129311306e-06, 'rewards/chosen': 0.13834266364574432, 'rewards/rejected': -1.2286938428878784, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3670364618301392, 'policy_logps/rejected': -519.7626342773438, 'policy_logps/chosen': -467.5374755859375, 'referece_logps/rejected': -507.4756774902344, 'referece_logps/chosen': -468.9208679199219, 'logits/rejected': -0.28888121247291565, 'logits/chosen': -0.16215559840202332, 'epoch': 2.18}

 36%|███▋      | 5853/16104 [27:14:15<43:55:51, 15.43s/it]


 36%|███▋      | 5855/16104 [27:14:49<44:41:58, 15.70s/it]
{'loss': 0.4766, 'learning_rate': 1.4711084731320028e-06, 'rewards/chosen': -0.42495197057724, 'rewards/rejected': -1.8801462650299072, 'rewards/accuracies': 0.875, 'rewards/margins': 1.455194354057312, 'policy_logps/rejected': -443.7793273925781, 'policy_logps/chosen': -362.6026611328125, 'referece_logps/rejected': -424.9778747558594, 'referece_logps/chosen': -358.3531494140625, 'logits/rejected': -0.033489685505628586, 'logits/chosen': 0.30100134015083313, 'epoch': 2.18}

 36%|███▋      | 5856/16104 [27:15:01<41:59:19, 14.75s/it]

 36%|███▋      | 5857/16104 [27:15:17<42:56:55, 15.09s/it]

 36%|███▋      | 5858/16104 [27:15:36<46:24:31, 16.31s/it]

 36%|███▋      | 5859/16104 [27:15:49<43:38:15, 15.33s/it]

 36%|███▋      | 5860/16104 [27:16:09<47:27:40, 16.68s/it]

 36%|███▋      | 5861/16104 [27:16:26<47:29:27, 16.69s/it]

 36%|███▋      | 5862/16104 [27:16:45<49:58:45, 17.57s/it]

 36%|███▋      | 5863/16104 [27:17:03<50:13:48, 17.66s/it]

 36%|███▋      | 5864/16104 [27:17:25<53:53:44, 18.95s/it]

 36%|███▋      | 5865/16104 [27:17:45<54:14:55, 19.07s/it]

 36%|███▋      | 5866/16104 [27:18:02<52:32:46, 18.48s/it]

 36%|███▋      | 5867/16104 [27:18:14<47:04:24, 16.55s/it]

 36%|███▋      | 5868/16104 [27:18:32<48:51:02, 17.18s/it]

 36%|███▋      | 5869/16104 [27:18:49<48:30:00, 17.06s/it]


 36%|███▋      | 5871/16104 [27:19:30<53:10:09, 18.71s/it]

 36%|███▋      | 5872/16104 [27:19:42<47:26:04, 16.69s/it]
{'loss': 0.5027, 'learning_rate': 1.4680897802459796e-06, 'rewards/chosen': -0.29007488489151, 'rewards/rejected': -1.5557297468185425, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2656548023223877, 'policy_logps/rejected': -647.3013305664062, 'policy_logps/chosen': -409.3719787597656, 'referece_logps/rejected': -631.7440795898438, 'referece_logps/chosen': -406.47119140625, 'logits/rejected': 0.008370041847229004, 'logits/chosen': 0.07916148006916046, 'epoch': 2.19}

 36%|███▋      | 5873/16104 [27:19:59<48:05:42, 16.92s/it]


 36%|███▋      | 5875/16104 [27:20:34<47:37:44, 16.76s/it]
{'loss': 0.424, 'learning_rate': 1.467556500678608e-06, 'rewards/chosen': 0.06621494144201279, 'rewards/rejected': -1.341260552406311, 'rewards/accuracies': 0.75, 'rewards/margins': 1.407475471496582, 'policy_logps/rejected': -454.42156982421875, 'policy_logps/chosen': -406.79241943359375, 'referece_logps/rejected': -441.0090026855469, 'referece_logps/chosen': -407.45452880859375, 'logits/rejected': -0.40816283226013184, 'logits/chosen': -0.30112335085868835, 'epoch': 2.19}

 36%|███▋      | 5876/16104 [27:20:51<48:17:00, 16.99s/it]


 37%|███▋      | 5878/16104 [27:21:24<47:53:06, 16.86s/it]

 37%|███▋      | 5879/16104 [27:21:42<48:58:55, 17.25s/it]
{'loss': 0.3465, 'learning_rate': 1.4668451965000911e-06, 'rewards/chosen': -0.025779180228710175, 'rewards/rejected': -1.5413541793823242, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5155750513076782, 'policy_logps/rejected': -256.4532775878906, 'policy_logps/chosen': -417.5576171875, 'referece_logps/rejected': -241.03973388671875, 'referece_logps/chosen': -417.2998352050781, 'logits/rejected': -0.37866246700286865, 'logits/chosen': -0.3217083215713501, 'epoch': 2.19}

 37%|███▋      | 5880/16104 [27:21:56<46:37:11, 16.42s/it]


 37%|███▋      | 5882/16104 [27:22:34<50:18:45, 17.72s/it]
{'loss': 0.509, 'learning_rate': 1.4663115200514565e-06, 'rewards/chosen': -0.13474367558956146, 'rewards/rejected': -1.7271698713302612, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5924263000488281, 'policy_logps/rejected': -414.1638488769531, 'policy_logps/chosen': -502.884765625, 'referece_logps/rejected': -396.8921203613281, 'referece_logps/chosen': -501.5373229980469, 'logits/rejected': 0.27279436588287354, 'logits/chosen': 0.07457555830478668, 'epoch': 2.19}

 37%|███▋      | 5883/16104 [27:22:52<50:46:21, 17.88s/it]

 37%|███▋      | 5884/16104 [27:23:05<46:03:52, 16.23s/it]


 37%|███▋      | 5886/16104 [27:23:34<43:23:20, 15.29s/it]
{'loss': 0.4601, 'learning_rate': 1.46559968740301e-06, 'rewards/chosen': 0.018731683492660522, 'rewards/rejected': -1.116804838180542, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1355363130569458, 'policy_logps/rejected': -551.8973388671875, 'policy_logps/chosen': -467.3805847167969, 'referece_logps/rejected': -540.729248046875, 'referece_logps/chosen': -467.5679016113281, 'logits/rejected': -0.0508609414100647, 'logits/chosen': 0.08765137195587158, 'epoch': 2.19}

 37%|███▋      | 5887/16104 [27:23:50<44:39:01, 15.73s/it]

 37%|███▋      | 5888/16104 [27:24:09<46:36:38, 16.43s/it]

 37%|███▋      | 5889/16104 [27:24:23<44:53:45, 15.82s/it]

 37%|███▋      | 5890/16104 [27:24:45<50:27:31, 17.78s/it]

 37%|███▋      | 5891/16104 [27:24:56<44:46:11, 15.78s/it]

 37%|███▋      | 5892/16104 [27:25:13<45:37:02, 16.08s/it]

 37%|███▋      | 5893/16104 [27:25:28<44:42:39, 15.76s/it]

 37%|███▋      | 5894/16104 [27:25:43<43:45:40, 15.43s/it]

 37%|███▋      | 5895/16104 [27:26:04<48:24:01, 17.07s/it]

 37%|███▋      | 5896/16104 [27:26:22<49:05:36, 17.31s/it]


 37%|███▋      | 5898/16104 [27:27:00<51:12:36, 18.06s/it]
{'loss': 0.5578, 'learning_rate': 1.4634623832051434e-06, 'rewards/chosen': -0.3415950834751129, 'rewards/rejected': -0.7250505089759827, 'rewards/accuracies': 0.625, 'rewards/margins': 0.38345539569854736, 'policy_logps/rejected': -374.8748474121094, 'policy_logps/chosen': -411.5012512207031, 'referece_logps/rejected': -367.62432861328125, 'referece_logps/chosen': -408.0853576660156, 'logits/rejected': 0.0595625638961792, 'logits/chosen': 0.039270296692848206, 'epoch': 2.2}

 37%|███▋      | 5899/16104 [27:27:11<45:24:39, 16.02s/it]


 37%|███▋      | 5901/16104 [27:27:38<41:45:56, 14.74s/it]

 37%|███▋      | 5902/16104 [27:27:58<46:08:38, 16.28s/it]
{'loss': 0.558, 'learning_rate': 1.4627493479253716e-06, 'rewards/chosen': -0.2062399983406067, 'rewards/rejected': -1.1963251829147339, 'rewards/accuracies': 0.625, 'rewards/margins': 0.990085244178772, 'policy_logps/rejected': -357.0416259765625, 'policy_logps/chosen': -430.0209655761719, 'referece_logps/rejected': -345.0783996582031, 'referece_logps/chosen': -427.95855712890625, 'logits/rejected': -0.3799596428871155, 'logits/chosen': -0.3978515863418579, 'epoch': 2.2}

 37%|███▋      | 5903/16104 [27:28:18<49:10:33, 17.35s/it]


 37%|███▋      | 5905/16104 [27:28:48<45:08:29, 15.93s/it]
{'loss': 0.4547, 'learning_rate': 1.46221437489042e-06, 'rewards/chosen': 0.042797937989234924, 'rewards/rejected': -0.9226577877998352, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9654557108879089, 'policy_logps/rejected': -397.98046875, 'policy_logps/chosen': -432.50640869140625, 'referece_logps/rejected': -388.75390625, 'referece_logps/chosen': -432.93438720703125, 'logits/rejected': -0.5172348022460938, 'logits/chosen': -0.5715854167938232, 'epoch': 2.2}

 37%|███▋      | 5906/16104 [27:29:04<45:00:19, 15.89s/it]

 37%|███▋      | 5907/16104 [27:29:21<45:56:12, 16.22s/it]

 37%|███▋      | 5908/16104 [27:29:37<45:38:03, 16.11s/it]

 37%|███▋      | 5909/16104 [27:29:57<49:23:40, 17.44s/it]

 37%|███▋      | 5910/16104 [27:30:13<48:05:19, 16.98s/it]

 37%|███▋      | 5911/16104 [27:30:31<48:47:52, 17.23s/it]

 37%|███▋      | 5912/16104 [27:30:47<48:08:56, 17.01s/it]

 37%|███▋      | 5913/16104 [27:31:07<50:18:33, 17.77s/it]


 37%|███▋      | 5915/16104 [27:31:44<51:57:19, 18.36s/it]
{'loss': 0.4002, 'learning_rate': 1.460429917204368e-06, 'rewards/chosen': -0.6917167901992798, 'rewards/rejected': -1.708364486694336, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0166478157043457, 'policy_logps/rejected': -422.2182312011719, 'policy_logps/chosen': -464.389892578125, 'referece_logps/rejected': -405.13458251953125, 'referece_logps/chosen': -457.47271728515625, 'logits/rejected': 0.3556796908378601, 'logits/chosen': 0.38448047637939453, 'epoch': 2.2}

 37%|███▋      | 5916/16104 [27:32:03<51:53:08, 18.33s/it]


 37%|███▋      | 5918/16104 [27:32:43<54:04:10, 19.11s/it]
{'loss': 0.4314, 'learning_rate': 1.459894216378407e-06, 'rewards/chosen': -0.6648435592651367, 'rewards/rejected': -1.4198578596115112, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7550142407417297, 'policy_logps/rejected': -296.4928283691406, 'policy_logps/chosen': -280.9695129394531, 'referece_logps/rejected': -282.29425048828125, 'referece_logps/chosen': -274.32110595703125, 'logits/rejected': -0.5177427530288696, 'logits/chosen': -0.575833797454834, 'epoch': 2.2}

 37%|███▋      | 5919/16104 [27:33:02<54:27:38, 19.25s/it]


 37%|███▋      | 5921/16104 [27:33:34<48:56:35, 17.30s/it]

 37%|███▋      | 5922/16104 [27:33:50<47:46:26, 16.89s/it]
{'loss': 0.4297, 'learning_rate': 1.4591796881945998e-06, 'rewards/chosen': -0.4518665075302124, 'rewards/rejected': -1.6076362133026123, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1557697057724, 'policy_logps/rejected': -396.45880126953125, 'policy_logps/chosen': -362.7887268066406, 'referece_logps/rejected': -380.3824462890625, 'referece_logps/chosen': -358.2700500488281, 'logits/rejected': 0.5136451721191406, 'logits/chosen': 0.49536749720573425, 'epoch': 2.21}


 37%|███▋      | 5924/16104 [27:34:25<48:24:21, 17.12s/it]
{'loss': 0.4132, 'learning_rate': 1.4588223126259639e-06, 'rewards/chosen': -1.0632978677749634, 'rewards/rejected': -1.6462342739105225, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5829364061355591, 'policy_logps/rejected': -257.1095275878906, 'policy_logps/chosen': -234.74412536621094, 'referece_logps/rejected': -240.6471710205078, 'referece_logps/chosen': -224.11114501953125, 'logits/rejected': -0.2798636555671692, 'logits/chosen': -0.24780619144439697, 'epoch': 2.21}

 37%|███▋      | 5925/16104 [27:34:42<48:45:32, 17.24s/it]

 37%|███▋      | 5926/16104 [27:34:57<46:40:05, 16.51s/it]


 37%|███▋      | 5928/16104 [27:35:29<45:26:06, 16.07s/it]
{'loss': 0.4726, 'learning_rate': 1.4581073388243558e-06, 'rewards/chosen': -0.16167353093624115, 'rewards/rejected': -1.1019209623336792, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9402473568916321, 'policy_logps/rejected': -488.0213623046875, 'policy_logps/chosen': -414.3565673828125, 'referece_logps/rejected': -477.0021667480469, 'referece_logps/chosen': -412.73980712890625, 'logits/rejected': 0.4367954730987549, 'logits/chosen': 0.5916588306427002, 'epoch': 2.21}


 37%|███▋      | 5930/16104 [27:36:02<45:54:44, 16.25s/it]
{'loss': 0.607, 'learning_rate': 1.4577497407070718e-06, 'rewards/chosen': -0.02164250612258911, 'rewards/rejected': -1.3910706043243408, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3694281578063965, 'policy_logps/rejected': -445.32635498046875, 'policy_logps/chosen': -434.0567626953125, 'referece_logps/rejected': -431.4156188964844, 'referece_logps/chosen': -433.84033203125, 'logits/rejected': -0.5656048059463501, 'logits/chosen': -0.5863592028617859, 'epoch': 2.21}

 37%|███▋      | 5931/16104 [27:36:22<48:34:38, 17.19s/it]

 37%|███▋      | 5932/16104 [27:36:43<52:17:27, 18.51s/it]

 37%|███▋      | 5933/16104 [27:37:03<53:08:07, 18.81s/it]

 37%|███▋      | 5934/16104 [27:37:15<47:31:38, 16.82s/it]

 37%|███▋      | 5935/16104 [27:37:32<47:56:33, 16.97s/it]

 37%|███▋      | 5936/16104 [27:37:46<44:55:54, 15.91s/it]

 37%|███▋      | 5937/16104 [27:38:01<44:22:31, 15.71s/it]

 37%|███▋      | 5938/16104 [27:38:20<47:03:58, 16.67s/it]


 37%|███▋      | 5940/16104 [27:38:50<45:44:25, 16.20s/it]

 37%|███▋      | 5941/16104 [27:39:06<45:40:17, 16.18s/it]

 37%|███▋      | 5942/16104 [27:39:21<44:15:04, 15.68s/it]

 37%|███▋      | 5943/16104 [27:39:33<41:00:48, 14.53s/it]

 37%|███▋      | 5944/16104 [27:39:51<44:17:52, 15.70s/it]

 37%|███▋      | 5945/16104 [27:40:14<50:09:18, 17.77s/it]

 37%|███▋      | 5946/16104 [27:40:33<51:01:22, 18.08s/it]

 37%|███▋      | 5947/16104 [27:40:46<46:43:05, 16.56s/it]

 37%|███▋      | 5948/16104 [27:41:02<46:11:39, 16.37s/it]

 37%|███▋      | 5949/16104 [27:41:22<49:09:10, 17.42s/it]

 37%|███▋      | 5950/16104 [27:41:42<52:08:29, 18.49s/it]

 37%|███▋      | 5951/16104 [27:42:02<53:22:21, 18.92s/it]

 37%|███▋      | 5952/16104 [27:42:22<54:18:07, 19.26s/it]

 37%|███▋      | 5953/16104 [27:42:41<53:45:53, 19.07s/it]

 37%|███▋      | 5954/16104 [27:43:02<55:32:54, 19.70s/it]

 37%|███▋      | 5955/16104 [27:43:18<52:22:51, 18.58s/it]

 37%|███▋      | 5956/16104 [27:43:37<52:44:57, 18.71s/it]

 37%|███▋      | 5957/16104 [27:43:55<51:33:33, 18.29s/it]

 37%|███▋      | 5958/16104 [27:44:07<46:37:55, 16.55s/it]

 37%|███▋      | 5959/16104 [27:44:27<49:31:31, 17.57s/it]

 37%|███▋      | 5960/16104 [27:44:47<51:23:28, 18.24s/it]

 37%|███▋      | 5961/16104 [27:45:01<47:58:05, 17.03s/it]

 37%|███▋      | 5962/16104 [27:45:20<50:02:25, 17.76s/it]

 37%|███▋      | 5963/16104 [27:45:36<48:24:35, 17.19s/it]

 37%|███▋      | 5964/16104 [27:45:53<47:47:18, 16.97s/it]

 37%|███▋      | 5965/16104 [27:46:08<46:07:02, 16.37s/it]

 37%|███▋      | 5966/16104 [27:46:29<49:50:15, 17.70s/it]

 37%|███▋      | 5967/16104 [27:46:49<51:50:54, 18.41s/it]

 37%|███▋      | 5968/16104 [27:47:09<53:55:33, 19.15s/it]
[2024-04-06 19:21:06,771] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 37%|███▋      | 5969/16104 [27:47:31<56:16:44, 19.99s/it]
[2024-04-06 19:21:28,716] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 37%|███▋      | 5970/16104 [27:47:47<52:28:04, 18.64s/it]

 37%|███▋      | 5971/16104 [27:47:59<47:07:24, 16.74s/it]

 37%|███▋      | 5972/16104 [27:48:17<47:56:15, 17.03s/it]

 37%|███▋      | 5973/16104 [27:48:35<48:55:28, 17.39s/it]

 37%|███▋      | 5974/16104 [27:48:46<43:42:07, 15.53s/it]

 37%|███▋      | 5975/16104 [27:49:06<46:49:13, 16.64s/it]

 37%|███▋      | 5976/16104 [27:49:23<47:09:23, 16.76s/it]

 37%|███▋      | 5977/16104 [27:49:44<51:11:29, 18.20s/it]

 37%|███▋      | 5978/16104 [27:50:01<49:53:34, 17.74s/it]

 37%|███▋      | 5979/16104 [27:50:20<51:26:34, 18.29s/it]

 37%|███▋      | 5980/16104 [27:50:37<49:40:14, 17.66s/it]

 37%|███▋      | 5981/16104 [27:50:53<48:12:05, 17.14s/it]

 37%|███▋      | 5982/16104 [27:51:10<48:27:59, 17.24s/it]

 37%|███▋      | 5983/16104 [27:51:28<48:54:57, 17.40s/it]

 37%|███▋      | 5984/16104 [27:51:43<46:44:37, 16.63s/it]

 37%|███▋      | 5985/16104 [27:52:03<49:35:46, 17.64s/it]

 37%|███▋      | 5986/16104 [27:52:22<51:17:16, 18.25s/it]

 37%|███▋      | 5987/16104 [27:52:43<53:27:51, 19.02s/it]

 37%|███▋      | 5988/16104 [27:53:01<52:33:55, 18.71s/it]

 37%|███▋      | 5989/16104 [27:53:15<48:33:25, 17.28s/it]

 37%|███▋      | 5990/16104 [27:53:28<45:16:01, 16.11s/it]

 37%|███▋      | 5991/16104 [27:53:43<43:50:45, 15.61s/it]
{'loss': 0.4961, 'learning_rate': 1.4468076918904488e-06, 'rewards/chosen': -0.3393753170967102, 'rewards/rejected': -0.8628061413764954, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5234308242797852, 'policy_logps/rejected': -321.54058837890625, 'policy_logps/chosen': -433.8775939941406, 'referece_logps/rejected': -312.9125061035156, 'referece_logps/chosen': -430.48382568359375, 'logits/rejected': 0.09311053156852722, 'logits/chosen': 0.12817130982875824, 'epoch': 2.23}


 37%|███▋      | 5993/16104 [27:54:16<45:39:56, 16.26s/it]

 37%|███▋      | 5994/16104 [27:54:31<45:01:28, 16.03s/it]

 37%|███▋      | 5995/16104 [27:54:48<46:09:19, 16.44s/it]

 37%|███▋      | 5996/16104 [27:55:09<49:25:41, 17.60s/it]

 37%|███▋      | 5997/16104 [27:55:22<45:36:37, 16.25s/it]

 37%|███▋      | 5998/16104 [27:55:44<50:32:35, 18.00s/it]

 37%|███▋      | 5999/16104 [27:56:05<53:16:12, 18.98s/it]

 37%|███▋      | 6000/16104 [27:56:22<51:52:47, 18.48s/it]

 37%|███▋      | 6001/16104 [27:57:00<68:12:38, 24.31s/it]
[2024-04-06 19:30:57,650] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 37%|███▋      | 6002/16104 [27:57:17<61:23:27, 21.88s/it]

 37%|███▋      | 6003/16104 [27:57:35<58:37:27, 20.89s/it]

 37%|███▋      | 6004/16104 [27:57:52<55:05:44, 19.64s/it]

 37%|███▋      | 6005/16104 [27:58:09<52:50:27, 18.84s/it]

 37%|███▋      | 6006/16104 [27:58:25<50:47:08, 18.11s/it]

 37%|███▋      | 6007/16104 [27:58:48<54:28:57, 19.43s/it]

 37%|███▋      | 6008/16104 [27:59:02<49:46:13, 17.75s/it]

 37%|███▋      | 6009/16104 [27:59:21<51:21:34, 18.32s/it]

 37%|███▋      | 6010/16104 [27:59:40<51:20:18, 18.31s/it]

 37%|███▋      | 6011/16104 [28:00:03<55:32:52, 19.81s/it]
[2024-04-06 19:34:00,129] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 37%|███▋      | 6012/16104 [28:00:22<54:52:02, 19.57s/it]

 37%|███▋      | 6013/16104 [28:00:42<55:25:37, 19.77s/it]

 37%|███▋      | 6014/16104 [28:00:56<50:44:13, 18.10s/it]

 37%|███▋      | 6015/16104 [28:01:12<48:44:22, 17.39s/it]

 37%|███▋      | 6016/16104 [28:01:32<51:10:20, 18.26s/it]

 37%|███▋      | 6017/16104 [28:01:44<45:17:25, 16.16s/it]

 37%|███▋      | 6018/16104 [28:02:01<46:43:43, 16.68s/it]

 37%|███▋      | 6019/16104 [28:02:21<49:04:54, 17.52s/it]

 37%|███▋      | 6020/16104 [28:02:37<47:53:17, 17.10s/it]

 37%|███▋      | 6021/16104 [28:02:56<49:13:23, 17.57s/it]

 37%|███▋      | 6022/16104 [28:03:14<49:28:18, 17.66s/it]

 37%|███▋      | 6023/16104 [28:03:31<49:13:06, 17.58s/it]

 37%|███▋      | 6024/16104 [28:03:51<51:08:28, 18.26s/it]

 37%|███▋      | 6025/16104 [28:04:09<51:01:59, 18.23s/it]

 37%|███▋      | 6026/16104 [28:04:20<45:08:12, 16.12s/it]

 37%|███▋      | 6027/16104 [28:04:41<48:37:55, 17.37s/it]

 37%|███▋      | 6028/16104 [28:04:52<43:29:56, 15.54s/it]

 37%|███▋      | 6029/16104 [28:05:06<42:37:43, 15.23s/it]

 37%|███▋      | 6030/16104 [28:05:27<47:19:46, 16.91s/it]
{'loss': 0.4275, 'learning_rate': 1.439776607389928e-06, 'rewards/chosen': -0.607273280620575, 'rewards/rejected': -1.254758358001709, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6474852561950684, 'policy_logps/rejected': -537.1112670898438, 'policy_logps/chosen': -522.51318359375, 'referece_logps/rejected': -524.563720703125, 'referece_logps/chosen': -516.4404907226562, 'logits/rejected': 0.5219985842704773, 'logits/chosen': 0.5604844689369202, 'epoch': 2.25}

 37%|███▋      | 6031/16104 [28:05:49<51:24:20, 18.37s/it]

 37%|███▋      | 6032/16104 [28:06:10<53:41:48, 19.19s/it]
[2024-04-06 19:40:07,299] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 37%|███▋      | 6033/16104 [28:06:30<54:20:03, 19.42s/it]
{'loss': 0.5501, 'learning_rate': 1.4392346284631989e-06, 'rewards/chosen': 0.06263181567192078, 'rewards/rejected': -0.8413953185081482, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9040271043777466, 'policy_logps/rejected': -441.2297058105469, 'policy_logps/chosen': -520.7412719726562, 'referece_logps/rejected': -432.8157653808594, 'referece_logps/chosen': -521.3676147460938, 'logits/rejected': 0.3944893479347229, 'logits/chosen': 0.33029645681381226, 'epoch': 2.25}
[2024-04-06 19:40:50,128] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 37%|███▋      | 6035/16104 [28:07:04<49:28:16, 17.69s/it]

 37%|███▋      | 6036/16104 [28:07:22<49:27:50, 17.69s/it]

 37%|███▋      | 6037/16104 [28:07:34<44:36:42, 15.95s/it]

 37%|███▋      | 6038/16104 [28:07:46<41:56:33, 15.00s/it]
{'loss': 0.374, 'learning_rate': 1.4383309749929695e-06, 'rewards/chosen': -0.3301682472229004, 'rewards/rejected': -1.8722195625305176, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5420511960983276, 'policy_logps/rejected': -448.23193359375, 'policy_logps/chosen': -425.34075927734375, 'referece_logps/rejected': -429.50970458984375, 'referece_logps/chosen': -422.0390625, 'logits/rejected': -0.3244640827178955, 'logits/chosen': -0.15456326305866241, 'epoch': 2.25}


 38%|███▊      | 6040/16104 [28:08:19<44:23:52, 15.88s/it]

 38%|███▊      | 6041/16104 [28:08:39<47:48:41, 17.10s/it]

 38%|███▊      | 6042/16104 [28:08:50<43:20:06, 15.50s/it]

 38%|███▊      | 6043/16104 [28:09:10<46:48:36, 16.75s/it]

 38%|███▊      | 6044/16104 [28:09:26<46:28:19, 16.63s/it]

 38%|███▊      | 6045/16104 [28:09:49<51:22:32, 18.39s/it]
[2024-04-06 19:43:46,159] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6046/16104 [28:10:06<50:33:13, 18.09s/it]
[2024-04-06 19:44:03,572] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6047/16104 [28:10:28<53:30:52, 19.16s/it]
{'loss': 0.4974, 'learning_rate': 1.436703282291028e-06, 'rewards/chosen': -0.13716793060302734, 'rewards/rejected': -1.9089105129241943, 'rewards/accuracies': 0.875, 'rewards/margins': 1.771742582321167, 'policy_logps/rejected': -449.1461181640625, 'policy_logps/chosen': -567.2778930664062, 'referece_logps/rejected': -430.0570373535156, 'referece_logps/chosen': -565.90625, 'logits/rejected': -0.8392556309700012, 'logits/chosen': -0.9737427234649658, 'epoch': 2.25}


 38%|███▊      | 6049/16104 [28:10:59<49:19:16, 17.66s/it]

 38%|███▊      | 6050/16104 [28:11:10<44:02:43, 15.77s/it]

 38%|███▊      | 6051/16104 [28:11:31<47:54:27, 17.16s/it]

 38%|███▊      | 6052/16104 [28:11:47<47:01:14, 16.84s/it]

 38%|███▊      | 6053/16104 [28:12:10<52:21:44, 18.75s/it]
[2024-04-06 19:46:07,201] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6054/16104 [28:12:31<54:02:07, 19.36s/it]

 38%|███▊      | 6055/16104 [28:12:52<56:04:50, 20.09s/it]
{'loss': 0.4895, 'learning_rate': 1.4352552429190982e-06, 'rewards/chosen': -0.4377029240131378, 'rewards/rejected': -1.8855935335159302, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4478905200958252, 'policy_logps/rejected': -621.4005737304688, 'policy_logps/chosen': -478.46063232421875, 'referece_logps/rejected': -602.544677734375, 'referece_logps/chosen': -474.0835876464844, 'logits/rejected': -0.6503547430038452, 'logits/chosen': -0.6062846183776855, 'epoch': 2.26}


 38%|███▊      | 6057/16104 [28:13:35<57:44:53, 20.69s/it]

 38%|███▊      | 6058/16104 [28:13:53<55:30:44, 19.89s/it]

 38%|███▊      | 6059/16104 [28:14:10<52:31:04, 18.82s/it]

 38%|███▊      | 6060/16104 [28:14:32<55:04:56, 19.74s/it]

 38%|███▊      | 6061/16104 [28:14:43<48:09:26, 17.26s/it]

 38%|███▊      | 6062/16104 [28:15:01<48:35:54, 17.42s/it]

 38%|███▊      | 6063/16104 [28:15:14<44:43:43, 16.04s/it]

 38%|███▊      | 6064/16104 [28:15:28<43:30:42, 15.60s/it]

 38%|███▊      | 6065/16104 [28:15:42<41:53:09, 15.02s/it]

 38%|███▊      | 6066/16104 [28:15:56<41:06:19, 14.74s/it]

 38%|███▊      | 6067/16104 [28:16:15<44:10:03, 15.84s/it]

 38%|███▊      | 6068/16104 [28:16:30<43:32:37, 15.62s/it]

 38%|███▊      | 6069/16104 [28:16:45<42:59:15, 15.42s/it]

 38%|███▊      | 6070/16104 [28:17:02<44:44:31, 16.05s/it]

 38%|███▊      | 6071/16104 [28:17:22<48:04:35, 17.25s/it]

 38%|███▊      | 6072/16104 [28:17:35<44:43:23, 16.05s/it]
{'loss': 0.4642, 'learning_rate': 1.4321744224701458e-06, 'rewards/chosen': -0.49532362818717957, 'rewards/rejected': -1.2058250904083252, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7105013728141785, 'policy_logps/rejected': -416.29388427734375, 'policy_logps/chosen': -588.743408203125, 'referece_logps/rejected': -404.23565673828125, 'referece_logps/chosen': -583.7901611328125, 'logits/rejected': 0.15833202004432678, 'logits/chosen': 0.14545631408691406, 'epoch': 2.26}

 38%|███▊      | 6073/16104 [28:17:54<46:29:32, 16.69s/it]


 38%|███▊      | 6075/16104 [28:18:29<48:24:50, 17.38s/it]

 38%|███▊      | 6076/16104 [28:18:47<49:06:37, 17.63s/it]
{'loss': 0.4451, 'learning_rate': 1.4314487879527344e-06, 'rewards/chosen': -0.7437976598739624, 'rewards/rejected': -1.851371169090271, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1075735092163086, 'policy_logps/rejected': -398.1242980957031, 'policy_logps/chosen': -647.5164184570312, 'referece_logps/rejected': -379.6105651855469, 'referece_logps/chosen': -640.0784301757812, 'logits/rejected': -0.336284339427948, 'logits/chosen': -0.46216830611228943, 'epoch': 2.26}


 38%|███▊      | 6078/16104 [28:19:09<39:22:40, 14.14s/it]

 38%|███▊      | 6079/16104 [28:19:21<38:00:11, 13.65s/it]

 38%|███▊      | 6080/16104 [28:19:33<36:13:06, 13.01s/it]

 38%|███▊      | 6081/16104 [28:19:47<37:21:42, 13.42s/it]

 38%|███▊      | 6082/16104 [28:20:07<42:51:14, 15.39s/it]
{'loss': 0.4094, 'learning_rate': 1.430359812737258e-06, 'rewards/chosen': -0.4203731417655945, 'rewards/rejected': -1.6127431392669678, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1923699378967285, 'policy_logps/rejected': -330.00408935546875, 'policy_logps/chosen': -421.8128662109375, 'referece_logps/rejected': -313.8766174316406, 'referece_logps/chosen': -417.6091613769531, 'logits/rejected': -0.7174092531204224, 'logits/chosen': -0.37132078409194946, 'epoch': 2.27}

 38%|███▊      | 6083/16104 [28:20:24<44:08:58, 15.86s/it]

 38%|███▊      | 6084/16104 [28:20:42<45:38:47, 16.40s/it]


 38%|███▊      | 6086/16104 [28:21:17<47:11:19, 16.96s/it]
[2024-04-06 19:55:14,349] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6087/16104 [28:21:34<46:51:51, 16.84s/it]
{'loss': 0.4045, 'learning_rate': 1.42945185458114e-06, 'rewards/chosen': -0.9113813042640686, 'rewards/rejected': -1.7767612934112549, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8653799295425415, 'policy_logps/rejected': -434.9168701171875, 'policy_logps/chosen': -388.9366455078125, 'referece_logps/rejected': -417.14923095703125, 'referece_logps/chosen': -379.8229064941406, 'logits/rejected': -0.43935850262641907, 'logits/chosen': -0.3028433322906494, 'epoch': 2.27}


 38%|███▊      | 6089/16104 [28:22:01<41:43:41, 15.00s/it]

 38%|███▊      | 6090/16104 [28:22:21<45:31:45, 16.37s/it]

 38%|███▊      | 6091/16104 [28:22:41<49:08:10, 17.67s/it]
[2024-04-06 19:56:38,621] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 38%|███▊      | 6092/16104 [28:23:03<52:45:43, 18.97s/it]

 38%|███▊      | 6093/16104 [28:23:15<46:49:35, 16.84s/it]

 38%|███▊      | 6094/16104 [28:23:34<48:07:29, 17.31s/it]

 38%|███▊      | 6095/16104 [28:23:47<44:53:07, 16.14s/it]
{'loss': 0.5098, 'learning_rate': 1.4279982185646847e-06, 'rewards/chosen': -0.38406580686569214, 'rewards/rejected': -1.9112796783447266, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5272138118743896, 'policy_logps/rejected': -286.1086730957031, 'policy_logps/chosen': -406.54071044921875, 'referece_logps/rejected': -266.9958801269531, 'referece_logps/chosen': -402.70001220703125, 'logits/rejected': 0.18829718232154846, 'logits/chosen': 0.3734737038612366, 'epoch': 2.27}


 38%|███▊      | 6097/16104 [28:24:21<46:18:15, 16.66s/it]

 38%|███▊      | 6098/16104 [28:24:36<44:55:10, 16.16s/it]

 38%|███▊      | 6099/16104 [28:24:50<43:12:24, 15.55s/it]

 38%|███▊      | 6100/16104 [28:25:08<45:11:12, 16.26s/it]

 38%|███▊      | 6101/16104 [28:25:27<47:34:08, 17.12s/it]

 38%|███▊      | 6102/16104 [28:25:45<48:23:11, 17.42s/it]
{'loss': 0.4467, 'learning_rate': 1.426725377973965e-06, 'rewards/chosen': -1.0976011753082275, 'rewards/rejected': -1.6839581727981567, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5863569974899292, 'policy_logps/rejected': -362.69403076171875, 'policy_logps/chosen': -396.6628112792969, 'referece_logps/rejected': -345.85443115234375, 'referece_logps/chosen': -385.686767578125, 'logits/rejected': -0.3960961103439331, 'logits/chosen': -0.4235081672668457, 'epoch': 2.27}


 38%|███▊      | 6104/16104 [28:26:22<49:19:24, 17.76s/it]

 38%|███▊      | 6105/16104 [28:26:38<48:04:43, 17.31s/it]

 38%|███▊      | 6106/16104 [28:26:59<51:18:38, 18.48s/it]
{'loss': 0.4577, 'learning_rate': 1.4259976605720576e-06, 'rewards/chosen': -0.4261971116065979, 'rewards/rejected': -0.9508012533187866, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5246042013168335, 'policy_logps/rejected': -402.0303955078125, 'policy_logps/chosen': -545.4468383789062, 'referece_logps/rejected': -392.5223693847656, 'referece_logps/chosen': -541.184814453125, 'logits/rejected': -0.7219134569168091, 'logits/chosen': -0.5872929096221924, 'epoch': 2.27}


 38%|███▊      | 6108/16104 [28:27:29<45:30:38, 16.39s/it]
{'loss': 0.3642, 'learning_rate': 1.4256336984474716e-06, 'rewards/chosen': -0.06268902122974396, 'rewards/rejected': -0.9735288619995117, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9108399748802185, 'policy_logps/rejected': -389.88836669921875, 'policy_logps/chosen': -399.76361083984375, 'referece_logps/rejected': -380.1530456542969, 'referece_logps/chosen': -399.13671875, 'logits/rejected': -0.039256319403648376, 'logits/chosen': 0.03780607506632805, 'epoch': 2.28}

 38%|███▊      | 6109/16104 [28:27:46<46:02:00, 16.58s/it]


 38%|███▊      | 6111/16104 [28:28:28<51:38:38, 18.60s/it]

 38%|███▊      | 6112/16104 [28:28:46<51:07:17, 18.42s/it]

 38%|███▊      | 6113/16104 [28:29:02<48:56:32, 17.64s/it]

 38%|███▊      | 6114/16104 [28:29:21<50:31:50, 18.21s/it]

 38%|███▊      | 6115/16104 [28:29:38<49:20:03, 17.78s/it]

 38%|███▊      | 6116/16104 [28:29:57<50:46:55, 18.30s/it]

 38%|███▊      | 6117/16104 [28:30:17<51:52:11, 18.70s/it]

 38%|███▊      | 6118/16104 [28:30:30<46:45:57, 16.86s/it]

 38%|███▊      | 6119/16104 [28:30:49<48:58:42, 17.66s/it]

 38%|███▊      | 6120/16104 [28:31:08<49:58:52, 18.02s/it]
{'loss': 0.5593, 'learning_rate': 1.4234484814799755e-06, 'rewards/chosen': -0.8306549787521362, 'rewards/rejected': -2.4539029598236084, 'rewards/accuracies': 0.625, 'rewards/margins': 1.6232479810714722, 'policy_logps/rejected': -643.0220336914062, 'policy_logps/chosen': -409.82525634765625, 'referece_logps/rejected': -618.4830322265625, 'referece_logps/chosen': -401.5186767578125, 'logits/rejected': -0.7046164274215698, 'logits/chosen': -0.4632999300956726, 'epoch': 2.28}


 38%|███▊      | 6122/16104 [28:31:31<41:21:54, 14.92s/it]
{'loss': 0.5125, 'learning_rate': 1.4230840384987486e-06, 'rewards/chosen': 0.6495755910873413, 'rewards/rejected': -0.46476423740386963, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1143399477005005, 'policy_logps/rejected': -442.86785888671875, 'policy_logps/chosen': -420.60003662109375, 'referece_logps/rejected': -438.22027587890625, 'referece_logps/chosen': -427.09576416015625, 'logits/rejected': -0.04237164929509163, 'logits/chosen': -0.13579276204109192, 'epoch': 2.28}


 38%|███▊      | 6124/16104 [28:32:05<42:54:37, 15.48s/it]
{'loss': 0.5417, 'learning_rate': 1.422719527059505e-06, 'rewards/chosen': -0.01837921142578125, 'rewards/rejected': -0.5416440963745117, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5232649445533752, 'policy_logps/rejected': -472.4973449707031, 'policy_logps/chosen': -422.18365478515625, 'referece_logps/rejected': -467.0809326171875, 'referece_logps/chosen': -421.9999084472656, 'logits/rejected': 0.4506341218948364, 'logits/chosen': 0.3572584092617035, 'epoch': 2.28}

 38%|███▊      | 6125/16104 [28:32:23<45:02:22, 16.25s/it]


 38%|███▊      | 6127/16104 [28:32:51<41:31:33, 14.98s/it]
{'loss': 0.425, 'learning_rate': 1.4221726316708813e-06, 'rewards/chosen': -0.5703651309013367, 'rewards/rejected': -0.42509475350379944, 'rewards/accuracies': 0.25, 'rewards/margins': -0.14527037739753723, 'policy_logps/rejected': -485.58843994140625, 'policy_logps/chosen': -390.6001892089844, 'referece_logps/rejected': -481.3374938964844, 'referece_logps/chosen': -384.8965148925781, 'logits/rejected': -0.22882576286792755, 'logits/chosen': -0.23203834891319275, 'epoch': 2.28}


 38%|███▊      | 6129/16104 [28:33:19<40:24:56, 14.59s/it]
{'loss': 0.5242, 'learning_rate': 1.4218079493446605e-06, 'rewards/chosen': -0.8973894715309143, 'rewards/rejected': -1.621795892715454, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7244064211845398, 'policy_logps/rejected': -481.221435546875, 'policy_logps/chosen': -390.3319091796875, 'referece_logps/rejected': -465.0033874511719, 'referece_logps/chosen': -381.3580322265625, 'logits/rejected': -0.4811272621154785, 'logits/chosen': -0.4013253450393677, 'epoch': 2.28}


 38%|███▊      | 6131/16104 [28:33:54<44:21:15, 16.01s/it]

 38%|███▊      | 6132/16104 [28:34:12<45:50:42, 16.55s/it]
{'loss': 0.4477, 'learning_rate': 1.4212607979021412e-06, 'rewards/chosen': -0.26586973667144775, 'rewards/rejected': -2.015483856201172, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7496140003204346, 'policy_logps/rejected': -366.91302490234375, 'policy_logps/chosen': -405.431396484375, 'referece_logps/rejected': -346.7582092285156, 'referece_logps/chosen': -402.772705078125, 'logits/rejected': -0.7555137872695923, 'logits/chosen': -0.799285352230072, 'epoch': 2.28}

 38%|███▊      | 6133/16104 [28:34:29<46:21:07, 16.74s/it]

 38%|███▊      | 6134/16104 [28:34:47<47:29:25, 17.15s/it]


 38%|███▊      | 6136/16104 [28:35:30<53:01:44, 19.15s/it]
{'loss': 0.4243, 'learning_rate': 1.4205310241093787e-06, 'rewards/chosen': -0.464433491230011, 'rewards/rejected': -1.9167864322662354, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4523530006408691, 'policy_logps/rejected': -518.6434326171875, 'policy_logps/chosen': -581.8635864257812, 'referece_logps/rejected': -499.4755554199219, 'referece_logps/chosen': -577.21923828125, 'logits/rejected': -0.7843620181083679, 'logits/chosen': -0.7462056875228882, 'epoch': 2.29}


 38%|███▊      | 6138/16104 [28:36:09<53:26:26, 19.30s/it]
{'loss': 0.3916, 'learning_rate': 1.4201660351160928e-06, 'rewards/chosen': -0.15746133029460907, 'rewards/rejected': -0.6338428258895874, 'rewards/accuracies': 0.75, 'rewards/margins': 0.47638142108917236, 'policy_logps/rejected': -341.4058532714844, 'policy_logps/chosen': -424.69110107421875, 'referece_logps/rejected': -335.0674133300781, 'referece_logps/chosen': -423.1164855957031, 'logits/rejected': -0.04533664137125015, 'logits/chosen': 0.02940547466278076, 'epoch': 2.29}


 38%|███▊      | 6140/16104 [28:36:44<51:26:16, 18.58s/it]

 38%|███▊      | 6141/16104 [28:36:58<47:37:29, 17.21s/it]
{'loss': 0.5326, 'learning_rate': 1.4196184241711295e-06, 'rewards/chosen': 0.2257566750049591, 'rewards/rejected': -1.3224678039550781, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5482244491577148, 'policy_logps/rejected': -457.3450622558594, 'policy_logps/chosen': -535.1511840820312, 'referece_logps/rejected': -444.12042236328125, 'referece_logps/chosen': -537.4088134765625, 'logits/rejected': -0.397537499666214, 'logits/chosen': -0.3969977796077728, 'epoch': 2.29}


 38%|███▊      | 6143/16104 [28:37:26<43:50:27, 15.84s/it]

 38%|███▊      | 6144/16104 [28:37:42<44:27:14, 16.07s/it]

 38%|███▊      | 6145/16104 [28:38:04<49:15:33, 17.81s/it]

 38%|███▊      | 6146/16104 [28:38:24<50:58:48, 18.43s/it]

 38%|███▊      | 6147/16104 [28:38:42<50:14:14, 18.16s/it]
{'loss': 0.4786, 'learning_rate': 1.4185227441741584e-06, 'rewards/chosen': -0.7482750415802002, 'rewards/rejected': -2.0444231033325195, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2961481809616089, 'policy_logps/rejected': -486.14471435546875, 'policy_logps/chosen': -455.1279296875, 'referece_logps/rejected': -465.70050048828125, 'referece_logps/chosen': -447.6451721191406, 'logits/rejected': -0.3725079894065857, 'logits/chosen': -0.3833637237548828, 'epoch': 2.29}


 38%|███▊      | 6149/16104 [28:39:18<50:11:07, 18.15s/it]
{'loss': 0.4295, 'learning_rate': 1.4181573819897617e-06, 'rewards/chosen': -0.4316973090171814, 'rewards/rejected': -1.5450891256332397, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1133918762207031, 'policy_logps/rejected': -428.5740661621094, 'policy_logps/chosen': -447.68035888671875, 'referece_logps/rejected': -413.1231689453125, 'referece_logps/chosen': -443.3633728027344, 'logits/rejected': -0.26618561148643494, 'logits/chosen': -0.1929198056459427, 'epoch': 2.29}

 38%|███▊      | 6150/16104 [28:39:32<46:06:27, 16.68s/it]

 38%|███▊      | 6151/16104 [28:39:51<48:27:10, 17.53s/it]

 38%|███▊      | 6152/16104 [28:40:13<52:08:44, 18.86s/it]

 38%|███▊      | 6153/16104 [28:40:33<52:55:09, 19.14s/it]


 38%|███▊      | 6155/16104 [28:41:06<49:37:01, 17.95s/it]

 38%|███▊      | 6156/16104 [28:41:21<46:34:12, 16.85s/it]
{'loss': 0.4976, 'learning_rate': 1.4168780819032539e-06, 'rewards/chosen': -0.30217474699020386, 'rewards/rejected': -0.8513777852058411, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5492030382156372, 'policy_logps/rejected': -411.563232421875, 'policy_logps/chosen': -361.0431213378906, 'referece_logps/rejected': -403.0494689941406, 'referece_logps/chosen': -358.0213317871094, 'logits/rejected': 0.2548138201236725, 'logits/chosen': 0.28862589597702026, 'epoch': 2.29}


 38%|███▊      | 6158/16104 [28:41:46<40:06:15, 14.52s/it]

 38%|███▊      | 6159/16104 [28:42:06<44:36:01, 16.14s/it]
{'loss': 0.307, 'learning_rate': 1.4163295573377985e-06, 'rewards/chosen': 0.3196241557598114, 'rewards/rejected': -1.427162528038025, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7467867136001587, 'policy_logps/rejected': -466.3793029785156, 'policy_logps/chosen': -433.8519592285156, 'referece_logps/rejected': -452.107666015625, 'referece_logps/chosen': -437.0482177734375, 'logits/rejected': 0.2720806896686554, 'logits/chosen': 0.2351008951663971, 'epoch': 2.29}


 38%|███▊      | 6161/16104 [28:42:34<41:05:04, 14.88s/it]
{'loss': 0.4535, 'learning_rate': 1.4159637900754666e-06, 'rewards/chosen': 0.24186038970947266, 'rewards/rejected': -0.8180180191993713, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0598783493041992, 'policy_logps/rejected': -484.6297302246094, 'policy_logps/chosen': -517.686279296875, 'referece_logps/rejected': -476.44952392578125, 'referece_logps/chosen': -520.1048583984375, 'logits/rejected': 0.49129191040992737, 'logits/chosen': 0.4497987627983093, 'epoch': 2.3}


 38%|███▊      | 6163/16104 [28:43:05<40:30:11, 14.67s/it]

 38%|███▊      | 6164/16104 [28:43:25<45:10:04, 16.36s/it]
{'loss': 0.4692, 'learning_rate': 1.4154150130018865e-06, 'rewards/chosen': 0.26949605345726013, 'rewards/rejected': -2.0424978733062744, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3119935989379883, 'policy_logps/rejected': -232.04515075683594, 'policy_logps/chosen': -357.43377685546875, 'referece_logps/rejected': -211.6201629638672, 'referece_logps/chosen': -360.1287536621094, 'logits/rejected': -0.5607110857963562, 'logits/chosen': -0.7035450339317322, 'epoch': 2.3}

 38%|███▊      | 6165/16104 [28:43:38<42:15:26, 15.31s/it]


 38%|███▊      | 6167/16104 [28:44:10<43:56:16, 15.92s/it]

 38%|███▊      | 6168/16104 [28:44:27<44:30:47, 16.13s/it]
{'loss': 0.5107, 'learning_rate': 1.4146830750117586e-06, 'rewards/chosen': -0.4260834753513336, 'rewards/rejected': -0.6300004720687866, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2039170265197754, 'policy_logps/rejected': -461.40191650390625, 'policy_logps/chosen': -382.58917236328125, 'referece_logps/rejected': -455.1019287109375, 'referece_logps/chosen': -378.3283386230469, 'logits/rejected': -0.20228423178195953, 'logits/chosen': -0.1868124008178711, 'epoch': 2.3}

 38%|███▊      | 6169/16104 [28:44:45<46:22:00, 16.80s/it]

 38%|███▊      | 6170/16104 [28:45:05<48:51:32, 17.71s/it]


 38%|███▊      | 6172/16104 [28:45:41<48:02:57, 17.42s/it]

 38%|███▊      | 6173/16104 [28:45:51<42:29:27, 15.40s/it]

 38%|███▊      | 6174/16104 [28:46:03<39:18:22, 14.25s/it]
{'loss': 0.453, 'learning_rate': 1.4135846649345695e-06, 'rewards/chosen': -0.1402359902858734, 'rewards/rejected': -0.8416852355003357, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7014492154121399, 'policy_logps/rejected': -486.26507568359375, 'policy_logps/chosen': -468.7928161621094, 'referece_logps/rejected': -477.8482360839844, 'referece_logps/chosen': -467.3904113769531, 'logits/rejected': -0.26165860891342163, 'logits/chosen': -0.5169044137001038, 'epoch': 2.3}

 38%|███▊      | 6175/16104 [28:46:14<36:30:02, 13.23s/it]

 38%|███▊      | 6176/16104 [28:46:30<39:07:10, 14.19s/it]


 38%|███▊      | 6178/16104 [28:47:05<43:27:17, 15.76s/it]
{'loss': 0.4526, 'learning_rate': 1.4128520568462863e-06, 'rewards/chosen': -0.7901849150657654, 'rewards/rejected': -1.896128535270691, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1059434413909912, 'policy_logps/rejected': -500.33734130859375, 'policy_logps/chosen': -307.1245422363281, 'referece_logps/rejected': -481.37603759765625, 'referece_logps/chosen': -299.2226867675781, 'logits/rejected': -0.7256246209144592, 'logits/chosen': -0.424424946308136, 'epoch': 2.3}


 38%|███▊      | 6180/16104 [28:47:37<44:11:16, 16.03s/it]

 38%|███▊      | 6181/16104 [28:47:56<47:02:39, 17.07s/it]

 38%|███▊      | 6182/16104 [28:48:15<48:31:17, 17.61s/it]

 38%|███▊      | 6183/16104 [28:48:36<51:27:07, 18.67s/it]

 38%|███▊      | 6184/16104 [28:48:57<52:45:44, 19.15s/it]

 38%|███▊      | 6185/16104 [28:49:18<55:02:39, 19.98s/it]

 38%|███▊      | 6186/16104 [28:49:35<52:28:58, 19.05s/it]

 38%|███▊      | 6187/16104 [28:49:59<56:10:07, 20.39s/it]
{'loss': 0.4118, 'learning_rate': 1.4112027123850966e-06, 'rewards/chosen': -0.7949404120445251, 'rewards/rejected': -2.3960163593292236, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6010758876800537, 'policy_logps/rejected': -580.3555908203125, 'policy_logps/chosen': -587.6318969726562, 'referece_logps/rejected': -556.3955078125, 'referece_logps/chosen': -579.6824951171875, 'logits/rejected': 0.1793210804462433, 'logits/chosen': 0.19250188767910004, 'epoch': 2.31}

 38%|███▊      | 6188/16104 [28:50:14<51:36:31, 18.74s/it]

 38%|███▊      | 6189/16104 [28:50:32<51:01:44, 18.53s/it]

 38%|███▊      | 6190/16104 [28:50:50<50:36:40, 18.38s/it]

 38%|███▊      | 6191/16104 [28:51:10<52:11:57, 18.96s/it]


 38%|███▊      | 6193/16104 [28:51:45<49:44:37, 18.07s/it]

 38%|███▊      | 6194/16104 [28:52:01<48:02:26, 17.45s/it]
{'loss': 0.4155, 'learning_rate': 1.4099189571411401e-06, 'rewards/chosen': -0.022852696478366852, 'rewards/rejected': -1.8438074588775635, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8209547996520996, 'policy_logps/rejected': -383.7364196777344, 'policy_logps/chosen': -460.6496276855469, 'referece_logps/rejected': -365.29833984375, 'referece_logps/chosen': -460.4210510253906, 'logits/rejected': 0.27213871479034424, 'logits/chosen': 0.20085252821445465, 'epoch': 2.31}


 38%|███▊      | 6196/16104 [28:52:35<47:17:27, 17.18s/it]
{'loss': 0.5051, 'learning_rate': 1.4095520205797062e-06, 'rewards/chosen': -0.3376566171646118, 'rewards/rejected': -1.2902835607528687, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9526269435882568, 'policy_logps/rejected': -410.86004638671875, 'policy_logps/chosen': -531.9588623046875, 'referece_logps/rejected': -397.9571533203125, 'referece_logps/chosen': -528.582275390625, 'logits/rejected': -0.2286042869091034, 'logits/chosen': -0.14288702607154846, 'epoch': 2.31}


 38%|███▊      | 6198/16104 [28:52:57<38:36:02, 14.03s/it]
{'loss': 0.4413, 'learning_rate': 1.4091850177498327e-06, 'rewards/chosen': -0.41256198287010193, 'rewards/rejected': -1.4107388257980347, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9981769323348999, 'policy_logps/rejected': -232.64854431152344, 'policy_logps/chosen': -456.6717224121094, 'referece_logps/rejected': -218.5411376953125, 'referece_logps/chosen': -452.546142578125, 'logits/rejected': -0.19746097922325134, 'logits/chosen': -0.24096211791038513, 'epoch': 2.31}

 38%|███▊      | 6199/16104 [28:53:08<36:00:47, 13.09s/it]

 38%|███▊      | 6200/16104 [28:53:19<34:04:08, 12.38s/it]

 39%|███▊      | 6201/16104 [28:53:39<40:10:26, 14.60s/it]

 39%|███▊      | 6202/16104 [28:53:58<44:09:29, 16.05s/it]


 39%|███▊      | 6204/16104 [28:54:31<44:31:50, 16.19s/it]

 39%|███▊      | 6205/16104 [28:54:53<49:26:20, 17.98s/it]
{'loss': 0.4976, 'learning_rate': 1.407899986838762e-06, 'rewards/chosen': -0.6028373837471008, 'rewards/rejected': -1.1108509302139282, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5080135464668274, 'policy_logps/rejected': -418.5145263671875, 'policy_logps/chosen': -363.904052734375, 'referece_logps/rejected': -407.40606689453125, 'referece_logps/chosen': -357.87567138671875, 'logits/rejected': -0.6867338418960571, 'logits/chosen': -0.7141143083572388, 'epoch': 2.31}

 39%|███▊      | 6206/16104 [28:55:13<50:39:00, 18.42s/it]


 39%|███▊      | 6208/16104 [28:55:49<49:59:30, 18.19s/it]
{'loss': 0.3773, 'learning_rate': 1.4073490116526743e-06, 'rewards/chosen': -0.33681145310401917, 'rewards/rejected': -2.586484909057617, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2496731281280518, 'policy_logps/rejected': -318.5883483886719, 'policy_logps/chosen': -411.46893310546875, 'referece_logps/rejected': -292.7234802246094, 'referece_logps/chosen': -408.100830078125, 'logits/rejected': -0.24692192673683167, 'logits/chosen': -0.278999388217926, 'epoch': 2.31}

 39%|███▊      | 6209/16104 [28:56:06<48:43:39, 17.73s/it]

 39%|███▊      | 6210/16104 [28:56:23<47:41:07, 17.35s/it]

 39%|███▊      | 6211/16104 [28:56:38<46:14:30, 16.83s/it]


 39%|███▊      | 6213/16104 [28:57:08<44:01:44, 16.03s/it]
{'loss': 0.3885, 'learning_rate': 1.4064303902150641e-06, 'rewards/chosen': -1.0966085195541382, 'rewards/rejected': -2.0713911056518555, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9747827053070068, 'policy_logps/rejected': -414.1273498535156, 'policy_logps/chosen': -290.6195068359375, 'referece_logps/rejected': -393.4134521484375, 'referece_logps/chosen': -279.6534118652344, 'logits/rejected': -0.5554536581039429, 'logits/chosen': -0.4251020848751068, 'epoch': 2.31}

 39%|███▊      | 6214/16104 [28:57:27<46:40:17, 16.99s/it]

 39%|███▊      | 6215/16104 [28:57:45<47:39:01, 17.35s/it]

 39%|███▊      | 6216/16104 [28:58:07<51:28:38, 18.74s/it]

 39%|███▊      | 6217/16104 [28:58:29<53:47:56, 19.59s/it]

 39%|███▊      | 6218/16104 [28:58:49<54:01:17, 19.67s/it]


 39%|███▊      | 6220/16104 [28:59:16<45:20:27, 16.51s/it]
{'loss': 0.4926, 'learning_rate': 1.4051436298955883e-06, 'rewards/chosen': -0.058292366564273834, 'rewards/rejected': -1.5568498373031616, 'rewards/accuracies': 0.875, 'rewards/margins': 1.498557686805725, 'policy_logps/rejected': -325.5957336425781, 'policy_logps/chosen': -277.2877197265625, 'referece_logps/rejected': -310.0272216796875, 'referece_logps/chosen': -276.7048034667969, 'logits/rejected': -0.8065617680549622, 'logits/chosen': -0.8301178216934204, 'epoch': 2.32}

 39%|███▊      | 6221/16104 [28:59:33<45:26:39, 16.55s/it]

 39%|███▊      | 6222/16104 [28:59:51<46:58:12, 17.11s/it]

 39%|███▊      | 6223/16104 [29:00:03<42:40:47, 15.55s/it]


 39%|███▊      | 6225/16104 [29:00:40<47:25:18, 17.28s/it]
{'loss': 0.4687, 'learning_rate': 1.40422402356949e-06, 'rewards/chosen': -0.16351546347141266, 'rewards/rejected': -0.6799113750457764, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5163958668708801, 'policy_logps/rejected': -522.0933837890625, 'policy_logps/chosen': -453.4339599609375, 'referece_logps/rejected': -515.2942504882812, 'referece_logps/chosen': -451.7987976074219, 'logits/rejected': -0.7530637979507446, 'logits/chosen': -0.83863765001297, 'epoch': 2.32}

 39%|███▊      | 6226/16104 [29:00:50<41:34:25, 15.15s/it]

 39%|███▊      | 6227/16104 [29:01:05<40:58:32, 14.93s/it]

 39%|███▊      | 6228/16104 [29:01:15<37:31:09, 13.68s/it]

 39%|███▊      | 6229/16104 [29:01:33<40:43:55, 14.85s/it]


 39%|███▊      | 6231/16104 [29:02:06<43:31:22, 15.87s/it]
{'loss': 0.4807, 'learning_rate': 1.4031199564578426e-06, 'rewards/chosen': -0.1089818924665451, 'rewards/rejected': -1.2261899709701538, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1172080039978027, 'policy_logps/rejected': -439.6748352050781, 'policy_logps/chosen': -541.0177612304688, 'referece_logps/rejected': -427.41290283203125, 'referece_logps/chosen': -539.9279174804688, 'logits/rejected': -0.09098821878433228, 'logits/chosen': -0.06133173406124115, 'epoch': 2.32}

 39%|███▊      | 6232/16104 [29:02:21<42:32:03, 15.51s/it]

 39%|███▊      | 6233/16104 [29:02:35<41:27:15, 15.12s/it]


 39%|███▊      | 6235/16104 [29:03:04<41:58:40, 15.31s/it]
{'loss': 0.3898, 'learning_rate': 1.402383585479068e-06, 'rewards/chosen': -0.3803889751434326, 'rewards/rejected': -1.4136265516281128, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0332376956939697, 'policy_logps/rejected': -353.6417236328125, 'policy_logps/chosen': -408.1349182128906, 'referece_logps/rejected': -339.5054626464844, 'referece_logps/chosen': -404.33099365234375, 'logits/rejected': -0.23175455629825592, 'logits/chosen': -0.1552504599094391, 'epoch': 2.32}

 39%|███▊      | 6236/16104 [29:03:24<45:14:44, 16.51s/it]

 39%|███▊      | 6237/16104 [29:03:38<43:05:49, 15.72s/it]

 39%|███▊      | 6238/16104 [29:03:49<39:26:32, 14.39s/it]

 39%|███▊      | 6239/16104 [29:04:05<41:11:26, 15.03s/it]

 39%|███▊      | 6240/16104 [29:04:25<45:07:30, 16.47s/it]

 39%|███▉      | 6241/16104 [29:04:45<47:45:24, 17.43s/it]

 39%|███▉      | 6242/16104 [29:05:05<49:48:00, 18.18s/it]

 39%|███▉      | 6243/16104 [29:05:25<51:50:34, 18.93s/it]

 39%|███▉      | 6244/16104 [29:05:45<52:46:42, 19.27s/it]

 39%|███▉      | 6245/16104 [29:06:09<55:53:14, 20.41s/it]

 39%|███▉      | 6246/16104 [29:06:29<55:59:16, 20.45s/it]

 39%|███▉      | 6247/16104 [29:06:49<55:47:36, 20.38s/it]


 39%|███▉      | 6249/16104 [29:07:18<46:56:22, 17.15s/it]
{'loss': 0.445, 'learning_rate': 1.399804239263775e-06, 'rewards/chosen': 0.028979308903217316, 'rewards/rejected': -0.6001598834991455, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6291391849517822, 'policy_logps/rejected': -387.9662170410156, 'policy_logps/chosen': -381.16802978515625, 'referece_logps/rejected': -381.96466064453125, 'referece_logps/chosen': -381.45782470703125, 'logits/rejected': -0.5393502712249756, 'logits/chosen': -0.5375771522521973, 'epoch': 2.33}


 39%|███▉      | 6251/16104 [29:07:40<38:21:54, 14.02s/it]
{'loss': 0.5311, 'learning_rate': 1.3994355019911766e-06, 'rewards/chosen': -0.06692105531692505, 'rewards/rejected': -0.5840349793434143, 'rewards/accuracies': 0.5, 'rewards/margins': 0.517113983631134, 'policy_logps/rejected': -342.7144775390625, 'policy_logps/chosen': -344.17816162109375, 'referece_logps/rejected': -336.8741149902344, 'referece_logps/chosen': -343.5089416503906, 'logits/rejected': -0.23391400277614594, 'logits/chosen': -0.18392522633075714, 'epoch': 2.33}

 39%|███▉      | 6252/16104 [29:07:57<40:14:33, 14.70s/it]


 39%|███▉      | 6254/16104 [29:08:22<37:30:47, 13.71s/it]

 39%|███▉      | 6255/16104 [29:08:40<41:15:21, 15.08s/it]

 39%|███▉      | 6256/16104 [29:08:52<38:45:51, 14.17s/it]
{'loss': 0.4731, 'learning_rate': 1.3985133761773455e-06, 'rewards/chosen': 0.11413973569869995, 'rewards/rejected': -0.9855607748031616, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0997005701065063, 'policy_logps/rejected': -395.94427490234375, 'policy_logps/chosen': -411.59002685546875, 'referece_logps/rejected': -386.0886535644531, 'referece_logps/chosen': -412.7314147949219, 'logits/rejected': -0.19806762039661407, 'logits/chosen': -0.05586619675159454, 'epoch': 2.33}

 39%|███▉      | 6257/16104 [29:09:05<37:44:16, 13.80s/it]

 39%|███▉      | 6258/16104 [29:09:23<41:14:23, 15.08s/it]

 39%|███▉      | 6259/16104 [29:09:40<42:22:46, 15.50s/it]

 39%|███▉      | 6260/16104 [29:09:54<41:22:56, 15.13s/it]

 39%|███▉      | 6261/16104 [29:10:11<43:10:02, 15.79s/it]


 39%|███▉      | 6263/16104 [29:10:47<45:16:33, 16.56s/it]
{'loss': 0.4072, 'learning_rate': 1.3972217231827603e-06, 'rewards/chosen': -0.4844350814819336, 'rewards/rejected': -1.8906234502792358, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4061882495880127, 'policy_logps/rejected': -429.09356689453125, 'policy_logps/chosen': -460.5567626953125, 'referece_logps/rejected': -410.1873474121094, 'referece_logps/chosen': -455.71240234375, 'logits/rejected': -0.23970995843410492, 'logits/chosen': -0.2918790876865387, 'epoch': 2.33}


 39%|███▉      | 6265/16104 [29:11:11<38:46:36, 14.19s/it]

 39%|███▉      | 6266/16104 [29:11:23<36:56:11, 13.52s/it]
{'loss': 0.4138, 'learning_rate': 1.3966679164394383e-06, 'rewards/chosen': -0.5286640524864197, 'rewards/rejected': -1.2017583847045898, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6730943322181702, 'policy_logps/rejected': -546.6746215820312, 'policy_logps/chosen': -473.0860900878906, 'referece_logps/rejected': -534.656982421875, 'referece_logps/chosen': -467.7994384765625, 'logits/rejected': -0.6545711755752563, 'logits/chosen': -0.5576501488685608, 'epoch': 2.33}

 39%|███▉      | 6267/16104 [29:11:37<37:53:02, 13.86s/it]

 39%|███▉      | 6268/16104 [29:11:55<41:08:47, 15.06s/it]

 39%|███▉      | 6269/16104 [29:12:14<44:31:22, 16.30s/it]

 39%|███▉      | 6270/16104 [29:12:33<46:51:44, 17.16s/it]

 39%|███▉      | 6271/16104 [29:12:46<43:16:51, 15.85s/it]


 39%|███▉      | 6273/16104 [29:13:23<46:00:56, 16.85s/it]
{'loss': 0.4395, 'learning_rate': 1.3953751394462393e-06, 'rewards/chosen': 0.04461194574832916, 'rewards/rejected': -1.0808689594268799, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1254810094833374, 'policy_logps/rejected': -430.03485107421875, 'policy_logps/chosen': -409.07958984375, 'referece_logps/rejected': -419.22613525390625, 'referece_logps/chosen': -409.52569580078125, 'logits/rejected': 0.19967810809612274, 'logits/chosen': 0.2603047788143158, 'epoch': 2.34}


 39%|███▉      | 6275/16104 [29:14:01<49:14:29, 18.04s/it]

 39%|███▉      | 6276/16104 [29:14:17<47:44:20, 17.49s/it]
{'loss': 0.4439, 'learning_rate': 1.3948208521095597e-06, 'rewards/chosen': -1.2305214405059814, 'rewards/rejected': -1.573904275894165, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3433828353881836, 'policy_logps/rejected': -402.4975891113281, 'policy_logps/chosen': -254.6291961669922, 'referece_logps/rejected': -386.758544921875, 'referece_logps/chosen': -242.32400512695312, 'logits/rejected': 0.35578715801239014, 'logits/chosen': 0.3505675196647644, 'epoch': 2.34}


 39%|███▉      | 6278/16104 [29:14:49<44:42:17, 16.38s/it]
{'loss': 0.4736, 'learning_rate': 1.3944512473499436e-06, 'rewards/chosen': -0.34173011779785156, 'rewards/rejected': -1.8209179639816284, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4791878461837769, 'policy_logps/rejected': -369.3572082519531, 'policy_logps/chosen': -439.6387023925781, 'referece_logps/rejected': -351.14801025390625, 'referece_logps/chosen': -436.22137451171875, 'logits/rejected': -0.504835844039917, 'logits/chosen': -0.5515888333320618, 'epoch': 2.34}

 39%|███▉      | 6279/16104 [29:15:02<42:20:10, 15.51s/it]

 39%|███▉      | 6280/16104 [29:15:23<46:57:54, 17.21s/it]

 39%|███▉      | 6281/16104 [29:15:34<41:49:56, 15.33s/it]


 39%|███▉      | 6283/16104 [29:16:05<42:49:00, 15.70s/it]
{'loss': 0.6331, 'learning_rate': 1.3935269563472588e-06, 'rewards/chosen': 0.14388293027877808, 'rewards/rejected': -0.19696159660816193, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3408445119857788, 'policy_logps/rejected': -527.4974365234375, 'policy_logps/chosen': -623.0784912109375, 'referece_logps/rejected': -525.52783203125, 'referece_logps/chosen': -624.5172729492188, 'logits/rejected': 0.4677906334400177, 'logits/chosen': 0.4465830326080322, 'epoch': 2.34}


 39%|███▉      | 6285/16104 [29:16:39<45:04:14, 16.52s/it]
{'loss': 0.5394, 'learning_rate': 1.393157128461762e-06, 'rewards/chosen': -0.19750568270683289, 'rewards/rejected': -1.0360759496688843, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8385703563690186, 'policy_logps/rejected': -383.02618408203125, 'policy_logps/chosen': -429.39422607421875, 'referece_logps/rejected': -372.6654357910156, 'referece_logps/chosen': -427.419189453125, 'logits/rejected': 0.520326554775238, 'logits/chosen': 0.46855300664901733, 'epoch': 2.34}


 39%|███▉      | 6287/16104 [29:17:13<46:29:58, 17.05s/it]
{'loss': 0.5454, 'learning_rate': 1.3927872369606358e-06, 'rewards/chosen': 0.19932174682617188, 'rewards/rejected': -1.4001694917678833, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5994913578033447, 'policy_logps/rejected': -530.9141845703125, 'policy_logps/chosen': -428.179931640625, 'referece_logps/rejected': -516.9124755859375, 'referece_logps/chosen': -430.17315673828125, 'logits/rejected': -0.37571513652801514, 'logits/chosen': -0.35950514674186707, 'epoch': 2.34}


 39%|███▉      | 6289/16104 [29:17:49<47:55:55, 17.58s/it]
{'loss': 0.4326, 'learning_rate': 1.3924172819037322e-06, 'rewards/chosen': 0.43530693650245667, 'rewards/rejected': -1.9946002960205078, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4299070835113525, 'policy_logps/rejected': -439.23883056640625, 'policy_logps/chosen': -519.55810546875, 'referece_logps/rejected': -419.29278564453125, 'referece_logps/chosen': -523.9111328125, 'logits/rejected': -0.21057292819023132, 'logits/chosen': -0.28192758560180664, 'epoch': 2.34}

 39%|███▉      | 6290/16104 [29:18:02<44:12:14, 16.22s/it]

 39%|███▉      | 6291/16104 [29:18:18<44:03:55, 16.17s/it]

 39%|███▉      | 6292/16104 [29:18:38<47:16:44, 17.35s/it]


 39%|███▉      | 6294/16104 [29:19:09<44:46:13, 16.43s/it]
{'loss': 0.5225, 'learning_rate': 1.3914921165978095e-06, 'rewards/chosen': -0.15187521278858185, 'rewards/rejected': -1.1226869821548462, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9708119630813599, 'policy_logps/rejected': -383.7554626464844, 'policy_logps/chosen': -412.7996826171875, 'referece_logps/rejected': -372.52862548828125, 'referece_logps/chosen': -411.28094482421875, 'logits/rejected': 0.21960964798927307, 'logits/chosen': 0.25633057951927185, 'epoch': 2.35}

 39%|███▉      | 6295/16104 [29:19:30<48:49:40, 17.92s/it]

 39%|███▉      | 6296/16104 [29:19:47<47:51:15, 17.56s/it]

 39%|███▉      | 6297/16104 [29:20:07<49:57:01, 18.34s/it]
{'loss': 0.4465, 'learning_rate': 1.3909368273157186e-06, 'rewards/chosen': -0.1075124740600586, 'rewards/rejected': -1.7392761707305908, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6317635774612427, 'policy_logps/rejected': -437.1799011230469, 'policy_logps/chosen': -412.9721374511719, 'referece_logps/rejected': -419.7871398925781, 'referece_logps/chosen': -411.89697265625, 'logits/rejected': -0.596908688545227, 'logits/chosen': -0.338047057390213, 'epoch': 2.35}

 39%|███▉      | 6298/16104 [29:20:24<48:58:05, 17.98s/it]

 39%|███▉      | 6299/16104 [29:20:41<47:55:31, 17.60s/it]

 39%|███▉      | 6300/16104 [29:20:58<47:39:31, 17.50s/it]

 39%|███▉      | 6301/16104 [29:21:10<42:35:24, 15.64s/it]

 39%|███▉      | 6302/16104 [29:21:29<45:51:30, 16.84s/it]

 39%|███▉      | 6303/16104 [29:21:40<40:59:40, 15.06s/it]

 39%|███▉      | 6304/16104 [29:21:59<43:46:02, 16.08s/it]

 39%|███▉      | 6305/16104 [29:22:15<43:32:39, 16.00s/it]

 39%|███▉      | 6306/16104 [29:22:35<47:20:21, 17.39s/it]

 39%|███▉      | 6307/16104 [29:22:55<49:18:03, 18.12s/it]

 39%|███▉      | 6308/16104 [29:23:15<50:38:00, 18.61s/it]

 39%|███▉      | 6309/16104 [29:23:35<51:34:39, 18.96s/it]

 39%|███▉      | 6310/16104 [29:23:48<47:16:10, 17.38s/it]

 39%|███▉      | 6311/16104 [29:24:05<46:36:57, 17.14s/it]

 39%|███▉      | 6312/16104 [29:24:23<47:27:52, 17.45s/it]

 39%|███▉      | 6313/16104 [29:24:42<49:04:09, 18.04s/it]

 39%|███▉      | 6314/16104 [29:24:56<45:30:57, 16.74s/it]

 39%|███▉      | 6315/16104 [29:25:09<42:17:20, 15.55s/it]

 39%|███▉      | 6316/16104 [29:25:21<39:29:40, 14.53s/it]


 39%|███▉      | 6318/16104 [29:25:55<44:11:50, 16.26s/it]

 39%|███▉      | 6319/16104 [29:26:14<45:56:19, 16.90s/it]

 39%|███▉      | 6320/16104 [29:26:29<44:29:55, 16.37s/it]

 39%|███▉      | 6321/16104 [29:26:41<40:45:45, 15.00s/it]

 39%|███▉      | 6322/16104 [29:26:57<42:06:59, 15.50s/it]

 39%|███▉      | 6323/16104 [29:27:15<43:38:19, 16.06s/it]

 39%|███▉      | 6324/16104 [29:27:31<43:45:47, 16.11s/it]

 39%|███▉      | 6325/16104 [29:27:53<48:07:22, 17.72s/it]

 39%|███▉      | 6326/16104 [29:28:14<51:14:33, 18.87s/it]

 39%|███▉      | 6327/16104 [29:28:32<50:06:11, 18.45s/it]

 39%|███▉      | 6328/16104 [29:28:46<46:56:23, 17.29s/it]

 39%|███▉      | 6329/16104 [29:29:06<49:00:55, 18.05s/it]

 39%|███▉      | 6330/16104 [29:29:29<53:04:42, 19.55s/it]

 39%|███▉      | 6331/16104 [29:29:44<49:44:02, 18.32s/it]

 39%|███▉      | 6332/16104 [29:30:04<51:01:55, 18.80s/it]

 39%|███▉      | 6333/16104 [29:30:22<49:43:15, 18.32s/it]

 39%|███▉      | 6334/16104 [29:30:36<46:31:30, 17.14s/it]

 39%|███▉      | 6335/16104 [29:30:50<43:48:49, 16.15s/it]

 39%|███▉      | 6336/16104 [29:31:06<44:09:44, 16.28s/it]

 39%|███▉      | 6337/16104 [29:31:25<45:56:26, 16.93s/it]

 39%|███▉      | 6338/16104 [29:31:39<43:23:00, 15.99s/it]

 39%|███▉      | 6339/16104 [29:31:58<46:28:07, 17.13s/it]

 39%|███▉      | 6340/16104 [29:32:14<45:01:44, 16.60s/it]

 39%|███▉      | 6341/16104 [29:32:25<40:34:29, 14.96s/it]

 39%|███▉      | 6342/16104 [29:32:40<40:39:45, 15.00s/it]

 39%|███▉      | 6343/16104 [29:32:56<41:18:29, 15.24s/it]

 39%|███▉      | 6344/16104 [29:33:07<38:22:20, 14.15s/it]

 39%|███▉      | 6345/16104 [29:33:26<42:20:10, 15.62s/it]

 39%|███▉      | 6346/16104 [29:33:40<40:56:17, 15.10s/it]

 39%|███▉      | 6347/16104 [29:34:02<45:57:53, 16.96s/it]

 39%|███▉      | 6348/16104 [29:34:17<44:57:01, 16.59s/it]

 39%|███▉      | 6349/16104 [29:34:35<45:49:19, 16.91s/it]

 39%|███▉      | 6350/16104 [29:34:55<48:09:43, 17.78s/it]

 39%|███▉      | 6351/16104 [29:35:05<42:21:36, 15.64s/it]

 39%|███▉      | 6352/16104 [29:35:22<43:00:37, 15.88s/it]

 39%|███▉      | 6353/16104 [29:35:35<40:32:48, 14.97s/it]

 39%|███▉      | 6354/16104 [29:35:54<44:20:10, 16.37s/it]

 39%|███▉      | 6355/16104 [29:36:15<47:37:18, 17.59s/it]

 39%|███▉      | 6356/16104 [29:36:36<50:41:52, 18.72s/it]

 39%|███▉      | 6357/16104 [29:36:48<45:09:17, 16.68s/it]

 39%|███▉      | 6358/16104 [29:37:05<45:27:37, 16.79s/it]

 39%|███▉      | 6359/16104 [29:37:16<40:26:49, 14.94s/it]

 39%|███▉      | 6360/16104 [29:37:27<37:01:39, 13.68s/it]

 39%|███▉      | 6361/16104 [29:37:46<41:44:02, 15.42s/it]

 40%|███▉      | 6362/16104 [29:37:59<39:49:27, 14.72s/it]

 40%|███▉      | 6363/16104 [29:38:12<38:06:38, 14.08s/it]

 40%|███▉      | 6364/16104 [29:38:22<35:19:17, 13.06s/it]

 40%|███▉      | 6365/16104 [29:38:45<43:01:08, 15.90s/it]

 40%|███▉      | 6366/16104 [29:39:03<44:36:08, 16.49s/it]

 40%|███▉      | 6367/16104 [29:39:21<46:24:18, 17.16s/it]

 40%|███▉      | 6368/16104 [29:39:41<48:20:26, 17.87s/it]

 40%|███▉      | 6369/16104 [29:40:01<50:13:09, 18.57s/it]

 40%|███▉      | 6370/16104 [29:40:17<48:00:48, 17.76s/it]

 40%|███▉      | 6371/16104 [29:40:31<44:59:49, 16.64s/it]

 40%|███▉      | 6372/16104 [29:40:51<47:23:24, 17.53s/it]

 40%|███▉      | 6373/16104 [29:41:05<44:53:50, 16.61s/it]

 40%|███▉      | 6374/16104 [29:41:25<47:29:22, 17.57s/it]

 40%|███▉      | 6375/16104 [29:41:38<43:40:13, 16.16s/it]

 40%|███▉      | 6376/16104 [29:41:50<40:41:44, 15.06s/it]

 40%|███▉      | 6377/16104 [29:42:10<44:36:52, 16.51s/it]

 40%|███▉      | 6378/16104 [29:42:28<45:25:21, 16.81s/it]

 40%|███▉      | 6379/16104 [29:42:48<47:54:03, 17.73s/it]

 40%|███▉      | 6380/16104 [29:43:03<45:53:23, 16.99s/it]

 40%|███▉      | 6381/16104 [29:43:22<47:56:57, 17.75s/it]

 40%|███▉      | 6382/16104 [29:43:34<42:41:30, 15.81s/it]

 40%|███▉      | 6383/16104 [29:43:53<45:37:31, 16.90s/it]

 40%|███▉      | 6384/16104 [29:44:05<41:10:57, 15.25s/it]

 40%|███▉      | 6385/16104 [29:44:16<37:46:00, 13.99s/it]

 40%|███▉      | 6386/16104 [29:44:27<35:44:28, 13.24s/it]

 40%|███▉      | 6387/16104 [29:44:38<33:42:29, 12.49s/it]

 40%|███▉      | 6388/16104 [29:44:57<38:53:23, 14.41s/it]

 40%|███▉      | 6389/16104 [29:45:08<35:58:28, 13.33s/it]

 40%|███▉      | 6390/16104 [29:45:20<35:30:35, 13.16s/it]

 40%|███▉      | 6391/16104 [29:45:36<37:44:12, 13.99s/it]

 40%|███▉      | 6392/16104 [29:45:56<42:03:15, 15.59s/it]

 40%|███▉      | 6393/16104 [29:46:10<41:16:33, 15.30s/it]

 40%|███▉      | 6394/16104 [29:46:21<37:33:27, 13.92s/it]

 40%|███▉      | 6395/16104 [29:46:39<40:44:33, 15.11s/it]

 40%|███▉      | 6396/16104 [29:46:57<43:13:25, 16.03s/it]

 40%|███▉      | 6397/16104 [29:47:16<45:58:42, 17.05s/it]

 40%|███▉      | 6398/16104 [29:47:36<47:59:58, 17.80s/it]

 40%|███▉      | 6399/16104 [29:47:50<44:49:25, 16.63s/it]

 40%|███▉      | 6400/16104 [29:48:12<49:26:33, 18.34s/it]

 40%|███▉      | 6401/16104 [29:48:28<47:33:19, 17.64s/it]

 40%|███▉      | 6402/16104 [29:48:41<43:16:56, 16.06s/it]

 40%|███▉      | 6403/16104 [29:48:54<41:00:58, 15.22s/it]

 40%|███▉      | 6404/16104 [29:49:11<42:18:56, 15.70s/it]

 40%|███▉      | 6405/16104 [29:49:26<41:43:42, 15.49s/it]

 40%|███▉      | 6406/16104 [29:49:39<40:20:01, 14.97s/it]

 40%|███▉      | 6407/16104 [29:50:03<47:05:45, 17.48s/it]
{'loss': 0.4088, 'learning_rate': 1.3704795995338578e-06, 'rewards/chosen': -0.9207828640937805, 'rewards/rejected': -1.5608454942703247, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6400628089904785, 'policy_logps/rejected': -376.3039855957031, 'policy_logps/chosen': -397.84942626953125, 'referece_logps/rejected': -360.69549560546875, 'referece_logps/chosen': -388.6415710449219, 'logits/rejected': 0.23450641334056854, 'logits/chosen': 0.20841777324676514, 'epoch': 2.39}


 40%|███▉      | 6409/16104 [29:50:41<49:37:20, 18.43s/it]
{'loss': 0.381, 'learning_rate': 1.3701059410412773e-06, 'rewards/chosen': 0.017984583973884583, 'rewards/rejected': -1.4474501609802246, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4654349088668823, 'policy_logps/rejected': -601.4851684570312, 'policy_logps/chosen': -538.934814453125, 'referece_logps/rejected': -587.0107421875, 'referece_logps/chosen': -539.1146240234375, 'logits/rejected': 0.2755851447582245, 'logits/chosen': 0.38577568531036377, 'epoch': 2.39}


 40%|███▉      | 6411/16104 [29:51:19<50:02:02, 18.58s/it]

 40%|███▉      | 6412/16104 [29:51:38<50:22:10, 18.71s/it]

 40%|███▉      | 6413/16104 [29:51:56<49:57:44, 18.56s/it]

 40%|███▉      | 6414/16104 [29:52:16<51:13:30, 19.03s/it]

 40%|███▉      | 6415/16104 [29:52:37<52:43:39, 19.59s/it]
{'loss': 0.4333, 'learning_rate': 1.368984606490732e-06, 'rewards/chosen': -0.04357489198446274, 'rewards/rejected': -1.2148054838180542, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1712305545806885, 'policy_logps/rejected': -292.2379150390625, 'policy_logps/chosen': -309.2337341308594, 'referece_logps/rejected': -280.08984375, 'referece_logps/chosen': -308.7980041503906, 'logits/rejected': 0.4505564868450165, 'logits/chosen': 0.45001456141471863, 'epoch': 2.39}


 40%|███▉      | 6417/16104 [29:53:15<52:01:10, 19.33s/it]

 40%|███▉      | 6418/16104 [29:53:34<51:37:44, 19.19s/it]

 40%|███▉      | 6419/16104 [29:53:45<44:52:54, 16.68s/it]

 40%|███▉      | 6420/16104 [29:54:07<48:58:28, 18.21s/it]
[2024-04-06 21:28:04,002] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 40%|███▉      | 6421/16104 [29:54:26<49:26:49, 18.38s/it]

 40%|███▉      | 6422/16104 [29:54:42<48:05:38, 17.88s/it]

 40%|███▉      | 6423/16104 [29:54:58<46:33:26, 17.31s/it]
{'loss': 0.4822, 'learning_rate': 1.3674886581783195e-06, 'rewards/chosen': -0.5138541460037231, 'rewards/rejected': -0.8238360285758972, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3099818229675293, 'policy_logps/rejected': -374.05230712890625, 'policy_logps/chosen': -512.2318725585938, 'referece_logps/rejected': -365.8139343261719, 'referece_logps/chosen': -507.0933837890625, 'logits/rejected': 0.34376949071884155, 'logits/chosen': 0.2907620668411255, 'epoch': 2.39}


 40%|███▉      | 6425/16104 [29:55:33<46:12:46, 17.19s/it]

 40%|███▉      | 6426/16104 [29:55:53<48:05:17, 17.89s/it]

 40%|███▉      | 6427/16104 [29:56:12<48:57:42, 18.21s/it]

 40%|███▉      | 6428/16104 [29:56:29<48:09:29, 17.92s/it]

 40%|███▉      | 6429/16104 [29:56:42<44:30:58, 16.56s/it]

 40%|███▉      | 6430/16104 [29:56:59<44:34:54, 16.59s/it]
{'loss': 0.5647, 'learning_rate': 1.3661789228301596e-06, 'rewards/chosen': -0.15097028017044067, 'rewards/rejected': -0.9709181785583496, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8199479579925537, 'policy_logps/rejected': -377.8391418457031, 'policy_logps/chosen': -533.3673706054688, 'referece_logps/rejected': -368.1299743652344, 'referece_logps/chosen': -531.8577270507812, 'logits/rejected': -0.10590462386608124, 'logits/chosen': -0.33629530668258667, 'epoch': 2.4}


 40%|███▉      | 6432/16104 [29:57:33<45:50:31, 17.06s/it]

 40%|███▉      | 6433/16104 [29:57:53<48:06:31, 17.91s/it]

 40%|███▉      | 6434/16104 [29:58:07<45:04:13, 16.78s/it]

 40%|███▉      | 6435/16104 [29:58:27<47:37:18, 17.73s/it]

 40%|███▉      | 6436/16104 [29:58:43<46:02:55, 17.15s/it]

 40%|███▉      | 6437/16104 [29:59:01<46:36:40, 17.36s/it]

 40%|███▉      | 6438/16104 [29:59:17<45:54:21, 17.10s/it]

 40%|███▉      | 6439/16104 [29:59:35<46:10:57, 17.20s/it]

 40%|███▉      | 6440/16104 [29:59:51<45:12:14, 16.84s/it]

 40%|███▉      | 6441/16104 [30:00:05<43:17:11, 16.13s/it]
{'loss': 0.53, 'learning_rate': 1.364119301836359e-06, 'rewards/chosen': -0.3449811339378357, 'rewards/rejected': -1.1893012523651123, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8443200588226318, 'policy_logps/rejected': -295.7462158203125, 'policy_logps/chosen': -429.76495361328125, 'referece_logps/rejected': -283.85321044921875, 'referece_logps/chosen': -426.31512451171875, 'logits/rejected': -0.558167576789856, 'logits/chosen': -0.5723904371261597, 'epoch': 2.4}

 40%|████      | 6442/16104 [30:00:18<40:44:48, 15.18s/it]

 40%|████      | 6443/16104 [30:00:38<44:37:05, 16.63s/it]

 40%|████      | 6444/16104 [30:01:00<49:02:07, 18.27s/it]


 40%|████      | 6446/16104 [30:01:38<49:52:25, 18.59s/it]

 40%|████      | 6447/16104 [30:01:49<43:31:26, 16.23s/it]

 40%|████      | 6448/16104 [30:02:10<47:29:54, 17.71s/it]

 40%|████      | 6449/16104 [30:02:21<42:05:22, 15.69s/it]
{'loss': 0.4173, 'learning_rate': 1.3626202756585891e-06, 'rewards/chosen': -0.16823256015777588, 'rewards/rejected': -1.9049259424209595, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7366931438446045, 'policy_logps/rejected': -390.903076171875, 'policy_logps/chosen': -434.1246643066406, 'referece_logps/rejected': -371.85382080078125, 'referece_logps/chosen': -432.4423828125, 'logits/rejected': 0.15679217875003815, 'logits/chosen': 0.18684399127960205, 'epoch': 2.4}


 40%|████      | 6451/16104 [30:02:56<45:00:25, 16.79s/it]

 40%|████      | 6452/16104 [30:03:15<47:09:15, 17.59s/it]

 40%|████      | 6453/16104 [30:03:34<48:03:02, 17.92s/it]

 40%|████      | 6454/16104 [30:03:51<47:37:10, 17.76s/it]

 40%|████      | 6455/16104 [30:04:09<47:59:51, 17.91s/it]

 40%|████      | 6456/16104 [30:04:28<48:15:03, 18.00s/it]

 40%|████      | 6457/16104 [30:04:47<49:32:49, 18.49s/it]

 40%|████      | 6458/16104 [30:05:08<51:00:32, 19.04s/it]

 40%|████      | 6459/16104 [30:05:27<51:30:00, 19.22s/it]

 40%|████      | 6460/16104 [30:05:47<51:44:44, 19.32s/it]

 40%|████      | 6461/16104 [30:06:04<49:37:22, 18.53s/it]

 40%|████      | 6462/16104 [30:06:24<51:09:36, 19.10s/it]

 40%|████      | 6463/16104 [30:06:36<45:25:55, 16.96s/it]

 40%|████      | 6464/16104 [30:06:48<41:22:45, 15.45s/it]
{'loss': 0.3868, 'learning_rate': 1.359807074288598e-06, 'rewards/chosen': -0.3636941909790039, 'rewards/rejected': -1.41584050655365, 'rewards/accuracies': 0.75, 'rewards/margins': 1.052146315574646, 'policy_logps/rejected': -361.1714782714844, 'policy_logps/chosen': -322.2335205078125, 'referece_logps/rejected': -347.01312255859375, 'referece_logps/chosen': -318.5965270996094, 'logits/rejected': 0.32840025424957275, 'logits/chosen': 0.3963637053966522, 'epoch': 2.41}

 40%|████      | 6465/16104 [30:07:05<42:23:57, 15.84s/it]

 40%|████      | 6466/16104 [30:07:23<44:07:23, 16.48s/it]


 40%|████      | 6468/16104 [30:07:49<39:51:04, 14.89s/it]

 40%|████      | 6469/16104 [30:08:04<39:26:28, 14.74s/it]

 40%|████      | 6470/16104 [30:08:16<37:22:23, 13.97s/it]
{'loss': 0.5748, 'learning_rate': 1.358680875351615e-06, 'rewards/chosen': 0.09442003071308136, 'rewards/rejected': -0.5206997394561768, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6151196956634521, 'policy_logps/rejected': -438.4771728515625, 'policy_logps/chosen': -398.603515625, 'referece_logps/rejected': -433.2701721191406, 'referece_logps/chosen': -399.5477600097656, 'logits/rejected': -0.04718635231256485, 'logits/chosen': 0.07135356962680817, 'epoch': 2.41}

 40%|████      | 6471/16104 [30:08:27<34:48:35, 13.01s/it]


 40%|████      | 6473/16104 [30:08:49<32:13:50, 12.05s/it]

 40%|████      | 6474/16104 [30:09:01<32:07:16, 12.01s/it]

 40%|████      | 6475/16104 [30:09:17<35:33:13, 13.29s/it]

 40%|████      | 6476/16104 [30:09:37<40:44:19, 15.23s/it]

 40%|████      | 6477/16104 [30:09:50<38:31:16, 14.40s/it]

 40%|████      | 6478/16104 [30:10:06<39:56:39, 14.94s/it]
{'loss': 0.5038, 'learning_rate': 1.3571784645328785e-06, 'rewards/chosen': -0.1999395191669464, 'rewards/rejected': -1.3161512613296509, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1162116527557373, 'policy_logps/rejected': -374.16314697265625, 'policy_logps/chosen': -441.5783386230469, 'referece_logps/rejected': -361.00164794921875, 'referece_logps/chosen': -439.5789794921875, 'logits/rejected': 0.31827783584594727, 'logits/chosen': 0.13476216793060303, 'epoch': 2.41}

 40%|████      | 6479/16104 [30:10:25<43:07:54, 16.13s/it]


 40%|████      | 6481/16104 [30:10:52<38:42:15, 14.48s/it]

 40%|████      | 6482/16104 [30:11:05<37:35:38, 14.07s/it]
{'loss': 0.5387, 'learning_rate': 1.356426912116239e-06, 'rewards/chosen': -0.2729848027229309, 'rewards/rejected': -0.7868667244911194, 'rewards/accuracies': 0.625, 'rewards/margins': 0.513882040977478, 'policy_logps/rejected': -428.2806396484375, 'policy_logps/chosen': -476.8192138671875, 'referece_logps/rejected': -420.4119873046875, 'referece_logps/chosen': -474.08941650390625, 'logits/rejected': -0.444627583026886, 'logits/chosen': -0.430937796831131, 'epoch': 2.42}


 40%|████      | 6484/16104 [30:11:42<44:31:10, 16.66s/it]
{'loss': 0.4425, 'learning_rate': 1.3560510493688884e-06, 'rewards/chosen': -0.1092403382062912, 'rewards/rejected': -1.2629505395889282, 'rewards/accuracies': 0.625, 'rewards/margins': 1.153710126876831, 'policy_logps/rejected': -365.7572021484375, 'policy_logps/chosen': -431.2642822265625, 'referece_logps/rejected': -353.127685546875, 'referece_logps/chosen': -430.171875, 'logits/rejected': 0.14530785381793976, 'logits/chosen': 0.14422598481178284, 'epoch': 2.42}


 40%|████      | 6486/16104 [30:12:09<39:35:36, 14.82s/it]

 40%|████      | 6487/16104 [30:12:26<41:33:00, 15.55s/it]
{'loss': 0.4519, 'learning_rate': 1.355487147245119e-06, 'rewards/chosen': -0.022983375936746597, 'rewards/rejected': -0.8222090005874634, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7992256283760071, 'policy_logps/rejected': -411.58172607421875, 'policy_logps/chosen': -389.03631591796875, 'referece_logps/rejected': -403.3596496582031, 'referece_logps/chosen': -388.8065185546875, 'logits/rejected': -0.6419241428375244, 'logits/chosen': -0.6034776568412781, 'epoch': 2.42}


 40%|████      | 6489/16104 [30:12:57<41:04:56, 15.38s/it]

 40%|████      | 6490/16104 [30:13:08<37:13:22, 13.94s/it]

 40%|████      | 6491/16104 [30:13:24<38:58:14, 14.59s/it]

 40%|████      | 6492/16104 [30:13:44<42:54:52, 16.07s/it]

 40%|████      | 6493/16104 [30:14:00<43:27:47, 16.28s/it]
{'loss': 0.4356, 'learning_rate': 1.3543589549405198e-06, 'rewards/chosen': 0.30630168318748474, 'rewards/rejected': -1.9400551319122314, 'rewards/accuracies': 1.0, 'rewards/margins': 2.246356725692749, 'policy_logps/rejected': -381.16595458984375, 'policy_logps/chosen': -511.79534912109375, 'referece_logps/rejected': -361.765380859375, 'referece_logps/chosen': -514.8583374023438, 'logits/rejected': 0.36319398880004883, 'logits/chosen': 0.24306580424308777, 'epoch': 2.42}


 40%|████      | 6495/16104 [30:14:31<43:01:44, 16.12s/it]
{'loss': 0.4074, 'learning_rate': 1.353982776082229e-06, 'rewards/chosen': -0.23084309697151184, 'rewards/rejected': -2.2141075134277344, 'rewards/accuracies': 0.875, 'rewards/margins': 1.983264446258545, 'policy_logps/rejected': -329.6926574707031, 'policy_logps/chosen': -404.5126037597656, 'referece_logps/rejected': -307.55157470703125, 'referece_logps/chosen': -402.2041931152344, 'logits/rejected': 0.13755440711975098, 'logits/chosen': 0.11245295405387878, 'epoch': 2.42}


 40%|████      | 6497/16104 [30:15:01<41:13:47, 15.45s/it]

 40%|████      | 6498/16104 [30:15:12<37:34:10, 14.08s/it]

 40%|████      | 6499/16104 [30:15:22<34:48:52, 13.05s/it]

 40%|████      | 6500/16104 [30:15:34<33:55:54, 12.72s/it]

 40%|████      | 6501/16104 [30:16:00<44:38:42, 16.74s/it]

 40%|████      | 6502/16104 [30:16:11<39:44:31, 14.90s/it]
{'loss': 0.507, 'learning_rate': 1.352665699421846e-06, 'rewards/chosen': 0.17265166342258453, 'rewards/rejected': -0.7259323000907898, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8985839486122131, 'policy_logps/rejected': -386.9534912109375, 'policy_logps/chosen': -548.9696044921875, 'referece_logps/rejected': -379.69415283203125, 'referece_logps/chosen': -550.6961669921875, 'logits/rejected': -0.549245297908783, 'logits/chosen': -0.5330877900123596, 'epoch': 2.42}


 40%|████      | 6504/16104 [30:16:34<35:01:32, 13.13s/it]

 40%|████      | 6505/16104 [30:16:48<36:01:51, 13.51s/it]

 40%|████      | 6506/16104 [30:17:01<35:09:41, 13.19s/it]
{'loss': 0.3823, 'learning_rate': 1.351912770168839e-06, 'rewards/chosen': 0.55758136510849, 'rewards/rejected': -1.1943769454956055, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7519583702087402, 'policy_logps/rejected': -681.6325073242188, 'policy_logps/chosen': -502.8135070800781, 'referece_logps/rejected': -669.688720703125, 'referece_logps/chosen': -508.3892822265625, 'logits/rejected': -0.16885404288768768, 'logits/chosen': -0.001054694876074791, 'epoch': 2.42}

 40%|████      | 6507/16104 [30:17:11<33:06:48, 12.42s/it]

 40%|████      | 6508/16104 [30:17:23<32:37:38, 12.24s/it]


 40%|████      | 6510/16104 [30:17:52<35:32:31, 13.34s/it]

 40%|████      | 6511/16104 [30:18:05<34:56:02, 13.11s/it]

 40%|████      | 6512/16104 [30:18:26<41:34:29, 15.60s/it]

 40%|████      | 6513/16104 [30:18:37<37:39:43, 14.14s/it]
{'loss': 0.598, 'learning_rate': 1.3505945962026064e-06, 'rewards/chosen': -0.5231168270111084, 'rewards/rejected': -0.9693658351898193, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4462489187717438, 'policy_logps/rejected': -389.4677734375, 'policy_logps/chosen': -357.774169921875, 'referece_logps/rejected': -379.77410888671875, 'referece_logps/chosen': -352.54302978515625, 'logits/rejected': -0.2739607095718384, 'logits/chosen': -0.3590083122253418, 'epoch': 2.43}

 40%|████      | 6514/16104 [30:18:52<38:21:19, 14.40s/it]

 40%|████      | 6515/16104 [30:19:10<41:09:26, 15.45s/it]


 40%|████      | 6517/16104 [30:19:48<46:35:52, 17.50s/it]

 40%|████      | 6518/16104 [30:20:03<44:39:29, 16.77s/it]

 40%|████      | 6519/16104 [30:20:24<48:09:24, 18.09s/it]

 40%|████      | 6520/16104 [30:20:42<48:07:57, 18.08s/it]

 40%|████      | 6521/16104 [30:20:57<45:22:39, 17.05s/it]
{'loss': 0.3471, 'learning_rate': 1.349087260891697e-06, 'rewards/chosen': 0.11875125765800476, 'rewards/rejected': -1.13154137134552, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2502927780151367, 'policy_logps/rejected': -431.7250061035156, 'policy_logps/chosen': -404.22015380859375, 'referece_logps/rejected': -420.40960693359375, 'referece_logps/chosen': -405.4076232910156, 'logits/rejected': 0.24641019105911255, 'logits/chosen': 0.2622632384300232, 'epoch': 2.43}


 41%|████      | 6523/16104 [30:21:29<43:21:33, 16.29s/it]

 41%|████      | 6524/16104 [30:21:51<47:23:25, 17.81s/it]

 41%|████      | 6525/16104 [30:22:07<46:23:03, 17.43s/it]

 41%|████      | 6526/16104 [30:22:29<49:57:27, 18.78s/it]

 41%|████      | 6527/16104 [30:22:41<44:38:04, 16.78s/it]

 41%|████      | 6528/16104 [30:22:57<43:48:21, 16.47s/it]

 41%|████      | 6529/16104 [30:23:13<43:14:41, 16.26s/it]

 41%|████      | 6530/16104 [30:23:25<40:01:35, 15.05s/it]

 41%|████      | 6531/16104 [30:23:43<42:12:29, 15.87s/it]

 41%|████      | 6532/16104 [30:23:53<38:05:54, 14.33s/it]

 41%|████      | 6533/16104 [30:24:11<40:42:41, 15.31s/it]
{'loss': 0.4078, 'learning_rate': 1.3468245646015034e-06, 'rewards/chosen': -0.39193859696388245, 'rewards/rejected': -2.288233518600464, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8962947130203247, 'policy_logps/rejected': -517.3374633789062, 'policy_logps/chosen': -477.7305908203125, 'referece_logps/rejected': -494.4551696777344, 'referece_logps/chosen': -473.81121826171875, 'logits/rejected': -1.0007948875427246, 'logits/chosen': -0.8612783551216125, 'epoch': 2.43}


 41%|████      | 6535/16104 [30:24:47<44:37:58, 16.79s/it]
{'loss': 0.3013, 'learning_rate': 1.346447251781694e-06, 'rewards/chosen': 0.34406164288520813, 'rewards/rejected': -1.4876415729522705, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8317031860351562, 'policy_logps/rejected': -409.71795654296875, 'policy_logps/chosen': -533.17919921875, 'referece_logps/rejected': -394.8415222167969, 'referece_logps/chosen': -536.6198120117188, 'logits/rejected': 0.03228607028722763, 'logits/chosen': 0.19523799419403076, 'epoch': 2.43}

 41%|████      | 6536/16104 [30:25:00<41:16:42, 15.53s/it]

 41%|████      | 6537/16104 [30:25:20<45:29:28, 17.12s/it]

 41%|████      | 6538/16104 [30:25:42<48:51:43, 18.39s/it]


 41%|████      | 6540/16104 [30:26:21<50:26:16, 18.99s/it]
{'loss': 0.4227, 'learning_rate': 1.3455037246135793e-06, 'rewards/chosen': -0.30853596329689026, 'rewards/rejected': -1.3579293489456177, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0493934154510498, 'policy_logps/rejected': -506.04443359375, 'policy_logps/chosen': -383.3748779296875, 'referece_logps/rejected': -492.46514892578125, 'referece_logps/chosen': -380.2895202636719, 'logits/rejected': -0.5987867116928101, 'logits/chosen': -0.38062331080436707, 'epoch': 2.44}

 41%|████      | 6541/16104 [30:26:32<44:24:20, 16.72s/it]

 41%|████      | 6542/16104 [30:26:50<45:17:47, 17.05s/it]

 41%|████      | 6543/16104 [30:27:05<43:28:13, 16.37s/it]

 41%|████      | 6544/16104 [30:27:20<42:46:21, 16.11s/it]

 41%|████      | 6545/16104 [30:27:32<39:13:14, 14.77s/it]

 41%|████      | 6546/16104 [30:27:44<37:17:49, 14.05s/it]


 41%|████      | 6548/16104 [30:28:20<43:15:06, 16.29s/it]
{'loss': 0.5046, 'learning_rate': 1.343993354777132e-06, 'rewards/chosen': -0.24601556360721588, 'rewards/rejected': -1.1875454187393188, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9415298700332642, 'policy_logps/rejected': -375.85369873046875, 'policy_logps/chosen': -491.97503662109375, 'referece_logps/rejected': -363.9782409667969, 'referece_logps/chosen': -489.5148620605469, 'logits/rejected': -0.675878643989563, 'logits/chosen': -0.644790768623352, 'epoch': 2.44}


 41%|████      | 6550/16104 [30:28:53<44:52:52, 16.91s/it]
{'loss': 0.4889, 'learning_rate': 1.3436156230138055e-06, 'rewards/chosen': -0.027768418192863464, 'rewards/rejected': -0.9038606882095337, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8760923147201538, 'policy_logps/rejected': -632.3530883789062, 'policy_logps/chosen': -629.2526245117188, 'referece_logps/rejected': -623.3145141601562, 'referece_logps/chosen': -628.9749755859375, 'logits/rejected': -0.6714849472045898, 'logits/chosen': -0.5997152328491211, 'epoch': 2.44}


 41%|████      | 6552/16104 [30:29:22<42:03:29, 15.85s/it]

 41%|████      | 6553/16104 [30:29:43<46:27:55, 17.51s/it]
{'loss': 0.4382, 'learning_rate': 1.3430489211389308e-06, 'rewards/chosen': 0.12804296612739563, 'rewards/rejected': -1.8151090145111084, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9431519508361816, 'policy_logps/rejected': -433.05535888671875, 'policy_logps/chosen': -401.8215026855469, 'referece_logps/rejected': -414.9042663574219, 'referece_logps/chosen': -403.1019592285156, 'logits/rejected': -0.27353358268737793, 'logits/chosen': -0.21982106566429138, 'epoch': 2.44}

 41%|████      | 6554/16104 [30:30:02<48:03:53, 18.12s/it]

 41%|████      | 6555/16104 [30:30:17<44:53:02, 16.92s/it]

 41%|████      | 6556/16104 [30:30:34<45:21:47, 17.10s/it]


 41%|████      | 6558/16104 [30:31:07<44:14:17, 16.68s/it]

 41%|████      | 6559/16104 [30:31:19<40:21:18, 15.22s/it]
{'loss': 0.3778, 'learning_rate': 1.3419151429181468e-06, 'rewards/chosen': -0.5210769772529602, 'rewards/rejected': -2.2088029384613037, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6877260208129883, 'policy_logps/rejected': -514.7471923828125, 'policy_logps/chosen': -528.2196044921875, 'referece_logps/rejected': -492.65911865234375, 'referece_logps/chosen': -523.0089111328125, 'logits/rejected': -0.5490084290504456, 'logits/chosen': -0.36649090051651, 'epoch': 2.44}

 41%|████      | 6560/16104 [30:31:38<43:38:10, 16.46s/it]


 41%|████      | 6562/16104 [30:32:19<48:54:50, 18.45s/it]
{'loss': 0.5056, 'learning_rate': 1.341348066985007e-06, 'rewards/chosen': -0.3328487277030945, 'rewards/rejected': -2.013371229171753, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6805224418640137, 'policy_logps/rejected': -542.889404296875, 'policy_logps/chosen': -381.7601318359375, 'referece_logps/rejected': -522.7557373046875, 'referece_logps/chosen': -378.431640625, 'logits/rejected': -0.21268554031848907, 'logits/chosen': -0.24234485626220703, 'epoch': 2.44}


 41%|████      | 6564/16104 [30:32:57<49:13:09, 18.57s/it]
{'loss': 0.3593, 'learning_rate': 1.3409699473094776e-06, 'rewards/chosen': -0.3119353652000427, 'rewards/rejected': -2.1113767623901367, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7994415760040283, 'policy_logps/rejected': -343.9417724609375, 'policy_logps/chosen': -262.20806884765625, 'referece_logps/rejected': -322.8280334472656, 'referece_logps/chosen': -259.08868408203125, 'logits/rejected': -0.2944733500480652, 'logits/chosen': -0.2979906499385834, 'epoch': 2.45}
[2024-04-06 22:07:14,363] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 41%|████      | 6566/16104 [30:33:30<45:29:00, 17.17s/it]
{'loss': 0.4209, 'learning_rate': 1.3405917724625778e-06, 'rewards/chosen': 0.1920040249824524, 'rewards/rejected': -0.9699438810348511, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1619479656219482, 'policy_logps/rejected': -347.6325988769531, 'policy_logps/chosen': -355.6723327636719, 'referece_logps/rejected': -337.9331359863281, 'referece_logps/chosen': -357.5924072265625, 'logits/rejected': -0.16228654980659485, 'logits/chosen': -0.1751987636089325, 'epoch': 2.45}
[2024-04-06 22:07:47,784] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 41%|████      | 6568/16104 [30:34:08<47:21:12, 17.88s/it]
{'loss': 0.4637, 'learning_rate': 1.3402135425054981e-06, 'rewards/chosen': -0.0061134472489356995, 'rewards/rejected': -1.013641595840454, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0075280666351318, 'policy_logps/rejected': -395.1486511230469, 'policy_logps/chosen': -328.3473205566406, 'referece_logps/rejected': -385.01220703125, 'referece_logps/chosen': -328.28619384765625, 'logits/rejected': -0.9153544306755066, 'logits/chosen': -0.8353108763694763, 'epoch': 2.45}


 41%|████      | 6570/16104 [30:34:31<38:48:24, 14.65s/it]

 41%|████      | 6571/16104 [30:34:46<38:39:50, 14.60s/it]
{'loss': 0.4422, 'learning_rate': 1.3396460943721708e-06, 'rewards/chosen': -0.7781882882118225, 'rewards/rejected': -1.685440182685852, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9072517156600952, 'policy_logps/rejected': -250.92965698242188, 'policy_logps/chosen': -473.72088623046875, 'referece_logps/rejected': -234.07525634765625, 'referece_logps/chosen': -465.93896484375, 'logits/rejected': -0.12143296003341675, 'logits/chosen': -0.16072191298007965, 'epoch': 2.45}

 41%|████      | 6572/16104 [30:35:01<39:22:33, 14.87s/it]

 41%|████      | 6573/16104 [30:35:12<36:23:28, 13.75s/it]

 41%|████      | 6574/16104 [30:35:26<36:33:49, 13.81s/it]


 41%|████      | 6576/16104 [30:36:06<44:31:25, 16.82s/it]
{'loss': 0.4526, 'learning_rate': 1.3387000727995263e-06, 'rewards/chosen': 0.1771177351474762, 'rewards/rejected': -0.9043369293212891, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0814546346664429, 'policy_logps/rejected': -367.4398498535156, 'policy_logps/chosen': -328.19219970703125, 'referece_logps/rejected': -358.3964538574219, 'referece_logps/chosen': -329.96337890625, 'logits/rejected': 0.009653136134147644, 'logits/chosen': -0.018930718302726746, 'epoch': 2.45}


 41%|████      | 6578/16104 [30:36:40<44:44:16, 16.91s/it]
{'loss': 0.5012, 'learning_rate': 1.3383215682097328e-06, 'rewards/chosen': -0.19199791550636292, 'rewards/rejected': -0.4596693515777588, 'rewards/accuracies': 0.75, 'rewards/margins': 0.26767146587371826, 'policy_logps/rejected': -576.6410522460938, 'policy_logps/chosen': -633.5790405273438, 'referece_logps/rejected': -572.0443115234375, 'referece_logps/chosen': -631.6591186523438, 'logits/rejected': -0.4007381796836853, 'logits/chosen': -0.23275257647037506, 'epoch': 2.45}
[2024-04-06 22:11:00,308] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 41%|████      | 6580/16104 [30:37:22<49:42:45, 18.79s/it]
[2024-04-06 22:11:19,052] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████      | 6581/16104 [30:37:44<52:29:40, 19.84s/it]
[2024-04-06 22:11:41,356] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████      | 6582/16104 [30:38:04<52:15:25, 19.76s/it]

 41%|████      | 6583/16104 [30:38:18<48:11:31, 18.22s/it]
{'loss': 0.4963, 'learning_rate': 1.3373750673693004e-06, 'rewards/chosen': -0.694951057434082, 'rewards/rejected': -1.588621973991394, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8936710953712463, 'policy_logps/rejected': -286.5512390136719, 'policy_logps/chosen': -456.7692565917969, 'referece_logps/rejected': -270.6650390625, 'referece_logps/chosen': -449.8197021484375, 'logits/rejected': -0.484110951423645, 'logits/chosen': -0.3249560594558716, 'epoch': 2.45}

 41%|████      | 6584/16104 [30:38:39<50:32:05, 19.11s/it]


 41%|████      | 6586/16104 [30:39:10<45:51:32, 17.35s/it]

 41%|████      | 6587/16104 [30:39:24<43:45:33, 16.55s/it]
{'loss': 0.5793, 'learning_rate': 1.336617620997394e-06, 'rewards/chosen': 0.07785225659608841, 'rewards/rejected': -0.8225722908973694, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9004244804382324, 'policy_logps/rejected': -356.94964599609375, 'policy_logps/chosen': -515.4024658203125, 'referece_logps/rejected': -348.723876953125, 'referece_logps/chosen': -516.1809692382812, 'logits/rejected': -0.02628568932414055, 'logits/chosen': 0.09579725563526154, 'epoch': 2.45}

 41%|████      | 6588/16104 [30:39:36<40:11:49, 15.21s/it]


 41%|████      | 6590/16104 [30:39:58<34:13:01, 12.95s/it]
{'loss': 0.6142, 'learning_rate': 1.33604939321543e-06, 'rewards/chosen': -0.614916980266571, 'rewards/rejected': -1.5994834899902344, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9845665693283081, 'policy_logps/rejected': -557.85107421875, 'policy_logps/chosen': -417.86773681640625, 'referece_logps/rejected': -541.8562622070312, 'referece_logps/chosen': -411.71856689453125, 'logits/rejected': -0.6228374242782593, 'logits/chosen': -0.645182728767395, 'epoch': 2.46}

 41%|████      | 6591/16104 [30:40:09<32:32:49, 12.32s/it]

 41%|████      | 6592/16104 [30:40:29<38:54:31, 14.73s/it]


 41%|████      | 6594/16104 [30:41:08<45:17:13, 17.14s/it]

 41%|████      | 6595/16104 [30:41:20<40:52:07, 15.47s/it]

 41%|████      | 6596/16104 [30:41:34<39:55:42, 15.12s/it]
{'loss': 0.5259, 'learning_rate': 1.334912570825893e-06, 'rewards/chosen': -0.825897216796875, 'rewards/rejected': -1.0714024305343628, 'rewards/accuracies': 0.375, 'rewards/margins': 0.245505228638649, 'policy_logps/rejected': -260.3785400390625, 'policy_logps/chosen': -493.7227783203125, 'referece_logps/rejected': -249.66453552246094, 'referece_logps/chosen': -485.4638366699219, 'logits/rejected': -0.37935757637023926, 'logits/chosen': -0.4181320369243622, 'epoch': 2.46}

 41%|████      | 6597/16104 [30:41:49<39:54:33, 15.11s/it]

 41%|████      | 6598/16104 [30:42:03<39:01:34, 14.78s/it]

 41%|████      | 6599/16104 [30:42:23<43:17:19, 16.40s/it]


 41%|████      | 6601/16104 [30:42:52<39:41:08, 15.03s/it]

 41%|████      | 6602/16104 [30:43:12<43:31:05, 16.49s/it]

 41%|████      | 6603/16104 [30:43:30<44:37:18, 16.91s/it]
{'loss': 0.4127, 'learning_rate': 1.3335856617290482e-06, 'rewards/chosen': -0.043926239013671875, 'rewards/rejected': -1.4323216676712036, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3883954286575317, 'policy_logps/rejected': -351.67144775390625, 'policy_logps/chosen': -592.30859375, 'referece_logps/rejected': -337.3482666015625, 'referece_logps/chosen': -591.8692626953125, 'logits/rejected': 0.3170802593231201, 'logits/chosen': 0.2956046462059021, 'epoch': 2.46}

 41%|████      | 6604/16104 [30:43:47<44:43:04, 16.95s/it]


 41%|████      | 6606/16104 [30:44:20<44:27:06, 16.85s/it]

 41%|████      | 6607/16104 [30:44:40<47:01:53, 17.83s/it]
{'loss': 0.4182, 'learning_rate': 1.3328271309197447e-06, 'rewards/chosen': 0.16989518702030182, 'rewards/rejected': -1.1189513206481934, 'rewards/accuracies': 1.0, 'rewards/margins': 1.288846492767334, 'policy_logps/rejected': -494.60687255859375, 'policy_logps/chosen': -531.97900390625, 'referece_logps/rejected': -483.4173278808594, 'referece_logps/chosen': -533.677978515625, 'logits/rejected': 0.5707467198371887, 'logits/chosen': 0.5909157991409302, 'epoch': 2.46}

 41%|████      | 6608/16104 [30:44:53<42:57:13, 16.28s/it]


 41%|████      | 6610/16104 [30:45:24<42:55:02, 16.27s/it]

 41%|████      | 6611/16104 [30:45:41<42:57:26, 16.29s/it]

 41%|████      | 6612/16104 [30:46:00<45:35:01, 17.29s/it]
{'loss': 0.4596, 'learning_rate': 1.3318786645380205e-06, 'rewards/chosen': -1.307087779045105, 'rewards/rejected': -2.246642589569092, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9395548105239868, 'policy_logps/rejected': -393.882080078125, 'policy_logps/chosen': -414.7041320800781, 'referece_logps/rejected': -371.4156494140625, 'referece_logps/chosen': -401.63323974609375, 'logits/rejected': 0.6817298531532288, 'logits/chosen': 0.6871609687805176, 'epoch': 2.46}


 41%|████      | 6614/16104 [30:46:30<43:28:25, 16.49s/it]
{'loss': 0.5191, 'learning_rate': 1.3314991839560234e-06, 'rewards/chosen': 0.1729322373867035, 'rewards/rejected': -0.8319675922393799, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0048998594284058, 'policy_logps/rejected': -434.01873779296875, 'policy_logps/chosen': -435.291259765625, 'referece_logps/rejected': -425.6990966796875, 'referece_logps/chosen': -437.02056884765625, 'logits/rejected': 0.21291446685791016, 'logits/chosen': 0.04372534155845642, 'epoch': 2.46}

 41%|████      | 6615/16104 [30:46:41<38:57:27, 14.78s/it]


 41%|████      | 6617/16104 [30:47:12<39:34:02, 15.01s/it]
{'loss': 0.4164, 'learning_rate': 1.330929862529218e-06, 'rewards/chosen': -1.1327950954437256, 'rewards/rejected': -1.8767110109329224, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7439157366752625, 'policy_logps/rejected': -347.48876953125, 'policy_logps/chosen': -327.324462890625, 'referece_logps/rejected': -328.72161865234375, 'referece_logps/chosen': -315.99652099609375, 'logits/rejected': -0.32194456458091736, 'logits/chosen': -0.2749413251876831, 'epoch': 2.47}

 41%|████      | 6618/16104 [30:47:23<36:26:58, 13.83s/it]


 41%|████      | 6620/16104 [30:47:50<35:29:43, 13.47s/it]

 41%|████      | 6621/16104 [30:48:08<38:50:39, 14.75s/it]
{'loss': 0.4104, 'learning_rate': 1.3301705799154644e-06, 'rewards/chosen': -0.09919704496860504, 'rewards/rejected': -2.083644151687622, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9844471216201782, 'policy_logps/rejected': -306.6983642578125, 'policy_logps/chosen': -339.406005859375, 'referece_logps/rejected': -285.8619384765625, 'referece_logps/chosen': -338.41400146484375, 'logits/rejected': -0.5802413821220398, 'logits/chosen': -0.44609490036964417, 'epoch': 2.47}

 41%|████      | 6622/16104 [30:48:27<42:05:14, 15.98s/it]

 41%|████      | 6623/16104 [30:48:45<43:51:26, 16.65s/it]


 41%|████      | 6625/16104 [30:49:19<43:46:07, 16.62s/it]
{'loss': 0.5246, 'learning_rate': 1.3294110836058956e-06, 'rewards/chosen': -0.6072863936424255, 'rewards/rejected': -1.4770997762680054, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8698132038116455, 'policy_logps/rejected': -486.8983154296875, 'policy_logps/chosen': -504.24737548828125, 'referece_logps/rejected': -472.1273193359375, 'referece_logps/chosen': -498.17449951171875, 'logits/rejected': -0.3785223960876465, 'logits/chosen': -0.480665922164917, 'epoch': 2.47}

 41%|████      | 6626/16104 [30:49:32<41:05:28, 15.61s/it]

 41%|████      | 6627/16104 [30:49:44<38:17:58, 14.55s/it]

 41%|████      | 6628/16104 [30:50:00<39:16:34, 14.92s/it]

 41%|████      | 6629/16104 [30:50:18<41:59:01, 15.95s/it]

 41%|████      | 6630/16104 [30:50:34<41:50:15, 15.90s/it]


 41%|████      | 6632/16104 [30:50:57<35:43:23, 13.58s/it]

 41%|████      | 6633/16104 [30:51:11<36:00:12, 13.69s/it]
{'loss': 0.4805, 'learning_rate': 1.32789145186572e-06, 'rewards/chosen': -0.04166048765182495, 'rewards/rejected': -0.4251296818256378, 'rewards/accuracies': 0.75, 'rewards/margins': 0.38346919417381287, 'policy_logps/rejected': -435.6361083984375, 'policy_logps/chosen': -406.3515319824219, 'referece_logps/rejected': -431.3847961425781, 'referece_logps/chosen': -405.9349365234375, 'logits/rejected': 0.15841928124427795, 'logits/chosen': 0.24964939057826996, 'epoch': 2.47}

 41%|████      | 6634/16104 [30:51:31<40:46:48, 15.50s/it]

 41%|████      | 6635/16104 [30:51:51<44:25:51, 16.89s/it]

 41%|████      | 6636/16104 [30:52:11<46:40:13, 17.75s/it]

 41%|████      | 6637/16104 [30:52:28<46:39:35, 17.74s/it]

 41%|████      | 6638/16104 [30:52:51<50:26:52, 19.19s/it]

 41%|████      | 6639/16104 [30:53:06<47:24:26, 18.03s/it]

 41%|████      | 6640/16104 [30:53:26<48:42:30, 18.53s/it]

 41%|████      | 6641/16104 [30:53:42<47:11:20, 17.95s/it]

 41%|████      | 6642/16104 [30:54:00<46:59:15, 17.88s/it]

 41%|████▏     | 6643/16104 [30:54:17<45:48:21, 17.43s/it]

 41%|████▏     | 6644/16104 [30:54:32<44:36:59, 16.98s/it]

 41%|████▏     | 6645/16104 [30:54:44<40:11:21, 15.30s/it]

 41%|████▏     | 6646/16104 [30:55:00<41:11:26, 15.68s/it]

 41%|████▏     | 6647/16104 [30:55:18<42:29:32, 16.18s/it]

 41%|████▏     | 6648/16104 [30:55:34<42:45:45, 16.28s/it]


 41%|████▏     | 6650/16104 [30:56:09<43:56:35, 16.73s/it]
{'loss': 0.4502, 'learning_rate': 1.3246594207635023e-06, 'rewards/chosen': -0.2283906638622284, 'rewards/rejected': -1.3630160093307495, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1346254348754883, 'policy_logps/rejected': -484.22943115234375, 'policy_logps/chosen': -481.65618896484375, 'referece_logps/rejected': -470.59930419921875, 'referece_logps/chosen': -479.372314453125, 'logits/rejected': -0.6560665369033813, 'logits/chosen': -0.6064305305480957, 'epoch': 2.48}

 41%|████▏     | 6651/16104 [30:56:30<46:47:43, 17.82s/it]

 41%|████▏     | 6652/16104 [30:56:40<41:12:57, 15.70s/it]

 41%|████▏     | 6653/16104 [30:57:01<44:57:04, 17.12s/it]

 41%|████▏     | 6654/16104 [30:57:19<45:31:53, 17.35s/it]

 41%|████▏     | 6655/16104 [30:57:38<47:12:50, 17.99s/it]

 41%|████▏     | 6656/16104 [30:57:56<46:54:12, 17.87s/it]

 41%|████▏     | 6657/16104 [30:58:12<45:55:27, 17.50s/it]


 41%|████▏     | 6659/16104 [30:58:49<47:53:12, 18.25s/it]
{'loss': 0.6418, 'learning_rate': 1.3229468065071182e-06, 'rewards/chosen': 0.0658574104309082, 'rewards/rejected': -0.6032936573028564, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6691510081291199, 'policy_logps/rejected': -648.0715942382812, 'policy_logps/chosen': -514.6832885742188, 'referece_logps/rejected': -642.0386352539062, 'referece_logps/chosen': -515.3418579101562, 'logits/rejected': -0.7554187774658203, 'logits/chosen': -0.5538409352302551, 'epoch': 2.48}

 41%|████▏     | 6660/16104 [30:59:03<44:08:08, 16.82s/it]

 41%|████▏     | 6661/16104 [30:59:15<40:13:12, 15.33s/it]

 41%|████▏     | 6662/16104 [30:59:26<37:17:21, 14.22s/it]

 41%|████▏     | 6663/16104 [30:59:39<35:46:12, 13.64s/it]

 41%|████▏     | 6664/16104 [30:59:53<35:52:09, 13.68s/it]

 41%|████▏     | 6665/16104 [31:00:05<34:42:17, 13.24s/it]

 41%|████▏     | 6666/16104 [31:00:19<35:39:47, 13.60s/it]


 41%|████▏     | 6668/16104 [31:00:47<36:41:59, 14.00s/it]
{'loss': 0.3744, 'learning_rate': 1.3212331340852757e-06, 'rewards/chosen': -0.6439573764801025, 'rewards/rejected': -3.4199888706207275, 'rewards/accuracies': 1.0, 'rewards/margins': 2.776031494140625, 'policy_logps/rejected': -556.7911987304688, 'policy_logps/chosen': -496.1231994628906, 'referece_logps/rejected': -522.5913696289062, 'referece_logps/chosen': -489.68359375, 'logits/rejected': -0.22085009515285492, 'logits/chosen': -0.1852802187204361, 'epoch': 2.48}

 41%|████▏     | 6669/16104 [31:00:58<34:08:48, 13.03s/it]

 41%|████▏     | 6670/16104 [31:01:09<32:25:20, 12.37s/it]

 41%|████▏     | 6671/16104 [31:01:20<31:32:40, 12.04s/it]

 41%|████▏     | 6672/16104 [31:01:39<36:34:43, 13.96s/it]

 41%|████▏     | 6673/16104 [31:01:51<35:04:42, 13.39s/it]

 41%|████▏     | 6674/16104 [31:02:07<37:03:35, 14.15s/it]
[2024-04-06 22:36:25,324] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████▏     | 6675/16104 [31:02:28<42:39:22, 16.29s/it]
[2024-04-06 22:36:45,294] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████▏     | 6676/16104 [31:02:48<45:32:45, 17.39s/it]
[2024-04-06 22:37:05,614] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 41%|████▏     | 6677/16104 [31:03:08<47:50:31, 18.27s/it]


 41%|████▏     | 6679/16104 [31:03:30<37:43:47, 14.41s/it]
{'loss': 0.4393, 'learning_rate': 1.3191372167453078e-06, 'rewards/chosen': -0.5349151492118835, 'rewards/rejected': -1.2956516742706299, 'rewards/accuracies': 0.75, 'rewards/margins': 0.760736346244812, 'policy_logps/rejected': -466.9862365722656, 'policy_logps/chosen': -414.1321105957031, 'referece_logps/rejected': -454.02972412109375, 'referece_logps/chosen': -408.782958984375, 'logits/rejected': -0.5219436287879944, 'logits/chosen': -0.18744440376758575, 'epoch': 2.49}

 41%|████▏     | 6680/16104 [31:03:40<34:46:55, 13.29s/it]


 41%|████▏     | 6682/16104 [31:04:12<39:05:51, 14.94s/it]
{'loss': 0.5889, 'learning_rate': 1.3185653313905496e-06, 'rewards/chosen': -0.9887346029281616, 'rewards/rejected': -2.191925048828125, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2031904458999634, 'policy_logps/rejected': -508.3570556640625, 'policy_logps/chosen': -316.7162170410156, 'referece_logps/rejected': -486.4377746582031, 'referece_logps/chosen': -306.8288879394531, 'logits/rejected': -0.7452629208564758, 'logits/chosen': -0.5702823996543884, 'epoch': 2.49}

 41%|████▏     | 6683/16104 [31:04:28<39:46:43, 15.20s/it]

 42%|████▏     | 6684/16104 [31:04:48<43:59:04, 16.81s/it]

 42%|████▏     | 6685/16104 [31:05:11<48:32:34, 18.55s/it]

 42%|████▏     | 6686/16104 [31:05:31<49:44:19, 19.01s/it]

 42%|████▏     | 6687/16104 [31:05:52<51:16:22, 19.60s/it]

 42%|████▏     | 6688/16104 [31:06:10<50:00:18, 19.12s/it]

 42%|████▏     | 6689/16104 [31:06:26<48:03:00, 18.37s/it]

 42%|████▏     | 6690/16104 [31:06:46<49:10:45, 18.81s/it]

 42%|████▏     | 6691/16104 [31:07:07<51:06:01, 19.54s/it]

 42%|████▏     | 6692/16104 [31:07:24<48:28:41, 18.54s/it]

 42%|████▏     | 6693/16104 [31:07:44<49:35:53, 18.97s/it]

 42%|████▏     | 6694/16104 [31:08:03<50:09:28, 19.19s/it]

 42%|████▏     | 6695/16104 [31:08:19<47:15:55, 18.08s/it]

 42%|████▏     | 6696/16104 [31:08:34<44:47:09, 17.14s/it]

 42%|████▏     | 6697/16104 [31:08:47<41:34:26, 15.91s/it]


 42%|████▏     | 6699/16104 [31:09:22<44:10:10, 16.91s/it]
{'loss': 0.4785, 'learning_rate': 1.3153224631224771e-06, 'rewards/chosen': -0.7215843200683594, 'rewards/rejected': -1.0626981258392334, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3411138355731964, 'policy_logps/rejected': -582.1990356445312, 'policy_logps/chosen': -483.082763671875, 'referece_logps/rejected': -571.572021484375, 'referece_logps/chosen': -475.866943359375, 'logits/rejected': 0.19284746050834656, 'logits/chosen': 0.20434072613716125, 'epoch': 2.5}

 42%|████▏     | 6700/16104 [31:09:41<45:34:12, 17.44s/it]

 42%|████▏     | 6701/16104 [31:09:58<45:44:23, 17.51s/it]

 42%|████▏     | 6702/16104 [31:10:15<44:50:50, 17.17s/it]

 42%|████▏     | 6703/16104 [31:10:36<47:40:42, 18.26s/it]

 42%|████▏     | 6704/16104 [31:10:49<43:45:55, 16.76s/it]

 42%|████▏     | 6705/16104 [31:11:09<46:47:42, 17.92s/it]


 42%|████▏     | 6707/16104 [31:11:45<47:37:20, 18.24s/it]

 42%|████▏     | 6708/16104 [31:12:06<49:17:57, 18.89s/it]

 42%|████▏     | 6709/16104 [31:12:26<50:03:13, 19.18s/it]

 42%|████▏     | 6710/16104 [31:12:44<49:11:47, 18.85s/it]

 42%|████▏     | 6711/16104 [31:13:03<49:54:49, 19.13s/it]

 42%|████▏     | 6712/16104 [31:13:19<47:05:36, 18.05s/it]

 42%|████▏     | 6713/16104 [31:13:39<48:28:50, 18.58s/it]

 42%|████▏     | 6714/16104 [31:13:56<47:18:05, 18.13s/it]

 42%|████▏     | 6715/16104 [31:14:16<48:40:12, 18.66s/it]

 42%|████▏     | 6716/16104 [31:14:28<43:51:06, 16.82s/it]

 42%|████▏     | 6717/16104 [31:14:48<46:12:51, 17.72s/it]

 42%|████▏     | 6718/16104 [31:15:01<42:18:03, 16.22s/it]

 42%|████▏     | 6719/16104 [31:15:18<43:18:04, 16.61s/it]

 42%|████▏     | 6720/16104 [31:15:30<39:25:03, 15.12s/it]

 42%|████▏     | 6721/16104 [31:15:44<38:20:09, 14.71s/it]

 42%|████▏     | 6722/16104 [31:15:59<38:31:38, 14.78s/it]

 42%|████▏     | 6723/16104 [31:16:13<38:00:15, 14.58s/it]

 42%|████▏     | 6724/16104 [31:16:24<34:59:52, 13.43s/it]

 42%|████▏     | 6725/16104 [31:16:38<35:34:58, 13.66s/it]

 42%|████▏     | 6726/16104 [31:16:49<33:40:42, 12.93s/it]

 42%|████▏     | 6727/16104 [31:17:08<38:50:13, 14.91s/it]

 42%|████▏     | 6728/16104 [31:17:28<42:29:49, 16.32s/it]

 42%|████▏     | 6729/16104 [31:17:41<40:05:49, 15.40s/it]

 42%|████▏     | 6730/16104 [31:18:01<43:20:27, 16.64s/it]

 42%|████▏     | 6731/16104 [31:18:24<48:25:46, 18.60s/it]

 42%|████▏     | 6732/16104 [31:18:43<48:59:42, 18.82s/it]

 42%|████▏     | 6733/16104 [31:19:03<49:54:16, 19.17s/it]

 42%|████▏     | 6734/16104 [31:19:22<49:13:05, 18.91s/it]

 42%|████▏     | 6735/16104 [31:19:37<46:26:59, 17.85s/it]

 42%|████▏     | 6736/16104 [31:19:50<43:00:24, 16.53s/it]

 42%|████▏     | 6737/16104 [31:20:11<46:03:28, 17.70s/it]

 42%|████▏     | 6738/16104 [31:20:28<45:18:45, 17.42s/it]

 42%|████▏     | 6739/16104 [31:20:50<48:53:35, 18.80s/it]

 42%|████▏     | 6740/16104 [31:21:05<45:54:13, 17.65s/it]

 42%|████▏     | 6741/16104 [31:21:23<46:13:42, 17.77s/it]

 42%|████▏     | 6742/16104 [31:21:39<45:22:23, 17.45s/it]

 42%|████▏     | 6743/16104 [31:21:59<47:05:20, 18.11s/it]
{'loss': 0.487, 'learning_rate': 1.3069121326659918e-06, 'rewards/chosen': -0.7663863301277161, 'rewards/rejected': -1.591050624847412, 'rewards/accuracies': 0.75, 'rewards/margins': 0.824664294719696, 'policy_logps/rejected': -476.7102966308594, 'policy_logps/chosen': -321.0520324707031, 'referece_logps/rejected': -460.7998046875, 'referece_logps/chosen': -313.38818359375, 'logits/rejected': -0.2809152901172638, 'logits/chosen': -0.048231616616249084, 'epoch': 2.51}


 42%|████▏     | 6745/16104 [31:22:41<50:39:11, 19.48s/it]

 42%|████▏     | 6746/16104 [31:22:56<46:55:18, 18.05s/it]

 42%|████▏     | 6747/16104 [31:23:16<48:18:05, 18.58s/it]
{'loss': 0.3682, 'learning_rate': 1.3061463554119735e-06, 'rewards/chosen': -0.14708349108695984, 'rewards/rejected': -2.2035651206970215, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0564815998077393, 'policy_logps/rejected': -470.8762512207031, 'policy_logps/chosen': -482.0757751464844, 'referece_logps/rejected': -448.840576171875, 'referece_logps/chosen': -480.60498046875, 'logits/rejected': 0.05271410942077637, 'logits/chosen': 0.03739216923713684, 'epoch': 2.51}


 42%|████▏     | 6749/16104 [31:23:52<47:16:23, 18.19s/it]

 42%|████▏     | 6750/16104 [31:24:03<41:33:39, 16.00s/it]
{'loss': 0.4788, 'learning_rate': 1.3055718924106097e-06, 'rewards/chosen': -0.09374560415744781, 'rewards/rejected': -2.3220739364624023, 'rewards/accuracies': 0.75, 'rewards/margins': 2.228328227996826, 'policy_logps/rejected': -255.26515197753906, 'policy_logps/chosen': -448.88848876953125, 'referece_logps/rejected': -232.04440307617188, 'referece_logps/chosen': -447.9510192871094, 'logits/rejected': -0.19660136103630066, 'logits/chosen': -0.40762436389923096, 'epoch': 2.51}


 42%|████▏     | 6752/16104 [31:24:36<42:01:45, 16.18s/it]

 42%|████▏     | 6753/16104 [31:24:56<44:33:12, 17.15s/it]

 42%|████▏     | 6754/16104 [31:25:18<48:24:13, 18.64s/it]

 42%|████▏     | 6755/16104 [31:25:30<43:36:29, 16.79s/it]

 42%|████▏     | 6756/16104 [31:25:48<44:41:42, 17.21s/it]

 42%|████▏     | 6757/16104 [31:26:02<41:42:19, 16.06s/it]

 42%|████▏     | 6758/16104 [31:26:14<38:48:15, 14.95s/it]

 42%|████▏     | 6759/16104 [31:26:27<37:27:18, 14.43s/it]

 42%|████▏     | 6760/16104 [31:26:47<41:11:34, 15.87s/it]

 42%|████▏     | 6761/16104 [31:27:04<42:48:36, 16.50s/it]

 42%|████▏     | 6762/16104 [31:27:23<44:10:20, 17.02s/it]

 42%|████▏     | 6763/16104 [31:27:40<44:14:02, 17.05s/it]

 42%|████▏     | 6764/16104 [31:27:52<40:15:36, 15.52s/it]

 42%|████▏     | 6765/16104 [31:28:04<37:40:44, 14.52s/it]

 42%|████▏     | 6766/16104 [31:28:23<40:48:17, 15.73s/it]

 42%|████▏     | 6767/16104 [31:28:41<42:51:07, 16.52s/it]

 42%|████▏     | 6768/16104 [31:29:02<46:36:41, 17.97s/it]

 42%|████▏     | 6769/16104 [31:29:22<48:01:42, 18.52s/it]

 42%|████▏     | 6770/16104 [31:29:36<44:31:24, 17.17s/it]

 42%|████▏     | 6771/16104 [31:29:53<44:10:37, 17.04s/it]

 42%|████▏     | 6772/16104 [31:30:12<46:08:22, 17.80s/it]

 42%|████▏     | 6773/16104 [31:30:32<47:43:07, 18.41s/it]

 42%|████▏     | 6774/16104 [31:30:52<49:07:21, 18.95s/it]

 42%|████▏     | 6775/16104 [31:31:05<43:47:02, 16.90s/it]

 42%|████▏     | 6776/16104 [31:31:19<41:38:02, 16.07s/it]

 42%|████▏     | 6777/16104 [31:31:35<41:56:58, 16.19s/it]

 42%|████▏     | 6778/16104 [31:31:48<39:28:28, 15.24s/it]

 42%|████▏     | 6779/16104 [31:32:00<37:03:29, 14.31s/it]
{'loss': 0.335, 'learning_rate': 1.3000130457603608e-06, 'rewards/chosen': -0.759523868560791, 'rewards/rejected': -2.4073843955993652, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6478605270385742, 'policy_logps/rejected': -337.3316955566406, 'policy_logps/chosen': -384.8356628417969, 'referece_logps/rejected': -313.2579040527344, 'referece_logps/chosen': -377.24041748046875, 'logits/rejected': -0.7992286086082458, 'logits/chosen': -0.8124745488166809, 'epoch': 2.53}


 42%|████▏     | 6781/16104 [31:32:35<41:47:49, 16.14s/it]

 42%|████▏     | 6782/16104 [31:32:53<43:10:22, 16.67s/it]
{'loss': 0.4937, 'learning_rate': 1.2994374069004525e-06, 'rewards/chosen': -0.03577452898025513, 'rewards/rejected': -1.9112764596939087, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8755018711090088, 'policy_logps/rejected': -378.671875, 'policy_logps/chosen': -342.1083679199219, 'referece_logps/rejected': -359.55908203125, 'referece_logps/chosen': -341.7506103515625, 'logits/rejected': -0.49423927068710327, 'logits/chosen': -0.528927206993103, 'epoch': 2.53}


 42%|████▏     | 6784/16104 [31:33:29<45:02:08, 17.40s/it]
{'loss': 0.4882, 'learning_rate': 1.2990535870836897e-06, 'rewards/chosen': -0.3295650780200958, 'rewards/rejected': -1.5193188190460205, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1897538900375366, 'policy_logps/rejected': -400.8826904296875, 'policy_logps/chosen': -418.86126708984375, 'referece_logps/rejected': -385.68951416015625, 'referece_logps/chosen': -415.56561279296875, 'logits/rejected': -0.3763194978237152, 'logits/chosen': -0.4228392243385315, 'epoch': 2.53}


 42%|████▏     | 6786/16104 [31:34:05<45:24:38, 17.54s/it]

 42%|████▏     | 6787/16104 [31:34:25<47:14:09, 18.25s/it]
{'loss': 0.5474, 'learning_rate': 1.298477766648572e-06, 'rewards/chosen': -0.5284565687179565, 'rewards/rejected': -1.2409741878509521, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7125176191329956, 'policy_logps/rejected': -406.78106689453125, 'policy_logps/chosen': -402.84747314453125, 'referece_logps/rejected': -394.3713073730469, 'referece_logps/chosen': -397.5628967285156, 'logits/rejected': -0.16749617457389832, 'logits/chosen': -0.16393332183361053, 'epoch': 2.53}


 42%|████▏     | 6789/16104 [31:34:58<45:15:40, 17.49s/it]

 42%|████▏     | 6790/16104 [31:35:09<40:51:33, 15.79s/it]

 42%|████▏     | 6791/16104 [31:35:20<37:03:50, 14.33s/it]

 42%|████▏     | 6792/16104 [31:35:32<35:13:58, 13.62s/it]

 42%|████▏     | 6793/16104 [31:35:50<38:44:12, 14.98s/it]

 42%|████▏     | 6794/16104 [31:36:03<36:47:06, 14.22s/it]

 42%|████▏     | 6795/16104 [31:36:20<39:20:54, 15.22s/it]

 42%|████▏     | 6796/16104 [31:36:37<40:36:45, 15.71s/it]

 42%|████▏     | 6797/16104 [31:36:55<42:18:06, 16.36s/it]

 42%|████▏     | 6798/16104 [31:37:16<45:28:59, 17.60s/it]

 42%|████▏     | 6799/16104 [31:37:35<46:54:36, 18.15s/it]

 42%|████▏     | 6800/16104 [31:37:53<46:54:24, 18.15s/it]

 42%|████▏     | 6801/16104 [31:38:13<48:25:15, 18.74s/it]
{'loss': 0.3463, 'learning_rate': 1.2957891712059213e-06, 'rewards/chosen': -0.30616310238838196, 'rewards/rejected': -1.5934268236160278, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2872636318206787, 'policy_logps/rejected': -410.723876953125, 'policy_logps/chosen': -508.6669616699219, 'referece_logps/rejected': -394.7895812988281, 'referece_logps/chosen': -505.6053161621094, 'logits/rejected': -0.17227496206760406, 'logits/chosen': -0.20590627193450928, 'epoch': 2.53}

 42%|████▏     | 6802/16104 [31:38:32<48:29:56, 18.77s/it]


 42%|████▏     | 6804/16104 [31:39:10<49:11:51, 19.04s/it]

 42%|████▏     | 6805/16104 [31:39:24<45:18:02, 17.54s/it]

 42%|████▏     | 6806/16104 [31:39:44<47:14:59, 18.29s/it]

 42%|████▏     | 6807/16104 [31:40:03<48:10:16, 18.65s/it]

 42%|████▏     | 6808/16104 [31:40:19<45:57:54, 17.80s/it]

 42%|████▏     | 6809/16104 [31:40:33<42:36:02, 16.50s/it]
{'loss': 0.3524, 'learning_rate': 1.29425177664807e-06, 'rewards/chosen': -0.8155888319015503, 'rewards/rejected': -2.850862979888916, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0352742671966553, 'policy_logps/rejected': -215.71438598632812, 'policy_logps/chosen': -235.90545654296875, 'referece_logps/rejected': -187.2057647705078, 'referece_logps/chosen': -227.7495880126953, 'logits/rejected': -0.8844249844551086, 'logits/chosen': -0.6705194115638733, 'epoch': 2.54}


 42%|████▏     | 6811/16104 [31:41:15<48:31:00, 18.79s/it]
{'loss': 0.4191, 'learning_rate': 1.2938673088230187e-06, 'rewards/chosen': -0.09180870652198792, 'rewards/rejected': -1.9052931070327759, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8134843111038208, 'policy_logps/rejected': -540.2255859375, 'policy_logps/chosen': -383.6097106933594, 'referece_logps/rejected': -521.1726684570312, 'referece_logps/chosen': -382.69158935546875, 'logits/rejected': -0.288388192653656, 'logits/chosen': -0.027841415256261826, 'epoch': 2.54}


 42%|████▏     | 6813/16104 [31:41:52<48:07:04, 18.64s/it]

 42%|████▏     | 6814/16104 [31:42:14<50:44:42, 19.66s/it]

 42%|████▏     | 6815/16104 [31:42:33<50:23:03, 19.53s/it]

 42%|████▏     | 6816/16104 [31:42:51<49:11:59, 19.07s/it]

 42%|████▏     | 6817/16104 [31:43:08<47:16:36, 18.33s/it]
{'loss': 0.3603, 'learning_rate': 1.2927136202977753e-06, 'rewards/chosen': -0.7605041861534119, 'rewards/rejected': -2.6303634643554688, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8698593378067017, 'policy_logps/rejected': -196.99559020996094, 'policy_logps/chosen': -289.8887939453125, 'referece_logps/rejected': -170.69195556640625, 'referece_logps/chosen': -282.28375244140625, 'logits/rejected': -0.4172784090042114, 'logits/chosen': -0.40956059098243713, 'epoch': 2.54}


 42%|████▏     | 6819/16104 [31:43:49<49:56:04, 19.36s/it]
{'loss': 0.4015, 'learning_rate': 1.2923289626467477e-06, 'rewards/chosen': -1.4308744668960571, 'rewards/rejected': -2.021878719329834, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5910042524337769, 'policy_logps/rejected': -286.5181884765625, 'policy_logps/chosen': -455.5245056152344, 'referece_logps/rejected': -266.2994079589844, 'referece_logps/chosen': -441.2157897949219, 'logits/rejected': -0.5762673020362854, 'logits/chosen': -0.5849167704582214, 'epoch': 2.54}

 42%|████▏     | 6820/16104 [31:44:08<50:10:51, 19.46s/it]


 42%|████▏     | 6822/16104 [31:44:39<44:56:44, 17.43s/it]

 42%|████▏     | 6823/16104 [31:44:59<47:02:18, 18.25s/it]

 42%|████▏     | 6824/16104 [31:45:19<48:15:07, 18.72s/it]
{'loss': 0.4682, 'learning_rate': 1.2913671117138572e-06, 'rewards/chosen': -0.22984904050827026, 'rewards/rejected': -1.0869735479354858, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8571244478225708, 'policy_logps/rejected': -542.9467163085938, 'policy_logps/chosen': -524.3812255859375, 'referece_logps/rejected': -532.0770263671875, 'referece_logps/chosen': -522.0827026367188, 'logits/rejected': -1.1523993015289307, 'logits/chosen': -1.145625114440918, 'epoch': 2.54}


 42%|████▏     | 6826/16104 [31:46:02<51:59:20, 20.17s/it]

 42%|████▏     | 6827/16104 [31:46:19<49:26:01, 19.18s/it]

 42%|████▏     | 6828/16104 [31:46:39<49:40:47, 19.28s/it]

 42%|████▏     | 6829/16104 [31:46:56<47:58:24, 18.62s/it]

 42%|████▏     | 6830/16104 [31:47:13<47:05:21, 18.28s/it]

 42%|████▏     | 6831/16104 [31:47:29<45:29:11, 17.66s/it]

 42%|████▏     | 6832/16104 [31:47:49<47:10:25, 18.32s/it]
{'loss': 0.4981, 'learning_rate': 1.2898275377374232e-06, 'rewards/chosen': -0.4760271906852722, 'rewards/rejected': -2.3674871921539307, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8914600610733032, 'policy_logps/rejected': -385.7908935546875, 'policy_logps/chosen': -297.03753662109375, 'referece_logps/rejected': -362.1159973144531, 'referece_logps/chosen': -292.2772521972656, 'logits/rejected': -0.3169059157371521, 'logits/chosen': -0.20755985379219055, 'epoch': 2.55}


 42%|████▏     | 6834/16104 [31:48:20<42:40:31, 16.57s/it]

 42%|████▏     | 6835/16104 [31:48:38<43:48:39, 17.02s/it]

 42%|████▏     | 6836/16104 [31:48:54<42:50:19, 16.64s/it]

 42%|████▏     | 6837/16104 [31:49:13<45:11:28, 17.56s/it]

 42%|████▏     | 6838/16104 [31:49:25<40:18:41, 15.66s/it]

 42%|████▏     | 6839/16104 [31:49:36<37:16:20, 14.48s/it]

 42%|████▏     | 6840/16104 [31:49:53<38:44:44, 15.06s/it]
{'loss': 0.342, 'learning_rate': 1.2882872134225184e-06, 'rewards/chosen': 0.7498149871826172, 'rewards/rejected': -1.017961025238037, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7677760124206543, 'policy_logps/rejected': -446.4051513671875, 'policy_logps/chosen': -603.309814453125, 'referece_logps/rejected': -436.2255554199219, 'referece_logps/chosen': -610.8079833984375, 'logits/rejected': 0.055218178778886795, 'logits/chosen': 0.014597414061427116, 'epoch': 2.55}


 42%|████▏     | 6842/16104 [31:50:33<45:00:53, 17.50s/it]

 42%|████▏     | 6843/16104 [31:50:43<39:45:19, 15.45s/it]

 42%|████▏     | 6844/16104 [31:50:54<36:03:20, 14.02s/it]

 43%|████▎     | 6845/16104 [31:51:09<37:11:16, 14.46s/it]

 43%|████▎     | 6846/16104 [31:51:24<37:02:23, 14.40s/it]
{'loss': 0.4904, 'learning_rate': 1.2871314801755363e-06, 'rewards/chosen': -0.16914217174053192, 'rewards/rejected': -0.9783778190612793, 'rewards/accuracies': 0.75, 'rewards/margins': 0.809235692024231, 'policy_logps/rejected': -474.6820983886719, 'policy_logps/chosen': -462.3670349121094, 'referece_logps/rejected': -464.8983154296875, 'referece_logps/chosen': -460.67559814453125, 'logits/rejected': -0.12753957509994507, 'logits/chosen': -0.1576860547065735, 'epoch': 2.55}


 43%|████▎     | 6848/16104 [31:51:54<37:03:18, 14.41s/it]

 43%|████▎     | 6849/16104 [31:52:06<35:07:26, 13.66s/it]

 43%|████▎     | 6850/16104 [31:52:22<36:58:51, 14.39s/it]

 43%|████▎     | 6851/16104 [31:52:41<40:10:21, 15.63s/it]
{'loss': 0.3668, 'learning_rate': 1.2861680496530077e-06, 'rewards/chosen': -0.653592050075531, 'rewards/rejected': -1.4073325395584106, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7537404298782349, 'policy_logps/rejected': -366.9305725097656, 'policy_logps/chosen': -387.4134826660156, 'referece_logps/rejected': -352.85723876953125, 'referece_logps/chosen': -380.8775634765625, 'logits/rejected': 0.2019597738981247, 'logits/chosen': 0.34263765811920166, 'epoch': 2.55}

 43%|████▎     | 6852/16104 [31:52:53<37:44:41, 14.69s/it]

 43%|████▎     | 6853/16104 [31:53:05<35:45:04, 13.91s/it]


 43%|████▎     | 6855/16104 [31:53:39<40:41:59, 15.84s/it]
{'loss': 0.5088, 'learning_rate': 1.2853970968200758e-06, 'rewards/chosen': -0.2961057424545288, 'rewards/rejected': -1.6158961057662964, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3197904825210571, 'policy_logps/rejected': -406.5655822753906, 'policy_logps/chosen': -474.9556884765625, 'referece_logps/rejected': -390.4065856933594, 'referece_logps/chosen': -471.9946594238281, 'logits/rejected': -0.18833333253860474, 'logits/chosen': -0.3395434617996216, 'epoch': 2.55}


 43%|████▎     | 6857/16104 [31:54:11<41:30:21, 16.16s/it]

 43%|████▎     | 6858/16104 [31:54:22<37:12:16, 14.49s/it]

 43%|████▎     | 6859/16104 [31:54:32<34:18:38, 13.36s/it]

 43%|████▎     | 6860/16104 [31:54:48<36:12:22, 14.10s/it]
{'loss': 0.4239, 'learning_rate': 1.284433146078918e-06, 'rewards/chosen': -0.4813741445541382, 'rewards/rejected': -0.9809898138046265, 'rewards/accuracies': 0.625, 'rewards/margins': 0.49961575865745544, 'policy_logps/rejected': -527.274658203125, 'policy_logps/chosen': -447.0504150390625, 'referece_logps/rejected': -517.46484375, 'referece_logps/chosen': -442.2366943359375, 'logits/rejected': -0.73919677734375, 'logits/chosen': -0.5913776755332947, 'epoch': 2.56}

 43%|████▎     | 6861/16104 [31:55:04<37:14:25, 14.50s/it]


 43%|████▎     | 6863/16104 [31:55:38<41:14:45, 16.07s/it]
{'loss': 0.4543, 'learning_rate': 1.2838546375018928e-06, 'rewards/chosen': -1.0945632457733154, 'rewards/rejected': -1.9869292974472046, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8923659324645996, 'policy_logps/rejected': -420.9729309082031, 'policy_logps/chosen': -339.8838806152344, 'referece_logps/rejected': -401.1036682128906, 'referece_logps/chosen': -328.938232421875, 'logits/rejected': -0.7839930057525635, 'logits/chosen': -0.6843318939208984, 'epoch': 2.56}


 43%|████▎     | 6865/16104 [31:56:10<41:44:44, 16.27s/it]

 43%|████▎     | 6866/16104 [31:56:25<40:31:50, 15.79s/it]
{'loss': 0.5064, 'learning_rate': 1.283276025583031e-06, 'rewards/chosen': -0.9624796509742737, 'rewards/rejected': -1.7700061798095703, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8075265288352966, 'policy_logps/rejected': -390.9342346191406, 'policy_logps/chosen': -388.1258850097656, 'referece_logps/rejected': -373.2341613769531, 'referece_logps/chosen': -378.5010986328125, 'logits/rejected': 0.005831480026245117, 'logits/chosen': -0.05992686748504639, 'epoch': 2.56}

 43%|████▎     | 6867/16104 [31:56:41<41:05:41, 16.02s/it]

 43%|████▎     | 6868/16104 [31:56:58<41:38:37, 16.23s/it]

 43%|████▎     | 6869/16104 [31:57:18<44:27:04, 17.33s/it]


 43%|████▎     | 6871/16104 [31:57:56<46:12:37, 18.02s/it]

 43%|████▎     | 6872/16104 [31:58:17<48:03:43, 18.74s/it]

 43%|████▎     | 6873/16104 [31:58:31<44:29:58, 17.35s/it]
{'loss': 0.3458, 'learning_rate': 1.2819255304041332e-06, 'rewards/chosen': -0.6359133124351501, 'rewards/rejected': -2.1127564907073975, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4768431186676025, 'policy_logps/rejected': -470.3211669921875, 'policy_logps/chosen': -429.2442321777344, 'referece_logps/rejected': -449.193603515625, 'referece_logps/chosen': -422.88507080078125, 'logits/rejected': -0.9074164628982544, 'logits/chosen': -0.812809944152832, 'epoch': 2.56}

 43%|████▎     | 6874/16104 [31:58:46<42:30:44, 16.58s/it]


 43%|████▎     | 6876/16104 [31:59:25<46:44:21, 18.23s/it]
{'loss': 0.3378, 'learning_rate': 1.2813465755340752e-06, 'rewards/chosen': -0.023973271250724792, 'rewards/rejected': -1.1726771593093872, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1487040519714355, 'policy_logps/rejected': -375.9772644042969, 'policy_logps/chosen': -426.2409973144531, 'referece_logps/rejected': -364.2505187988281, 'referece_logps/chosen': -426.001220703125, 'logits/rejected': -0.2668991684913635, 'logits/chosen': -0.13010238111019135, 'epoch': 2.56}

 43%|████▎     | 6877/16104 [31:59:42<45:36:17, 17.79s/it]


 43%|████▎     | 6879/16104 [32:00:21<48:25:35, 18.90s/it]
{'loss': 0.3502, 'learning_rate': 1.2807675182352803e-06, 'rewards/chosen': -0.18145257234573364, 'rewards/rejected': -1.12107515335083, 'rewards/accuracies': 0.875, 'rewards/margins': 0.939622700214386, 'policy_logps/rejected': -401.46795654296875, 'policy_logps/chosen': -333.8852233886719, 'referece_logps/rejected': -390.2572021484375, 'referece_logps/chosen': -332.0706787109375, 'logits/rejected': 0.18517754971981049, 'logits/chosen': 0.267069548368454, 'epoch': 2.56}


 43%|████▎     | 6881/16104 [32:00:53<44:20:19, 17.31s/it]

 43%|████▎     | 6882/16104 [32:01:07<42:14:56, 16.49s/it]
{'loss': 0.5737, 'learning_rate': 1.2801883587185643e-06, 'rewards/chosen': 0.00983285903930664, 'rewards/rejected': -1.9302245378494263, 'rewards/accuracies': 0.875, 'rewards/margins': 1.940057396888733, 'policy_logps/rejected': -355.6679382324219, 'policy_logps/chosen': -469.65130615234375, 'referece_logps/rejected': -336.3656921386719, 'referece_logps/chosen': -469.7496032714844, 'logits/rejected': -0.6360527276992798, 'logits/chosen': -0.5151007771492004, 'epoch': 2.56}

 43%|████▎     | 6883/16104 [32:01:28<45:35:31, 17.80s/it]

 43%|████▎     | 6884/16104 [32:01:44<44:29:15, 17.37s/it]


 43%|████▎     | 6886/16104 [32:02:23<46:43:59, 18.25s/it]
{'loss': 0.4487, 'learning_rate': 1.279415987388395e-06, 'rewards/chosen': -0.004208754748106003, 'rewards/rejected': -1.1438498497009277, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1396411657333374, 'policy_logps/rejected': -442.8756408691406, 'policy_logps/chosen': -403.87066650390625, 'referece_logps/rejected': -431.43707275390625, 'referece_logps/chosen': -403.8285827636719, 'logits/rejected': 0.1060531958937645, 'logits/chosen': 0.0303280521184206, 'epoch': 2.57}

 43%|████▎     | 6887/16104 [32:02:34<41:10:40, 16.08s/it]

 43%|████▎     | 6888/16104 [32:02:50<40:42:24, 15.90s/it]

 43%|████▎     | 6889/16104 [32:03:01<36:45:43, 14.36s/it]


 43%|████▎     | 6891/16104 [32:03:35<41:32:45, 16.23s/it]
{'loss': 0.4912, 'learning_rate': 1.2784502689695956e-06, 'rewards/chosen': -0.3021942973136902, 'rewards/rejected': -1.8709169626235962, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5687227249145508, 'policy_logps/rejected': -361.2420654296875, 'policy_logps/chosen': -309.1356201171875, 'referece_logps/rejected': -342.5328674316406, 'referece_logps/chosen': -306.1136474609375, 'logits/rejected': -0.4491093158721924, 'logits/chosen': -0.3418126702308655, 'epoch': 2.57}


 43%|████▎     | 6893/16104 [32:04:00<36:31:09, 14.27s/it]
{'loss': 0.4953, 'learning_rate': 1.2780639027007095e-06, 'rewards/chosen': -0.5395366549491882, 'rewards/rejected': -1.3242440223693848, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7847074866294861, 'policy_logps/rejected': -488.79638671875, 'policy_logps/chosen': -321.86724853515625, 'referece_logps/rejected': -475.553955078125, 'referece_logps/chosen': -316.4718933105469, 'logits/rejected': -0.6450872421264648, 'logits/chosen': -0.49866098165512085, 'epoch': 2.57}


 43%|████▎     | 6895/16104 [32:04:33<39:44:01, 15.53s/it]

 43%|████▎     | 6896/16104 [32:04:53<43:04:06, 16.84s/it]

 43%|████▎     | 6897/16104 [32:05:07<41:19:43, 16.16s/it]

 43%|████▎     | 6898/16104 [32:05:24<41:31:06, 16.24s/it]

 43%|████▎     | 6899/16104 [32:05:43<44:06:12, 17.25s/it]

 43%|████▎     | 6900/16104 [32:06:00<43:21:20, 16.96s/it]

 43%|████▎     | 6901/16104 [32:06:14<41:03:31, 16.06s/it]

 43%|████▎     | 6902/16104 [32:06:33<43:48:01, 17.14s/it]
{'loss': 0.4025, 'learning_rate': 1.2763246986085226e-06, 'rewards/chosen': -0.040347203612327576, 'rewards/rejected': -1.1756664514541626, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1353192329406738, 'policy_logps/rejected': -360.27685546875, 'policy_logps/chosen': -406.16583251953125, 'referece_logps/rejected': -348.5201416015625, 'referece_logps/chosen': -405.76239013671875, 'logits/rejected': 0.36299073696136475, 'logits/chosen': 0.36697447299957275, 'epoch': 2.57}


 43%|████▎     | 6904/16104 [32:07:09<45:22:00, 17.75s/it]

 43%|████▎     | 6905/16104 [32:07:31<48:34:39, 19.01s/it]

 43%|████▎     | 6906/16104 [32:07:43<43:04:27, 16.86s/it]

 43%|████▎     | 6907/16104 [32:08:03<45:21:56, 17.76s/it]

 43%|████▎     | 6908/16104 [32:08:15<40:50:26, 15.99s/it]
{'loss': 0.462, 'learning_rate': 1.275164725859753e-06, 'rewards/chosen': -0.49013465642929077, 'rewards/rejected': -1.8257324695587158, 'rewards/accuracies': 0.5, 'rewards/margins': 1.3355977535247803, 'policy_logps/rejected': -387.6002197265625, 'policy_logps/chosen': -364.31298828125, 'referece_logps/rejected': -369.3429260253906, 'referece_logps/chosen': -359.41162109375, 'logits/rejected': -0.06841251254081726, 'logits/chosen': -0.13367609679698944, 'epoch': 2.57}


 43%|████▎     | 6910/16104 [32:08:49<41:53:39, 16.40s/it]
{'loss': 0.3903, 'learning_rate': 1.2747779791461717e-06, 'rewards/chosen': -0.6188486218452454, 'rewards/rejected': -2.7856171131134033, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1667685508728027, 'policy_logps/rejected': -490.7796936035156, 'policy_logps/chosen': -522.731689453125, 'referece_logps/rejected': -462.92352294921875, 'referece_logps/chosen': -516.5432739257812, 'logits/rejected': 0.13372802734375, 'logits/chosen': 0.2658987045288086, 'epoch': 2.57}


 43%|████▎     | 6912/16104 [32:09:22<40:52:06, 16.01s/it]

 43%|████▎     | 6913/16104 [32:09:39<42:04:59, 16.48s/it]
{'loss': 0.5146, 'learning_rate': 1.2741977757309105e-06, 'rewards/chosen': 0.020889118313789368, 'rewards/rejected': -0.9377333521842957, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9586224555969238, 'policy_logps/rejected': -405.5611267089844, 'policy_logps/chosen': -395.0472106933594, 'referece_logps/rejected': -396.18377685546875, 'referece_logps/chosen': -395.256103515625, 'logits/rejected': -0.4400985538959503, 'logits/chosen': -0.570320725440979, 'epoch': 2.58}


 43%|████▎     | 6915/16104 [32:10:09<40:41:22, 15.94s/it]
{'loss': 0.4292, 'learning_rate': 1.2738109179820844e-06, 'rewards/chosen': 0.2065320760011673, 'rewards/rejected': -1.0332891941070557, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2398213148117065, 'policy_logps/rejected': -496.13482666015625, 'policy_logps/chosen': -489.9359130859375, 'referece_logps/rejected': -485.80194091796875, 'referece_logps/chosen': -492.0012512207031, 'logits/rejected': -0.09521007537841797, 'logits/chosen': -0.20417824387550354, 'epoch': 2.58}


 43%|████▎     | 6917/16104 [32:10:42<41:32:15, 16.28s/it]

 43%|████▎     | 6918/16104 [32:10:54<38:21:38, 15.03s/it]
{'loss': 0.5647, 'learning_rate': 1.2732305483073573e-06, 'rewards/chosen': 0.5294475555419922, 'rewards/rejected': -0.6952463388442993, 'rewards/accuracies': 0.75, 'rewards/margins': 1.224694013595581, 'policy_logps/rejected': -518.7611694335938, 'policy_logps/chosen': -676.5194702148438, 'referece_logps/rejected': -511.8086853027344, 'referece_logps/chosen': -681.8139038085938, 'logits/rejected': 0.6774415373802185, 'logits/chosen': 0.5515878796577454, 'epoch': 2.58}

 43%|████▎     | 6919/16104 [32:11:15<42:44:12, 16.75s/it]

 43%|████▎     | 6920/16104 [32:11:27<38:57:52, 15.27s/it]

 43%|████▎     | 6921/16104 [32:11:38<36:17:56, 14.23s/it]


 43%|████▎     | 6923/16104 [32:12:06<36:35:27, 14.35s/it]
{'loss': 0.4401, 'learning_rate': 1.2722630445672451e-06, 'rewards/chosen': -0.08182945847511292, 'rewards/rejected': -1.555861234664917, 'rewards/accuracies': 0.875, 'rewards/margins': 1.474031686782837, 'policy_logps/rejected': -251.21859741210938, 'policy_logps/chosen': -321.7111511230469, 'referece_logps/rejected': -235.6599884033203, 'referece_logps/chosen': -320.8928527832031, 'logits/rejected': 0.12103193253278732, 'logits/chosen': 0.2922544777393341, 'epoch': 2.58}

 43%|████▎     | 6924/16104 [32:12:23<38:27:48, 15.08s/it]


 43%|████▎     | 6926/16104 [32:12:58<41:08:57, 16.14s/it]
{'loss': 0.4094, 'learning_rate': 1.2716824100982452e-06, 'rewards/chosen': -1.1178064346313477, 'rewards/rejected': -1.6857645511627197, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5679580569267273, 'policy_logps/rejected': -444.77001953125, 'policy_logps/chosen': -360.82635498046875, 'referece_logps/rejected': -427.9123840332031, 'referece_logps/chosen': -349.6482849121094, 'logits/rejected': -0.3311338722705841, 'logits/chosen': -0.3754042983055115, 'epoch': 2.58}


 43%|████▎     | 6928/16104 [32:13:28<39:32:50, 15.52s/it]

 43%|████▎     | 6929/16104 [32:13:42<38:59:27, 15.30s/it]
{'loss': 0.5154, 'learning_rate': 1.271101676718903e-06, 'rewards/chosen': -0.7342003583908081, 'rewards/rejected': -1.1007599830627441, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3665597438812256, 'policy_logps/rejected': -421.8445129394531, 'policy_logps/chosen': -377.5292053222656, 'referece_logps/rejected': -410.8369445800781, 'referece_logps/chosen': -370.18719482421875, 'logits/rejected': -0.2979930639266968, 'logits/chosen': -0.2713845670223236, 'epoch': 2.58}


 43%|████▎     | 6931/16104 [32:14:16<41:03:26, 16.11s/it]
{'loss': 0.5874, 'learning_rate': 1.2707144662868915e-06, 'rewards/chosen': -0.6069101691246033, 'rewards/rejected': -0.05247918516397476, 'rewards/accuracies': 0.375, 'rewards/margins': -0.5544309616088867, 'policy_logps/rejected': -457.23486328125, 'policy_logps/chosen': -497.736083984375, 'referece_logps/rejected': -456.7100830078125, 'referece_logps/chosen': -491.6669921875, 'logits/rejected': -0.2789163589477539, 'logits/chosen': -0.40973934531211853, 'epoch': 2.58}

 43%|████▎     | 6932/16104 [32:14:29<38:43:58, 15.20s/it]

 43%|████▎     | 6933/16104 [32:14:46<40:19:31, 15.83s/it]


 43%|████▎     | 6935/16104 [32:15:18<39:52:50, 15.66s/it]
{'loss': 0.3727, 'learning_rate': 1.26993991407493e-06, 'rewards/chosen': -0.22684654593467712, 'rewards/rejected': -2.004210948944092, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7773643732070923, 'policy_logps/rejected': -367.33306884765625, 'policy_logps/chosen': -525.6406860351562, 'referece_logps/rejected': -347.2909851074219, 'referece_logps/chosen': -523.3722534179688, 'logits/rejected': -0.03613314777612686, 'logits/chosen': -0.039181917905807495, 'epoch': 2.58}


 43%|████▎     | 6937/16104 [32:15:50<40:34:12, 15.93s/it]

 43%|████▎     | 6938/16104 [32:16:00<36:32:10, 14.35s/it]

 43%|████▎     | 6939/16104 [32:16:20<40:48:27, 16.03s/it]

 43%|████▎     | 6940/16104 [32:16:40<43:41:00, 17.16s/it]
{'loss': 0.5055, 'learning_rate': 1.2689714781788467e-06, 'rewards/chosen': -0.3166450262069702, 'rewards/rejected': -0.9352811574935913, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6186361312866211, 'policy_logps/rejected': -365.66058349609375, 'policy_logps/chosen': -450.3287658691406, 'referece_logps/rejected': -356.3077392578125, 'referece_logps/chosen': -447.16229248046875, 'logits/rejected': 0.517445981502533, 'logits/chosen': 0.547613263130188, 'epoch': 2.59}

 43%|████▎     | 6941/16104 [32:16:51<38:46:47, 15.24s/it]


 43%|████▎     | 6943/16104 [32:17:19<36:49:39, 14.47s/it]
{'loss': 0.5239, 'learning_rate': 1.268390286014001e-06, 'rewards/chosen': -0.0036024018190801144, 'rewards/rejected': -1.3329631090164185, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3293606042861938, 'policy_logps/rejected': -358.0610046386719, 'policy_logps/chosen': -310.36041259765625, 'referece_logps/rejected': -344.73138427734375, 'referece_logps/chosen': -310.32440185546875, 'logits/rejected': 0.47156885266304016, 'logits/chosen': 0.5001850128173828, 'epoch': 2.59}


 43%|████▎     | 6945/16104 [32:17:50<39:43:45, 15.62s/it]

 43%|████▎     | 6946/16104 [32:18:10<43:12:10, 16.98s/it]
{'loss': 0.3332, 'learning_rate': 1.2678089961373635e-06, 'rewards/chosen': 0.28474122285842896, 'rewards/rejected': -1.2780059576034546, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5627472400665283, 'policy_logps/rejected': -480.2513122558594, 'policy_logps/chosen': -410.95806884765625, 'referece_logps/rejected': -467.4712219238281, 'referece_logps/chosen': -413.80548095703125, 'logits/rejected': 0.4393917918205261, 'logits/chosen': 0.4354809522628784, 'epoch': 2.59}

 43%|████▎     | 6947/16104 [32:18:31<46:21:22, 18.22s/it]

 43%|████▎     | 6948/16104 [32:18:51<47:42:11, 18.76s/it]

 43%|████▎     | 6949/16104 [32:19:11<48:37:20, 19.12s/it]

 43%|████▎     | 6950/16104 [32:19:27<46:15:11, 18.19s/it]


 43%|████▎     | 6952/16104 [32:20:02<44:48:40, 17.63s/it]

 43%|████▎     | 6953/16104 [32:20:20<44:53:55, 17.66s/it]
{'loss': 0.3788, 'learning_rate': 1.2664522742904166e-06, 'rewards/chosen': -1.1164920330047607, 'rewards/rejected': -1.6181023120880127, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5016102194786072, 'policy_logps/rejected': -338.99786376953125, 'policy_logps/chosen': -315.47601318359375, 'referece_logps/rejected': -322.81683349609375, 'referece_logps/chosen': -304.31109619140625, 'logits/rejected': -0.5899623036384583, 'logits/chosen': -0.5300261378288269, 'epoch': 2.59}

 43%|████▎     | 6954/16104 [32:20:39<46:10:59, 18.17s/it]

 43%|████▎     | 6955/16104 [32:20:58<46:06:34, 18.14s/it]


 43%|████▎     | 6957/16104 [32:21:37<47:25:49, 18.67s/it]
{'loss': 0.3678, 'learning_rate': 1.2656767673647596e-06, 'rewards/chosen': -1.2997242212295532, 'rewards/rejected': -2.184256076812744, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8845317363739014, 'policy_logps/rejected': -284.5401306152344, 'policy_logps/chosen': -315.7038879394531, 'referece_logps/rejected': -262.6975402832031, 'referece_logps/chosen': -302.7066345214844, 'logits/rejected': -0.3087051808834076, 'logits/chosen': -0.354535847902298, 'epoch': 2.59}

 43%|████▎     | 6958/16104 [32:21:53<45:48:20, 18.03s/it]


 43%|████▎     | 6960/16104 [32:22:28<45:25:46, 17.89s/it]

 43%|████▎     | 6961/16104 [32:22:48<46:52:11, 18.45s/it]
{'loss': 0.6401, 'learning_rate': 1.264901088485522e-06, 'rewards/chosen': -0.28218650817871094, 'rewards/rejected': -0.5833227634429932, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3011362552642822, 'policy_logps/rejected': -454.7604675292969, 'policy_logps/chosen': -500.44512939453125, 'referece_logps/rejected': -448.9272766113281, 'referece_logps/chosen': -497.62322998046875, 'logits/rejected': 0.007106110453605652, 'logits/chosen': 0.0564274825155735, 'epoch': 2.59}

 43%|████▎     | 6962/16104 [32:23:08<47:38:48, 18.76s/it]

 43%|████▎     | 6963/16104 [32:23:19<42:28:23, 16.73s/it]

 43%|████▎     | 6964/16104 [32:23:38<43:29:42, 17.13s/it]


 43%|████▎     | 6966/16104 [32:24:11<42:14:27, 16.64s/it]
{'loss': 0.443, 'learning_rate': 1.2639312488415915e-06, 'rewards/chosen': -0.524039089679718, 'rewards/rejected': -1.7304061651229858, 'rewards/accuracies': 0.625, 'rewards/margins': 1.206367015838623, 'policy_logps/rejected': -712.7742919921875, 'policy_logps/chosen': -552.072998046875, 'referece_logps/rejected': -695.4703369140625, 'referece_logps/chosen': -546.8326416015625, 'logits/rejected': 0.060375064611434937, 'logits/chosen': 0.05858394503593445, 'epoch': 2.6}


 43%|████▎     | 6968/16104 [32:24:45<42:53:11, 16.90s/it]
{'loss': 0.4632, 'learning_rate': 1.263543238193662e-06, 'rewards/chosen': -0.6201656460762024, 'rewards/rejected': -1.3673427104949951, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7471771240234375, 'policy_logps/rejected': -467.98211669921875, 'policy_logps/chosen': -347.74169921875, 'referece_logps/rejected': -454.3086853027344, 'referece_logps/chosen': -341.5400390625, 'logits/rejected': -0.45426538586616516, 'logits/chosen': -0.21645602583885193, 'epoch': 2.6}


 43%|████▎     | 6970/16104 [32:25:14<39:43:15, 15.66s/it]
{'loss': 0.5113, 'learning_rate': 1.2631551849025556e-06, 'rewards/chosen': 0.15867692232131958, 'rewards/rejected': -0.8965753316879272, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0552523136138916, 'policy_logps/rejected': -414.3482360839844, 'policy_logps/chosen': -428.0180358886719, 'referece_logps/rejected': -405.3825378417969, 'referece_logps/chosen': -429.6048278808594, 'logits/rejected': -0.9329373240470886, 'logits/chosen': -0.69446861743927, 'epoch': 2.6}

 43%|████▎     | 6971/16104 [32:25:30<39:53:34, 15.72s/it]

 43%|████▎     | 6972/16104 [32:25:44<38:46:47, 15.29s/it]

 43%|████▎     | 6973/16104 [32:25:56<35:54:10, 14.16s/it]

 43%|████▎     | 6974/16104 [32:26:14<38:39:57, 15.25s/it]

 43%|████▎     | 6975/16104 [32:26:26<36:29:28, 14.39s/it]

 43%|████▎     | 6976/16104 [32:26:40<36:20:07, 14.33s/it]

 43%|████▎     | 6977/16104 [32:27:02<42:01:44, 16.58s/it]

 43%|████▎     | 6978/16104 [32:27:16<39:45:09, 15.68s/it]

 43%|████▎     | 6979/16104 [32:27:33<41:17:07, 16.29s/it]

 43%|████▎     | 6980/16104 [32:27:52<42:59:47, 16.96s/it]

 43%|████▎     | 6981/16104 [32:28:12<45:06:39, 17.80s/it]


 43%|████▎     | 6983/16104 [32:28:51<47:31:11, 18.76s/it]
{'loss': 0.3606, 'learning_rate': 1.260631803420007e-06, 'rewards/chosen': 0.1577077955007553, 'rewards/rejected': -1.353261113166809, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5109691619873047, 'policy_logps/rejected': -480.45904541015625, 'policy_logps/chosen': -426.4826965332031, 'referece_logps/rejected': -466.9264221191406, 'referece_logps/chosen': -428.05975341796875, 'logits/rejected': 0.26169249415397644, 'logits/chosen': 0.34713485836982727, 'epoch': 2.6}

 43%|████▎     | 6984/16104 [32:29:10<47:57:02, 18.93s/it]

 43%|████▎     | 6985/16104 [32:29:26<45:18:20, 17.89s/it]


 43%|████▎     | 6987/16104 [32:30:07<49:02:26, 19.36s/it]

 43%|████▎     | 6988/16104 [32:30:19<43:26:11, 17.15s/it]
{'loss': 0.3675, 'learning_rate': 1.2596607967022332e-06, 'rewards/chosen': -0.33041420578956604, 'rewards/rejected': -1.8423116207122803, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5118974447250366, 'policy_logps/rejected': -273.01312255859375, 'policy_logps/chosen': -406.0380554199219, 'referece_logps/rejected': -254.59002685546875, 'referece_logps/chosen': -402.73388671875, 'logits/rejected': -0.018671348690986633, 'logits/chosen': 0.06594008207321167, 'epoch': 2.6}


 43%|████▎     | 6990/16104 [32:30:47<40:13:16, 15.89s/it]
{'loss': 0.5468, 'learning_rate': 1.2592723204339324e-06, 'rewards/chosen': -0.5805104970932007, 'rewards/rejected': -2.1930174827575684, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6125068664550781, 'policy_logps/rejected': -398.5705261230469, 'policy_logps/chosen': -299.76568603515625, 'referece_logps/rejected': -376.640380859375, 'referece_logps/chosen': -293.9605712890625, 'logits/rejected': -0.8271266222000122, 'logits/chosen': -0.7923541069030762, 'epoch': 2.6}

 43%|████▎     | 6991/16104 [32:31:07<43:00:51, 16.99s/it]

 43%|████▎     | 6992/16104 [32:31:22<41:31:40, 16.41s/it]

 43%|████▎     | 6993/16104 [32:31:36<39:42:38, 15.69s/it]

 43%|████▎     | 6994/16104 [32:31:52<40:05:08, 15.84s/it]

 43%|████▎     | 6995/16104 [32:32:09<40:42:36, 16.09s/it]

 43%|████▎     | 6996/16104 [32:32:29<43:38:01, 17.25s/it]

 43%|████▎     | 6997/16104 [32:32:46<43:21:53, 17.14s/it]

 43%|████▎     | 6998/16104 [32:33:04<44:14:28, 17.49s/it]

 43%|████▎     | 6999/16104 [32:33:20<43:21:59, 17.15s/it]

 43%|████▎     | 7000/16104 [32:33:34<41:03:18, 16.23s/it]


 43%|████▎     | 7002/16104 [32:34:21<48:16:08, 19.09s/it]
{'loss': 0.4649, 'learning_rate': 1.2569405840302933e-06, 'rewards/chosen': -0.8199746012687683, 'rewards/rejected': -1.341668963432312, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5216943621635437, 'policy_logps/rejected': -505.8300476074219, 'policy_logps/chosen': -539.822998046875, 'referece_logps/rejected': -492.4133605957031, 'referece_logps/chosen': -531.623291015625, 'logits/rejected': -0.18032437562942505, 'logits/chosen': -0.261719286441803, 'epoch': 2.61}

 43%|████▎     | 7003/16104 [32:34:37<45:27:09, 17.98s/it]

 43%|████▎     | 7004/16104 [32:34:55<45:50:10, 18.13s/it]

 43%|████▎     | 7005/16104 [32:35:15<47:14:42, 18.69s/it]

 44%|████▎     | 7006/16104 [32:35:29<43:19:54, 17.15s/it]

 44%|████▎     | 7007/16104 [32:35:42<40:24:45, 15.99s/it]

 44%|████▎     | 7008/16104 [32:36:03<44:05:32, 17.45s/it]

 44%|████▎     | 7009/16104 [32:36:25<47:46:04, 18.91s/it]

 44%|████▎     | 7010/16104 [32:36:45<48:28:12, 19.19s/it]

 44%|████▎     | 7011/16104 [32:37:06<49:51:05, 19.74s/it]

 44%|████▎     | 7012/16104 [32:37:19<44:39:14, 17.68s/it]

 44%|████▎     | 7013/16104 [32:37:35<43:43:32, 17.32s/it]

 44%|████▎     | 7014/16104 [32:37:53<44:22:36, 17.57s/it]

 44%|████▎     | 7015/16104 [32:38:08<42:04:01, 16.66s/it]


 44%|████▎     | 7017/16104 [32:38:37<39:13:29, 15.54s/it]
{'loss': 0.4834, 'learning_rate': 1.2540238103939994e-06, 'rewards/chosen': -0.9650912284851074, 'rewards/rejected': -1.819822072982788, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8547308444976807, 'policy_logps/rejected': -257.6321105957031, 'policy_logps/chosen': -252.4844512939453, 'referece_logps/rejected': -239.43389892578125, 'referece_logps/chosen': -242.83355712890625, 'logits/rejected': -0.22069059312343597, 'logits/chosen': -0.03553684800863266, 'epoch': 2.61}

 44%|████▎     | 7018/16104 [32:38:54<40:06:09, 15.89s/it]

 44%|████▎     | 7019/16104 [32:39:15<44:02:06, 17.45s/it]

 44%|████▎     | 7020/16104 [32:39:31<42:50:56, 16.98s/it]


 44%|████▎     | 7022/16104 [32:40:10<45:56:30, 18.21s/it]

 44%|████▎     | 7023/16104 [32:40:26<44:07:41, 17.49s/it]

 44%|████▎     | 7024/16104 [32:40:42<43:12:22, 17.13s/it]
{'loss': 0.3874, 'learning_rate': 1.252661856518236e-06, 'rewards/chosen': -0.7476093769073486, 'rewards/rejected': -1.223804235458374, 'rewards/accuracies': 0.5, 'rewards/margins': 0.47619494795799255, 'policy_logps/rejected': -427.986328125, 'policy_logps/chosen': -469.60711669921875, 'referece_logps/rejected': -415.7482604980469, 'referece_logps/chosen': -462.1310119628906, 'logits/rejected': -0.8881839513778687, 'logits/chosen': -0.7326264381408691, 'epoch': 2.62}


 44%|████▎     | 7026/16104 [32:41:16<42:50:15, 16.99s/it]

 44%|████▎     | 7027/16104 [32:41:32<42:16:46, 16.77s/it]
{'loss': 0.529, 'learning_rate': 1.2520780085332868e-06, 'rewards/chosen': -0.11773359030485153, 'rewards/rejected': -0.8142715692520142, 'rewards/accuracies': 0.875, 'rewards/margins': 0.696537971496582, 'policy_logps/rejected': -434.46405029296875, 'policy_logps/chosen': -449.7320556640625, 'referece_logps/rejected': -426.3213195800781, 'referece_logps/chosen': -448.5547180175781, 'logits/rejected': -0.12752334773540497, 'logits/chosen': -0.2511032223701477, 'epoch': 2.62}

 44%|████▎     | 7028/16104 [32:41:52<44:22:55, 17.60s/it]

 44%|████▎     | 7029/16104 [32:42:13<46:54:00, 18.60s/it]


 44%|████▎     | 7031/16104 [32:42:54<49:35:27, 19.68s/it]
{'loss': 0.463, 'learning_rate': 1.251299401832028e-06, 'rewards/chosen': -0.8348633646965027, 'rewards/rejected': -2.935265302658081, 'rewards/accuracies': 0.5, 'rewards/margins': 2.1004018783569336, 'policy_logps/rejected': -564.7060546875, 'policy_logps/chosen': -524.63232421875, 'referece_logps/rejected': -535.3533935546875, 'referece_logps/chosen': -516.28369140625, 'logits/rejected': 0.05317734181880951, 'logits/chosen': 0.2429654896259308, 'epoch': 2.62}

 44%|████▎     | 7032/16104 [32:43:14<49:35:28, 19.68s/it]

 44%|████▎     | 7033/16104 [32:43:31<48:05:48, 19.09s/it]


 44%|████▎     | 7035/16104 [32:44:12<49:55:38, 19.82s/it]

 44%|████▎     | 7036/16104 [32:44:24<43:55:54, 17.44s/it]
{'loss': 0.4389, 'learning_rate': 1.2503259147905732e-06, 'rewards/chosen': -0.3848324120044708, 'rewards/rejected': -1.3904879093170166, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0056555271148682, 'policy_logps/rejected': -300.5667724609375, 'policy_logps/chosen': -316.9911804199219, 'referece_logps/rejected': -286.6618957519531, 'referece_logps/chosen': -313.1427917480469, 'logits/rejected': -0.33515438437461853, 'logits/chosen': -0.24205031991004944, 'epoch': 2.62}


 44%|████▎     | 7038/16104 [32:44:54<41:07:46, 16.33s/it]
{'loss': 0.5003, 'learning_rate': 1.2499364490359475e-06, 'rewards/chosen': 0.055399298667907715, 'rewards/rejected': -0.9783967733383179, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0337960720062256, 'policy_logps/rejected': -363.3351745605469, 'policy_logps/chosen': -465.6513671875, 'referece_logps/rejected': -353.55120849609375, 'referece_logps/chosen': -466.20538330078125, 'logits/rejected': -0.26697540283203125, 'logits/chosen': -0.2026979625225067, 'epoch': 2.62}

 44%|████▎     | 7039/16104 [32:45:15<44:56:07, 17.85s/it]

 44%|████▎     | 7040/16104 [32:45:37<47:34:30, 18.90s/it]

 44%|████▎     | 7041/16104 [32:45:52<45:08:20, 17.93s/it]


 44%|████▎     | 7043/16104 [32:46:20<39:04:31, 15.52s/it]
{'loss': 0.4249, 'learning_rate': 1.2489626078556852e-06, 'rewards/chosen': -0.2805417776107788, 'rewards/rejected': -1.0024237632751465, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7218819260597229, 'policy_logps/rejected': -389.3284606933594, 'policy_logps/chosen': -479.1623229980469, 'referece_logps/rejected': -379.3042297363281, 'referece_logps/chosen': -476.35693359375, 'logits/rejected': 0.5496823191642761, 'logits/chosen': 0.3397863507270813, 'epoch': 2.62}

 44%|████▎     | 7044/16104 [32:46:33<37:34:07, 14.93s/it]


 44%|████▍     | 7046/16104 [32:47:02<37:21:16, 14.85s/it]
{'loss': 0.5858, 'learning_rate': 1.2483781822327158e-06, 'rewards/chosen': -0.17025335133075714, 'rewards/rejected': -0.7083675265312195, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5381141304969788, 'policy_logps/rejected': -335.46929931640625, 'policy_logps/chosen': -421.2212829589844, 'referece_logps/rejected': -328.3856201171875, 'referece_logps/chosen': -419.51873779296875, 'logits/rejected': -1.0101689100265503, 'logits/chosen': -1.1173282861709595, 'epoch': 2.63}

 44%|████▍     | 7047/16104 [32:47:23<42:02:29, 16.71s/it]


 44%|████▍     | 7049/16104 [32:47:54<39:35:06, 15.74s/it]
{'loss': 0.4245, 'learning_rate': 1.247793666183683e-06, 'rewards/chosen': -0.10155285894870758, 'rewards/rejected': -1.383556604385376, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2820037603378296, 'policy_logps/rejected': -306.72991943359375, 'policy_logps/chosen': -435.82861328125, 'referece_logps/rejected': -292.89434814453125, 'referece_logps/chosen': -434.8130798339844, 'logits/rejected': 0.06818914413452148, 'logits/chosen': 0.02065586857497692, 'epoch': 2.63}

 44%|████▍     | 7050/16104 [32:48:05<35:53:39, 14.27s/it]

 44%|████▍     | 7051/16104 [32:48:16<33:05:57, 13.16s/it]

 44%|████▍     | 7052/16104 [32:48:27<31:34:32, 12.56s/it]

 44%|████▍     | 7053/16104 [32:48:44<34:52:07, 13.87s/it]

 44%|████▍     | 7054/16104 [32:48:56<33:13:34, 13.22s/it]


 44%|████▍     | 7056/16104 [32:49:28<35:52:27, 14.27s/it]
{'loss': 0.4847, 'learning_rate': 1.2464294449411242e-06, 'rewards/chosen': 0.4434995651245117, 'rewards/rejected': -0.4713138937950134, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9148134589195251, 'policy_logps/rejected': -421.9296875, 'policy_logps/chosen': -605.2682495117188, 'referece_logps/rejected': -417.2165222167969, 'referece_logps/chosen': -609.7032470703125, 'logits/rejected': 0.10830269753932953, 'logits/chosen': -0.07719539105892181, 'epoch': 2.63}


 44%|████▍     | 7058/16104 [32:50:03<38:51:44, 15.47s/it]
{'loss': 0.4729, 'learning_rate': 1.2460395776083896e-06, 'rewards/chosen': -0.48152750730514526, 'rewards/rejected': -1.317223310470581, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8356958627700806, 'policy_logps/rejected': -406.40252685546875, 'policy_logps/chosen': -325.934326171875, 'referece_logps/rejected': -393.2303161621094, 'referece_logps/chosen': -321.1190185546875, 'logits/rejected': 0.06526584923267365, 'logits/chosen': 0.3049636483192444, 'epoch': 2.63}


 44%|████▍     | 7060/16104 [32:50:36<41:20:25, 16.46s/it]

 44%|████▍     | 7061/16104 [32:50:57<44:05:04, 17.55s/it]
{'loss': 0.4227, 'learning_rate': 1.2454547019834536e-06, 'rewards/chosen': -0.19532480835914612, 'rewards/rejected': -1.560165524482727, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3648407459259033, 'policy_logps/rejected': -571.9107055664062, 'policy_logps/chosen': -425.979736328125, 'referece_logps/rejected': -556.3090209960938, 'referece_logps/chosen': -424.0264892578125, 'logits/rejected': -0.10866154730319977, 'logits/chosen': -0.11248421669006348, 'epoch': 2.63}

 44%|████▍     | 7062/16104 [32:51:18<47:03:12, 18.73s/it]

 44%|████▍     | 7063/16104 [32:51:38<47:45:16, 19.02s/it]


 44%|████▍     | 7065/16104 [32:52:11<43:44:07, 17.42s/it]
{'loss': 0.4483, 'learning_rate': 1.2446747288465543e-06, 'rewards/chosen': 0.2036292999982834, 'rewards/rejected': -1.6191424131393433, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8227717876434326, 'policy_logps/rejected': -507.05133056640625, 'policy_logps/chosen': -389.35406494140625, 'referece_logps/rejected': -490.8598937988281, 'referece_logps/chosen': -391.3903503417969, 'logits/rejected': -0.19414430856704712, 'logits/chosen': -0.14693143963813782, 'epoch': 2.63}

 44%|████▍     | 7066/16104 [32:52:28<43:48:37, 17.45s/it]


 44%|████▍     | 7068/16104 [32:52:55<38:07:29, 15.19s/it]
{'loss': 0.5485, 'learning_rate': 1.2440896450422147e-06, 'rewards/chosen': -0.17953374981880188, 'rewards/rejected': -1.3645039796829224, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1849700212478638, 'policy_logps/rejected': -223.32394409179688, 'policy_logps/chosen': -343.66387939453125, 'referece_logps/rejected': -209.67889404296875, 'referece_logps/chosen': -341.8685607910156, 'logits/rejected': -0.6421500444412231, 'logits/chosen': -0.7752582430839539, 'epoch': 2.63}

 44%|████▍     | 7069/16104 [32:53:05<34:41:25, 13.82s/it]

 44%|████▍     | 7070/16104 [32:53:24<37:59:07, 15.14s/it]

 44%|████▍     | 7071/16104 [32:53:34<34:35:56, 13.79s/it]

 44%|████▍     | 7072/16104 [32:53:45<32:32:38, 12.97s/it]

 44%|████▍     | 7073/16104 [32:53:59<32:59:34, 13.15s/it]

 44%|████▍     | 7074/16104 [32:54:10<31:53:25, 12.71s/it]

 44%|████▍     | 7075/16104 [32:54:26<33:55:58, 13.53s/it]

 44%|████▍     | 7076/16104 [32:54:43<36:31:38, 14.57s/it]

 44%|████▍     | 7077/16104 [32:54:56<35:43:18, 14.25s/it]

 44%|████▍     | 7078/16104 [32:55:08<33:30:11, 13.36s/it]

 44%|████▍     | 7079/16104 [32:55:28<38:29:12, 15.35s/it]

 44%|████▍     | 7080/16104 [32:55:40<36:26:54, 14.54s/it]

 44%|████▍     | 7081/16104 [32:55:51<33:43:40, 13.46s/it]

 44%|████▍     | 7082/16104 [32:56:09<37:04:28, 14.79s/it]

 44%|████▍     | 7083/16104 [32:56:27<39:19:05, 15.69s/it]

 44%|████▍     | 7084/16104 [32:56:39<36:40:59, 14.64s/it]

 44%|████▍     | 7085/16104 [32:56:56<38:18:21, 15.29s/it]

 44%|████▍     | 7086/16104 [32:57:18<43:26:10, 17.34s/it]

 44%|████▍     | 7087/16104 [32:57:31<40:19:53, 16.10s/it]

 44%|████▍     | 7088/16104 [32:57:43<37:15:32, 14.88s/it]

 44%|████▍     | 7089/16104 [32:57:54<34:12:23, 13.66s/it]

 44%|████▍     | 7090/16104 [32:58:14<39:02:28, 15.59s/it]


 44%|████▍     | 7092/16104 [32:58:46<39:59:27, 15.98s/it]

 44%|████▍     | 7093/16104 [32:58:59<37:47:43, 15.10s/it]

 44%|████▍     | 7094/16104 [32:59:18<41:20:40, 16.52s/it]
{'loss': 0.4346, 'learning_rate': 1.2390152191038784e-06, 'rewards/chosen': -0.28869688510894775, 'rewards/rejected': -1.5610332489013672, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2723362445831299, 'policy_logps/rejected': -338.8743591308594, 'policy_logps/chosen': -351.1207275390625, 'referece_logps/rejected': -323.2640075683594, 'referece_logps/chosen': -348.2337646484375, 'logits/rejected': -0.5836469531059265, 'logits/chosen': -0.6536197662353516, 'epoch': 2.64}


 44%|████▍     | 7096/16104 [32:59:45<37:53:13, 15.14s/it]

 44%|████▍     | 7097/16104 [33:00:00<37:17:43, 14.91s/it]

 44%|████▍     | 7098/16104 [33:00:19<40:52:41, 16.34s/it]
{'loss': 0.4725, 'learning_rate': 1.238233954599867e-06, 'rewards/chosen': -0.9311708211898804, 'rewards/rejected': -1.7634010314941406, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8322300314903259, 'policy_logps/rejected': -297.6143798828125, 'policy_logps/chosen': -371.64385986328125, 'referece_logps/rejected': -279.9803466796875, 'referece_logps/chosen': -362.3321533203125, 'logits/rejected': -1.0029473304748535, 'logits/chosen': -0.8095951080322266, 'epoch': 2.64}


 44%|████▍     | 7100/16104 [33:00:50<38:33:31, 15.42s/it]

 44%|████▍     | 7101/16104 [33:01:06<39:13:17, 15.68s/it]

 44%|████▍     | 7102/16104 [33:01:19<36:41:09, 14.67s/it]

 44%|████▍     | 7103/16104 [33:01:33<36:49:44, 14.73s/it]

 44%|████▍     | 7104/16104 [33:01:44<33:58:45, 13.59s/it]

 44%|████▍     | 7105/16104 [33:02:00<35:44:13, 14.30s/it]

 44%|████▍     | 7106/16104 [33:02:18<38:13:52, 15.30s/it]

 44%|████▍     | 7107/16104 [33:02:31<36:27:15, 14.59s/it]

 44%|████▍     | 7108/16104 [33:02:50<39:51:50, 15.95s/it]

 44%|████▍     | 7109/16104 [33:03:01<35:55:04, 14.38s/it]

 44%|████▍     | 7110/16104 [33:03:13<34:26:21, 13.78s/it]

 44%|████▍     | 7111/16104 [33:03:24<32:03:15, 12.83s/it]

 44%|████▍     | 7112/16104 [33:03:37<32:33:03, 13.03s/it]

 44%|████▍     | 7113/16104 [33:03:58<38:24:10, 15.38s/it]

 44%|████▍     | 7114/16104 [33:04:16<40:03:07, 16.04s/it]

 44%|████▍     | 7115/16104 [33:04:31<39:43:55, 15.91s/it]

 44%|████▍     | 7116/16104 [33:04:47<39:44:48, 15.92s/it]

 44%|████▍     | 7117/16104 [33:05:00<37:40:10, 15.09s/it]

 44%|████▍     | 7118/16104 [33:05:21<41:36:39, 16.67s/it]

 44%|████▍     | 7119/16104 [33:05:38<41:57:30, 16.81s/it]

 44%|████▍     | 7120/16104 [33:06:00<45:59:15, 18.43s/it]

 44%|████▍     | 7121/16104 [33:06:12<41:23:51, 16.59s/it]

 44%|████▍     | 7122/16104 [33:06:28<41:02:43, 16.45s/it]

 44%|████▍     | 7123/16104 [33:06:42<39:05:13, 15.67s/it]
{'loss': 0.4941, 'learning_rate': 1.2333475780982435e-06, 'rewards/chosen': 0.8185840845108032, 'rewards/rejected': -0.48845863342285156, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3070428371429443, 'policy_logps/rejected': -561.8165893554688, 'policy_logps/chosen': -649.0308837890625, 'referece_logps/rejected': -556.9320068359375, 'referece_logps/chosen': -657.2166748046875, 'logits/rejected': 0.43263882398605347, 'logits/chosen': 0.6671293377876282, 'epoch': 2.65}


 44%|████▍     | 7125/16104 [33:07:14<38:15:00, 15.34s/it]

 44%|████▍     | 7126/16104 [33:07:33<41:34:03, 16.67s/it]

 44%|████▍     | 7127/16104 [33:07:52<42:39:39, 17.11s/it]

 44%|████▍     | 7128/16104 [33:08:05<39:56:11, 16.02s/it]

 44%|████▍     | 7129/16104 [33:08:20<39:02:27, 15.66s/it]

 44%|████▍     | 7130/16104 [33:08:35<38:54:02, 15.61s/it]

 44%|████▍     | 7131/16104 [33:08:59<44:41:14, 17.93s/it]

 44%|████▍     | 7132/16104 [33:09:18<45:28:01, 18.24s/it]

 44%|████▍     | 7133/16104 [33:09:37<46:31:14, 18.67s/it]

 44%|████▍     | 7134/16104 [33:09:51<43:02:11, 17.27s/it]

 44%|████▍     | 7135/16104 [33:10:11<44:56:49, 18.04s/it]

 44%|████▍     | 7136/16104 [33:10:31<46:20:25, 18.60s/it]

 44%|████▍     | 7137/16104 [33:10:49<45:28:24, 18.26s/it]

 44%|████▍     | 7138/16104 [33:11:01<40:55:44, 16.43s/it]

 44%|████▍     | 7139/16104 [33:11:12<36:49:31, 14.79s/it]

 44%|████▍     | 7140/16104 [33:11:31<40:28:29, 16.25s/it]

 44%|████▍     | 7141/16104 [33:11:47<40:09:34, 16.13s/it]

 44%|████▍     | 7142/16104 [33:12:07<42:41:11, 17.15s/it]

 44%|████▍     | 7143/16104 [33:12:21<40:12:34, 16.15s/it]

 44%|████▍     | 7144/16104 [33:12:38<41:01:55, 16.49s/it]
{'loss': 0.334, 'learning_rate': 1.2292384575558754e-06, 'rewards/chosen': 0.3978971838951111, 'rewards/rejected': -0.6180880069732666, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0159852504730225, 'policy_logps/rejected': -425.01239013671875, 'policy_logps/chosen': -418.4389343261719, 'referece_logps/rejected': -418.8315124511719, 'referece_logps/chosen': -422.4179382324219, 'logits/rejected': 0.18234127759933472, 'logits/chosen': 0.27201706171035767, 'epoch': 2.66}


 44%|████▍     | 7146/16104 [33:13:13<41:31:24, 16.69s/it]

 44%|████▍     | 7147/16104 [33:13:34<45:19:13, 18.22s/it]

 44%|████▍     | 7148/16104 [33:13:55<46:55:35, 18.86s/it]

 44%|████▍     | 7149/16104 [33:14:07<42:14:29, 16.98s/it]

 44%|████▍     | 7150/16104 [33:14:31<47:17:35, 19.01s/it]

 44%|████▍     | 7151/16104 [33:14:44<43:00:55, 17.30s/it]

 44%|████▍     | 7152/16104 [33:15:02<42:56:46, 17.27s/it]

 44%|████▍     | 7153/16104 [33:15:13<38:37:47, 15.54s/it]

 44%|████▍     | 7154/16104 [33:15:29<39:09:46, 15.75s/it]

 44%|████▍     | 7155/16104 [33:15:50<42:34:13, 17.13s/it]

 44%|████▍     | 7156/16104 [33:16:03<39:43:06, 15.98s/it]

 44%|████▍     | 7157/16104 [33:16:21<41:07:37, 16.55s/it]

 44%|████▍     | 7158/16104 [33:16:33<38:10:06, 15.36s/it]

 44%|████▍     | 7159/16104 [33:16:50<38:44:54, 15.59s/it]

 44%|████▍     | 7160/16104 [33:17:10<42:08:32, 16.96s/it]

 44%|████▍     | 7161/16104 [33:17:25<41:12:08, 16.59s/it]

 44%|████▍     | 7162/16104 [33:17:46<44:18:38, 17.84s/it]

 44%|████▍     | 7163/16104 [33:18:05<44:47:21, 18.03s/it]

 44%|████▍     | 7164/16104 [33:18:24<45:33:53, 18.35s/it]

 44%|████▍     | 7165/16104 [33:18:37<42:01:13, 16.92s/it]

 44%|████▍     | 7166/16104 [33:18:55<42:30:47, 17.12s/it]

 45%|████▍     | 7167/16104 [33:19:08<39:09:53, 15.78s/it]
{'loss': 0.5234, 'learning_rate': 1.2247333026880919e-06, 'rewards/chosen': -0.14654406905174255, 'rewards/rejected': -0.8912111520767212, 'rewards/accuracies': 0.625, 'rewards/margins': 0.744667112827301, 'policy_logps/rejected': -534.7749633789062, 'policy_logps/chosen': -371.60028076171875, 'referece_logps/rejected': -525.8628540039062, 'referece_logps/chosen': -370.13482666015625, 'logits/rejected': -0.1573379933834076, 'logits/chosen': 0.12143883854150772, 'epoch': 2.67}


 45%|████▍     | 7169/16104 [33:19:42<40:43:03, 16.41s/it]

 45%|████▍     | 7170/16104 [33:19:54<37:26:06, 15.08s/it]
{'loss': 0.4073, 'learning_rate': 1.2241453171879649e-06, 'rewards/chosen': 0.48034781217575073, 'rewards/rejected': -1.3320932388305664, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8124412298202515, 'policy_logps/rejected': -552.6710205078125, 'policy_logps/chosen': -534.3143310546875, 'referece_logps/rejected': -539.35009765625, 'referece_logps/chosen': -539.1178588867188, 'logits/rejected': -0.6776717305183411, 'logits/chosen': -0.6095954775810242, 'epoch': 2.67}


 45%|████▍     | 7172/16104 [33:20:28<40:58:05, 16.51s/it]

 45%|████▍     | 7173/16104 [33:20:40<37:04:44, 14.95s/it]

 45%|████▍     | 7174/16104 [33:20:57<39:01:03, 15.73s/it]
{'loss': 0.5123, 'learning_rate': 1.2233612096190426e-06, 'rewards/chosen': -0.8268497586250305, 'rewards/rejected': -0.7443628311157227, 'rewards/accuracies': 0.375, 'rewards/margins': -0.08248700946569443, 'policy_logps/rejected': -325.0268859863281, 'policy_logps/chosen': -431.4061584472656, 'referece_logps/rejected': -317.583251953125, 'referece_logps/chosen': -423.1376037597656, 'logits/rejected': -0.6507349610328674, 'logits/chosen': -0.6573798656463623, 'epoch': 2.67}


 45%|████▍     | 7176/16104 [33:21:32<40:43:22, 16.42s/it]

 45%|████▍     | 7177/16104 [33:21:45<38:18:11, 15.45s/it]

 45%|████▍     | 7178/16104 [33:22:07<42:55:03, 17.31s/it]

 45%|████▍     | 7179/16104 [33:22:18<37:59:15, 15.32s/it]

 45%|████▍     | 7180/16104 [33:22:39<42:47:08, 17.26s/it]

 45%|████▍     | 7181/16104 [33:22:59<44:35:12, 17.99s/it]

 45%|████▍     | 7182/16104 [33:23:19<46:23:58, 18.72s/it]
{'loss': 0.3732, 'learning_rate': 1.2217925612915535e-06, 'rewards/chosen': -0.5167276263237, 'rewards/rejected': -2.489436149597168, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9727083444595337, 'policy_logps/rejected': -453.1256103515625, 'policy_logps/chosen': -451.7042236328125, 'referece_logps/rejected': -428.23126220703125, 'referece_logps/chosen': -446.53692626953125, 'logits/rejected': 0.1137545108795166, 'logits/chosen': 0.012450695037841797, 'epoch': 2.68}


 45%|████▍     | 7184/16104 [33:23:58<46:31:51, 18.78s/it]

 45%|████▍     | 7185/16104 [33:24:19<48:29:58, 19.58s/it]

 45%|████▍     | 7186/16104 [33:24:40<49:41:40, 20.06s/it]

 45%|████▍     | 7187/16104 [33:25:00<49:20:09, 19.92s/it]

 45%|████▍     | 7188/16104 [33:25:18<48:07:45, 19.43s/it]
{'loss': 0.5626, 'learning_rate': 1.220615698003864e-06, 'rewards/chosen': -0.8153026700019836, 'rewards/rejected': -0.9593492150306702, 'rewards/accuracies': 0.625, 'rewards/margins': 0.14404650032520294, 'policy_logps/rejected': -316.99908447265625, 'policy_logps/chosen': -347.79638671875, 'referece_logps/rejected': -307.4056091308594, 'referece_logps/chosen': -339.64337158203125, 'logits/rejected': 0.08837154507637024, 'logits/chosen': 0.004024296998977661, 'epoch': 2.68}


 45%|████▍     | 7190/16104 [33:25:43<38:54:30, 15.71s/it]
{'loss': 0.4797, 'learning_rate': 1.2202233387622733e-06, 'rewards/chosen': 0.19268828630447388, 'rewards/rejected': -0.6897881031036377, 'rewards/accuracies': 0.75, 'rewards/margins': 0.882476270198822, 'policy_logps/rejected': -452.71319580078125, 'policy_logps/chosen': -406.6310729980469, 'referece_logps/rejected': -445.8153381347656, 'referece_logps/chosen': -408.5579833984375, 'logits/rejected': 0.2947584092617035, 'logits/chosen': 0.32517480850219727, 'epoch': 2.68}


 45%|████▍     | 7192/16104 [33:26:11<36:33:55, 14.77s/it]
{'loss': 0.645, 'learning_rate': 1.2198309438869746e-06, 'rewards/chosen': -0.5752958655357361, 'rewards/rejected': -1.602508306503296, 'rewards/accuracies': 0.75, 'rewards/margins': 1.027212381362915, 'policy_logps/rejected': -327.63800048828125, 'policy_logps/chosen': -366.48504638671875, 'referece_logps/rejected': -311.6129150390625, 'referece_logps/chosen': -360.7320861816406, 'logits/rejected': -0.9125410318374634, 'logits/chosen': -1.0015106201171875, 'epoch': 2.68}

 45%|████▍     | 7193/16104 [33:26:27<37:41:18, 15.23s/it]


 45%|████▍     | 7195/16104 [33:26:55<36:14:28, 14.64s/it]

 45%|████▍     | 7196/16104 [33:27:08<35:23:06, 14.30s/it]
{'loss': 0.3642, 'learning_rate': 1.219046047489229e-06, 'rewards/chosen': -0.12408627569675446, 'rewards/rejected': -0.5084043741226196, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3843180537223816, 'policy_logps/rejected': -447.202880859375, 'policy_logps/chosen': -563.967041015625, 'referece_logps/rejected': -442.1188659667969, 'referece_logps/chosen': -562.7261352539062, 'logits/rejected': 0.46225467324256897, 'logits/chosen': 0.40132445096969604, 'epoch': 2.68}


 45%|████▍     | 7198/16104 [33:27:37<35:18:00, 14.27s/it]

 45%|████▍     | 7199/16104 [33:27:48<32:46:21, 13.25s/it]
{'loss': 0.3817, 'learning_rate': 1.2184572821247024e-06, 'rewards/chosen': 0.14468324184417725, 'rewards/rejected': -1.3666234016418457, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5113065242767334, 'policy_logps/rejected': -414.28814697265625, 'policy_logps/chosen': -460.2305908203125, 'referece_logps/rejected': -400.6219482421875, 'referece_logps/chosen': -461.67742919921875, 'logits/rejected': 0.2051769644021988, 'logits/chosen': 0.21471931040287018, 'epoch': 2.68}

 45%|████▍     | 7200/16104 [33:28:09<38:49:55, 15.70s/it]


 45%|████▍     | 7202/16104 [33:28:37<35:49:41, 14.49s/it]

 45%|████▍     | 7203/16104 [33:28:57<39:55:02, 16.14s/it]

 45%|████▍     | 7204/16104 [33:29:08<36:17:25, 14.68s/it]

 45%|████▍     | 7205/16104 [33:29:28<40:06:39, 16.23s/it]

 45%|████▍     | 7206/16104 [33:29:47<42:12:51, 17.08s/it]
{'loss': 0.3703, 'learning_rate': 1.217083187350142e-06, 'rewards/chosen': 0.4232272803783417, 'rewards/rejected': -1.43764066696167, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8608680963516235, 'policy_logps/rejected': -529.0345458984375, 'policy_logps/chosen': -660.5575561523438, 'referece_logps/rejected': -514.6580810546875, 'referece_logps/chosen': -664.7899169921875, 'logits/rejected': 0.03059110790491104, 'logits/chosen': 0.09875980019569397, 'epoch': 2.68}


 45%|████▍     | 7208/16104 [33:30:18<40:48:39, 16.52s/it]

 45%|████▍     | 7209/16104 [33:30:32<38:47:35, 15.70s/it]

 45%|████▍     | 7210/16104 [33:30:50<40:31:03, 16.40s/it]

 45%|████▍     | 7211/16104 [33:31:08<41:26:30, 16.78s/it]
{'loss': 0.473, 'learning_rate': 1.2161014274817257e-06, 'rewards/chosen': -0.10840856283903122, 'rewards/rejected': -0.9030904769897461, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7946818470954895, 'policy_logps/rejected': -482.3013000488281, 'policy_logps/chosen': -520.0001831054688, 'referece_logps/rejected': -473.2703857421875, 'referece_logps/chosen': -518.9161376953125, 'logits/rejected': 0.1389819085597992, 'logits/chosen': 0.15239444375038147, 'epoch': 2.69}

 45%|████▍     | 7212/16104 [33:31:28<43:45:42, 17.72s/it]


 45%|████▍     | 7214/16104 [33:32:07<46:13:08, 18.72s/it]
{'loss': 0.4103, 'learning_rate': 1.2155122665968724e-06, 'rewards/chosen': -0.10461558401584625, 'rewards/rejected': -1.0766915082931519, 'rewards/accuracies': 0.625, 'rewards/margins': 0.972075879573822, 'policy_logps/rejected': -481.28240966796875, 'policy_logps/chosen': -470.83648681640625, 'referece_logps/rejected': -470.5155029296875, 'referece_logps/chosen': -469.79034423828125, 'logits/rejected': -0.15898403525352478, 'logits/chosen': -0.15747129917144775, 'epoch': 2.69}


 45%|████▍     | 7216/16104 [33:32:31<37:56:54, 15.37s/it]

 45%|████▍     | 7217/16104 [33:32:43<35:38:25, 14.44s/it]

 45%|████▍     | 7218/16104 [33:32:56<34:48:19, 14.10s/it]

 45%|████▍     | 7219/16104 [33:33:07<32:17:13, 13.08s/it]
{'loss': 0.4682, 'learning_rate': 1.2145301575376086e-06, 'rewards/chosen': -0.21154889464378357, 'rewards/rejected': -0.8441250324249268, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6325762271881104, 'policy_logps/rejected': -502.6880187988281, 'policy_logps/chosen': -507.4883728027344, 'referece_logps/rejected': -494.24676513671875, 'referece_logps/chosen': -505.3728332519531, 'logits/rejected': -0.1533183455467224, 'logits/chosen': 0.02460765838623047, 'epoch': 2.69}


 45%|████▍     | 7221/16104 [33:33:36<35:13:54, 14.28s/it]
{'loss': 0.5141, 'learning_rate': 1.2141372531113872e-06, 'rewards/chosen': -0.398175984621048, 'rewards/rejected': -1.1870381832122803, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7888622283935547, 'policy_logps/rejected': -378.21697998046875, 'policy_logps/chosen': -344.37237548828125, 'referece_logps/rejected': -366.34661865234375, 'referece_logps/chosen': -340.3905944824219, 'logits/rejected': -0.6094567775726318, 'logits/chosen': -0.43802133202552795, 'epoch': 2.69}


 45%|████▍     | 7223/16104 [33:34:06<35:34:03, 14.42s/it]

 45%|████▍     | 7224/16104 [33:34:25<38:34:18, 15.64s/it]
{'loss': 0.5267, 'learning_rate': 1.2135478315251694e-06, 'rewards/chosen': 0.28886717557907104, 'rewards/rejected': -1.679906964302063, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9687743186950684, 'policy_logps/rejected': -334.3892822265625, 'policy_logps/chosen': -417.5979919433594, 'referece_logps/rejected': -317.5901794433594, 'referece_logps/chosen': -420.4866638183594, 'logits/rejected': -0.1622370481491089, 'logits/chosen': 0.01699896901845932, 'epoch': 2.69}


 45%|████▍     | 7226/16104 [33:34:51<34:40:04, 14.06s/it]

 45%|████▍     | 7227/16104 [33:35:01<32:13:59, 13.07s/it]

 45%|████▍     | 7228/16104 [33:35:19<35:24:17, 14.36s/it]

 45%|████▍     | 7229/16104 [33:35:35<37:01:25, 15.02s/it]

 45%|████▍     | 7230/16104 [33:35:55<40:44:45, 16.53s/it]

 45%|████▍     | 7231/16104 [33:36:15<43:00:10, 17.45s/it]

 45%|████▍     | 7232/16104 [33:36:36<45:52:44, 18.62s/it]
{'loss': 0.3394, 'learning_rate': 1.2119756611223237e-06, 'rewards/chosen': -0.02977713756263256, 'rewards/rejected': -0.6483180522918701, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6185410022735596, 'policy_logps/rejected': -310.00146484375, 'policy_logps/chosen': -395.5768127441406, 'referece_logps/rejected': -303.5182800292969, 'referece_logps/chosen': -395.2790222167969, 'logits/rejected': 0.12313269078731537, 'logits/chosen': 0.10240904241800308, 'epoch': 2.69}

 45%|████▍     | 7233/16104 [33:36:56<46:35:33, 18.91s/it]


 45%|████▍     | 7235/16104 [33:37:30<44:17:23, 17.98s/it]

 45%|████▍     | 7236/16104 [33:37:48<44:16:55, 17.98s/it]

 45%|████▍     | 7237/16104 [33:38:07<44:35:45, 18.11s/it]

 45%|████▍     | 7238/16104 [33:38:25<44:36:06, 18.11s/it]
{'loss': 0.3928, 'learning_rate': 1.210796172956285e-06, 'rewards/chosen': -1.27711820602417, 'rewards/rejected': -2.972968578338623, 'rewards/accuracies': 0.875, 'rewards/margins': 1.695850133895874, 'policy_logps/rejected': -389.94744873046875, 'policy_logps/chosen': -283.0937194824219, 'referece_logps/rejected': -360.2177734375, 'referece_logps/chosen': -270.3225402832031, 'logits/rejected': -0.3298725485801697, 'logits/chosen': -0.40796521306037903, 'epoch': 2.7}

 45%|████▍     | 7239/16104 [33:38:46<46:53:57, 19.05s/it]


 45%|████▍     | 7241/16104 [33:39:13<40:11:45, 16.33s/it]
{'loss': 0.5075, 'learning_rate': 1.2102063136503104e-06, 'rewards/chosen': -0.01953563466668129, 'rewards/rejected': -0.9633324146270752, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9437967538833618, 'policy_logps/rejected': -471.7939453125, 'policy_logps/chosen': -421.4742431640625, 'referece_logps/rejected': -462.16058349609375, 'referece_logps/chosen': -421.27886962890625, 'logits/rejected': -0.7886537313461304, 'logits/chosen': -0.7211079001426697, 'epoch': 2.7}


 45%|████▍     | 7243/16104 [33:39:39<35:59:09, 14.62s/it]
{'loss': 0.5131, 'learning_rate': 1.2098130315836353e-06, 'rewards/chosen': 0.14959748089313507, 'rewards/rejected': -0.7377675771713257, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8873650431632996, 'policy_logps/rejected': -365.27520751953125, 'policy_logps/chosen': -413.8677062988281, 'referece_logps/rejected': -357.8975524902344, 'referece_logps/chosen': -415.3636779785156, 'logits/rejected': -0.5913397669792175, 'logits/chosen': -0.5775064826011658, 'epoch': 2.7}

 45%|████▍     | 7244/16104 [33:39:54<36:18:00, 14.75s/it]

 45%|████▍     | 7245/16104 [33:40:14<40:05:15, 16.29s/it]

 45%|████▍     | 7246/16104 [33:40:26<37:08:49, 15.10s/it]


 45%|████▌     | 7248/16104 [33:41:07<44:07:27, 17.94s/it]

 45%|████▌     | 7249/16104 [33:41:27<45:39:38, 18.56s/it]

 45%|████▌     | 7250/16104 [33:41:47<46:29:59, 18.91s/it]

 45%|████▌     | 7251/16104 [33:42:04<44:50:57, 18.24s/it]
{'loss': 0.4811, 'learning_rate': 1.208239564460918e-06, 'rewards/chosen': -0.23221471905708313, 'rewards/rejected': -1.800262451171875, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5680476427078247, 'policy_logps/rejected': -440.80426025390625, 'policy_logps/chosen': -326.11669921875, 'referece_logps/rejected': -422.80169677734375, 'referece_logps/chosen': -323.7945556640625, 'logits/rejected': -0.6915404796600342, 'logits/chosen': -0.6809806823730469, 'epoch': 2.7}


 45%|████▌     | 7253/16104 [33:42:35<40:44:45, 16.57s/it]

 45%|████▌     | 7254/16104 [33:42:53<41:44:39, 16.98s/it]
{'loss': 0.5473, 'learning_rate': 1.207649375080666e-06, 'rewards/chosen': -0.36218899488449097, 'rewards/rejected': -0.590543806552887, 'rewards/accuracies': 0.625, 'rewards/margins': 0.22835473716259003, 'policy_logps/rejected': -524.3131103515625, 'policy_logps/chosen': -509.3176574707031, 'referece_logps/rejected': -518.40771484375, 'referece_logps/chosen': -505.6957702636719, 'logits/rejected': -0.28196287155151367, 'logits/chosen': -0.2684202790260315, 'epoch': 2.7}

 45%|████▌     | 7255/16104 [33:43:13<43:31:14, 17.71s/it]


 45%|████▌     | 7257/16104 [33:43:54<47:18:05, 19.25s/it]

 45%|████▌     | 7258/16104 [33:44:13<47:24:44, 19.30s/it]

 45%|████▌     | 7259/16104 [33:44:29<45:03:40, 18.34s/it]

 45%|████▌     | 7260/16104 [33:44:49<46:19:58, 18.86s/it]
{'loss': 0.419, 'learning_rate': 1.2064687697407937e-06, 'rewards/chosen': -1.543338418006897, 'rewards/rejected': -3.1827564239501953, 'rewards/accuracies': 0.75, 'rewards/margins': 1.639418125152588, 'policy_logps/rejected': -654.3804931640625, 'policy_logps/chosen': -512.490966796875, 'referece_logps/rejected': -622.5529174804688, 'referece_logps/chosen': -497.05755615234375, 'logits/rejected': -0.07007786631584167, 'logits/chosen': 0.0723964273929596, 'epoch': 2.7}

 45%|████▌     | 7261/16104 [33:45:09<46:46:49, 19.04s/it]

 45%|████▌     | 7262/16104 [33:45:29<47:27:17, 19.32s/it]


 45%|████▌     | 7264/16104 [33:46:02<44:01:27, 17.93s/it]

 45%|████▌     | 7265/16104 [33:46:24<47:14:31, 19.24s/it]

 45%|████▌     | 7266/16104 [33:46:43<47:01:52, 19.16s/it]
{'loss': 0.3302, 'learning_rate': 1.2052878637278705e-06, 'rewards/chosen': -0.483333557844162, 'rewards/rejected': -1.9970353841781616, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5137019157409668, 'policy_logps/rejected': -586.7174072265625, 'policy_logps/chosen': -661.6837158203125, 'referece_logps/rejected': -566.7470703125, 'referece_logps/chosen': -656.8504028320312, 'logits/rejected': -0.339063823223114, 'logits/chosen': -0.4219915270805359, 'epoch': 2.71}


 45%|████▌     | 7268/16104 [33:47:19<45:31:43, 18.55s/it]
{'loss': 0.3443, 'learning_rate': 1.2048941618712172e-06, 'rewards/chosen': -0.8092731833457947, 'rewards/rejected': -1.970824122428894, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1615508794784546, 'policy_logps/rejected': -365.4686279296875, 'policy_logps/chosen': -408.6721496582031, 'referece_logps/rejected': -345.76043701171875, 'referece_logps/chosen': -400.57940673828125, 'logits/rejected': 0.1578160524368286, 'logits/chosen': -0.058823615312576294, 'epoch': 2.71}

 45%|████▌     | 7269/16104 [33:47:31<40:21:18, 16.44s/it]


 45%|████▌     | 7271/16104 [33:47:59<38:18:36, 15.61s/it]

 45%|████▌     | 7272/16104 [33:48:18<40:19:15, 16.44s/it]

 45%|████▌     | 7273/16104 [33:48:40<44:29:17, 18.14s/it]

 45%|████▌     | 7274/16104 [33:48:55<42:28:55, 17.32s/it]

 45%|████▌     | 7275/16104 [33:49:15<44:17:08, 18.06s/it]

 45%|████▌     | 7276/16104 [33:49:35<45:45:17, 18.66s/it]
{'loss': 0.4084, 'learning_rate': 1.2033190235483467e-06, 'rewards/chosen': 0.09238511323928833, 'rewards/rejected': -1.3304563760757446, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4228414297103882, 'policy_logps/rejected': -606.749755859375, 'policy_logps/chosen': -462.216796875, 'referece_logps/rejected': -593.4451293945312, 'referece_logps/chosen': -463.1406555175781, 'logits/rejected': 0.02217785269021988, 'logits/chosen': 0.12930262088775635, 'epoch': 2.71}

 45%|████▌     | 7277/16104 [33:49:55<46:38:24, 19.02s/it]


 45%|████▌     | 7279/16104 [33:50:32<46:09:28, 18.83s/it]
{'loss': 0.4963, 'learning_rate': 1.202728210752042e-06, 'rewards/chosen': -0.14870797097682953, 'rewards/rejected': -0.8190920352935791, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6703840494155884, 'policy_logps/rejected': -389.50555419921875, 'policy_logps/chosen': -341.93194580078125, 'referece_logps/rejected': -381.31463623046875, 'referece_logps/chosen': -340.44488525390625, 'logits/rejected': 0.5058320164680481, 'logits/chosen': 0.6424334049224854, 'epoch': 2.71}

 45%|████▌     | 7280/16104 [33:50:51<46:17:57, 18.89s/it]


 45%|████▌     | 7282/16104 [33:51:26<44:14:07, 18.05s/it]
{'loss': 0.483, 'learning_rate': 1.2021373241492785e-06, 'rewards/chosen': -0.27605876326560974, 'rewards/rejected': -0.9260063171386719, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6499475836753845, 'policy_logps/rejected': -325.935546875, 'policy_logps/chosen': -383.3500671386719, 'referece_logps/rejected': -316.6755065917969, 'referece_logps/chosen': -380.5894470214844, 'logits/rejected': -0.0932481437921524, 'logits/chosen': -0.1914285570383072, 'epoch': 2.71}


 45%|████▌     | 7284/16104 [33:52:06<46:24:11, 18.94s/it]

 45%|████▌     | 7285/16104 [33:52:24<46:15:51, 18.89s/it]
{'loss': 0.3965, 'learning_rate': 1.2015463639551775e-06, 'rewards/chosen': -0.11058346927165985, 'rewards/rejected': -1.4994555711746216, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3888720273971558, 'policy_logps/rejected': -528.416015625, 'policy_logps/chosen': -678.852783203125, 'referece_logps/rejected': -513.4214477539062, 'referece_logps/chosen': -677.7469482421875, 'logits/rejected': 0.017357729375362396, 'logits/chosen': 0.003176361322402954, 'epoch': 2.71}


 45%|████▌     | 7287/16104 [33:53:02<46:27:36, 18.97s/it]

 45%|████▌     | 7288/16104 [33:53:18<44:37:45, 18.22s/it]
{'loss': 0.4494, 'learning_rate': 1.2009553303848875e-06, 'rewards/chosen': -1.4173132181167603, 'rewards/rejected': -2.5583009719848633, 'rewards/accuracies': 0.75, 'rewards/margins': 1.140987753868103, 'policy_logps/rejected': -509.3690490722656, 'policy_logps/chosen': -509.599365234375, 'referece_logps/rejected': -483.78607177734375, 'referece_logps/chosen': -495.42620849609375, 'logits/rejected': -0.36723774671554565, 'logits/chosen': -0.3647798001766205, 'epoch': 2.72}


 45%|████▌     | 7290/16104 [33:53:56<45:51:03, 18.73s/it]
{'loss': 0.4584, 'learning_rate': 1.2005612673464034e-06, 'rewards/chosen': -0.052931711077690125, 'rewards/rejected': -2.0150492191314697, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9621175527572632, 'policy_logps/rejected': -476.3619689941406, 'policy_logps/chosen': -472.8670654296875, 'referece_logps/rejected': -456.21148681640625, 'referece_logps/chosen': -472.33770751953125, 'logits/rejected': 0.24296355247497559, 'logits/chosen': 0.24129660427570343, 'epoch': 2.72}

 45%|████▌     | 7291/16104 [33:54:15<46:04:04, 18.82s/it]


 45%|████▌     | 7293/16104 [33:54:57<48:07:27, 19.66s/it]
{'loss': 0.407, 'learning_rate': 1.1999701119606462e-06, 'rewards/chosen': -0.4506370425224304, 'rewards/rejected': -1.4870898723602295, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0364526510238647, 'policy_logps/rejected': -318.48614501953125, 'policy_logps/chosen': -356.2112731933594, 'referece_logps/rejected': -303.615234375, 'referece_logps/chosen': -351.70489501953125, 'logits/rejected': -0.85905522108078, 'logits/chosen': -0.6601121425628662, 'epoch': 2.72}

 45%|████▌     | 7294/16104 [33:55:11<44:04:32, 18.01s/it]

 45%|████▌     | 7295/16104 [33:55:30<44:44:42, 18.29s/it]


 45%|████▌     | 7297/16104 [33:56:06<44:46:48, 18.30s/it]

 45%|████▌     | 7298/16104 [33:56:26<45:58:24, 18.79s/it]
{'loss': 0.3786, 'learning_rate': 1.1989846913077242e-06, 'rewards/chosen': -0.8668959140777588, 'rewards/rejected': -2.5200607776641846, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6531647443771362, 'policy_logps/rejected': -559.3641967773438, 'policy_logps/chosen': -593.5672607421875, 'referece_logps/rejected': -534.1636962890625, 'referece_logps/chosen': -584.8982543945312, 'logits/rejected': 0.29702693223953247, 'logits/chosen': 0.218157097697258, 'epoch': 2.72}

 45%|████▌     | 7299/16104 [33:56:46<46:30:48, 19.02s/it]

 45%|████▌     | 7300/16104 [33:56:59<42:22:50, 17.33s/it]

 45%|████▌     | 7301/16104 [33:57:17<42:55:05, 17.55s/it]


 45%|████▌     | 7303/16104 [33:57:45<38:08:41, 15.60s/it]
{'loss': 0.4286, 'learning_rate': 1.1979990694226725e-06, 'rewards/chosen': -0.5738072991371155, 'rewards/rejected': -1.3603678941726685, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7865605354309082, 'policy_logps/rejected': -333.13726806640625, 'policy_logps/chosen': -368.0268859863281, 'referece_logps/rejected': -319.5335998535156, 'referece_logps/chosen': -362.2888488769531, 'logits/rejected': -0.6365982294082642, 'logits/chosen': -0.5870056748390198, 'epoch': 2.72}

 45%|████▌     | 7304/16104 [33:58:00<37:54:33, 15.51s/it]

 45%|████▌     | 7305/16104 [33:58:20<40:54:54, 16.74s/it]


 45%|████▌     | 7307/16104 [33:58:59<44:27:07, 18.19s/it]

 45%|████▌     | 7308/16104 [33:59:16<43:58:04, 18.00s/it]
{'loss': 0.4285, 'learning_rate': 1.1970132473022445e-06, 'rewards/chosen': -0.3329674005508423, 'rewards/rejected': -1.6598122119903564, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3268449306488037, 'policy_logps/rejected': -383.9757080078125, 'policy_logps/chosen': -583.3756103515625, 'referece_logps/rejected': -367.3775939941406, 'referece_logps/chosen': -580.0458984375, 'logits/rejected': -0.4575895369052887, 'logits/chosen': -0.4722077250480652, 'epoch': 2.72}

 45%|████▌     | 7309/16104 [33:59:35<44:33:48, 18.24s/it]

 45%|████▌     | 7310/16104 [33:59:48<40:17:00, 16.49s/it]

 45%|████▌     | 7311/16104 [34:00:07<42:32:40, 17.42s/it]

 45%|████▌     | 7312/16104 [34:00:23<41:27:10, 16.97s/it]

 45%|████▌     | 7313/16104 [34:00:39<40:40:57, 16.66s/it]

 45%|████▌     | 7314/16104 [34:00:58<41:55:38, 17.17s/it]


 45%|████▌     | 7316/16104 [34:01:39<46:02:00, 18.86s/it]
{'loss': 0.4414, 'learning_rate': 1.195435517908457e-06, 'rewards/chosen': -0.499592125415802, 'rewards/rejected': -1.9906153678894043, 'rewards/accuracies': 1.0, 'rewards/margins': 1.491023302078247, 'policy_logps/rejected': -436.32208251953125, 'policy_logps/chosen': -590.3032836914062, 'referece_logps/rejected': -416.41595458984375, 'referece_logps/chosen': -585.3074951171875, 'logits/rejected': -0.3929651975631714, 'logits/chosen': -0.40291717648506165, 'epoch': 2.73}


 45%|████▌     | 7318/16104 [34:02:01<36:05:14, 14.79s/it]
{'loss': 0.5036, 'learning_rate': 1.1950410063432888e-06, 'rewards/chosen': -0.20881442725658417, 'rewards/rejected': -1.4965088367462158, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2876944541931152, 'policy_logps/rejected': -319.9378967285156, 'policy_logps/chosen': -393.85662841796875, 'referece_logps/rejected': -304.9727783203125, 'referece_logps/chosen': -391.76849365234375, 'logits/rejected': 0.12053092569112778, 'logits/chosen': 0.027167126536369324, 'epoch': 2.73}

 45%|████▌     | 7319/16104 [34:02:11<33:03:42, 13.55s/it]


 45%|████▌     | 7321/16104 [34:02:48<39:24:07, 16.15s/it]

 45%|████▌     | 7322/16104 [34:03:05<39:35:35, 16.23s/it]

 45%|████▌     | 7323/16104 [34:03:25<42:25:17, 17.39s/it]

 45%|████▌     | 7324/16104 [34:03:43<42:35:14, 17.46s/it]
{'loss': 0.4104, 'learning_rate': 1.1938572825489883e-06, 'rewards/chosen': -0.616950273513794, 'rewards/rejected': -1.1876198053359985, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5706695914268494, 'policy_logps/rejected': -416.6969909667969, 'policy_logps/chosen': -360.9705810546875, 'referece_logps/rejected': -404.82080078125, 'referece_logps/chosen': -354.80108642578125, 'logits/rejected': -0.22455713152885437, 'logits/chosen': -0.2052181363105774, 'epoch': 2.73}

 45%|████▌     | 7325/16104 [34:03:54<38:27:23, 15.77s/it]


 45%|████▌     | 7327/16104 [34:04:33<43:08:10, 17.69s/it]
{'loss': 0.4176, 'learning_rate': 1.1932653146788101e-06, 'rewards/chosen': -0.2850339412689209, 'rewards/rejected': -2.634000301361084, 'rewards/accuracies': 1.0, 'rewards/margins': 2.348966360092163, 'policy_logps/rejected': -458.91400146484375, 'policy_logps/chosen': -482.8252258300781, 'referece_logps/rejected': -432.5740051269531, 'referece_logps/chosen': -479.974853515625, 'logits/rejected': 0.18478849530220032, 'logits/chosen': 0.23151499032974243, 'epoch': 2.73}

 46%|████▌     | 7328/16104 [34:04:54<45:46:50, 18.78s/it]


 46%|████▌     | 7330/16104 [34:05:25<41:40:24, 17.10s/it]

 46%|████▌     | 7331/16104 [34:05:43<42:11:31, 17.31s/it]

 46%|████▌     | 7332/16104 [34:06:03<43:59:09, 18.05s/it]
{'loss': 0.5607, 'learning_rate': 1.1922785453097527e-06, 'rewards/chosen': -1.4052810668945312, 'rewards/rejected': -1.455141305923462, 'rewards/accuracies': 0.5, 'rewards/margins': 0.04986017197370529, 'policy_logps/rejected': -300.07794189453125, 'policy_logps/chosen': -313.56549072265625, 'referece_logps/rejected': -285.5265197753906, 'referece_logps/chosen': -299.5126647949219, 'logits/rejected': -0.1528368443250656, 'logits/chosen': -0.18790364265441895, 'epoch': 2.73}


 46%|████▌     | 7334/16104 [34:06:27<36:53:47, 15.15s/it]

 46%|████▌     | 7335/16104 [34:06:49<41:51:56, 17.19s/it]
{'loss': 0.382, 'learning_rate': 1.191686390288328e-06, 'rewards/chosen': -0.6184698343276978, 'rewards/rejected': -1.784648060798645, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1661781072616577, 'policy_logps/rejected': -375.69537353515625, 'policy_logps/chosen': -520.0916137695312, 'referece_logps/rejected': -357.8488464355469, 'referece_logps/chosen': -513.9068603515625, 'logits/rejected': -0.6076014637947083, 'logits/chosen': -0.5202940702438354, 'epoch': 2.73}


 46%|████▌     | 7337/16104 [34:07:19<38:10:51, 15.68s/it]

 46%|████▌     | 7338/16104 [34:07:35<38:34:59, 15.85s/it]

 46%|████▌     | 7339/16104 [34:07:51<38:32:03, 15.83s/it]
{'loss': 0.5587, 'learning_rate': 1.1908967417402376e-06, 'rewards/chosen': -0.4672628343105316, 'rewards/rejected': -1.293291449546814, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8260285258293152, 'policy_logps/rejected': -450.1265563964844, 'policy_logps/chosen': -550.025634765625, 'referece_logps/rejected': -437.1936340332031, 'referece_logps/chosen': -545.35302734375, 'logits/rejected': -0.7125904560089111, 'logits/chosen': -0.6088482737541199, 'epoch': 2.73}

 46%|████▌     | 7340/16104 [34:08:02<35:12:48, 14.46s/it]


 46%|████▌     | 7342/16104 [34:08:35<36:39:30, 15.06s/it]

 46%|████▌     | 7343/16104 [34:08:45<33:23:52, 13.72s/it]
{'loss': 0.3982, 'learning_rate': 1.1901069696383319e-06, 'rewards/chosen': 0.13176706433296204, 'rewards/rejected': -0.6975506544113159, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8293177485466003, 'policy_logps/rejected': -360.83184814453125, 'policy_logps/chosen': -471.9322204589844, 'referece_logps/rejected': -353.8563537597656, 'referece_logps/chosen': -473.2499084472656, 'logits/rejected': -0.6003491282463074, 'logits/chosen': -0.5119299292564392, 'epoch': 2.74}


 46%|████▌     | 7345/16104 [34:09:17<35:44:47, 14.69s/it]

 46%|████▌     | 7346/16104 [34:09:27<32:44:46, 13.46s/it]

 46%|████▌     | 7347/16104 [34:09:45<35:45:42, 14.70s/it]
{'loss': 0.3171, 'learning_rate': 1.1893170744937737e-06, 'rewards/chosen': -0.2726289629936218, 'rewards/rejected': -1.232604742050171, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9599758386611938, 'policy_logps/rejected': -458.76922607421875, 'policy_logps/chosen': -330.3090515136719, 'referece_logps/rejected': -446.4432067871094, 'referece_logps/chosen': -327.5827941894531, 'logits/rejected': -0.4335938096046448, 'logits/chosen': -0.4437485635280609, 'epoch': 2.74}

 46%|████▌     | 7348/16104 [34:09:58<34:28:02, 14.17s/it]

 46%|████▌     | 7349/16104 [34:10:13<34:46:49, 14.30s/it]

 46%|████▌     | 7350/16104 [34:10:26<34:23:46, 14.15s/it]

 46%|████▌     | 7351/16104 [34:10:44<37:06:32, 15.26s/it]

 46%|████▌     | 7352/16104 [34:10:56<34:21:31, 14.13s/it]


 46%|████▌     | 7354/16104 [34:11:27<35:30:35, 14.61s/it]
{'loss': 0.4632, 'learning_rate': 1.1879344634571812e-06, 'rewards/chosen': -1.0429679155349731, 'rewards/rejected': -2.118452548980713, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0754847526550293, 'policy_logps/rejected': -236.92703247070312, 'policy_logps/chosen': -346.74627685546875, 'referece_logps/rejected': -215.74249267578125, 'referece_logps/chosen': -336.31658935546875, 'logits/rejected': -0.4030804932117462, 'logits/chosen': -0.4769691526889801, 'epoch': 2.74}

 46%|████▌     | 7355/16104 [34:11:46<38:47:19, 15.96s/it]

 46%|████▌     | 7356/16104 [34:12:06<41:31:20, 17.09s/it]


 46%|████▌     | 7358/16104 [34:12:39<41:25:40, 17.05s/it]
{'loss': 0.4706, 'learning_rate': 1.1871442325816624e-06, 'rewards/chosen': -0.11270198971033096, 'rewards/rejected': -0.8718892931938171, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7591873407363892, 'policy_logps/rejected': -377.7904968261719, 'policy_logps/chosen': -419.502685546875, 'referece_logps/rejected': -369.07159423828125, 'referece_logps/chosen': -418.3756408691406, 'logits/rejected': -0.32717379927635193, 'logits/chosen': -0.3956632614135742, 'epoch': 2.74}

 46%|████▌     | 7359/16104 [34:12:59<43:17:55, 17.82s/it]

 46%|████▌     | 7360/16104 [34:13:20<46:00:23, 18.94s/it]

 46%|████▌     | 7361/16104 [34:13:39<45:19:34, 18.66s/it]


 46%|████▌     | 7363/16104 [34:14:10<42:26:54, 17.48s/it]

 46%|████▌     | 7364/16104 [34:14:30<44:00:24, 18.13s/it]

 46%|████▌     | 7365/16104 [34:14:46<42:36:44, 17.55s/it]
{'loss': 0.4249, 'learning_rate': 1.1857610373999884e-06, 'rewards/chosen': -0.48347920179367065, 'rewards/rejected': -1.9913922548294067, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5079128742218018, 'policy_logps/rejected': -318.6854553222656, 'policy_logps/chosen': -284.4009704589844, 'referece_logps/rejected': -298.77154541015625, 'referece_logps/chosen': -279.5661926269531, 'logits/rejected': 0.3276783227920532, 'logits/chosen': 0.5776407122612, 'epoch': 2.74}


 46%|████▌     | 7367/16104 [34:15:16<40:14:35, 16.58s/it]
{'loss': 0.4765, 'learning_rate': 1.185365771027458e-06, 'rewards/chosen': -0.38107872009277344, 'rewards/rejected': -1.3192142248153687, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9381355047225952, 'policy_logps/rejected': -485.8743591308594, 'policy_logps/chosen': -421.2109069824219, 'referece_logps/rejected': -472.68218994140625, 'referece_logps/chosen': -417.4001159667969, 'logits/rejected': -0.9761755466461182, 'logits/chosen': -0.8890472054481506, 'epoch': 2.74}

 46%|████▌     | 7368/16104 [34:15:30<38:47:15, 15.98s/it]


 46%|████▌     | 7370/16104 [34:16:06<41:00:37, 16.90s/it]

 46%|████▌     | 7371/16104 [34:16:28<44:37:48, 18.40s/it]

 46%|████▌     | 7372/16104 [34:16:48<45:41:30, 18.84s/it]
{'loss': 0.5282, 'learning_rate': 1.1843774740144672e-06, 'rewards/chosen': -0.366629421710968, 'rewards/rejected': -1.4843323230743408, 'rewards/accuracies': 0.75, 'rewards/margins': 1.117702841758728, 'policy_logps/rejected': -547.4521484375, 'policy_logps/chosen': -472.99346923828125, 'referece_logps/rejected': -532.60888671875, 'referece_logps/chosen': -469.3271484375, 'logits/rejected': -0.24861732125282288, 'logits/chosen': -0.4097483456134796, 'epoch': 2.75}

 46%|████▌     | 7373/16104 [34:17:01<41:42:22, 17.20s/it]


 46%|████▌     | 7375/16104 [34:17:28<36:27:11, 15.03s/it]
{'loss': 0.5811, 'learning_rate': 1.1837844062419327e-06, 'rewards/chosen': -0.6829668283462524, 'rewards/rejected': -1.027856469154358, 'rewards/accuracies': 0.375, 'rewards/margins': 0.3448895812034607, 'policy_logps/rejected': -380.586181640625, 'policy_logps/chosen': -430.5664978027344, 'referece_logps/rejected': -370.3076171875, 'referece_logps/chosen': -423.73681640625, 'logits/rejected': -0.7792412638664246, 'logits/chosen': -0.7705755233764648, 'epoch': 2.75}


 46%|████▌     | 7377/16104 [34:17:56<34:37:52, 14.29s/it]

 46%|████▌     | 7378/16104 [34:18:08<32:59:42, 13.61s/it]

 46%|████▌     | 7379/16104 [34:18:20<31:36:44, 13.04s/it]

 46%|████▌     | 7380/16104 [34:18:34<32:27:23, 13.39s/it]

 46%|████▌     | 7381/16104 [34:18:50<34:15:07, 14.14s/it]

 46%|████▌     | 7382/16104 [34:19:06<35:50:03, 14.79s/it]
{'loss': 0.5374, 'learning_rate': 1.1824003216083407e-06, 'rewards/chosen': 0.32243216037750244, 'rewards/rejected': -0.695220410823822, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0176525115966797, 'policy_logps/rejected': -487.4391784667969, 'policy_logps/chosen': -531.81640625, 'referece_logps/rejected': -480.4869384765625, 'referece_logps/chosen': -535.0407104492188, 'logits/rejected': -0.26212143898010254, 'logits/chosen': -0.25243446230888367, 'epoch': 2.75}

 46%|████▌     | 7383/16104 [34:19:17<32:52:48, 13.57s/it]

 46%|████▌     | 7384/16104 [34:19:34<35:44:58, 14.76s/it]

 46%|████▌     | 7385/16104 [34:19:51<37:22:52, 15.43s/it]


 46%|████▌     | 7387/16104 [34:20:32<43:24:25, 17.93s/it]
{'loss': 0.4572, 'learning_rate': 1.1814114682146882e-06, 'rewards/chosen': -0.3579784631729126, 'rewards/rejected': -1.3014541864395142, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9434757232666016, 'policy_logps/rejected': -681.8173217773438, 'policy_logps/chosen': -483.36627197265625, 'referece_logps/rejected': -668.802734375, 'referece_logps/chosen': -479.7865295410156, 'logits/rejected': -0.7180653810501099, 'logits/chosen': -0.5060756206512451, 'epoch': 2.75}

 46%|████▌     | 7388/16104 [34:20:43<38:11:57, 15.78s/it]

 46%|████▌     | 7389/16104 [34:20:55<35:28:34, 14.65s/it]

 46%|████▌     | 7390/16104 [34:21:13<38:33:38, 15.93s/it]


 46%|████▌     | 7392/16104 [34:21:46<39:50:23, 16.46s/it]
{'loss': 0.4328, 'learning_rate': 1.1804224313606102e-06, 'rewards/chosen': -0.7786518335342407, 'rewards/rejected': -2.152764081954956, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3741123676300049, 'policy_logps/rejected': -365.481689453125, 'policy_logps/chosen': -653.3485717773438, 'referece_logps/rejected': -343.95404052734375, 'referece_logps/chosen': -645.56201171875, 'logits/rejected': -0.3066878914833069, 'logits/chosen': -0.5166578888893127, 'epoch': 2.75}

 46%|████▌     | 7393/16104 [34:22:06<42:16:30, 17.47s/it]

 46%|████▌     | 7394/16104 [34:22:28<45:16:28, 18.71s/it]

 46%|████▌     | 7395/16104 [34:22:46<45:06:00, 18.64s/it]

 46%|████▌     | 7396/16104 [34:23:00<41:39:46, 17.22s/it]

 46%|████▌     | 7397/16104 [34:23:16<41:02:26, 16.97s/it]

 46%|████▌     | 7398/16104 [34:23:34<41:31:12, 17.17s/it]

 46%|████▌     | 7399/16104 [34:23:51<40:59:06, 16.95s/it]

 46%|████▌     | 7400/16104 [34:24:10<42:44:26, 17.68s/it]

 46%|████▌     | 7401/16104 [34:24:30<44:16:37, 18.32s/it]

 46%|████▌     | 7402/16104 [34:24:48<44:24:20, 18.37s/it]

 46%|████▌     | 7403/16104 [34:25:00<39:19:55, 16.27s/it]

 46%|████▌     | 7404/16104 [34:25:19<41:43:20, 17.26s/it]

 46%|████▌     | 7405/16104 [34:25:37<41:52:04, 17.33s/it]

 46%|████▌     | 7406/16104 [34:25:56<43:30:41, 18.01s/it]


 46%|████▌     | 7408/16104 [34:26:27<39:45:28, 16.46s/it]
{'loss': 0.3139, 'learning_rate': 1.177256292225099e-06, 'rewards/chosen': -0.27026310563087463, 'rewards/rejected': -1.6145951747894287, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3443318605422974, 'policy_logps/rejected': -505.1028747558594, 'policy_logps/chosen': -458.52197265625, 'referece_logps/rejected': -488.9569091796875, 'referece_logps/chosen': -455.8193664550781, 'logits/rejected': -0.5546214580535889, 'logits/chosen': -0.3650588393211365, 'epoch': 2.76}

 46%|████▌     | 7409/16104 [34:26:45<40:57:24, 16.96s/it]

 46%|████▌     | 7410/16104 [34:27:02<40:50:10, 16.91s/it]

 46%|████▌     | 7411/16104 [34:27:14<37:51:29, 15.68s/it]

 46%|████▌     | 7412/16104 [34:27:34<40:52:13, 16.93s/it]

 46%|████▌     | 7413/16104 [34:27:50<39:48:18, 16.49s/it]


 46%|████▌     | 7415/16104 [34:28:31<44:33:20, 18.46s/it]
{'loss': 0.4176, 'learning_rate': 1.1758705272081437e-06, 'rewards/chosen': -0.41301271319389343, 'rewards/rejected': -1.300714373588562, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8877016305923462, 'policy_logps/rejected': -394.5013122558594, 'policy_logps/chosen': -417.9428405761719, 'referece_logps/rejected': -381.4941101074219, 'referece_logps/chosen': -413.812744140625, 'logits/rejected': -0.0966312512755394, 'logits/chosen': -0.06706257909536362, 'epoch': 2.76}

 46%|████▌     | 7416/16104 [34:28:46<42:16:53, 17.52s/it]

 46%|████▌     | 7417/16104 [34:29:00<39:54:16, 16.54s/it]

 46%|████▌     | 7418/16104 [34:29:17<40:21:10, 16.72s/it]

 46%|████▌     | 7419/16104 [34:29:38<43:26:32, 18.01s/it]

 46%|████▌     | 7420/16104 [34:29:58<44:28:37, 18.44s/it]

 46%|████▌     | 7421/16104 [34:30:18<45:33:15, 18.89s/it]

 46%|████▌     | 7422/16104 [34:30:33<42:53:16, 17.78s/it]

 46%|████▌     | 7423/16104 [34:30:50<41:55:32, 17.39s/it]

 46%|████▌     | 7424/16104 [34:31:11<44:33:23, 18.48s/it]

 46%|████▌     | 7425/16104 [34:31:29<44:39:53, 18.53s/it]

 46%|████▌     | 7426/16104 [34:31:45<43:04:19, 17.87s/it]

 46%|████▌     | 7427/16104 [34:32:01<41:05:58, 17.05s/it]

 46%|████▌     | 7428/16104 [34:32:19<41:54:36, 17.39s/it]


 46%|████▌     | 7430/16104 [34:32:55<42:35:29, 17.68s/it]
{'loss': 0.3367, 'learning_rate': 1.1728998604122593e-06, 'rewards/chosen': -0.4684501886367798, 'rewards/rejected': -1.559761643409729, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0913114547729492, 'policy_logps/rejected': -450.4859619140625, 'policy_logps/chosen': -348.543701171875, 'referece_logps/rejected': -434.8883361816406, 'referece_logps/chosen': -343.8592529296875, 'logits/rejected': -0.15280109643936157, 'logits/chosen': -0.14324316382408142, 'epoch': 2.77}

 46%|████▌     | 7431/16104 [34:33:12<42:17:24, 17.55s/it]

 46%|████▌     | 7432/16104 [34:33:27<39:52:03, 16.55s/it]

 46%|████▌     | 7433/16104 [34:33:39<36:36:11, 15.20s/it]

 46%|████▌     | 7434/16104 [34:33:59<40:33:09, 16.84s/it]

 46%|████▌     | 7435/16104 [34:34:10<36:08:21, 15.01s/it]

 46%|████▌     | 7436/16104 [34:34:22<34:15:09, 14.23s/it]

 46%|████▌     | 7437/16104 [34:34:39<35:52:08, 14.90s/it]

 46%|████▌     | 7438/16104 [34:35:01<40:59:18, 17.03s/it]

 46%|████▌     | 7439/16104 [34:35:14<38:03:07, 15.81s/it]

 46%|████▌     | 7440/16104 [34:35:34<41:06:05, 17.08s/it]

 46%|████▌     | 7441/16104 [34:35:54<43:20:11, 18.01s/it]

 46%|████▌     | 7442/16104 [34:36:09<41:12:14, 17.12s/it]

 46%|████▌     | 7443/16104 [34:36:29<42:54:22, 17.83s/it]

 46%|████▌     | 7444/16104 [34:36:50<45:24:52, 18.88s/it]

 46%|████▌     | 7445/16104 [34:37:08<45:13:03, 18.80s/it]

 46%|████▌     | 7446/16104 [34:37:28<45:47:24, 19.04s/it]

 46%|████▌     | 7447/16104 [34:37:48<46:21:25, 19.28s/it]

 46%|████▌     | 7448/16104 [34:38:02<42:50:37, 17.82s/it]


 46%|████▋     | 7450/16104 [34:38:39<43:23:21, 18.05s/it]
{'loss': 0.4752, 'learning_rate': 1.1689365280904607e-06, 'rewards/chosen': -0.05645333230495453, 'rewards/rejected': -1.0745171308517456, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0180637836456299, 'policy_logps/rejected': -576.2394409179688, 'policy_logps/chosen': -630.7599487304688, 'referece_logps/rejected': -565.4942626953125, 'referece_logps/chosen': -630.1953735351562, 'logits/rejected': -0.18432168662548065, 'logits/chosen': -0.24628859758377075, 'epoch': 2.78}

 46%|████▋     | 7451/16104 [34:38:59<44:44:58, 18.62s/it]

 46%|████▋     | 7452/16104 [34:39:20<46:35:30, 19.39s/it]

 46%|████▋     | 7453/16104 [34:39:38<45:17:24, 18.85s/it]


 46%|████▋     | 7455/16104 [34:39:59<35:14:50, 14.67s/it]
{'loss': 0.4783, 'learning_rate': 1.1679452653930466e-06, 'rewards/chosen': -0.23187334835529327, 'rewards/rejected': -2.046297073364258, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8144240379333496, 'policy_logps/rejected': -405.7893371582031, 'policy_logps/chosen': -530.1198120117188, 'referece_logps/rejected': -385.32635498046875, 'referece_logps/chosen': -527.8011474609375, 'logits/rejected': 0.3577303886413574, 'logits/chosen': 0.18763236701488495, 'epoch': 2.78}

 46%|████▋     | 7456/16104 [34:40:10<32:29:33, 13.53s/it]

 46%|████▋     | 7457/16104 [34:40:27<35:01:07, 14.58s/it]

 46%|████▋     | 7458/16104 [34:40:40<34:02:35, 14.17s/it]

 46%|████▋     | 7459/16104 [34:40:52<31:50:32, 13.26s/it]

 46%|████▋     | 7460/16104 [34:41:09<34:55:03, 14.54s/it]

 46%|████▋     | 7461/16104 [34:41:25<36:02:47, 15.01s/it]

 46%|████▋     | 7462/16104 [34:41:37<33:54:17, 14.12s/it]

 46%|████▋     | 7463/16104 [34:41:48<31:27:07, 13.10s/it]

 46%|████▋     | 7464/16104 [34:42:01<31:37:00, 13.17s/it]


 46%|████▋     | 7466/16104 [34:42:28<32:25:05, 13.51s/it]

 46%|████▋     | 7467/16104 [34:42:48<36:45:36, 15.32s/it]

 46%|████▋     | 7468/16104 [34:43:05<38:19:03, 15.97s/it]

 46%|████▋     | 7469/16104 [34:43:25<41:06:47, 17.14s/it]

 46%|████▋     | 7470/16104 [34:43:44<42:14:32, 17.61s/it]

 46%|████▋     | 7471/16104 [34:43:59<40:43:43, 16.98s/it]

 46%|████▋     | 7472/16104 [34:44:12<37:46:04, 15.75s/it]

 46%|████▋     | 7473/16104 [34:44:31<39:34:22, 16.51s/it]

 46%|████▋     | 7474/16104 [34:44:42<35:38:32, 14.87s/it]

 46%|████▋     | 7475/16104 [34:45:01<39:00:33, 16.27s/it]

 46%|████▋     | 7476/16104 [34:45:15<37:22:17, 15.59s/it]

 46%|████▋     | 7477/16104 [34:45:36<40:51:37, 17.05s/it]

 46%|████▋     | 7478/16104 [34:45:52<40:01:53, 16.71s/it]

 46%|████▋     | 7479/16104 [34:46:14<43:56:06, 18.34s/it]

 46%|████▋     | 7480/16104 [34:46:25<38:44:32, 16.17s/it]

 46%|████▋     | 7481/16104 [34:46:38<36:34:07, 15.27s/it]

 46%|████▋     | 7482/16104 [34:46:59<40:27:30, 16.89s/it]

 46%|████▋     | 7483/16104 [34:47:21<44:13:02, 18.46s/it]

 46%|████▋     | 7484/16104 [34:47:40<44:32:53, 18.60s/it]

 46%|████▋     | 7485/16104 [34:47:57<43:21:09, 18.11s/it]

 46%|████▋     | 7486/16104 [34:48:17<44:40:19, 18.66s/it]

 46%|████▋     | 7487/16104 [34:48:38<46:37:34, 19.48s/it]

 46%|████▋     | 7488/16104 [34:48:57<46:32:55, 19.45s/it]

 47%|████▋     | 7489/16104 [34:49:15<44:58:00, 18.79s/it]

 47%|████▋     | 7490/16104 [34:49:33<44:24:36, 18.56s/it]

 47%|████▋     | 7491/16104 [34:49:52<45:03:40, 18.83s/it]

 47%|████▋     | 7492/16104 [34:50:09<43:59:28, 18.39s/it]

 47%|████▋     | 7493/16104 [34:50:23<40:16:22, 16.84s/it]

 47%|████▋     | 7494/16104 [34:50:40<40:22:36, 16.88s/it]

 47%|████▋     | 7495/16104 [34:51:00<42:35:37, 17.81s/it]

 47%|████▋     | 7496/16104 [34:51:15<41:11:23, 17.23s/it]

 47%|████▋     | 7497/16104 [34:51:28<37:43:22, 15.78s/it]

 47%|████▋     | 7498/16104 [34:51:39<34:33:47, 14.46s/it]

 47%|████▋     | 7499/16104 [34:51:52<33:32:54, 14.04s/it]

 47%|████▋     | 7500/16104 [34:52:13<38:10:51, 15.98s/it]

 47%|████▋     | 7501/16104 [34:52:39<45:43:31, 19.13s/it]

 47%|████▋     | 7502/16104 [34:52:56<43:37:11, 18.26s/it]
{'loss': 0.4643, 'learning_rate': 1.1586192314210239e-06, 'rewards/chosen': 0.032122403383255005, 'rewards/rejected': -1.0314171314239502, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0635395050048828, 'policy_logps/rejected': -547.5121459960938, 'policy_logps/chosen': -577.7152099609375, 'referece_logps/rejected': -537.1979370117188, 'referece_logps/chosen': -578.0364379882812, 'logits/rejected': -0.3024772107601166, 'logits/chosen': -0.16870905458927155, 'epoch': 2.8}


 47%|████▋     | 7504/16104 [34:53:29<41:42:59, 17.46s/it]
{'loss': 0.4989, 'learning_rate': 1.1582220586045373e-06, 'rewards/chosen': 0.1495460569858551, 'rewards/rejected': -0.4277416467666626, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5772877335548401, 'policy_logps/rejected': -413.68426513671875, 'policy_logps/chosen': -446.8424377441406, 'referece_logps/rejected': -409.4068603515625, 'referece_logps/chosen': -448.3379211425781, 'logits/rejected': -0.8967136740684509, 'logits/chosen': -0.8140993118286133, 'epoch': 2.8}


 47%|████▋     | 7506/16104 [34:54:06<43:21:29, 18.15s/it]

 47%|████▋     | 7507/16104 [34:54:17<37:59:41, 15.91s/it]

 47%|████▋     | 7508/16104 [34:54:30<36:01:59, 15.09s/it]

 47%|████▋     | 7509/16104 [34:54:41<33:00:41, 13.83s/it]

 47%|████▋     | 7510/16104 [34:55:00<36:53:03, 15.45s/it]

 47%|████▋     | 7511/16104 [34:55:12<34:12:54, 14.33s/it]

 47%|████▋     | 7512/16104 [34:55:27<35:01:25, 14.67s/it]

 47%|████▋     | 7513/16104 [34:55:41<33:50:08, 14.18s/it]
{'loss': 0.4622, 'learning_rate': 1.156434465040231e-06, 'rewards/chosen': -0.7706127762794495, 'rewards/rejected': -1.3054364919662476, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5348237752914429, 'policy_logps/rejected': -268.1055908203125, 'policy_logps/chosen': -264.19415283203125, 'referece_logps/rejected': -255.0512237548828, 'referece_logps/chosen': -256.4880065917969, 'logits/rejected': -0.8499952554702759, 'logits/chosen': -0.8454492092132568, 'epoch': 2.8}

 47%|████▋     | 7514/16104 [34:55:59<36:50:02, 15.44s/it]


 47%|████▋     | 7516/16104 [34:56:37<41:09:26, 17.25s/it]

 47%|████▋     | 7517/16104 [34:56:57<43:19:50, 18.17s/it]

 47%|████▋     | 7518/16104 [34:57:17<44:26:05, 18.63s/it]
{'loss': 0.3891, 'learning_rate': 1.1554411356476842e-06, 'rewards/chosen': -0.16391021013259888, 'rewards/rejected': -1.2204675674438477, 'rewards/accuracies': 0.5, 'rewards/margins': 1.056557297706604, 'policy_logps/rejected': -558.86474609375, 'policy_logps/chosen': -652.983642578125, 'referece_logps/rejected': -546.6600341796875, 'referece_logps/chosen': -651.3445434570312, 'logits/rejected': -0.1374465525150299, 'logits/chosen': -0.14584152400493622, 'epoch': 2.8}


 47%|████▋     | 7520/16104 [34:57:57<45:47:28, 19.20s/it]

 47%|████▋     | 7521/16104 [34:58:12<43:14:31, 18.14s/it]
{'loss': 0.4063, 'learning_rate': 1.1548450624934083e-06, 'rewards/chosen': -0.5010610818862915, 'rewards/rejected': -1.8638664484024048, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3628053665161133, 'policy_logps/rejected': -274.1099548339844, 'policy_logps/chosen': -445.04156494140625, 'referece_logps/rejected': -255.47129821777344, 'referece_logps/chosen': -440.03094482421875, 'logits/rejected': 0.49082398414611816, 'logits/chosen': 0.6390798091888428, 'epoch': 2.8}


 47%|████▋     | 7523/16104 [34:58:46<41:38:25, 17.47s/it]

 47%|████▋     | 7524/16104 [34:59:03<41:36:25, 17.46s/it]

 47%|████▋     | 7525/16104 [34:59:20<40:52:21, 17.15s/it]
{'loss': 0.3758, 'learning_rate': 1.1540502106325933e-06, 'rewards/chosen': -0.695499062538147, 'rewards/rejected': -1.1593554019927979, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4638563096523285, 'policy_logps/rejected': -482.53192138671875, 'policy_logps/chosen': -419.3056945800781, 'referece_logps/rejected': -470.9383850097656, 'referece_logps/chosen': -412.3507080078125, 'logits/rejected': 0.6531373262405396, 'logits/chosen': 0.6662452220916748, 'epoch': 2.8}


 47%|████▋     | 7527/16104 [34:59:54<41:31:19, 17.43s/it]
{'loss': 0.3704, 'learning_rate': 1.1536527472803964e-06, 'rewards/chosen': -1.0678766965866089, 'rewards/rejected': -2.9945156574249268, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9266389608383179, 'policy_logps/rejected': -366.0816955566406, 'policy_logps/chosen': -351.74853515625, 'referece_logps/rejected': -336.136474609375, 'referece_logps/chosen': -341.06976318359375, 'logits/rejected': -0.1972343921661377, 'logits/chosen': -0.1148264929652214, 'epoch': 2.8}

 47%|████▋     | 7528/16104 [35:00:11<40:51:53, 17.15s/it]


 47%|████▋     | 7530/16104 [35:00:43<38:18:16, 16.08s/it]

 47%|████▋     | 7531/16104 [35:00:57<36:56:58, 15.52s/it]

 47%|████▋     | 7532/16104 [35:01:19<41:27:28, 17.41s/it]

 47%|████▋     | 7533/16104 [35:01:34<40:16:30, 16.92s/it]

 47%|████▋     | 7534/16104 [35:01:53<41:13:05, 17.31s/it]

 47%|████▋     | 7535/16104 [35:02:06<38:16:00, 16.08s/it]

 47%|████▋     | 7536/16104 [35:02:18<35:28:37, 14.91s/it]

 47%|████▋     | 7537/16104 [35:02:38<39:02:14, 16.40s/it]

 47%|████▋     | 7538/16104 [35:02:50<35:48:34, 15.05s/it]

 47%|████▋     | 7539/16104 [35:03:06<36:44:05, 15.44s/it]
{'loss': 0.4156, 'learning_rate': 1.1512674473140994e-06, 'rewards/chosen': -0.44829627871513367, 'rewards/rejected': -1.726189136505127, 'rewards/accuracies': 0.75, 'rewards/margins': 1.277892827987671, 'policy_logps/rejected': -730.5078125, 'policy_logps/chosen': -478.01141357421875, 'referece_logps/rejected': -713.2459106445312, 'referece_logps/chosen': -473.5284729003906, 'logits/rejected': -0.5334647297859192, 'logits/chosen': -0.39293575286865234, 'epoch': 2.81}


 47%|████▋     | 7541/16104 [35:03:42<40:40:42, 17.10s/it]

 47%|████▋     | 7542/16104 [35:04:02<42:35:29, 17.91s/it]

 47%|████▋     | 7543/16104 [35:04:14<38:30:59, 16.20s/it]

 47%|████▋     | 7544/16104 [35:04:31<38:37:08, 16.24s/it]

 47%|████▋     | 7545/16104 [35:04:50<40:27:41, 17.02s/it]

 47%|████▋     | 7546/16104 [35:05:08<41:45:20, 17.56s/it]
{'loss': 0.4317, 'learning_rate': 1.1498756145265142e-06, 'rewards/chosen': -0.31053274869918823, 'rewards/rejected': -1.3853908777236938, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0748581886291504, 'policy_logps/rejected': -382.6936950683594, 'policy_logps/chosen': -354.302490234375, 'referece_logps/rejected': -368.8398132324219, 'referece_logps/chosen': -351.1971435546875, 'logits/rejected': -0.17868344485759735, 'logits/chosen': -0.19792962074279785, 'epoch': 2.81}


 47%|████▋     | 7548/16104 [35:05:48<44:26:04, 18.70s/it]

 47%|████▋     | 7549/16104 [35:06:06<43:58:01, 18.50s/it]
{'loss': 0.3518, 'learning_rate': 1.1492790236584959e-06, 'rewards/chosen': 0.5485913753509521, 'rewards/rejected': -0.6257010102272034, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1742923259735107, 'policy_logps/rejected': -331.7037353515625, 'policy_logps/chosen': -533.6480712890625, 'referece_logps/rejected': -325.4466857910156, 'referece_logps/chosen': -539.1339721679688, 'logits/rejected': -0.24819086492061615, 'logits/chosen': -0.33354100584983826, 'epoch': 2.81}


 47%|████▋     | 7551/16104 [35:06:39<40:57:08, 17.24s/it]
{'loss': 0.3528, 'learning_rate': 1.1488812662067291e-06, 'rewards/chosen': 0.06617166101932526, 'rewards/rejected': -2.0146377086639404, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0808093547821045, 'policy_logps/rejected': -186.26048278808594, 'policy_logps/chosen': -342.92626953125, 'referece_logps/rejected': -166.11410522460938, 'referece_logps/chosen': -343.58795166015625, 'logits/rejected': 0.4920297861099243, 'logits/chosen': 0.4750317335128784, 'epoch': 2.81}


 47%|████▋     | 7553/16104 [35:07:12<39:41:51, 16.71s/it]

 47%|████▋     | 7554/16104 [35:07:32<42:14:29, 17.79s/it]
{'loss': 0.4267, 'learning_rate': 1.1482845848803453e-06, 'rewards/chosen': 0.13265305757522583, 'rewards/rejected': -0.931236743927002, 'rewards/accuracies': 0.875, 'rewards/margins': 1.063889741897583, 'policy_logps/rejected': -613.1312255859375, 'policy_logps/chosen': -575.813720703125, 'referece_logps/rejected': -603.81884765625, 'referece_logps/chosen': -577.1402587890625, 'logits/rejected': 0.07833024859428406, 'logits/chosen': 0.0710899606347084, 'epoch': 2.81}

 47%|████▋     | 7555/16104 [35:07:54<44:44:41, 18.84s/it]


 47%|████▋     | 7557/16104 [35:08:35<46:37:10, 19.64s/it]

 47%|████▋     | 7558/16104 [35:08:55<46:42:23, 19.68s/it]

 47%|████▋     | 7559/16104 [35:09:11<44:07:47, 18.59s/it]

 47%|████▋     | 7560/16104 [35:09:31<45:19:53, 19.10s/it]

 47%|████▋     | 7561/16104 [35:09:49<44:14:53, 18.65s/it]

 47%|████▋     | 7562/16104 [35:10:01<39:46:33, 16.76s/it]

 47%|████▋     | 7563/16104 [35:10:21<41:52:30, 17.65s/it]

 47%|████▋     | 7564/16104 [35:10:39<42:12:27, 17.79s/it]

 47%|████▋     | 7565/16104 [35:10:59<43:46:39, 18.46s/it]

 47%|████▋     | 7566/16104 [35:11:19<44:50:50, 18.91s/it]

 47%|████▋     | 7567/16104 [35:11:40<46:33:48, 19.64s/it]

 47%|████▋     | 7568/16104 [35:11:55<43:15:23, 18.24s/it]
{'loss': 0.4454, 'learning_rate': 1.1454993617282512e-06, 'rewards/chosen': -0.47275903820991516, 'rewards/rejected': -1.6948168277740479, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2220579385757446, 'policy_logps/rejected': -466.746337890625, 'policy_logps/chosen': -521.7809448242188, 'referece_logps/rejected': -449.79815673828125, 'referece_logps/chosen': -517.0533447265625, 'logits/rejected': 0.11622835695743561, 'logits/chosen': 0.18359103798866272, 'epoch': 2.82}


 47%|████▋     | 7570/16104 [35:12:20<36:14:20, 15.29s/it]
{'loss': 0.4489, 'learning_rate': 1.145101378020079e-06, 'rewards/chosen': -0.460257887840271, 'rewards/rejected': -1.993865728378296, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5336077213287354, 'policy_logps/rejected': -298.3158264160156, 'policy_logps/chosen': -374.2958679199219, 'referece_logps/rejected': -278.377197265625, 'referece_logps/chosen': -369.69329833984375, 'logits/rejected': -0.25014811754226685, 'logits/chosen': -0.39705538749694824, 'epoch': 2.82}


 47%|████▋     | 7572/16104 [35:12:57<39:56:36, 16.85s/it]
{'loss': 0.5441, 'learning_rate': 1.1447033708334685e-06, 'rewards/chosen': -0.9751916527748108, 'rewards/rejected': -1.1929739713668823, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21778225898742676, 'policy_logps/rejected': -360.26165771484375, 'policy_logps/chosen': -395.96502685546875, 'referece_logps/rejected': -348.3319091796875, 'referece_logps/chosen': -386.2131042480469, 'logits/rejected': 0.06674326211214066, 'logits/chosen': 0.023079033941030502, 'epoch': 2.82}


 47%|████▋     | 7574/16104 [35:13:23<35:16:57, 14.89s/it]

 47%|████▋     | 7575/16104 [35:13:37<34:45:33, 14.67s/it]
{'loss': 0.3413, 'learning_rate': 1.1441063161723577e-06, 'rewards/chosen': -0.15391844511032104, 'rewards/rejected': -1.3813410997390747, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2274224758148193, 'policy_logps/rejected': -387.31591796875, 'policy_logps/chosen': -466.41461181640625, 'referece_logps/rejected': -373.50250244140625, 'referece_logps/chosen': -464.87548828125, 'logits/rejected': 0.05731576681137085, 'logits/chosen': 0.21864894032478333, 'epoch': 2.82}


 47%|████▋     | 7577/16104 [35:14:14<38:50:15, 16.40s/it]

 47%|████▋     | 7578/16104 [35:14:31<39:15:09, 16.57s/it]
{'loss': 0.4871, 'learning_rate': 1.1435092090470294e-06, 'rewards/chosen': -0.25930386781692505, 'rewards/rejected': -0.8223026990890503, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5629988312721252, 'policy_logps/rejected': -388.54095458984375, 'policy_logps/chosen': -392.8465881347656, 'referece_logps/rejected': -380.31793212890625, 'referece_logps/chosen': -390.2535705566406, 'logits/rejected': -0.037952691316604614, 'logits/chosen': -0.03208643198013306, 'epoch': 2.82}


 47%|████▋     | 7580/16104 [35:14:59<35:57:59, 15.19s/it]
{'loss': 0.4875, 'learning_rate': 1.1431111085907068e-06, 'rewards/chosen': 0.0542881116271019, 'rewards/rejected': -0.4864378869533539, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5407260060310364, 'policy_logps/rejected': -318.1589660644531, 'policy_logps/chosen': -364.78106689453125, 'referece_logps/rejected': -313.29461669921875, 'referece_logps/chosen': -365.3239440917969, 'logits/rejected': -0.6246256232261658, 'logits/chosen': -0.533555805683136, 'epoch': 2.82}

 47%|████▋     | 7581/16104 [35:15:14<35:59:22, 15.20s/it]

 47%|████▋     | 7582/16104 [35:15:34<39:14:48, 16.58s/it]


 47%|████▋     | 7584/16104 [35:16:05<38:30:25, 16.27s/it]

 47%|████▋     | 7585/16104 [35:16:16<35:14:38, 14.89s/it]

 47%|████▋     | 7586/16104 [35:16:38<39:55:33, 16.87s/it]

 47%|████▋     | 7587/16104 [35:16:57<41:53:51, 17.71s/it]

 47%|████▋     | 7588/16104 [35:17:13<40:31:14, 17.13s/it]

 47%|████▋     | 7589/16104 [35:17:33<42:21:19, 17.91s/it]

 47%|████▋     | 7590/16104 [35:17:50<41:27:12, 17.53s/it]

 47%|████▋     | 7591/16104 [35:18:09<42:41:52, 18.06s/it]

 47%|████▋     | 7592/16104 [35:18:27<42:24:14, 17.93s/it]
{'loss': 0.4565, 'learning_rate': 1.1407220218232043e-06, 'rewards/chosen': 0.2870582640171051, 'rewards/rejected': -0.8499991297721863, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1370573043823242, 'policy_logps/rejected': -378.9590759277344, 'policy_logps/chosen': -421.703125, 'referece_logps/rejected': -370.4590759277344, 'referece_logps/chosen': -424.57373046875, 'logits/rejected': -0.15417641401290894, 'logits/chosen': -0.21518880128860474, 'epoch': 2.83}


 47%|████▋     | 7594/16104 [35:19:03<43:05:41, 18.23s/it]

 47%|████▋     | 7595/16104 [35:19:15<39:06:29, 16.55s/it]

 47%|████▋     | 7596/16104 [35:19:37<42:31:44, 18.00s/it]
{'loss': 0.5494, 'learning_rate': 1.1399254767214611e-06, 'rewards/chosen': -0.40289705991744995, 'rewards/rejected': -1.0235148668289185, 'rewards/accuracies': 0.625, 'rewards/margins': 0.620617687702179, 'policy_logps/rejected': -451.27545166015625, 'policy_logps/chosen': -538.1534423828125, 'referece_logps/rejected': -441.0403137207031, 'referece_logps/chosen': -534.1244506835938, 'logits/rejected': -0.3770313560962677, 'logits/chosen': -0.46952012181282043, 'epoch': 2.83}


 47%|████▋     | 7598/16104 [35:20:03<36:47:20, 15.57s/it]

 47%|████▋     | 7599/16104 [35:20:17<35:38:27, 15.09s/it]

 47%|████▋     | 7600/16104 [35:20:38<40:06:00, 16.98s/it]

 47%|████▋     | 7601/16104 [35:20:49<35:44:25, 15.13s/it]

 47%|████▋     | 7602/16104 [35:21:02<34:03:27, 14.42s/it]
{'loss': 0.5132, 'learning_rate': 1.1387304894229229e-06, 'rewards/chosen': -0.7823832631111145, 'rewards/rejected': -1.1175053119659424, 'rewards/accuracies': 0.625, 'rewards/margins': 0.33512192964553833, 'policy_logps/rejected': -496.18756103515625, 'policy_logps/chosen': -551.92431640625, 'referece_logps/rejected': -485.012451171875, 'referece_logps/chosen': -544.1004638671875, 'logits/rejected': -0.0581878200173378, 'logits/chosen': -0.0811719000339508, 'epoch': 2.83}


 47%|████▋     | 7604/16104 [35:21:32<35:46:31, 15.15s/it]
{'loss': 0.4916, 'learning_rate': 1.138332115342303e-06, 'rewards/chosen': 0.05156402662396431, 'rewards/rejected': -0.9387904405593872, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9903543591499329, 'policy_logps/rejected': -633.3201293945312, 'policy_logps/chosen': -492.5962219238281, 'referece_logps/rejected': -623.9322509765625, 'referece_logps/chosen': -493.11187744140625, 'logits/rejected': -0.7998756170272827, 'logits/chosen': -0.7866060733795166, 'epoch': 2.83}


 47%|████▋     | 7606/16104 [35:22:02<35:17:25, 14.95s/it]

 47%|████▋     | 7607/16104 [35:22:16<34:37:05, 14.67s/it]
{'loss': 0.5553, 'learning_rate': 1.1377345122731622e-06, 'rewards/chosen': -0.6711585521697998, 'rewards/rejected': -2.1442158222198486, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4730572700500488, 'policy_logps/rejected': -469.408935546875, 'policy_logps/chosen': -498.3154296875, 'referece_logps/rejected': -447.966796875, 'referece_logps/chosen': -491.6038513183594, 'logits/rejected': -0.6493279933929443, 'logits/chosen': -0.5965307354927063, 'epoch': 2.83}

 47%|████▋     | 7608/16104 [35:22:29<33:02:29, 14.00s/it]

 47%|████▋     | 7609/16104 [35:22:48<37:13:28, 15.78s/it]


 47%|████▋     | 7611/16104 [35:23:18<36:21:58, 15.41s/it]

 47%|████▋     | 7612/16104 [35:23:30<33:40:33, 14.28s/it]
{'loss': 0.394, 'learning_rate': 1.1367383958332425e-06, 'rewards/chosen': -0.11958657950162888, 'rewards/rejected': -1.980596899986267, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8610104322433472, 'policy_logps/rejected': -474.8586730957031, 'policy_logps/chosen': -442.8043212890625, 'referece_logps/rejected': -455.0527038574219, 'referece_logps/chosen': -441.60845947265625, 'logits/rejected': 0.8112548589706421, 'logits/chosen': 0.7358729839324951, 'epoch': 2.84}

 47%|████▋     | 7613/16104 [35:23:50<38:04:18, 16.14s/it]


 47%|████▋     | 7615/16104 [35:24:28<41:30:15, 17.60s/it]
{'loss': 0.4011, 'learning_rate': 1.1361406595290733e-06, 'rewards/chosen': -0.23817750811576843, 'rewards/rejected': -1.2870105504989624, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0488331317901611, 'policy_logps/rejected': -561.8418579101562, 'policy_logps/chosen': -516.3419799804688, 'referece_logps/rejected': -548.9718017578125, 'referece_logps/chosen': -513.960205078125, 'logits/rejected': -0.019633200019598007, 'logits/chosen': 0.0554305836558342, 'epoch': 2.84}


 47%|████▋     | 7617/16104 [35:24:54<35:55:07, 15.24s/it]
{'loss': 0.4325, 'learning_rate': 1.1357421411105313e-06, 'rewards/chosen': -0.48723679780960083, 'rewards/rejected': -1.6844937801361084, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1972570419311523, 'policy_logps/rejected': -319.80718994140625, 'policy_logps/chosen': -592.3040161132812, 'referece_logps/rejected': -302.9622497558594, 'referece_logps/chosen': -587.4317016601562, 'logits/rejected': 0.31209757924079895, 'logits/chosen': 0.30688440799713135, 'epoch': 2.84}


 47%|████▋     | 7619/16104 [35:25:19<32:51:43, 13.94s/it]

 47%|████▋     | 7620/16104 [35:25:30<30:27:57, 12.93s/it]

 47%|████▋     | 7621/16104 [35:25:45<32:14:24, 13.68s/it]

 47%|████▋     | 7622/16104 [35:25:56<30:02:39, 12.75s/it]

 47%|████▋     | 7623/16104 [35:26:12<32:34:08, 13.82s/it]
{'loss': 0.4768, 'learning_rate': 1.134546454328572e-06, 'rewards/chosen': -0.5227894186973572, 'rewards/rejected': -1.1959576606750488, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6731681823730469, 'policy_logps/rejected': -354.7595520019531, 'policy_logps/chosen': -503.22674560546875, 'referece_logps/rejected': -342.7999572753906, 'referece_logps/chosen': -497.9988098144531, 'logits/rejected': 0.9615648984909058, 'logits/chosen': 0.9867798089981079, 'epoch': 2.84}

 47%|████▋     | 7624/16104 [35:26:25<31:57:34, 13.57s/it]

 47%|████▋     | 7625/16104 [35:26:43<35:04:15, 14.89s/it]


 47%|████▋     | 7627/16104 [35:27:18<38:23:01, 16.30s/it]

 47%|████▋     | 7628/16104 [35:27:34<38:06:11, 16.18s/it]

 47%|████▋     | 7629/16104 [35:27:56<42:11:18, 17.92s/it]
{'loss': 0.3928, 'learning_rate': 1.1333505716114453e-06, 'rewards/chosen': -0.4726722240447998, 'rewards/rejected': -1.8288991451263428, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3562268018722534, 'policy_logps/rejected': -641.382568359375, 'policy_logps/chosen': -680.28173828125, 'referece_logps/rejected': -623.0935668945312, 'referece_logps/chosen': -675.5548706054688, 'logits/rejected': 0.3103753924369812, 'logits/chosen': 0.45404794812202454, 'epoch': 2.84}

 47%|████▋     | 7630/16104 [35:28:15<43:22:12, 18.42s/it]

 47%|████▋     | 7631/16104 [35:28:35<44:30:43, 18.91s/it]


 47%|████▋     | 7633/16104 [35:29:16<46:28:36, 19.75s/it]

 47%|████▋     | 7634/16104 [35:29:38<48:02:13, 20.42s/it]

 47%|████▋     | 7635/16104 [35:29:58<47:24:59, 20.16s/it]

 47%|████▋     | 7636/16104 [35:30:10<42:06:22, 17.90s/it]

 47%|████▋     | 7637/16104 [35:30:22<37:32:00, 15.96s/it]
{'loss': 0.5458, 'learning_rate': 1.1317557595439826e-06, 'rewards/chosen': -1.0832910537719727, 'rewards/rejected': -0.9194751977920532, 'rewards/accuracies': 0.625, 'rewards/margins': -0.16381587088108063, 'policy_logps/rejected': -542.8113403320312, 'policy_logps/chosen': -488.85986328125, 'referece_logps/rejected': -533.6165771484375, 'referece_logps/chosen': -478.0269775390625, 'logits/rejected': -0.5743191838264465, 'logits/chosen': -0.8026607036590576, 'epoch': 2.85}


 47%|████▋     | 7639/16104 [35:30:56<38:51:42, 16.53s/it]

 47%|████▋     | 7640/16104 [35:31:16<41:34:01, 17.68s/it]
{'loss': 0.4599, 'learning_rate': 1.131157616855944e-06, 'rewards/chosen': 0.05501803755760193, 'rewards/rejected': -1.8201425075531006, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8751606941223145, 'policy_logps/rejected': -385.4917907714844, 'policy_logps/chosen': -598.0410766601562, 'referece_logps/rejected': -367.29034423828125, 'referece_logps/chosen': -598.59130859375, 'logits/rejected': -0.2027449905872345, 'logits/chosen': -0.38601285219192505, 'epoch': 2.85}


 47%|████▋     | 7642/16104 [35:31:49<39:13:50, 16.69s/it]
{'loss': 0.4218, 'learning_rate': 1.130758828522678e-06, 'rewards/chosen': -0.41321203112602234, 'rewards/rejected': -1.5466550588607788, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1334431171417236, 'policy_logps/rejected': -372.964599609375, 'policy_logps/chosen': -536.1363525390625, 'referece_logps/rejected': -357.498046875, 'referece_logps/chosen': -532.0042114257812, 'logits/rejected': -0.05254736170172691, 'logits/chosen': -0.059871356934309006, 'epoch': 2.85}


 47%|████▋     | 7644/16104 [35:32:24<40:07:35, 17.08s/it]

 47%|████▋     | 7645/16104 [35:32:38<38:10:08, 16.24s/it]
{'loss': 0.6398, 'learning_rate': 1.1301606063722348e-06, 'rewards/chosen': -0.8341196179389954, 'rewards/rejected': -1.9219915866851807, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0878719091415405, 'policy_logps/rejected': -537.3538818359375, 'policy_logps/chosen': -494.51727294921875, 'referece_logps/rejected': -518.1339111328125, 'referece_logps/chosen': -486.17608642578125, 'logits/rejected': -0.2327651083469391, 'logits/chosen': -0.018989412114024162, 'epoch': 2.85}

 47%|████▋     | 7646/16104 [35:32:51<35:52:27, 15.27s/it]


 47%|████▋     | 7648/16104 [35:33:26<38:05:28, 16.22s/it]
{'loss': 0.5279, 'learning_rate': 1.1295623368347337e-06, 'rewards/chosen': -0.4218989610671997, 'rewards/rejected': -1.3812229633331299, 'rewards/accuracies': 1.0, 'rewards/margins': 0.959324061870575, 'policy_logps/rejected': -393.97705078125, 'policy_logps/chosen': -528.456787109375, 'referece_logps/rejected': -380.1648254394531, 'referece_logps/chosen': -524.2377319335938, 'logits/rejected': -0.18862906098365784, 'logits/chosen': 0.11346052587032318, 'epoch': 2.85}


 48%|████▊     | 7650/16104 [35:34:03<40:17:20, 17.16s/it]
{'loss': 0.315, 'learning_rate': 1.1291634642578162e-06, 'rewards/chosen': -0.7121140360832214, 'rewards/rejected': -1.6611895561218262, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9490756988525391, 'policy_logps/rejected': -480.4417724609375, 'policy_logps/chosen': -496.64306640625, 'referece_logps/rejected': -463.8299255371094, 'referece_logps/chosen': -489.52197265625, 'logits/rejected': -0.512945294380188, 'logits/chosen': -0.5787571668624878, 'epoch': 2.85}


 48%|████▊     | 7652/16104 [35:34:39<40:37:15, 17.30s/it]

 48%|████▊     | 7653/16104 [35:34:57<41:06:55, 17.51s/it]

 48%|████▊     | 7654/16104 [35:35:13<40:11:11, 17.12s/it]

 48%|████▊     | 7655/16104 [35:35:32<41:39:19, 17.75s/it]
{'loss': 0.3489, 'learning_rate': 1.1281661915210929e-06, 'rewards/chosen': -1.0242128372192383, 'rewards/rejected': -2.46805477142334, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4438422918319702, 'policy_logps/rejected': -344.0550231933594, 'policy_logps/chosen': -443.687255859375, 'referece_logps/rejected': -319.37451171875, 'referece_logps/chosen': -433.4450988769531, 'logits/rejected': -0.2020382136106491, 'logits/chosen': -0.199916809797287, 'epoch': 2.85}

 48%|████▊     | 7656/16104 [35:35:48<40:06:22, 17.09s/it]

 48%|████▊     | 7657/16104 [35:36:07<41:56:57, 17.88s/it]


 48%|████▊     | 7659/16104 [35:36:45<43:05:45, 18.37s/it]

 48%|████▊     | 7660/16104 [35:37:05<44:19:55, 18.90s/it]
{'loss': 0.3707, 'learning_rate': 1.1271687891706009e-06, 'rewards/chosen': -0.7987613677978516, 'rewards/rejected': -3.226224660873413, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4274630546569824, 'policy_logps/rejected': -322.43212890625, 'policy_logps/chosen': -327.2096252441406, 'referece_logps/rejected': -290.1698913574219, 'referece_logps/chosen': -319.22198486328125, 'logits/rejected': -0.2970923185348511, 'logits/chosen': 0.10748633742332458, 'epoch': 2.85}


 48%|████▊     | 7662/16104 [35:37:37<40:19:53, 17.20s/it]

 48%|████▊     | 7663/16104 [35:37:55<41:05:26, 17.52s/it]
{'loss': 0.3356, 'learning_rate': 1.126570285965297e-06, 'rewards/chosen': -0.32002657651901245, 'rewards/rejected': -2.6491382122039795, 'rewards/accuracies': 0.75, 'rewards/margins': 2.3291115760803223, 'policy_logps/rejected': -482.76593017578125, 'policy_logps/chosen': -495.821044921875, 'referece_logps/rejected': -456.2745361328125, 'referece_logps/chosen': -492.62078857421875, 'logits/rejected': 0.21539652347564697, 'logits/chosen': 0.25760573148727417, 'epoch': 2.86}


 48%|████▊     | 7665/16104 [35:38:34<43:14:53, 18.45s/it]
{'loss': 0.3291, 'learning_rate': 1.126171258215008e-06, 'rewards/chosen': -0.17219087481498718, 'rewards/rejected': -1.6119294166564941, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4397385120391846, 'policy_logps/rejected': -497.2472839355469, 'policy_logps/chosen': -437.02618408203125, 'referece_logps/rejected': -481.1280212402344, 'referece_logps/chosen': -435.30426025390625, 'logits/rejected': -0.10678437352180481, 'logits/chosen': -0.13323599100112915, 'epoch': 2.86}


 48%|████▊     | 7667/16104 [35:39:05<39:16:09, 16.76s/it]
{'loss': 0.4124, 'learning_rate': 1.1257722100493088e-06, 'rewards/chosen': -0.32889023423194885, 'rewards/rejected': -1.2305575609207153, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9016674757003784, 'policy_logps/rejected': -410.6802978515625, 'policy_logps/chosen': -359.0802917480469, 'referece_logps/rejected': -398.374755859375, 'referece_logps/chosen': -355.7913513183594, 'logits/rejected': 0.1394464075565338, 'logits/chosen': 0.06205563247203827, 'epoch': 2.86}


 48%|████▊     | 7669/16104 [35:39:33<36:47:09, 15.70s/it]

 48%|████▊     | 7670/16104 [35:39:53<39:38:26, 16.92s/it]
{'loss': 0.4959, 'learning_rate': 1.1251735996631115e-06, 'rewards/chosen': -0.724514901638031, 'rewards/rejected': -1.3868939876556396, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6623790264129639, 'policy_logps/rejected': -505.8141174316406, 'policy_logps/chosen': -504.2166748046875, 'referece_logps/rejected': -491.9451599121094, 'referece_logps/chosen': -496.9715270996094, 'logits/rejected': 0.08705897629261017, 'logits/chosen': 0.056644514203071594, 'epoch': 2.86}


 48%|████▊     | 7672/16104 [35:40:19<34:50:34, 14.88s/it]
{'loss': 0.4434, 'learning_rate': 1.1247745007413834e-06, 'rewards/chosen': -0.48190200328826904, 'rewards/rejected': -1.7868551015853882, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3049532175064087, 'policy_logps/rejected': -429.6842956542969, 'policy_logps/chosen': -303.0557861328125, 'referece_logps/rejected': -411.81573486328125, 'referece_logps/chosen': -298.23675537109375, 'logits/rejected': -0.6480618119239807, 'logits/chosen': -0.719944953918457, 'epoch': 2.86}


 48%|████▊     | 7674/16104 [35:40:48<34:51:05, 14.88s/it]

 48%|████▊     | 7675/16104 [35:41:01<33:10:23, 14.17s/it]
{'loss': 0.3999, 'learning_rate': 1.1241758145238387e-06, 'rewards/chosen': -1.1442164182662964, 'rewards/rejected': -2.1010539531707764, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9568377137184143, 'policy_logps/rejected': -407.689453125, 'policy_logps/chosen': -368.48480224609375, 'referece_logps/rejected': -386.678955078125, 'referece_logps/chosen': -357.0426025390625, 'logits/rejected': -0.5251833200454712, 'logits/chosen': -0.6509633660316467, 'epoch': 2.86}


 48%|████▊     | 7677/16104 [35:41:29<32:29:04, 13.88s/it]
{'loss': 0.3981, 'learning_rate': 1.1237766652496878e-06, 'rewards/chosen': -0.13446027040481567, 'rewards/rejected': -1.3111906051635742, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1767303943634033, 'policy_logps/rejected': -446.1961975097656, 'policy_logps/chosen': -576.1724243164062, 'referece_logps/rejected': -433.0843200683594, 'referece_logps/chosen': -574.8278198242188, 'logits/rejected': -0.12324962764978409, 'logits/chosen': -0.3244714140892029, 'epoch': 2.86}

 48%|████▊     | 7678/16104 [35:41:48<36:25:48, 15.56s/it]


 48%|████▊     | 7680/16104 [35:42:25<39:46:32, 17.00s/it]

 48%|████▊     | 7681/16104 [35:42:37<35:43:40, 15.27s/it]
{'loss': 0.4146, 'learning_rate': 1.122978306682132e-06, 'rewards/chosen': -0.12244397401809692, 'rewards/rejected': -1.6297446489334106, 'rewards/accuracies': 0.75, 'rewards/margins': 1.507300615310669, 'policy_logps/rejected': -344.151123046875, 'policy_logps/chosen': -687.2481079101562, 'referece_logps/rejected': -327.85369873046875, 'referece_logps/chosen': -686.023681640625, 'logits/rejected': 0.22300656139850616, 'logits/chosen': -0.010713040828704834, 'epoch': 2.86}

 48%|████▊     | 7682/16104 [35:42:54<37:30:22, 16.03s/it]


 48%|████▊     | 7684/16104 [35:43:31<40:04:20, 17.13s/it]

 48%|████▊     | 7685/16104 [35:43:51<41:43:48, 17.84s/it]
{'loss': 0.3608, 'learning_rate': 1.1221798685195082e-06, 'rewards/chosen': -0.5908206105232239, 'rewards/rejected': -1.309610366821289, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7187896966934204, 'policy_logps/rejected': -252.61976623535156, 'policy_logps/chosen': -376.6028137207031, 'referece_logps/rejected': -239.52366638183594, 'referece_logps/chosen': -370.69464111328125, 'logits/rejected': -0.8438839316368103, 'logits/chosen': -0.8215913772583008, 'epoch': 2.86}


 48%|████▊     | 7687/16104 [35:44:23<39:46:09, 17.01s/it]
{'loss': 0.4557, 'learning_rate': 1.1217806197515354e-06, 'rewards/chosen': -0.2086288332939148, 'rewards/rejected': -1.6490707397460938, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4404418468475342, 'policy_logps/rejected': -397.93780517578125, 'policy_logps/chosen': -343.1241455078125, 'referece_logps/rejected': -381.4471130371094, 'referece_logps/chosen': -341.0378723144531, 'logits/rejected': 0.17733366787433624, 'logits/chosen': 0.1780584752559662, 'epoch': 2.86}

 48%|████▊     | 7688/16104 [35:44:42<41:18:43, 17.67s/it]

 48%|████▊     | 7689/16104 [35:44:56<39:02:05, 16.70s/it]

 48%|████▊     | 7690/16104 [35:45:16<41:06:23, 17.59s/it]


 48%|████▊     | 7692/16104 [35:45:45<38:02:49, 16.28s/it]

 48%|████▊     | 7693/16104 [35:45:57<34:37:21, 14.82s/it]

 48%|████▊     | 7694/16104 [35:46:19<39:44:07, 17.01s/it]
{'loss': 0.4129, 'learning_rate': 1.1203830943109407e-06, 'rewards/chosen': -0.6307922601699829, 'rewards/rejected': -0.739560067653656, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1087677925825119, 'policy_logps/rejected': -304.0196838378906, 'policy_logps/chosen': -333.50433349609375, 'referece_logps/rejected': -296.62408447265625, 'referece_logps/chosen': -327.1964416503906, 'logits/rejected': -0.05813482403755188, 'logits/chosen': -0.12934528291225433, 'epoch': 2.87}

 48%|████▊     | 7695/16104 [35:46:36<40:08:12, 17.18s/it]


 48%|████▊     | 7697/16104 [35:47:12<41:01:28, 17.57s/it]
{'loss': 0.4826, 'learning_rate': 1.1197840816292091e-06, 'rewards/chosen': -0.6800021529197693, 'rewards/rejected': -1.168990135192871, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4889880418777466, 'policy_logps/rejected': -187.36766052246094, 'policy_logps/chosen': -275.27197265625, 'referece_logps/rejected': -175.677734375, 'referece_logps/chosen': -268.4719543457031, 'logits/rejected': -0.21263396739959717, 'logits/chosen': -0.07872941344976425, 'epoch': 2.87}


 48%|████▊     | 7699/16104 [35:47:51<44:04:46, 18.88s/it]

 48%|████▊     | 7700/16104 [35:48:11<44:39:57, 19.13s/it]
{'loss': 0.4057, 'learning_rate': 1.1191850253381601e-06, 'rewards/chosen': -0.1082279235124588, 'rewards/rejected': -1.9439363479614258, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8357086181640625, 'policy_logps/rejected': -449.090576171875, 'policy_logps/chosen': -512.6633911132812, 'referece_logps/rejected': -429.65118408203125, 'referece_logps/chosen': -511.5811462402344, 'logits/rejected': 1.2984318733215332, 'logits/chosen': 1.2931151390075684, 'epoch': 2.87}


 48%|████▊     | 7702/16104 [35:48:49<44:05:18, 18.89s/it]

 48%|████▊     | 7703/16104 [35:49:09<44:35:24, 19.11s/it]
{'loss': 0.5617, 'learning_rate': 1.1185859256558894e-06, 'rewards/chosen': -0.4324962794780731, 'rewards/rejected': -0.8913061618804932, 'rewards/accuracies': 0.75, 'rewards/margins': 0.45880991220474243, 'policy_logps/rejected': -426.0857849121094, 'policy_logps/chosen': -635.6657104492188, 'referece_logps/rejected': -417.1727294921875, 'referece_logps/chosen': -631.3407592773438, 'logits/rejected': 0.2974173426628113, 'logits/chosen': 0.2674112915992737, 'epoch': 2.87}

 48%|████▊     | 7704/16104 [35:49:25<42:18:18, 18.13s/it]


 48%|████▊     | 7706/16104 [35:49:53<37:04:07, 15.89s/it]
{'loss': 0.5164, 'learning_rate': 1.117986782800509e-06, 'rewards/chosen': -0.8792383074760437, 'rewards/rejected': -1.5108258724212646, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6315876245498657, 'policy_logps/rejected': -408.4508972167969, 'policy_logps/chosen': -344.2059631347656, 'referece_logps/rejected': -393.3426818847656, 'referece_logps/chosen': -335.41357421875, 'logits/rejected': -0.490902841091156, 'logits/chosen': -0.5099887847900391, 'epoch': 2.87}

 48%|████▊     | 7707/16104 [35:50:08<36:28:34, 15.64s/it]

 48%|████▊     | 7708/16104 [35:50:26<38:06:54, 16.34s/it]


 48%|████▊     | 7710/16104 [35:50:55<36:24:46, 15.62s/it]

 48%|████▊     | 7711/16104 [35:51:07<33:48:01, 14.50s/it]

 48%|████▊     | 7712/16104 [35:51:18<31:04:00, 13.33s/it]
{'loss': 0.5685, 'learning_rate': 1.116788368442946e-06, 'rewards/chosen': -0.4760517477989197, 'rewards/rejected': -1.6699552536010742, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1939035654067993, 'policy_logps/rejected': -391.2719421386719, 'policy_logps/chosen': -351.14703369140625, 'referece_logps/rejected': -374.5723876953125, 'referece_logps/chosen': -346.38653564453125, 'logits/rejected': 0.7575846910476685, 'logits/chosen': 0.777817964553833, 'epoch': 2.87}

 48%|████▊     | 7713/16104 [35:51:29<29:14:50, 12.55s/it]


 48%|████▊     | 7715/16104 [35:52:00<32:55:23, 14.13s/it]
{'loss': 0.561, 'learning_rate': 1.1161890973770647e-06, 'rewards/chosen': -0.5573199987411499, 'rewards/rejected': -0.8815699219703674, 'rewards/accuracies': 0.5, 'rewards/margins': 0.32424992322921753, 'policy_logps/rejected': -342.45330810546875, 'policy_logps/chosen': -461.8399353027344, 'referece_logps/rejected': -333.6376037597656, 'referece_logps/chosen': -456.2667236328125, 'logits/rejected': -0.5132431983947754, 'logits/chosen': -0.5410287380218506, 'epoch': 2.87}

 48%|████▊     | 7716/16104 [35:52:19<36:44:36, 15.77s/it]


 48%|████▊     | 7718/16104 [35:52:56<39:41:09, 17.04s/it]
{'loss': 0.4612, 'learning_rate': 1.1155897840106779e-06, 'rewards/chosen': -1.5174286365509033, 'rewards/rejected': -1.9916291236877441, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4742004871368408, 'policy_logps/rejected': -312.77783203125, 'policy_logps/chosen': -333.4303894042969, 'referece_logps/rejected': -292.86151123046875, 'referece_logps/chosen': -318.256103515625, 'logits/rejected': -0.6313861608505249, 'logits/chosen': -0.6425946950912476, 'epoch': 2.88}

 48%|████▊     | 7719/16104 [35:53:11<37:54:19, 16.27s/it]


 48%|████▊     | 7721/16104 [35:53:46<40:03:24, 17.20s/it]
{'loss': 0.4059, 'learning_rate': 1.1149904285619747e-06, 'rewards/chosen': -0.41522517800331116, 'rewards/rejected': -0.7989203929901123, 'rewards/accuracies': 0.875, 'rewards/margins': 0.38369518518447876, 'policy_logps/rejected': -275.3145751953125, 'policy_logps/chosen': -315.7720642089844, 'referece_logps/rejected': -267.32537841796875, 'referece_logps/chosen': -311.61981201171875, 'logits/rejected': 0.026682063937187195, 'logits/chosen': -0.03811635076999664, 'epoch': 2.88}

 48%|████▊     | 7722/16104 [35:54:03<39:32:36, 16.98s/it]

 48%|████▊     | 7723/16104 [35:54:22<40:57:40, 17.59s/it]

 48%|████▊     | 7724/16104 [35:54:36<39:02:19, 16.77s/it]

 48%|████▊     | 7725/16104 [35:54:57<41:33:26, 17.85s/it]


 48%|████▊     | 7727/16104 [35:55:36<43:39:28, 18.76s/it]
{'loss': 0.4159, 'learning_rate': 1.1137915922904552e-06, 'rewards/chosen': -0.11419002711772919, 'rewards/rejected': -1.7025024890899658, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5883123874664307, 'policy_logps/rejected': -525.0111694335938, 'policy_logps/chosen': -500.85748291015625, 'referece_logps/rejected': -507.98614501953125, 'referece_logps/chosen': -499.7156066894531, 'logits/rejected': 0.38465505838394165, 'logits/chosen': 0.316060334444046, 'epoch': 2.88}

 48%|████▊     | 7728/16104 [35:55:50<40:40:31, 17.48s/it]

 48%|████▊     | 7729/16104 [35:56:11<42:51:24, 18.42s/it]

 48%|████▊     | 7730/16104 [35:56:32<44:29:51, 19.13s/it]

 48%|████▊     | 7731/16104 [35:56:51<44:48:54, 19.27s/it]

 48%|████▊     | 7732/16104 [35:57:10<44:41:52, 19.22s/it]


 48%|████▊     | 7734/16104 [35:57:32<34:53:03, 15.00s/it]
{'loss': 0.4346, 'learning_rate': 1.1123927406564857e-06, 'rewards/chosen': -0.15199831128120422, 'rewards/rejected': -0.7929112911224365, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6409128904342651, 'policy_logps/rejected': -474.4512634277344, 'policy_logps/chosen': -587.50537109375, 'referece_logps/rejected': -466.5221862792969, 'referece_logps/chosen': -585.9853515625, 'logits/rejected': 0.21887442469596863, 'logits/chosen': 0.20795685052871704, 'epoch': 2.88}


 48%|████▊     | 7736/16104 [35:58:04<35:52:06, 15.43s/it]
{'loss': 0.4568, 'learning_rate': 1.111993027721423e-06, 'rewards/chosen': -1.186631679534912, 'rewards/rejected': -2.029642343521118, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8430108428001404, 'policy_logps/rejected': -452.0312805175781, 'policy_logps/chosen': -507.24114990234375, 'referece_logps/rejected': -431.7348327636719, 'referece_logps/chosen': -495.37481689453125, 'logits/rejected': -0.28259509801864624, 'logits/chosen': -0.368504136800766, 'epoch': 2.88}

 48%|████▊     | 7737/16104 [35:58:24<38:47:36, 16.69s/it]

 48%|████▊     | 7738/16104 [35:58:35<34:43:10, 14.94s/it]


 48%|████▊     | 7740/16104 [35:59:12<39:26:38, 16.98s/it]
{'loss': 0.3981, 'learning_rate': 1.1111935475521639e-06, 'rewards/chosen': -0.4402269721031189, 'rewards/rejected': -1.8500603437423706, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4098334312438965, 'policy_logps/rejected': -375.1495666503906, 'policy_logps/chosen': -498.2381591796875, 'referece_logps/rejected': -356.6489562988281, 'referece_logps/chosen': -493.83587646484375, 'logits/rejected': -0.48393917083740234, 'logits/chosen': -0.5688401460647583, 'epoch': 2.88}

 48%|████▊     | 7741/16104 [35:59:23<35:07:47, 15.12s/it]

 48%|████▊     | 7742/16104 [35:59:35<32:57:57, 14.19s/it]

 48%|████▊     | 7743/16104 [35:59:50<33:32:31, 14.44s/it]

 48%|████▊     | 7744/16104 [36:00:09<36:43:00, 15.81s/it]

 48%|████▊     | 7745/16104 [36:00:21<33:52:57, 14.59s/it]

 48%|████▊     | 7746/16104 [36:00:35<33:45:23, 14.54s/it]

 48%|████▊     | 7747/16104 [36:00:51<34:20:17, 14.79s/it]

 48%|████▊     | 7748/16104 [36:01:02<32:04:33, 13.82s/it]

 48%|████▊     | 7749/16104 [36:01:22<36:14:42, 15.62s/it]

 48%|████▊     | 7750/16104 [36:01:42<38:57:39, 16.79s/it]

 48%|████▊     | 7751/16104 [36:01:57<38:00:54, 16.38s/it]

 48%|████▊     | 7752/16104 [36:02:09<34:50:53, 15.02s/it]

 48%|████▊     | 7753/16104 [36:02:23<34:35:25, 14.91s/it]

 48%|████▊     | 7754/16104 [36:02:35<32:19:06, 13.93s/it]

 48%|████▊     | 7755/16104 [36:02:47<30:45:07, 13.26s/it]

 48%|████▊     | 7756/16104 [36:03:00<30:24:17, 13.11s/it]


 48%|████▊     | 7758/16104 [36:03:37<37:09:45, 16.03s/it]
{'loss': 0.374, 'learning_rate': 1.1075950036627344e-06, 'rewards/chosen': -0.4111570715904236, 'rewards/rejected': -1.7655305862426758, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3543736934661865, 'policy_logps/rejected': -208.6441192626953, 'policy_logps/chosen': -278.4093017578125, 'referece_logps/rejected': -190.98883056640625, 'referece_logps/chosen': -274.2977294921875, 'logits/rejected': -0.12204281985759735, 'logits/chosen': -0.056645460426807404, 'epoch': 2.89}

 48%|████▊     | 7759/16104 [36:03:49<34:36:52, 14.93s/it]

 48%|████▊     | 7760/16104 [36:04:08<37:31:58, 16.19s/it]

 48%|████▊     | 7761/16104 [36:04:24<37:05:50, 16.01s/it]

 48%|████▊     | 7762/16104 [36:04:43<39:42:37, 17.14s/it]

 48%|████▊     | 7763/16104 [36:05:04<42:10:21, 18.20s/it]


 48%|████▊     | 7765/16104 [36:05:39<40:42:51, 17.58s/it]
{'loss': 0.3972, 'learning_rate': 1.1061951864972873e-06, 'rewards/chosen': -0.46395155787467957, 'rewards/rejected': -1.3992645740509033, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9353129267692566, 'policy_logps/rejected': -477.64056396484375, 'policy_logps/chosen': -546.02197265625, 'referece_logps/rejected': -463.64788818359375, 'referece_logps/chosen': -541.3824462890625, 'logits/rejected': -0.5580178499221802, 'logits/chosen': -0.44740599393844604, 'epoch': 2.89}


 48%|████▊     | 7767/16104 [36:06:17<41:44:55, 18.03s/it]
{'loss': 0.4435, 'learning_rate': 1.1057951999523246e-06, 'rewards/chosen': -1.2779728174209595, 'rewards/rejected': -2.056602716445923, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7786298990249634, 'policy_logps/rejected': -826.435302734375, 'policy_logps/chosen': -474.1009216308594, 'referece_logps/rejected': -805.8692016601562, 'referece_logps/chosen': -461.32122802734375, 'logits/rejected': -0.635223388671875, 'logits/chosen': -0.42264488339424133, 'epoch': 2.89}


 48%|████▊     | 7769/16104 [36:06:53<41:55:32, 18.11s/it]

 48%|████▊     | 7770/16104 [36:07:13<43:10:49, 18.65s/it]
{'loss': 0.4187, 'learning_rate': 1.1051951880580712e-06, 'rewards/chosen': 0.029766499996185303, 'rewards/rejected': -1.379170536994934, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4089372158050537, 'policy_logps/rejected': -504.7270202636719, 'policy_logps/chosen': -499.55206298828125, 'referece_logps/rejected': -490.935302734375, 'referece_logps/chosen': -499.8497619628906, 'logits/rejected': 0.5519247055053711, 'logits/chosen': 0.64453125, 'epoch': 2.89}

 48%|████▊     | 7771/16104 [36:07:32<43:15:07, 18.69s/it]


 48%|████▊     | 7773/16104 [36:08:01<38:45:25, 16.75s/it]
{'loss': 0.4695, 'learning_rate': 1.1045951378658214e-06, 'rewards/chosen': -0.20360928773880005, 'rewards/rejected': -1.1836845874786377, 'rewards/accuracies': 0.625, 'rewards/margins': 0.980075478553772, 'policy_logps/rejected': -446.28509521484375, 'policy_logps/chosen': -511.9772644042969, 'referece_logps/rejected': -434.4482421875, 'referece_logps/chosen': -509.941162109375, 'logits/rejected': -0.16638576984405518, 'logits/chosen': -0.1624312847852707, 'epoch': 2.9}

 48%|████▊     | 7774/16104 [36:08:22<41:56:40, 18.13s/it]

 48%|████▊     | 7775/16104 [36:08:41<42:05:24, 18.19s/it]

 48%|████▊     | 7776/16104 [36:08:54<38:38:19, 16.70s/it]

 48%|████▊     | 7777/16104 [36:09:07<35:56:51, 15.54s/it]

 48%|████▊     | 7778/16104 [36:09:25<37:32:43, 16.23s/it]

 48%|████▊     | 7779/16104 [36:09:42<38:31:01, 16.66s/it]

 48%|████▊     | 7780/16104 [36:09:53<34:37:45, 14.98s/it]


 48%|████▊     | 7782/16104 [36:10:25<35:53:59, 15.53s/it]
{'loss': 0.3872, 'learning_rate': 1.10279475968574e-06, 'rewards/chosen': -0.9614658355712891, 'rewards/rejected': -2.089141607284546, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1276757717132568, 'policy_logps/rejected': -385.5632019042969, 'policy_logps/chosen': -299.15118408203125, 'referece_logps/rejected': -364.67181396484375, 'referece_logps/chosen': -289.53656005859375, 'logits/rejected': -0.5437862277030945, 'logits/chosen': -0.6239258050918579, 'epoch': 2.9}

 48%|████▊     | 7783/16104 [36:10:45<38:37:37, 16.71s/it]

 48%|████▊     | 7784/16104 [36:10:58<36:30:21, 15.80s/it]

 48%|████▊     | 7785/16104 [36:11:15<36:59:08, 16.01s/it]

 48%|████▊     | 7786/16104 [36:11:26<33:21:52, 14.44s/it]

 48%|████▊     | 7787/16104 [36:11:36<30:41:26, 13.28s/it]


 48%|████▊     | 7789/16104 [36:12:07<32:43:27, 14.17s/it]
{'loss': 0.5514, 'learning_rate': 1.101394232382635e-06, 'rewards/chosen': -0.5129197835922241, 'rewards/rejected': -0.45054230093955994, 'rewards/accuracies': 0.5, 'rewards/margins': -0.06237751245498657, 'policy_logps/rejected': -511.7822570800781, 'policy_logps/chosen': -431.7254943847656, 'referece_logps/rejected': -507.27685546875, 'referece_logps/chosen': -426.5963439941406, 'logits/rejected': -0.1785670518875122, 'logits/chosen': -0.2007702887058258, 'epoch': 2.9}

 48%|████▊     | 7790/16104 [36:12:18<30:19:58, 13.13s/it]

 48%|████▊     | 7791/16104 [36:12:29<28:39:24, 12.41s/it]

 48%|████▊     | 7792/16104 [36:12:43<29:50:02, 12.92s/it]


 48%|████▊     | 7794/16104 [36:13:11<31:59:09, 13.86s/it]
{'loss': 0.4912, 'learning_rate': 1.1003937325283667e-06, 'rewards/chosen': -0.13774777948856354, 'rewards/rejected': -0.5643032789230347, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4265555441379547, 'policy_logps/rejected': -427.7897033691406, 'policy_logps/chosen': -589.1472778320312, 'referece_logps/rejected': -422.14666748046875, 'referece_logps/chosen': -587.769775390625, 'logits/rejected': 0.09371152520179749, 'logits/chosen': -0.06535473465919495, 'epoch': 2.9}


 48%|████▊     | 7796/16104 [36:13:33<28:48:54, 12.49s/it]
{'loss': 0.5106, 'learning_rate': 1.099993504102258e-06, 'rewards/chosen': 0.10012663900852203, 'rewards/rejected': -0.4461229145526886, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5462496280670166, 'policy_logps/rejected': -469.4298400878906, 'policy_logps/chosen': -513.687744140625, 'referece_logps/rejected': -464.9685974121094, 'referece_logps/chosen': -514.6890258789062, 'logits/rejected': 0.08160805702209473, 'logits/chosen': 0.15762363374233246, 'epoch': 2.9}

 48%|████▊     | 7797/16104 [36:13:49<30:43:31, 13.32s/it]

 48%|████▊     | 7798/16104 [36:14:02<30:49:06, 13.36s/it]

 48%|████▊     | 7799/16104 [36:14:18<32:29:02, 14.08s/it]

 48%|████▊     | 7800/16104 [36:14:39<37:26:48, 16.23s/it]

 48%|████▊     | 7801/16104 [36:14:56<38:06:23, 16.52s/it]

 48%|████▊     | 7802/16104 [36:15:16<40:09:12, 17.41s/it]

 48%|████▊     | 7803/16104 [36:15:28<36:44:17, 15.93s/it]


 48%|████▊     | 7805/16104 [36:15:55<33:54:58, 14.71s/it]

 48%|████▊     | 7806/16104 [36:16:15<37:39:47, 16.34s/it]

 48%|████▊     | 7807/16104 [36:16:29<36:00:24, 15.62s/it]
{'loss': 0.5281, 'learning_rate': 1.0977919602836963e-06, 'rewards/chosen': -0.3818195164203644, 'rewards/rejected': -1.014113187789917, 'rewards/accuracies': 0.625, 'rewards/margins': 0.632293701171875, 'policy_logps/rejected': -489.6875, 'policy_logps/chosen': -602.2937622070312, 'referece_logps/rejected': -479.54632568359375, 'referece_logps/chosen': -598.4755859375, 'logits/rejected': 0.5870742797851562, 'logits/chosen': 0.4887291491031647, 'epoch': 2.91}

 48%|████▊     | 7808/16104 [36:16:49<38:49:54, 16.85s/it]

 48%|████▊     | 7809/16104 [36:17:08<40:22:25, 17.52s/it]

 48%|████▊     | 7810/16104 [36:17:19<35:52:22, 15.57s/it]


 49%|████▊     | 7812/16104 [36:17:53<37:20:44, 16.21s/it]
{'loss': 0.3638, 'learning_rate': 1.0967910996659087e-06, 'rewards/chosen': 0.2506767511367798, 'rewards/rejected': -0.9745866656303406, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2252634763717651, 'policy_logps/rejected': -627.23681640625, 'policy_logps/chosen': -548.8334350585938, 'referece_logps/rejected': -617.4910278320312, 'referece_logps/chosen': -551.3401489257812, 'logits/rejected': 0.16863913834095, 'logits/chosen': 0.13449709117412567, 'epoch': 2.91}

 49%|████▊     | 7813/16104 [36:18:11<38:31:26, 16.73s/it]

 49%|████▊     | 7814/16104 [36:18:25<36:18:24, 15.77s/it]

 49%|████▊     | 7815/16104 [36:18:42<37:08:17, 16.13s/it]

 49%|████▊     | 7816/16104 [36:18:58<37:12:52, 16.16s/it]

 49%|████▊     | 7817/16104 [36:19:17<39:18:17, 17.07s/it]

 49%|████▊     | 7818/16104 [36:19:32<37:33:19, 16.32s/it]

 49%|████▊     | 7819/16104 [36:19:48<37:36:39, 16.34s/it]

 49%|████▊     | 7820/16104 [36:20:07<39:29:29, 17.16s/it]

 49%|████▊     | 7821/16104 [36:20:23<38:42:44, 16.83s/it]

 49%|████▊     | 7822/16104 [36:20:35<35:16:44, 15.33s/it]

 49%|████▊     | 7823/16104 [36:20:46<32:04:17, 13.94s/it]

 49%|████▊     | 7824/16104 [36:21:01<32:42:44, 14.22s/it]

 49%|████▊     | 7825/16104 [36:21:16<33:04:58, 14.39s/it]

 49%|████▊     | 7826/16104 [36:21:31<34:05:15, 14.82s/it]


 49%|████▊     | 7828/16104 [36:22:02<35:26:02, 15.41s/it]
{'loss': 0.5884, 'learning_rate': 1.0935876928950085e-06, 'rewards/chosen': -0.8606500625610352, 'rewards/rejected': -0.738510012626648, 'rewards/accuracies': 0.5, 'rewards/margins': -0.12213999032974243, 'policy_logps/rejected': -414.88787841796875, 'policy_logps/chosen': -321.9884033203125, 'referece_logps/rejected': -407.5027770996094, 'referece_logps/chosen': -313.38189697265625, 'logits/rejected': -0.22090500593185425, 'logits/chosen': -0.07596984505653381, 'epoch': 2.92}

 49%|████▊     | 7829/16104 [36:22:21<37:59:29, 16.53s/it]

 49%|████▊     | 7830/16104 [36:22:41<40:05:31, 17.44s/it]

 49%|████▊     | 7831/16104 [36:22:56<38:52:41, 16.92s/it]

 49%|████▊     | 7832/16104 [36:23:10<36:29:20, 15.88s/it]

 49%|████▊     | 7833/16104 [36:23:26<36:28:16, 15.87s/it]

 49%|████▊     | 7834/16104 [36:23:43<37:47:23, 16.45s/it]

 49%|████▊     | 7835/16104 [36:24:04<40:25:46, 17.60s/it]

 49%|████▊     | 7836/16104 [36:24:21<40:08:53, 17.48s/it]

 49%|████▊     | 7837/16104 [36:24:32<36:07:05, 15.73s/it]

 49%|████▊     | 7838/16104 [36:24:43<32:38:28, 14.22s/it]

 49%|████▊     | 7839/16104 [36:24:56<31:57:30, 13.92s/it]

 49%|████▊     | 7840/16104 [36:25:11<32:42:00, 14.25s/it]

 49%|████▊     | 7841/16104 [36:25:23<31:14:59, 13.61s/it]

 49%|████▊     | 7842/16104 [36:25:43<35:25:16, 15.43s/it]

 49%|████▊     | 7843/16104 [36:25:57<34:06:51, 14.87s/it]

 49%|████▊     | 7844/16104 [36:26:08<31:36:51, 13.78s/it]

 49%|████▊     | 7845/16104 [36:26:28<36:04:10, 15.72s/it]

 49%|████▊     | 7846/16104 [36:26:46<37:09:02, 16.20s/it]

 49%|████▊     | 7847/16104 [36:27:05<39:35:21, 17.26s/it]

 49%|████▊     | 7848/16104 [36:27:25<41:24:46, 18.06s/it]

 49%|████▊     | 7849/16104 [36:27:38<37:32:33, 16.37s/it]

 49%|████▊     | 7850/16104 [36:27:56<38:41:37, 16.88s/it]

 49%|████▉     | 7851/16104 [36:28:09<36:15:24, 15.82s/it]


 49%|████▉     | 7853/16104 [36:28:41<36:44:58, 16.03s/it]

 49%|████▉     | 7854/16104 [36:29:01<39:27:19, 17.22s/it]

 49%|████▉     | 7855/16104 [36:29:12<35:35:55, 15.54s/it]
{'loss': 0.4172, 'learning_rate': 1.0881797635638431e-06, 'rewards/chosen': 0.21799872815608978, 'rewards/rejected': -1.7207965850830078, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9387953281402588, 'policy_logps/rejected': -399.60589599609375, 'policy_logps/chosen': -514.6474609375, 'referece_logps/rejected': -382.39794921875, 'referece_logps/chosen': -516.8274536132812, 'logits/rejected': 0.3545866906642914, 'logits/chosen': 0.35306060314178467, 'epoch': 2.93}


 49%|████▉     | 7857/16104 [36:29:43<34:59:27, 15.27s/it]

 49%|████▉     | 7858/16104 [36:30:01<37:08:54, 16.22s/it]

 49%|████▉     | 7859/16104 [36:30:12<33:24:17, 14.59s/it]

 49%|████▉     | 7860/16104 [36:30:26<33:21:04, 14.56s/it]

 49%|████▉     | 7861/16104 [36:30:39<31:54:14, 13.93s/it]

 49%|████▉     | 7862/16104 [36:30:50<29:41:56, 12.97s/it]

 49%|████▉     | 7863/16104 [36:31:07<32:59:31, 14.41s/it]

 49%|████▉     | 7864/16104 [36:31:24<34:19:15, 14.99s/it]

 49%|████▉     | 7865/16104 [36:31:34<31:18:22, 13.68s/it]

 49%|████▉     | 7866/16104 [36:31:46<30:12:01, 13.20s/it]
{'loss': 0.4905, 'learning_rate': 1.085975778554467e-06, 'rewards/chosen': -0.6491161584854126, 'rewards/rejected': -2.3386290073394775, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6895127296447754, 'policy_logps/rejected': -333.35302734375, 'policy_logps/chosen': -400.2320556640625, 'referece_logps/rejected': -309.96673583984375, 'referece_logps/chosen': -393.74090576171875, 'logits/rejected': -0.48538947105407715, 'logits/chosen': -0.5113926529884338, 'epoch': 2.93}


 49%|████▉     | 7868/16104 [36:32:18<34:07:13, 14.91s/it]

 49%|████▉     | 7869/16104 [36:32:35<35:36:41, 15.57s/it]

 49%|████▉     | 7870/16104 [36:32:50<34:41:11, 15.17s/it]

 49%|████▉     | 7871/16104 [36:33:10<38:17:10, 16.74s/it]

 49%|████▉     | 7872/16104 [36:33:28<39:28:28, 17.26s/it]

 49%|████▉     | 7873/16104 [36:33:46<39:30:38, 17.28s/it]

 49%|████▉     | 7874/16104 [36:34:02<38:49:32, 16.98s/it]
{'loss': 0.3487, 'learning_rate': 1.0843726154314767e-06, 'rewards/chosen': -0.17881718277931213, 'rewards/rejected': -1.24884831905365, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0700311660766602, 'policy_logps/rejected': -221.2918701171875, 'policy_logps/chosen': -280.2933349609375, 'referece_logps/rejected': -208.8033905029297, 'referece_logps/chosen': -278.5051574707031, 'logits/rejected': -0.5660783648490906, 'logits/chosen': -0.6152018904685974, 'epoch': 2.93}


 49%|████▉     | 7876/16104 [36:34:43<42:34:15, 18.63s/it]

 49%|████▉     | 7877/16104 [36:34:57<39:57:08, 17.48s/it]

 49%|████▉     | 7878/16104 [36:35:08<35:19:26, 15.46s/it]
{'loss': 0.4293, 'learning_rate': 1.083570951698025e-06, 'rewards/chosen': -0.5754455924034119, 'rewards/rejected': -2.387709140777588, 'rewards/accuracies': 0.625, 'rewards/margins': 1.8122633695602417, 'policy_logps/rejected': -393.7620849609375, 'policy_logps/chosen': -427.5234375, 'referece_logps/rejected': -369.88494873046875, 'referece_logps/chosen': -421.76898193359375, 'logits/rejected': 0.04247373342514038, 'logits/chosen': -0.03581377863883972, 'epoch': 2.94}


 49%|████▉     | 7880/16104 [36:35:31<30:33:04, 13.37s/it]

 49%|████▉     | 7881/16104 [36:35:44<30:16:07, 13.25s/it]

 49%|████▉     | 7882/16104 [36:35:57<30:37:17, 13.41s/it]

 49%|████▉     | 7883/16104 [36:36:18<35:26:47, 15.52s/it]

 49%|████▉     | 7884/16104 [36:36:29<32:07:27, 14.07s/it]

 49%|████▉     | 7885/16104 [36:36:42<31:42:15, 13.89s/it]

 49%|████▉     | 7886/16104 [36:36:58<32:49:35, 14.38s/it]

 49%|████▉     | 7887/16104 [36:37:17<36:33:56, 16.02s/it]
{'loss': 0.4665, 'learning_rate': 1.0817670113235192e-06, 'rewards/chosen': -0.5207237005233765, 'rewards/rejected': -2.222018003463745, 'rewards/accuracies': 0.875, 'rewards/margins': 1.701294183731079, 'policy_logps/rejected': -575.268310546875, 'policy_logps/chosen': -465.1283874511719, 'referece_logps/rejected': -553.048095703125, 'referece_logps/chosen': -459.921142578125, 'logits/rejected': -0.23915809392929077, 'logits/chosen': -0.17642797529697418, 'epoch': 2.94}


 49%|████▉     | 7889/16104 [36:37:49<36:31:57, 16.01s/it]
{'loss': 0.533, 'learning_rate': 1.081366099092789e-06, 'rewards/chosen': 0.07157480716705322, 'rewards/rejected': -2.255095958709717, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3266706466674805, 'policy_logps/rejected': -476.2693786621094, 'policy_logps/chosen': -476.59259033203125, 'referece_logps/rejected': -453.71844482421875, 'referece_logps/chosen': -477.3083190917969, 'logits/rejected': 0.4768999516963959, 'logits/chosen': 0.451546311378479, 'epoch': 2.94}


 49%|████▉     | 7891/16104 [36:38:22<37:24:00, 16.39s/it]

 49%|████▉     | 7892/16104 [36:38:42<39:54:14, 17.49s/it]

 49%|████▉     | 7893/16104 [36:39:00<40:13:19, 17.63s/it]

 49%|████▉     | 7894/16104 [36:39:17<39:51:09, 17.48s/it]
{'loss': 0.4931, 'learning_rate': 1.0803637610583047e-06, 'rewards/chosen': -0.8219702243804932, 'rewards/rejected': -1.3307344913482666, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5087642669677734, 'policy_logps/rejected': -414.6463317871094, 'policy_logps/chosen': -361.94293212890625, 'referece_logps/rejected': -401.3389892578125, 'referece_logps/chosen': -353.7232360839844, 'logits/rejected': 0.18143612146377563, 'logits/chosen': 0.16763091087341309, 'epoch': 2.94}


 49%|████▉     | 7896/16104 [36:39:54<41:20:18, 18.13s/it]

 49%|████▉     | 7897/16104 [36:40:16<43:46:12, 19.20s/it]

 49%|████▉     | 7898/16104 [36:40:30<40:44:29, 17.87s/it]

 49%|████▉     | 7899/16104 [36:40:47<39:31:47, 17.34s/it]
{'loss': 0.4032, 'learning_rate': 1.0793613417523885e-06, 'rewards/chosen': -0.11671067029237747, 'rewards/rejected': -0.7328912615776062, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6161807179450989, 'policy_logps/rejected': -601.7708129882812, 'policy_logps/chosen': -508.96026611328125, 'referece_logps/rejected': -594.4419555664062, 'referece_logps/chosen': -507.79315185546875, 'logits/rejected': -0.4493557810783386, 'logits/chosen': -0.4443414807319641, 'epoch': 2.94}


 49%|████▉     | 7901/16104 [36:41:19<39:38:56, 17.40s/it]

 49%|████▉     | 7902/16104 [36:41:41<42:38:08, 18.71s/it]

 49%|████▉     | 7903/16104 [36:41:58<41:22:55, 18.17s/it]

 49%|████▉     | 7904/16104 [36:42:09<36:33:59, 16.05s/it]

 49%|████▉     | 7905/16104 [36:42:30<39:31:02, 17.35s/it]

 49%|████▉     | 7906/16104 [36:42:52<42:44:21, 18.77s/it]

 49%|████▉     | 7907/16104 [36:43:06<39:34:24, 17.38s/it]
{'loss': 0.4943, 'learning_rate': 1.0777573043486722e-06, 'rewards/chosen': -0.7230905294418335, 'rewards/rejected': -2.220306396484375, 'rewards/accuracies': 0.875, 'rewards/margins': 1.497215747833252, 'policy_logps/rejected': -362.17474365234375, 'policy_logps/chosen': -528.413818359375, 'referece_logps/rejected': -339.9716796875, 'referece_logps/chosen': -521.1829223632812, 'logits/rejected': -0.7751070261001587, 'logits/chosen': -0.9141736030578613, 'epoch': 2.95}

 49%|████▉     | 7908/16104 [36:43:25<41:09:04, 18.08s/it]


 49%|████▉     | 7910/16104 [36:44:00<40:13:50, 17.68s/it]

 49%|████▉     | 7911/16104 [36:44:22<43:10:16, 18.97s/it]

 49%|████▉     | 7912/16104 [36:44:42<44:01:56, 19.35s/it]

 49%|████▉     | 7913/16104 [36:45:02<44:34:05, 19.59s/it]

 49%|████▉     | 7914/16104 [36:45:19<42:27:18, 18.66s/it]

 49%|████▉     | 7915/16104 [36:45:33<39:19:35, 17.29s/it]

 49%|████▉     | 7916/16104 [36:45:54<42:05:16, 18.50s/it]

 49%|████▉     | 7917/16104 [36:46:14<43:03:31, 18.93s/it]

 49%|████▉     | 7918/16104 [36:46:35<44:38:14, 19.63s/it]

 49%|████▉     | 7919/16104 [36:46:50<41:31:51, 18.27s/it]

 49%|████▉     | 7920/16104 [36:47:10<42:24:17, 18.65s/it]

 49%|████▉     | 7921/16104 [36:47:29<43:06:46, 18.97s/it]

 49%|████▉     | 7922/16104 [36:47:49<43:11:11, 19.00s/it]

 49%|████▉     | 7923/16104 [36:48:09<44:00:35, 19.37s/it]

 49%|████▉     | 7924/16104 [36:48:29<44:19:42, 19.51s/it]

 49%|████▉     | 7925/16104 [36:48:46<43:05:54, 18.97s/it]

 49%|████▉     | 7926/16104 [36:48:59<38:30:53, 16.95s/it]

 49%|████▉     | 7927/16104 [36:49:15<37:51:46, 16.67s/it]

 49%|████▉     | 7928/16104 [36:49:31<37:51:47, 16.67s/it]

 49%|████▉     | 7929/16104 [36:49:51<40:10:29, 17.69s/it]
{'loss': 0.3893, 'learning_rate': 1.0733451759919482e-06, 'rewards/chosen': -0.24643023312091827, 'rewards/rejected': -1.0221045017242432, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7756742238998413, 'policy_logps/rejected': -419.49688720703125, 'policy_logps/chosen': -416.39788818359375, 'referece_logps/rejected': -409.27581787109375, 'referece_logps/chosen': -413.9335632324219, 'logits/rejected': -0.2942774295806885, 'logits/chosen': -0.36091548204421997, 'epoch': 2.95}

 49%|████▉     | 7930/16104 [36:50:12<42:07:21, 18.55s/it]


 49%|████▉     | 7932/16104 [36:50:39<36:45:38, 16.19s/it]
{'loss': 0.4696, 'learning_rate': 1.0727434089378362e-06, 'rewards/chosen': -0.18528462946414948, 'rewards/rejected': -2.0441434383392334, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8588589429855347, 'policy_logps/rejected': -418.3468017578125, 'policy_logps/chosen': -496.8485412597656, 'referece_logps/rejected': -397.9053649902344, 'referece_logps/chosen': -494.9957275390625, 'logits/rejected': 0.07411785423755646, 'logits/chosen': 0.016683489084243774, 'epoch': 2.96}


 49%|████▉     | 7934/16104 [36:51:01<30:32:49, 13.46s/it]

 49%|████▉     | 7935/16104 [36:51:18<32:38:21, 14.38s/it]

 49%|████▉     | 7936/16104 [36:51:40<37:51:30, 16.69s/it]

 49%|████▉     | 7937/16104 [36:51:57<38:05:13, 16.79s/it]
{'loss': 0.5441, 'learning_rate': 1.07174040510383e-06, 'rewards/chosen': -0.8003337979316711, 'rewards/rejected': -1.4410902261734009, 'rewards/accuracies': 0.75, 'rewards/margins': 0.640756368637085, 'policy_logps/rejected': -383.535400390625, 'policy_logps/chosen': -525.450439453125, 'referece_logps/rejected': -369.12451171875, 'referece_logps/chosen': -517.4470825195312, 'logits/rejected': -0.7747726440429688, 'logits/chosen': -0.9308260679244995, 'epoch': 2.96}


 49%|████▉     | 7939/16104 [36:52:29<36:25:26, 16.06s/it]
{'loss': 0.5098, 'learning_rate': 1.0713391831992323e-06, 'rewards/chosen': -0.046656228601932526, 'rewards/rejected': -1.1294044256210327, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0827481746673584, 'policy_logps/rejected': -609.1583251953125, 'policy_logps/chosen': -511.07763671875, 'referece_logps/rejected': -597.8642578125, 'referece_logps/chosen': -510.6110534667969, 'logits/rejected': -0.2538731098175049, 'logits/chosen': -0.1598607897758484, 'epoch': 2.96}

 49%|████▉     | 7940/16104 [36:52:48<38:47:15, 17.10s/it]


 49%|████▉     | 7942/16104 [36:53:21<37:05:05, 16.36s/it]

 49%|████▉     | 7943/16104 [36:53:32<33:17:52, 14.69s/it]
{'loss': 0.4991, 'learning_rate': 1.0705367048253926e-06, 'rewards/chosen': -1.0769853591918945, 'rewards/rejected': -2.1135284900665283, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0365430116653442, 'policy_logps/rejected': -221.3122100830078, 'policy_logps/chosen': -290.58294677734375, 'referece_logps/rejected': -200.17694091796875, 'referece_logps/chosen': -279.8131103515625, 'logits/rejected': -0.7070041298866272, 'logits/chosen': -0.5763771533966064, 'epoch': 2.96}


 49%|████▉     | 7945/16104 [36:53:59<32:36:07, 14.39s/it]

 49%|████▉     | 7946/16104 [36:54:09<30:03:00, 13.26s/it]

 49%|████▉     | 7947/16104 [36:54:23<30:09:24, 13.31s/it]
{'loss': 0.5501, 'learning_rate': 1.0697341807981856e-06, 'rewards/chosen': -0.12982842326164246, 'rewards/rejected': -2.0195226669311523, 'rewards/accuracies': 0.875, 'rewards/margins': 1.889694094657898, 'policy_logps/rejected': -479.53070068359375, 'policy_logps/chosen': -505.24627685546875, 'referece_logps/rejected': -459.33551025390625, 'referece_logps/chosen': -503.947998046875, 'logits/rejected': -0.4196121096611023, 'logits/chosen': -0.5208027362823486, 'epoch': 2.96}


 49%|████▉     | 7949/16104 [36:54:51<31:11:38, 13.77s/it]

 49%|████▉     | 7950/16104 [36:55:03<30:18:49, 13.38s/it]
{'loss': 0.5108, 'learning_rate': 1.0691322581302186e-06, 'rewards/chosen': 0.35455629229545593, 'rewards/rejected': -0.8508484959602356, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2054047584533691, 'policy_logps/rejected': -374.3368225097656, 'policy_logps/chosen': -514.5297241210938, 'referece_logps/rejected': -365.82830810546875, 'referece_logps/chosen': -518.0752563476562, 'logits/rejected': 0.6847652792930603, 'logits/chosen': 0.7104959487915039, 'epoch': 2.96}


 49%|████▉     | 7952/16104 [36:55:32<30:32:13, 13.49s/it]

 49%|████▉     | 7953/16104 [36:55:50<33:48:30, 14.93s/it]

 49%|████▉     | 7954/16104 [36:56:11<38:01:06, 16.79s/it]

 49%|████▉     | 7955/16104 [36:56:23<34:38:51, 15.31s/it]

 49%|████▉     | 7956/16104 [36:56:35<32:25:03, 14.32s/it]

 49%|████▉     | 7957/16104 [36:56:50<32:35:02, 14.40s/it]

 49%|████▉     | 7958/16104 [36:57:10<36:32:21, 16.15s/it]

 49%|████▉     | 7959/16104 [36:57:32<40:18:18, 17.81s/it]

 49%|████▉     | 7960/16104 [36:57:47<38:54:43, 17.20s/it]
{'loss': 0.5139, 'learning_rate': 1.0671256686940305e-06, 'rewards/chosen': -0.8417487144470215, 'rewards/rejected': -1.4832382202148438, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6414893865585327, 'policy_logps/rejected': -198.4498291015625, 'policy_logps/chosen': -231.56414794921875, 'referece_logps/rejected': -183.61746215820312, 'referece_logps/chosen': -223.14666748046875, 'logits/rejected': 0.046696536242961884, 'logits/chosen': -0.16293759644031525, 'epoch': 2.97}


 49%|████▉     | 7962/16104 [36:58:22<38:18:16, 16.94s/it]

 49%|████▉     | 7963/16104 [36:58:42<40:39:40, 17.98s/it]
{'loss': 0.4671, 'learning_rate': 1.0665236385444531e-06, 'rewards/chosen': 0.09949437528848648, 'rewards/rejected': -1.4039921760559082, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5034865140914917, 'policy_logps/rejected': -462.6343994140625, 'policy_logps/chosen': -372.16162109375, 'referece_logps/rejected': -448.594482421875, 'referece_logps/chosen': -373.1566162109375, 'logits/rejected': -0.10245494544506073, 'logits/chosen': -0.10584213584661484, 'epoch': 2.97}


 49%|████▉     | 7965/16104 [36:59:16<39:14:59, 17.36s/it]

 49%|████▉     | 7966/16104 [36:59:27<35:03:34, 15.51s/it]

 49%|████▉     | 7967/16104 [36:59:40<32:55:58, 14.57s/it]

 49%|████▉     | 7968/16104 [36:59:58<35:16:37, 15.61s/it]
{'loss': 0.4597, 'learning_rate': 1.0655202012500688e-06, 'rewards/chosen': -0.1770288646221161, 'rewards/rejected': -0.8557903170585632, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6787614822387695, 'policy_logps/rejected': -360.7969055175781, 'policy_logps/chosen': -374.8159484863281, 'referece_logps/rejected': -352.239013671875, 'referece_logps/chosen': -373.045654296875, 'logits/rejected': 0.028144970536231995, 'logits/chosen': 0.04036623612046242, 'epoch': 2.97}


 49%|████▉     | 7970/16104 [37:00:24<32:59:19, 14.60s/it]

 49%|████▉     | 7971/16104 [37:00:38<32:33:13, 14.41s/it]
{'loss': 0.5132, 'learning_rate': 1.0649181070035841e-06, 'rewards/chosen': -0.20502394437789917, 'rewards/rejected': -0.9220635890960693, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7170397639274597, 'policy_logps/rejected': -618.6138916015625, 'policy_logps/chosen': -519.6165771484375, 'referece_logps/rejected': -609.3932495117188, 'referece_logps/chosen': -517.56640625, 'logits/rejected': 0.4194977581501007, 'logits/chosen': 0.14649221301078796, 'epoch': 2.97}


 50%|████▉     | 7973/16104 [37:01:07<32:24:38, 14.35s/it]

 50%|████▉     | 7974/16104 [37:01:26<35:26:58, 15.70s/it]
{'loss': 0.6384, 'learning_rate': 1.0643159891226203e-06, 'rewards/chosen': -0.27812087535858154, 'rewards/rejected': -1.3074239492416382, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0293031930923462, 'policy_logps/rejected': -549.7943725585938, 'policy_logps/chosen': -353.9572448730469, 'referece_logps/rejected': -536.7200927734375, 'referece_logps/chosen': -351.1760559082031, 'logits/rejected': -0.5952463150024414, 'logits/chosen': -0.42397645115852356, 'epoch': 2.97}


 50%|████▉     | 7976/16104 [37:01:50<30:40:01, 13.58s/it]

 50%|████▉     | 7977/16104 [37:02:02<29:54:42, 13.25s/it]

 50%|████▉     | 7978/16104 [37:02:22<34:12:32, 15.16s/it]
{'loss': 0.4859, 'learning_rate': 1.0635131288954746e-06, 'rewards/chosen': -0.3823719024658203, 'rewards/rejected': -1.1546138525009155, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7722419500350952, 'policy_logps/rejected': -587.5523681640625, 'policy_logps/chosen': -648.3509521484375, 'referece_logps/rejected': -576.0062255859375, 'referece_logps/chosen': -644.5272827148438, 'logits/rejected': -0.11828494071960449, 'logits/chosen': -0.20949682593345642, 'epoch': 2.97}


 50%|████▉     | 7980/16104 [37:02:57<37:19:44, 16.54s/it]
{'loss': 0.5486, 'learning_rate': 1.0631116833341077e-06, 'rewards/chosen': -0.44827061891555786, 'rewards/rejected': -1.3082228899002075, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8599523305892944, 'policy_logps/rejected': -333.67559814453125, 'policy_logps/chosen': -381.0729064941406, 'referece_logps/rejected': -320.5933532714844, 'referece_logps/chosen': -376.5901794433594, 'logits/rejected': -0.07105676084756851, 'logits/chosen': -0.06870487332344055, 'epoch': 2.97}


 50%|████▉     | 7982/16104 [37:03:31<38:14:14, 16.95s/it]

 50%|████▉     | 7983/16104 [37:03:50<39:08:25, 17.35s/it]
{'loss': 0.4302, 'learning_rate': 1.0625094958650055e-06, 'rewards/chosen': 0.06422080844640732, 'rewards/rejected': -1.4430134296417236, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5072343349456787, 'policy_logps/rejected': -414.52508544921875, 'policy_logps/chosen': -420.681396484375, 'referece_logps/rejected': -400.09490966796875, 'referece_logps/chosen': -421.3236389160156, 'logits/rejected': -0.034366413950920105, 'logits/chosen': -0.10891499370336533, 'epoch': 2.97}

 50%|████▉     | 7984/16104 [37:04:11<41:45:44, 18.52s/it]


 50%|████▉     | 7986/16104 [37:04:40<36:29:54, 16.19s/it]

 50%|████▉     | 7987/16104 [37:04:53<34:04:56, 15.12s/it]

 50%|████▉     | 7988/16104 [37:05:14<38:09:54, 16.93s/it]

 50%|████▉     | 7989/16104 [37:05:24<33:54:32, 15.04s/it]

 50%|████▉     | 7990/16104 [37:05:45<37:23:13, 16.59s/it]
{'loss': 0.5007, 'learning_rate': 1.0611043036476555e-06, 'rewards/chosen': 0.08536280691623688, 'rewards/rejected': -0.9277752041816711, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0131380558013916, 'policy_logps/rejected': -313.1321716308594, 'policy_logps/chosen': -430.62335205078125, 'referece_logps/rejected': -303.8544006347656, 'referece_logps/chosen': -431.47698974609375, 'logits/rejected': 0.20951363444328308, 'logits/chosen': 0.2871529757976532, 'epoch': 2.98}

 50%|████▉     | 7991/16104 [37:06:03<38:33:13, 17.11s/it]

 50%|████▉     | 7992/16104 [37:06:21<39:05:16, 17.35s/it]


 50%|████▉     | 7994/16104 [37:06:52<36:24:25, 16.16s/it]

 50%|████▉     | 7995/16104 [37:07:12<39:00:16, 17.32s/it]
{'loss': 0.4382, 'learning_rate': 1.0601005206052285e-06, 'rewards/chosen': -0.5457683205604553, 'rewards/rejected': -2.34346866607666, 'rewards/accuracies': 0.875, 'rewards/margins': 1.79770028591156, 'policy_logps/rejected': -493.6605529785156, 'policy_logps/chosen': -442.1570739746094, 'referece_logps/rejected': -470.22589111328125, 'referece_logps/chosen': -436.6994323730469, 'logits/rejected': 0.5048201084136963, 'logits/chosen': 0.663292407989502, 'epoch': 2.98}


 50%|████▉     | 7997/16104 [37:07:38<33:26:48, 14.85s/it]

 50%|████▉     | 7998/16104 [37:07:52<33:19:04, 14.80s/it]

 50%|████▉     | 7999/16104 [37:08:05<31:41:26, 14.08s/it]
{'loss': 0.4765, 'learning_rate': 1.059297450361443e-06, 'rewards/chosen': -0.48623278737068176, 'rewards/rejected': -1.7173290252685547, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2310963869094849, 'policy_logps/rejected': -421.5479736328125, 'policy_logps/chosen': -384.5284729003906, 'referece_logps/rejected': -404.3747253417969, 'referece_logps/chosen': -379.6661071777344, 'logits/rejected': 0.11406004428863525, 'logits/chosen': 0.33696460723876953, 'epoch': 2.98}

 50%|████▉     | 8000/16104 [37:08:25<35:48:50, 15.91s/it]

 50%|████▉     | 8001/16104 [37:08:51<42:56:43, 19.08s/it]

 50%|████▉     | 8002/16104 [37:09:05<39:26:22, 17.52s/it]


 50%|████▉     | 8004/16104 [37:09:34<35:58:36, 15.99s/it]

 50%|████▉     | 8005/16104 [37:09:50<36:00:10, 16.00s/it]
{'loss': 0.4035, 'learning_rate': 1.0580927731975726e-06, 'rewards/chosen': 0.2623893618583679, 'rewards/rejected': -1.8327314853668213, 'rewards/accuracies': 1.0, 'rewards/margins': 2.095120906829834, 'policy_logps/rejected': -446.5234069824219, 'policy_logps/chosen': -494.16290283203125, 'referece_logps/rejected': -428.1960754394531, 'referece_logps/chosen': -496.78680419921875, 'logits/rejected': -0.7496883273124695, 'logits/chosen': -0.7535550594329834, 'epoch': 2.98}

 50%|████▉     | 8006/16104 [37:10:06<35:41:55, 15.87s/it]


 50%|████▉     | 8008/16104 [37:10:36<35:16:43, 15.69s/it]

 50%|████▉     | 8009/16104 [37:10:55<37:15:29, 16.57s/it]
{'loss': 0.4571, 'learning_rate': 1.0572896079809077e-06, 'rewards/chosen': -0.24971087276935577, 'rewards/rejected': -0.7750334143638611, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5253224968910217, 'policy_logps/rejected': -370.5461730957031, 'policy_logps/chosen': -401.0848388671875, 'referece_logps/rejected': -362.79583740234375, 'referece_logps/chosen': -398.5876770019531, 'logits/rejected': -0.29834142327308655, 'logits/chosen': -0.19965137541294098, 'epoch': 2.98}

 50%|████▉     | 8010/16104 [37:11:08<34:38:14, 15.41s/it]


 50%|████▉     | 8012/16104 [37:11:46<39:08:13, 17.41s/it]

 50%|████▉     | 8013/16104 [37:12:00<36:35:25, 16.28s/it]
{'loss': 0.45, 'learning_rate': 1.0564864056847744e-06, 'rewards/chosen': -1.420391321182251, 'rewards/rejected': -2.708549976348877, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2881587743759155, 'policy_logps/rejected': -458.40606689453125, 'policy_logps/chosen': -531.2435302734375, 'referece_logps/rejected': -431.3205871582031, 'referece_logps/chosen': -517.0396118164062, 'logits/rejected': -0.5554868578910828, 'logits/chosen': -0.7120705842971802, 'epoch': 2.99}

 50%|████▉     | 8014/16104 [37:12:20<38:48:50, 17.27s/it]

 50%|████▉     | 8015/16104 [37:12:38<39:21:22, 17.52s/it]


 50%|████▉     | 8017/16104 [37:13:13<39:09:53, 17.43s/it]

 50%|████▉     | 8018/16104 [37:13:31<39:19:51, 17.51s/it]
{'loss': 0.4558, 'learning_rate': 1.0554823514635753e-06, 'rewards/chosen': -0.1503184288740158, 'rewards/rejected': -2.063316583633423, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9129983186721802, 'policy_logps/rejected': -349.5415954589844, 'policy_logps/chosen': -410.8730163574219, 'referece_logps/rejected': -328.908447265625, 'referece_logps/chosen': -409.36981201171875, 'logits/rejected': 0.03255558758974075, 'logits/chosen': 0.047735922038555145, 'epoch': 2.99}


 50%|████▉     | 8020/16104 [37:14:03<38:15:39, 17.04s/it]
{'loss': 0.4741, 'learning_rate': 1.055080714007712e-06, 'rewards/chosen': -0.10578443109989166, 'rewards/rejected': -1.9257521629333496, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8199676275253296, 'policy_logps/rejected': -444.6793518066406, 'policy_logps/chosen': -486.5960693359375, 'referece_logps/rejected': -425.42181396484375, 'referece_logps/chosen': -485.5382080078125, 'logits/rejected': -0.19791701436042786, 'logits/chosen': 0.04441903531551361, 'epoch': 2.99}

 50%|████▉     | 8021/16104 [37:14:17<36:35:10, 16.29s/it]

 50%|████▉     | 8022/16104 [37:14:32<35:18:38, 15.73s/it]


 50%|████▉     | 8024/16104 [37:15:09<38:30:24, 17.16s/it]
{'loss': 0.4638, 'learning_rate': 1.054277412423617e-06, 'rewards/chosen': 0.22201882302761078, 'rewards/rejected': -1.0895978212356567, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3116166591644287, 'policy_logps/rejected': -493.47332763671875, 'policy_logps/chosen': -455.1541442871094, 'referece_logps/rejected': -482.57733154296875, 'referece_logps/chosen': -457.3742980957031, 'logits/rejected': -0.06496712565422058, 'logits/chosen': 0.10097086429595947, 'epoch': 2.99}


 50%|████▉     | 8026/16104 [37:15:45<40:12:40, 17.92s/it]

 50%|████▉     | 8027/16104 [37:16:05<41:17:40, 18.41s/it]

 50%|████▉     | 8028/16104 [37:16:21<40:01:01, 17.84s/it]

 50%|████▉     | 8029/16104 [37:16:41<41:08:41, 18.34s/it]

 50%|████▉     | 8030/16104 [37:16:59<40:51:30, 18.22s/it]

 50%|████▉     | 8031/16104 [37:17:11<36:40:02, 16.35s/it]

 50%|████▉     | 8032/16104 [37:17:29<38:05:23, 16.99s/it]

 50%|████▉     | 8033/16104 [37:17:41<34:43:23, 15.49s/it]
{'loss': 0.4208, 'learning_rate': 1.0524698562078477e-06, 'rewards/chosen': 0.31331807374954224, 'rewards/rejected': -0.21540601551532745, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5287240743637085, 'policy_logps/rejected': -545.6598510742188, 'policy_logps/chosen': -389.58929443359375, 'referece_logps/rejected': -543.5057983398438, 'referece_logps/chosen': -392.72247314453125, 'logits/rejected': 0.0013643279671669006, 'logits/chosen': 0.08860143274068832, 'epoch': 2.99}


 50%|████▉     | 8035/16104 [37:18:09<32:41:40, 14.59s/it]

 50%|████▉     | 8036/16104 [37:18:29<36:02:02, 16.08s/it]

 50%|████▉     | 8037/16104 [37:18:41<33:16:48, 14.85s/it]

 50%|████▉     | 8038/16104 [37:19:01<36:42:48, 16.39s/it]

 50%|████▉     | 8039/16104 [37:19:17<36:33:29, 16.32s/it]
{'loss': 0.5377, 'learning_rate': 1.051264722852607e-06, 'rewards/chosen': -0.5325286984443665, 'rewards/rejected': -0.9287561774253845, 'rewards/accuracies': 0.75, 'rewards/margins': 0.39622747898101807, 'policy_logps/rejected': -321.80364990234375, 'policy_logps/chosen': -363.23724365234375, 'referece_logps/rejected': -312.51611328125, 'referece_logps/chosen': -357.9119873046875, 'logits/rejected': -0.28119727969169617, 'logits/chosen': -0.4601597189903259, 'epoch': 3.0}


 50%|████▉     | 8041/16104 [37:19:51<37:53:49, 16.92s/it]
{'loss': 0.4609, 'learning_rate': 1.0508629950575297e-06, 'rewards/chosen': -0.19534340500831604, 'rewards/rejected': -0.9849202632904053, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7895769476890564, 'policy_logps/rejected': -519.4389038085938, 'policy_logps/chosen': -456.688720703125, 'referece_logps/rejected': -509.5897521972656, 'referece_logps/chosen': -454.7353210449219, 'logits/rejected': 0.6933232545852661, 'logits/chosen': 0.7160606384277344, 'epoch': 3.0}


 50%|████▉     | 8043/16104 [37:20:25<38:35:26, 17.23s/it]

 50%|████▉     | 8044/16104 [37:20:42<37:50:05, 16.90s/it]

 50%|████▉     | 8045/16104 [37:20:55<35:45:51, 15.98s/it]
{'loss': 0.3678, 'learning_rate': 1.0500595148423923e-06, 'rewards/chosen': -1.1364268064498901, 'rewards/rejected': -2.6098134517669678, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4733867645263672, 'policy_logps/rejected': -328.8287353515625, 'policy_logps/chosen': -362.697509765625, 'referece_logps/rejected': -302.7306213378906, 'referece_logps/chosen': -351.33319091796875, 'logits/rejected': 0.34168335795402527, 'logits/chosen': 0.5204756259918213, 'epoch': 3.0}

 50%|████▉     | 8046/16104 [37:21:11<35:18:42, 15.78s/it]

 50%|████▉     | 8047/16104 [37:21:28<36:27:32, 16.29s/it]


 50%|████▉     | 8049/16104 [37:21:58<34:39:37, 15.49s/it]

 50%|████▉     | 8050/16104 [37:22:17<37:20:15, 16.69s/it]
{'loss': 0.4145, 'learning_rate': 1.0490551190719906e-06, 'rewards/chosen': -0.1960669755935669, 'rewards/rejected': -2.547948122024536, 'rewards/accuracies': 1.0, 'rewards/margins': 2.351881265640259, 'policy_logps/rejected': -520.599853515625, 'policy_logps/chosen': -378.677978515625, 'referece_logps/rejected': -495.120361328125, 'referece_logps/chosen': -376.7173156738281, 'logits/rejected': 0.09183337539434433, 'logits/chosen': 0.09965899586677551, 'epoch': 3.0}

 50%|████▉     | 8051/16104 [37:22:28<33:37:16, 15.03s/it]

 50%|█████     | 8052/16104 [37:22:40<31:40:53, 14.16s/it]


 50%|█████     | 8054/16104 [37:23:07<31:11:34, 13.95s/it]
{'loss': 0.4453, 'learning_rate': 1.0482515666883069e-06, 'rewards/chosen': -0.08307571709156036, 'rewards/rejected': -0.8142819404602051, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7312061190605164, 'policy_logps/rejected': -346.0706787109375, 'policy_logps/chosen': -463.7859191894531, 'referece_logps/rejected': -337.9278564453125, 'referece_logps/chosen': -462.9551086425781, 'logits/rejected': -0.8407328724861145, 'logits/chosen': -0.8737002611160278, 'epoch': 3.0}


 50%|█████     | 8056/16104 [37:23:37<33:23:15, 14.93s/it]
{'loss': 0.426, 'learning_rate': 1.0478497787527877e-06, 'rewards/chosen': -0.05277309939265251, 'rewards/rejected': -1.4147427082061768, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3619694709777832, 'policy_logps/rejected': -434.0244140625, 'policy_logps/chosen': -650.0767822265625, 'referece_logps/rejected': -419.8769836425781, 'referece_logps/chosen': -649.5490112304688, 'logits/rejected': -0.0876302421092987, 'logits/chosen': -0.1462104320526123, 'epoch': 3.0}

 50%|█████     | 8057/16104 [37:23:50<32:05:02, 14.35s/it]


 50%|█████     | 8059/16104 [37:24:16<29:38:55, 13.27s/it]

 50%|█████     | 8060/16104 [37:24:33<32:37:49, 14.60s/it]
{'loss': 0.511, 'learning_rate': 1.0470461797194562e-06, 'rewards/chosen': 0.007515892386436462, 'rewards/rejected': -0.7461055517196655, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7536214590072632, 'policy_logps/rejected': -426.41009521484375, 'policy_logps/chosen': -456.79833984375, 'referece_logps/rejected': -418.9490661621094, 'referece_logps/chosen': -456.87347412109375, 'logits/rejected': -0.11912607401609421, 'logits/chosen': -0.09365523606538773, 'epoch': 3.0}


 50%|█████     | 8062/16104 [37:25:02<32:53:21, 14.72s/it]

 50%|█████     | 8063/16104 [37:25:14<30:58:43, 13.87s/it]

 50%|█████     | 8064/16104 [37:25:30<32:19:11, 14.47s/it]

 50%|█████     | 8065/16104 [37:25:42<30:52:13, 13.82s/it]
{'loss': 0.527, 'learning_rate': 1.0460416381689535e-06, 'rewards/chosen': 0.1062021255493164, 'rewards/rejected': -0.6923597455024719, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7985618114471436, 'policy_logps/rejected': -469.1811828613281, 'policy_logps/chosen': -489.91522216796875, 'referece_logps/rejected': -462.257568359375, 'referece_logps/chosen': -490.9772644042969, 'logits/rejected': -0.18170562386512756, 'logits/chosen': -0.12575972080230713, 'epoch': 3.0}

 50%|█████     | 8066/16104 [37:25:54<29:47:41, 13.34s/it]

 50%|█████     | 8067/16104 [37:26:09<30:41:42, 13.75s/it]

 50%|█████     | 8068/16104 [37:26:29<34:37:03, 15.51s/it]

 50%|█████     | 8069/16104 [37:26:39<31:17:39, 14.02s/it]


 50%|█████     | 8071/16104 [37:27:08<30:57:22, 13.87s/it]
{'loss': 0.4364, 'learning_rate': 1.044836126936364e-06, 'rewards/chosen': -0.16546307504177094, 'rewards/rejected': -1.284860610961914, 'rewards/accuracies': 0.5, 'rewards/margins': 1.1193974018096924, 'policy_logps/rejected': -383.51947021484375, 'policy_logps/chosen': -475.33197021484375, 'referece_logps/rejected': -370.6708679199219, 'referece_logps/chosen': -473.67730712890625, 'logits/rejected': 0.9010288715362549, 'logits/chosen': 0.8246124982833862, 'epoch': 3.01}

 50%|█████     | 8072/16104 [37:27:27<34:43:05, 15.56s/it]

 50%|█████     | 8073/16104 [37:27:39<31:47:23, 14.25s/it]

 50%|█████     | 8074/16104 [37:27:58<35:32:52, 15.94s/it]


 50%|█████     | 8076/16104 [37:28:38<40:00:11, 17.94s/it]

 50%|█████     | 8077/16104 [37:29:00<42:27:23, 19.04s/it]

 50%|█████     | 8078/16104 [37:29:22<44:18:26, 19.87s/it]
{'loss': 0.4203, 'learning_rate': 1.0434296147648808e-06, 'rewards/chosen': 0.4832916557788849, 'rewards/rejected': -1.1132745742797852, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5965663194656372, 'policy_logps/rejected': -483.375732421875, 'policy_logps/chosen': -613.3500366210938, 'referece_logps/rejected': -472.24298095703125, 'referece_logps/chosen': -618.1829833984375, 'logits/rejected': -0.274541437625885, 'logits/chosen': 0.13086915016174316, 'epoch': 3.01}

 50%|█████     | 8079/16104 [37:29:43<45:01:45, 20.20s/it]

 50%|█████     | 8080/16104 [37:29:55<39:50:46, 17.88s/it]

 50%|█████     | 8081/16104 [37:30:14<40:56:18, 18.37s/it]

 50%|█████     | 8082/16104 [37:30:32<40:03:54, 17.98s/it]

 50%|█████     | 8083/16104 [37:30:54<42:48:06, 19.21s/it]

 50%|█████     | 8084/16104 [37:31:11<41:34:30, 18.66s/it]


 50%|█████     | 8086/16104 [37:31:48<41:39:26, 18.70s/it]
{'loss': 0.2791, 'learning_rate': 1.0418220670374457e-06, 'rewards/chosen': -0.09298460930585861, 'rewards/rejected': -1.5748130083084106, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4818283319473267, 'policy_logps/rejected': -361.2977294921875, 'policy_logps/chosen': -370.1442565917969, 'referece_logps/rejected': -345.5495910644531, 'referece_logps/chosen': -369.21435546875, 'logits/rejected': 0.4099242687225342, 'logits/chosen': 0.4198462963104248, 'epoch': 3.01}

 50%|█████     | 8087/16104 [37:32:07<41:29:07, 18.63s/it]


 50%|█████     | 8089/16104 [37:32:44<41:49:58, 18.79s/it]
{'loss': 0.4985, 'learning_rate': 1.0412192085017955e-06, 'rewards/chosen': -0.5618694424629211, 'rewards/rejected': -2.569262742996216, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0073935985565186, 'policy_logps/rejected': -216.23089599609375, 'policy_logps/chosen': -432.0751953125, 'referece_logps/rejected': -190.53826904296875, 'referece_logps/chosen': -426.45654296875, 'logits/rejected': -0.7703841328620911, 'logits/chosen': -1.0027172565460205, 'epoch': 3.01}

 50%|█████     | 8090/16104 [37:33:01<40:41:06, 18.28s/it]

 50%|█████     | 8091/16104 [37:33:21<41:52:25, 18.81s/it]


 50%|█████     | 8093/16104 [37:33:58<41:14:08, 18.53s/it]

 50%|█████     | 8094/16104 [37:34:15<39:41:39, 17.84s/it]
{'loss': 0.4765, 'learning_rate': 1.0402144110362897e-06, 'rewards/chosen': -0.7280797958374023, 'rewards/rejected': -1.6605473756790161, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9324675798416138, 'policy_logps/rejected': -348.9720458984375, 'policy_logps/chosen': -411.70050048828125, 'referece_logps/rejected': -332.3665771484375, 'referece_logps/chosen': -404.41973876953125, 'logits/rejected': 0.6791090369224548, 'logits/chosen': 0.6174890398979187, 'epoch': 3.02}

 50%|█████     | 8095/16104 [37:34:33<40:23:00, 18.15s/it]

 50%|█████     | 8096/16104 [37:34:50<39:03:01, 17.56s/it]


 50%|█████     | 8098/16104 [37:35:27<39:49:09, 17.91s/it]
{'loss': 0.433, 'learning_rate': 1.0394105437337071e-06, 'rewards/chosen': -0.2177739143371582, 'rewards/rejected': -0.7640073299407959, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5462334156036377, 'policy_logps/rejected': -383.7551574707031, 'policy_logps/chosen': -386.8395080566406, 'referece_logps/rejected': -376.11505126953125, 'referece_logps/chosen': -384.6617431640625, 'logits/rejected': 0.5338845252990723, 'logits/chosen': 0.5256201028823853, 'epoch': 3.02}

 50%|█████     | 8099/16104 [37:35:48<41:57:10, 18.87s/it]

 50%|█████     | 8100/16104 [37:36:06<41:26:36, 18.64s/it]

 50%|█████     | 8101/16104 [37:36:17<36:38:21, 16.48s/it]

 50%|█████     | 8102/16104 [37:36:32<35:16:51, 15.87s/it]


 50%|█████     | 8104/16104 [37:37:12<40:01:43, 18.01s/it]
{'loss': 0.474, 'learning_rate': 1.0382046951156243e-06, 'rewards/chosen': 0.26344412565231323, 'rewards/rejected': -0.4518713355064392, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7153154611587524, 'policy_logps/rejected': -392.089599609375, 'policy_logps/chosen': -546.7535400390625, 'referece_logps/rejected': -387.5708923339844, 'referece_logps/chosen': -549.387939453125, 'logits/rejected': -0.26982545852661133, 'logits/chosen': -0.42229002714157104, 'epoch': 3.02}

 50%|█████     | 8105/16104 [37:37:32<41:03:03, 18.48s/it]


 50%|█████     | 8107/16104 [37:38:02<36:30:14, 16.43s/it]

 50%|█████     | 8108/16104 [37:38:17<34:58:26, 15.75s/it]

 50%|█████     | 8109/16104 [37:38:30<33:45:25, 15.20s/it]
{'loss': 0.476, 'learning_rate': 1.0371997786928785e-06, 'rewards/chosen': -0.39693066477775574, 'rewards/rejected': -1.364872932434082, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9679422378540039, 'policy_logps/rejected': -492.2754211425781, 'policy_logps/chosen': -520.081787109375, 'referece_logps/rejected': -478.6267395019531, 'referece_logps/chosen': -516.1124267578125, 'logits/rejected': 0.15807461738586426, 'logits/chosen': -0.04485997557640076, 'epoch': 3.02}

 50%|█████     | 8110/16104 [37:38:41<30:50:47, 13.89s/it]

 50%|█████     | 8111/16104 [37:38:55<30:44:36, 13.85s/it]

 50%|█████     | 8112/16104 [37:39:12<32:53:40, 14.82s/it]

 50%|█████     | 8113/16104 [37:39:23<30:19:31, 13.66s/it]

 50%|█████     | 8114/16104 [37:39:40<32:23:48, 14.60s/it]

 50%|█████     | 8115/16104 [37:40:00<35:47:57, 16.13s/it]

 50%|█████     | 8116/16104 [37:40:12<32:59:34, 14.87s/it]

 50%|█████     | 8117/16104 [37:40:22<30:12:51, 13.62s/it]

 50%|█████     | 8118/16104 [37:40:33<28:17:45, 12.76s/it]


 50%|█████     | 8120/16104 [37:40:55<26:04:12, 11.76s/it]
{'loss': 0.4387, 'learning_rate': 1.034988831571635e-06, 'rewards/chosen': 0.055007174611091614, 'rewards/rejected': -0.8616978526115417, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9167049527168274, 'policy_logps/rejected': -509.46173095703125, 'policy_logps/chosen': -565.5804443359375, 'referece_logps/rejected': -500.8448181152344, 'referece_logps/chosen': -566.1304931640625, 'logits/rejected': -0.4901723861694336, 'logits/chosen': -0.4737696349620819, 'epoch': 3.03}

 50%|█████     | 8121/16104 [37:41:14<31:15:19, 14.09s/it]

 50%|█████     | 8122/16104 [37:41:36<36:26:59, 16.44s/it]


 50%|█████     | 8124/16104 [37:42:15<39:52:02, 17.99s/it]
{'loss': 0.3653, 'learning_rate': 1.0341848077703013e-06, 'rewards/chosen': -0.1397099494934082, 'rewards/rejected': -1.9785045385360718, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8387945890426636, 'policy_logps/rejected': -215.40309143066406, 'policy_logps/chosen': -402.58154296875, 'referece_logps/rejected': -195.6180419921875, 'referece_logps/chosen': -401.1844482421875, 'logits/rejected': -0.055769141763448715, 'logits/chosen': -0.2168205827474594, 'epoch': 3.03}

 50%|█████     | 8125/16104 [37:42:34<40:51:22, 18.43s/it]

 50%|█████     | 8126/16104 [37:42:51<39:55:05, 18.01s/it]

 50%|█████     | 8127/16104 [37:43:08<38:45:08, 17.49s/it]


 50%|█████     | 8129/16104 [37:43:45<39:01:37, 17.62s/it]
{'loss': 0.3604, 'learning_rate': 1.033179746965799e-06, 'rewards/chosen': -0.3570779860019684, 'rewards/rejected': -2.4306676387786865, 'rewards/accuracies': 0.75, 'rewards/margins': 2.073589563369751, 'policy_logps/rejected': -436.39251708984375, 'policy_logps/chosen': -461.3536376953125, 'referece_logps/rejected': -412.08587646484375, 'referece_logps/chosen': -457.78289794921875, 'logits/rejected': -0.2124176174402237, 'logits/chosen': -0.07444681227207184, 'epoch': 3.03}

 50%|█████     | 8130/16104 [37:44:00<37:35:53, 16.97s/it]

 50%|█████     | 8131/16104 [37:44:18<37:59:18, 17.15s/it]

 50%|█████     | 8132/16104 [37:44:38<40:10:11, 18.14s/it]


 51%|█████     | 8134/16104 [37:45:05<34:40:41, 15.66s/it]
{'loss': 0.3735, 'learning_rate': 1.0321746526068004e-06, 'rewards/chosen': -0.630536675453186, 'rewards/rejected': -2.6322314739227295, 'rewards/accuracies': 0.5, 'rewards/margins': 2.001695156097412, 'policy_logps/rejected': -512.5336303710938, 'policy_logps/chosen': -572.5889892578125, 'referece_logps/rejected': -486.2113037109375, 'referece_logps/chosen': -566.28369140625, 'logits/rejected': -0.8379872441291809, 'logits/chosen': -0.6684000492095947, 'epoch': 3.03}

 51%|█████     | 8135/16104 [37:45:26<38:30:06, 17.39s/it]


 51%|█████     | 8137/16104 [37:45:55<35:18:02, 15.95s/it]

 51%|█████     | 8138/16104 [37:46:15<37:51:00, 17.11s/it]
{'loss': 0.6371, 'learning_rate': 1.031370553643415e-06, 'rewards/chosen': -0.7311820983886719, 'rewards/rejected': -1.0264390707015991, 'rewards/accuracies': 0.5, 'rewards/margins': 0.29525700211524963, 'policy_logps/rejected': -383.50469970703125, 'policy_logps/chosen': -408.3187561035156, 'referece_logps/rejected': -373.24029541015625, 'referece_logps/chosen': -401.0069580078125, 'logits/rejected': -0.3367413878440857, 'logits/chosen': -0.22520047426223755, 'epoch': 3.03}

 51%|█████     | 8139/16104 [37:46:28<35:10:48, 15.90s/it]


 51%|█████     | 8141/16104 [37:46:59<34:36:50, 15.65s/it]
{'loss': 0.4362, 'learning_rate': 1.0307674660679681e-06, 'rewards/chosen': -1.0234317779541016, 'rewards/rejected': -2.3866360187530518, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3632044792175293, 'policy_logps/rejected': -528.5802001953125, 'policy_logps/chosen': -470.29345703125, 'referece_logps/rejected': -504.7138671875, 'referece_logps/chosen': -460.05914306640625, 'logits/rejected': -0.6682309508323669, 'logits/chosen': -0.6230208277702332, 'epoch': 3.03}


 51%|█████     | 8143/16104 [37:47:35<36:26:36, 16.48s/it]
{'loss': 0.4652, 'learning_rate': 1.0303654014477893e-06, 'rewards/chosen': -0.3281811773777008, 'rewards/rejected': -1.6806254386901855, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3524441719055176, 'policy_logps/rejected': -369.4700622558594, 'policy_logps/chosen': -413.23297119140625, 'referece_logps/rejected': -352.6637878417969, 'referece_logps/chosen': -409.9511413574219, 'logits/rejected': -0.5230703949928284, 'logits/chosen': -0.5559525489807129, 'epoch': 3.03}


 51%|█████     | 8145/16104 [37:48:07<36:33:00, 16.53s/it]
{'loss': 0.3553, 'learning_rate': 1.0299633319142719e-06, 'rewards/chosen': -0.6173362135887146, 'rewards/rejected': -2.6093170642852783, 'rewards/accuracies': 1.0, 'rewards/margins': 1.991980791091919, 'policy_logps/rejected': -367.1969909667969, 'policy_logps/chosen': -308.9908142089844, 'referece_logps/rejected': -341.10382080078125, 'referece_logps/chosen': -302.8174133300781, 'logits/rejected': -0.051505617797374725, 'logits/chosen': 0.13920685648918152, 'epoch': 3.03}


 51%|█████     | 8147/16104 [37:48:41<37:45:03, 17.08s/it]
{'loss': 0.4384, 'learning_rate': 1.029561257532473e-06, 'rewards/chosen': -0.6191580295562744, 'rewards/rejected': -2.4725747108459473, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8534168004989624, 'policy_logps/rejected': -470.6474609375, 'policy_logps/chosen': -403.6287536621094, 'referece_logps/rejected': -445.9217224121094, 'referece_logps/chosen': -397.4371643066406, 'logits/rejected': -0.2958846092224121, 'logits/chosen': -0.3172231912612915, 'epoch': 3.04}


 51%|█████     | 8149/16104 [37:49:13<35:35:31, 16.11s/it]
{'loss': 0.3929, 'learning_rate': 1.0291591783674524e-06, 'rewards/chosen': -0.7394434809684753, 'rewards/rejected': -1.6852142810821533, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9457707405090332, 'policy_logps/rejected': -368.349853515625, 'policy_logps/chosen': -495.45794677734375, 'referece_logps/rejected': -351.4977111816406, 'referece_logps/chosen': -488.06353759765625, 'logits/rejected': 0.5692052841186523, 'logits/chosen': 0.5503042936325073, 'epoch': 3.04}

 51%|█████     | 8150/16104 [37:49:28<34:33:16, 15.64s/it]

 51%|█████     | 8151/16104 [37:49:40<32:06:32, 14.53s/it]

 51%|█████     | 8152/16104 [37:49:51<30:02:18, 13.60s/it]

 51%|█████     | 8153/16104 [37:50:02<28:22:20, 12.85s/it]

 51%|█████     | 8154/16104 [37:50:21<32:14:26, 14.60s/it]

 51%|█████     | 8155/16104 [37:50:33<30:29:19, 13.81s/it]

 51%|█████     | 8156/16104 [37:50:44<29:00:46, 13.14s/it]

 51%|█████     | 8157/16104 [37:51:01<31:31:19, 14.28s/it]

 51%|█████     | 8158/16104 [37:51:21<35:02:57, 15.88s/it]

 51%|█████     | 8159/16104 [37:51:43<39:17:02, 17.80s/it]

 51%|█████     | 8160/16104 [37:52:03<40:27:25, 18.33s/it]

 51%|█████     | 8161/16104 [37:52:24<42:37:11, 19.32s/it]

 51%|█████     | 8162/16104 [37:52:45<43:46:36, 19.84s/it]

 51%|█████     | 8163/16104 [37:53:03<42:29:46, 19.27s/it]

 51%|█████     | 8164/16104 [37:53:21<41:33:00, 18.84s/it]

 51%|█████     | 8165/16104 [37:53:32<36:09:56, 16.40s/it]

 51%|█████     | 8166/16104 [37:53:52<38:20:32, 17.39s/it]

 51%|█████     | 8167/16104 [37:54:11<39:26:16, 17.89s/it]


 51%|█████     | 8169/16104 [37:54:46<39:09:54, 17.77s/it]
{'loss': 0.386, 'learning_rate': 1.0251381379534204e-06, 'rewards/chosen': -0.323880672454834, 'rewards/rejected': -2.5232956409454346, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1994147300720215, 'policy_logps/rejected': -421.231689453125, 'policy_logps/chosen': -276.9948425292969, 'referece_logps/rejected': -395.9987487792969, 'referece_logps/chosen': -273.7560119628906, 'logits/rejected': -0.3150140345096588, 'logits/chosen': -0.38573160767555237, 'epoch': 3.04}

 51%|█████     | 8170/16104 [37:55:04<39:42:01, 18.01s/it]

 51%|█████     | 8171/16104 [37:55:24<40:47:45, 18.51s/it]

 51%|█████     | 8172/16104 [37:55:44<41:43:43, 18.94s/it]

 51%|█████     | 8173/16104 [37:55:58<38:37:46, 17.53s/it]

 51%|█████     | 8174/16104 [37:56:17<39:15:42, 17.82s/it]

 51%|█████     | 8175/16104 [37:56:32<37:21:47, 16.96s/it]


 51%|█████     | 8177/16104 [37:57:14<42:13:21, 19.18s/it]
{'loss': 0.2868, 'learning_rate': 1.0235296042533438e-06, 'rewards/chosen': -0.5613964200019836, 'rewards/rejected': -1.5289380550384521, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9675416350364685, 'policy_logps/rejected': -382.0054016113281, 'policy_logps/chosen': -310.14764404296875, 'referece_logps/rejected': -366.7159729003906, 'referece_logps/chosen': -304.53369140625, 'logits/rejected': 0.2142661213874817, 'logits/chosen': 0.37712353467941284, 'epoch': 3.05}

 51%|█████     | 8178/16104 [37:57:30<40:12:55, 18.27s/it]

 51%|█████     | 8179/16104 [37:57:52<42:27:56, 19.29s/it]

 51%|█████     | 8180/16104 [37:58:12<42:49:32, 19.46s/it]

 51%|█████     | 8181/16104 [37:58:26<39:42:26, 18.04s/it]

 51%|█████     | 8182/16104 [37:58:43<38:44:37, 17.61s/it]

 51%|█████     | 8183/16104 [37:59:04<40:49:41, 18.56s/it]

 51%|█████     | 8184/16104 [37:59:19<38:54:03, 17.68s/it]

 51%|█████     | 8185/16104 [37:59:39<39:59:28, 18.18s/it]

 51%|█████     | 8186/16104 [37:59:54<37:50:20, 17.20s/it]

 51%|█████     | 8187/16104 [38:00:12<38:18:47, 17.42s/it]

 51%|█████     | 8188/16104 [38:00:28<37:48:40, 17.20s/it]

 51%|█████     | 8189/16104 [38:00:46<38:22:58, 17.46s/it]

 51%|█████     | 8190/16104 [38:01:01<36:25:13, 16.57s/it]

 51%|█████     | 8191/16104 [38:01:17<36:18:05, 16.52s/it]

 51%|█████     | 8192/16104 [38:01:30<33:50:48, 15.40s/it]

 51%|█████     | 8193/16104 [38:01:45<33:29:06, 15.24s/it]

 51%|█████     | 8194/16104 [38:01:58<32:21:01, 14.72s/it]

 51%|█████     | 8195/16104 [38:02:14<32:56:37, 15.00s/it]

 51%|█████     | 8196/16104 [38:02:27<31:29:11, 14.33s/it]

 51%|█████     | 8197/16104 [38:02:45<34:03:03, 15.50s/it]

 51%|█████     | 8198/16104 [38:03:05<36:49:39, 16.77s/it]

 51%|█████     | 8199/16104 [38:03:20<35:56:44, 16.37s/it]

 51%|█████     | 8200/16104 [38:03:33<33:24:57, 15.22s/it]

 51%|█████     | 8201/16104 [38:03:49<33:51:55, 15.43s/it]

 51%|█████     | 8202/16104 [38:04:08<36:33:26, 16.65s/it]

 51%|█████     | 8203/16104 [38:04:26<37:18:17, 17.00s/it]

 51%|█████     | 8204/16104 [38:04:42<36:29:50, 16.63s/it]

 51%|█████     | 8205/16104 [38:05:00<37:34:02, 17.12s/it]


 51%|█████     | 8207/16104 [38:05:34<38:14:35, 17.43s/it]
{'loss': 0.4466, 'learning_rate': 1.017497094343778e-06, 'rewards/chosen': -0.7743809223175049, 'rewards/rejected': -1.1426063776016235, 'rewards/accuracies': 0.625, 'rewards/margins': 0.36822545528411865, 'policy_logps/rejected': -392.48138427734375, 'policy_logps/chosen': -459.8112487792969, 'referece_logps/rejected': -381.0553283691406, 'referece_logps/chosen': -452.0674743652344, 'logits/rejected': 0.7397774457931519, 'logits/chosen': 0.872552752494812, 'epoch': 3.06}

 51%|█████     | 8208/16104 [38:05:50<37:10:39, 16.95s/it]

 51%|█████     | 8209/16104 [38:06:10<38:56:58, 17.76s/it]

 51%|█████     | 8210/16104 [38:06:30<40:28:21, 18.46s/it]

 51%|█████     | 8211/16104 [38:06:50<41:40:07, 19.01s/it]

 51%|█████     | 8212/16104 [38:07:07<40:23:34, 18.43s/it]

 51%|█████     | 8213/16104 [38:07:25<40:05:16, 18.29s/it]

 51%|█████     | 8214/16104 [38:07:45<41:07:01, 18.76s/it]

 51%|█████     | 8215/16104 [38:08:00<38:34:10, 17.60s/it]

 51%|█████     | 8216/16104 [38:08:11<34:05:20, 15.56s/it]

 51%|█████     | 8217/16104 [38:08:33<38:20:16, 17.50s/it]

 51%|█████     | 8218/16104 [38:08:52<39:40:33, 18.11s/it]

 51%|█████     | 8219/16104 [38:09:12<40:52:31, 18.66s/it]

 51%|█████     | 8220/16104 [38:09:25<36:49:53, 16.82s/it]

 51%|█████     | 8221/16104 [38:09:40<35:30:36, 16.22s/it]

 51%|█████     | 8222/16104 [38:09:52<32:36:11, 14.89s/it]

 51%|█████     | 8223/16104 [38:10:10<35:14:27, 16.10s/it]

 51%|█████     | 8224/16104 [38:10:23<33:10:17, 15.15s/it]

 51%|█████     | 8225/16104 [38:10:35<30:58:50, 14.16s/it]


 51%|█████     | 8227/16104 [38:11:03<31:11:29, 14.26s/it]

 51%|█████     | 8228/16104 [38:11:19<32:27:55, 14.84s/it]

 51%|█████     | 8229/16104 [38:11:38<34:42:38, 15.87s/it]

 51%|█████     | 8230/16104 [38:11:57<37:02:28, 16.94s/it]

 51%|█████     | 8231/16104 [38:12:08<32:51:26, 15.02s/it]

 51%|█████     | 8232/16104 [38:12:22<32:20:30, 14.79s/it]

 51%|█████     | 8233/16104 [38:12:35<31:17:16, 14.31s/it]

 51%|█████     | 8234/16104 [38:12:55<34:45:39, 15.90s/it]

 51%|█████     | 8235/16104 [38:13:10<34:15:55, 15.68s/it]

 51%|█████     | 8236/16104 [38:13:25<34:01:34, 15.57s/it]

 51%|█████     | 8237/16104 [38:13:45<36:51:58, 16.87s/it]

 51%|█████     | 8238/16104 [38:14:05<38:36:04, 17.67s/it]

 51%|█████     | 8239/16104 [38:14:24<40:04:34, 18.34s/it]

 51%|█████     | 8240/16104 [38:14:41<38:37:54, 17.68s/it]

 51%|█████     | 8241/16104 [38:14:52<34:43:20, 15.90s/it]

 51%|█████     | 8242/16104 [38:15:03<31:17:43, 14.33s/it]

 51%|█████     | 8243/16104 [38:15:17<31:01:18, 14.21s/it]

 51%|█████     | 8244/16104 [38:15:28<28:45:57, 13.18s/it]

 51%|█████     | 8245/16104 [38:15:41<28:45:29, 13.17s/it]

 51%|█████     | 8246/16104 [38:15:54<28:34:35, 13.09s/it]

 51%|█████     | 8247/16104 [38:16:12<31:52:22, 14.60s/it]

 51%|█████     | 8248/16104 [38:16:33<36:04:05, 16.53s/it]

 51%|█████     | 8249/16104 [38:16:53<38:04:12, 17.45s/it]

 51%|█████     | 8250/16104 [38:17:07<36:06:48, 16.55s/it]

 51%|█████     | 8251/16104 [38:17:18<32:21:49, 14.84s/it]

 51%|█████     | 8252/16104 [38:17:31<31:11:08, 14.30s/it]

 51%|█████     | 8253/16104 [38:17:42<28:53:02, 13.24s/it]

 51%|█████▏    | 8254/16104 [38:17:56<29:27:14, 13.51s/it]

 51%|█████▏    | 8255/16104 [38:18:11<30:25:32, 13.95s/it]

 51%|█████▏    | 8256/16104 [38:18:28<32:23:21, 14.86s/it]

 51%|█████▏    | 8257/16104 [38:18:39<30:16:26, 13.89s/it]

 51%|█████▏    | 8258/16104 [38:18:55<31:13:18, 14.33s/it]

 51%|█████▏    | 8259/16104 [38:19:11<32:47:30, 15.05s/it]

 51%|█████▏    | 8260/16104 [38:19:31<35:45:18, 16.41s/it]

 51%|█████▏    | 8261/16104 [38:19:48<36:25:27, 16.72s/it]

 51%|█████▏    | 8262/16104 [38:20:05<36:03:40, 16.55s/it]

 51%|█████▏    | 8263/16104 [38:20:16<32:54:21, 15.11s/it]

 51%|█████▏    | 8264/16104 [38:20:29<31:15:25, 14.35s/it]

 51%|█████▏    | 8265/16104 [38:20:44<31:53:36, 14.65s/it]

 51%|█████▏    | 8266/16104 [38:20:56<29:57:42, 13.76s/it]

 51%|█████▏    | 8267/16104 [38:21:11<30:45:52, 14.13s/it]

 51%|█████▏    | 8268/16104 [38:21:31<34:48:28, 15.99s/it]

 51%|█████▏    | 8269/16104 [38:21:49<36:13:23, 16.64s/it]

 51%|█████▏    | 8270/16104 [38:22:06<36:15:05, 16.66s/it]

 51%|█████▏    | 8271/16104 [38:22:26<38:31:00, 17.70s/it]

 51%|█████▏    | 8272/16104 [38:22:37<33:55:06, 15.59s/it]

 51%|█████▏    | 8273/16104 [38:22:53<34:07:27, 15.69s/it]

 51%|█████▏    | 8274/16104 [38:23:05<31:30:53, 14.49s/it]

 51%|█████▏    | 8275/16104 [38:23:26<36:10:09, 16.63s/it]

 51%|█████▏    | 8276/16104 [38:23:39<33:58:09, 15.62s/it]

 51%|█████▏    | 8277/16104 [38:23:55<34:09:34, 15.71s/it]

 51%|█████▏    | 8278/16104 [38:24:12<34:25:54, 15.84s/it]

 51%|█████▏    | 8279/16104 [38:24:29<35:31:09, 16.34s/it]

 51%|█████▏    | 8280/16104 [38:24:46<36:02:54, 16.59s/it]
{'loss': 0.4143, 'learning_rate': 1.0028157643425719e-06, 'rewards/chosen': -0.5990445613861084, 'rewards/rejected': -1.7508468627929688, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1518023014068604, 'policy_logps/rejected': -359.074462890625, 'policy_logps/chosen': -521.48828125, 'referece_logps/rejected': -341.56597900390625, 'referece_logps/chosen': -515.4978637695312, 'logits/rejected': -0.33445218205451965, 'logits/chosen': -0.45434802770614624, 'epoch': 3.08}


 51%|█████▏    | 8282/16104 [38:25:22<37:14:27, 17.14s/it]

 51%|█████▏    | 8283/16104 [38:25:38<36:33:11, 16.83s/it]

 51%|█████▏    | 8284/16104 [38:25:51<34:31:48, 15.90s/it]

 51%|█████▏    | 8285/16104 [38:26:11<36:55:37, 17.00s/it]

 51%|█████▏    | 8286/16104 [38:26:30<38:31:02, 17.74s/it]

 51%|█████▏    | 8287/16104 [38:26:51<40:20:42, 18.58s/it]
{'loss': 0.4029, 'learning_rate': 1.0014078835665953e-06, 'rewards/chosen': -0.5239497423171997, 'rewards/rejected': -1.340157151222229, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8162074089050293, 'policy_logps/rejected': -451.0068664550781, 'policy_logps/chosen': -453.3396911621094, 'referece_logps/rejected': -437.6052551269531, 'referece_logps/chosen': -448.10015869140625, 'logits/rejected': 0.10982441157102585, 'logits/chosen': 0.02876201458275318, 'epoch': 3.09}


 51%|█████▏    | 8289/16104 [38:27:32<42:08:46, 19.41s/it]

 51%|█████▏    | 8290/16104 [38:27:54<43:43:31, 20.14s/it]

 51%|█████▏    | 8291/16104 [38:28:12<42:25:06, 19.55s/it]
{'loss': 0.4006, 'learning_rate': 1.000603378834116e-06, 'rewards/chosen': -0.4494190216064453, 'rewards/rejected': -2.1813693046569824, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7319501638412476, 'policy_logps/rejected': -288.4354553222656, 'policy_logps/chosen': -401.7181396484375, 'referece_logps/rejected': -266.62176513671875, 'referece_logps/chosen': -397.22393798828125, 'logits/rejected': -0.03818915784358978, 'logits/chosen': -0.032532840967178345, 'epoch': 3.09}

 51%|█████▏    | 8292/16104 [38:28:34<44:13:22, 20.38s/it]


 52%|█████▏    | 8294/16104 [38:29:05<39:36:56, 18.26s/it]

 52%|█████▏    | 8295/16104 [38:29:25<40:28:04, 18.66s/it]

 52%|█████▏    | 8296/16104 [38:29:40<38:06:59, 17.57s/it]
{'loss': 0.4611, 'learning_rate': 9.995977474303627e-07, 'rewards/chosen': -1.4148744344711304, 'rewards/rejected': -2.8622617721557617, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4473875761032104, 'policy_logps/rejected': -544.079345703125, 'policy_logps/chosen': -458.054931640625, 'referece_logps/rejected': -515.4567260742188, 'referece_logps/chosen': -443.90618896484375, 'logits/rejected': 0.19216367602348328, 'logits/chosen': 0.3375462293624878, 'epoch': 3.09}

 52%|█████▏    | 8297/16104 [38:29:50<33:35:23, 15.49s/it]


 52%|█████▏    | 8299/16104 [38:30:22<32:53:40, 15.17s/it]

 52%|█████▏    | 8300/16104 [38:30:34<30:50:29, 14.23s/it]

 52%|█████▏    | 8301/16104 [38:30:45<29:07:35, 13.44s/it]

 52%|█████▏    | 8302/16104 [38:30:56<27:19:51, 12.61s/it]

 52%|█████▏    | 8303/16104 [38:31:10<28:02:52, 12.94s/it]

 52%|█████▏    | 8304/16104 [38:31:23<28:07:39, 12.98s/it]
{'loss': 0.3387, 'learning_rate': 9.9798873845356e-07, 'rewards/chosen': -1.1009857654571533, 'rewards/rejected': -3.0383551120758057, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9373691082000732, 'policy_logps/rejected': -364.0376892089844, 'policy_logps/chosen': -451.0675048828125, 'referece_logps/rejected': -333.65411376953125, 'referece_logps/chosen': -440.0576477050781, 'logits/rejected': -1.0927700996398926, 'logits/chosen': -0.9956550002098083, 'epoch': 3.09}


 52%|█████▏    | 8306/16104 [38:32:00<34:02:46, 15.72s/it]
{'loss': 0.3957, 'learning_rate': 9.97586486860232e-07, 'rewards/chosen': -0.8829151391983032, 'rewards/rejected': -1.8190717697143555, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9361568689346313, 'policy_logps/rejected': -608.978759765625, 'policy_logps/chosen': -483.965576171875, 'referece_logps/rejected': -590.7879028320312, 'referece_logps/chosen': -475.13641357421875, 'logits/rejected': -0.05353887379169464, 'logits/chosen': 0.09023497998714447, 'epoch': 3.09}

 52%|█████▏    | 8307/16104 [38:32:15<33:23:47, 15.42s/it]


 52%|█████▏    | 8309/16104 [38:32:50<36:20:44, 16.79s/it]

 52%|█████▏    | 8310/16104 [38:33:09<37:54:51, 17.51s/it]

 52%|█████▏    | 8311/16104 [38:33:20<33:30:53, 15.48s/it]

 52%|█████▏    | 8312/16104 [38:33:41<37:06:50, 17.15s/it]
{'loss': 0.3751, 'learning_rate': 9.963797346837395e-07, 'rewards/chosen': -1.0740537643432617, 'rewards/rejected': -3.8962759971618652, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8222222328186035, 'policy_logps/rejected': -569.2387084960938, 'policy_logps/chosen': -641.491455078125, 'referece_logps/rejected': -530.2760009765625, 'referece_logps/chosen': -630.7509155273438, 'logits/rejected': 0.9866057634353638, 'logits/chosen': 0.8552259206771851, 'epoch': 3.1}

 52%|█████▏    | 8313/16104 [38:34:01<38:40:33, 17.87s/it]

 52%|█████▏    | 8314/16104 [38:34:19<38:49:54, 17.95s/it]


 52%|█████▏    | 8316/16104 [38:34:48<34:15:48, 15.84s/it]

 52%|█████▏    | 8317/16104 [38:35:06<35:33:24, 16.44s/it]

 52%|█████▏    | 8318/16104 [38:35:24<36:52:21, 17.05s/it]

 52%|█████▏    | 8319/16104 [38:35:35<32:54:10, 15.22s/it]

 52%|█████▏    | 8320/16104 [38:35:52<33:58:07, 15.71s/it]
{'loss': 0.4528, 'learning_rate': 9.94770740286473e-07, 'rewards/chosen': -0.8977243900299072, 'rewards/rejected': -1.2885936498641968, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3908693790435791, 'policy_logps/rejected': -399.77435302734375, 'policy_logps/chosen': -346.900390625, 'referece_logps/rejected': -386.888427734375, 'referece_logps/chosen': -337.9231262207031, 'logits/rejected': -0.5408370494842529, 'logits/chosen': -0.5408231616020203, 'epoch': 3.1}


 52%|█████▏    | 8322/16104 [38:36:28<36:53:03, 17.06s/it]

 52%|█████▏    | 8323/16104 [38:36:44<36:23:59, 16.84s/it]

 52%|█████▏    | 8324/16104 [38:37:00<35:27:13, 16.41s/it]

 52%|█████▏    | 8325/16104 [38:37:18<36:39:28, 16.96s/it]

 52%|█████▏    | 8326/16104 [38:37:32<34:52:27, 16.14s/it]
{'loss': 0.5011, 'learning_rate': 9.93564003145101e-07, 'rewards/chosen': -0.25438806414604187, 'rewards/rejected': -1.2749147415161133, 'rewards/accuracies': 0.75, 'rewards/margins': 1.020526647567749, 'policy_logps/rejected': -464.1098937988281, 'policy_logps/chosen': -475.33685302734375, 'referece_logps/rejected': -451.3607482910156, 'referece_logps/chosen': -472.79296875, 'logits/rejected': 0.00664161890745163, 'logits/chosen': 0.22912533581256866, 'epoch': 3.1}


 52%|█████▏    | 8328/16104 [38:38:00<32:08:37, 14.88s/it]

 52%|█████▏    | 8329/16104 [38:38:19<34:36:11, 16.02s/it]
{'loss': 0.4205, 'learning_rate': 9.929606379792737e-07, 'rewards/chosen': -1.3018507957458496, 'rewards/rejected': -2.3725392818450928, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0706884860992432, 'policy_logps/rejected': -499.7393493652344, 'policy_logps/chosen': -626.83984375, 'referece_logps/rejected': -476.0139465332031, 'referece_logps/chosen': -613.8212890625, 'logits/rejected': -0.030720770359039307, 'logits/chosen': -0.11008712649345398, 'epoch': 3.1}


 52%|█████▏    | 8331/16104 [38:38:58<38:34:30, 17.87s/it]

 52%|█████▏    | 8332/16104 [38:39:11<35:43:19, 16.55s/it]
{'loss': 0.389, 'learning_rate': 9.923572753762395e-07, 'rewards/chosen': -0.5147179365158081, 'rewards/rejected': -1.2653203010559082, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7506024241447449, 'policy_logps/rejected': -269.9432678222656, 'policy_logps/chosen': -406.595458984375, 'referece_logps/rejected': -257.2900390625, 'referece_logps/chosen': -401.4482727050781, 'logits/rejected': -0.4127967953681946, 'logits/chosen': -0.5070973634719849, 'epoch': 3.1}


 52%|█████▏    | 8334/16104 [38:39:38<31:35:49, 14.64s/it]

 52%|█████▏    | 8335/16104 [38:39:49<29:04:17, 13.47s/it]
{'loss': 0.4647, 'learning_rate': 9.917539155556616e-07, 'rewards/chosen': -0.8467680811882019, 'rewards/rejected': -0.6863827109336853, 'rewards/accuracies': 0.25, 'rewards/margins': -0.16038532555103302, 'policy_logps/rejected': -377.0151672363281, 'policy_logps/chosen': -351.92327880859375, 'referece_logps/rejected': -370.1513671875, 'referece_logps/chosen': -343.4555969238281, 'logits/rejected': -0.35208603739738464, 'logits/chosen': -0.3792138993740082, 'epoch': 3.11}

 52%|█████▏    | 8336/16104 [38:40:07<32:19:58, 14.98s/it]

 52%|█████▏    | 8337/16104 [38:40:27<35:34:09, 16.49s/it]


 52%|█████▏    | 8339/16104 [38:40:57<33:51:43, 15.70s/it]

 52%|█████▏    | 8340/16104 [38:41:16<36:32:03, 16.94s/it]

 52%|█████▏    | 8341/16104 [38:41:36<38:04:03, 17.65s/it]

 52%|█████▏    | 8342/16104 [38:41:52<37:24:55, 17.35s/it]
{'loss': 0.3601, 'learning_rate': 9.903460880288842e-07, 'rewards/chosen': -0.2971208393573761, 'rewards/rejected': -2.0777816772460938, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7806609869003296, 'policy_logps/rejected': -615.1494750976562, 'policy_logps/chosen': -294.5050964355469, 'referece_logps/rejected': -594.3717041015625, 'referece_logps/chosen': -291.53387451171875, 'logits/rejected': 0.19587919116020203, 'logits/chosen': 0.2561536431312561, 'epoch': 3.11}

 52%|█████▏    | 8343/16104 [38:42:13<39:39:12, 18.39s/it]

 52%|█████▏    | 8344/16104 [38:42:33<40:43:01, 18.89s/it]

 52%|█████▏    | 8345/16104 [38:42:45<36:12:26, 16.80s/it]


 52%|█████▏    | 8347/16104 [38:43:12<32:33:39, 15.11s/it]
{'loss': 0.5224, 'learning_rate': 9.893405084911558e-07, 'rewards/chosen': -0.5569726228713989, 'rewards/rejected': -0.8527345657348633, 'rewards/accuracies': 0.375, 'rewards/margins': 0.29576200246810913, 'policy_logps/rejected': -412.10791015625, 'policy_logps/chosen': -340.216796875, 'referece_logps/rejected': -403.5805358886719, 'referece_logps/chosen': -334.6470031738281, 'logits/rejected': 0.24277794361114502, 'logits/chosen': 0.25962644815444946, 'epoch': 3.11}


 52%|█████▏    | 8349/16104 [38:43:43<33:53:38, 15.73s/it]

 52%|█████▏    | 8350/16104 [38:44:04<37:11:22, 17.27s/it]
{'loss': 0.4532, 'learning_rate': 9.8873716587778e-07, 'rewards/chosen': -0.20859678089618683, 'rewards/rejected': -1.4511305093765259, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2425336837768555, 'policy_logps/rejected': -329.68048095703125, 'policy_logps/chosen': -301.7280578613281, 'referece_logps/rejected': -315.169189453125, 'referece_logps/chosen': -299.64208984375, 'logits/rejected': -0.3921591639518738, 'logits/chosen': -0.35719650983810425, 'epoch': 3.11}


 52%|█████▏    | 8352/16104 [38:44:44<40:07:58, 18.64s/it]

 52%|█████▏    | 8353/16104 [38:44:59<38:02:40, 17.67s/it]

 52%|█████▏    | 8354/16104 [38:45:21<40:48:01, 18.95s/it]

 52%|█████▏    | 8355/16104 [38:45:32<35:40:53, 16.58s/it]
{'loss': 0.4549, 'learning_rate': 9.877316040759939e-07, 'rewards/chosen': -0.5301828384399414, 'rewards/rejected': -1.7833144664764404, 'rewards/accuracies': 0.75, 'rewards/margins': 1.253131628036499, 'policy_logps/rejected': -421.7428283691406, 'policy_logps/chosen': -514.8974609375, 'referece_logps/rejected': -403.9096984863281, 'referece_logps/chosen': -509.5956115722656, 'logits/rejected': -0.5236483216285706, 'logits/chosen': -0.44016140699386597, 'epoch': 3.11}

 52%|█████▏    | 8356/16104 [38:45:51<37:28:38, 17.41s/it]


 52%|█████▏    | 8358/16104 [38:46:20<33:30:41, 15.57s/it]

 52%|█████▏    | 8359/16104 [38:46:31<30:24:04, 14.13s/it]

 52%|█████▏    | 8360/16104 [38:46:46<31:09:30, 14.48s/it]

 52%|█████▏    | 8361/16104 [38:47:05<33:46:25, 15.70s/it]

 52%|█████▏    | 8362/16104 [38:47:25<36:24:46, 16.93s/it]

 52%|█████▏    | 8363/16104 [38:47:45<38:21:23, 17.84s/it]

 52%|█████▏    | 8364/16104 [38:47:58<35:30:16, 16.51s/it]
{'loss': 0.4593, 'learning_rate': 9.859216247816833e-07, 'rewards/chosen': -0.32047560811042786, 'rewards/rejected': -2.3125481605529785, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9920728206634521, 'policy_logps/rejected': -392.0000915527344, 'policy_logps/chosen': -451.1420593261719, 'referece_logps/rejected': -368.87457275390625, 'referece_logps/chosen': -447.9372863769531, 'logits/rejected': -0.4891078770160675, 'logits/chosen': -0.4924781024456024, 'epoch': 3.12}


 52%|█████▏    | 8366/16104 [38:48:31<36:09:57, 16.83s/it]

 52%|█████▏    | 8367/16104 [38:48:46<35:00:42, 16.29s/it]

 52%|█████▏    | 8368/16104 [38:48:58<32:23:56, 15.08s/it]
{'loss': 0.4127, 'learning_rate': 9.851172039941238e-07, 'rewards/chosen': -0.5623870491981506, 'rewards/rejected': -2.0051817893981934, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4427947998046875, 'policy_logps/rejected': -445.54815673828125, 'policy_logps/chosen': -378.51171875, 'referece_logps/rejected': -425.4963073730469, 'referece_logps/chosen': -372.8878173828125, 'logits/rejected': -0.3141214847564697, 'logits/chosen': -0.3499124050140381, 'epoch': 3.12}


 52%|█████▏    | 8370/16104 [38:49:28<31:24:43, 14.62s/it]
{'loss': 0.4988, 'learning_rate': 9.84714997180018e-07, 'rewards/chosen': -0.7724689841270447, 'rewards/rejected': -1.0538244247436523, 'rewards/accuracies': 0.625, 'rewards/margins': 0.28135550022125244, 'policy_logps/rejected': -338.27545166015625, 'policy_logps/chosen': -370.4499816894531, 'referece_logps/rejected': -327.7372131347656, 'referece_logps/chosen': -362.7253112792969, 'logits/rejected': 0.36642950773239136, 'logits/chosen': 0.2226961851119995, 'epoch': 3.12}


 52%|█████▏    | 8372/16104 [38:50:02<33:55:58, 15.80s/it]

 52%|█████▏    | 8373/16104 [38:50:19<34:39:45, 16.14s/it]

 52%|█████▏    | 8374/16104 [38:50:37<35:49:04, 16.68s/it]

 52%|█████▏    | 8375/16104 [38:50:57<37:42:52, 17.57s/it]
{'loss': 0.3424, 'learning_rate': 9.837094911074622e-07, 'rewards/chosen': -0.39930933713912964, 'rewards/rejected': -1.274889349937439, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8755799531936646, 'policy_logps/rejected': -241.83692932128906, 'policy_logps/chosen': -339.6719970703125, 'referece_logps/rejected': -229.08802795410156, 'referece_logps/chosen': -335.6789245605469, 'logits/rejected': -0.8176298141479492, 'logits/chosen': -0.915444016456604, 'epoch': 3.12}

 52%|█████▏    | 8376/16104 [38:51:16<38:58:27, 18.16s/it]


 52%|█████▏    | 8378/16104 [38:51:49<36:39:29, 17.08s/it]

 52%|█████▏    | 8379/16104 [38:52:09<38:24:07, 17.90s/it]
{'loss': 0.5274, 'learning_rate': 9.82905098062251e-07, 'rewards/chosen': -0.5986284613609314, 'rewards/rejected': -1.4480963945388794, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8494680523872375, 'policy_logps/rejected': -400.15673828125, 'policy_logps/chosen': -400.7126770019531, 'referece_logps/rejected': -385.67578125, 'referece_logps/chosen': -394.7263488769531, 'logits/rejected': -0.2665061056613922, 'logits/chosen': -0.27742132544517517, 'epoch': 3.12}


 52%|█████▏    | 8381/16104 [38:52:43<37:31:11, 17.49s/it]

 52%|█████▏    | 8382/16104 [38:53:05<40:11:06, 18.73s/it]
{'loss': 0.5123, 'learning_rate': 9.823018105108232e-07, 'rewards/chosen': -0.4156469404697418, 'rewards/rejected': -1.5096795558929443, 'rewards/accuracies': 0.75, 'rewards/margins': 1.094032645225525, 'policy_logps/rejected': -352.35418701171875, 'policy_logps/chosen': -446.96942138671875, 'referece_logps/rejected': -337.2573547363281, 'referece_logps/chosen': -442.81298828125, 'logits/rejected': 0.3554788827896118, 'logits/chosen': 0.4252244234085083, 'epoch': 3.12}


 52%|█████▏    | 8384/16104 [38:53:41<39:07:52, 18.25s/it]
{'loss': 0.5119, 'learning_rate': 9.818996223759304e-07, 'rewards/chosen': -0.7295001745223999, 'rewards/rejected': -1.1302592754364014, 'rewards/accuracies': 0.875, 'rewards/margins': 0.40075913071632385, 'policy_logps/rejected': -290.91473388671875, 'policy_logps/chosen': -272.10186767578125, 'referece_logps/rejected': -279.6121826171875, 'referece_logps/chosen': -264.8068542480469, 'logits/rejected': -0.13613232970237732, 'logits/chosen': -0.0912356898188591, 'epoch': 3.12}

 52%|█████▏    | 8385/16104 [38:53:56<37:14:35, 17.37s/it]

 52%|█████▏    | 8386/16104 [38:54:14<37:49:36, 17.64s/it]

 52%|█████▏    | 8387/16104 [38:54:33<38:09:18, 17.80s/it]

 52%|█████▏    | 8388/16104 [38:54:53<39:32:00, 18.44s/it]

 52%|█████▏    | 8389/16104 [38:55:12<40:26:45, 18.87s/it]


 52%|█████▏    | 8391/16104 [38:55:47<38:09:13, 17.81s/it]

 52%|█████▏    | 8392/16104 [38:56:07<39:10:55, 18.29s/it]
{'loss': 0.4055, 'learning_rate': 9.802908997748235e-07, 'rewards/chosen': 0.1208517998456955, 'rewards/rejected': -1.523769736289978, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6446216106414795, 'policy_logps/rejected': -513.4270629882812, 'policy_logps/chosen': -428.24212646484375, 'referece_logps/rejected': -498.1893310546875, 'referece_logps/chosen': -429.45062255859375, 'logits/rejected': 0.463775634765625, 'logits/chosen': 0.5734293460845947, 'epoch': 3.13}


 52%|█████▏    | 8394/16104 [38:56:39<36:42:10, 17.14s/it]
{'loss': 0.4315, 'learning_rate': 9.798887269345409e-07, 'rewards/chosen': -1.0310726165771484, 'rewards/rejected': -1.4839667081832886, 'rewards/accuracies': 0.75, 'rewards/margins': 0.45289403200149536, 'policy_logps/rejected': -565.3977661132812, 'policy_logps/chosen': -614.2841186523438, 'referece_logps/rejected': -550.55810546875, 'referece_logps/chosen': -603.973388671875, 'logits/rejected': -0.11220763623714447, 'logits/chosen': -0.1831359714269638, 'epoch': 3.13}

 52%|█████▏    | 8395/16104 [38:56:59<38:11:56, 17.84s/it]

 52%|█████▏    | 8396/16104 [38:57:12<35:35:59, 16.63s/it]

 52%|█████▏    | 8397/16104 [38:57:24<32:26:04, 15.15s/it]


 52%|█████▏    | 8399/16104 [38:58:04<37:28:04, 17.51s/it]

 52%|█████▏    | 8400/16104 [38:58:15<33:40:06, 15.73s/it]
{'loss': 0.4878, 'learning_rate': 9.786822281988746e-07, 'rewards/chosen': -0.020194437354803085, 'rewards/rejected': -1.2962744235992432, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2760801315307617, 'policy_logps/rejected': -362.8922424316406, 'policy_logps/chosen': -431.5093078613281, 'referece_logps/rejected': -349.92950439453125, 'referece_logps/chosen': -431.3073425292969, 'logits/rejected': 0.02927069365978241, 'logits/chosen': 0.24367594718933105, 'epoch': 3.13}

 52%|█████▏    | 8401/16104 [38:58:26<30:27:36, 14.24s/it]

 52%|█████▏    | 8402/16104 [38:58:45<33:11:19, 15.51s/it]


 52%|█████▏    | 8404/16104 [38:59:18<35:19:37, 16.52s/it]
{'loss': 0.3925, 'learning_rate': 9.778779128468133e-07, 'rewards/chosen': -0.6395977139472961, 'rewards/rejected': -1.9496819972991943, 'rewards/accuracies': 0.75, 'rewards/margins': 1.310084342956543, 'policy_logps/rejected': -438.826416015625, 'policy_logps/chosen': -384.3116455078125, 'referece_logps/rejected': -419.32958984375, 'referece_logps/chosen': -377.9156494140625, 'logits/rejected': -0.15052460134029388, 'logits/chosen': -0.05812294781208038, 'epoch': 3.13}

 52%|█████▏    | 8405/16104 [38:59:29<31:47:09, 14.86s/it]

 52%|█████▏    | 8406/16104 [38:59:48<34:49:20, 16.28s/it]


 52%|█████▏    | 8408/16104 [39:00:19<33:14:42, 15.55s/it]
{'loss': 0.4545, 'learning_rate': 9.77073611812797e-07, 'rewards/chosen': -0.8677371144294739, 'rewards/rejected': -1.5981775522232056, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7304403185844421, 'policy_logps/rejected': -300.8788757324219, 'policy_logps/chosen': -318.10211181640625, 'referece_logps/rejected': -284.8970947265625, 'referece_logps/chosen': -309.42474365234375, 'logits/rejected': -0.8314563035964966, 'logits/chosen': -0.7914180159568787, 'epoch': 3.13}

 52%|█████▏    | 8409/16104 [39:00:38<35:15:39, 16.50s/it]

 52%|█████▏    | 8410/16104 [39:00:57<36:43:22, 17.18s/it]

 52%|█████▏    | 8411/16104 [39:01:17<38:32:09, 18.03s/it]

 52%|█████▏    | 8412/16104 [39:01:33<37:07:51, 17.38s/it]

 52%|█████▏    | 8413/16104 [39:01:49<36:17:08, 16.98s/it]


 52%|█████▏    | 8415/16104 [39:02:28<38:19:52, 17.95s/it]

 52%|█████▏    | 8416/16104 [39:02:47<39:31:22, 18.51s/it]
{'loss': 0.4137, 'learning_rate': 9.754650547811587e-07, 'rewards/chosen': -0.6947429180145264, 'rewards/rejected': -1.4964550733566284, 'rewards/accuracies': 0.75, 'rewards/margins': 0.801712155342102, 'policy_logps/rejected': -568.6788330078125, 'policy_logps/chosen': -528.81982421875, 'referece_logps/rejected': -553.7142944335938, 'referece_logps/chosen': -521.8724365234375, 'logits/rejected': -0.1964607834815979, 'logits/chosen': -0.28394263982772827, 'epoch': 3.14}

 52%|█████▏    | 8417/16104 [39:03:05<38:40:34, 18.11s/it]

 52%|█████▏    | 8418/16104 [39:03:24<39:35:47, 18.55s/it]


 52%|█████▏    | 8420/16104 [39:04:03<40:37:00, 19.03s/it]

 52%|█████▏    | 8421/16104 [39:04:18<37:30:54, 17.58s/it]
{'loss': 0.4329, 'learning_rate': 9.744597386277173e-07, 'rewards/chosen': -0.2698734402656555, 'rewards/rejected': -1.858481526374817, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5886080265045166, 'policy_logps/rejected': -368.6072998046875, 'policy_logps/chosen': -396.35296630859375, 'referece_logps/rejected': -350.02252197265625, 'referece_logps/chosen': -393.65423583984375, 'logits/rejected': -0.09323395788669586, 'logits/chosen': -0.06763678789138794, 'epoch': 3.14}


 52%|█████▏    | 8423/16104 [39:04:52<36:53:03, 17.29s/it]

 52%|█████▏    | 8424/16104 [39:05:08<36:18:38, 17.02s/it]

 52%|█████▏    | 8425/16104 [39:05:24<35:27:09, 16.62s/it]

 52%|█████▏    | 8426/16104 [39:05:44<37:57:51, 17.80s/it]
{'loss': 0.3639, 'learning_rate': 9.734544483030025e-07, 'rewards/chosen': -0.5883440375328064, 'rewards/rejected': -2.008443832397461, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4200996160507202, 'policy_logps/rejected': -504.4527282714844, 'policy_logps/chosen': -551.98193359375, 'referece_logps/rejected': -484.3682556152344, 'referece_logps/chosen': -546.0985107421875, 'logits/rejected': -0.12834440171718597, 'logits/chosen': -0.002205261494964361, 'epoch': 3.14}

 52%|█████▏    | 8427/16104 [39:05:57<34:51:30, 16.35s/it]


 52%|█████▏    | 8429/16104 [39:06:28<33:25:24, 15.68s/it]
{'loss': 0.4309, 'learning_rate': 9.728512869288874e-07, 'rewards/chosen': -1.5196517705917358, 'rewards/rejected': -2.1511077880859375, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6314559578895569, 'policy_logps/rejected': -449.28729248046875, 'policy_logps/chosen': -447.38433837890625, 'referece_logps/rejected': -427.7762145996094, 'referece_logps/chosen': -432.1878356933594, 'logits/rejected': -0.4257967472076416, 'logits/chosen': -0.42622432112693787, 'epoch': 3.14}


 52%|█████▏    | 8431/16104 [39:07:00<34:42:37, 16.29s/it]

 52%|█████▏    | 8432/16104 [39:07:20<37:01:04, 17.37s/it]

 52%|█████▏    | 8433/16104 [39:07:36<36:03:34, 16.92s/it]

 52%|█████▏    | 8434/16104 [39:07:48<32:47:57, 15.39s/it]
{'loss': 0.3298, 'learning_rate': 9.718460400447448e-07, 'rewards/chosen': -0.6187532544136047, 'rewards/rejected': -2.5461323261260986, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9273791313171387, 'policy_logps/rejected': -319.9844665527344, 'policy_logps/chosen': -354.1693115234375, 'referece_logps/rejected': -294.52313232421875, 'referece_logps/chosen': -347.9817199707031, 'logits/rejected': -0.2237778753042221, 'logits/chosen': -0.11592981219291687, 'epoch': 3.14}


 52%|█████▏    | 8436/16104 [39:08:28<37:50:09, 17.76s/it]
{'loss': 0.3895, 'learning_rate': 9.714439492063038e-07, 'rewards/chosen': -0.6702274680137634, 'rewards/rejected': -1.0868430137634277, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4166156053543091, 'policy_logps/rejected': -380.4346618652344, 'policy_logps/chosen': -332.4060363769531, 'referece_logps/rejected': -369.56622314453125, 'referece_logps/chosen': -325.7037353515625, 'logits/rejected': 0.1332671046257019, 'logits/chosen': 0.04497072845697403, 'epoch': 3.14}


 52%|█████▏    | 8438/16104 [39:08:56<33:59:14, 15.96s/it]

 52%|█████▏    | 8439/16104 [39:09:14<35:40:05, 16.75s/it]

 52%|█████▏    | 8440/16104 [39:09:34<37:41:51, 17.71s/it]
{'loss': 0.4015, 'learning_rate': 9.706397814562006e-07, 'rewards/chosen': -0.697069525718689, 'rewards/rejected': -2.9628825187683105, 'rewards/accuracies': 0.875, 'rewards/margins': 2.265812873840332, 'policy_logps/rejected': -568.1632080078125, 'policy_logps/chosen': -627.6556396484375, 'referece_logps/rejected': -538.5343627929688, 'referece_logps/chosen': -620.6849365234375, 'logits/rejected': -0.42980271577835083, 'logits/chosen': -0.39563295245170593, 'epoch': 3.14}

 52%|█████▏    | 8441/16104 [39:09:49<35:39:14, 16.75s/it]

 52%|█████▏    | 8442/16104 [39:10:07<36:31:50, 17.16s/it]


 52%|█████▏    | 8444/16104 [39:10:44<37:34:24, 17.66s/it]

 52%|█████▏    | 8445/16104 [39:11:00<36:18:05, 17.06s/it]

 52%|█████▏    | 8446/16104 [39:11:16<35:41:10, 16.78s/it]

 52%|█████▏    | 8447/16104 [39:11:36<37:36:08, 17.68s/it]

 52%|█████▏    | 8448/16104 [39:11:51<35:44:21, 16.81s/it]

 52%|█████▏    | 8449/16104 [39:12:04<33:33:14, 15.78s/it]

 52%|█████▏    | 8450/16104 [39:12:21<34:05:59, 16.04s/it]
{'loss': 0.3313, 'learning_rate': 9.686294463565854e-07, 'rewards/chosen': -1.0112415552139282, 'rewards/rejected': -2.3562586307525635, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3450171947479248, 'policy_logps/rejected': -334.8017578125, 'policy_logps/chosen': -328.3162841796875, 'referece_logps/rejected': -311.23919677734375, 'referece_logps/chosen': -318.2038879394531, 'logits/rejected': 0.33863067626953125, 'logits/chosen': 0.24126678705215454, 'epoch': 3.15}

 52%|█████▏    | 8451/16104 [39:12:42<37:10:02, 17.48s/it]


 52%|█████▏    | 8453/16104 [39:13:13<34:40:25, 16.31s/it]

 52%|█████▏    | 8454/16104 [39:13:26<33:04:05, 15.56s/it]

 53%|█████▎    | 8455/16104 [39:13:46<35:51:33, 16.88s/it]

 53%|█████▎    | 8456/16104 [39:14:04<36:19:24, 17.10s/it]
{'loss': 0.5197, 'learning_rate': 9.674233056881124e-07, 'rewards/chosen': -0.2769794464111328, 'rewards/rejected': -0.4178817868232727, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1409023404121399, 'policy_logps/rejected': -382.85986328125, 'policy_logps/chosen': -369.4416198730469, 'referece_logps/rejected': -378.6810607910156, 'referece_logps/chosen': -366.67181396484375, 'logits/rejected': -0.2667500376701355, 'logits/chosen': 0.00454777292907238, 'epoch': 3.15}


 53%|█████▎    | 8458/16104 [39:14:40<37:12:39, 17.52s/it]
{'loss': 0.4515, 'learning_rate': 9.670212692541666e-07, 'rewards/chosen': -0.8082560300827026, 'rewards/rejected': -1.7535269260406494, 'rewards/accuracies': 0.875, 'rewards/margins': 0.945270836353302, 'policy_logps/rejected': -433.63751220703125, 'policy_logps/chosen': -446.21453857421875, 'referece_logps/rejected': -416.102294921875, 'referece_logps/chosen': -438.1319580078125, 'logits/rejected': -0.0925438404083252, 'logits/chosen': -0.19933879375457764, 'epoch': 3.15}

 53%|█████▎    | 8459/16104 [39:15:02<39:33:25, 18.63s/it]

 53%|█████▎    | 8460/16104 [39:15:21<40:07:08, 18.89s/it]

 53%|█████▎    | 8461/16104 [39:15:34<36:07:39, 17.02s/it]


 53%|█████▎    | 8463/16104 [39:16:15<39:58:15, 18.83s/it]

 53%|█████▎    | 8464/16104 [39:16:36<41:55:38, 19.76s/it]

 53%|█████▎    | 8465/16104 [39:16:50<38:13:19, 18.01s/it]
{'loss': 0.3935, 'learning_rate': 9.65614184184783e-07, 'rewards/chosen': -0.7893587350845337, 'rewards/rejected': -2.356748580932617, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5673900842666626, 'policy_logps/rejected': -337.1488952636719, 'policy_logps/chosen': -426.1938171386719, 'referece_logps/rejected': -313.5814208984375, 'referece_logps/chosen': -418.30023193359375, 'logits/rejected': -0.560300350189209, 'logits/chosen': -0.6030581593513489, 'epoch': 3.15}


 53%|█████▎    | 8467/16104 [39:17:17<32:49:10, 15.47s/it]

 53%|█████▎    | 8468/16104 [39:17:28<30:28:42, 14.37s/it]
{'loss': 0.3416, 'learning_rate': 9.65011168428365e-07, 'rewards/chosen': -0.43295857310295105, 'rewards/rejected': -2.8022377490997314, 'rewards/accuracies': 1.0, 'rewards/margins': 2.369278907775879, 'policy_logps/rejected': -365.99530029296875, 'policy_logps/chosen': -515.0173950195312, 'referece_logps/rejected': -337.9729309082031, 'referece_logps/chosen': -510.687744140625, 'logits/rejected': -0.2537917494773865, 'logits/chosen': -0.2523626983165741, 'epoch': 3.15}

 53%|█████▎    | 8469/16104 [39:17:48<33:44:28, 15.91s/it]


 53%|█████▎    | 8471/16104 [39:18:18<32:02:34, 15.11s/it]

 53%|█████▎    | 8472/16104 [39:18:29<29:11:06, 13.77s/it]

 53%|█████▎    | 8473/16104 [39:18:40<27:44:29, 13.09s/it]

 53%|█████▎    | 8474/16104 [39:19:01<32:20:07, 15.26s/it]
{'loss': 0.4947, 'learning_rate': 9.638051753497994e-07, 'rewards/chosen': -0.8510512709617615, 'rewards/rejected': -1.4397825002670288, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5887314081192017, 'policy_logps/rejected': -350.39013671875, 'policy_logps/chosen': -336.4805908203125, 'referece_logps/rejected': -335.9922790527344, 'referece_logps/chosen': -327.9700622558594, 'logits/rejected': -0.12702327966690063, 'logits/chosen': -0.01595800369977951, 'epoch': 3.16}


 53%|█████▎    | 8476/16104 [39:19:29<30:49:05, 14.54s/it]
{'loss': 0.4832, 'learning_rate': 9.634031892833789e-07, 'rewards/chosen': -0.6419313549995422, 'rewards/rejected': -1.583802342414856, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9418710470199585, 'policy_logps/rejected': -426.9753112792969, 'policy_logps/chosen': -509.54998779296875, 'referece_logps/rejected': -411.1372985839844, 'referece_logps/chosen': -503.13067626953125, 'logits/rejected': -0.20274731516838074, 'logits/chosen': -0.18535655736923218, 'epoch': 3.16}

 53%|█████▎    | 8477/16104 [39:19:42<30:00:07, 14.16s/it]

 53%|█████▎    | 8478/16104 [39:19:57<30:45:37, 14.52s/it]


 53%|█████▎    | 8480/16104 [39:20:29<33:16:04, 15.71s/it]
{'loss': 0.3666, 'learning_rate': 9.625992349804564e-07, 'rewards/chosen': -0.34666693210601807, 'rewards/rejected': -2.1052424907684326, 'rewards/accuracies': 1.0, 'rewards/margins': 1.758575439453125, 'policy_logps/rejected': -428.05584716796875, 'policy_logps/chosen': -403.7462158203125, 'referece_logps/rejected': -407.0034484863281, 'referece_logps/chosen': -400.279541015625, 'logits/rejected': 0.6162817478179932, 'logits/chosen': 0.6138374209403992, 'epoch': 3.16}


 53%|█████▎    | 8482/16104 [39:20:57<31:47:53, 15.02s/it]

 53%|█████▎    | 8483/16104 [39:21:17<34:52:45, 16.48s/it]

 53%|█████▎    | 8484/16104 [39:21:37<37:05:24, 17.52s/it]
{'loss': 0.4314, 'learning_rate': 9.617953048843758e-07, 'rewards/chosen': -1.0723627805709839, 'rewards/rejected': -2.6550207138061523, 'rewards/accuracies': 1.0, 'rewards/margins': 1.582658052444458, 'policy_logps/rejected': -510.0608215332031, 'policy_logps/chosen': -392.84228515625, 'referece_logps/rejected': -483.5106201171875, 'referece_logps/chosen': -382.11865234375, 'logits/rejected': 0.3351476788520813, 'logits/chosen': 0.25173789262771606, 'epoch': 3.16}

 53%|█████▎    | 8485/16104 [39:21:54<36:39:12, 17.32s/it]

 53%|█████▎    | 8486/16104 [39:22:12<37:12:56, 17.59s/it]

 53%|█████▎    | 8487/16104 [39:22:29<36:47:52, 17.39s/it]

 53%|█████▎    | 8488/16104 [39:22:46<36:22:31, 17.19s/it]

 53%|█████▎    | 8489/16104 [39:23:02<35:39:58, 16.86s/it]

 53%|█████▎    | 8490/16104 [39:23:19<35:53:20, 16.97s/it]


 53%|█████▎    | 8492/16104 [39:23:51<34:20:53, 16.24s/it]
{'loss': 0.5009, 'learning_rate': 9.6018751939403e-07, 'rewards/chosen': -0.8583810329437256, 'rewards/rejected': -1.3684605360031128, 'rewards/accuracies': 0.875, 'rewards/margins': 0.510079562664032, 'policy_logps/rejected': -277.2073669433594, 'policy_logps/chosen': -352.54815673828125, 'referece_logps/rejected': -263.52276611328125, 'referece_logps/chosen': -343.96435546875, 'logits/rejected': -0.4307134747505188, 'logits/chosen': -0.3116774260997772, 'epoch': 3.16}

 53%|█████▎    | 8493/16104 [39:24:08<34:28:20, 16.31s/it]

 53%|█████▎    | 8494/16104 [39:24:19<31:00:43, 14.67s/it]

 53%|█████▎    | 8495/16104 [39:24:40<35:33:06, 16.82s/it]

 53%|█████▎    | 8496/16104 [39:24:52<32:17:02, 15.28s/it]


 53%|█████▎    | 8498/16104 [39:25:19<30:18:50, 14.35s/it]
{'loss': 0.4679, 'learning_rate': 9.58981747689041e-07, 'rewards/chosen': -0.31667521595954895, 'rewards/rejected': -1.0524541139602661, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7357789278030396, 'policy_logps/rejected': -313.24444580078125, 'policy_logps/chosen': -505.0523376464844, 'referece_logps/rejected': -302.71990966796875, 'referece_logps/chosen': -501.8855895996094, 'logits/rejected': -1.2882431745529175, 'logits/chosen': -1.23745596408844, 'epoch': 3.17}

 53%|█████▎    | 8499/16104 [39:25:30<28:00:01, 13.25s/it]

 53%|█████▎    | 8500/16104 [39:25:41<26:42:00, 12.64s/it]

 53%|█████▎    | 8501/16104 [39:26:12<38:02:09, 18.01s/it]

 53%|█████▎    | 8502/16104 [39:26:23<33:34:00, 15.90s/it]

 53%|█████▎    | 8503/16104 [39:26:43<36:05:16, 17.09s/it]

 53%|█████▎    | 8504/16104 [39:27:03<37:58:51, 17.99s/it]


 53%|█████▎    | 8506/16104 [39:27:44<40:17:28, 19.09s/it]
{'loss': 0.4321, 'learning_rate': 9.573741453045023e-07, 'rewards/chosen': -0.0834880843758583, 'rewards/rejected': -1.609955906867981, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5264678001403809, 'policy_logps/rejected': -365.5860595703125, 'policy_logps/chosen': -328.8923645019531, 'referece_logps/rejected': -349.4864501953125, 'referece_logps/chosen': -328.0574951171875, 'logits/rejected': -0.19038721919059753, 'logits/chosen': -0.17574667930603027, 'epoch': 3.17}

 53%|█████▎    | 8507/16104 [39:28:02<39:54:43, 18.91s/it]

 53%|█████▎    | 8508/16104 [39:28:15<35:59:05, 17.05s/it]

 53%|█████▎    | 8509/16104 [39:28:31<35:13:53, 16.70s/it]

 53%|█████▎    | 8510/16104 [39:28:42<32:06:38, 15.22s/it]

 53%|█████▎    | 8511/16104 [39:29:00<33:38:14, 15.95s/it]


 53%|█████▎    | 8513/16104 [39:29:40<37:51:26, 17.95s/it]
{'loss': 0.3733, 'learning_rate': 9.55967583601089e-07, 'rewards/chosen': -0.622113823890686, 'rewards/rejected': -1.3109349012374878, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6888210773468018, 'policy_logps/rejected': -260.12164306640625, 'policy_logps/chosen': -236.2626495361328, 'referece_logps/rejected': -247.01229858398438, 'referece_logps/chosen': -230.04150390625, 'logits/rejected': -0.8210671544075012, 'logits/chosen': -0.7436903715133667, 'epoch': 3.17}

 53%|█████▎    | 8514/16104 [39:29:57<37:12:32, 17.65s/it]

 53%|█████▎    | 8515/16104 [39:30:13<36:00:49, 17.08s/it]

 53%|█████▎    | 8516/16104 [39:30:32<37:49:31, 17.95s/it]

 53%|█████▎    | 8517/16104 [39:30:43<33:18:56, 15.81s/it]

 53%|█████▎    | 8518/16104 [39:30:58<32:52:35, 15.60s/it]

 53%|█████▎    | 8519/16104 [39:31:18<35:23:04, 16.79s/it]


 53%|█████▎    | 8521/16104 [39:31:42<30:07:57, 14.31s/it]

 53%|█████▎    | 8522/16104 [39:32:00<32:29:49, 15.43s/it]

 53%|█████▎    | 8523/16104 [39:32:16<32:48:25, 15.58s/it]
{'loss': 0.4096, 'learning_rate': 9.539583618310466e-07, 'rewards/chosen': -0.6795499920845032, 'rewards/rejected': -1.601252794265747, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9217029213905334, 'policy_logps/rejected': -371.2089538574219, 'policy_logps/chosen': -389.53387451171875, 'referece_logps/rejected': -355.1964416503906, 'referece_logps/chosen': -382.73834228515625, 'logits/rejected': 0.14283567667007446, 'logits/chosen': 0.014644831418991089, 'epoch': 3.18}


 53%|█████▎    | 8525/16104 [39:32:52<35:19:07, 16.78s/it]
{'loss': 0.3796, 'learning_rate': 9.535565395665562e-07, 'rewards/chosen': -0.01579933613538742, 'rewards/rejected': -1.456904649734497, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4411052465438843, 'policy_logps/rejected': -371.3518981933594, 'policy_logps/chosen': -451.035400390625, 'referece_logps/rejected': -356.7828369140625, 'referece_logps/chosen': -450.8774108886719, 'logits/rejected': 0.30686259269714355, 'logits/chosen': 0.25351718068122864, 'epoch': 3.18}

 53%|█████▎    | 8526/16104 [39:33:03<31:44:46, 15.08s/it]

 53%|█████▎    | 8527/16104 [39:33:23<34:48:17, 16.54s/it]

 53%|█████▎    | 8528/16104 [39:33:36<32:17:24, 15.34s/it]

 53%|█████▎    | 8529/16104 [39:33:52<33:14:14, 15.80s/it]

 53%|█████▎    | 8530/16104 [39:34:07<32:35:33, 15.49s/it]

 53%|█████▎    | 8531/16104 [39:34:23<32:46:16, 15.58s/it]

 53%|█████▎    | 8532/16104 [39:34:41<34:05:42, 16.21s/it]

 53%|█████▎    | 8533/16104 [39:35:02<37:05:59, 17.64s/it]


 53%|█████▎    | 8535/16104 [39:35:32<35:00:50, 16.65s/it]

 53%|█████▎    | 8536/16104 [39:35:48<34:45:17, 16.53s/it]
{'loss': 0.4351, 'learning_rate': 9.513466531836221e-07, 'rewards/chosen': -1.1314175128936768, 'rewards/rejected': -2.1530051231384277, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0215874910354614, 'policy_logps/rejected': -351.14678955078125, 'policy_logps/chosen': -511.10601806640625, 'referece_logps/rejected': -329.6167297363281, 'referece_logps/chosen': -499.79180908203125, 'logits/rejected': -0.18243730068206787, 'logits/chosen': -0.28446894884109497, 'epoch': 3.18}

 53%|█████▎    | 8537/16104 [39:36:09<37:10:24, 17.69s/it]

 53%|█████▎    | 8538/16104 [39:36:24<35:29:10, 16.88s/it]

 53%|█████▎    | 8539/16104 [39:36:35<32:15:14, 15.35s/it]

 53%|█████▎    | 8540/16104 [39:36:55<34:54:15, 16.61s/it]

 53%|█████▎    | 8541/16104 [39:37:13<35:54:44, 17.09s/it]


 53%|█████▎    | 8543/16104 [39:37:48<36:48:24, 17.52s/it]
{'loss': 0.4162, 'learning_rate': 9.499404851576076e-07, 'rewards/chosen': -0.2482011914253235, 'rewards/rejected': -2.0941076278686523, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8459064960479736, 'policy_logps/rejected': -578.2133178710938, 'policy_logps/chosen': -320.5533447265625, 'referece_logps/rejected': -557.2721557617188, 'referece_logps/chosen': -318.07135009765625, 'logits/rejected': -0.6567708253860474, 'logits/chosen': -0.3849925398826599, 'epoch': 3.18}


 53%|█████▎    | 8545/16104 [39:38:28<39:15:50, 18.70s/it]

 53%|█████▎    | 8546/16104 [39:38:48<40:02:44, 19.07s/it]
{'loss': 0.3744, 'learning_rate': 9.493378719303199e-07, 'rewards/chosen': -1.3135281801223755, 'rewards/rejected': -3.079042673110962, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7655142545700073, 'policy_logps/rejected': -475.68927001953125, 'policy_logps/chosen': -514.4381103515625, 'referece_logps/rejected': -444.8988342285156, 'referece_logps/chosen': -501.3028259277344, 'logits/rejected': -0.26614218950271606, 'logits/chosen': -0.1703706681728363, 'epoch': 3.18}

 53%|█████▎    | 8547/16104 [39:39:07<39:41:41, 18.91s/it]


 53%|█████▎    | 8549/16104 [39:39:38<35:48:27, 17.06s/it]
{'loss': 0.3368, 'learning_rate': 9.487352771473932e-07, 'rewards/chosen': -0.3542264997959137, 'rewards/rejected': -1.6371042728424072, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2828776836395264, 'policy_logps/rejected': -314.12579345703125, 'policy_logps/chosen': -650.51171875, 'referece_logps/rejected': -297.7547607421875, 'referece_logps/chosen': -646.969482421875, 'logits/rejected': 0.22898095846176147, 'logits/chosen': 0.16002340614795685, 'epoch': 3.19}

 53%|█████▎    | 8550/16104 [39:39:57<36:36:54, 17.45s/it]

 53%|█████▎    | 8551/16104 [39:40:09<33:35:18, 16.01s/it]


 53%|█████▎    | 8553/16104 [39:40:48<37:13:16, 17.75s/it]
{'loss': 0.4666, 'learning_rate': 9.479318465072337e-07, 'rewards/chosen': -0.0743759423494339, 'rewards/rejected': -1.5480927228927612, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4737169742584229, 'policy_logps/rejected': -507.78765869140625, 'policy_logps/chosen': -474.86822509765625, 'referece_logps/rejected': -492.30670166015625, 'referece_logps/chosen': -474.1244201660156, 'logits/rejected': -0.6264123320579529, 'logits/chosen': -0.3199782967567444, 'epoch': 3.19}


 53%|█████▎    | 8555/16104 [39:41:23<37:01:29, 17.66s/it]
{'loss': 0.3868, 'learning_rate': 9.475301437921524e-07, 'rewards/chosen': -0.5846726894378662, 'rewards/rejected': -1.4337807893753052, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8491081595420837, 'policy_logps/rejected': -424.7113037109375, 'policy_logps/chosen': -374.4257507324219, 'referece_logps/rejected': -410.3735046386719, 'referece_logps/chosen': -368.5789794921875, 'logits/rejected': 0.2202935367822647, 'logits/chosen': 0.266888827085495, 'epoch': 3.19}

 53%|█████▎    | 8556/16104 [39:41:40<36:56:49, 17.62s/it]

 53%|█████▎    | 8557/16104 [39:42:02<39:21:38, 18.78s/it]


 53%|█████▎    | 8559/16104 [39:42:33<36:38:47, 17.49s/it]
{'loss': 0.471, 'learning_rate': 9.467267638969781e-07, 'rewards/chosen': -0.0016757920384407043, 'rewards/rejected': -1.043075680732727, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0413999557495117, 'policy_logps/rejected': -525.1231689453125, 'policy_logps/chosen': -305.03570556640625, 'referece_logps/rejected': -514.6924438476562, 'referece_logps/chosen': -305.0189514160156, 'logits/rejected': -0.018000885844230652, 'logits/chosen': 0.010341251268982887, 'epoch': 3.19}


 53%|█████▎    | 8561/16104 [39:42:58<32:08:36, 15.34s/it]

 53%|█████▎    | 8562/16104 [39:43:19<35:12:51, 16.81s/it]
{'loss': 0.3295, 'learning_rate': 9.461242515746347e-07, 'rewards/chosen': -0.6562771201133728, 'rewards/rejected': -1.970826506614685, 'rewards/accuracies': 0.875, 'rewards/margins': 1.314549446105957, 'policy_logps/rejected': -308.19732666015625, 'policy_logps/chosen': -339.09417724609375, 'referece_logps/rejected': -288.4891052246094, 'referece_logps/chosen': -332.5313415527344, 'logits/rejected': -0.481405645608902, 'logits/chosen': -0.4959990382194519, 'epoch': 3.19}

 53%|█████▎    | 8563/16104 [39:43:38<36:57:59, 17.65s/it]

 53%|█████▎    | 8564/16104 [39:44:01<40:16:04, 19.23s/it]

 53%|█████▎    | 8565/16104 [39:44:20<39:46:46, 19.00s/it]

 53%|█████▎    | 8566/16104 [39:44:39<39:53:40, 19.05s/it]

 53%|█████▎    | 8567/16104 [39:44:58<40:12:50, 19.21s/it]


 53%|█████▎    | 8569/16104 [39:45:35<39:08:08, 18.70s/it]
{'loss': 0.4066, 'learning_rate': 9.447184661462381e-07, 'rewards/chosen': -0.6023926734924316, 'rewards/rejected': -1.80326509475708, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2008723020553589, 'policy_logps/rejected': -372.6415710449219, 'policy_logps/chosen': -427.0180358886719, 'referece_logps/rejected': -354.6089172363281, 'referece_logps/chosen': -420.9940490722656, 'logits/rejected': -0.781616747379303, 'logits/chosen': -0.8255997896194458, 'epoch': 3.19}

 53%|█████▎    | 8570/16104 [39:45:54<39:48:14, 19.02s/it]

 53%|█████▎    | 8571/16104 [39:46:06<35:10:03, 16.81s/it]

 53%|█████▎    | 8572/16104 [39:46:23<35:14:25, 16.84s/it]

 53%|█████▎    | 8573/16104 [39:46:38<34:01:44, 16.27s/it]

 53%|█████▎    | 8574/16104 [39:46:54<33:49:11, 16.17s/it]

 53%|█████▎    | 8575/16104 [39:47:13<35:27:41, 16.96s/it]

 53%|█████▎    | 8576/16104 [39:47:30<35:29:08, 16.97s/it]

 53%|█████▎    | 8577/16104 [39:47:44<33:57:22, 16.24s/it]

 53%|█████▎    | 8578/16104 [39:47:58<32:44:41, 15.66s/it]


 53%|█████▎    | 8580/16104 [39:48:25<30:33:43, 14.62s/it]
{'loss': 0.5301, 'learning_rate': 9.425095972184198e-07, 'rewards/chosen': -0.7221941947937012, 'rewards/rejected': -1.0940361022949219, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3718418478965759, 'policy_logps/rejected': -419.6463928222656, 'policy_logps/chosen': -348.6170654296875, 'referece_logps/rejected': -408.7060241699219, 'referece_logps/chosen': -341.3951110839844, 'logits/rejected': 0.14495623111724854, 'logits/chosen': 0.2642092704772949, 'epoch': 3.2}

 53%|█████▎    | 8581/16104 [39:48:41<31:43:39, 15.18s/it]


 53%|█████▎    | 8583/16104 [39:49:19<35:10:26, 16.84s/it]

 53%|█████▎    | 8584/16104 [39:49:35<34:41:16, 16.61s/it]
{'loss': 0.5335, 'learning_rate': 9.417064413528463e-07, 'rewards/chosen': -1.358497977256775, 'rewards/rejected': -2.189728260040283, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8312303423881531, 'policy_logps/rejected': -451.019287109375, 'policy_logps/chosen': -384.9498596191406, 'referece_logps/rejected': -429.12200927734375, 'referece_logps/chosen': -371.3648681640625, 'logits/rejected': -0.4812629818916321, 'logits/chosen': -0.46239209175109863, 'epoch': 3.2}

 53%|█████▎    | 8585/16104 [39:49:55<37:02:27, 17.73s/it]

 53%|█████▎    | 8586/16104 [39:50:13<36:50:54, 17.64s/it]

 53%|█████▎    | 8587/16104 [39:50:34<38:47:48, 18.58s/it]

 53%|█████▎    | 8588/16104 [39:50:45<34:26:09, 16.49s/it]

 53%|█████▎    | 8589/16104 [39:51:06<37:18:39, 17.87s/it]

 53%|█████▎    | 8590/16104 [39:51:24<37:22:37, 17.91s/it]

 53%|█████▎    | 8591/16104 [39:51:36<33:47:57, 16.20s/it]

 53%|█████▎    | 8592/16104 [39:51:56<36:10:44, 17.34s/it]

 53%|█████▎    | 8593/16104 [39:52:11<34:39:13, 16.61s/it]

 53%|█████▎    | 8594/16104 [39:52:24<31:52:08, 15.28s/it]

 53%|█████▎    | 8595/16104 [39:52:43<34:31:32, 16.55s/it]

 53%|█████▎    | 8596/16104 [39:53:03<36:24:47, 17.46s/it]

 53%|█████▎    | 8597/16104 [39:53:23<38:22:18, 18.40s/it]

 53%|█████▎    | 8598/16104 [39:53:38<36:03:50, 17.30s/it]

 53%|█████▎    | 8599/16104 [39:53:58<37:41:30, 18.08s/it]

 53%|█████▎    | 8600/16104 [39:54:13<35:54:34, 17.23s/it]

 53%|█████▎    | 8601/16104 [39:54:29<35:13:56, 16.90s/it]

 53%|█████▎    | 8602/16104 [39:54:43<33:01:45, 15.85s/it]

 53%|█████▎    | 8603/16104 [39:55:02<35:04:18, 16.83s/it]

 53%|█████▎    | 8604/16104 [39:55:20<35:53:12, 17.23s/it]

 53%|█████▎    | 8605/16104 [39:55:40<37:24:11, 17.96s/it]

 53%|█████▎    | 8606/16104 [39:55:54<34:52:53, 16.75s/it]

 53%|█████▎    | 8607/16104 [39:56:12<36:13:57, 17.40s/it]

 53%|█████▎    | 8608/16104 [39:56:31<36:48:05, 17.67s/it]

 53%|█████▎    | 8609/16104 [39:56:48<36:48:17, 17.68s/it]

 53%|█████▎    | 8610/16104 [39:57:07<37:34:35, 18.05s/it]

 53%|█████▎    | 8611/16104 [39:57:20<34:06:02, 16.38s/it]

 53%|█████▎    | 8612/16104 [39:57:39<35:47:06, 17.20s/it]

 53%|█████▎    | 8613/16104 [39:57:52<32:57:56, 15.84s/it]


 53%|█████▎    | 8615/16104 [39:58:25<34:25:57, 16.55s/it]

 54%|█████▎    | 8616/16104 [39:58:44<35:40:20, 17.15s/it]

 54%|█████▎    | 8617/16104 [39:59:03<37:07:02, 17.85s/it]

 54%|█████▎    | 8618/16104 [39:59:23<38:07:06, 18.33s/it]

 54%|█████▎    | 8619/16104 [39:59:41<38:11:06, 18.37s/it]

 54%|█████▎    | 8620/16104 [40:00:01<38:53:09, 18.71s/it]

 54%|█████▎    | 8621/16104 [40:00:15<36:19:54, 17.48s/it]

 54%|█████▎    | 8622/16104 [40:00:27<32:23:28, 15.59s/it]

 54%|█████▎    | 8623/16104 [40:00:43<33:09:56, 15.96s/it]

 54%|█████▎    | 8624/16104 [40:00:57<31:25:42, 15.13s/it]

 54%|█████▎    | 8625/16104 [40:01:13<31:53:58, 15.35s/it]

 54%|█████▎    | 8626/16104 [40:01:26<30:23:26, 14.63s/it]

 54%|█████▎    | 8627/16104 [40:01:42<31:21:18, 15.10s/it]

 54%|█████▎    | 8628/16104 [40:01:57<31:44:44, 15.29s/it]

 54%|█████▎    | 8629/16104 [40:02:15<33:10:46, 15.98s/it]

 54%|█████▎    | 8630/16104 [40:02:32<33:44:39, 16.25s/it]

 54%|█████▎    | 8631/16104 [40:02:53<36:54:44, 17.78s/it]

 54%|█████▎    | 8632/16104 [40:03:12<37:22:52, 18.01s/it]

 54%|█████▎    | 8633/16104 [40:03:26<35:15:05, 16.99s/it]

 54%|█████▎    | 8634/16104 [40:03:41<33:49:09, 16.30s/it]

 54%|█████▎    | 8635/16104 [40:04:01<35:45:19, 17.23s/it]

 54%|█████▎    | 8636/16104 [40:04:21<38:04:13, 18.35s/it]

 54%|█████▎    | 8637/16104 [40:04:37<36:01:19, 17.37s/it]

 54%|█████▎    | 8638/16104 [40:04:51<34:05:38, 16.44s/it]

 54%|█████▎    | 8639/16104 [40:05:04<31:59:58, 15.43s/it]

 54%|█████▎    | 8640/16104 [40:05:24<34:49:20, 16.80s/it]

 54%|█████▎    | 8641/16104 [40:05:38<33:12:49, 16.02s/it]

 54%|█████▎    | 8642/16104 [40:06:00<36:53:28, 17.80s/it]

 54%|█████▎    | 8643/16104 [40:06:20<38:09:05, 18.41s/it]

 54%|█████▎    | 8644/16104 [40:06:37<37:20:13, 18.02s/it]

 54%|█████▎    | 8645/16104 [40:06:57<38:18:22, 18.49s/it]

 54%|█████▎    | 8646/16104 [40:07:15<38:07:24, 18.40s/it]

 54%|█████▎    | 8647/16104 [40:07:33<38:14:13, 18.46s/it]

 54%|█████▎    | 8648/16104 [40:07:49<36:30:18, 17.63s/it]

 54%|█████▎    | 8649/16104 [40:08:05<35:22:45, 17.08s/it]

 54%|█████▎    | 8650/16104 [40:08:16<31:59:52, 15.45s/it]

 54%|█████▎    | 8651/16104 [40:08:30<30:40:33, 14.82s/it]
{'loss': 0.4061, 'learning_rate': 9.2825959489617e-07, 'rewards/chosen': -0.39085957407951355, 'rewards/rejected': -0.9811084866523743, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5902489423751831, 'policy_logps/rejected': -377.7295837402344, 'policy_logps/chosen': -428.9276123046875, 'referece_logps/rejected': -367.9184875488281, 'referece_logps/chosen': -425.01904296875, 'logits/rejected': -0.5632887482643127, 'logits/chosen': -0.6460535526275635, 'epoch': 3.22}


 54%|█████▎    | 8653/16104 [40:08:54<27:42:27, 13.39s/it]

 54%|█████▎    | 8654/16104 [40:09:14<31:29:35, 15.22s/it]

 54%|█████▎    | 8655/16104 [40:09:27<30:38:43, 14.81s/it]

 54%|█████▍    | 8656/16104 [40:09:41<30:07:42, 14.56s/it]
{'loss': 0.3796, 'learning_rate': 9.272565910621638e-07, 'rewards/chosen': -0.5008791089057922, 'rewards/rejected': -2.341555118560791, 'rewards/accuracies': 0.75, 'rewards/margins': 1.840675711631775, 'policy_logps/rejected': -352.76593017578125, 'policy_logps/chosen': -416.2884521484375, 'referece_logps/rejected': -329.3503723144531, 'referece_logps/chosen': -411.2796630859375, 'logits/rejected': -1.1294093132019043, 'logits/chosen': -0.9813491702079773, 'epoch': 3.23}


 54%|█████▍    | 8658/16104 [40:10:12<31:50:26, 15.39s/it]

 54%|█████▍    | 8659/16104 [40:10:27<31:36:56, 15.29s/it]

 54%|█████▍    | 8660/16104 [40:10:47<34:22:13, 16.62s/it]
{'loss': 0.4094, 'learning_rate': 9.264542409130819e-07, 'rewards/chosen': -0.11854659020900726, 'rewards/rejected': -2.1056532859802246, 'rewards/accuracies': 0.625, 'rewards/margins': 1.9871065616607666, 'policy_logps/rejected': -364.426513671875, 'policy_logps/chosen': -404.70745849609375, 'referece_logps/rejected': -343.3699951171875, 'referece_logps/chosen': -403.5219421386719, 'logits/rejected': -0.7831090688705444, 'logits/chosen': -0.7991393804550171, 'epoch': 3.23}


 54%|█████▍    | 8662/16104 [40:11:18<33:57:50, 16.43s/it]

 54%|█████▍    | 8663/16104 [40:11:35<34:20:39, 16.62s/it]

 54%|█████▍    | 8664/16104 [40:11:54<35:31:44, 17.19s/it]

 54%|█████▍    | 8665/16104 [40:12:14<37:29:50, 18.15s/it]

 54%|█████▍    | 8666/16104 [40:12:34<38:29:16, 18.63s/it]

 54%|█████▍    | 8667/16104 [40:12:56<40:27:06, 19.58s/it]

 54%|█████▍    | 8668/16104 [40:13:09<36:47:04, 17.81s/it]

 54%|█████▍    | 8669/16104 [40:13:25<35:33:53, 17.22s/it]

 54%|█████▍    | 8670/16104 [40:13:41<34:43:14, 16.81s/it]

 54%|█████▍    | 8671/16104 [40:14:02<37:03:56, 17.95s/it]

 54%|█████▍    | 8672/16104 [40:14:21<38:12:24, 18.51s/it]

 54%|█████▍    | 8673/16104 [40:14:42<39:14:22, 19.01s/it]

 54%|█████▍    | 8674/16104 [40:14:57<37:12:58, 18.03s/it]

 54%|█████▍    | 8675/16104 [40:15:14<36:11:48, 17.54s/it]

 54%|█████▍    | 8676/16104 [40:15:34<37:33:33, 18.20s/it]

 54%|█████▍    | 8677/16104 [40:15:44<33:02:15, 16.01s/it]

 54%|█████▍    | 8678/16104 [40:16:01<33:35:40, 16.29s/it]

 54%|█████▍    | 8679/16104 [40:16:12<30:11:19, 14.64s/it]

 54%|█████▍    | 8680/16104 [40:16:25<29:20:11, 14.23s/it]

 54%|█████▍    | 8681/16104 [40:16:40<29:16:13, 14.20s/it]

 54%|█████▍    | 8682/16104 [40:16:54<29:08:48, 14.14s/it]

 54%|█████▍    | 8683/16104 [40:17:09<29:48:05, 14.46s/it]

 54%|█████▍    | 8684/16104 [40:17:28<32:57:09, 15.99s/it]

 54%|█████▍    | 8685/16104 [40:17:50<36:38:23, 17.78s/it]

 54%|█████▍    | 8686/16104 [40:18:08<36:53:41, 17.91s/it]

 54%|█████▍    | 8687/16104 [40:18:26<36:41:16, 17.81s/it]
{'loss': 0.429, 'learning_rate': 9.210396484989038e-07, 'rewards/chosen': 0.3207666575908661, 'rewards/rejected': -0.7423301935195923, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0630968809127808, 'policy_logps/rejected': -550.7628173828125, 'policy_logps/chosen': -552.7080688476562, 'referece_logps/rejected': -543.3395385742188, 'referece_logps/chosen': -555.915771484375, 'logits/rejected': 0.623691976070404, 'logits/chosen': 0.5962571501731873, 'epoch': 3.24}


 54%|█████▍    | 8689/16104 [40:19:00<36:11:59, 17.58s/it]

 54%|█████▍    | 8690/16104 [40:19:22<38:53:58, 18.89s/it]

 54%|█████▍    | 8691/16104 [40:19:38<37:15:22, 18.09s/it]

 54%|█████▍    | 8692/16104 [40:19:54<35:29:34, 17.24s/it]

 54%|█████▍    | 8693/16104 [40:20:12<36:21:46, 17.66s/it]

 54%|█████▍    | 8694/16104 [40:20:30<36:25:52, 17.70s/it]

 54%|█████▍    | 8695/16104 [40:20:48<36:39:29, 17.81s/it]

 54%|█████▍    | 8696/16104 [40:21:05<36:07:11, 17.55s/it]

 54%|█████▍    | 8697/16104 [40:21:17<32:57:50, 16.02s/it]

 54%|█████▍    | 8698/16104 [40:21:38<36:03:14, 17.53s/it]
{'loss': 0.442, 'learning_rate': 9.188343619637367e-07, 'rewards/chosen': -0.3669120669364929, 'rewards/rejected': -1.2657876014709473, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8988754749298096, 'policy_logps/rejected': -448.59478759765625, 'policy_logps/chosen': -501.56231689453125, 'referece_logps/rejected': -435.9369201660156, 'referece_logps/chosen': -497.8931884765625, 'logits/rejected': 0.9103410840034485, 'logits/chosen': 0.8952679634094238, 'epoch': 3.24}

 54%|█████▍    | 8699/16104 [40:21:55<35:38:18, 17.33s/it]


 54%|█████▍    | 8701/16104 [40:22:34<37:24:43, 18.19s/it]

 54%|█████▍    | 8702/16104 [40:22:54<38:32:08, 18.74s/it]

 54%|█████▍    | 8703/16104 [40:23:09<35:46:24, 17.40s/it]
{'loss': 0.2671, 'learning_rate': 9.178320896762363e-07, 'rewards/chosen': -0.02930907905101776, 'rewards/rejected': -1.3059546947479248, 'rewards/accuracies': 0.875, 'rewards/margins': 1.276645541191101, 'policy_logps/rejected': -276.9138488769531, 'policy_logps/chosen': -375.42803955078125, 'referece_logps/rejected': -263.85430908203125, 'referece_logps/chosen': -375.13494873046875, 'logits/rejected': -0.6044124364852905, 'logits/chosen': -0.7579598426818848, 'epoch': 3.24}


 54%|█████▍    | 8705/16104 [40:23:40<34:17:19, 16.68s/it]

 54%|█████▍    | 8706/16104 [40:24:00<36:27:45, 17.74s/it]

 54%|█████▍    | 8707/16104 [40:24:19<36:57:08, 17.98s/it]
{'loss': 0.376, 'learning_rate': 9.170303316266769e-07, 'rewards/chosen': -0.7515164613723755, 'rewards/rejected': -2.3051722049713135, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5536558628082275, 'policy_logps/rejected': -523.032958984375, 'policy_logps/chosen': -347.7769470214844, 'referece_logps/rejected': -499.9812316894531, 'referece_logps/chosen': -340.26177978515625, 'logits/rejected': -0.3959926962852478, 'logits/chosen': -0.29051753878593445, 'epoch': 3.24}


 54%|█████▍    | 8709/16104 [40:24:53<35:19:26, 17.20s/it]

 54%|█████▍    | 8710/16104 [40:25:05<32:11:32, 15.67s/it]

 54%|█████▍    | 8711/16104 [40:25:23<33:31:06, 16.32s/it]
{'loss': 0.3117, 'learning_rate': 9.162286272774525e-07, 'rewards/chosen': -0.7406814098358154, 'rewards/rejected': -2.5348174571990967, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7941359281539917, 'policy_logps/rejected': -486.02642822265625, 'policy_logps/chosen': -376.16729736328125, 'referece_logps/rejected': -460.6782531738281, 'referece_logps/chosen': -368.7605285644531, 'logits/rejected': -0.5681064128875732, 'logits/chosen': -0.28881797194480896, 'epoch': 3.25}


 54%|█████▍    | 8713/16104 [40:25:57<35:24:58, 17.25s/it]

 54%|█████▍    | 8714/16104 [40:26:11<32:57:04, 16.05s/it]

 54%|█████▍    | 8715/16104 [40:26:27<32:58:06, 16.06s/it]

 54%|█████▍    | 8716/16104 [40:26:48<36:21:37, 17.72s/it]
{'loss': 0.4025, 'learning_rate': 9.152265731475061e-07, 'rewards/chosen': -0.6564522981643677, 'rewards/rejected': -2.2806155681610107, 'rewards/accuracies': 1.0, 'rewards/margins': 1.624163269996643, 'policy_logps/rejected': -287.94464111328125, 'policy_logps/chosen': -366.8267822265625, 'referece_logps/rejected': -265.13848876953125, 'referece_logps/chosen': -360.26226806640625, 'logits/rejected': 0.2780683934688568, 'logits/chosen': 0.3389255106449127, 'epoch': 3.25}


 54%|█████▍    | 8718/16104 [40:27:21<35:17:51, 17.20s/it]

 54%|█████▍    | 8719/16104 [40:27:33<32:08:14, 15.67s/it]
{'loss': 0.4713, 'learning_rate': 9.146253817555195e-07, 'rewards/chosen': -0.5772274732589722, 'rewards/rejected': -1.7397363185882568, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1625089645385742, 'policy_logps/rejected': -434.9783020019531, 'policy_logps/chosen': -337.92340087890625, 'referece_logps/rejected': -417.5809631347656, 'referece_logps/chosen': -332.151123046875, 'logits/rejected': -0.3905099332332611, 'logits/chosen': -0.37045082449913025, 'epoch': 3.25}


 54%|█████▍    | 8721/16104 [40:28:11<35:23:39, 17.26s/it]

 54%|█████▍    | 8722/16104 [40:28:29<35:54:03, 17.51s/it]
{'loss': 0.4305, 'learning_rate': 9.14024221445533e-07, 'rewards/chosen': -0.801421582698822, 'rewards/rejected': -1.6320722103118896, 'rewards/accuracies': 0.75, 'rewards/margins': 0.830650806427002, 'policy_logps/rejected': -357.3314208984375, 'policy_logps/chosen': -374.079833984375, 'referece_logps/rejected': -341.0107116699219, 'referece_logps/chosen': -366.0656433105469, 'logits/rejected': -0.7291075587272644, 'logits/chosen': -0.7843402028083801, 'epoch': 3.25}


 54%|█████▍    | 8724/16104 [40:29:05<36:37:20, 17.86s/it]
{'loss': 0.4352, 'learning_rate': 9.136234652814005e-07, 'rewards/chosen': -0.7095060348510742, 'rewards/rejected': -1.918684482574463, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2091784477233887, 'policy_logps/rejected': -388.4635925292969, 'policy_logps/chosen': -372.1988220214844, 'referece_logps/rejected': -369.2767639160156, 'referece_logps/chosen': -365.1037292480469, 'logits/rejected': -0.2478712797164917, 'logits/chosen': -0.11733262240886688, 'epoch': 3.25}


 54%|█████▍    | 8726/16104 [40:29:39<35:02:27, 17.10s/it]
{'loss': 0.3492, 'learning_rate': 9.132227230936075e-07, 'rewards/chosen': -0.8636775612831116, 'rewards/rejected': -2.016232967376709, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1525555849075317, 'policy_logps/rejected': -377.762451171875, 'policy_logps/chosen': -343.2367858886719, 'referece_logps/rejected': -357.60009765625, 'referece_logps/chosen': -334.60003662109375, 'logits/rejected': -0.2926253378391266, 'logits/chosen': -0.2946023941040039, 'epoch': 3.25}

 54%|█████▍    | 8727/16104 [40:29:58<36:05:51, 17.62s/it]


 54%|█████▍    | 8729/16104 [40:30:39<38:42:04, 18.89s/it]
{'loss': 0.4302, 'learning_rate': 9.126216361593983e-07, 'rewards/chosen': -1.0085710287094116, 'rewards/rejected': -1.1825151443481445, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17394417524337769, 'policy_logps/rejected': -389.98284912109375, 'policy_logps/chosen': -409.6023254394531, 'referece_logps/rejected': -378.1576843261719, 'referece_logps/chosen': -399.5166015625, 'logits/rejected': -0.8498234748840332, 'logits/chosen': -0.866134524345398, 'epoch': 3.25}


 54%|█████▍    | 8731/16104 [40:31:11<35:02:07, 17.11s/it]

 54%|█████▍    | 8732/16104 [40:31:27<34:31:58, 16.86s/it]

 54%|█████▍    | 8733/16104 [40:31:40<31:52:24, 15.57s/it]
{'loss': 0.4635, 'learning_rate': 9.118202364361566e-07, 'rewards/chosen': -0.4847237467765808, 'rewards/rejected': -1.2912046909332275, 'rewards/accuracies': 0.625, 'rewards/margins': 0.806480884552002, 'policy_logps/rejected': -393.8241271972656, 'policy_logps/chosen': -414.447021484375, 'referece_logps/rejected': -380.912109375, 'referece_logps/chosen': -409.5998229980469, 'logits/rejected': 0.14628641307353973, 'logits/chosen': 0.22629690170288086, 'epoch': 3.25}


 54%|█████▍    | 8735/16104 [40:32:07<29:40:58, 14.50s/it]

 54%|█████▍    | 8736/16104 [40:32:26<32:20:38, 15.80s/it]

 54%|█████▍    | 8737/16104 [40:32:45<34:19:58, 16.78s/it]
{'loss': 0.3225, 'learning_rate': 9.110188937853734e-07, 'rewards/chosen': -1.2134943008422852, 'rewards/rejected': -2.154468536376953, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9409739971160889, 'policy_logps/rejected': -257.3863830566406, 'policy_logps/chosen': -382.64697265625, 'referece_logps/rejected': -235.84169006347656, 'referece_logps/chosen': -370.5120544433594, 'logits/rejected': -0.7177853584289551, 'logits/chosen': -0.7583156228065491, 'epoch': 3.26}


 54%|█████▍    | 8739/16104 [40:33:25<37:44:10, 18.45s/it]

 54%|█████▍    | 8740/16104 [40:33:37<33:54:37, 16.58s/it]

 54%|█████▍    | 8741/16104 [40:33:57<36:13:38, 17.71s/it]

 54%|█████▍    | 8742/16104 [40:34:17<37:41:43, 18.43s/it]

 54%|█████▍    | 8743/16104 [40:34:37<38:23:26, 18.78s/it]

 54%|█████▍    | 8744/16104 [40:34:55<38:02:34, 18.61s/it]
{'loss': 0.3463, 'learning_rate': 9.096166830370896e-07, 'rewards/chosen': -0.30311745405197144, 'rewards/rejected': -1.7834371328353882, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4803197383880615, 'policy_logps/rejected': -483.2284851074219, 'policy_logps/chosen': -251.39515686035156, 'referece_logps/rejected': -465.3941650390625, 'referece_logps/chosen': -248.36398315429688, 'logits/rejected': -0.07040022313594818, 'logits/chosen': -0.04558270797133446, 'epoch': 3.26}

 54%|█████▍    | 8745/16104 [40:35:10<35:39:39, 17.45s/it]


 54%|█████▍    | 8747/16104 [40:35:35<30:32:36, 14.95s/it]
{'loss': 0.4677, 'learning_rate': 9.090157902539775e-07, 'rewards/chosen': -0.5277870297431946, 'rewards/rejected': -1.3585331439971924, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8307461738586426, 'policy_logps/rejected': -385.5751647949219, 'policy_logps/chosen': -558.3388061523438, 'referece_logps/rejected': -371.98980712890625, 'referece_logps/chosen': -553.0609130859375, 'logits/rejected': -0.03310015797615051, 'logits/chosen': -0.011322736740112305, 'epoch': 3.26}

 54%|█████▍    | 8748/16104 [40:35:46<28:08:53, 13.78s/it]


 54%|█████▍    | 8750/16104 [40:36:19<31:42:16, 15.52s/it]

 54%|█████▍    | 8751/16104 [40:36:36<32:26:39, 15.88s/it]

 54%|█████▍    | 8752/16104 [40:36:56<34:52:59, 17.08s/it]
{'loss': 0.3713, 'learning_rate': 9.080143759996216e-07, 'rewards/chosen': -1.0709260702133179, 'rewards/rejected': -2.5170741081237793, 'rewards/accuracies': 0.625, 'rewards/margins': 1.446148157119751, 'policy_logps/rejected': -505.6023864746094, 'policy_logps/chosen': -512.3282470703125, 'referece_logps/rejected': -480.4316101074219, 'referece_logps/chosen': -501.6189880371094, 'logits/rejected': 0.8282076716423035, 'logits/chosen': 0.7880525588989258, 'epoch': 3.26}

 54%|█████▍    | 8753/16104 [40:37:17<37:18:39, 18.27s/it]

 54%|█████▍    | 8754/16104 [40:37:36<38:07:11, 18.67s/it]

 54%|█████▍    | 8755/16104 [40:37:49<34:12:16, 16.76s/it]

 54%|█████▍    | 8756/16104 [40:38:11<37:26:34, 18.34s/it]

 54%|█████▍    | 8757/16104 [40:38:27<35:53:23, 17.59s/it]


 54%|█████▍    | 8759/16104 [40:38:54<31:19:10, 15.35s/it]

 54%|█████▍    | 8760/16104 [40:39:08<30:21:55, 14.88s/it]

 54%|█████▍    | 8761/16104 [40:39:27<33:11:49, 16.28s/it]

 54%|█████▍    | 8762/16104 [40:39:38<29:51:07, 14.64s/it]
{'loss': 0.4571, 'learning_rate': 9.060118275772155e-07, 'rewards/chosen': -0.1747293472290039, 'rewards/rejected': -1.6430000066757202, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4682706594467163, 'policy_logps/rejected': -411.48663330078125, 'policy_logps/chosen': -434.3212890625, 'referece_logps/rejected': -395.0566711425781, 'referece_logps/chosen': -432.57403564453125, 'logits/rejected': 0.11194582283496857, 'logits/chosen': 0.1878107488155365, 'epoch': 3.26}

 54%|█████▍    | 8763/16104 [40:39:53<29:54:12, 14.66s/it]

 54%|█████▍    | 8764/16104 [40:40:13<33:18:09, 16.33s/it]


 54%|█████▍    | 8766/16104 [40:40:46<33:47:15, 16.58s/it]
{'loss': 0.4425, 'learning_rate': 9.052109142103315e-07, 'rewards/chosen': -0.549574077129364, 'rewards/rejected': -1.8800302743911743, 'rewards/accuracies': 0.875, 'rewards/margins': 1.330456256866455, 'policy_logps/rejected': -234.6002197265625, 'policy_logps/chosen': -433.3194885253906, 'referece_logps/rejected': -215.7999267578125, 'referece_logps/chosen': -427.82373046875, 'logits/rejected': -0.940319836139679, 'logits/chosen': -1.0984083414077759, 'epoch': 3.27}

 54%|█████▍    | 8767/16104 [40:41:03<33:57:14, 16.66s/it]

 54%|█████▍    | 8768/16104 [40:41:23<36:05:51, 17.71s/it]


 54%|█████▍    | 8770/16104 [40:41:57<35:55:57, 17.64s/it]
{'loss': 0.3864, 'learning_rate': 9.044100621936479e-07, 'rewards/chosen': -0.5858880281448364, 'rewards/rejected': -1.4451549053192139, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8592668771743774, 'policy_logps/rejected': -278.03607177734375, 'policy_logps/chosen': -433.6053466796875, 'referece_logps/rejected': -263.58453369140625, 'referece_logps/chosen': -427.74652099609375, 'logits/rejected': 0.3457706868648529, 'logits/chosen': 0.279336541891098, 'epoch': 3.27}

 54%|█████▍    | 8771/16104 [40:42:15<35:52:33, 17.61s/it]


 54%|█████▍    | 8773/16104 [40:42:52<37:23:08, 18.36s/it]
{'loss': 0.3528, 'learning_rate': 9.038094637540154e-07, 'rewards/chosen': -0.4061168432235718, 'rewards/rejected': -1.6611794233322144, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2550625801086426, 'policy_logps/rejected': -362.0605773925781, 'policy_logps/chosen': -534.2252197265625, 'referece_logps/rejected': -345.44879150390625, 'referece_logps/chosen': -530.1641235351562, 'logits/rejected': -0.19332674145698547, 'logits/chosen': -0.2594025433063507, 'epoch': 3.27}


 54%|█████▍    | 8775/16104 [40:43:26<35:40:18, 17.52s/it]

 54%|█████▍    | 8776/16104 [40:43:44<35:35:05, 17.48s/it]

 55%|█████▍    | 8777/16104 [40:43:58<33:36:10, 16.51s/it]

 55%|█████▍    | 8778/16104 [40:44:18<35:45:27, 17.57s/it]
{'loss': 0.5091, 'learning_rate': 9.028085442841759e-07, 'rewards/chosen': -0.16053535044193268, 'rewards/rejected': -0.8698854446411133, 'rewards/accuracies': 0.625, 'rewards/margins': 0.709350049495697, 'policy_logps/rejected': -319.7015380859375, 'policy_logps/chosen': -347.82781982421875, 'referece_logps/rejected': -311.002685546875, 'referece_logps/chosen': -346.22247314453125, 'logits/rejected': 0.0018187034875154495, 'logits/chosen': -0.023613888770341873, 'epoch': 3.27}


 55%|█████▍    | 8780/16104 [40:44:58<38:19:25, 18.84s/it]
{'loss': 0.4148, 'learning_rate': 9.024082039605312e-07, 'rewards/chosen': -0.2406991869211197, 'rewards/rejected': -0.9565629959106445, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7158637642860413, 'policy_logps/rejected': -663.439697265625, 'policy_logps/chosen': -514.8333740234375, 'referece_logps/rejected': -653.8740844726562, 'referece_logps/chosen': -512.4263305664062, 'logits/rejected': 0.292685866355896, 'logits/chosen': 0.3371354341506958, 'epoch': 3.27}


 55%|█████▍    | 8782/16104 [40:45:36<38:16:54, 18.82s/it]
{'loss': 0.4835, 'learning_rate': 9.020078794279358e-07, 'rewards/chosen': -0.41826507449150085, 'rewards/rejected': -1.1476236581802368, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7293585538864136, 'policy_logps/rejected': -370.42120361328125, 'policy_logps/chosen': -373.7630920410156, 'referece_logps/rejected': -358.9449462890625, 'referece_logps/chosen': -369.5804443359375, 'logits/rejected': 0.2332589030265808, 'logits/chosen': 0.07315102964639664, 'epoch': 3.27}

 55%|█████▍    | 8783/16104 [40:45:47<33:38:07, 16.54s/it]


 55%|█████▍    | 8785/16104 [40:46:28<37:34:58, 18.49s/it]
{'loss': 0.4291, 'learning_rate': 9.014074223789549e-07, 'rewards/chosen': -0.7223851680755615, 'rewards/rejected': -1.856031894683838, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1336467266082764, 'policy_logps/rejected': -397.1607360839844, 'policy_logps/chosen': -385.7715759277344, 'referece_logps/rejected': -378.60040283203125, 'referece_logps/chosen': -378.5476989746094, 'logits/rejected': -0.5702950954437256, 'logits/chosen': -0.5623165965080261, 'epoch': 3.27}


 55%|█████▍    | 8787/16104 [40:46:54<31:51:39, 15.68s/it]
{'loss': 0.4284, 'learning_rate': 9.010071376073687e-07, 'rewards/chosen': -0.6973730325698853, 'rewards/rejected': -2.719921588897705, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0225484371185303, 'policy_logps/rejected': -454.8071594238281, 'policy_logps/chosen': -521.02197265625, 'referece_logps/rejected': -427.6079406738281, 'referece_logps/chosen': -514.0482788085938, 'logits/rejected': -0.07097338140010834, 'logits/chosen': 0.003692135214805603, 'epoch': 3.27}

 55%|█████▍    | 8788/16104 [40:47:12<33:14:00, 16.35s/it]

 55%|█████▍    | 8789/16104 [40:47:25<31:27:04, 15.48s/it]

 55%|█████▍    | 8790/16104 [40:47:41<31:51:18, 15.68s/it]


 55%|█████▍    | 8792/16104 [40:48:08<29:16:19, 14.41s/it]
{'loss': 0.3846, 'learning_rate': 9.000064958977421e-07, 'rewards/chosen': -0.669784665107727, 'rewards/rejected': -1.1178815364837646, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4480969309806824, 'policy_logps/rejected': -459.51318359375, 'policy_logps/chosen': -457.7325439453125, 'referece_logps/rejected': -448.3343505859375, 'referece_logps/chosen': -451.03466796875, 'logits/rejected': -0.5087087750434875, 'logits/chosen': -0.32833319902420044, 'epoch': 3.28}

 55%|█████▍    | 8793/16104 [40:48:27<32:24:14, 15.96s/it]


 55%|█████▍    | 8795/16104 [40:49:02<34:40:10, 17.08s/it]

 55%|█████▍    | 8796/16104 [40:49:22<36:22:46, 17.92s/it]

 55%|█████▍    | 8797/16104 [40:49:39<35:20:29, 17.41s/it]
{'loss': 0.4838, 'learning_rate': 8.990059553109992e-07, 'rewards/chosen': 0.2409665584564209, 'rewards/rejected': -1.205777645111084, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4467443227767944, 'policy_logps/rejected': -511.786376953125, 'policy_logps/chosen': -464.174072265625, 'referece_logps/rejected': -499.72857666015625, 'referece_logps/chosen': -466.583740234375, 'logits/rejected': 0.3355295658111572, 'logits/chosen': 0.2833283543586731, 'epoch': 3.28}

 55%|█████▍    | 8798/16104 [40:49:52<32:41:38, 16.11s/it]


 55%|█████▍    | 8800/16104 [40:50:33<37:32:13, 18.50s/it]

 55%|█████▍    | 8801/16104 [40:50:51<37:09:25, 18.32s/it]
{'loss': 0.4426, 'learning_rate': 8.982055963300416e-07, 'rewards/chosen': -0.47159332036972046, 'rewards/rejected': -0.8670023083686829, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3954089879989624, 'policy_logps/rejected': -312.8851318359375, 'policy_logps/chosen': -433.5751647949219, 'referece_logps/rejected': -304.21514892578125, 'referece_logps/chosen': -428.85919189453125, 'logits/rejected': 0.22731149196624756, 'logits/chosen': 0.08318410813808441, 'epoch': 3.28}


 55%|█████▍    | 8803/16104 [40:51:12<29:18:28, 14.45s/it]

 55%|█████▍    | 8804/16104 [40:51:27<29:15:52, 14.43s/it]
{'loss': 0.507, 'learning_rate': 8.976053703025295e-07, 'rewards/chosen': -1.0263948440551758, 'rewards/rejected': -1.462952971458435, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4365581274032593, 'policy_logps/rejected': -312.90240478515625, 'policy_logps/chosen': -422.0199279785156, 'referece_logps/rejected': -298.27288818359375, 'referece_logps/chosen': -411.75592041015625, 'logits/rejected': -0.21350961923599243, 'logits/chosen': -0.08375183492898941, 'epoch': 3.28}


 55%|█████▍    | 8806/16104 [40:51:49<25:49:00, 12.74s/it]

 55%|█████▍    | 8807/16104 [40:52:00<25:04:38, 12.37s/it]

 55%|█████▍    | 8808/16104 [40:52:13<25:11:49, 12.43s/it]

 55%|█████▍    | 8809/16104 [40:52:32<29:13:33, 14.42s/it]

 55%|█████▍    | 8810/16104 [40:52:45<28:04:26, 13.86s/it]

 55%|█████▍    | 8811/16104 [40:53:05<31:47:42, 15.69s/it]

 55%|█████▍    | 8812/16104 [40:53:22<32:57:09, 16.27s/it]

 55%|█████▍    | 8813/16104 [40:53:45<36:45:22, 18.15s/it]

 55%|█████▍    | 8814/16104 [40:53:57<33:08:29, 16.37s/it]
{'loss': 0.4182, 'learning_rate': 8.95604887337837e-07, 'rewards/chosen': -0.16423439979553223, 'rewards/rejected': -2.609269618988037, 'rewards/accuracies': 0.875, 'rewards/margins': 2.445035219192505, 'policy_logps/rejected': -551.5108032226562, 'policy_logps/chosen': -497.4487609863281, 'referece_logps/rejected': -525.4180908203125, 'referece_logps/chosen': -495.806396484375, 'logits/rejected': 0.19222117960453033, 'logits/chosen': 0.315731942653656, 'epoch': 3.28}

 55%|█████▍    | 8815/16104 [40:54:14<33:19:48, 16.46s/it]


 55%|█████▍    | 8817/16104 [40:54:51<35:57:36, 17.77s/it]

 55%|█████▍    | 8818/16104 [40:55:07<34:50:15, 17.21s/it]

 55%|█████▍    | 8819/16104 [40:55:27<36:41:25, 18.13s/it]

 55%|█████▍    | 8820/16104 [40:55:47<37:48:43, 18.69s/it]
{'loss': 0.4333, 'learning_rate': 8.944047997436094e-07, 'rewards/chosen': -0.5296222567558289, 'rewards/rejected': -1.198137879371643, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6685155034065247, 'policy_logps/rejected': -375.47833251953125, 'policy_logps/chosen': -344.9730529785156, 'referece_logps/rejected': -363.4969482421875, 'referece_logps/chosen': -339.6768493652344, 'logits/rejected': -0.1724814474582672, 'logits/chosen': -0.18244504928588867, 'epoch': 3.29}


 55%|█████▍    | 8822/16104 [40:56:21<36:27:55, 18.03s/it]
{'loss': 0.4624, 'learning_rate': 8.940048046313469e-07, 'rewards/chosen': -0.5877359509468079, 'rewards/rejected': -2.473710298538208, 'rewards/accuracies': 1.0, 'rewards/margins': 1.885974407196045, 'policy_logps/rejected': -493.3965759277344, 'policy_logps/chosen': -406.793212890625, 'referece_logps/rejected': -468.65948486328125, 'referece_logps/chosen': -400.91583251953125, 'logits/rejected': -0.25650686025619507, 'logits/chosen': -0.22533626854419708, 'epoch': 3.29}


 55%|█████▍    | 8824/16104 [40:56:59<37:33:14, 18.57s/it]
{'loss': 0.4253, 'learning_rate': 8.93604826669863e-07, 'rewards/chosen': -0.6961960196495056, 'rewards/rejected': -1.4813560247421265, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7851600050926208, 'policy_logps/rejected': -453.4609069824219, 'policy_logps/chosen': -351.8974609375, 'referece_logps/rejected': -438.6473693847656, 'referece_logps/chosen': -344.935546875, 'logits/rejected': -0.11948470771312714, 'logits/chosen': 0.0223553329706192, 'epoch': 3.29}


 55%|█████▍    | 8826/16104 [40:57:35<36:27:02, 18.03s/it]
{'loss': 0.3341, 'learning_rate': 8.932048659238779e-07, 'rewards/chosen': -0.33131763339042664, 'rewards/rejected': -1.6271597146987915, 'rewards/accuracies': 0.75, 'rewards/margins': 1.295842170715332, 'policy_logps/rejected': -316.4862060546875, 'policy_logps/chosen': -301.8190612792969, 'referece_logps/rejected': -300.2146301269531, 'referece_logps/chosen': -298.505859375, 'logits/rejected': 0.28610533475875854, 'logits/chosen': 0.3414999842643738, 'epoch': 3.29}

 55%|█████▍    | 8827/16104 [40:57:48<33:39:59, 16.66s/it]

 55%|█████▍    | 8828/16104 [40:58:00<30:37:02, 15.15s/it]


 55%|█████▍    | 8830/16104 [40:58:35<33:51:39, 16.76s/it]

 55%|█████▍    | 8831/16104 [40:58:47<31:11:17, 15.44s/it]

 55%|█████▍    | 8832/16104 [40:59:07<34:06:19, 16.88s/it]
{'loss': 0.4439, 'learning_rate': 8.920050876260629e-07, 'rewards/chosen': -0.5649470090866089, 'rewards/rejected': -1.266463041305542, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7015160322189331, 'policy_logps/rejected': -547.708251953125, 'policy_logps/chosen': -528.15283203125, 'referece_logps/rejected': -535.0435791015625, 'referece_logps/chosen': -522.50341796875, 'logits/rejected': -0.10531294345855713, 'logits/chosen': -0.15498118102550507, 'epoch': 3.29}

 55%|█████▍    | 8833/16104 [40:59:29<36:43:14, 18.18s/it]


 55%|█████▍    | 8835/16104 [40:59:59<34:01:24, 16.85s/it]
{'loss': 0.5393, 'learning_rate': 8.914052573438814e-07, 'rewards/chosen': -0.3306935429573059, 'rewards/rejected': -1.3294885158538818, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9987950325012207, 'policy_logps/rejected': -437.35052490234375, 'policy_logps/chosen': -449.71026611328125, 'referece_logps/rejected': -424.05560302734375, 'referece_logps/chosen': -446.40338134765625, 'logits/rejected': -0.3375423550605774, 'logits/chosen': -0.3864573836326599, 'epoch': 3.29}

 55%|█████▍    | 8836/16104 [41:00:20<36:08:44, 17.90s/it]

 55%|█████▍    | 8837/16104 [41:00:41<37:53:45, 18.77s/it]

 55%|█████▍    | 8838/16104 [41:00:52<33:44:11, 16.72s/it]

 55%|█████▍    | 8839/16104 [41:01:12<35:26:48, 17.56s/it]

 55%|█████▍    | 8840/16104 [41:01:30<35:29:42, 17.59s/it]


 55%|█████▍    | 8842/16104 [41:02:01<34:35:03, 17.14s/it]
{'loss': 0.3117, 'learning_rate': 8.900058074793258e-07, 'rewards/chosen': 0.06293391436338425, 'rewards/rejected': -1.1170730590820312, 'rewards/accuracies': 0.875, 'rewards/margins': 1.180006980895996, 'policy_logps/rejected': -533.0400390625, 'policy_logps/chosen': -456.8427429199219, 'referece_logps/rejected': -521.8692626953125, 'referece_logps/chosen': -457.47210693359375, 'logits/rejected': 0.6314904093742371, 'logits/chosen': 0.6086894273757935, 'epoch': 3.29}

 55%|█████▍    | 8843/16104 [41:02:14<31:39:55, 15.70s/it]

 55%|█████▍    | 8844/16104 [41:02:24<28:40:11, 14.22s/it]


 55%|█████▍    | 8846/16104 [41:02:57<31:26:22, 15.59s/it]
{'loss': 0.5121, 'learning_rate': 8.892062195526709e-07, 'rewards/chosen': -0.15246781706809998, 'rewards/rejected': -1.5740147829055786, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4215469360351562, 'policy_logps/rejected': -365.8467102050781, 'policy_logps/chosen': -445.78875732421875, 'referece_logps/rejected': -350.1065673828125, 'referece_logps/chosen': -444.26409912109375, 'logits/rejected': 0.07015734910964966, 'logits/chosen': 0.12342353165149689, 'epoch': 3.3}

 55%|█████▍    | 8847/16104 [41:03:10<29:46:01, 14.77s/it]

 55%|█████▍    | 8848/16104 [41:03:21<27:24:17, 13.60s/it]


 55%|█████▍    | 8850/16104 [41:03:45<26:07:35, 12.97s/it]
{'loss': 0.5231, 'learning_rate': 8.884067033349108e-07, 'rewards/chosen': 0.11195296794176102, 'rewards/rejected': -0.19041499495506287, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3023679852485657, 'policy_logps/rejected': -605.9293823242188, 'policy_logps/chosen': -575.2852783203125, 'referece_logps/rejected': -604.0252685546875, 'referece_logps/chosen': -576.40478515625, 'logits/rejected': 0.3111022114753723, 'logits/chosen': 0.34173154830932617, 'epoch': 3.3}

 55%|█████▍    | 8851/16104 [41:04:03<28:41:26, 14.24s/it]

 55%|█████▍    | 8852/16104 [41:04:21<31:03:18, 15.42s/it]

 55%|█████▍    | 8853/16104 [41:04:40<33:31:18, 16.64s/it]

 55%|█████▍    | 8854/16104 [41:04:56<32:57:01, 16.36s/it]

 55%|█████▍    | 8855/16104 [41:05:10<31:28:15, 15.63s/it]


 55%|█████▍    | 8857/16104 [41:05:44<31:59:27, 15.89s/it]
{'loss': 0.5096, 'learning_rate': 8.870077240597828e-07, 'rewards/chosen': -1.0021860599517822, 'rewards/rejected': -1.4513802528381348, 'rewards/accuracies': 0.75, 'rewards/margins': 0.44919419288635254, 'policy_logps/rejected': -304.2308349609375, 'policy_logps/chosen': -292.0865478515625, 'referece_logps/rejected': -289.717041015625, 'referece_logps/chosen': -282.0646667480469, 'logits/rejected': -0.393866628408432, 'logits/chosen': -0.2694542407989502, 'epoch': 3.3}

 55%|█████▌    | 8858/16104 [41:05:57<30:25:08, 15.11s/it]

 55%|█████▌    | 8859/16104 [41:06:11<29:45:52, 14.79s/it]

 55%|█████▌    | 8860/16104 [41:06:28<31:09:59, 15.49s/it]


 55%|█████▌    | 8862/16104 [41:06:54<28:26:22, 14.14s/it]
{'loss': 0.3712, 'learning_rate': 8.860085901094594e-07, 'rewards/chosen': -0.2143680602312088, 'rewards/rejected': -1.647284984588623, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4329169988632202, 'policy_logps/rejected': -483.8193359375, 'policy_logps/chosen': -432.4966125488281, 'referece_logps/rejected': -467.34649658203125, 'referece_logps/chosen': -430.35296630859375, 'logits/rejected': -0.09686879068613052, 'logits/chosen': 0.04741286486387253, 'epoch': 3.3}

 55%|█████▌    | 8863/16104 [41:07:13<31:50:31, 15.83s/it]


 55%|█████▌    | 8865/16104 [41:07:52<35:47:48, 17.80s/it]

 55%|█████▌    | 8866/16104 [41:08:12<37:01:28, 18.42s/it]

 55%|█████▌    | 8867/16104 [41:08:34<39:17:51, 19.55s/it]
{'loss': 0.4551, 'learning_rate': 8.850095714380254e-07, 'rewards/chosen': -1.0210055112838745, 'rewards/rejected': -2.3262314796447754, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3052259683609009, 'policy_logps/rejected': -521.9835205078125, 'policy_logps/chosen': -319.4433898925781, 'referece_logps/rejected': -498.72119140625, 'referece_logps/chosen': -309.23333740234375, 'logits/rejected': -0.7183643579483032, 'logits/chosen': -0.426266610622406, 'epoch': 3.3}


 55%|█████▌    | 8869/16104 [41:09:00<32:13:59, 16.04s/it]
{'loss': 0.3305, 'learning_rate': 8.846099964738524e-07, 'rewards/chosen': -0.2754614055156708, 'rewards/rejected': -1.5360472202301025, 'rewards/accuracies': 1.0, 'rewards/margins': 1.260585904121399, 'policy_logps/rejected': -298.14886474609375, 'policy_logps/chosen': -429.0865783691406, 'referece_logps/rejected': -282.78839111328125, 'referece_logps/chosen': -426.33203125, 'logits/rejected': -0.293739378452301, 'logits/chosen': -0.26659417152404785, 'epoch': 3.3}


 55%|█████▌    | 8871/16104 [41:09:34<33:23:27, 16.62s/it]
{'loss': 0.4283, 'learning_rate': 8.84210440180605e-07, 'rewards/chosen': -0.9702333211898804, 'rewards/rejected': -2.158419609069824, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1881862878799438, 'policy_logps/rejected': -535.7481689453125, 'policy_logps/chosen': -451.6203308105469, 'referece_logps/rejected': -514.1639404296875, 'referece_logps/chosen': -441.91796875, 'logits/rejected': -0.7472541928291321, 'logits/chosen': -0.8476252555847168, 'epoch': 3.31}

 55%|█████▌    | 8872/16104 [41:09:55<36:32:05, 18.19s/it]


 55%|█████▌    | 8874/16104 [41:10:26<33:17:08, 16.57s/it]
{'loss': 0.4651, 'learning_rate': 8.836111408901441e-07, 'rewards/chosen': -0.21940863132476807, 'rewards/rejected': -1.939252257347107, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7198436260223389, 'policy_logps/rejected': -349.5787048339844, 'policy_logps/chosen': -512.2901611328125, 'referece_logps/rejected': -330.1861877441406, 'referece_logps/chosen': -510.0960998535156, 'logits/rejected': -0.6941863894462585, 'logits/chosen': -0.6670010089874268, 'epoch': 3.31}

 55%|█████▌    | 8875/16104 [41:10:41<32:27:50, 16.17s/it]

 55%|█████▌    | 8876/16104 [41:11:01<34:41:10, 17.28s/it]

 55%|█████▌    | 8877/16104 [41:11:13<31:24:02, 15.64s/it]

 55%|█████▌    | 8878/16104 [41:11:29<31:25:18, 15.65s/it]

 55%|█████▌    | 8879/16104 [41:11:50<34:28:39, 17.18s/it]

 55%|█████▌    | 8880/16104 [41:12:02<31:24:03, 15.65s/it]

 55%|█████▌    | 8881/16104 [41:12:13<28:37:42, 14.27s/it]


 55%|█████▌    | 8883/16104 [41:12:40<27:33:36, 13.74s/it]
{'loss': 0.4907, 'learning_rate': 8.818134981308163e-07, 'rewards/chosen': -0.42125797271728516, 'rewards/rejected': -2.5160090923309326, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0947511196136475, 'policy_logps/rejected': -368.1792297363281, 'policy_logps/chosen': -646.9157104492188, 'referece_logps/rejected': -343.0191650390625, 'referece_logps/chosen': -642.7030639648438, 'logits/rejected': -0.10432815551757812, 'logits/chosen': -0.1510583907365799, 'epoch': 3.31}

 55%|█████▌    | 8884/16104 [41:12:53<26:56:19, 13.43s/it]

 55%|█████▌    | 8885/16104 [41:13:11<30:00:06, 14.96s/it]

 55%|█████▌    | 8886/16104 [41:13:31<33:08:24, 16.53s/it]


 55%|█████▌    | 8888/16104 [41:14:08<34:45:36, 17.34s/it]

 55%|█████▌    | 8889/16104 [41:14:26<35:01:43, 17.48s/it]
{'loss': 0.4558, 'learning_rate': 8.806152843994732e-07, 'rewards/chosen': -0.6493753790855408, 'rewards/rejected': -2.1288819313049316, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4795067310333252, 'policy_logps/rejected': -407.2732849121094, 'policy_logps/chosen': -426.520263671875, 'referece_logps/rejected': -385.9844665527344, 'referece_logps/chosen': -420.0264892578125, 'logits/rejected': 0.14048519730567932, 'logits/chosen': 0.10151667147874832, 'epoch': 3.31}


 55%|█████▌    | 8891/16104 [41:14:56<32:51:28, 16.40s/it]
{'loss': 0.2989, 'learning_rate': 8.802159183707911e-07, 'rewards/chosen': -0.21555404365062714, 'rewards/rejected': -2.1963725090026855, 'rewards/accuracies': 1.0, 'rewards/margins': 1.980818510055542, 'policy_logps/rejected': -537.0020141601562, 'policy_logps/chosen': -555.2434692382812, 'referece_logps/rejected': -515.0382690429688, 'referece_logps/chosen': -553.087890625, 'logits/rejected': -0.34808114171028137, 'logits/chosen': -0.2413344830274582, 'epoch': 3.31}

 55%|█████▌    | 8892/16104 [41:15:18<35:44:14, 17.84s/it]


 55%|█████▌    | 8894/16104 [41:15:54<36:33:33, 18.25s/it]

 55%|█████▌    | 8895/16104 [41:16:14<37:21:12, 18.65s/it]
{'loss': 0.3768, 'learning_rate': 8.794172445238017e-07, 'rewards/chosen': -0.25321656465530396, 'rewards/rejected': -1.424514889717102, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1712982654571533, 'policy_logps/rejected': -477.5003356933594, 'policy_logps/chosen': -423.4082946777344, 'referece_logps/rejected': -463.2552490234375, 'referece_logps/chosen': -420.8761291503906, 'logits/rejected': -0.08334170281887054, 'logits/chosen': -0.02715342305600643, 'epoch': 3.31}

 55%|█████▌    | 8896/16104 [41:16:30<35:43:32, 17.84s/it]

 55%|█████▌    | 8897/16104 [41:16:52<38:04:02, 19.02s/it]

 55%|█████▌    | 8898/16104 [41:17:13<39:28:33, 19.72s/it]

 55%|█████▌    | 8899/16104 [41:17:31<38:18:49, 19.14s/it]


 55%|█████▌    | 8901/16104 [41:18:02<34:00:22, 17.00s/it]

 55%|█████▌    | 8902/16104 [41:18:22<35:50:20, 17.91s/it]
{'loss': 0.3578, 'learning_rate': 8.780197533973189e-07, 'rewards/chosen': -1.2944203615188599, 'rewards/rejected': -2.6436190605163574, 'rewards/accuracies': 0.875, 'rewards/margins': 1.349198579788208, 'policy_logps/rejected': -386.94683837890625, 'policy_logps/chosen': -460.2948303222656, 'referece_logps/rejected': -360.51068115234375, 'referece_logps/chosen': -447.35064697265625, 'logits/rejected': -0.07612939178943634, 'logits/chosen': -0.17826935648918152, 'epoch': 3.32}


 55%|█████▌    | 8904/16104 [41:19:01<37:25:00, 18.71s/it]

 55%|█████▌    | 8905/16104 [41:19:16<35:41:02, 17.84s/it]
{'loss': 0.4444, 'learning_rate': 8.774209024820935e-07, 'rewards/chosen': -0.17485103011131287, 'rewards/rejected': -1.6343940496444702, 'rewards/accuracies': 0.75, 'rewards/margins': 1.459542989730835, 'policy_logps/rejected': -343.7577209472656, 'policy_logps/chosen': -597.9861450195312, 'referece_logps/rejected': -327.4137878417969, 'referece_logps/chosen': -596.2376098632812, 'logits/rejected': -0.2561541795730591, 'logits/chosen': -0.19330823421478271, 'epoch': 3.32}


 55%|█████▌    | 8907/16104 [41:19:52<35:26:50, 17.73s/it]
{'loss': 0.4671, 'learning_rate': 8.77021693317868e-07, 'rewards/chosen': -0.35394608974456787, 'rewards/rejected': -1.5427478551864624, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1888017654418945, 'policy_logps/rejected': -368.05426025390625, 'policy_logps/chosen': -440.55908203125, 'referece_logps/rejected': -352.62677001953125, 'referece_logps/chosen': -437.0196228027344, 'logits/rejected': -0.14017881453037262, 'logits/chosen': -0.13218998908996582, 'epoch': 3.32}

 55%|█████▌    | 8908/16104 [41:20:09<34:55:21, 17.47s/it]

 55%|█████▌    | 8909/16104 [41:20:28<35:44:27, 17.88s/it]

 55%|█████▌    | 8910/16104 [41:20:39<31:34:46, 15.80s/it]


 55%|█████▌    | 8912/16104 [41:21:19<35:42:06, 17.87s/it]
{'loss': 0.4716, 'learning_rate': 8.760237576057064e-07, 'rewards/chosen': -0.11921528726816177, 'rewards/rejected': -1.7628679275512695, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6436525583267212, 'policy_logps/rejected': -496.5372314453125, 'policy_logps/chosen': -396.4507141113281, 'referece_logps/rejected': -478.9085693359375, 'referece_logps/chosen': -395.2585754394531, 'logits/rejected': 0.37015360593795776, 'logits/chosen': 0.28258246183395386, 'epoch': 3.32}


 55%|█████▌    | 8914/16104 [41:21:54<35:06:14, 17.58s/it]

 55%|█████▌    | 8915/16104 [41:22:07<32:04:44, 16.06s/it]

 55%|█████▌    | 8916/16104 [41:22:25<33:10:27, 16.61s/it]

 55%|█████▌    | 8917/16104 [41:22:38<31:23:10, 15.72s/it]

 55%|█████▌    | 8918/16104 [41:22:59<34:10:02, 17.12s/it]
{'loss': 0.474, 'learning_rate': 8.748264003368882e-07, 'rewards/chosen': -1.1661629676818848, 'rewards/rejected': -1.7692731618881226, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6031103134155273, 'policy_logps/rejected': -433.44873046875, 'policy_logps/chosen': -478.7877197265625, 'referece_logps/rejected': -415.7560729980469, 'referece_logps/chosen': -467.1260986328125, 'logits/rejected': -0.009398696012794971, 'logits/chosen': -0.01090245507657528, 'epoch': 3.32}

 55%|█████▌    | 8919/16104 [41:23:17<35:02:07, 17.55s/it]


 55%|█████▌    | 8921/16104 [41:23:51<33:11:29, 16.64s/it]
{'loss': 0.433, 'learning_rate': 8.742277899506914e-07, 'rewards/chosen': 0.3188430666923523, 'rewards/rejected': -1.068372130393982, 'rewards/accuracies': 1.0, 'rewards/margins': 1.387215256690979, 'policy_logps/rejected': -557.4591064453125, 'policy_logps/chosen': -495.35540771484375, 'referece_logps/rejected': -546.775390625, 'referece_logps/chosen': -498.5438232421875, 'logits/rejected': -0.06145533174276352, 'logits/chosen': 0.023147881031036377, 'epoch': 3.32}

 55%|█████▌    | 8922/16104 [41:24:07<33:15:34, 16.67s/it]


 55%|█████▌    | 8924/16104 [41:24:31<28:02:05, 14.06s/it]
{'loss': 0.442, 'learning_rate': 8.736292253538861e-07, 'rewards/chosen': -0.2220296859741211, 'rewards/rejected': -1.2596255540847778, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0375958681106567, 'policy_logps/rejected': -479.67510986328125, 'policy_logps/chosen': -424.548583984375, 'referece_logps/rejected': -467.078857421875, 'referece_logps/chosen': -422.3282775878906, 'logits/rejected': -0.5050829648971558, 'logits/chosen': -0.3163495361804962, 'epoch': 3.32}

 55%|█████▌    | 8925/16104 [41:24:52<32:15:40, 16.18s/it]

 55%|█████▌    | 8926/16104 [41:25:11<34:14:34, 17.17s/it]

 55%|█████▌    | 8927/16104 [41:25:31<35:44:48, 17.93s/it]

 55%|█████▌    | 8928/16104 [41:25:50<36:17:18, 18.20s/it]

 55%|█████▌    | 8929/16104 [41:26:10<37:16:38, 18.70s/it]

 55%|█████▌    | 8930/16104 [41:26:28<36:59:50, 18.57s/it]

 55%|█████▌    | 8931/16104 [41:26:42<34:36:43, 17.37s/it]

 55%|█████▌    | 8932/16104 [41:27:02<35:45:21, 17.95s/it]

 55%|█████▌    | 8933/16104 [41:27:15<33:01:20, 16.58s/it]

 55%|█████▌    | 8934/16104 [41:27:28<30:47:47, 15.46s/it]

 55%|█████▌    | 8935/16104 [41:27:39<27:56:26, 14.03s/it]

 55%|█████▌    | 8936/16104 [41:27:59<31:36:33, 15.88s/it]

 55%|█████▌    | 8937/16104 [41:28:17<32:39:26, 16.40s/it]

 56%|█████▌    | 8938/16104 [41:28:29<30:07:04, 15.13s/it]

 56%|█████▌    | 8939/16104 [41:28:40<27:45:10, 13.94s/it]

 56%|█████▌    | 8940/16104 [41:28:52<26:28:35, 13.30s/it]

 56%|█████▌    | 8941/16104 [41:29:11<30:08:17, 15.15s/it]

 56%|█████▌    | 8942/16104 [41:29:22<27:36:30, 13.88s/it]

 56%|█████▌    | 8943/16104 [41:29:42<30:58:41, 15.57s/it]

 56%|█████▌    | 8944/16104 [41:29:59<32:22:06, 16.27s/it]

 56%|█████▌    | 8945/16104 [41:30:15<31:47:48, 15.99s/it]

 56%|█████▌    | 8946/16104 [41:30:35<34:29:44, 17.35s/it]

 56%|█████▌    | 8947/16104 [41:30:54<35:07:54, 17.67s/it]

 56%|█████▌    | 8948/16104 [41:31:12<35:23:42, 17.81s/it]

 56%|█████▌    | 8949/16104 [41:31:25<32:41:24, 16.45s/it]

 56%|█████▌    | 8950/16104 [41:31:45<34:58:21, 17.60s/it]

 56%|█████▌    | 8951/16104 [41:32:06<36:45:12, 18.50s/it]

 56%|█████▌    | 8952/16104 [41:32:25<37:08:49, 18.70s/it]

 56%|█████▌    | 8953/16104 [41:32:42<35:46:41, 18.01s/it]

 56%|█████▌    | 8954/16104 [41:32:58<34:46:29, 17.51s/it]

 56%|█████▌    | 8955/16104 [41:33:18<36:19:11, 18.29s/it]

 56%|█████▌    | 8956/16104 [41:33:38<37:24:58, 18.84s/it]

 56%|█████▌    | 8957/16104 [41:33:58<38:17:14, 19.29s/it]

 56%|█████▌    | 8958/16104 [41:34:19<38:53:46, 19.60s/it]

 56%|█████▌    | 8959/16104 [41:34:34<36:31:03, 18.40s/it]

 56%|█████▌    | 8960/16104 [41:34:56<38:12:59, 19.26s/it]

 56%|█████▌    | 8961/16104 [41:35:06<33:03:47, 16.66s/it]

 56%|█████▌    | 8962/16104 [41:35:20<31:35:30, 15.92s/it]

 56%|█████▌    | 8963/16104 [41:35:32<28:48:14, 14.52s/it]

 56%|█████▌    | 8964/16104 [41:35:44<27:30:43, 13.87s/it]

 56%|█████▌    | 8965/16104 [41:35:56<26:12:26, 13.22s/it]

 56%|█████▌    | 8966/16104 [41:36:06<24:43:12, 12.47s/it]

 56%|█████▌    | 8967/16104 [41:36:17<23:48:26, 12.01s/it]

 56%|█████▌    | 8968/16104 [41:36:34<26:15:40, 13.25s/it]

 56%|█████▌    | 8969/16104 [41:36:51<28:55:53, 14.60s/it]

 56%|█████▌    | 8970/16104 [41:37:11<31:51:39, 16.08s/it]

 56%|█████▌    | 8971/16104 [41:37:26<31:33:56, 15.93s/it]

 56%|█████▌    | 8972/16104 [41:37:40<29:53:18, 15.09s/it]

 56%|█████▌    | 8973/16104 [41:37:59<32:22:20, 16.34s/it]

 56%|█████▌    | 8974/16104 [41:38:17<33:10:13, 16.75s/it]

 56%|█████▌    | 8975/16104 [41:38:35<34:15:35, 17.30s/it]

 56%|█████▌    | 8976/16104 [41:38:55<35:34:47, 17.97s/it]

 56%|█████▌    | 8977/16104 [41:39:10<33:53:39, 17.12s/it]

 56%|█████▌    | 8978/16104 [41:39:23<31:23:00, 15.85s/it]

 56%|█████▌    | 8979/16104 [41:39:44<34:36:34, 17.49s/it]

 56%|█████▌    | 8980/16104 [41:40:04<35:51:13, 18.12s/it]

 56%|█████▌    | 8981/16104 [41:40:22<35:47:47, 18.09s/it]

 56%|█████▌    | 8982/16104 [41:40:41<36:29:29, 18.45s/it]

 56%|█████▌    | 8983/16104 [41:40:53<32:49:06, 16.59s/it]

 56%|█████▌    | 8984/16104 [41:41:09<32:33:59, 16.47s/it]

 56%|█████▌    | 8985/16104 [41:41:29<34:21:08, 17.37s/it]

 56%|█████▌    | 8986/16104 [41:41:48<35:35:10, 18.00s/it]

 56%|█████▌    | 8987/16104 [41:42:00<31:40:04, 16.02s/it]

 56%|█████▌    | 8988/16104 [41:42:13<30:19:07, 15.34s/it]

 56%|█████▌    | 8989/16104 [41:42:30<30:48:51, 15.59s/it]

 56%|█████▌    | 8990/16104 [41:42:43<29:25:46, 14.89s/it]

 56%|█████▌    | 8991/16104 [41:42:57<28:53:48, 14.63s/it]

 56%|█████▌    | 8992/16104 [41:43:11<28:38:23, 14.50s/it]

 56%|█████▌    | 8993/16104 [41:43:29<30:26:58, 15.42s/it]

 56%|█████▌    | 8994/16104 [41:43:44<30:26:31, 15.41s/it]

 56%|█████▌    | 8995/16104 [41:44:01<31:20:31, 15.87s/it]

 56%|█████▌    | 8996/16104 [41:44:17<31:18:19, 15.86s/it]

 56%|█████▌    | 8997/16104 [41:44:35<32:50:12, 16.63s/it]

 56%|█████▌    | 8998/16104 [41:44:50<31:31:08, 15.97s/it]

 56%|█████▌    | 8999/16104 [41:45:00<28:26:58, 14.42s/it]

 56%|█████▌    | 9000/16104 [41:45:11<26:24:03, 13.38s/it]


 56%|█████▌    | 9002/16104 [41:46:05<38:47:26, 19.66s/it]

 56%|█████▌    | 9003/16104 [41:46:25<38:40:18, 19.61s/it]

 56%|█████▌    | 9004/16104 [41:46:43<37:35:34, 19.06s/it]

 56%|█████▌    | 9005/16104 [41:47:05<39:14:38, 19.90s/it]

 56%|█████▌    | 9006/16104 [41:47:23<38:11:02, 19.37s/it]

 56%|█████▌    | 9007/16104 [41:47:34<33:25:52, 16.96s/it]

 56%|█████▌    | 9008/16104 [41:47:54<34:58:06, 17.74s/it]

 56%|█████▌    | 9009/16104 [41:48:13<35:55:28, 18.23s/it]

 56%|█████▌    | 9010/16104 [41:48:33<36:45:10, 18.65s/it]

 56%|█████▌    | 9011/16104 [41:48:55<38:42:50, 19.65s/it]

 56%|█████▌    | 9012/16104 [41:49:12<37:19:51, 18.95s/it]

 56%|█████▌    | 9013/16104 [41:49:31<37:41:10, 19.13s/it]

 56%|█████▌    | 9014/16104 [41:49:49<36:30:32, 18.54s/it]

 56%|█████▌    | 9015/16104 [41:50:11<38:42:36, 19.66s/it]

 56%|█████▌    | 9016/16104 [41:50:30<38:22:15, 19.49s/it]

 56%|█████▌    | 9017/16104 [41:50:41<33:25:24, 16.98s/it]

 56%|█████▌    | 9018/16104 [41:51:02<35:35:15, 18.08s/it]

 56%|█████▌    | 9019/16104 [41:51:22<36:34:45, 18.59s/it]

 56%|█████▌    | 9020/16104 [41:51:38<35:23:12, 17.98s/it]

 56%|█████▌    | 9021/16104 [41:51:56<35:11:20, 17.89s/it]

 56%|█████▌    | 9022/16104 [41:52:15<36:13:54, 18.42s/it]

 56%|█████▌    | 9023/16104 [41:52:32<34:51:58, 17.73s/it]

 56%|█████▌    | 9024/16104 [41:52:44<31:52:49, 16.21s/it]

 56%|█████▌    | 9025/16104 [41:53:04<33:52:20, 17.23s/it]

 56%|█████▌    | 9026/16104 [41:53:19<32:57:43, 16.77s/it]

 56%|█████▌    | 9027/16104 [41:53:38<33:49:15, 17.20s/it]

 56%|█████▌    | 9028/16104 [41:53:50<31:05:24, 15.82s/it]

 56%|█████▌    | 9029/16104 [41:54:06<31:06:30, 15.83s/it]

 56%|█████▌    | 9030/16104 [41:54:17<28:26:06, 14.47s/it]

 56%|█████▌    | 9031/16104 [41:54:37<31:22:45, 15.97s/it]

 56%|█████▌    | 9032/16104 [41:54:55<32:24:49, 16.50s/it]

 56%|█████▌    | 9033/16104 [41:55:13<33:45:47, 17.19s/it]

 56%|█████▌    | 9034/16104 [41:55:28<31:55:56, 16.26s/it]
{'loss': 0.3797, 'learning_rate': 8.517154151196548e-07, 'rewards/chosen': -0.6461685299873352, 'rewards/rejected': -1.9367313385009766, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2905628681182861, 'policy_logps/rejected': -677.2733154296875, 'policy_logps/chosen': -335.32916259765625, 'referece_logps/rejected': -657.9060668945312, 'referece_logps/chosen': -328.86749267578125, 'logits/rejected': -0.9150306582450867, 'logits/chosen': -0.679810106754303, 'epoch': 3.37}


 56%|█████▌    | 9036/16104 [41:55:54<29:25:12, 14.98s/it]

 56%|█████▌    | 9037/16104 [41:56:10<29:36:04, 15.08s/it]

 56%|█████▌    | 9038/16104 [41:56:23<28:13:59, 14.38s/it]

 56%|█████▌    | 9039/16104 [41:56:35<26:54:14, 13.71s/it]

 56%|█████▌    | 9040/16104 [41:56:46<25:20:08, 12.91s/it]

 56%|█████▌    | 9041/16104 [41:57:06<29:38:41, 15.11s/it]

 56%|█████▌    | 9042/16104 [41:57:17<27:03:02, 13.79s/it]
{'loss': 0.51, 'learning_rate': 8.501243854734856e-07, 'rewards/chosen': -0.5444375872612, 'rewards/rejected': -2.3675920963287354, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8231545686721802, 'policy_logps/rejected': -313.1650085449219, 'policy_logps/chosen': -374.09552001953125, 'referece_logps/rejected': -289.4891052246094, 'referece_logps/chosen': -368.6511535644531, 'logits/rejected': -0.5807325839996338, 'logits/chosen': -0.5120810270309448, 'epoch': 3.37}

 56%|█████▌    | 9043/16104 [41:57:29<26:29:04, 13.50s/it]

 56%|█████▌    | 9044/16104 [41:57:45<27:47:28, 14.17s/it]


 56%|█████▌    | 9046/16104 [41:58:13<27:26:18, 14.00s/it]

 56%|█████▌    | 9047/16104 [41:58:32<30:38:03, 15.63s/it]

 56%|█████▌    | 9048/16104 [41:58:45<28:48:17, 14.70s/it]

 56%|█████▌    | 9049/16104 [41:58:59<28:10:03, 14.37s/it]

 56%|█████▌    | 9050/16104 [41:59:10<26:39:52, 13.61s/it]
{'loss': 0.3947, 'learning_rate': 8.485337438423423e-07, 'rewards/chosen': -0.5252321362495422, 'rewards/rejected': -2.4867453575134277, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9615131616592407, 'policy_logps/rejected': -472.4433288574219, 'policy_logps/chosen': -412.3829040527344, 'referece_logps/rejected': -447.57586669921875, 'referece_logps/chosen': -407.130615234375, 'logits/rejected': 0.10303106904029846, 'logits/chosen': 0.07911849766969681, 'epoch': 3.37}


 56%|█████▌    | 9052/16104 [41:59:48<32:03:39, 16.37s/it]
{'loss': 0.422, 'learning_rate': 8.481361445445086e-07, 'rewards/chosen': -0.3749113082885742, 'rewards/rejected': -1.480003833770752, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1050925254821777, 'policy_logps/rejected': -440.2119140625, 'policy_logps/chosen': -707.957763671875, 'referece_logps/rejected': -425.411865234375, 'referece_logps/chosen': -704.2086181640625, 'logits/rejected': 0.399288535118103, 'logits/chosen': 0.33298924565315247, 'epoch': 3.37}


 56%|█████▌    | 9054/16104 [42:00:24<33:29:29, 17.10s/it]
{'loss': 0.5208, 'learning_rate': 8.477385698193303e-07, 'rewards/chosen': -0.5993673205375671, 'rewards/rejected': -0.005078226327896118, 'rewards/accuracies': 0.125, 'rewards/margins': -0.5942891240119934, 'policy_logps/rejected': -380.3687744140625, 'policy_logps/chosen': -389.3248291015625, 'referece_logps/rejected': -380.3179931640625, 'referece_logps/chosen': -383.3311462402344, 'logits/rejected': -0.3551991581916809, 'logits/chosen': -0.30083340406417847, 'epoch': 3.37}


 56%|█████▌    | 9056/16104 [42:00:56<32:49:22, 16.77s/it]
{'loss': 0.432, 'learning_rate': 8.473410197311384e-07, 'rewards/chosen': -0.6897023916244507, 'rewards/rejected': -1.1353495121002197, 'rewards/accuracies': 0.625, 'rewards/margins': 0.44564715027809143, 'policy_logps/rejected': -453.5766296386719, 'policy_logps/chosen': -409.4433898925781, 'referece_logps/rejected': -442.2231140136719, 'referece_logps/chosen': -402.5463562011719, 'logits/rejected': 0.41241782903671265, 'logits/chosen': 0.5075951814651489, 'epoch': 3.37}


 56%|█████▌    | 9058/16104 [42:01:18<26:54:48, 13.75s/it]

 56%|█████▋    | 9059/16104 [42:01:31<26:09:43, 13.37s/it]

 56%|█████▋    | 9060/16104 [42:01:50<29:49:59, 15.25s/it]
{'loss': 0.63, 'learning_rate': 8.465459937230132e-07, 'rewards/chosen': -1.1626113653182983, 'rewards/rejected': -0.9535037875175476, 'rewards/accuracies': 0.5, 'rewards/margins': -0.20910757780075073, 'policy_logps/rejected': -350.5112609863281, 'policy_logps/chosen': -381.8285827636719, 'referece_logps/rejected': -340.97625732421875, 'referece_logps/chosen': -370.2025146484375, 'logits/rejected': -1.0053192377090454, 'logits/chosen': -1.0780889987945557, 'epoch': 3.38}


 56%|█████▋    | 9062/16104 [42:02:23<31:45:27, 16.24s/it]

 56%|█████▋    | 9063/16104 [42:02:43<33:25:43, 17.09s/it]

 56%|█████▋    | 9064/16104 [42:03:05<36:38:50, 18.74s/it]
{'loss': 0.5778, 'learning_rate': 8.457510670346974e-07, 'rewards/chosen': -0.3687862455844879, 'rewards/rejected': -1.1513561010360718, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7825698852539062, 'policy_logps/rejected': -593.3731079101562, 'policy_logps/chosen': -688.9541015625, 'referece_logps/rejected': -581.8595581054688, 'referece_logps/chosen': -685.2661743164062, 'logits/rejected': 0.33519551157951355, 'logits/chosen': 0.3423442244529724, 'epoch': 3.38}


 56%|█████▋    | 9066/16104 [42:03:33<31:37:39, 16.18s/it]

 56%|█████▋    | 9067/16104 [42:03:53<33:54:18, 17.35s/it]

 56%|█████▋    | 9068/16104 [42:04:09<33:01:10, 16.89s/it]

 56%|█████▋    | 9069/16104 [42:04:31<36:06:32, 18.48s/it]

 56%|█████▋    | 9070/16104 [42:04:51<37:17:28, 19.09s/it]

 56%|█████▋    | 9071/16104 [42:05:03<32:36:34, 16.69s/it]

 56%|█████▋    | 9072/16104 [42:05:13<29:14:10, 14.97s/it]

 56%|█████▋    | 9073/16104 [42:05:27<28:26:58, 14.57s/it]
{'loss': 0.4499, 'learning_rate': 8.43962847788881e-07, 'rewards/chosen': -0.4225662648677826, 'rewards/rejected': -1.1971187591552734, 'rewards/accuracies': 0.75, 'rewards/margins': 0.774552583694458, 'policy_logps/rejected': -504.4224548339844, 'policy_logps/chosen': -558.9114990234375, 'referece_logps/rejected': -492.4512939453125, 'referece_logps/chosen': -554.6858520507812, 'logits/rejected': -1.0296964645385742, 'logits/chosen': -1.0241613388061523, 'epoch': 3.38}


 56%|█████▋    | 9075/16104 [42:05:49<24:40:15, 12.64s/it]

 56%|█████▋    | 9076/16104 [42:06:06<27:10:14, 13.92s/it]

 56%|█████▋    | 9077/16104 [42:06:17<25:52:20, 13.25s/it]
{'loss': 0.5402, 'learning_rate': 8.431682474428703e-07, 'rewards/chosen': -1.1345734596252441, 'rewards/rejected': -1.9794732332229614, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8448997735977173, 'policy_logps/rejected': -627.9065551757812, 'policy_logps/chosen': -436.91778564453125, 'referece_logps/rejected': -608.11181640625, 'referece_logps/chosen': -425.57208251953125, 'logits/rejected': 0.25963181257247925, 'logits/chosen': 0.29435014724731445, 'epoch': 3.38}

 56%|█████▋    | 9078/16104 [42:06:28<24:23:10, 12.50s/it]


 56%|█████▋    | 9080/16104 [42:07:04<30:04:08, 15.41s/it]

 56%|█████▋    | 9081/16104 [42:07:17<28:53:30, 14.81s/it]
{'loss': 0.4966, 'learning_rate': 8.423737486028428e-07, 'rewards/chosen': -0.6319018006324768, 'rewards/rejected': -1.3520288467407227, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7201269865036011, 'policy_logps/rejected': -282.50872802734375, 'policy_logps/chosen': -446.6197509765625, 'referece_logps/rejected': -268.98846435546875, 'referece_logps/chosen': -440.30078125, 'logits/rejected': -0.29053735733032227, 'logits/chosen': -0.42791748046875, 'epoch': 3.38}


 56%|█████▋    | 9083/16104 [42:07:39<25:13:23, 12.93s/it]

 56%|█████▋    | 9084/16104 [42:07:51<24:17:21, 12.46s/it]

 56%|█████▋    | 9085/16104 [42:08:10<28:05:42, 14.41s/it]

 56%|█████▋    | 9086/16104 [42:08:25<28:28:48, 14.61s/it]
{'loss': 0.377, 'learning_rate': 8.413807685789759e-07, 'rewards/chosen': -0.30707472562789917, 'rewards/rejected': -2.1710171699523926, 'rewards/accuracies': 0.75, 'rewards/margins': 1.863942265510559, 'policy_logps/rejected': -428.31146240234375, 'policy_logps/chosen': -554.10791015625, 'referece_logps/rejected': -406.6012878417969, 'referece_logps/chosen': -551.0372314453125, 'logits/rejected': 0.03570261597633362, 'logits/chosen': 0.0604722797870636, 'epoch': 3.39}

 56%|█████▋    | 9087/16104 [42:08:42<30:15:39, 15.53s/it]


 56%|█████▋    | 9089/16104 [42:09:25<36:03:28, 18.50s/it]

 56%|█████▋    | 9090/16104 [42:09:44<36:19:40, 18.65s/it]
{'loss': 0.3375, 'learning_rate': 8.40586500007435e-07, 'rewards/chosen': -0.7923678159713745, 'rewards/rejected': -3.6820592880249023, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8896913528442383, 'policy_logps/rejected': -349.0179748535156, 'policy_logps/chosen': -370.4111022949219, 'referece_logps/rejected': -312.19732666015625, 'referece_logps/chosen': -362.4873962402344, 'logits/rejected': -0.6005856394767761, 'logits/chosen': -0.3484817147254944, 'epoch': 3.39}

 56%|█████▋    | 9091/16104 [42:10:04<37:29:23, 19.24s/it]


 56%|█████▋    | 9093/16104 [42:10:44<37:39:17, 19.33s/it]

 56%|█████▋    | 9094/16104 [42:11:03<37:48:41, 19.42s/it]

 56%|█████▋    | 9095/16104 [42:11:22<37:07:30, 19.07s/it]
{'loss': 0.3925, 'learning_rate': 8.395938094458502e-07, 'rewards/chosen': -0.009561453014612198, 'rewards/rejected': -1.3724240064620972, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3628625869750977, 'policy_logps/rejected': -406.1822509765625, 'policy_logps/chosen': -340.95458984375, 'referece_logps/rejected': -392.4579772949219, 'referece_logps/chosen': -340.8589782714844, 'logits/rejected': -0.08672244846820831, 'logits/chosen': -0.14511145651340485, 'epoch': 3.39}


 56%|█████▋    | 9097/16104 [42:12:03<38:33:05, 19.81s/it]
{'loss': 0.4017, 'learning_rate': 8.391967785860156e-07, 'rewards/chosen': -0.44502565264701843, 'rewards/rejected': -2.383333683013916, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9383080005645752, 'policy_logps/rejected': -431.7759704589844, 'policy_logps/chosen': -560.4037475585938, 'referece_logps/rejected': -407.9426574707031, 'referece_logps/chosen': -555.9534912109375, 'logits/rejected': -0.30152493715286255, 'logits/chosen': -0.28584808111190796, 'epoch': 3.39}


 57%|█████▋    | 9099/16104 [42:12:35<34:31:15, 17.74s/it]

 57%|█████▋    | 9100/16104 [42:12:48<31:32:28, 16.21s/it]
{'loss': 0.4261, 'learning_rate': 8.38601281102168e-07, 'rewards/chosen': -0.21763001382350922, 'rewards/rejected': -1.1229193210601807, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9052892923355103, 'policy_logps/rejected': -489.6673583984375, 'policy_logps/chosen': -451.15753173828125, 'referece_logps/rejected': -478.43817138671875, 'referece_logps/chosen': -448.981201171875, 'logits/rejected': -0.22221650183200836, 'logits/chosen': -0.18858928978443146, 'epoch': 3.39}


 57%|█████▋    | 9102/16104 [42:13:21<32:12:57, 16.56s/it]
{'loss': 0.3749, 'learning_rate': 8.382043154105512e-07, 'rewards/chosen': -0.3243085741996765, 'rewards/rejected': -2.192080020904541, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8677715063095093, 'policy_logps/rejected': -358.9956970214844, 'policy_logps/chosen': -471.3338317871094, 'referece_logps/rejected': -337.0749206542969, 'referece_logps/chosen': -468.09075927734375, 'logits/rejected': 0.45447129011154175, 'logits/chosen': 0.37029680609703064, 'epoch': 3.39}

 57%|█████▋    | 9103/16104 [42:13:40<33:57:09, 17.46s/it]


 57%|█████▋    | 9105/16104 [42:14:22<37:07:53, 19.10s/it]

 57%|█████▋    | 9106/16104 [42:14:38<35:38:30, 18.34s/it]
{'loss': 0.4521, 'learning_rate': 8.374104626306346e-07, 'rewards/chosen': -0.7078309059143066, 'rewards/rejected': -1.763450264930725, 'rewards/accuracies': 0.875, 'rewards/margins': 1.055619478225708, 'policy_logps/rejected': -430.51934814453125, 'policy_logps/chosen': -503.38323974609375, 'referece_logps/rejected': -412.8848571777344, 'referece_logps/chosen': -496.304931640625, 'logits/rejected': -0.11471256613731384, 'logits/chosen': -0.14010131359100342, 'epoch': 3.39}


 57%|█████▋    | 9108/16104 [42:15:04<30:15:07, 15.57s/it]

 57%|█████▋    | 9109/16104 [42:15:25<33:41:44, 17.34s/it]

 57%|█████▋    | 9110/16104 [42:15:48<36:37:56, 18.86s/it]

 57%|█████▋    | 9111/16104 [42:16:02<34:04:44, 17.54s/it]

 57%|█████▋    | 9112/16104 [42:16:23<36:17:47, 18.69s/it]

 57%|█████▋    | 9113/16104 [42:16:35<32:16:11, 16.62s/it]

 57%|█████▋    | 9114/16104 [42:16:48<29:46:29, 15.33s/it]

 57%|█████▋    | 9115/16104 [42:17:06<31:22:22, 16.16s/it]
{'loss': 0.5248, 'learning_rate': 8.356246794151003e-07, 'rewards/chosen': -0.7113760113716125, 'rewards/rejected': -1.8036608695983887, 'rewards/accuracies': 0.75, 'rewards/margins': 1.092284917831421, 'policy_logps/rejected': -303.3419494628906, 'policy_logps/chosen': -350.38507080078125, 'referece_logps/rejected': -285.3053283691406, 'referece_logps/chosen': -343.27130126953125, 'logits/rejected': -0.2770266830921173, 'logits/chosen': -0.17859412729740143, 'epoch': 3.4}

 57%|█████▋    | 9116/16104 [42:17:17<28:22:20, 14.62s/it]


 57%|█████▋    | 9118/16104 [42:17:56<33:37:39, 17.33s/it]

 57%|█████▋    | 9119/16104 [42:18:08<30:45:47, 15.86s/it]
{'loss': 0.3924, 'learning_rate': 8.348311705193292e-07, 'rewards/chosen': -1.143064022064209, 'rewards/rejected': -1.7127162218093872, 'rewards/accuracies': 0.5, 'rewards/margins': 0.569652259349823, 'policy_logps/rejected': -277.3431396484375, 'policy_logps/chosen': -333.29681396484375, 'referece_logps/rejected': -260.21600341796875, 'referece_logps/chosen': -321.86614990234375, 'logits/rejected': 0.3504182696342468, 'logits/chosen': 0.5609474182128906, 'epoch': 3.4}

 57%|█████▋    | 9120/16104 [42:18:21<28:44:54, 14.82s/it]


 57%|█████▋    | 9122/16104 [42:18:48<26:53:24, 13.86s/it]

 57%|█████▋    | 9123/16104 [42:19:02<27:08:39, 14.00s/it]
{'loss': 0.4493, 'learning_rate': 8.340377685255355e-07, 'rewards/chosen': -0.37677404284477234, 'rewards/rejected': -1.0408893823623657, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6641153693199158, 'policy_logps/rejected': -425.4211730957031, 'policy_logps/chosen': -473.5100402832031, 'referece_logps/rejected': -415.0122985839844, 'referece_logps/chosen': -469.7423095703125, 'logits/rejected': -0.7020821571350098, 'logits/chosen': -0.723565936088562, 'epoch': 3.4}


 57%|█████▋    | 9125/16104 [42:19:38<31:15:09, 16.12s/it]

 57%|█████▋    | 9126/16104 [42:19:50<28:55:49, 14.93s/it]

 57%|█████▋    | 9127/16104 [42:20:06<29:49:24, 15.39s/it]

 57%|█████▋    | 9128/16104 [42:20:22<29:54:48, 15.44s/it]
{'loss': 0.3789, 'learning_rate': 8.330461671464956e-07, 'rewards/chosen': -0.6330852508544922, 'rewards/rejected': -1.4177577495574951, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7846724390983582, 'policy_logps/rejected': -405.9132995605469, 'policy_logps/chosen': -576.98291015625, 'referece_logps/rejected': -391.7357482910156, 'referece_logps/chosen': -570.6521606445312, 'logits/rejected': -0.8118095397949219, 'logits/chosen': -1.054967999458313, 'epoch': 3.4}


 57%|█████▋    | 9130/16104 [42:20:48<26:55:58, 13.90s/it]

 57%|█████▋    | 9131/16104 [42:21:08<30:49:43, 15.92s/it]
{'loss': 0.4368, 'learning_rate': 8.324512872978582e-07, 'rewards/chosen': -0.6643516421318054, 'rewards/rejected': -2.689422845840454, 'rewards/accuracies': 0.875, 'rewards/margins': 2.025071144104004, 'policy_logps/rejected': -445.3169250488281, 'policy_logps/chosen': -649.1570434570312, 'referece_logps/rejected': -418.4227294921875, 'referece_logps/chosen': -642.5135498046875, 'logits/rejected': -0.4589722454547882, 'logits/chosen': -0.4580003619194031, 'epoch': 3.4}


 57%|█████▋    | 9133/16104 [42:21:44<32:01:09, 16.54s/it]

 57%|█████▋    | 9134/16104 [42:22:00<31:35:42, 16.32s/it]

 57%|█████▋    | 9135/16104 [42:22:18<32:46:39, 16.93s/it]

 57%|█████▋    | 9136/16104 [42:22:33<31:43:41, 16.39s/it]

 57%|█████▋    | 9137/16104 [42:22:49<31:04:37, 16.06s/it]
{'loss': 0.4378, 'learning_rate': 8.312617108135314e-07, 'rewards/chosen': -1.0892168283462524, 'rewards/rejected': -2.334773063659668, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2455562353134155, 'policy_logps/rejected': -256.72412109375, 'policy_logps/chosen': -354.4891052246094, 'referece_logps/rejected': -233.3764190673828, 'referece_logps/chosen': -343.5968933105469, 'logits/rejected': 0.07639031857252121, 'logits/chosen': -0.0432119145989418, 'epoch': 3.4}


 57%|█████▋    | 9139/16104 [42:23:26<33:32:44, 17.34s/it]
{'loss': 0.428, 'learning_rate': 8.308652398393318e-07, 'rewards/chosen': -0.004098232835531235, 'rewards/rejected': -1.1168098449707031, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1127116680145264, 'policy_logps/rejected': -521.1322631835938, 'policy_logps/chosen': -361.35845947265625, 'referece_logps/rejected': -509.96417236328125, 'referece_logps/chosen': -361.3175354003906, 'logits/rejected': -0.5799373984336853, 'logits/chosen': -0.44134700298309326, 'epoch': 3.4}


 57%|█████▋    | 9141/16104 [42:23:56<30:41:16, 15.87s/it]

 57%|█████▋    | 9142/16104 [42:24:08<28:23:10, 14.68s/it]
{'loss': 0.4182, 'learning_rate': 8.30270584711599e-07, 'rewards/chosen': -0.6068120002746582, 'rewards/rejected': -1.6443556547164917, 'rewards/accuracies': 0.875, 'rewards/margins': 1.037543535232544, 'policy_logps/rejected': -388.8090515136719, 'policy_logps/chosen': -307.7304382324219, 'referece_logps/rejected': -372.3655090332031, 'referece_logps/chosen': -301.6623229980469, 'logits/rejected': 0.0071052610874176025, 'logits/chosen': 0.2412940412759781, 'epoch': 3.41}

 57%|█████▋    | 9143/16104 [42:24:23<28:29:51, 14.74s/it]


 57%|█████▋    | 9145/16104 [42:24:56<30:48:30, 15.94s/it]

 57%|█████▋    | 9146/16104 [42:25:08<28:05:11, 14.53s/it]

 57%|█████▋    | 9147/16104 [42:25:24<29:03:47, 15.04s/it]

 57%|█████▋    | 9148/16104 [42:25:35<26:44:32, 13.84s/it]

 57%|█████▋    | 9149/16104 [42:25:54<30:01:51, 15.54s/it]

 57%|█████▋    | 9150/16104 [42:26:13<31:45:18, 16.44s/it]

 57%|█████▋    | 9151/16104 [42:26:25<29:15:48, 15.15s/it]
{'loss': 0.4467, 'learning_rate': 8.284869909505705e-07, 'rewards/chosen': -0.8484370708465576, 'rewards/rejected': -1.4729828834533691, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6245457530021667, 'policy_logps/rejected': -487.10186767578125, 'policy_logps/chosen': -539.2794799804688, 'referece_logps/rejected': -472.37200927734375, 'referece_logps/chosen': -530.7950439453125, 'logits/rejected': -0.41647058725357056, 'logits/chosen': -0.4590540826320648, 'epoch': 3.41}

 57%|█████▋    | 9152/16104 [42:26:42<30:11:00, 15.63s/it]


 57%|█████▋    | 9154/16104 [42:27:07<26:53:55, 13.93s/it]

 57%|█████▋    | 9155/16104 [42:27:25<29:04:25, 15.06s/it]
{'loss': 0.4357, 'learning_rate': 8.276944626531562e-07, 'rewards/chosen': -0.15914881229400635, 'rewards/rejected': -2.1092987060546875, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9501497745513916, 'policy_logps/rejected': -508.1043701171875, 'policy_logps/chosen': -531.762451171875, 'referece_logps/rejected': -487.0113830566406, 'referece_logps/chosen': -530.1708984375, 'logits/rejected': -0.7077437043190002, 'logits/chosen': -0.7257218360900879, 'epoch': 3.41}


 57%|█████▋    | 9157/16104 [42:27:46<24:55:17, 12.91s/it]
{'loss': 0.5414, 'learning_rate': 8.272982402927894e-07, 'rewards/chosen': -0.7254366278648376, 'rewards/rejected': -1.2790580987930298, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5536215305328369, 'policy_logps/rejected': -442.154541015625, 'policy_logps/chosen': -441.806640625, 'referece_logps/rejected': -429.36395263671875, 'referece_logps/chosen': -434.5523376464844, 'logits/rejected': -0.5124291181564331, 'logits/chosen': -0.5411695241928101, 'epoch': 3.41}

 57%|█████▋    | 9158/16104 [42:27:58<24:03:22, 12.47s/it]

 57%|█████▋    | 9159/16104 [42:28:17<28:08:30, 14.59s/it]

 57%|█████▋    | 9160/16104 [42:28:28<25:57:39, 13.46s/it]

 57%|█████▋    | 9161/16104 [42:28:40<25:03:02, 12.99s/it]

 57%|█████▋    | 9162/16104 [42:28:57<27:36:06, 14.31s/it]


 57%|█████▋    | 9164/16104 [42:29:27<27:11:12, 14.10s/it]
{'loss': 0.5202, 'learning_rate': 8.259116825141677e-07, 'rewards/chosen': -1.1248719692230225, 'rewards/rejected': -1.4953393936157227, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3704673647880554, 'policy_logps/rejected': -265.4501647949219, 'policy_logps/chosen': -389.17724609375, 'referece_logps/rejected': -250.49676513671875, 'referece_logps/chosen': -377.92852783203125, 'logits/rejected': 0.13392503559589386, 'logits/chosen': 0.01590610295534134, 'epoch': 3.41}

 57%|█████▋    | 9165/16104 [42:29:42<28:02:36, 14.55s/it]


 57%|█████▋    | 9167/16104 [42:30:19<32:00:00, 16.61s/it]

 57%|█████▋    | 9168/16104 [42:30:39<33:44:03, 17.51s/it]
{'loss': 0.4507, 'learning_rate': 8.251195185352788e-07, 'rewards/chosen': -0.3746587038040161, 'rewards/rejected': -1.3974766731262207, 'rewards/accuracies': 0.875, 'rewards/margins': 1.022817850112915, 'policy_logps/rejected': -433.120849609375, 'policy_logps/chosen': -422.89593505859375, 'referece_logps/rejected': -419.1460876464844, 'referece_logps/chosen': -419.1492919921875, 'logits/rejected': -0.14375634491443634, 'logits/chosen': -0.10289213061332703, 'epoch': 3.42}


 57%|█████▋    | 9170/16104 [42:31:09<31:48:29, 16.51s/it]

 57%|█████▋    | 9171/16104 [42:31:27<32:51:03, 17.06s/it]
{'loss': 0.4591, 'learning_rate': 8.245254698024617e-07, 'rewards/chosen': -0.36970967054367065, 'rewards/rejected': -1.5321404933929443, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1624308824539185, 'policy_logps/rejected': -373.77496337890625, 'policy_logps/chosen': -328.20086669921875, 'referece_logps/rejected': -358.4535827636719, 'referece_logps/chosen': -324.5037841796875, 'logits/rejected': -0.7442352771759033, 'logits/chosen': -0.4936811327934265, 'epoch': 3.42}


 57%|█████▋    | 9173/16104 [42:31:57<31:41:42, 16.46s/it]
{'loss': 0.4894, 'learning_rate': 8.241294727918563e-07, 'rewards/chosen': 0.0027165487408638, 'rewards/rejected': -1.930967926979065, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9336845874786377, 'policy_logps/rejected': -322.8221130371094, 'policy_logps/chosen': -298.78521728515625, 'referece_logps/rejected': -303.5124816894531, 'referece_logps/chosen': -298.8123779296875, 'logits/rejected': -0.30060121417045593, 'logits/chosen': -0.28297704458236694, 'epoch': 3.42}

 57%|█████▋    | 9174/16104 [42:32:17<33:49:47, 17.57s/it]


 57%|█████▋    | 9176/16104 [42:32:53<34:22:41, 17.86s/it]
{'loss': 0.4303, 'learning_rate': 8.235355306530445e-07, 'rewards/chosen': -0.6821798086166382, 'rewards/rejected': -2.197269916534424, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5150901079177856, 'policy_logps/rejected': -454.48663330078125, 'policy_logps/chosen': -369.3294677734375, 'referece_logps/rejected': -432.513916015625, 'referece_logps/chosen': -362.5076904296875, 'logits/rejected': -0.4645897150039673, 'logits/chosen': -0.4547181725502014, 'epoch': 3.42}

 57%|█████▋    | 9177/16104 [42:33:04<30:40:46, 15.94s/it]

 57%|█████▋    | 9178/16104 [42:33:24<32:48:30, 17.05s/it]

 57%|█████▋    | 9179/16104 [42:33:43<33:45:38, 17.55s/it]

 57%|█████▋    | 9180/16104 [42:34:02<35:04:40, 18.24s/it]


 57%|█████▋    | 9182/16104 [42:34:25<28:11:55, 14.67s/it]
{'loss': 0.4234, 'learning_rate': 8.223478393257993e-07, 'rewards/chosen': -0.5570279955863953, 'rewards/rejected': -2.622459888458252, 'rewards/accuracies': 0.75, 'rewards/margins': 2.065431833267212, 'policy_logps/rejected': -495.1626892089844, 'policy_logps/chosen': -530.5055541992188, 'referece_logps/rejected': -468.9380798339844, 'referece_logps/chosen': -524.9352416992188, 'logits/rejected': -0.4746662378311157, 'logits/chosen': -0.281364768743515, 'epoch': 3.42}

 57%|█████▋    | 9183/16104 [42:34:39<27:30:21, 14.31s/it]


 57%|█████▋    | 9185/16104 [42:35:13<30:05:25, 15.66s/it]
{'loss': 0.4577, 'learning_rate': 8.217540905697637e-07, 'rewards/chosen': -0.21576958894729614, 'rewards/rejected': -1.44073486328125, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2249653339385986, 'policy_logps/rejected': -285.0638732910156, 'policy_logps/chosen': -527.963623046875, 'referece_logps/rejected': -270.6565246582031, 'referece_logps/chosen': -525.805908203125, 'logits/rejected': 0.40204373002052307, 'logits/chosen': 0.2770515978336334, 'epoch': 3.42}

 57%|█████▋    | 9186/16104 [42:35:24<27:30:56, 14.32s/it]

 57%|█████▋    | 9187/16104 [42:35:40<28:31:06, 14.84s/it]

 57%|█████▋    | 9188/16104 [42:35:52<26:35:05, 13.84s/it]

 57%|█████▋    | 9189/16104 [42:36:03<24:46:34, 12.90s/it]

 57%|█████▋    | 9190/16104 [42:36:17<25:20:13, 13.19s/it]

 57%|█████▋    | 9191/16104 [42:36:30<25:21:53, 13.21s/it]


 57%|█████▋    | 9193/16104 [42:36:58<26:12:19, 13.65s/it]
{'loss': 0.3926, 'learning_rate': 8.201710783967622e-07, 'rewards/chosen': 0.49716320633888245, 'rewards/rejected': -0.931252658367157, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4284158945083618, 'policy_logps/rejected': -571.49609375, 'policy_logps/chosen': -590.0103149414062, 'referece_logps/rejected': -562.18359375, 'referece_logps/chosen': -594.98193359375, 'logits/rejected': 0.48973357677459717, 'logits/chosen': 0.3490070700645447, 'epoch': 3.43}


 57%|█████▋    | 9195/16104 [42:37:33<30:08:55, 15.71s/it]
{'loss': 0.3565, 'learning_rate': 8.197753979374415e-07, 'rewards/chosen': -0.5611986517906189, 'rewards/rejected': -2.0350663661956787, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4738675355911255, 'policy_logps/rejected': -299.8455810546875, 'policy_logps/chosen': -407.88067626953125, 'referece_logps/rejected': -279.4949645996094, 'referece_logps/chosen': -402.2686767578125, 'logits/rejected': -0.4085463285446167, 'logits/chosen': -0.3267250955104828, 'epoch': 3.43}


 57%|█████▋    | 9197/16104 [42:38:09<32:22:01, 16.87s/it]

 57%|█████▋    | 9198/16104 [42:38:27<33:13:47, 17.32s/it]

 57%|█████▋    | 9199/16104 [42:38:47<34:43:22, 18.10s/it]
{'loss': 0.4989, 'learning_rate': 8.189841245676994e-07, 'rewards/chosen': -0.5951671600341797, 'rewards/rejected': -1.1050825119018555, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5099153518676758, 'policy_logps/rejected': -367.454345703125, 'policy_logps/chosen': -518.168701171875, 'referece_logps/rejected': -356.4035339355469, 'referece_logps/chosen': -512.217041015625, 'logits/rejected': 0.11685965210199356, 'logits/chosen': -0.04036228358745575, 'epoch': 3.43}


 57%|█████▋    | 9201/16104 [42:39:15<29:59:05, 15.64s/it]

 57%|█████▋    | 9202/16104 [42:39:26<27:08:25, 14.16s/it]
{'loss': 0.5031, 'learning_rate': 8.183907463977437e-07, 'rewards/chosen': -0.03320112079381943, 'rewards/rejected': -0.8729750514030457, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8397738933563232, 'policy_logps/rejected': -502.37652587890625, 'policy_logps/chosen': -427.36273193359375, 'referece_logps/rejected': -493.6468505859375, 'referece_logps/chosen': -427.03076171875, 'logits/rejected': -0.2884954810142517, 'logits/chosen': -0.1815921813249588, 'epoch': 3.43}

 57%|█████▋    | 9203/16104 [42:39:38<26:12:02, 13.67s/it]

 57%|█████▋    | 9204/16104 [42:39:51<25:23:49, 13.25s/it]


 57%|█████▋    | 9206/16104 [42:40:27<30:03:26, 15.69s/it]
{'loss': 0.3436, 'learning_rate': 8.175996783916595e-07, 'rewards/chosen': 0.17298632860183716, 'rewards/rejected': -1.5325042009353638, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7054904699325562, 'policy_logps/rejected': -380.3076171875, 'policy_logps/chosen': -412.86767578125, 'referece_logps/rejected': -364.9825744628906, 'referece_logps/chosen': -414.5975341796875, 'logits/rejected': -0.2614442706108093, 'logits/chosen': -0.13287003338336945, 'epoch': 3.43}

 57%|█████▋    | 9207/16104 [42:40:47<32:11:08, 16.80s/it]


 57%|█████▋    | 9209/16104 [42:41:23<33:22:00, 17.42s/it]
{'loss': 0.4068, 'learning_rate': 8.17006454832489e-07, 'rewards/chosen': -0.32236844301223755, 'rewards/rejected': -1.6653730869293213, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3430047035217285, 'policy_logps/rejected': -371.10125732421875, 'policy_logps/chosen': -475.122802734375, 'referece_logps/rejected': -354.44757080078125, 'referece_logps/chosen': -471.89910888671875, 'logits/rejected': 0.4662708342075348, 'logits/chosen': 0.37531909346580505, 'epoch': 3.43}


 57%|█████▋    | 9211/16104 [42:42:02<34:55:04, 18.24s/it]
{'loss': 0.4483, 'learning_rate': 8.166110094584546e-07, 'rewards/chosen': -0.6427285075187683, 'rewards/rejected': -1.5547122955322266, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9119837880134583, 'policy_logps/rejected': -538.4149780273438, 'policy_logps/chosen': -583.2107543945312, 'referece_logps/rejected': -522.867919921875, 'referece_logps/chosen': -576.783447265625, 'logits/rejected': 1.2299021482467651, 'logits/chosen': 1.2353012561798096, 'epoch': 3.43}


 57%|█████▋    | 9213/16104 [42:42:29<30:56:24, 16.16s/it]
{'loss': 0.4518, 'learning_rate': 8.16215593758067e-07, 'rewards/chosen': -1.180476188659668, 'rewards/rejected': -1.834887146949768, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6544111967086792, 'policy_logps/rejected': -585.0270385742188, 'policy_logps/chosen': -369.4139404296875, 'referece_logps/rejected': -566.6781616210938, 'referece_logps/chosen': -357.60919189453125, 'logits/rejected': 0.2622320055961609, 'logits/chosen': 0.2862723469734192, 'epoch': 3.43}

 57%|█████▋    | 9214/16104 [42:42:47<31:38:24, 16.53s/it]

 57%|█████▋    | 9215/16104 [42:43:01<30:03:18, 15.71s/it]


 57%|█████▋    | 9217/16104 [42:43:32<29:33:42, 15.45s/it]
{'loss': 0.3192, 'learning_rate': 8.154248516341546e-07, 'rewards/chosen': -0.4932805895805359, 'rewards/rejected': -2.541663646697998, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0483832359313965, 'policy_logps/rejected': -347.33465576171875, 'policy_logps/chosen': -469.0526123046875, 'referece_logps/rejected': -321.91796875, 'referece_logps/chosen': -464.11981201171875, 'logits/rejected': 0.2868614196777344, 'logits/chosen': 0.38060620427131653, 'epoch': 3.43}

 57%|█████▋    | 9218/16104 [42:43:43<26:49:41, 14.03s/it]

 57%|█████▋    | 9219/16104 [42:43:54<25:25:08, 13.29s/it]

 57%|█████▋    | 9220/16104 [42:44:05<23:58:33, 12.54s/it]


 57%|█████▋    | 9222/16104 [42:44:38<28:19:28, 14.82s/it]

 57%|█████▋    | 9223/16104 [42:44:52<27:39:30, 14.47s/it]
{'loss': 0.5001, 'learning_rate': 8.142389626000114e-07, 'rewards/chosen': -0.7372593283653259, 'rewards/rejected': -1.0166943073272705, 'rewards/accuracies': 0.75, 'rewards/margins': 0.27943503856658936, 'policy_logps/rejected': -537.8905029296875, 'policy_logps/chosen': -491.2521057128906, 'referece_logps/rejected': -527.7235717773438, 'referece_logps/chosen': -483.8795166015625, 'logits/rejected': 0.963973343372345, 'logits/chosen': 0.8586450815200806, 'epoch': 3.44}


 57%|█████▋    | 9225/16104 [42:45:28<31:38:49, 16.56s/it]

 57%|█████▋    | 9226/16104 [42:45:40<29:16:57, 15.33s/it]

 57%|█████▋    | 9227/16104 [42:45:56<29:23:55, 15.39s/it]
{'loss': 0.4105, 'learning_rate': 8.134485200912874e-07, 'rewards/chosen': -0.32754290103912354, 'rewards/rejected': -1.988095760345459, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6605528593063354, 'policy_logps/rejected': -300.00115966796875, 'policy_logps/chosen': -358.01190185546875, 'referece_logps/rejected': -280.1202087402344, 'referece_logps/chosen': -354.7365417480469, 'logits/rejected': 0.17957666516304016, 'logits/chosen': 0.1534137725830078, 'epoch': 3.44}


 57%|█████▋    | 9229/16104 [42:46:22<26:40:07, 13.96s/it]
{'loss': 0.4664, 'learning_rate': 8.130533440829927e-07, 'rewards/chosen': -0.3975113034248352, 'rewards/rejected': -1.8193888664245605, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4218775033950806, 'policy_logps/rejected': -410.4776306152344, 'policy_logps/chosen': -348.14862060546875, 'referece_logps/rejected': -392.28375244140625, 'referece_logps/chosen': -344.1735534667969, 'logits/rejected': -0.14123043417930603, 'logits/chosen': -0.0189039446413517, 'epoch': 3.44}

 57%|█████▋    | 9230/16104 [42:46:38<28:14:39, 14.79s/it]


 57%|█████▋    | 9232/16104 [42:47:00<24:27:56, 12.82s/it]

 57%|█████▋    | 9233/16104 [42:47:20<28:27:10, 14.91s/it]
{'loss': 0.5203, 'learning_rate': 8.122630828782503e-07, 'rewards/chosen': -0.9735183715820312, 'rewards/rejected': -1.5473606586456299, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5738422274589539, 'policy_logps/rejected': -473.20477294921875, 'policy_logps/chosen': -461.55816650390625, 'referece_logps/rejected': -457.73114013671875, 'referece_logps/chosen': -451.82305908203125, 'logits/rejected': -0.6604915857315063, 'logits/chosen': -0.6247413158416748, 'epoch': 3.44}


 57%|█████▋    | 9235/16104 [42:47:56<31:41:12, 16.61s/it]
{'loss': 0.3965, 'learning_rate': 8.118679978096719e-07, 'rewards/chosen': -0.3592628836631775, 'rewards/rejected': -2.0170435905456543, 'rewards/accuracies': 0.875, 'rewards/margins': 1.657780647277832, 'policy_logps/rejected': -444.37152099609375, 'policy_logps/chosen': -386.34490966796875, 'referece_logps/rejected': -424.2010192871094, 'referece_logps/chosen': -382.75225830078125, 'logits/rejected': -0.030017521232366562, 'logits/chosen': 0.011736365966498852, 'epoch': 3.44}

 57%|█████▋    | 9236/16104 [42:48:13<31:52:48, 16.71s/it]


 57%|█████▋    | 9238/16104 [42:48:46<31:33:07, 16.54s/it]
{'loss': 0.3834, 'learning_rate': 8.112754273038444e-07, 'rewards/chosen': 0.10502130538225174, 'rewards/rejected': -0.2502164840698242, 'rewards/accuracies': 0.625, 'rewards/margins': 0.35523778200149536, 'policy_logps/rejected': -480.7855224609375, 'policy_logps/chosen': -598.3734130859375, 'referece_logps/rejected': -478.28338623046875, 'referece_logps/chosen': -599.4236450195312, 'logits/rejected': 0.229671910405159, 'logits/chosen': 0.1910109668970108, 'epoch': 3.44}


 57%|█████▋    | 9240/16104 [42:49:16<29:33:27, 15.50s/it]
{'loss': 0.4413, 'learning_rate': 8.108804184578708e-07, 'rewards/chosen': -0.3745102882385254, 'rewards/rejected': -1.0866200923919678, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7121098041534424, 'policy_logps/rejected': -315.2616271972656, 'policy_logps/chosen': -461.0938720703125, 'referece_logps/rejected': -304.3954162597656, 'referece_logps/chosen': -457.3487854003906, 'logits/rejected': 0.005022555589675903, 'logits/chosen': -0.13277167081832886, 'epoch': 3.44}

 57%|█████▋    | 9241/16104 [42:49:27<26:48:43, 14.06s/it]

 57%|█████▋    | 9242/16104 [42:49:40<26:13:18, 13.76s/it]


 57%|█████▋    | 9244/16104 [42:50:10<26:57:40, 14.15s/it]

 57%|█████▋    | 9245/16104 [42:50:30<30:07:06, 15.81s/it]
{'loss': 0.4198, 'learning_rate': 8.098930303616682e-07, 'rewards/chosen': -0.36525386571884155, 'rewards/rejected': -2.362914800643921, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9976608753204346, 'policy_logps/rejected': -453.5138854980469, 'policy_logps/chosen': -445.86749267578125, 'referece_logps/rejected': -429.8847351074219, 'referece_logps/chosen': -442.2149353027344, 'logits/rejected': -0.06247032433748245, 'logits/chosen': -0.13854676485061646, 'epoch': 3.44}

 57%|█████▋    | 9246/16104 [42:50:50<32:23:37, 17.00s/it]

 57%|█████▋    | 9247/16104 [42:51:11<34:51:11, 18.30s/it]


 57%|█████▋    | 9249/16104 [42:51:51<36:18:48, 19.07s/it]
{'loss': 0.4202, 'learning_rate': 8.091032582597625e-07, 'rewards/chosen': -0.29715651273727417, 'rewards/rejected': -1.9602890014648438, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6631324291229248, 'policy_logps/rejected': -557.9512329101562, 'policy_logps/chosen': -447.8215026855469, 'referece_logps/rejected': -538.348388671875, 'referece_logps/chosen': -444.8499755859375, 'logits/rejected': -0.04597915709018707, 'logits/chosen': -0.0162019282579422, 'epoch': 3.45}

 57%|█████▋    | 9250/16104 [42:52:05<33:50:15, 17.77s/it]


 57%|█████▋    | 9252/16104 [42:52:36<30:57:16, 16.26s/it]
{'loss': 0.3288, 'learning_rate': 8.085110102375734e-07, 'rewards/chosen': -0.3498685956001282, 'rewards/rejected': -1.7185959815979004, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3687273263931274, 'policy_logps/rejected': -395.2681579589844, 'policy_logps/chosen': -346.06756591796875, 'referece_logps/rejected': -378.08221435546875, 'referece_logps/chosen': -342.5688781738281, 'logits/rejected': -0.32773876190185547, 'logits/chosen': -0.400248646736145, 'epoch': 3.45}


 57%|█████▋    | 9254/16104 [42:53:08<30:47:47, 16.19s/it]

 57%|█████▋    | 9255/16104 [42:53:26<31:51:17, 16.74s/it]
{'loss': 0.5141, 'learning_rate': 8.079188319300245e-07, 'rewards/chosen': -0.6087120175361633, 'rewards/rejected': -1.6175148487091064, 'rewards/accuracies': 0.75, 'rewards/margins': 1.008802890777588, 'policy_logps/rejected': -489.397216796875, 'policy_logps/chosen': -491.088134765625, 'referece_logps/rejected': -473.2220764160156, 'referece_logps/chosen': -485.00103759765625, 'logits/rejected': 0.10821399092674255, 'logits/chosen': 0.2991381585597992, 'epoch': 3.45}


 57%|█████▋    | 9257/16104 [42:53:54<29:33:13, 15.54s/it]
{'loss': 0.4628, 'learning_rate': 8.075240852284802e-07, 'rewards/chosen': 0.21385955810546875, 'rewards/rejected': -1.8263423442840576, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0402021408081055, 'policy_logps/rejected': -491.1463317871094, 'policy_logps/chosen': -493.05810546875, 'referece_logps/rejected': -472.8829345703125, 'referece_logps/chosen': -495.19671630859375, 'logits/rejected': 0.7960938811302185, 'logits/chosen': 0.776124894618988, 'epoch': 3.45}


 57%|█████▋    | 9259/16104 [42:54:26<30:32:14, 16.06s/it]

 58%|█████▊    | 9260/16104 [42:54:45<31:47:28, 16.72s/it]

 58%|█████▊    | 9261/16104 [42:54:59<30:15:22, 15.92s/it]
{'loss': 0.4199, 'learning_rate': 8.067346853211899e-07, 'rewards/chosen': -0.7409489154815674, 'rewards/rejected': -1.2663114070892334, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5253623723983765, 'policy_logps/rejected': -285.5814208984375, 'policy_logps/chosen': -383.82025146484375, 'referece_logps/rejected': -272.9183044433594, 'referece_logps/chosen': -376.4107360839844, 'logits/rejected': 0.24842527508735657, 'logits/chosen': 0.2548433542251587, 'epoch': 3.45}


 58%|█████▊    | 9263/16104 [42:55:29<30:09:57, 15.87s/it]
{'loss': 0.4645, 'learning_rate': 8.06340032243174e-07, 'rewards/chosen': -1.0024386644363403, 'rewards/rejected': -1.6896793842315674, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6872405409812927, 'policy_logps/rejected': -614.5296020507812, 'policy_logps/chosen': -347.6903076171875, 'referece_logps/rejected': -597.6328125, 'referece_logps/chosen': -337.6658935546875, 'logits/rejected': -1.2193018198013306, 'logits/chosen': -1.1601110696792603, 'epoch': 3.45}

 58%|█████▊    | 9264/16104 [42:55:41<28:13:27, 14.85s/it]


 58%|█████▊    | 9266/16104 [42:56:15<29:23:29, 15.47s/it]
{'loss': 0.3638, 'learning_rate': 8.057481114002884e-07, 'rewards/chosen': 0.05494767427444458, 'rewards/rejected': -2.4053945541381836, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4603424072265625, 'policy_logps/rejected': -730.1041259765625, 'policy_logps/chosen': -586.8599243164062, 'referece_logps/rejected': -706.05029296875, 'referece_logps/chosen': -587.409423828125, 'logits/rejected': -0.45364847779273987, 'logits/chosen': -0.3573940694332123, 'epoch': 3.45}


 58%|█████▊    | 9268/16104 [42:56:49<30:06:00, 15.85s/it]
{'loss': 0.475, 'learning_rate': 8.053535367809061e-07, 'rewards/chosen': -0.5214172601699829, 'rewards/rejected': -1.9185307025909424, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3971134424209595, 'policy_logps/rejected': -459.1666259765625, 'policy_logps/chosen': -513.3905029296875, 'referece_logps/rejected': -439.9813232421875, 'referece_logps/chosen': -508.17633056640625, 'logits/rejected': 0.34405794739723206, 'logits/chosen': 0.3072936534881592, 'epoch': 3.45}

 58%|█████▊    | 9269/16104 [42:57:08<32:06:04, 16.91s/it]

 58%|█████▊    | 9270/16104 [42:57:26<32:41:34, 17.22s/it]

 58%|█████▊    | 9271/16104 [42:57:37<29:19:39, 15.45s/it]

 58%|█████▊    | 9272/16104 [42:57:55<30:44:51, 16.20s/it]

 58%|█████▊    | 9273/16104 [42:58:10<29:42:14, 15.65s/it]

 58%|█████▊    | 9274/16104 [42:58:23<28:40:19, 15.11s/it]

 58%|█████▊    | 9275/16104 [42:58:35<26:24:18, 13.92s/it]

 58%|█████▊    | 9276/16104 [42:58:46<25:04:28, 13.22s/it]

 58%|█████▊    | 9277/16104 [42:59:00<25:28:43, 13.44s/it]

 58%|█████▊    | 9278/16104 [42:59:13<25:26:12, 13.42s/it]

 58%|█████▊    | 9279/16104 [42:59:34<29:21:13, 15.48s/it]

 58%|█████▊    | 9280/16104 [42:59:54<32:06:10, 16.94s/it]

 58%|█████▊    | 9281/16104 [43:00:06<29:05:01, 15.35s/it]

 58%|█████▊    | 9282/16104 [43:00:26<31:52:02, 16.82s/it]

 58%|█████▊    | 9283/16104 [43:00:46<33:56:04, 17.91s/it]


 58%|█████▊    | 9285/16104 [43:01:19<32:56:16, 17.39s/it]
{'loss': 0.3941, 'learning_rate': 8.020009305773278e-07, 'rewards/chosen': 0.10765475034713745, 'rewards/rejected': -1.9532798528671265, 'rewards/accuracies': 1.0, 'rewards/margins': 2.060934543609619, 'policy_logps/rejected': -464.4429931640625, 'policy_logps/chosen': -415.47515869140625, 'referece_logps/rejected': -444.91021728515625, 'referece_logps/chosen': -416.55169677734375, 'logits/rejected': -0.0849832072854042, 'logits/chosen': -9.346453589387238e-05, 'epoch': 3.46}

 58%|█████▊    | 9286/16104 [43:01:36<32:34:22, 17.20s/it]

 58%|█████▊    | 9287/16104 [43:01:53<32:19:05, 17.07s/it]

 58%|█████▊    | 9288/16104 [43:02:10<32:48:48, 17.33s/it]

 58%|█████▊    | 9289/16104 [43:02:31<34:26:00, 18.19s/it]


 58%|█████▊    | 9291/16104 [43:03:07<34:36:46, 18.29s/it]
{'loss': 0.3062, 'learning_rate': 8.008182084312285e-07, 'rewards/chosen': -0.45454350113868713, 'rewards/rejected': -2.1821200847625732, 'rewards/accuracies': 1.0, 'rewards/margins': 1.727576732635498, 'policy_logps/rejected': -333.7994079589844, 'policy_logps/chosen': -414.1282043457031, 'referece_logps/rejected': -311.9781799316406, 'referece_logps/chosen': -409.582763671875, 'logits/rejected': -0.3880617618560791, 'logits/chosen': -0.3738137483596802, 'epoch': 3.46}


 58%|█████▊    | 9293/16104 [43:03:39<32:58:14, 17.43s/it]
{'loss': 0.5344, 'learning_rate': 8.004240320888833e-07, 'rewards/chosen': -1.0522886514663696, 'rewards/rejected': -1.2141402959823608, 'rewards/accuracies': 0.375, 'rewards/margins': 0.16185173392295837, 'policy_logps/rejected': -483.5660705566406, 'policy_logps/chosen': -528.5035400390625, 'referece_logps/rejected': -471.4246520996094, 'referece_logps/chosen': -517.9805908203125, 'logits/rejected': 0.3535478711128235, 'logits/chosen': 0.2063681036233902, 'epoch': 3.46}

 58%|█████▊    | 9294/16104 [43:03:54<31:17:44, 16.54s/it]

 58%|█████▊    | 9295/16104 [43:04:14<33:10:21, 17.54s/it]

 58%|█████▊    | 9296/16104 [43:04:33<34:03:00, 18.01s/it]

 58%|█████▊    | 9297/16104 [43:04:51<34:13:29, 18.10s/it]

 58%|█████▊    | 9298/16104 [43:05:11<35:12:54, 18.63s/it]

 58%|█████▊    | 9299/16104 [43:05:23<31:37:20, 16.73s/it]

 58%|█████▊    | 9300/16104 [43:05:35<28:48:21, 15.24s/it]

 58%|█████▊    | 9301/16104 [43:05:54<30:50:11, 16.32s/it]

 58%|█████▊    | 9302/16104 [43:06:13<32:27:48, 17.18s/it]


 58%|█████▊    | 9304/16104 [43:06:45<31:12:28, 16.52s/it]
{'loss': 0.3486, 'learning_rate': 7.982566411499205e-07, 'rewards/chosen': 0.07486321032047272, 'rewards/rejected': -1.2517521381378174, 'rewards/accuracies': 0.875, 'rewards/margins': 1.326615333557129, 'policy_logps/rejected': -433.1507873535156, 'policy_logps/chosen': -463.15679931640625, 'referece_logps/rejected': -420.63323974609375, 'referece_logps/chosen': -463.90545654296875, 'logits/rejected': 0.23167413473129272, 'logits/chosen': 0.21937797963619232, 'epoch': 3.47}

 58%|█████▊    | 9305/16104 [43:07:05<32:59:16, 17.47s/it]


 58%|█████▊    | 9307/16104 [43:07:37<32:18:38, 17.11s/it]
{'loss': 0.3948, 'learning_rate': 7.976657054623614e-07, 'rewards/chosen': -0.7482013702392578, 'rewards/rejected': -1.497199535369873, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7489981651306152, 'policy_logps/rejected': -339.19561767578125, 'policy_logps/chosen': -280.0745849609375, 'referece_logps/rejected': -324.2236328125, 'referece_logps/chosen': -272.5925598144531, 'logits/rejected': 0.37031346559524536, 'logits/chosen': 0.3002299964427948, 'epoch': 3.47}

 58%|█████▊    | 9308/16104 [43:07:58<34:22:26, 18.21s/it]

 58%|█████▊    | 9309/16104 [43:08:15<33:23:08, 17.69s/it]

 58%|█████▊    | 9310/16104 [43:08:33<33:36:38, 17.81s/it]

 58%|█████▊    | 9311/16104 [43:08:53<35:00:40, 18.55s/it]


 58%|█████▊    | 9313/16104 [43:09:32<35:27:16, 18.79s/it]
{'loss': 0.6112, 'learning_rate': 7.964840552914981e-07, 'rewards/chosen': -0.4775444269180298, 'rewards/rejected': -0.8057794570922852, 'rewards/accuracies': 0.625, 'rewards/margins': 0.32823503017425537, 'policy_logps/rejected': -294.7872619628906, 'policy_logps/chosen': -344.3586730957031, 'referece_logps/rejected': -286.7294616699219, 'referece_logps/chosen': -339.583251953125, 'logits/rejected': -0.13448897004127502, 'logits/chosen': -0.33221912384033203, 'epoch': 3.47}

 58%|█████▊    | 9314/16104 [43:09:48<34:09:20, 18.11s/it]


 58%|█████▊    | 9316/16104 [43:10:24<34:07:38, 18.10s/it]
{'loss': 0.4528, 'learning_rate': 7.958933412383929e-07, 'rewards/chosen': 0.19004936516284943, 'rewards/rejected': -1.3684898614883423, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5585392713546753, 'policy_logps/rejected': -506.953125, 'policy_logps/chosen': -430.31182861328125, 'referece_logps/rejected': -493.2682800292969, 'referece_logps/chosen': -432.2123107910156, 'logits/rejected': -0.13106991350650787, 'logits/chosen': 0.003264659084379673, 'epoch': 3.47}

 58%|█████▊    | 9317/16104 [43:10:41<33:47:47, 17.93s/it]

 58%|█████▊    | 9318/16104 [43:11:01<34:55:43, 18.53s/it]

 58%|█████▊    | 9319/16104 [43:11:21<35:30:34, 18.84s/it]


 58%|█████▊    | 9321/16104 [43:11:52<31:25:18, 16.68s/it]

 58%|█████▊    | 9322/16104 [43:12:10<32:11:59, 17.09s/it]
{'loss': 0.3433, 'learning_rate': 7.947121362721296e-07, 'rewards/chosen': -1.0658574104309082, 'rewards/rejected': -1.366066575050354, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3002092242240906, 'policy_logps/rejected': -406.53033447265625, 'policy_logps/chosen': -400.5767822265625, 'referece_logps/rejected': -392.86962890625, 'referece_logps/chosen': -389.918212890625, 'logits/rejected': -0.37052541971206665, 'logits/chosen': -0.4365113079547882, 'epoch': 3.47}

 58%|█████▊    | 9323/16104 [43:12:32<35:10:04, 18.67s/it]

 58%|█████▊    | 9324/16104 [43:12:48<33:45:57, 17.93s/it]

 58%|█████▊    | 9325/16104 [43:13:08<35:00:57, 18.60s/it]

 58%|█████▊    | 9326/16104 [43:13:24<33:23:33, 17.74s/it]

 58%|█████▊    | 9327/16104 [43:13:39<31:35:51, 16.78s/it]

 58%|█████▊    | 9328/16104 [43:13:57<32:13:57, 17.12s/it]

 58%|█████▊    | 9329/16104 [43:14:10<29:55:41, 15.90s/it]

 58%|█████▊    | 9330/16104 [43:14:26<30:19:42, 16.12s/it]

 58%|█████▊    | 9331/16104 [43:14:40<29:01:44, 15.43s/it]

 58%|█████▊    | 9332/16104 [43:14:58<30:35:57, 16.27s/it]

 58%|█████▊    | 9333/16104 [43:15:09<27:26:36, 14.59s/it]

 58%|█████▊    | 9334/16104 [43:15:26<28:32:53, 15.18s/it]

 58%|█████▊    | 9335/16104 [43:15:37<26:18:36, 13.99s/it]


 58%|█████▊    | 9337/16104 [43:16:02<24:59:47, 13.30s/it]
{'loss': 0.5056, 'learning_rate': 7.917604355390818e-07, 'rewards/chosen': -1.0685423612594604, 'rewards/rejected': -1.2784907817840576, 'rewards/accuracies': 0.625, 'rewards/margins': 0.20994833111763, 'policy_logps/rejected': -429.5881042480469, 'policy_logps/chosen': -423.0979919433594, 'referece_logps/rejected': -416.80322265625, 'referece_logps/chosen': -412.4125671386719, 'logits/rejected': -0.06284435093402863, 'logits/chosen': -0.12439819425344467, 'epoch': 3.48}

 58%|█████▊    | 9338/16104 [43:16:16<25:04:21, 13.34s/it]

 58%|█████▊    | 9339/16104 [43:16:29<25:18:44, 13.47s/it]


 58%|█████▊    | 9341/16104 [43:17:00<27:47:53, 14.80s/it]

 58%|█████▊    | 9342/16104 [43:17:12<26:15:24, 13.98s/it]
{'loss': 0.4429, 'learning_rate': 7.907769551513254e-07, 'rewards/chosen': -0.2332611083984375, 'rewards/rejected': -1.539129376411438, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3058682680130005, 'policy_logps/rejected': -443.11572265625, 'policy_logps/chosen': -417.147705078125, 'referece_logps/rejected': -427.7244567871094, 'referece_logps/chosen': -414.81512451171875, 'logits/rejected': -0.06065550446510315, 'logits/chosen': 0.21810907125473022, 'epoch': 3.48}


 58%|█████▊    | 9344/16104 [43:17:42<27:57:58, 14.89s/it]
{'loss': 0.488, 'learning_rate': 7.903836221846469e-07, 'rewards/chosen': -0.3044656813144684, 'rewards/rejected': -1.6878292560577393, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3833636045455933, 'policy_logps/rejected': -435.4266357421875, 'policy_logps/chosen': -411.5723571777344, 'referece_logps/rejected': -418.54833984375, 'referece_logps/chosen': -408.5277099609375, 'logits/rejected': -0.052028805017471313, 'logits/chosen': -0.049700044095516205, 'epoch': 3.48}

 58%|█████▊    | 9345/16104 [43:18:03<31:11:22, 16.61s/it]

 58%|█████▊    | 9346/16104 [43:18:20<31:24:12, 16.73s/it]

 58%|█████▊    | 9347/16104 [43:18:41<33:40:24, 17.94s/it]

 58%|█████▊    | 9348/16104 [43:18:53<30:46:26, 16.40s/it]

 58%|█████▊    | 9349/16104 [43:19:15<33:37:14, 17.92s/it]


 58%|█████▊    | 9351/16104 [43:19:46<30:57:18, 16.50s/it]

 58%|█████▊    | 9352/16104 [43:19:58<28:32:51, 15.22s/it]
{'loss': 0.4322, 'learning_rate': 7.888106301285494e-07, 'rewards/chosen': -0.4506054222583771, 'rewards/rejected': -1.6909394264221191, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2403340339660645, 'policy_logps/rejected': -361.3305969238281, 'policy_logps/chosen': -327.1212463378906, 'referece_logps/rejected': -344.4211730957031, 'referece_logps/chosen': -322.61517333984375, 'logits/rejected': 0.5704641342163086, 'logits/chosen': 0.5797187089920044, 'epoch': 3.48}

 58%|█████▊    | 9353/16104 [43:20:21<32:38:45, 17.41s/it]

 58%|█████▊    | 9354/16104 [43:20:32<29:03:28, 15.50s/it]

 58%|█████▊    | 9355/16104 [43:20:45<27:43:07, 14.79s/it]

 58%|█████▊    | 9356/16104 [43:20:57<26:07:28, 13.94s/it]

 58%|█████▊    | 9357/16104 [43:21:08<24:19:28, 12.98s/it]

 58%|█████▊    | 9358/16104 [43:21:29<28:55:40, 15.44s/it]

 58%|█████▊    | 9359/16104 [43:21:45<29:03:39, 15.51s/it]


 58%|█████▊    | 9361/16104 [43:22:20<31:01:01, 16.56s/it]
{'loss': 0.4979, 'learning_rate': 7.870416678065637e-07, 'rewards/chosen': -0.2313254326581955, 'rewards/rejected': -1.2366693019866943, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0053439140319824, 'policy_logps/rejected': -455.4364929199219, 'policy_logps/chosen': -461.82818603515625, 'referece_logps/rejected': -443.06976318359375, 'referece_logps/chosen': -459.51495361328125, 'logits/rejected': -0.34178972244262695, 'logits/chosen': -0.2919185161590576, 'epoch': 3.49}


 58%|█████▊    | 9363/16104 [43:22:50<29:10:50, 15.58s/it]
{'loss': 0.4984, 'learning_rate': 7.86648659624282e-07, 'rewards/chosen': -0.36377930641174316, 'rewards/rejected': -1.7886881828308105, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4249088764190674, 'policy_logps/rejected': -523.99169921875, 'policy_logps/chosen': -602.9650268554688, 'referece_logps/rejected': -506.10479736328125, 'referece_logps/chosen': -599.3272705078125, 'logits/rejected': 0.7538588047027588, 'logits/chosen': 0.8214067220687866, 'epoch': 3.49}

 58%|█████▊    | 9364/16104 [43:23:01<26:36:38, 14.21s/it]

 58%|█████▊    | 9365/16104 [43:23:13<25:24:09, 13.57s/it]

 58%|█████▊    | 9366/16104 [43:23:30<26:57:44, 14.41s/it]

 58%|█████▊    | 9367/16104 [43:23:42<25:48:42, 13.79s/it]

 58%|█████▊    | 9368/16104 [43:23:53<24:06:15, 12.88s/it]

 58%|█████▊    | 9369/16104 [43:24:11<27:16:41, 14.58s/it]

 58%|█████▊    | 9370/16104 [43:24:32<30:31:22, 16.32s/it]


 58%|█████▊    | 9372/16104 [43:24:59<27:28:07, 14.69s/it]
{'loss': 0.4723, 'learning_rate': 7.848805509288824e-07, 'rewards/chosen': -0.9004871845245361, 'rewards/rejected': -1.8428341150283813, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9423469305038452, 'policy_logps/rejected': -368.17303466796875, 'policy_logps/chosen': -364.9687194824219, 'referece_logps/rejected': -349.74468994140625, 'referece_logps/chosen': -355.9638671875, 'logits/rejected': -0.007295891642570496, 'logits/chosen': 0.047125041484832764, 'epoch': 3.49}

 58%|█████▊    | 9373/16104 [43:25:18<30:18:36, 16.21s/it]

 58%|█████▊    | 9374/16104 [43:25:38<32:13:21, 17.24s/it]


 58%|█████▊    | 9376/16104 [43:26:15<33:27:00, 17.90s/it]
{'loss': 0.3646, 'learning_rate': 7.840949507487956e-07, 'rewards/chosen': -0.4518440365791321, 'rewards/rejected': -2.150393486022949, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6985492706298828, 'policy_logps/rejected': -466.9837951660156, 'policy_logps/chosen': -505.6203308105469, 'referece_logps/rejected': -445.4798278808594, 'referece_logps/chosen': -501.1018981933594, 'logits/rejected': 0.054672397673130035, 'logits/chosen': 0.059011489152908325, 'epoch': 3.49}


 58%|█████▊    | 9378/16104 [43:26:45<31:24:13, 16.81s/it]

 58%|█████▊    | 9379/16104 [43:27:03<32:03:00, 17.16s/it]
{'loss': 0.4073, 'learning_rate': 7.835058422902403e-07, 'rewards/chosen': -0.22152021527290344, 'rewards/rejected': -1.4191447496414185, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1976244449615479, 'policy_logps/rejected': -388.8673400878906, 'policy_logps/chosen': -385.9073791503906, 'referece_logps/rejected': -374.6759033203125, 'referece_logps/chosen': -383.692138671875, 'logits/rejected': 0.15746551752090454, 'logits/chosen': 0.24046602845191956, 'epoch': 3.49}

 58%|█████▊    | 9380/16104 [43:27:23<34:06:50, 18.26s/it]

 58%|█████▊    | 9381/16104 [43:27:37<31:39:06, 16.95s/it]

 58%|█████▊    | 9382/16104 [43:27:57<33:19:37, 17.85s/it]

 58%|█████▊    | 9383/16104 [43:28:12<31:36:08, 16.93s/it]

 58%|█████▊    | 9384/16104 [43:28:30<32:07:20, 17.21s/it]

 58%|█████▊    | 9385/16104 [43:28:46<31:42:38, 16.99s/it]

 58%|█████▊    | 9386/16104 [43:28:58<28:51:10, 15.46s/it]

 58%|█████▊    | 9387/16104 [43:29:13<28:29:50, 15.27s/it]

 58%|█████▊    | 9388/16104 [43:29:35<32:19:55, 17.33s/it]

 58%|█████▊    | 9389/16104 [43:29:51<31:41:14, 16.99s/it]

 58%|█████▊    | 9390/16104 [43:30:14<34:44:47, 18.63s/it]

 58%|█████▊    | 9391/16104 [43:30:34<35:28:59, 19.03s/it]

 58%|█████▊    | 9392/16104 [43:30:46<31:53:49, 17.11s/it]

 58%|█████▊    | 9393/16104 [43:31:00<29:45:20, 15.96s/it]

 58%|█████▊    | 9394/16104 [43:31:21<32:29:35, 17.43s/it]

 58%|█████▊    | 9395/16104 [43:31:39<32:55:50, 17.67s/it]

 58%|█████▊    | 9396/16104 [43:31:57<33:06:36, 17.77s/it]

 58%|█████▊    | 9397/16104 [43:32:16<33:49:55, 18.16s/it]

 58%|█████▊    | 9398/16104 [43:32:37<35:37:42, 19.13s/it]

 58%|█████▊    | 9399/16104 [43:32:54<34:30:25, 18.53s/it]

 58%|█████▊    | 9400/16104 [43:33:07<31:13:27, 16.77s/it]

 58%|█████▊    | 9401/16104 [43:33:18<27:57:46, 15.02s/it]

 58%|█████▊    | 9402/16104 [43:33:32<27:18:01, 14.66s/it]

 58%|█████▊    | 9403/16104 [43:33:43<25:17:59, 13.59s/it]

 58%|█████▊    | 9404/16104 [43:33:54<23:45:39, 12.77s/it]

 58%|█████▊    | 9405/16104 [43:34:05<22:53:03, 12.30s/it]


 58%|█████▊    | 9407/16104 [43:34:32<23:56:41, 12.87s/it]

 58%|█████▊    | 9408/16104 [43:34:45<24:16:33, 13.05s/it]

 58%|█████▊    | 9409/16104 [43:35:04<27:35:09, 14.83s/it]

 58%|█████▊    | 9410/16104 [43:35:26<31:22:51, 16.88s/it]
{'loss': 0.5226, 'learning_rate': 7.774230425156247e-07, 'rewards/chosen': 0.4333723485469818, 'rewards/rejected': -1.30644953250885, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7398219108581543, 'policy_logps/rejected': -452.86883544921875, 'policy_logps/chosen': -422.3603210449219, 'referece_logps/rejected': -439.8043212890625, 'referece_logps/chosen': -426.6940612792969, 'logits/rejected': -0.21020740270614624, 'logits/chosen': -0.23569291830062866, 'epoch': 3.51}


 58%|█████▊    | 9412/16104 [43:36:03<32:56:02, 17.72s/it]

 58%|█████▊    | 9413/16104 [43:36:23<34:15:26, 18.43s/it]

 58%|█████▊    | 9414/16104 [43:36:43<34:45:08, 18.70s/it]

 58%|█████▊    | 9415/16104 [43:36:58<32:48:36, 17.66s/it]

 58%|█████▊    | 9416/16104 [43:37:17<33:42:04, 18.14s/it]

 58%|█████▊    | 9417/16104 [43:37:35<33:30:43, 18.04s/it]

 58%|█████▊    | 9418/16104 [43:37:51<32:42:42, 17.61s/it]
{'loss': 0.4018, 'learning_rate': 7.758546828120351e-07, 'rewards/chosen': -0.4092757999897003, 'rewards/rejected': -2.3680944442749023, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9588184356689453, 'policy_logps/rejected': -501.0165710449219, 'policy_logps/chosen': -399.88238525390625, 'referece_logps/rejected': -477.33563232421875, 'referece_logps/chosen': -395.7896423339844, 'logits/rejected': 0.24315780401229858, 'logits/chosen': 0.28570884466171265, 'epoch': 3.51}


 58%|█████▊    | 9420/16104 [43:38:27<32:44:12, 17.63s/it]

 59%|█████▊    | 9421/16104 [43:38:47<33:55:50, 18.28s/it]

 59%|█████▊    | 9422/16104 [43:39:00<31:04:25, 16.74s/it]

 59%|█████▊    | 9423/16104 [43:39:15<30:23:51, 16.38s/it]

 59%|█████▊    | 9424/16104 [43:39:28<28:29:12, 15.35s/it]

 59%|█████▊    | 9425/16104 [43:39:43<28:07:32, 15.16s/it]

 59%|█████▊    | 9426/16104 [43:40:04<31:28:18, 16.97s/it]

 59%|█████▊    | 9427/16104 [43:40:23<32:12:56, 17.37s/it]
{'loss': 0.4163, 'learning_rate': 7.740909719789874e-07, 'rewards/chosen': -0.8104934692382812, 'rewards/rejected': -1.2782491445541382, 'rewards/accuracies': 0.625, 'rewards/margins': 0.46775567531585693, 'policy_logps/rejected': -308.73321533203125, 'policy_logps/chosen': -355.9952087402344, 'referece_logps/rejected': -295.95074462890625, 'referece_logps/chosen': -347.8902893066406, 'logits/rejected': -0.36151987314224243, 'logits/chosen': -0.389067679643631, 'epoch': 3.51}


 59%|█████▊    | 9429/16104 [43:40:59<33:27:18, 18.04s/it]

 59%|█████▊    | 9430/16104 [43:41:19<34:30:44, 18.62s/it]
{'loss': 0.3654, 'learning_rate': 7.735032325742355e-07, 'rewards/chosen': 0.022437237203121185, 'rewards/rejected': -1.4443199634552002, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4667572975158691, 'policy_logps/rejected': -448.1942443847656, 'policy_logps/chosen': -419.55108642578125, 'referece_logps/rejected': -433.75103759765625, 'referece_logps/chosen': -419.775390625, 'logits/rejected': -0.03733183816075325, 'logits/chosen': -0.057773325592279434, 'epoch': 3.51}


 59%|█████▊    | 9432/16104 [43:41:49<31:59:20, 17.26s/it]

 59%|█████▊    | 9433/16104 [43:42:01<28:35:53, 15.43s/it]

 59%|█████▊    | 9434/16104 [43:42:20<30:37:22, 16.53s/it]

 59%|█████▊    | 9435/16104 [43:42:39<32:15:36, 17.41s/it]

 59%|█████▊    | 9436/16104 [43:43:01<34:45:31, 18.77s/it]

 59%|█████▊    | 9437/16104 [43:43:16<32:46:18, 17.70s/it]

 59%|█████▊    | 9438/16104 [43:43:34<32:55:25, 17.78s/it]

 59%|█████▊    | 9439/16104 [43:43:54<33:52:56, 18.30s/it]

 59%|█████▊    | 9440/16104 [43:44:13<34:21:02, 18.56s/it]

 59%|█████▊    | 9441/16104 [43:44:28<32:24:07, 17.51s/it]

 59%|█████▊    | 9442/16104 [43:44:45<32:23:08, 17.50s/it]

 59%|█████▊    | 9443/16104 [43:44:59<30:19:49, 16.39s/it]

 59%|█████▊    | 9444/16104 [43:45:18<31:50:08, 17.21s/it]

 59%|█████▊    | 9445/16104 [43:45:31<29:06:43, 15.74s/it]

 59%|█████▊    | 9446/16104 [43:45:51<31:34:02, 17.07s/it]
{'loss': 0.3675, 'learning_rate': 7.703700202882941e-07, 'rewards/chosen': -0.021236054599285126, 'rewards/rejected': -1.240421175956726, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2191851139068604, 'policy_logps/rejected': -585.59521484375, 'policy_logps/chosen': -413.6831359863281, 'referece_logps/rejected': -573.1910400390625, 'referece_logps/chosen': -413.47076416015625, 'logits/rejected': -0.7595053911209106, 'logits/chosen': -0.36977726221084595, 'epoch': 3.52}


 59%|█████▊    | 9448/16104 [43:46:26<31:32:41, 17.06s/it]

 59%|█████▊    | 9449/16104 [43:46:45<32:36:01, 17.64s/it]

 59%|█████▊    | 9450/16104 [43:47:04<33:33:31, 18.16s/it]

 59%|█████▊    | 9451/16104 [43:47:18<31:11:03, 16.87s/it]

 59%|█████▊    | 9452/16104 [43:47:30<28:31:59, 15.44s/it]

 59%|█████▊    | 9453/16104 [43:47:43<27:08:41, 14.69s/it]

 59%|█████▊    | 9454/16104 [43:48:04<30:34:33, 16.55s/it]

 59%|█████▊    | 9455/16104 [43:48:23<32:12:14, 17.44s/it]

 59%|█████▊    | 9456/16104 [43:48:43<33:31:18, 18.15s/it]

 59%|█████▊    | 9457/16104 [43:49:03<34:16:48, 18.57s/it]

 59%|█████▊    | 9458/16104 [43:49:24<35:45:23, 19.37s/it]
{'loss': 0.4919, 'learning_rate': 7.680216698413364e-07, 'rewards/chosen': -0.8527120351791382, 'rewards/rejected': -1.8385814428329468, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9858694076538086, 'policy_logps/rejected': -406.00390625, 'policy_logps/chosen': -432.1827087402344, 'referece_logps/rejected': -387.6180725097656, 'referece_logps/chosen': -423.65557861328125, 'logits/rejected': 0.24372410774230957, 'logits/chosen': 0.3459911346435547, 'epoch': 3.52}

 59%|█████▊    | 9459/16104 [43:49:40<34:08:01, 18.49s/it]

 59%|█████▊    | 9460/16104 [43:49:57<32:51:53, 17.81s/it]


 59%|█████▉    | 9462/16104 [43:50:38<35:22:54, 19.18s/it]

 59%|█████▉    | 9463/16104 [43:50:56<34:36:05, 18.76s/it]

 59%|█████▉    | 9464/16104 [43:51:15<34:54:32, 18.93s/it]

 59%|█████▉    | 9465/16104 [43:51:33<34:23:43, 18.65s/it]

 59%|█████▉    | 9466/16104 [43:51:54<35:41:59, 19.36s/it]

 59%|█████▉    | 9467/16104 [43:52:14<35:48:12, 19.42s/it]

 59%|█████▉    | 9468/16104 [43:52:28<32:46:17, 17.78s/it]

 59%|█████▉    | 9469/16104 [43:52:41<30:36:18, 16.61s/it]

 59%|█████▉    | 9470/16104 [43:53:01<32:09:17, 17.45s/it]

 59%|█████▉    | 9471/16104 [43:53:18<32:03:42, 17.40s/it]

 59%|█████▉    | 9472/16104 [43:53:38<33:14:11, 18.04s/it]

 59%|█████▉    | 9473/16104 [43:53:55<32:54:28, 17.87s/it]

 59%|█████▉    | 9474/16104 [43:54:11<31:43:57, 17.23s/it]

 59%|█████▉    | 9475/16104 [43:54:28<31:48:40, 17.28s/it]

 59%|█████▉    | 9476/16104 [43:54:46<32:08:03, 17.45s/it]

 59%|█████▉    | 9477/16104 [43:55:08<34:33:00, 18.77s/it]

 59%|█████▉    | 9478/16104 [43:55:22<31:44:56, 17.25s/it]

 59%|█████▉    | 9479/16104 [43:55:38<31:12:23, 16.96s/it]

 59%|█████▉    | 9480/16104 [43:55:59<33:36:22, 18.26s/it]

 59%|█████▉    | 9481/16104 [43:56:15<31:56:54, 17.37s/it]

 59%|█████▉    | 9482/16104 [43:56:34<33:03:25, 17.97s/it]

 59%|█████▉    | 9483/16104 [43:56:46<29:35:47, 16.09s/it]

 59%|█████▉    | 9484/16104 [43:57:00<28:53:28, 15.71s/it]

 59%|█████▉    | 9485/16104 [43:57:20<31:03:17, 16.89s/it]

 59%|█████▉    | 9486/16104 [43:57:40<32:27:14, 17.65s/it]

 59%|█████▉    | 9487/16104 [43:58:00<33:55:15, 18.45s/it]

 59%|█████▉    | 9488/16104 [43:58:19<34:29:30, 18.77s/it]

 59%|█████▉    | 9489/16104 [43:58:36<33:34:48, 18.27s/it]

 59%|█████▉    | 9490/16104 [43:58:52<32:00:24, 17.42s/it]

 59%|█████▉    | 9491/16104 [43:59:09<31:58:35, 17.41s/it]

 59%|█████▉    | 9492/16104 [43:59:29<33:09:47, 18.06s/it]

 59%|█████▉    | 9493/16104 [43:59:50<34:51:26, 18.98s/it]

 59%|█████▉    | 9494/16104 [44:00:08<34:29:12, 18.78s/it]

 59%|█████▉    | 9495/16104 [44:00:30<35:51:13, 19.53s/it]

 59%|█████▉    | 9496/16104 [44:00:51<36:44:16, 20.01s/it]

 59%|█████▉    | 9497/16104 [44:01:06<33:58:54, 18.52s/it]

 59%|█████▉    | 9498/16104 [44:01:21<31:55:11, 17.40s/it]

 59%|█████▉    | 9499/16104 [44:01:40<33:12:08, 18.10s/it]

 59%|█████▉    | 9500/16104 [44:01:56<32:10:08, 17.54s/it]

 59%|█████▉    | 9501/16104 [44:02:32<42:08:36, 22.98s/it]

 59%|█████▉    | 9502/16104 [44:02:50<39:34:59, 21.58s/it]
{'loss': 0.4159, 'learning_rate': 7.594227164860543e-07, 'rewards/chosen': -0.6334440112113953, 'rewards/rejected': -1.5106867551803589, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8772426843643188, 'policy_logps/rejected': -465.3411865234375, 'policy_logps/chosen': -432.53485107421875, 'referece_logps/rejected': -450.2342834472656, 'referece_logps/chosen': -426.2004089355469, 'logits/rejected': -0.661520779132843, 'logits/chosen': -0.7434576153755188, 'epoch': 3.54}

 59%|█████▉    | 9503/16104 [44:03:12<39:31:07, 21.55s/it]

 59%|█████▉    | 9504/16104 [44:03:33<39:27:40, 21.52s/it]

 59%|█████▉    | 9505/16104 [44:03:50<36:29:24, 19.91s/it]

 59%|█████▉    | 9506/16104 [44:04:01<31:56:02, 17.42s/it]


 59%|█████▉    | 9508/16104 [44:04:34<31:19:04, 17.09s/it]

 59%|█████▉    | 9509/16104 [44:04:51<31:00:55, 16.93s/it]

 59%|█████▉    | 9510/16104 [44:05:11<32:40:15, 17.84s/it]

 59%|█████▉    | 9511/16104 [44:05:31<34:00:42, 18.57s/it]

 59%|█████▉    | 9512/16104 [44:05:45<31:20:29, 17.12s/it]

 59%|█████▉    | 9513/16104 [44:06:05<33:12:49, 18.14s/it]

 59%|█████▉    | 9514/16104 [44:06:25<33:56:46, 18.54s/it]
{'loss': 0.5229, 'learning_rate': 7.570807889476812e-07, 'rewards/chosen': -0.9194717407226562, 'rewards/rejected': -1.6964478492736816, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7769760489463806, 'policy_logps/rejected': -530.9180908203125, 'policy_logps/chosen': -444.6540222167969, 'referece_logps/rejected': -513.95361328125, 'referece_logps/chosen': -435.4593505859375, 'logits/rejected': -0.6258925199508667, 'logits/chosen': -0.6070236563682556, 'epoch': 3.54}


 59%|█████▉    | 9516/16104 [44:07:01<33:51:31, 18.50s/it]

 59%|█████▉    | 9517/16104 [44:07:13<30:42:44, 16.79s/it]

 59%|█████▉    | 9518/16104 [44:07:25<27:44:47, 15.17s/it]

 59%|█████▉    | 9519/16104 [44:07:37<26:19:48, 14.39s/it]

 59%|█████▉    | 9520/16104 [44:07:57<29:22:18, 16.06s/it]
{'loss': 0.45, 'learning_rate': 7.559103549577852e-07, 'rewards/chosen': -0.16689470410346985, 'rewards/rejected': -0.5592563152313232, 'rewards/accuracies': 0.625, 'rewards/margins': 0.392361581325531, 'policy_logps/rejected': -432.1285095214844, 'policy_logps/chosen': -429.1211853027344, 'referece_logps/rejected': -426.535888671875, 'referece_logps/chosen': -427.45220947265625, 'logits/rejected': 0.19533348083496094, 'logits/chosen': -0.03913868963718414, 'epoch': 3.55}

 59%|█████▉    | 9521/16104 [44:08:13<29:28:12, 16.12s/it]

 59%|█████▉    | 9522/16104 [44:08:26<27:28:40, 15.03s/it]


 59%|█████▉    | 9524/16104 [44:08:49<23:55:52, 13.09s/it]
{'loss': 0.3908, 'learning_rate': 7.551302630032064e-07, 'rewards/chosen': -0.1935325562953949, 'rewards/rejected': -2.5223147869110107, 'rewards/accuracies': 1.0, 'rewards/margins': 2.328782081604004, 'policy_logps/rejected': -347.2349853515625, 'policy_logps/chosen': -415.2226867675781, 'referece_logps/rejected': -322.0118408203125, 'referece_logps/chosen': -413.287353515625, 'logits/rejected': -0.2944243252277374, 'logits/chosen': -0.25306734442710876, 'epoch': 3.55}


 59%|█████▉    | 9526/16104 [44:09:13<23:03:38, 12.62s/it]

 59%|█████▉    | 9527/16104 [44:09:25<22:14:59, 12.18s/it]

 59%|█████▉    | 9528/16104 [44:09:37<22:07:44, 12.11s/it]

 59%|█████▉    | 9529/16104 [44:09:57<26:44:51, 14.65s/it]
{'loss': 0.5061, 'learning_rate': 7.541553709910307e-07, 'rewards/chosen': -0.8286833763122559, 'rewards/rejected': -1.4915755987167358, 'rewards/accuracies': 0.75, 'rewards/margins': 0.66289222240448, 'policy_logps/rejected': -311.8300476074219, 'policy_logps/chosen': -422.87579345703125, 'referece_logps/rejected': -296.9142761230469, 'referece_logps/chosen': -414.5889587402344, 'logits/rejected': -0.5762879252433777, 'logits/chosen': -0.5124552845954895, 'epoch': 3.55}

 59%|█████▉    | 9530/16104 [44:10:16<29:06:58, 15.94s/it]

 59%|█████▉    | 9531/16104 [44:10:32<29:20:07, 16.07s/it]

 59%|█████▉    | 9532/16104 [44:10:52<31:24:04, 17.20s/it]


 59%|█████▉    | 9534/16104 [44:11:31<33:43:28, 18.48s/it]

 59%|█████▉    | 9535/16104 [44:11:51<34:24:14, 18.85s/it]

 59%|█████▉    | 9536/16104 [44:12:13<36:09:54, 19.82s/it]

 59%|█████▉    | 9537/16104 [44:12:24<31:05:54, 17.05s/it]

 59%|█████▉    | 9538/16104 [44:12:35<27:56:35, 15.32s/it]

 59%|█████▉    | 9539/16104 [44:12:49<27:27:07, 15.05s/it]

 59%|█████▉    | 9540/16104 [44:13:07<29:04:40, 15.95s/it]

 59%|█████▉    | 9541/16104 [44:13:27<31:05:31, 17.05s/it]

 59%|█████▉    | 9542/16104 [44:13:43<30:30:44, 16.74s/it]
{'loss': 0.4558, 'learning_rate': 7.516218177672841e-07, 'rewards/chosen': -0.1563492715358734, 'rewards/rejected': -1.1711997985839844, 'rewards/accuracies': 1.0, 'rewards/margins': 1.014850378036499, 'policy_logps/rejected': -322.54681396484375, 'policy_logps/chosen': -381.82635498046875, 'referece_logps/rejected': -310.8348083496094, 'referece_logps/chosen': -380.26287841796875, 'logits/rejected': 0.35579872131347656, 'logits/chosen': 0.25472843647003174, 'epoch': 3.56}


 59%|█████▉    | 9544/16104 [44:14:07<26:05:11, 14.32s/it]
{'loss': 0.4896, 'learning_rate': 7.512321906248298e-07, 'rewards/chosen': 0.0913005918264389, 'rewards/rejected': -0.5438133478164673, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6351139545440674, 'policy_logps/rejected': -645.1019287109375, 'policy_logps/chosen': -482.62908935546875, 'referece_logps/rejected': -639.663818359375, 'referece_logps/chosen': -483.5421142578125, 'logits/rejected': 0.40666642785072327, 'logits/chosen': 0.4020184874534607, 'epoch': 3.56}


 59%|█████▉    | 9546/16104 [44:14:41<28:07:13, 15.44s/it]
{'loss': 0.3776, 'learning_rate': 7.508426037347817e-07, 'rewards/chosen': -1.4669630527496338, 'rewards/rejected': -2.948276996612549, 'rewards/accuracies': 0.75, 'rewards/margins': 1.481313943862915, 'policy_logps/rejected': -578.4375, 'policy_logps/chosen': -558.3810424804688, 'referece_logps/rejected': -548.9547119140625, 'referece_logps/chosen': -543.71142578125, 'logits/rejected': -0.26109129190444946, 'logits/chosen': -0.3662889003753662, 'epoch': 3.56}


 59%|█████▉    | 9548/16104 [44:15:16<30:03:37, 16.51s/it]

 59%|█████▉    | 9549/16104 [44:15:37<32:59:54, 18.12s/it]
{'loss': 0.4181, 'learning_rate': 7.502582990108669e-07, 'rewards/chosen': -0.1981273591518402, 'rewards/rejected': -1.2112762928009033, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0131489038467407, 'policy_logps/rejected': -536.9175415039062, 'policy_logps/chosen': -476.1778564453125, 'referece_logps/rejected': -524.8048095703125, 'referece_logps/chosen': -474.19659423828125, 'logits/rejected': 0.5800203084945679, 'logits/chosen': 0.47191473841667175, 'epoch': 3.56}

 59%|█████▉    | 9550/16104 [44:15:55<32:35:03, 17.90s/it]


 59%|█████▉    | 9552/16104 [44:16:26<30:23:21, 16.70s/it]

 59%|█████▉    | 9553/16104 [44:16:47<32:56:37, 18.10s/it]

 59%|█████▉    | 9554/16104 [44:17:09<34:58:08, 19.22s/it]

 59%|█████▉    | 9555/16104 [44:17:27<34:25:08, 18.92s/it]
{'loss': 0.4976, 'learning_rate': 7.490899625431541e-07, 'rewards/chosen': -1.4118285179138184, 'rewards/rejected': -2.283698797225952, 'rewards/accuracies': 0.625, 'rewards/margins': 0.871870219707489, 'policy_logps/rejected': -575.5939331054688, 'policy_logps/chosen': -527.3397216796875, 'referece_logps/rejected': -552.7569580078125, 'referece_logps/chosen': -513.221435546875, 'logits/rejected': -0.03509598970413208, 'logits/chosen': -0.247654527425766, 'epoch': 3.56}


 59%|█████▉    | 9557/16104 [44:18:00<32:29:21, 17.86s/it]

 59%|█████▉    | 9558/16104 [44:18:21<34:25:33, 18.93s/it]

 59%|█████▉    | 9559/16104 [44:18:41<34:59:27, 19.25s/it]

 59%|█████▉    | 9560/16104 [44:19:00<34:27:07, 18.95s/it]

 59%|█████▉    | 9561/16104 [44:19:12<30:37:53, 16.85s/it]

 59%|█████▉    | 9562/16104 [44:19:26<29:12:04, 16.07s/it]

 59%|█████▉    | 9563/16104 [44:19:46<31:16:00, 17.21s/it]

 59%|█████▉    | 9564/16104 [44:20:06<32:53:39, 18.11s/it]
{'loss': 0.3887, 'learning_rate': 7.473381434817641e-07, 'rewards/chosen': -0.24179181456565857, 'rewards/rejected': -2.049409866333008, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8076180219650269, 'policy_logps/rejected': -351.5557861328125, 'policy_logps/chosen': -432.2830505371094, 'referece_logps/rejected': -331.06170654296875, 'referece_logps/chosen': -429.8650817871094, 'logits/rejected': -0.3510601222515106, 'logits/chosen': -0.48682117462158203, 'epoch': 3.56}

 59%|█████▉    | 9565/16104 [44:20:20<30:50:49, 16.98s/it]


 59%|█████▉    | 9567/16104 [44:20:50<29:21:09, 16.16s/it]

 59%|█████▉    | 9568/16104 [44:21:05<28:53:47, 15.92s/it]

 59%|█████▉    | 9569/16104 [44:21:16<25:59:08, 14.31s/it]
{'loss': 0.5033, 'learning_rate': 7.46365268024255e-07, 'rewards/chosen': -0.5116891860961914, 'rewards/rejected': -1.2174872159957886, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7057980298995972, 'policy_logps/rejected': -268.1536560058594, 'policy_logps/chosen': -291.5760803222656, 'referece_logps/rejected': -255.9788055419922, 'referece_logps/chosen': -286.4591979980469, 'logits/rejected': 0.5371006727218628, 'logits/chosen': 0.4953787922859192, 'epoch': 3.57}

 59%|█████▉    | 9570/16104 [44:21:29<25:10:13, 13.87s/it]

 59%|█████▉    | 9571/16104 [44:21:48<28:13:52, 15.56s/it]


 59%|█████▉    | 9573/16104 [44:22:26<31:08:09, 17.16s/it]
{'loss': 0.4555, 'learning_rate': 7.45587152290611e-07, 'rewards/chosen': -0.6909546256065369, 'rewards/rejected': -1.8939292430877686, 'rewards/accuracies': 0.875, 'rewards/margins': 1.202974796295166, 'policy_logps/rejected': -390.9178771972656, 'policy_logps/chosen': -805.1694946289062, 'referece_logps/rejected': -371.9785461425781, 'referece_logps/chosen': -798.260009765625, 'logits/rejected': -0.49187520146369934, 'logits/chosen': -0.5842118263244629, 'epoch': 3.57}

 59%|█████▉    | 9574/16104 [44:22:45<31:54:03, 17.59s/it]

 59%|█████▉    | 9575/16104 [44:23:03<32:16:31, 17.80s/it]


 59%|█████▉    | 9577/16104 [44:23:32<28:41:31, 15.83s/it]

 59%|█████▉    | 9578/16104 [44:23:46<27:39:41, 15.26s/it]

 59%|█████▉    | 9579/16104 [44:24:06<30:11:57, 16.66s/it]

 59%|█████▉    | 9580/16104 [44:24:18<27:43:34, 15.30s/it]
{'loss': 0.3963, 'learning_rate': 7.442258462805797e-07, 'rewards/chosen': -0.4556085169315338, 'rewards/rejected': -1.484283685684204, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0286750793457031, 'policy_logps/rejected': -519.2303466796875, 'policy_logps/chosen': -359.0433349609375, 'referece_logps/rejected': -504.3874816894531, 'referece_logps/chosen': -354.4872741699219, 'logits/rejected': -0.6135815978050232, 'logits/chosen': -0.3844178020954132, 'epoch': 3.57}


 60%|█████▉    | 9582/16104 [44:24:42<24:35:45, 13.58s/it]
{'loss': 0.4417, 'learning_rate': 7.43836994706982e-07, 'rewards/chosen': -0.16042795777320862, 'rewards/rejected': -1.2890084981918335, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1285805702209473, 'policy_logps/rejected': -475.2756042480469, 'policy_logps/chosen': -462.66375732421875, 'referece_logps/rejected': -462.3855285644531, 'referece_logps/chosen': -461.05950927734375, 'logits/rejected': 0.22337551414966583, 'logits/chosen': 0.18602527678012848, 'epoch': 3.57}


 60%|█████▉    | 9584/16104 [44:25:10<24:32:12, 13.55s/it]
{'loss': 0.4744, 'learning_rate': 7.43448184582387e-07, 'rewards/chosen': -0.765602171421051, 'rewards/rejected': -1.6283104419708252, 'rewards/accuracies': 0.625, 'rewards/margins': 0.862708330154419, 'policy_logps/rejected': -572.4057006835938, 'policy_logps/chosen': -504.62164306640625, 'referece_logps/rejected': -556.12255859375, 'referece_logps/chosen': -496.9656066894531, 'logits/rejected': -0.7222411036491394, 'logits/chosen': -0.6389409303665161, 'epoch': 3.57}

 60%|█████▉    | 9585/16104 [44:25:29<27:46:50, 15.34s/it]

 60%|█████▉    | 9586/16104 [44:25:45<28:01:46, 15.48s/it]

 60%|█████▉    | 9587/16104 [44:26:01<28:23:15, 15.68s/it]


 60%|█████▉    | 9589/16104 [44:26:36<29:42:37, 16.42s/it]
{'loss': 0.3948, 'learning_rate': 7.424763410231295e-07, 'rewards/chosen': -0.9146896600723267, 'rewards/rejected': -2.887195587158203, 'rewards/accuracies': 0.875, 'rewards/margins': 1.972505807876587, 'policy_logps/rejected': -419.4779052734375, 'policy_logps/chosen': -464.1184997558594, 'referece_logps/rejected': -390.60595703125, 'referece_logps/chosen': -454.97161865234375, 'logits/rejected': 0.3493793308734894, 'logits/chosen': 0.2559770345687866, 'epoch': 3.57}


 60%|█████▉    | 9591/16104 [44:27:14<31:45:51, 17.56s/it]
{'loss': 0.3821, 'learning_rate': 7.420876764654325e-07, 'rewards/chosen': -0.5381415486335754, 'rewards/rejected': -1.6778768301010132, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1397353410720825, 'policy_logps/rejected': -405.5260925292969, 'policy_logps/chosen': -281.08331298828125, 'referece_logps/rejected': -388.7473449707031, 'referece_logps/chosen': -275.701904296875, 'logits/rejected': -0.6696969270706177, 'logits/chosen': -0.4796393811702728, 'epoch': 3.57}

 60%|█████▉    | 9592/16104 [44:27:28<29:33:53, 16.34s/it]

 60%|█████▉    | 9593/16104 [44:27:47<31:08:50, 17.22s/it]


 60%|█████▉    | 9595/16104 [44:28:12<27:18:07, 15.10s/it]

 60%|█████▉    | 9596/16104 [44:28:26<26:48:53, 14.83s/it]
{'loss': 0.4552, 'learning_rate': 7.411161977864802e-07, 'rewards/chosen': -0.4193730652332306, 'rewards/rejected': -1.5571281909942627, 'rewards/accuracies': 0.75, 'rewards/margins': 1.137755274772644, 'policy_logps/rejected': -302.07598876953125, 'policy_logps/chosen': -297.2684631347656, 'referece_logps/rejected': -286.50469970703125, 'referece_logps/chosen': -293.07470703125, 'logits/rejected': -0.4286867380142212, 'logits/chosen': -0.4423041343688965, 'epoch': 3.58}

 60%|█████▉    | 9597/16104 [44:28:47<29:55:44, 16.56s/it]


 60%|█████▉    | 9599/16104 [44:29:16<28:13:40, 15.62s/it]
{'loss': 0.4558, 'learning_rate': 7.405334361839746e-07, 'rewards/chosen': -0.5230134725570679, 'rewards/rejected': -2.0257062911987305, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5026929378509521, 'policy_logps/rejected': -390.41705322265625, 'policy_logps/chosen': -463.02886962890625, 'referece_logps/rejected': -370.15997314453125, 'referece_logps/chosen': -457.79876708984375, 'logits/rejected': -0.5306314826011658, 'logits/chosen': -0.5202735662460327, 'epoch': 3.58}

 60%|█████▉    | 9600/16104 [44:29:29<27:08:34, 15.02s/it]


 60%|█████▉    | 9602/16104 [44:30:07<30:39:22, 16.97s/it]

 60%|█████▉    | 9603/16104 [44:30:28<33:03:56, 18.31s/it]
{'loss': 0.4437, 'learning_rate': 7.397565676930252e-07, 'rewards/chosen': -0.951514482498169, 'rewards/rejected': -2.5385940074920654, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5870800018310547, 'policy_logps/rejected': -439.0654602050781, 'policy_logps/chosen': -593.2216796875, 'referece_logps/rejected': -413.6795349121094, 'referece_logps/chosen': -583.70654296875, 'logits/rejected': 0.40585437417030334, 'logits/chosen': 0.42549484968185425, 'epoch': 3.58}


 60%|█████▉    | 9605/16104 [44:31:01<30:18:19, 16.79s/it]
{'loss': 0.4848, 'learning_rate': 7.393681965799934e-07, 'rewards/chosen': -0.8148825168609619, 'rewards/rejected': -1.8019325733184814, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9870501160621643, 'policy_logps/rejected': -320.276611328125, 'policy_logps/chosen': -441.10931396484375, 'referece_logps/rejected': -302.25732421875, 'referece_logps/chosen': -432.96044921875, 'logits/rejected': 0.08196218311786652, 'logits/chosen': -0.012655101716518402, 'epoch': 3.58}

 60%|█████▉    | 9606/16104 [44:31:12<27:05:25, 15.01s/it]

 60%|█████▉    | 9607/16104 [44:31:33<30:38:55, 16.98s/it]

 60%|█████▉    | 9608/16104 [44:31:47<28:57:09, 16.05s/it]

 60%|█████▉    | 9609/16104 [44:32:07<31:09:31, 17.27s/it]

 60%|█████▉    | 9610/16104 [44:32:22<29:42:55, 16.47s/it]

 60%|█████▉    | 9611/16104 [44:32:42<31:32:09, 17.48s/it]


 60%|█████▉    | 9613/16104 [44:33:11<29:00:14, 16.09s/it]

 60%|█████▉    | 9614/16104 [44:33:31<31:10:43, 17.29s/it]

 60%|█████▉    | 9615/16104 [44:33:42<27:57:19, 15.51s/it]
{'loss': 0.4259, 'learning_rate': 7.374269748527055e-07, 'rewards/chosen': -0.07556039839982986, 'rewards/rejected': -0.9775756597518921, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9020153284072876, 'policy_logps/rejected': -313.4471435546875, 'policy_logps/chosen': -405.97265625, 'referece_logps/rejected': -303.67138671875, 'referece_logps/chosen': -405.217041015625, 'logits/rejected': 0.06757203489542007, 'logits/chosen': 0.21690869331359863, 'epoch': 3.58}


 60%|█████▉    | 9617/16104 [44:34:10<26:45:52, 14.85s/it]
{'loss': 0.4418, 'learning_rate': 7.370388577145672e-07, 'rewards/chosen': -0.8520574569702148, 'rewards/rejected': -1.6331844329833984, 'rewards/accuracies': 0.75, 'rewards/margins': 0.781126856803894, 'policy_logps/rejected': -261.096435546875, 'policy_logps/chosen': -288.5801696777344, 'referece_logps/rejected': -244.76458740234375, 'referece_logps/chosen': -280.05963134765625, 'logits/rejected': -0.6927595138549805, 'logits/chosen': -0.7730798721313477, 'epoch': 3.58}


 60%|█████▉    | 9619/16104 [44:34:45<28:31:57, 15.84s/it]
{'loss': 0.3957, 'learning_rate': 7.366507831254183e-07, 'rewards/chosen': -0.6948840022087097, 'rewards/rejected': -1.7166383266448975, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0217543840408325, 'policy_logps/rejected': -339.6148681640625, 'policy_logps/chosen': -577.2128295898438, 'referece_logps/rejected': -322.4484558105469, 'referece_logps/chosen': -570.2639770507812, 'logits/rejected': -0.46098795533180237, 'logits/chosen': -0.4410804808139801, 'epoch': 3.58}

 60%|█████▉    | 9620/16104 [44:35:06<31:43:46, 17.62s/it]


 60%|█████▉    | 9622/16104 [44:35:41<31:24:03, 17.44s/it]
{'loss': 0.5524, 'learning_rate': 7.360687511584085e-07, 'rewards/chosen': -0.4789943993091583, 'rewards/rejected': -1.7292386293411255, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2502442598342896, 'policy_logps/rejected': -631.49267578125, 'policy_logps/chosen': -455.7095642089844, 'referece_logps/rejected': -614.2003173828125, 'referece_logps/chosen': -450.91961669921875, 'logits/rejected': 0.12447769194841385, 'logits/chosen': 0.32729631662368774, 'epoch': 3.58}

 60%|█████▉    | 9623/16104 [44:36:01<32:30:32, 18.06s/it]

 60%|█████▉    | 9624/16104 [44:36:20<33:17:29, 18.50s/it]

 60%|█████▉    | 9625/16104 [44:36:34<30:36:49, 17.01s/it]

 60%|█████▉    | 9626/16104 [44:36:44<27:10:59, 15.11s/it]


 60%|█████▉    | 9628/16104 [44:37:09<24:45:59, 13.77s/it]

 60%|█████▉    | 9629/16104 [44:37:29<28:03:27, 15.60s/it]

 60%|█████▉    | 9630/16104 [44:37:49<30:24:38, 16.91s/it]
{'loss': 0.3452, 'learning_rate': 7.345171362540107e-07, 'rewards/chosen': -0.7654052972793579, 'rewards/rejected': -2.5521414279937744, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7867358922958374, 'policy_logps/rejected': -376.5584716796875, 'policy_logps/chosen': -421.26446533203125, 'referece_logps/rejected': -351.0370788574219, 'referece_logps/chosen': -413.61041259765625, 'logits/rejected': 0.014598576352000237, 'logits/chosen': 0.06622575223445892, 'epoch': 3.59}

 60%|█████▉    | 9631/16104 [44:38:09<31:55:51, 17.76s/it]

 60%|█████▉    | 9632/16104 [44:38:29<33:35:07, 18.68s/it]

 60%|█████▉    | 9633/16104 [44:38:43<31:00:37, 17.25s/it]


 60%|█████▉    | 9635/16104 [44:39:19<31:57:26, 17.78s/it]
{'loss': 0.3582, 'learning_rate': 7.335477257095837e-07, 'rewards/chosen': -0.04834853857755661, 'rewards/rejected': -1.6014385223388672, 'rewards/accuracies': 0.875, 'rewards/margins': 1.55308997631073, 'policy_logps/rejected': -417.392333984375, 'policy_logps/chosen': -385.2864990234375, 'referece_logps/rejected': -401.3779296875, 'referece_logps/chosen': -384.8030090332031, 'logits/rejected': 0.07659043371677399, 'logits/chosen': 0.11682314425706863, 'epoch': 3.59}

 60%|█████▉    | 9636/16104 [44:39:38<32:52:55, 18.30s/it]

 60%|█████▉    | 9637/16104 [44:39:58<33:46:08, 18.80s/it]


 60%|█████▉    | 9639/16104 [44:40:33<32:48:42, 18.27s/it]

 60%|█████▉    | 9640/16104 [44:40:53<33:47:10, 18.82s/it]
{'loss': 0.3319, 'learning_rate': 7.325785846268839e-07, 'rewards/chosen': -0.39678215980529785, 'rewards/rejected': -2.5013139247894287, 'rewards/accuracies': 1.0, 'rewards/margins': 2.104531764984131, 'policy_logps/rejected': -382.8267822265625, 'policy_logps/chosen': -404.3965759277344, 'referece_logps/rejected': -357.8136291503906, 'referece_logps/chosen': -400.42877197265625, 'logits/rejected': 0.1500149816274643, 'logits/chosen': 0.20222337543964386, 'epoch': 3.59}


 60%|█████▉    | 9642/16104 [44:41:31<34:16:25, 19.09s/it]
{'loss': 0.3934, 'learning_rate': 7.321910038626367e-07, 'rewards/chosen': -0.5282459855079651, 'rewards/rejected': -3.077643632888794, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5493977069854736, 'policy_logps/rejected': -417.9186706542969, 'policy_logps/chosen': -456.2684020996094, 'referece_logps/rejected': -387.1422119140625, 'referece_logps/chosen': -450.9859313964844, 'logits/rejected': -0.09830538183450699, 'logits/chosen': -0.03803357481956482, 'epoch': 3.59}

 60%|█████▉    | 9643/16104 [44:41:52<35:08:33, 19.58s/it]

 60%|█████▉    | 9644/16104 [44:42:05<31:38:19, 17.63s/it]


 60%|█████▉    | 9646/16104 [44:42:37<29:55:23, 16.68s/it]
{'loss': 0.4306, 'learning_rate': 7.314159723970684e-07, 'rewards/chosen': -0.6788995862007141, 'rewards/rejected': -1.9532805681228638, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2743809223175049, 'policy_logps/rejected': -469.90203857421875, 'policy_logps/chosen': -507.23004150390625, 'referece_logps/rejected': -450.3692321777344, 'referece_logps/chosen': -500.4410400390625, 'logits/rejected': 0.1623113751411438, 'logits/chosen': 0.034726426005363464, 'epoch': 3.59}

 60%|█████▉    | 9647/16104 [44:42:50<27:38:00, 15.41s/it]

 60%|█████▉    | 9648/16104 [44:43:07<28:20:15, 15.80s/it]

 60%|█████▉    | 9649/16104 [44:43:20<26:53:07, 14.99s/it]

 60%|█████▉    | 9650/16104 [44:43:32<25:36:43, 14.29s/it]

 60%|█████▉    | 9651/16104 [44:43:52<28:38:45, 15.98s/it]


 60%|█████▉    | 9653/16104 [44:44:20<26:18:19, 14.68s/it]
{'loss': 0.4158, 'learning_rate': 7.300600859250698e-07, 'rewards/chosen': -0.3853837847709656, 'rewards/rejected': -1.7613909244537354, 'rewards/accuracies': 1.0, 'rewards/margins': 1.376007318496704, 'policy_logps/rejected': -510.17144775390625, 'policy_logps/chosen': -540.3890991210938, 'referece_logps/rejected': -492.55755615234375, 'referece_logps/chosen': -536.5352783203125, 'logits/rejected': 0.13709211349487305, 'logits/chosen': 0.0858742892742157, 'epoch': 3.6}

 60%|█████▉    | 9654/16104 [44:44:42<30:18:11, 16.91s/it]

 60%|█████▉    | 9655/16104 [44:44:55<28:29:17, 15.90s/it]


 60%|█████▉    | 9657/16104 [44:45:29<28:53:08, 16.13s/it]
{'loss': 0.4758, 'learning_rate': 7.29285533713109e-07, 'rewards/chosen': -0.05268401652574539, 'rewards/rejected': -2.437094211578369, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3844103813171387, 'policy_logps/rejected': -375.8363037109375, 'policy_logps/chosen': -392.2498779296875, 'referece_logps/rejected': -351.46539306640625, 'referece_logps/chosen': -391.72308349609375, 'logits/rejected': -0.23517060279846191, 'logits/chosen': 0.02906164526939392, 'epoch': 3.6}

 60%|█████▉    | 9658/16104 [44:45:43<27:16:59, 15.24s/it]

 60%|█████▉    | 9659/16104 [44:45:55<25:54:33, 14.47s/it]


 60%|█████▉    | 9661/16104 [44:46:30<27:42:27, 15.48s/it]
{'loss': 0.4594, 'learning_rate': 7.285111567152708e-07, 'rewards/chosen': -0.0614677369594574, 'rewards/rejected': -2.0481667518615723, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9866989850997925, 'policy_logps/rejected': -370.54547119140625, 'policy_logps/chosen': -392.45166015625, 'referece_logps/rejected': -350.0637512207031, 'referece_logps/chosen': -391.83697509765625, 'logits/rejected': 0.2337830364704132, 'logits/chosen': 0.19791877269744873, 'epoch': 3.6}


 60%|██████    | 9663/16104 [44:47:00<27:39:38, 15.46s/it]
{'loss': 0.505, 'learning_rate': 7.281240340782772e-07, 'rewards/chosen': -0.6691370606422424, 'rewards/rejected': -1.4482245445251465, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7790873646736145, 'policy_logps/rejected': -319.923828125, 'policy_logps/chosen': -409.3157958984375, 'referece_logps/rejected': -305.44158935546875, 'referece_logps/chosen': -402.6243896484375, 'logits/rejected': -0.4944494068622589, 'logits/chosen': -0.571965217590332, 'epoch': 3.6}


 60%|██████    | 9665/16104 [44:47:32<28:11:03, 15.76s/it]
{'loss': 0.4527, 'learning_rate': 7.277369554327548e-07, 'rewards/chosen': -1.567405104637146, 'rewards/rejected': -2.2732961177825928, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7058911919593811, 'policy_logps/rejected': -492.9500732421875, 'policy_logps/chosen': -432.3443908691406, 'referece_logps/rejected': -470.21710205078125, 'referece_logps/chosen': -416.67034912109375, 'logits/rejected': 0.1824849545955658, 'logits/chosen': 0.2555100917816162, 'epoch': 3.6}

 60%|██████    | 9666/16104 [44:47:47<27:49:49, 15.56s/it]

 60%|██████    | 9667/16104 [44:48:04<28:48:59, 16.12s/it]

 60%|██████    | 9668/16104 [44:48:17<27:08:17, 15.18s/it]

 60%|██████    | 9669/16104 [44:48:37<29:32:49, 16.53s/it]

 60%|██████    | 9670/16104 [44:48:47<26:20:15, 14.74s/it]

 60%|██████    | 9671/16104 [44:49:07<28:55:29, 16.19s/it]

 60%|██████    | 9672/16104 [44:49:26<30:44:14, 17.20s/it]


 60%|██████    | 9674/16104 [44:50:04<32:12:20, 18.03s/it]

 60%|██████    | 9675/16104 [44:50:18<30:05:15, 16.85s/it]

 60%|██████    | 9676/16104 [44:50:40<32:46:14, 18.35s/it]
{'loss': 0.4784, 'learning_rate': 7.256088120284479e-07, 'rewards/chosen': -0.970350444316864, 'rewards/rejected': -2.1543140411376953, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1839637756347656, 'policy_logps/rejected': -359.60980224609375, 'policy_logps/chosen': -411.7693176269531, 'referece_logps/rejected': -338.066650390625, 'referece_logps/chosen': -402.0658264160156, 'logits/rejected': -0.4030822813510895, 'logits/chosen': -0.54661625623703, 'epoch': 3.61}

 60%|██████    | 9677/16104 [44:50:53<29:46:06, 16.67s/it]


 60%|██████    | 9679/16104 [44:51:22<28:10:36, 15.79s/it]
{'loss': 0.5538, 'learning_rate': 7.250286419354967e-07, 'rewards/chosen': -0.4481506645679474, 'rewards/rejected': -1.194295048713684, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7461445331573486, 'policy_logps/rejected': -340.5797119140625, 'policy_logps/chosen': -399.8063049316406, 'referece_logps/rejected': -328.63671875, 'referece_logps/chosen': -395.3248291015625, 'logits/rejected': 0.08769725263118744, 'logits/chosen': 0.15638451278209686, 'epoch': 3.61}

 60%|██████    | 9680/16104 [44:51:41<30:06:36, 16.87s/it]


 60%|██████    | 9682/16104 [44:52:14<28:53:04, 16.19s/it]
{'loss': 0.5271, 'learning_rate': 7.244485719502817e-07, 'rewards/chosen': -0.06328316032886505, 'rewards/rejected': -1.182977557182312, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1196942329406738, 'policy_logps/rejected': -354.3999328613281, 'policy_logps/chosen': -400.35052490234375, 'referece_logps/rejected': -342.5701599121094, 'referece_logps/chosen': -399.71771240234375, 'logits/rejected': -0.09839324653148651, 'logits/chosen': 0.03219342976808548, 'epoch': 3.61}

 60%|██████    | 9683/16104 [44:52:25<26:10:53, 14.68s/it]

 60%|██████    | 9684/16104 [44:52:40<26:35:42, 14.91s/it]


 60%|██████    | 9686/16104 [44:53:20<31:11:23, 17.50s/it]
{'loss': 0.3661, 'learning_rate': 7.236753013914776e-07, 'rewards/chosen': -0.09402607381343842, 'rewards/rejected': -1.3971407413482666, 'rewards/accuracies': 0.875, 'rewards/margins': 1.303114414215088, 'policy_logps/rejected': -564.0347290039062, 'policy_logps/chosen': -536.017333984375, 'referece_logps/rejected': -550.0632934570312, 'referece_logps/chosen': -535.0770263671875, 'logits/rejected': -0.02274034358561039, 'logits/chosen': 0.2859257757663727, 'epoch': 3.61}

 60%|██████    | 9687/16104 [44:53:36<30:36:44, 17.17s/it]

 60%|██████    | 9688/16104 [44:53:53<30:31:51, 17.13s/it]

 60%|██████    | 9689/16104 [44:54:05<27:43:34, 15.56s/it]

 60%|██████    | 9690/16104 [44:54:25<29:52:17, 16.77s/it]


 60%|██████    | 9692/16104 [44:55:00<30:17:38, 17.01s/it]
{'loss': 0.3659, 'learning_rate': 7.225157310444381e-07, 'rewards/chosen': -0.08720492571592331, 'rewards/rejected': -1.740090012550354, 'rewards/accuracies': 1.0, 'rewards/margins': 1.652884840965271, 'policy_logps/rejected': -426.86016845703125, 'policy_logps/chosen': -406.0771789550781, 'referece_logps/rejected': -409.4592590332031, 'referece_logps/chosen': -405.20513916015625, 'logits/rejected': -0.25933218002319336, 'logits/chosen': -0.13794681429862976, 'epoch': 3.61}

 60%|██████    | 9693/16104 [44:55:17<30:13:19, 16.97s/it]

 60%|██████    | 9694/16104 [44:55:32<29:21:24, 16.49s/it]


 60%|██████    | 9696/16104 [44:56:06<29:42:11, 16.69s/it]
{'loss': 0.4378, 'learning_rate': 7.217429085368496e-07, 'rewards/chosen': 0.3829748034477234, 'rewards/rejected': -1.2889825105667114, 'rewards/accuracies': 0.75, 'rewards/margins': 1.67195725440979, 'policy_logps/rejected': -464.5396728515625, 'policy_logps/chosen': -551.5170288085938, 'referece_logps/rejected': -451.6498718261719, 'referece_logps/chosen': -555.3467407226562, 'logits/rejected': -0.28772658109664917, 'logits/chosen': -0.35732388496398926, 'epoch': 3.61}


 60%|██████    | 9698/16104 [44:56:48<33:42:33, 18.94s/it]
{'loss': 0.3697, 'learning_rate': 7.213565647877696e-07, 'rewards/chosen': -0.30170518159866333, 'rewards/rejected': -1.0060114860534668, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7043063640594482, 'policy_logps/rejected': -365.269287109375, 'policy_logps/chosen': -333.252685546875, 'referece_logps/rejected': -355.2091979980469, 'referece_logps/chosen': -330.2356262207031, 'logits/rejected': -0.3033483922481537, 'logits/chosen': -0.25315165519714355, 'epoch': 3.61}

 60%|██████    | 9699/16104 [44:57:11<35:51:42, 20.16s/it]

 60%|██████    | 9700/16104 [44:57:31<35:41:44, 20.07s/it]


 60%|██████    | 9702/16104 [44:58:10<35:17:03, 19.84s/it]
{'loss': 0.3722, 'learning_rate': 7.20584012611605e-07, 'rewards/chosen': -0.49080437421798706, 'rewards/rejected': -1.8504823446273804, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3596779108047485, 'policy_logps/rejected': -404.88555908203125, 'policy_logps/chosen': -326.3641357421875, 'referece_logps/rejected': -386.3807373046875, 'referece_logps/chosen': -321.4560852050781, 'logits/rejected': -0.5840452313423157, 'logits/chosen': -0.5630283951759338, 'epoch': 3.61}

 60%|██████    | 9703/16104 [44:58:31<35:45:01, 20.11s/it]


 60%|██████    | 9705/16104 [44:59:02<30:58:10, 17.42s/it]
{'loss': 0.4275, 'learning_rate': 7.200047171323256e-07, 'rewards/chosen': -0.8088497519493103, 'rewards/rejected': -1.3160324096679688, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5071827173233032, 'policy_logps/rejected': -357.3072204589844, 'policy_logps/chosen': -333.9263000488281, 'referece_logps/rejected': -344.14691162109375, 'referece_logps/chosen': -325.8377990722656, 'logits/rejected': 0.03285805881023407, 'logits/chosen': 0.20555321872234344, 'epoch': 3.62}

 60%|██████    | 9706/16104 [44:59:17<29:44:54, 16.74s/it]

 60%|██████    | 9707/16104 [44:59:37<31:16:22, 17.60s/it]

 60%|██████    | 9708/16104 [44:59:51<29:11:02, 16.43s/it]

 60%|██████    | 9709/16104 [45:00:02<26:12:59, 14.76s/it]

 60%|██████    | 9710/16104 [45:00:15<25:42:36, 14.48s/it]

 60%|██████    | 9711/16104 [45:00:36<28:46:43, 16.21s/it]


 60%|██████    | 9713/16104 [45:01:15<31:27:14, 17.72s/it]
{'loss': 0.4489, 'learning_rate': 7.184604281178587e-07, 'rewards/chosen': -0.7484914660453796, 'rewards/rejected': -2.0362236499786377, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2877321243286133, 'policy_logps/rejected': -395.52435302734375, 'policy_logps/chosen': -317.1269226074219, 'referece_logps/rejected': -375.1620788574219, 'referece_logps/chosen': -309.6419982910156, 'logits/rejected': -0.27019044756889343, 'logits/chosen': -0.30682092905044556, 'epoch': 3.62}

 60%|██████    | 9714/16104 [45:01:27<28:29:37, 16.05s/it]

 60%|██████    | 9715/16104 [45:01:48<31:06:01, 17.52s/it]


 60%|██████    | 9717/16104 [45:02:17<27:45:06, 15.64s/it]
{'loss': 0.5186, 'learning_rate': 7.176885566914375e-07, 'rewards/chosen': -1.1348392963409424, 'rewards/rejected': -1.3860043287277222, 'rewards/accuracies': 0.5, 'rewards/margins': 0.25116515159606934, 'policy_logps/rejected': -321.6234130859375, 'policy_logps/chosen': -439.3504333496094, 'referece_logps/rejected': -307.7633361816406, 'referece_logps/chosen': -428.0020446777344, 'logits/rejected': -0.5515149235725403, 'logits/chosen': -0.6152781248092651, 'epoch': 3.62}

 60%|██████    | 9718/16104 [45:02:36<29:48:47, 16.81s/it]

 60%|██████    | 9719/16104 [45:02:56<31:31:24, 17.77s/it]

 60%|██████    | 9720/16104 [45:03:16<32:31:05, 18.34s/it]


 60%|██████    | 9722/16104 [45:03:51<31:15:36, 17.63s/it]
{'loss': 0.4759, 'learning_rate': 7.16723974416969e-07, 'rewards/chosen': -0.18580855429172516, 'rewards/rejected': -1.2301170825958252, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0443085432052612, 'policy_logps/rejected': -417.53143310546875, 'policy_logps/chosen': -415.2450866699219, 'referece_logps/rejected': -405.23028564453125, 'referece_logps/chosen': -413.386962890625, 'logits/rejected': -0.8183853626251221, 'logits/chosen': -0.7649443745613098, 'epoch': 3.62}

 60%|██████    | 9723/16104 [45:04:02<27:41:36, 15.62s/it]

 60%|██████    | 9724/16104 [45:04:12<25:00:21, 14.11s/it]

 60%|██████    | 9725/16104 [45:04:24<23:43:44, 13.39s/it]

 60%|██████    | 9726/16104 [45:04:35<22:47:35, 12.87s/it]

 60%|██████    | 9727/16104 [45:04:51<24:18:39, 13.72s/it]

 60%|██████    | 9728/16104 [45:05:03<23:23:02, 13.20s/it]

 60%|██████    | 9729/16104 [45:05:14<22:07:29, 12.49s/it]

 60%|██████    | 9730/16104 [45:05:25<21:11:05, 11.97s/it]

 60%|██████    | 9731/16104 [45:05:36<20:34:09, 11.62s/it]

 60%|██████    | 9732/16104 [45:05:48<20:44:22, 11.72s/it]

 60%|██████    | 9733/16104 [45:06:02<22:23:36, 12.65s/it]

 60%|██████    | 9734/16104 [45:06:22<26:09:35, 14.78s/it]

 60%|██████    | 9735/16104 [45:06:36<25:30:30, 14.42s/it]

 60%|██████    | 9736/16104 [45:06:48<24:34:37, 13.89s/it]

 60%|██████    | 9737/16104 [45:07:08<27:41:36, 15.66s/it]

 60%|██████    | 9738/16104 [45:07:26<29:06:12, 16.46s/it]

 60%|██████    | 9739/16104 [45:07:38<26:26:37, 14.96s/it]

 60%|██████    | 9740/16104 [45:07:55<27:28:22, 15.54s/it]

 60%|██████    | 9741/16104 [45:08:12<28:27:13, 16.10s/it]

 60%|██████    | 9742/16104 [45:08:31<29:43:06, 16.82s/it]

 61%|██████    | 9743/16104 [45:08:50<31:10:54, 17.65s/it]

 61%|██████    | 9744/16104 [45:09:03<28:24:10, 16.08s/it]

 61%|██████    | 9745/16104 [45:09:23<30:27:10, 17.24s/it]

 61%|██████    | 9746/16104 [45:09:39<30:13:27, 17.11s/it]

 61%|██████    | 9747/16104 [45:09:52<27:40:12, 15.67s/it]

 61%|██████    | 9748/16104 [45:10:09<28:31:21, 16.16s/it]

 61%|██████    | 9749/16104 [45:10:26<28:48:59, 16.32s/it]

 61%|██████    | 9750/16104 [45:10:40<27:29:48, 15.58s/it]

 61%|██████    | 9751/16104 [45:10:53<26:18:26, 14.91s/it]

 61%|██████    | 9752/16104 [45:11:04<24:08:20, 13.68s/it]

 61%|██████    | 9753/16104 [45:11:14<22:13:25, 12.60s/it]

 61%|██████    | 9754/16104 [45:11:27<22:16:17, 12.63s/it]

 61%|██████    | 9755/16104 [45:11:48<27:01:10, 15.32s/it]

 61%|██████    | 9756/16104 [45:12:09<29:43:09, 16.85s/it]

 61%|██████    | 9757/16104 [45:12:22<27:40:46, 15.70s/it]

 61%|██████    | 9758/16104 [45:12:37<27:41:26, 15.71s/it]

 61%|██████    | 9759/16104 [45:12:57<29:43:49, 16.87s/it]

 61%|██████    | 9760/16104 [45:13:18<31:43:18, 18.00s/it]

 61%|██████    | 9761/16104 [45:13:38<32:48:34, 18.62s/it]

 61%|██████    | 9762/16104 [45:13:57<32:59:32, 18.73s/it]

 61%|██████    | 9763/16104 [45:14:19<35:03:35, 19.90s/it]

 61%|██████    | 9764/16104 [45:14:33<31:51:55, 18.09s/it]

 61%|██████    | 9765/16104 [45:14:45<28:21:56, 16.11s/it]

 61%|██████    | 9766/16104 [45:14:57<26:26:38, 15.02s/it]

 61%|██████    | 9767/16104 [45:15:15<28:03:46, 15.94s/it]

 61%|██████    | 9768/16104 [45:15:26<25:20:20, 14.40s/it]

 61%|██████    | 9769/16104 [45:15:43<27:00:09, 15.34s/it]

 61%|██████    | 9770/16104 [45:15:57<25:50:40, 14.69s/it]

 61%|██████    | 9771/16104 [45:16:17<28:36:03, 16.26s/it]

 61%|██████    | 9772/16104 [45:16:28<26:07:29, 14.85s/it]

 61%|██████    | 9773/16104 [45:16:43<26:00:48, 14.79s/it]

 61%|██████    | 9774/16104 [45:16:57<25:37:03, 14.57s/it]

 61%|██████    | 9775/16104 [45:17:17<28:42:23, 16.33s/it]

 61%|██████    | 9776/16104 [45:17:38<30:48:13, 17.52s/it]

 61%|██████    | 9777/16104 [45:17:53<29:28:34, 16.77s/it]

 61%|██████    | 9778/16104 [45:18:05<27:19:00, 15.55s/it]

 61%|██████    | 9779/16104 [45:18:21<27:24:05, 15.60s/it]


 61%|██████    | 9781/16104 [45:18:53<26:59:25, 15.37s/it]

 61%|██████    | 9782/16104 [45:19:14<30:01:54, 17.10s/it]
{'loss': 0.3981, 'learning_rate': 7.051716109063614e-07, 'rewards/chosen': -0.4915451407432556, 'rewards/rejected': -1.246073603630066, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7545285224914551, 'policy_logps/rejected': -355.1304626464844, 'policy_logps/chosen': -371.09393310546875, 'referece_logps/rejected': -342.66973876953125, 'referece_logps/chosen': -366.1784973144531, 'logits/rejected': 0.2681330442428589, 'logits/chosen': 0.2627871334552765, 'epoch': 3.64}


 61%|██████    | 9784/16104 [45:19:53<32:13:36, 18.36s/it]

 61%|██████    | 9785/16104 [45:20:07<29:43:41, 16.94s/it]
{'loss': 0.4674, 'learning_rate': 7.045951057978e-07, 'rewards/chosen': -0.2607406675815582, 'rewards/rejected': -1.7610533237457275, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5003126859664917, 'policy_logps/rejected': -386.4952697753906, 'policy_logps/chosen': -452.1658935546875, 'referece_logps/rejected': -368.8847351074219, 'referece_logps/chosen': -449.5585021972656, 'logits/rejected': 0.15518192946910858, 'logits/chosen': 0.13617955148220062, 'epoch': 3.65}


 61%|██████    | 9787/16104 [45:20:33<25:46:08, 14.69s/it]

 61%|██████    | 9788/16104 [45:20:49<26:19:00, 15.00s/it]

 61%|██████    | 9789/16104 [45:20:59<24:02:45, 13.71s/it]

 61%|██████    | 9790/16104 [45:21:10<22:20:59, 12.74s/it]

 61%|██████    | 9791/16104 [45:21:21<21:41:06, 12.37s/it]

 61%|██████    | 9792/16104 [45:21:36<23:05:22, 13.17s/it]

 61%|██████    | 9793/16104 [45:21:51<23:58:36, 13.68s/it]

 61%|██████    | 9794/16104 [45:22:02<22:25:52, 12.80s/it]

 61%|██████    | 9795/16104 [45:22:13<21:20:25, 12.18s/it]
{'loss': 0.5035, 'learning_rate': 7.026742000088523e-07, 'rewards/chosen': -0.4936250150203705, 'rewards/rejected': -1.4238696098327637, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9302448034286499, 'policy_logps/rejected': -447.7230529785156, 'policy_logps/chosen': -460.1340637207031, 'referece_logps/rejected': -433.484375, 'referece_logps/chosen': -455.19781494140625, 'logits/rejected': -0.854303777217865, 'logits/chosen': -0.8838914632797241, 'epoch': 3.65}


 61%|██████    | 9797/16104 [45:22:50<27:17:49, 15.58s/it]

 61%|██████    | 9798/16104 [45:23:08<28:24:37, 16.22s/it]

 61%|██████    | 9799/16104 [45:23:23<27:51:23, 15.91s/it]

 61%|██████    | 9800/16104 [45:23:37<27:06:05, 15.48s/it]

 61%|██████    | 9801/16104 [45:23:50<25:52:12, 14.78s/it]

 61%|██████    | 9802/16104 [45:24:04<25:00:48, 14.29s/it]

 61%|██████    | 9803/16104 [45:24:23<27:46:44, 15.87s/it]

 61%|██████    | 9804/16104 [45:24:35<25:50:02, 14.76s/it]

 61%|██████    | 9805/16104 [45:24:51<26:13:44, 14.99s/it]
{'loss': 0.445, 'learning_rate': 7.007544969554215e-07, 'rewards/chosen': 0.10898400843143463, 'rewards/rejected': -1.062671422958374, 'rewards/accuracies': 1.0, 'rewards/margins': 1.171655297279358, 'policy_logps/rejected': -581.89990234375, 'policy_logps/chosen': -556.8401489257812, 'referece_logps/rejected': -571.273193359375, 'referece_logps/chosen': -557.9300537109375, 'logits/rejected': 0.04753616452217102, 'logits/chosen': 0.0833248421549797, 'epoch': 3.65}


 61%|██████    | 9807/16104 [45:25:26<28:06:09, 16.07s/it]

 61%|██████    | 9808/16104 [45:25:43<28:40:48, 16.40s/it]

 61%|██████    | 9809/16104 [45:25:58<27:51:36, 15.93s/it]

 61%|██████    | 9810/16104 [45:26:18<29:57:25, 17.13s/it]

 61%|██████    | 9811/16104 [45:26:34<29:29:30, 16.87s/it]

 61%|██████    | 9812/16104 [45:26:51<29:24:31, 16.83s/it]

 61%|██████    | 9813/16104 [45:27:08<29:46:06, 17.03s/it]

 61%|██████    | 9814/16104 [45:27:21<27:36:53, 15.81s/it]

 61%|██████    | 9815/16104 [45:27:42<30:19:47, 17.36s/it]
{'loss': 0.4297, 'learning_rate': 6.988360044030472e-07, 'rewards/chosen': -0.20171195268630981, 'rewards/rejected': -1.6978764533996582, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4961644411087036, 'policy_logps/rejected': -345.4967041015625, 'policy_logps/chosen': -277.8658142089844, 'referece_logps/rejected': -328.5179443359375, 'referece_logps/chosen': -275.84869384765625, 'logits/rejected': -0.795735239982605, 'logits/chosen': -0.8628787994384766, 'epoch': 3.66}


 61%|██████    | 9817/16104 [45:28:20<31:42:09, 18.15s/it]

 61%|██████    | 9818/16104 [45:28:35<29:54:17, 17.13s/it]

 61%|██████    | 9819/16104 [45:28:57<32:36:49, 18.68s/it]

 61%|██████    | 9820/16104 [45:29:13<30:58:04, 17.74s/it]

 61%|██████    | 9821/16104 [45:29:33<32:07:28, 18.41s/it]

 61%|██████    | 9822/16104 [45:29:44<28:17:44, 16.22s/it]

 61%|██████    | 9823/16104 [45:29:58<26:52:08, 15.40s/it]

 61%|██████    | 9824/16104 [45:30:19<30:13:19, 17.32s/it]

 61%|██████    | 9825/16104 [45:30:39<31:20:30, 17.97s/it]

 61%|██████    | 9826/16104 [45:31:00<32:46:45, 18.80s/it]

 61%|██████    | 9827/16104 [45:31:21<33:53:43, 19.44s/it]

 61%|██████    | 9828/16104 [45:31:37<32:35:41, 18.70s/it]
{'loss': 0.3788, 'learning_rate': 6.963437865458075e-07, 'rewards/chosen': 0.008798502385616302, 'rewards/rejected': -2.410773992538452, 'rewards/accuracies': 1.0, 'rewards/margins': 2.419572591781616, 'policy_logps/rejected': -495.52227783203125, 'policy_logps/chosen': -463.873291015625, 'referece_logps/rejected': -471.4145202636719, 'referece_logps/chosen': -463.9613037109375, 'logits/rejected': -0.4867233633995056, 'logits/chosen': -0.3667618930339813, 'epoch': 3.66}


 61%|██████    | 9830/16104 [45:32:20<34:56:19, 20.05s/it]

 61%|██████    | 9831/16104 [45:32:32<30:40:11, 17.60s/it]

 61%|██████    | 9832/16104 [45:32:43<27:12:16, 15.61s/it]

 61%|██████    | 9833/16104 [45:32:59<27:09:58, 15.60s/it]

 61%|██████    | 9834/16104 [45:33:18<29:22:53, 16.87s/it]

 61%|██████    | 9835/16104 [45:33:31<27:17:38, 15.67s/it]

 61%|██████    | 9836/16104 [45:33:46<26:53:37, 15.45s/it]

 61%|██████    | 9837/16104 [45:34:03<27:45:05, 15.94s/it]
{'loss': 0.608, 'learning_rate': 6.946196199886967e-07, 'rewards/chosen': 0.4449705183506012, 'rewards/rejected': -0.02823255956172943, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4732031226158142, 'policy_logps/rejected': -508.1697692871094, 'policy_logps/chosen': -534.713134765625, 'referece_logps/rejected': -507.887451171875, 'referece_logps/chosen': -539.1629028320312, 'logits/rejected': 0.1646156907081604, 'logits/chosen': 0.10678498446941376, 'epoch': 3.67}


 61%|██████    | 9839/16104 [45:34:36<27:21:22, 15.72s/it]
{'loss': 0.474, 'learning_rate': 6.942366075510121e-07, 'rewards/chosen': -0.4762834310531616, 'rewards/rejected': -2.039262056350708, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5629785060882568, 'policy_logps/rejected': -476.62432861328125, 'policy_logps/chosen': -532.3872680664062, 'referece_logps/rejected': -456.2316589355469, 'referece_logps/chosen': -527.6243896484375, 'logits/rejected': 0.37745076417922974, 'logits/chosen': 0.5196473002433777, 'epoch': 3.67}


 61%|██████    | 9841/16104 [45:35:04<26:05:59, 15.00s/it]

 61%|██████    | 9842/16104 [45:35:15<23:57:25, 13.77s/it]

 61%|██████    | 9843/16104 [45:35:36<27:42:55, 15.94s/it]
{'loss': 0.5379, 'learning_rate': 6.934707311617056e-07, 'rewards/chosen': -0.7062674164772034, 'rewards/rejected': -2.047816514968872, 'rewards/accuracies': 0.875, 'rewards/margins': 1.341549038887024, 'policy_logps/rejected': -439.26422119140625, 'policy_logps/chosen': -453.2484130859375, 'referece_logps/rejected': -418.7860107421875, 'referece_logps/chosen': -446.18572998046875, 'logits/rejected': -0.0652131587266922, 'logits/chosen': -0.06946449726819992, 'epoch': 3.67}


 61%|██████    | 9845/16104 [45:36:12<30:08:58, 17.34s/it]
{'loss': 0.4944, 'learning_rate': 6.930878673340083e-07, 'rewards/chosen': -0.6536230444908142, 'rewards/rejected': -2.60526180267334, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9516388177871704, 'policy_logps/rejected': -606.6660766601562, 'policy_logps/chosen': -507.62396240234375, 'referece_logps/rejected': -580.613525390625, 'referece_logps/chosen': -501.0877380371094, 'logits/rejected': 0.1909618228673935, 'logits/chosen': 0.2194162756204605, 'epoch': 3.67}


 61%|██████    | 9847/16104 [45:36:44<28:49:04, 16.58s/it]

 61%|██████    | 9848/16104 [45:36:59<28:01:18, 16.13s/it]

 61%|██████    | 9849/16104 [45:37:12<26:42:23, 15.37s/it]

 61%|██████    | 9850/16104 [45:37:28<26:55:58, 15.50s/it]

 61%|██████    | 9851/16104 [45:37:44<27:10:46, 15.65s/it]

 61%|██████    | 9852/16104 [45:38:04<29:22:57, 16.92s/it]

 61%|██████    | 9853/16104 [45:38:14<25:49:02, 14.87s/it]
{'loss': 0.3837, 'learning_rate': 6.91556909248332e-07, 'rewards/chosen': -1.0318621397018433, 'rewards/rejected': -2.228728771209717, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1968668699264526, 'policy_logps/rejected': -235.69517517089844, 'policy_logps/chosen': -353.7950439453125, 'referece_logps/rejected': -213.40789794921875, 'referece_logps/chosen': -343.4764404296875, 'logits/rejected': 0.055723994970321655, 'logits/chosen': 0.12640458345413208, 'epoch': 3.67}

 61%|██████    | 9854/16104 [45:38:32<27:09:20, 15.64s/it]


 61%|██████    | 9856/16104 [45:38:58<25:17:57, 14.58s/it]

 61%|██████    | 9857/16104 [45:39:09<23:15:28, 13.40s/it]

 61%|██████    | 9858/16104 [45:39:26<25:09:18, 14.50s/it]

 61%|██████    | 9859/16104 [45:39:39<24:10:11, 13.93s/it]
{'loss': 0.5502, 'learning_rate': 6.904092145043702e-07, 'rewards/chosen': -0.644321084022522, 'rewards/rejected': -1.0784085988998413, 'rewards/accuracies': 0.625, 'rewards/margins': 0.43408751487731934, 'policy_logps/rejected': -669.361328125, 'policy_logps/chosen': -321.3994140625, 'referece_logps/rejected': -658.5772705078125, 'referece_logps/chosen': -314.95623779296875, 'logits/rejected': -0.6256242394447327, 'logits/chosen': -0.5038251876831055, 'epoch': 3.67}


 61%|██████    | 9861/16104 [45:40:18<29:25:55, 16.97s/it]
{'loss': 0.3797, 'learning_rate': 6.900267496951857e-07, 'rewards/chosen': -0.7727145552635193, 'rewards/rejected': -2.037414312362671, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2646996974945068, 'policy_logps/rejected': -402.8126220703125, 'policy_logps/chosen': -359.69158935546875, 'referece_logps/rejected': -382.4384765625, 'referece_logps/chosen': -351.9644775390625, 'logits/rejected': -0.3393690884113312, 'logits/chosen': -0.20050063729286194, 'epoch': 3.67}


 61%|██████    | 9863/16104 [45:40:55<29:56:02, 17.27s/it]

 61%|██████▏   | 9864/16104 [45:41:14<31:06:58, 17.95s/it]

 61%|██████▏   | 9865/16104 [45:41:28<29:06:12, 16.79s/it]

 61%|██████▏   | 9866/16104 [45:41:44<28:45:11, 16.59s/it]
{'loss': 0.4085, 'learning_rate': 6.890708072395709e-07, 'rewards/chosen': -0.12421274185180664, 'rewards/rejected': -1.0665762424468994, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9423635005950928, 'policy_logps/rejected': -315.55804443359375, 'policy_logps/chosen': -346.4505310058594, 'referece_logps/rejected': -304.89227294921875, 'referece_logps/chosen': -345.2083740234375, 'logits/rejected': 0.07309134304523468, 'logits/chosen': -0.03142452985048294, 'epoch': 3.68}


 61%|██████▏   | 9868/16104 [45:42:23<31:14:10, 18.03s/it]

 61%|██████▏   | 9869/16104 [45:42:39<30:05:49, 17.38s/it]
{'loss': 0.4993, 'learning_rate': 6.884973926360208e-07, 'rewards/chosen': -0.9740206003189087, 'rewards/rejected': -2.2200815677642822, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2460609674453735, 'policy_logps/rejected': -389.40484619140625, 'policy_logps/chosen': -517.4906616210938, 'referece_logps/rejected': -367.20404052734375, 'referece_logps/chosen': -507.75042724609375, 'logits/rejected': -0.14193668961524963, 'logits/chosen': -0.10023718327283859, 'epoch': 3.68}


 61%|██████▏   | 9871/16104 [45:43:10<28:35:27, 16.51s/it]
{'loss': 0.4465, 'learning_rate': 6.881151792249487e-07, 'rewards/chosen': -0.1390884518623352, 'rewards/rejected': -1.9390716552734375, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7999833822250366, 'policy_logps/rejected': -581.6517333984375, 'policy_logps/chosen': -435.14788818359375, 'referece_logps/rejected': -562.260986328125, 'referece_logps/chosen': -433.7569580078125, 'logits/rejected': 0.19897544384002686, 'logits/chosen': 0.13347938656806946, 'epoch': 3.68}


 61%|██████▏   | 9873/16104 [45:43:52<32:27:46, 18.76s/it]
{'loss': 0.3686, 'learning_rate': 6.877330162790665e-07, 'rewards/chosen': -1.5000476837158203, 'rewards/rejected': -2.988713264465332, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4886655807495117, 'policy_logps/rejected': -268.763916015625, 'policy_logps/chosen': -318.9635925292969, 'referece_logps/rejected': -238.87680053710938, 'referece_logps/chosen': -303.963134765625, 'logits/rejected': 0.06659726053476334, 'logits/chosen': 0.0565919503569603, 'epoch': 3.68}

 61%|██████▏   | 9874/16104 [45:44:14<33:57:52, 19.63s/it]


 61%|██████▏   | 9876/16104 [45:44:51<32:36:45, 18.85s/it]
{'loss': 0.4406, 'learning_rate': 6.871598666177396e-07, 'rewards/chosen': -1.287231683731079, 'rewards/rejected': -2.3013226985931396, 'rewards/accuracies': 0.75, 'rewards/margins': 1.01409113407135, 'policy_logps/rejected': -345.9570007324219, 'policy_logps/chosen': -638.426025390625, 'referece_logps/rejected': -322.94378662109375, 'referece_logps/chosen': -625.5537109375, 'logits/rejected': -0.9553459882736206, 'logits/chosen': -0.9650487303733826, 'epoch': 3.68}


 61%|██████▏   | 9878/16104 [45:45:23<29:19:41, 16.96s/it]

 61%|██████▏   | 9879/16104 [45:45:40<29:45:21, 17.21s/it]
{'loss': 0.3737, 'learning_rate': 6.865868308508846e-07, 'rewards/chosen': -0.2576879560947418, 'rewards/rejected': -2.3592631816864014, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1015748977661133, 'policy_logps/rejected': -403.21905517578125, 'policy_logps/chosen': -309.72320556640625, 'referece_logps/rejected': -379.62640380859375, 'referece_logps/chosen': -307.14630126953125, 'logits/rejected': -0.7523099780082703, 'logits/chosen': -0.6880677938461304, 'epoch': 3.68}

 61%|██████▏   | 9880/16104 [45:46:02<31:54:45, 18.46s/it]


 61%|██████▏   | 9882/16104 [45:46:29<27:09:53, 15.72s/it]
{'loss': 0.4266, 'learning_rate': 6.86013909187124e-07, 'rewards/chosen': -0.38884294033050537, 'rewards/rejected': -1.4609301090240479, 'rewards/accuracies': 0.875, 'rewards/margins': 1.072087049484253, 'policy_logps/rejected': -328.8101501464844, 'policy_logps/chosen': -338.12359619140625, 'referece_logps/rejected': -314.2008361816406, 'referece_logps/chosen': -334.23516845703125, 'logits/rejected': -0.0773024633526802, 'logits/chosen': -0.1941661685705185, 'epoch': 3.68}


 61%|██████▏   | 9884/16104 [45:47:01<27:17:54, 15.80s/it]

 61%|██████▏   | 9885/16104 [45:47:19<28:22:54, 16.43s/it]
{'loss': 0.4967, 'learning_rate': 6.854411018350396e-07, 'rewards/chosen': -0.33005890250205994, 'rewards/rejected': -1.625305414199829, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2952467203140259, 'policy_logps/rejected': -456.69488525390625, 'policy_logps/chosen': -415.61151123046875, 'referece_logps/rejected': -440.4418640136719, 'referece_logps/chosen': -412.3109130859375, 'logits/rejected': -0.27523335814476013, 'logits/chosen': -0.4481581151485443, 'epoch': 3.68}


 61%|██████▏   | 9887/16104 [45:48:00<31:44:06, 18.38s/it]

 61%|██████▏   | 9888/16104 [45:48:20<32:32:37, 18.85s/it]
{'loss': 0.4844, 'learning_rate': 6.848684090031709e-07, 'rewards/chosen': -0.7126501202583313, 'rewards/rejected': -1.5665349960327148, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8538848161697388, 'policy_logps/rejected': -425.7322692871094, 'policy_logps/chosen': -546.32177734375, 'referece_logps/rejected': -410.06689453125, 'referece_logps/chosen': -539.1952514648438, 'logits/rejected': 0.5214648246765137, 'logits/chosen': 0.5933692455291748, 'epoch': 3.68}


 61%|██████▏   | 9890/16104 [45:48:49<29:13:17, 16.93s/it]

 61%|██████▏   | 9891/16104 [45:49:05<28:47:17, 16.68s/it]

 61%|██████▏   | 9892/16104 [45:49:23<29:32:45, 17.12s/it]
{'loss': 0.4464, 'learning_rate': 6.841049970635984e-07, 'rewards/chosen': -0.6974382400512695, 'rewards/rejected': -2.133758783340454, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4363205432891846, 'policy_logps/rejected': -443.1521911621094, 'policy_logps/chosen': -360.467529296875, 'referece_logps/rejected': -421.8145751953125, 'referece_logps/chosen': -353.49310302734375, 'logits/rejected': -0.2472793161869049, 'logits/chosen': -0.04565510153770447, 'epoch': 3.69}


 61%|██████▏   | 9894/16104 [45:49:53<27:43:24, 16.07s/it]
{'loss': 0.3839, 'learning_rate': 6.837233677340314e-07, 'rewards/chosen': 0.25256845355033875, 'rewards/rejected': -1.5212905406951904, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7738590240478516, 'policy_logps/rejected': -444.4784851074219, 'policy_logps/chosen': -510.37005615234375, 'referece_logps/rejected': -429.2655334472656, 'referece_logps/chosen': -512.8956909179688, 'logits/rejected': -0.29466211795806885, 'logits/chosen': -0.2698676884174347, 'epoch': 3.69}


 61%|██████▏   | 9896/16104 [45:50:34<31:33:28, 18.30s/it]

 61%|██████▏   | 9897/16104 [45:50:45<27:41:14, 16.06s/it]

 61%|██████▏   | 9898/16104 [45:51:01<27:39:33, 16.04s/it]
{'loss': 0.5688, 'learning_rate': 6.829602626640878e-07, 'rewards/chosen': -0.5907419323921204, 'rewards/rejected': -1.5323830842971802, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9416412115097046, 'policy_logps/rejected': -387.7206115722656, 'policy_logps/chosen': -502.8269348144531, 'referece_logps/rejected': -372.3967590332031, 'referece_logps/chosen': -496.91949462890625, 'logits/rejected': -0.42803171277046204, 'logits/chosen': -0.3953167200088501, 'epoch': 3.69}

 61%|██████▏   | 9899/16104 [45:51:19<28:35:16, 16.59s/it]

 61%|██████▏   | 9900/16104 [45:51:32<27:11:10, 15.78s/it]


 61%|██████▏   | 9902/16104 [45:52:04<27:42:41, 16.09s/it]

 61%|██████▏   | 9903/16104 [45:52:17<26:11:32, 15.21s/it]
{'loss': 0.4388, 'learning_rate': 6.82006669943031e-07, 'rewards/chosen': -0.8630207777023315, 'rewards/rejected': -1.8157682418823242, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9527475833892822, 'policy_logps/rejected': -426.1142883300781, 'policy_logps/chosen': -317.1560363769531, 'referece_logps/rejected': -407.95660400390625, 'referece_logps/chosen': -308.5258483886719, 'logits/rejected': -1.1901922225952148, 'logits/chosen': -0.9200553297996521, 'epoch': 3.69}


 62%|██████▏   | 9905/16104 [45:52:55<29:46:17, 17.29s/it]

 62%|██████▏   | 9906/16104 [45:53:12<29:28:46, 17.12s/it]

 62%|██████▏   | 9907/16104 [45:53:33<31:35:44, 18.35s/it]

 62%|██████▏   | 9908/16104 [45:53:44<27:40:16, 16.08s/it]
{'loss': 0.4808, 'learning_rate': 6.810533988068896e-07, 'rewards/chosen': -0.5087212920188904, 'rewards/rejected': -1.050083041191101, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5413617491722107, 'policy_logps/rejected': -505.6759948730469, 'policy_logps/chosen': -578.1749877929688, 'referece_logps/rejected': -495.1751708984375, 'referece_logps/chosen': -573.0877685546875, 'logits/rejected': 0.4560442864894867, 'logits/chosen': 0.49061119556427, 'epoch': 3.69}


 62%|██████▏   | 9910/16104 [45:54:17<27:39:22, 16.07s/it]

 62%|██████▏   | 9911/16104 [45:54:30<25:46:46, 14.99s/it]

 62%|██████▏   | 9912/16104 [45:54:41<24:00:18, 13.96s/it]
{'loss': 0.5607, 'learning_rate': 6.802910140869599e-07, 'rewards/chosen': 0.021829210221767426, 'rewards/rejected': -0.4841299057006836, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5059590935707092, 'policy_logps/rejected': -408.8522033691406, 'policy_logps/chosen': -354.5096740722656, 'referece_logps/rejected': -404.0108947753906, 'referece_logps/chosen': -354.72796630859375, 'logits/rejected': -0.24990183115005493, 'logits/chosen': -0.12194136530160904, 'epoch': 3.69}


 62%|██████▏   | 9914/16104 [45:55:03<21:19:34, 12.40s/it]

 62%|██████▏   | 9915/16104 [45:55:22<24:30:36, 14.26s/it]
{'loss': 0.3841, 'learning_rate': 6.797193613144152e-07, 'rewards/chosen': 0.01730215549468994, 'rewards/rejected': -1.1531555652618408, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1704576015472412, 'policy_logps/rejected': -366.40594482421875, 'policy_logps/chosen': -356.0135192871094, 'referece_logps/rejected': -354.87432861328125, 'referece_logps/chosen': -356.1865539550781, 'logits/rejected': -0.32753583788871765, 'logits/chosen': -0.20115090906620026, 'epoch': 3.69}


 62%|██████▏   | 9917/16104 [45:55:52<25:59:56, 15.13s/it]
{'loss': 0.4514, 'learning_rate': 6.793383242328224e-07, 'rewards/chosen': -0.6445987224578857, 'rewards/rejected': -2.5278353691101074, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8832365274429321, 'policy_logps/rejected': -344.096923828125, 'policy_logps/chosen': -321.7045593261719, 'referece_logps/rejected': -318.81854248046875, 'referece_logps/chosen': -315.25860595703125, 'logits/rejected': -0.8041989207267761, 'logits/chosen': -0.7622864842414856, 'epoch': 3.69}


 62%|██████▏   | 9919/16104 [45:56:29<28:47:56, 16.76s/it]

 62%|██████▏   | 9920/16104 [45:56:49<30:27:23, 17.73s/it]

 62%|██████▏   | 9921/16104 [45:57:10<31:48:30, 18.52s/it]

 62%|██████▏   | 9922/16104 [45:57:30<32:27:30, 18.90s/it]
{'loss': 0.3674, 'learning_rate': 6.783859586620839e-07, 'rewards/chosen': -0.3897640109062195, 'rewards/rejected': -1.6152664422988892, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2255022525787354, 'policy_logps/rejected': -466.0806579589844, 'policy_logps/chosen': -363.82159423828125, 'referece_logps/rejected': -449.92803955078125, 'referece_logps/chosen': -359.9239501953125, 'logits/rejected': 0.07490040361881256, 'logits/chosen': 0.09014560282230377, 'epoch': 3.7}


 62%|██████▏   | 9924/16104 [45:58:08<32:51:26, 19.14s/it]
{'loss': 0.4034, 'learning_rate': 6.780051034488903e-07, 'rewards/chosen': -0.8703989386558533, 'rewards/rejected': -1.5486540794372559, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6782550811767578, 'policy_logps/rejected': -421.3132019042969, 'policy_logps/chosen': -409.8136291503906, 'referece_logps/rejected': -405.82666015625, 'referece_logps/chosen': -401.109619140625, 'logits/rejected': -0.15725107491016388, 'logits/chosen': 0.015330158174037933, 'epoch': 3.7}


 62%|██████▏   | 9926/16104 [45:58:38<28:56:39, 16.87s/it]

 62%|██████▏   | 9927/16104 [45:58:56<29:26:39, 17.16s/it]

 62%|██████▏   | 9928/16104 [45:59:16<31:03:15, 18.10s/it]
{'loss': 0.4806, 'learning_rate': 6.772435493873367e-07, 'rewards/chosen': -0.5566380620002747, 'rewards/rejected': -1.4620189666748047, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9053809642791748, 'policy_logps/rejected': -446.95654296875, 'policy_logps/chosen': -452.75384521484375, 'referece_logps/rejected': -432.3363342285156, 'referece_logps/chosen': -447.1875, 'logits/rejected': -0.413616418838501, 'logits/chosen': -0.42702335119247437, 'epoch': 3.7}


 62%|██████▏   | 9930/16104 [45:59:52<30:36:03, 17.84s/it]

 62%|██████▏   | 9931/16104 [46:00:03<27:23:37, 15.98s/it]

 62%|██████▏   | 9932/16104 [46:00:14<24:42:29, 14.41s/it]

 62%|██████▏   | 9933/16104 [46:00:28<24:17:41, 14.17s/it]

 62%|██████▏   | 9934/16104 [46:00:46<26:24:28, 15.41s/it]
{'loss': 0.468, 'learning_rate': 6.761016101312121e-07, 'rewards/chosen': -0.2969297170639038, 'rewards/rejected': -1.1734898090362549, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8765600919723511, 'policy_logps/rejected': -451.4772033691406, 'policy_logps/chosen': -491.58709716796875, 'referece_logps/rejected': -439.74237060546875, 'referece_logps/chosen': -488.6178283691406, 'logits/rejected': -0.029727011919021606, 'logits/chosen': 0.1098008006811142, 'epoch': 3.7}

 62%|██████▏   | 9935/16104 [46:00:59<25:19:05, 14.77s/it]

 62%|██████▏   | 9936/16104 [46:01:19<27:47:55, 16.22s/it]


 62%|██████▏   | 9938/16104 [46:01:52<27:28:40, 16.04s/it]
{'loss': 0.421, 'learning_rate': 6.753405792364979e-07, 'rewards/chosen': -0.9561703205108643, 'rewards/rejected': -1.8642373085021973, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9080671668052673, 'policy_logps/rejected': -432.2087707519531, 'policy_logps/chosen': -528.5205078125, 'referece_logps/rejected': -413.56640625, 'referece_logps/chosen': -518.958740234375, 'logits/rejected': -0.7679822444915771, 'logits/chosen': -0.8046246767044067, 'epoch': 3.7}


 62%|██████▏   | 9940/16104 [46:02:30<30:22:05, 17.74s/it]

 62%|██████▏   | 9941/16104 [46:02:46<29:22:33, 17.16s/it]

 62%|██████▏   | 9942/16104 [46:03:06<30:28:54, 17.81s/it]

 62%|██████▏   | 9943/16104 [46:03:27<32:06:59, 18.77s/it]
{'loss': 0.4529, 'learning_rate': 6.743895861694899e-07, 'rewards/chosen': -0.9322390556335449, 'rewards/rejected': -1.8320813179016113, 'rewards/accuracies': 0.75, 'rewards/margins': 0.899842381477356, 'policy_logps/rejected': -466.02813720703125, 'policy_logps/chosen': -489.77020263671875, 'referece_logps/rejected': -447.7073059082031, 'referece_logps/chosen': -480.4477844238281, 'logits/rejected': 0.16590112447738647, 'logits/chosen': 0.017383992671966553, 'epoch': 3.7}


 62%|██████▏   | 9945/16104 [46:03:54<28:06:20, 16.43s/it]

 62%|██████▏   | 9946/16104 [46:04:06<25:53:56, 15.14s/it]

 62%|██████▏   | 9947/16104 [46:04:19<24:35:28, 14.38s/it]
{'loss': 0.3854, 'learning_rate': 6.736290287571139e-07, 'rewards/chosen': 0.062058642506599426, 'rewards/rejected': -1.4004325866699219, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4624912738800049, 'policy_logps/rejected': -524.2321166992188, 'policy_logps/chosen': -579.2609252929688, 'referece_logps/rejected': -510.227783203125, 'referece_logps/chosen': -579.8815307617188, 'logits/rejected': 0.2897028625011444, 'logits/chosen': 0.3537307381629944, 'epoch': 3.71}


 62%|██████▏   | 9949/16104 [46:04:49<25:37:41, 14.99s/it]

 62%|██████▏   | 9950/16104 [46:05:04<25:35:36, 14.97s/it]

 62%|██████▏   | 9951/16104 [46:05:20<26:15:13, 15.36s/it]

 62%|██████▏   | 9952/16104 [46:05:38<27:28:46, 16.08s/it]

 62%|██████▏   | 9953/16104 [46:05:53<26:53:25, 15.74s/it]

 62%|██████▏   | 9954/16104 [46:06:10<27:49:00, 16.28s/it]

 62%|██████▏   | 9955/16104 [46:06:22<25:42:42, 15.05s/it]
{'loss': 0.3509, 'learning_rate': 6.721085481342803e-07, 'rewards/chosen': -0.4522932171821594, 'rewards/rejected': -1.4309980869293213, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9787048697471619, 'policy_logps/rejected': -434.3404235839844, 'policy_logps/chosen': -472.06805419921875, 'referece_logps/rejected': -420.0304260253906, 'referece_logps/chosen': -467.545166015625, 'logits/rejected': -0.672370433807373, 'logits/chosen': -0.6339929699897766, 'epoch': 3.71}


 62%|██████▏   | 9957/16104 [46:06:54<26:02:50, 15.25s/it]

 62%|██████▏   | 9958/16104 [46:07:14<28:24:27, 16.64s/it]
{'loss': 0.3599, 'learning_rate': 6.715385865419205e-07, 'rewards/chosen': -0.1871650665998459, 'rewards/rejected': -2.348928689956665, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1617636680603027, 'policy_logps/rejected': -412.3255920410156, 'policy_logps/chosen': -496.72991943359375, 'referece_logps/rejected': -388.8363037109375, 'referece_logps/chosen': -494.8583068847656, 'logits/rejected': -0.6327089667320251, 'logits/chosen': -0.6204272508621216, 'epoch': 3.71}

 62%|██████▏   | 9959/16104 [46:07:34<29:50:53, 17.49s/it]

 62%|██████▏   | 9960/16104 [46:07:53<31:02:41, 18.19s/it]

 62%|██████▏   | 9961/16104 [46:08:14<32:09:23, 18.84s/it]

 62%|██████▏   | 9962/16104 [46:08:26<28:49:53, 16.90s/it]


 62%|██████▏   | 9964/16104 [46:09:02<29:22:55, 17.23s/it]

 62%|██████▏   | 9965/16104 [46:09:20<29:44:27, 17.44s/it]

 62%|██████▏   | 9966/16104 [46:09:39<30:05:20, 17.65s/it]
{'loss': 0.4718, 'learning_rate': 6.700192741471446e-07, 'rewards/chosen': -1.0042009353637695, 'rewards/rejected': -1.4924495220184326, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4882485866546631, 'policy_logps/rejected': -392.6557312011719, 'policy_logps/chosen': -429.17584228515625, 'referece_logps/rejected': -377.7312316894531, 'referece_logps/chosen': -419.1338195800781, 'logits/rejected': -0.41781938076019287, 'logits/chosen': -0.3353286683559418, 'epoch': 3.71}

 62%|██████▏   | 9967/16104 [46:09:56<30:06:40, 17.66s/it]


 62%|██████▏   | 9969/16104 [46:10:31<29:26:04, 17.27s/it]

 62%|██████▏   | 9970/16104 [46:10:53<31:45:58, 18.64s/it]
{'loss': 0.4226, 'learning_rate': 6.692599380633603e-07, 'rewards/chosen': -0.5124205946922302, 'rewards/rejected': -1.6663627624511719, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1539421081542969, 'policy_logps/rejected': -425.8659362792969, 'policy_logps/chosen': -348.7966613769531, 'referece_logps/rejected': -409.20233154296875, 'referece_logps/chosen': -343.6724548339844, 'logits/rejected': -0.5325934886932373, 'logits/chosen': -0.4426332712173462, 'epoch': 3.71}

 62%|██████▏   | 9971/16104 [46:11:14<33:00:03, 19.37s/it]

 62%|██████▏   | 9972/16104 [46:11:32<32:43:54, 19.22s/it]

 62%|██████▏   | 9973/16104 [46:11:54<33:47:25, 19.84s/it]

 62%|██████▏   | 9974/16104 [46:12:10<31:52:01, 18.71s/it]

 62%|██████▏   | 9975/16104 [46:12:30<32:46:58, 19.26s/it]


 62%|██████▏   | 9977/16104 [46:13:05<30:41:37, 18.03s/it]

 62%|██████▏   | 9978/16104 [46:13:25<31:36:45, 18.58s/it]
{'loss': 0.4068, 'learning_rate': 6.677419085803186e-07, 'rewards/chosen': 0.304874986410141, 'rewards/rejected': -1.225602388381958, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5304774045944214, 'policy_logps/rejected': -667.7904663085938, 'policy_logps/chosen': -666.955810546875, 'referece_logps/rejected': -655.534423828125, 'referece_logps/chosen': -670.0045776367188, 'logits/rejected': -0.1884218156337738, 'logits/chosen': -0.2166006863117218, 'epoch': 3.72}


 62%|██████▏   | 9980/16104 [46:13:55<29:23:01, 17.27s/it]
{'loss': 0.3723, 'learning_rate': 6.673625354603885e-07, 'rewards/chosen': -0.6597293615341187, 'rewards/rejected': -1.9774274826049805, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3176980018615723, 'policy_logps/rejected': -612.668701171875, 'policy_logps/chosen': -403.38323974609375, 'referece_logps/rejected': -592.8944091796875, 'referece_logps/chosen': -396.7859802246094, 'logits/rejected': -0.6409171223640442, 'logits/chosen': -0.32907426357269287, 'epoch': 3.72}

 62%|██████▏   | 9981/16104 [46:14:13<29:55:51, 17.60s/it]

 62%|██████▏   | 9982/16104 [46:14:24<26:25:34, 15.54s/it]

 62%|██████▏   | 9983/16104 [46:14:41<26:52:15, 15.80s/it]

 62%|██████▏   | 9984/16104 [46:15:00<28:48:19, 16.94s/it]


 62%|██████▏   | 9986/16104 [46:15:31<26:41:13, 15.70s/it]

 62%|██████▏   | 9987/16104 [46:15:53<29:51:25, 17.57s/it]

 62%|██████▏   | 9988/16104 [46:16:05<27:15:14, 16.04s/it]
{'loss': 0.4331, 'learning_rate': 6.658455818255444e-07, 'rewards/chosen': -0.25632211565971375, 'rewards/rejected': -1.548351764678955, 'rewards/accuracies': 0.875, 'rewards/margins': 1.292029857635498, 'policy_logps/rejected': -288.90496826171875, 'policy_logps/chosen': -598.2994995117188, 'referece_logps/rejected': -273.42144775390625, 'referece_logps/chosen': -595.7362060546875, 'logits/rejected': -0.7199419140815735, 'logits/chosen': -0.935795783996582, 'epoch': 3.72}

 62%|██████▏   | 9989/16104 [46:16:24<28:44:17, 16.92s/it]

 62%|██████▏   | 9990/16104 [46:16:36<25:59:41, 15.31s/it]

 62%|██████▏   | 9991/16104 [46:16:53<26:43:22, 15.74s/it]

 62%|██████▏   | 9992/16104 [46:17:04<24:41:05, 14.54s/it]

 62%|██████▏   | 9993/16104 [46:17:24<27:11:58, 16.02s/it]


 62%|██████▏   | 9995/16104 [46:17:51<25:10:26, 14.83s/it]
{'loss': 0.3516, 'learning_rate': 6.645189569107094e-07, 'rewards/chosen': -0.3706567883491516, 'rewards/rejected': -1.899393916130066, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5287370681762695, 'policy_logps/rejected': -422.2353210449219, 'policy_logps/chosen': -423.3533935546875, 'referece_logps/rejected': -403.2413635253906, 'referece_logps/chosen': -419.6468200683594, 'logits/rejected': -0.5855125784873962, 'logits/chosen': -0.4265516698360443, 'epoch': 3.72}

 62%|██████▏   | 9996/16104 [46:18:04<24:07:10, 14.22s/it]


 62%|██████▏   | 9998/16104 [46:18:36<26:20:38, 15.53s/it]
{'loss': 0.596, 'learning_rate': 6.639506067845698e-07, 'rewards/chosen': -1.3236825466156006, 'rewards/rejected': -1.891268253326416, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5675856471061707, 'policy_logps/rejected': -536.125732421875, 'policy_logps/chosen': -694.5401611328125, 'referece_logps/rejected': -517.2130737304688, 'referece_logps/chosen': -681.3033447265625, 'logits/rejected': -0.15654000639915466, 'logits/chosen': -0.3344263434410095, 'epoch': 3.73}

 62%|██████▏   | 9999/16104 [46:18:50<25:50:17, 15.24s/it]

 62%|██████▏   | 10000/16104 [46:19:02<24:21:32, 14.37s/it]

 62%|██████▏   | 10001/16104 [46:19:30<31:13:45, 18.42s/it]

 62%|██████▏   | 10002/16104 [46:19:42<27:58:28, 16.50s/it]


 62%|██████▏   | 10004/16104 [46:20:13<26:20:01, 15.54s/it]

 62%|██████▏   | 10005/16104 [46:20:32<27:49:22, 16.42s/it]
{'loss': 0.457, 'learning_rate': 6.626249326306996e-07, 'rewards/chosen': 0.028731517493724823, 'rewards/rejected': -2.1011245250701904, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1298561096191406, 'policy_logps/rejected': -691.0716552734375, 'policy_logps/chosen': -438.24053955078125, 'referece_logps/rejected': -670.0604248046875, 'referece_logps/chosen': -438.52783203125, 'logits/rejected': -0.10408315807580948, 'logits/chosen': 0.015189165249466896, 'epoch': 3.73}

 62%|██████▏   | 10006/16104 [46:20:50<28:53:08, 17.05s/it]


 62%|██████▏   | 10008/16104 [46:21:26<29:25:29, 17.38s/it]
{'loss': 0.3476, 'learning_rate': 6.62056991122905e-07, 'rewards/chosen': -0.638586163520813, 'rewards/rejected': -1.5732965469360352, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9347103238105774, 'policy_logps/rejected': -278.4146728515625, 'policy_logps/chosen': -339.1966247558594, 'referece_logps/rejected': -262.6817321777344, 'referece_logps/chosen': -332.8107604980469, 'logits/rejected': -0.13704100251197815, 'logits/chosen': -0.290534108877182, 'epoch': 3.73}

 62%|██████▏   | 10009/16104 [46:21:44<29:58:47, 17.71s/it]

 62%|██████▏   | 10010/16104 [46:21:59<28:28:35, 16.82s/it]

 62%|██████▏   | 10011/16104 [46:22:21<31:10:57, 18.42s/it]

 62%|██████▏   | 10012/16104 [46:22:43<33:00:45, 19.51s/it]

 62%|██████▏   | 10013/16104 [46:23:03<33:00:29, 19.51s/it]


 62%|██████▏   | 10015/16104 [46:23:37<30:52:58, 18.26s/it]

 62%|██████▏   | 10016/16104 [46:23:50<27:50:06, 16.46s/it]
{'loss': 0.4219, 'learning_rate': 6.605430824943887e-07, 'rewards/chosen': -0.35979464650154114, 'rewards/rejected': -1.5792797803878784, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2194851636886597, 'policy_logps/rejected': -503.9493103027344, 'policy_logps/chosen': -407.7580871582031, 'referece_logps/rejected': -488.1565246582031, 'referece_logps/chosen': -404.16015625, 'logits/rejected': -0.2503093183040619, 'logits/chosen': -0.21359843015670776, 'epoch': 3.73}


 62%|██████▏   | 10018/16104 [46:24:17<25:39:35, 15.18s/it]
{'loss': 0.3929, 'learning_rate': 6.601647425005606e-07, 'rewards/chosen': -0.31681135296821594, 'rewards/rejected': -2.0980021953582764, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7811905145645142, 'policy_logps/rejected': -335.50634765625, 'policy_logps/chosen': -336.453857421875, 'referece_logps/rejected': -314.5263366699219, 'referece_logps/chosen': -333.2857360839844, 'logits/rejected': -1.07733952999115, 'logits/chosen': -0.8972877860069275, 'epoch': 3.73}

 62%|██████▏   | 10019/16104 [46:24:28<23:23:06, 13.84s/it]

 62%|██████▏   | 10020/16104 [46:24:45<24:57:59, 14.77s/it]

 62%|██████▏   | 10021/16104 [46:25:02<26:04:15, 15.43s/it]

 62%|██████▏   | 10022/16104 [46:25:15<24:57:31, 14.77s/it]


 62%|██████▏   | 10024/16104 [46:25:49<26:55:57, 15.95s/it]
{'loss': 0.4202, 'learning_rate': 6.590300526905225e-07, 'rewards/chosen': -0.41250571608543396, 'rewards/rejected': -1.0299761295318604, 'rewards/accuracies': 0.75, 'rewards/margins': 0.617470383644104, 'policy_logps/rejected': -537.6453857421875, 'policy_logps/chosen': -388.91632080078125, 'referece_logps/rejected': -527.3455810546875, 'referece_logps/chosen': -384.791259765625, 'logits/rejected': -0.8466092348098755, 'logits/chosen': -0.6131075620651245, 'epoch': 3.73}


 62%|██████▏   | 10026/16104 [46:26:22<27:33:40, 16.32s/it]

 62%|██████▏   | 10027/16104 [46:26:34<25:30:29, 15.11s/it]

 62%|██████▏   | 10028/16104 [46:26:46<23:55:39, 14.18s/it]
{'loss': 0.401, 'learning_rate': 6.582738685720168e-07, 'rewards/chosen': 0.11501996964216232, 'rewards/rejected': -1.4765958786010742, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5916157960891724, 'policy_logps/rejected': -338.20623779296875, 'policy_logps/chosen': -515.791015625, 'referece_logps/rejected': -323.4403076171875, 'referece_logps/chosen': -516.941162109375, 'logits/rejected': -0.20067349076271057, 'logits/chosen': -0.19382424652576447, 'epoch': 3.74}

 62%|██████▏   | 10029/16104 [46:27:07<27:27:52, 16.28s/it]


 62%|██████▏   | 10031/16104 [46:27:32<23:57:26, 14.20s/it]

 62%|██████▏   | 10032/16104 [46:27:48<25:05:06, 14.87s/it]
{'loss': 0.3675, 'learning_rate': 6.575179056284095e-07, 'rewards/chosen': -0.43591904640197754, 'rewards/rejected': -1.2806661128997803, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8447471261024475, 'policy_logps/rejected': -344.9901123046875, 'policy_logps/chosen': -397.7811584472656, 'referece_logps/rejected': -332.18341064453125, 'referece_logps/chosen': -393.4219970703125, 'logits/rejected': 0.28378042578697205, 'logits/chosen': 0.32972806692123413, 'epoch': 3.74}


 62%|██████▏   | 10034/16104 [46:28:24<27:48:12, 16.49s/it]
{'loss': 0.3372, 'learning_rate': 6.571400072500981e-07, 'rewards/chosen': -0.9348481893539429, 'rewards/rejected': -2.690279245376587, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7554311752319336, 'policy_logps/rejected': -291.1246643066406, 'policy_logps/chosen': -262.9859619140625, 'referece_logps/rejected': -264.22186279296875, 'referece_logps/chosen': -253.63748168945312, 'logits/rejected': -0.6130165457725525, 'logits/chosen': -0.5628207921981812, 'epoch': 3.74}


 62%|██████▏   | 10036/16104 [46:29:00<29:07:32, 17.28s/it]
{'loss': 0.4735, 'learning_rate': 6.567621643489807e-07, 'rewards/chosen': -0.016239536926150322, 'rewards/rejected': -1.3616288900375366, 'rewards/accuracies': 0.625, 'rewards/margins': 1.345389485359192, 'policy_logps/rejected': -476.7090759277344, 'policy_logps/chosen': -448.28131103515625, 'referece_logps/rejected': -463.0927734375, 'referece_logps/chosen': -448.1189270019531, 'logits/rejected': 0.5716241002082825, 'logits/chosen': 0.5317245721817017, 'epoch': 3.74}

 62%|██████▏   | 10037/16104 [46:29:11<26:01:10, 15.44s/it]

 62%|██████▏   | 10038/16104 [46:29:23<24:15:50, 14.40s/it]


 62%|██████▏   | 10040/16104 [46:30:00<27:05:41, 16.09s/it]

 62%|██████▏   | 10041/16104 [46:30:16<27:03:47, 16.07s/it]

 62%|██████▏   | 10042/16104 [46:30:30<26:04:36, 15.49s/it]
{'loss': 0.4142, 'learning_rate': 6.556289691201211e-07, 'rewards/chosen': -0.046954743564128876, 'rewards/rejected': -1.2085936069488525, 'rewards/accuracies': 0.875, 'rewards/margins': 1.161638855934143, 'policy_logps/rejected': -313.0700988769531, 'policy_logps/chosen': -411.6592712402344, 'referece_logps/rejected': -300.98419189453125, 'referece_logps/chosen': -411.1897277832031, 'logits/rejected': -0.04311007261276245, 'logits/chosen': -0.058650270104408264, 'epoch': 3.74}


 62%|██████▏   | 10044/16104 [46:31:04<27:37:45, 16.41s/it]
{'loss': 0.4172, 'learning_rate': 6.552513487390648e-07, 'rewards/chosen': -0.4766039550304413, 'rewards/rejected': -1.9804420471191406, 'rewards/accuracies': 0.75, 'rewards/margins': 1.503838300704956, 'policy_logps/rejected': -329.8844299316406, 'policy_logps/chosen': -499.65374755859375, 'referece_logps/rejected': -310.08001708984375, 'referece_logps/chosen': -494.8876953125, 'logits/rejected': 0.7973828315734863, 'logits/chosen': 0.7300221920013428, 'epoch': 3.74}

 62%|██████▏   | 10045/16104 [46:31:21<28:02:20, 16.66s/it]


 62%|██████▏   | 10047/16104 [46:31:54<27:25:27, 16.30s/it]
{'loss': 0.4761, 'learning_rate': 6.546850227793073e-07, 'rewards/chosen': -1.594815969467163, 'rewards/rejected': -2.1928141117095947, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5979981422424316, 'policy_logps/rejected': -381.506591796875, 'policy_logps/chosen': -491.37164306640625, 'referece_logps/rejected': -359.57843017578125, 'referece_logps/chosen': -475.4234619140625, 'logits/rejected': -0.3239476978778839, 'logits/chosen': -0.24417105317115784, 'epoch': 3.74}

 62%|██████▏   | 10048/16104 [46:32:13<28:48:58, 17.13s/it]

 62%|██████▏   | 10049/16104 [46:32:31<28:55:50, 17.20s/it]

 62%|██████▏   | 10050/16104 [46:32:45<27:39:54, 16.45s/it]


 62%|██████▏   | 10052/16104 [46:33:12<24:47:52, 14.75s/it]

 62%|██████▏   | 10053/16104 [46:33:26<24:20:55, 14.49s/it]
{'loss': 0.4373, 'learning_rate': 6.535527482183059e-07, 'rewards/chosen': -0.11944100260734558, 'rewards/rejected': -1.7985270023345947, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6790859699249268, 'policy_logps/rejected': -505.9195556640625, 'policy_logps/chosen': -489.8562927246094, 'referece_logps/rejected': -487.93426513671875, 'referece_logps/chosen': -488.6618347167969, 'logits/rejected': 0.4893569052219391, 'logits/chosen': 0.548547089099884, 'epoch': 3.75}

 62%|██████▏   | 10054/16104 [46:33:39<23:29:02, 13.97s/it]


 62%|██████▏   | 10056/16104 [46:34:07<22:53:33, 13.63s/it]

 62%|██████▏   | 10057/16104 [46:34:20<22:53:24, 13.63s/it]
{'loss': 0.6289, 'learning_rate': 6.52798178697377e-07, 'rewards/chosen': -0.4772844910621643, 'rewards/rejected': -1.0545554161071777, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5772708654403687, 'policy_logps/rejected': -568.3650512695312, 'policy_logps/chosen': -510.6126403808594, 'referece_logps/rejected': -557.8195190429688, 'referece_logps/chosen': -505.83984375, 'logits/rejected': -0.21359296143054962, 'logits/chosen': -0.1915995180606842, 'epoch': 3.75}

 62%|██████▏   | 10058/16104 [46:34:39<25:45:25, 15.34s/it]

 62%|██████▏   | 10059/16104 [46:34:55<25:48:22, 15.37s/it]

 62%|██████▏   | 10060/16104 [46:35:08<24:34:46, 14.64s/it]


 62%|██████▏   | 10062/16104 [46:35:39<24:26:54, 14.57s/it]
{'loss': 0.5328, 'learning_rate': 6.518552828644159e-07, 'rewards/chosen': -0.5392223596572876, 'rewards/rejected': -1.6959846019744873, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1567623615264893, 'policy_logps/rejected': -471.638916015625, 'policy_logps/chosen': -497.29400634765625, 'referece_logps/rejected': -454.6790771484375, 'referece_logps/chosen': -491.90179443359375, 'logits/rejected': -0.9277344346046448, 'logits/chosen': -1.021490454673767, 'epoch': 3.75}


 62%|██████▏   | 10064/16104 [46:36:01<21:23:29, 12.75s/it]
{'loss': 0.4757, 'learning_rate': 6.514782230593622e-07, 'rewards/chosen': -1.0782732963562012, 'rewards/rejected': -1.7702267169952393, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6919534206390381, 'policy_logps/rejected': -335.25067138671875, 'policy_logps/chosen': -359.9928894042969, 'referece_logps/rejected': -317.54840087890625, 'referece_logps/chosen': -349.2101745605469, 'logits/rejected': -0.5036922693252563, 'logits/chosen': -0.5663443803787231, 'epoch': 3.75}

 62%|██████▎   | 10065/16104 [46:36:15<22:22:02, 13.33s/it]


 63%|██████▎   | 10067/16104 [46:36:37<20:08:50, 12.01s/it]
{'loss': 0.5388, 'learning_rate': 6.509127391083029e-07, 'rewards/chosen': -0.8958936929702759, 'rewards/rejected': -1.4795424938201904, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5836487412452698, 'policy_logps/rejected': -494.32550048828125, 'policy_logps/chosen': -383.9137878417969, 'referece_logps/rejected': -479.53009033203125, 'referece_logps/chosen': -374.9548034667969, 'logits/rejected': -1.2760472297668457, 'logits/chosen': -1.019101858139038, 'epoch': 3.75}

 63%|██████▎   | 10068/16104 [46:36:47<19:31:19, 11.64s/it]

 63%|██████▎   | 10069/16104 [46:36:58<19:09:24, 11.43s/it]

 63%|██████▎   | 10070/16104 [46:37:19<23:35:17, 14.07s/it]

 63%|██████▎   | 10071/16104 [46:37:39<26:45:26, 15.97s/it]

 63%|██████▎   | 10072/16104 [46:37:59<28:35:41, 17.07s/it]

 63%|██████▎   | 10073/16104 [46:38:10<25:41:15, 15.33s/it]

 63%|██████▎   | 10074/16104 [46:38:26<25:59:42, 15.52s/it]

 63%|██████▎   | 10075/16104 [46:38:46<28:10:34, 16.82s/it]

 63%|██████▎   | 10076/16104 [46:39:05<29:28:24, 17.60s/it]

 63%|██████▎   | 10077/16104 [46:39:17<26:44:48, 15.98s/it]

 63%|██████▎   | 10078/16104 [46:39:39<29:25:33, 17.58s/it]

 63%|██████▎   | 10079/16104 [46:39:59<30:55:39, 18.48s/it]


 63%|██████▎   | 10081/16104 [46:40:33<29:35:22, 17.69s/it]

 63%|██████▎   | 10082/16104 [46:40:55<31:48:21, 19.01s/it]

 63%|██████▎   | 10083/16104 [46:41:15<32:17:59, 19.31s/it]
{'loss': 0.486, 'learning_rate': 6.478989761456228e-07, 'rewards/chosen': -0.38240936398506165, 'rewards/rejected': -1.7982702255249023, 'rewards/accuracies': 0.875, 'rewards/margins': 1.415860891342163, 'policy_logps/rejected': -305.8406066894531, 'policy_logps/chosen': -430.10699462890625, 'referece_logps/rejected': -287.85791015625, 'referece_logps/chosen': -426.2829284667969, 'logits/rejected': 0.22200331091880798, 'logits/chosen': 0.1417022943496704, 'epoch': 3.76}

 63%|██████▎   | 10084/16104 [46:41:33<31:24:28, 18.78s/it]

 63%|██████▎   | 10085/16104 [46:41:48<29:50:53, 17.85s/it]

 63%|██████▎   | 10086/16104 [46:42:08<30:49:57, 18.44s/it]

 63%|██████▎   | 10087/16104 [46:42:23<28:49:13, 17.24s/it]

 63%|██████▎   | 10088/16104 [46:42:42<30:00:54, 17.96s/it]

 63%|██████▎   | 10089/16104 [46:43:02<30:59:53, 18.55s/it]

 63%|██████▎   | 10090/16104 [46:43:18<29:36:06, 17.72s/it]

 63%|██████▎   | 10091/16104 [46:43:36<29:42:58, 17.79s/it]

 63%|██████▎   | 10092/16104 [46:43:56<30:43:03, 18.39s/it]

 63%|██████▎   | 10093/16104 [46:44:11<29:21:45, 17.59s/it]

 63%|██████▎   | 10094/16104 [46:44:25<27:09:42, 16.27s/it]


 63%|██████▎   | 10096/16104 [46:44:57<27:43:47, 16.62s/it]
{'loss': 0.3822, 'learning_rate': 6.454529771282087e-07, 'rewards/chosen': -0.6006050109863281, 'rewards/rejected': -2.4824318885803223, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8818268775939941, 'policy_logps/rejected': -449.6742248535156, 'policy_logps/chosen': -416.8678894042969, 'referece_logps/rejected': -424.8498840332031, 'referece_logps/chosen': -410.86187744140625, 'logits/rejected': -0.12436030805110931, 'logits/chosen': -0.20643311738967896, 'epoch': 3.76}


 63%|██████▎   | 10098/16104 [46:45:21<23:46:12, 14.25s/it]
{'loss': 0.3924, 'learning_rate': 6.450768842994522e-07, 'rewards/chosen': -0.5198026895523071, 'rewards/rejected': -1.0192533731460571, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4994506537914276, 'policy_logps/rejected': -504.12982177734375, 'policy_logps/chosen': -404.8384094238281, 'referece_logps/rejected': -493.937255859375, 'referece_logps/chosen': -399.640380859375, 'logits/rejected': -0.5778020024299622, 'logits/chosen': -0.4100581407546997, 'epoch': 3.76}

 63%|██████▎   | 10099/16104 [46:45:34<22:55:07, 13.74s/it]

 63%|██████▎   | 10100/16104 [46:45:52<25:07:23, 15.06s/it]

 63%|██████▎   | 10101/16104 [46:46:11<27:21:36, 16.41s/it]

 63%|██████▎   | 10102/16104 [46:46:24<25:31:56, 15.31s/it]

 63%|██████▎   | 10103/16104 [46:46:38<24:42:01, 14.82s/it]

 63%|██████▎   | 10104/16104 [46:46:50<23:24:15, 14.04s/it]

 63%|██████▎   | 10105/16104 [46:47:02<22:25:27, 13.46s/it]

 63%|██████▎   | 10106/16104 [46:47:22<25:26:55, 15.27s/it]


 63%|██████▎   | 10108/16104 [46:47:51<25:01:09, 15.02s/it]
{'loss': 0.4148, 'learning_rate': 6.431972828088281e-07, 'rewards/chosen': -0.9439697861671448, 'rewards/rejected': -1.655301809310913, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7113319635391235, 'policy_logps/rejected': -300.9803161621094, 'policy_logps/chosen': -318.2951965332031, 'referece_logps/rejected': -284.42730712890625, 'referece_logps/chosen': -308.85552978515625, 'logits/rejected': 0.6690108776092529, 'logits/chosen': 0.6068603992462158, 'epoch': 3.77}

 63%|██████▎   | 10109/16104 [46:48:10<26:56:57, 16.18s/it]

 63%|██████▎   | 10110/16104 [46:48:28<27:40:25, 16.62s/it]

 63%|██████▎   | 10111/16104 [46:48:50<30:25:36, 18.28s/it]

 63%|██████▎   | 10112/16104 [46:49:03<27:47:48, 16.70s/it]

 63%|██████▎   | 10113/16104 [46:49:14<24:50:23, 14.93s/it]

 63%|██████▎   | 10114/16104 [46:49:25<22:45:15, 13.68s/it]

 63%|██████▎   | 10115/16104 [46:49:44<25:39:46, 15.43s/it]

 63%|██████▎   | 10116/16104 [46:49:59<25:27:04, 15.30s/it]

 63%|██████▎   | 10117/16104 [46:50:13<24:51:32, 14.95s/it]

 63%|██████▎   | 10118/16104 [46:50:26<23:33:33, 14.17s/it]

 63%|██████▎   | 10119/16104 [46:50:44<25:51:02, 15.55s/it]

 63%|██████▎   | 10120/16104 [46:50:58<24:57:37, 15.02s/it]

 63%|██████▎   | 10121/16104 [46:51:17<26:54:28, 16.19s/it]

 63%|██████▎   | 10122/16104 [46:51:37<28:50:01, 17.35s/it]

 63%|██████▎   | 10123/16104 [46:51:56<29:41:05, 17.87s/it]

 63%|██████▎   | 10124/16104 [46:52:14<29:33:17, 17.79s/it]

 63%|██████▎   | 10125/16104 [46:52:33<30:25:07, 18.32s/it]

 63%|██████▎   | 10126/16104 [46:52:49<29:00:27, 17.47s/it]

 63%|██████▎   | 10127/16104 [46:53:10<30:39:27, 18.47s/it]

 63%|██████▎   | 10128/16104 [46:53:27<30:10:37, 18.18s/it]

 63%|██████▎   | 10129/16104 [46:53:46<30:19:48, 18.27s/it]


 63%|██████▎   | 10131/16104 [46:54:16<27:20:02, 16.47s/it]
{'loss': 0.3878, 'learning_rate': 6.388796893117649e-07, 'rewards/chosen': -1.2599257230758667, 'rewards/rejected': -1.770129680633545, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5102037191390991, 'policy_logps/rejected': -414.9258728027344, 'policy_logps/chosen': -390.0733337402344, 'referece_logps/rejected': -397.2245788574219, 'referece_logps/chosen': -377.4740905761719, 'logits/rejected': -0.1901778131723404, 'logits/chosen': -0.25156641006469727, 'epoch': 3.77}

 63%|██████▎   | 10132/16104 [46:54:35<28:53:51, 17.42s/it]

 63%|██████▎   | 10133/16104 [46:54:52<28:39:45, 17.28s/it]

 63%|██████▎   | 10134/16104 [46:55:05<26:07:35, 15.75s/it]

 63%|██████▎   | 10135/16104 [46:55:17<24:29:59, 14.78s/it]

 63%|██████▎   | 10136/16104 [46:55:39<28:08:06, 16.97s/it]

 63%|██████▎   | 10137/16104 [46:55:53<26:45:44, 16.15s/it]

 63%|██████▎   | 10138/16104 [46:56:12<27:59:17, 16.89s/it]

 63%|██████▎   | 10139/16104 [46:56:25<25:51:38, 15.61s/it]

 63%|██████▎   | 10140/16104 [46:56:44<27:47:39, 16.78s/it]

 63%|██████▎   | 10141/16104 [46:56:57<25:56:11, 15.66s/it]

 63%|██████▎   | 10142/16104 [46:57:08<23:36:57, 14.26s/it]

 63%|██████▎   | 10143/16104 [46:57:23<23:54:46, 14.44s/it]

 63%|██████▎   | 10144/16104 [46:57:43<26:27:38, 15.98s/it]

 63%|██████▎   | 10145/16104 [46:57:56<25:14:10, 15.25s/it]

 63%|██████▎   | 10146/16104 [46:58:11<25:01:23, 15.12s/it]

 63%|██████▎   | 10147/16104 [46:58:22<23:09:20, 13.99s/it]

 63%|██████▎   | 10148/16104 [46:58:34<21:45:46, 13.15s/it]

 63%|██████▎   | 10149/16104 [46:58:55<25:43:26, 15.55s/it]

 63%|██████▎   | 10150/16104 [46:59:08<24:30:33, 14.82s/it]

 63%|██████▎   | 10151/16104 [46:59:18<22:25:22, 13.56s/it]

 63%|██████▎   | 10152/16104 [46:59:35<23:57:50, 14.49s/it]

 63%|██████▎   | 10153/16104 [46:59:52<25:11:25, 15.24s/it]

 63%|██████▎   | 10154/16104 [47:00:12<27:18:52, 16.53s/it]

 63%|██████▎   | 10155/16104 [47:00:32<29:06:09, 17.61s/it]

 63%|██████▎   | 10156/16104 [47:00:49<28:54:43, 17.50s/it]

 63%|██████▎   | 10157/16104 [47:01:11<30:56:33, 18.73s/it]

 63%|██████▎   | 10158/16104 [47:01:31<31:44:38, 19.22s/it]

 63%|██████▎   | 10159/16104 [47:01:47<30:09:11, 18.26s/it]

 63%|██████▎   | 10160/16104 [47:02:02<28:31:47, 17.28s/it]

 63%|██████▎   | 10161/16104 [47:02:14<26:04:09, 15.79s/it]

 63%|██████▎   | 10162/16104 [47:02:30<26:00:31, 15.76s/it]

 63%|██████▎   | 10163/16104 [47:02:48<27:00:24, 16.36s/it]

 63%|██████▎   | 10164/16104 [47:03:05<27:39:44, 16.77s/it]

 63%|██████▎   | 10165/16104 [47:03:25<29:13:50, 17.72s/it]

 63%|██████▎   | 10166/16104 [47:03:45<30:18:13, 18.37s/it]

 63%|██████▎   | 10167/16104 [47:04:05<31:11:32, 18.91s/it]

 63%|██████▎   | 10168/16104 [47:04:27<32:22:45, 19.64s/it]

 63%|██████▎   | 10169/16104 [47:04:45<31:41:22, 19.22s/it]


 63%|██████▎   | 10171/16104 [47:05:19<29:23:38, 17.84s/it]

 63%|██████▎   | 10172/16104 [47:05:40<31:14:27, 18.96s/it]

 63%|██████▎   | 10173/16104 [47:05:51<27:12:05, 16.51s/it]

 63%|██████▎   | 10174/16104 [47:06:04<25:37:11, 15.55s/it]

 63%|██████▎   | 10175/16104 [47:06:24<27:54:58, 16.95s/it]

 63%|██████▎   | 10176/16104 [47:06:44<29:12:34, 17.74s/it]

 63%|██████▎   | 10177/16104 [47:06:57<26:40:36, 16.20s/it]

 63%|██████▎   | 10178/16104 [47:07:12<26:21:51, 16.02s/it]

 63%|██████▎   | 10179/16104 [47:07:25<24:57:51, 15.17s/it]

 63%|██████▎   | 10180/16104 [47:07:46<27:42:56, 16.84s/it]

 63%|██████▎   | 10181/16104 [47:08:06<29:01:07, 17.64s/it]

 63%|██████▎   | 10182/16104 [47:08:16<25:35:59, 15.56s/it]

 63%|██████▎   | 10183/16104 [47:08:28<23:34:26, 14.33s/it]

 63%|██████▎   | 10184/16104 [47:08:40<22:18:28, 13.57s/it]

 63%|██████▎   | 10185/16104 [47:09:00<25:44:56, 15.66s/it]

 63%|██████▎   | 10186/16104 [47:09:16<26:04:21, 15.86s/it]

 63%|██████▎   | 10187/16104 [47:09:37<28:15:04, 17.19s/it]

 63%|██████▎   | 10188/16104 [47:09:52<27:19:53, 16.63s/it]
{'loss': 0.5242, 'learning_rate': 6.282130682154602e-07, 'rewards/chosen': -0.572792649269104, 'rewards/rejected': -1.081358790397644, 'rewards/accuracies': 0.625, 'rewards/margins': 0.50856614112854, 'policy_logps/rejected': -327.8427734375, 'policy_logps/chosen': -595.8704833984375, 'referece_logps/rejected': -317.0292053222656, 'referece_logps/chosen': -590.142578125, 'logits/rejected': 0.4036003649234772, 'logits/chosen': 0.34031176567077637, 'epoch': 3.8}


 63%|██████▎   | 10190/16104 [47:10:14<22:32:09, 13.72s/it]

 63%|██████▎   | 10191/16104 [47:10:30<23:39:52, 14.41s/it]

 63%|██████▎   | 10192/16104 [47:10:44<23:25:43, 14.27s/it]

 63%|██████▎   | 10193/16104 [47:11:04<26:17:24, 16.01s/it]

 63%|██████▎   | 10194/16104 [47:11:15<23:38:46, 14.40s/it]

 63%|██████▎   | 10195/16104 [47:11:28<23:12:07, 14.14s/it]
{'loss': 0.5729, 'learning_rate': 6.269064728974562e-07, 'rewards/chosen': 0.10118180513381958, 'rewards/rejected': -0.5099853277206421, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6111671924591064, 'policy_logps/rejected': -531.61767578125, 'policy_logps/chosen': -495.2412109375, 'referece_logps/rejected': -526.517822265625, 'referece_logps/chosen': -496.25299072265625, 'logits/rejected': 0.7611914277076721, 'logits/chosen': 0.7893141508102417, 'epoch': 3.8}


 63%|██████▎   | 10197/16104 [47:12:01<24:52:46, 15.16s/it]

 63%|██████▎   | 10198/16104 [47:12:17<25:22:29, 15.47s/it]

 63%|██████▎   | 10199/16104 [47:12:32<25:12:34, 15.37s/it]

 63%|██████▎   | 10200/16104 [47:12:52<27:39:31, 16.87s/it]

 63%|██████▎   | 10201/16104 [47:13:13<29:18:46, 17.88s/it]

 63%|██████▎   | 10202/16104 [47:13:31<29:31:38, 18.01s/it]

 63%|██████▎   | 10203/16104 [47:13:51<30:23:16, 18.54s/it]

 63%|██████▎   | 10204/16104 [47:14:03<27:10:04, 16.58s/it]

 63%|██████▎   | 10205/16104 [47:14:14<24:28:35, 14.94s/it]

 63%|██████▎   | 10206/16104 [47:14:28<24:17:07, 14.82s/it]

 63%|██████▎   | 10207/16104 [47:14:46<25:34:36, 15.61s/it]
{'loss': 0.3089, 'learning_rate': 6.246683171651088e-07, 'rewards/chosen': 0.060190968215465546, 'rewards/rejected': -2.040327548980713, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1005187034606934, 'policy_logps/rejected': -252.57400512695312, 'policy_logps/chosen': -374.4923400878906, 'referece_logps/rejected': -232.1707305908203, 'referece_logps/chosen': -375.0942687988281, 'logits/rejected': -0.19948981702327728, 'logits/chosen': -0.2179347723722458, 'epoch': 3.8}


 63%|██████▎   | 10209/16104 [47:15:22<27:34:23, 16.84s/it]
{'loss': 0.488, 'learning_rate': 6.242955034174203e-07, 'rewards/chosen': -1.2997534275054932, 'rewards/rejected': -1.730779767036438, 'rewards/accuracies': 0.875, 'rewards/margins': 0.431026428937912, 'policy_logps/rejected': -379.7262268066406, 'policy_logps/chosen': -484.274169921875, 'referece_logps/rejected': -362.4184265136719, 'referece_logps/chosen': -471.276611328125, 'logits/rejected': 0.8023651838302612, 'logits/chosen': 0.8660218119621277, 'epoch': 3.8}

 63%|██████▎   | 10210/16104 [47:15:39<27:40:18, 16.90s/it]

 63%|██████▎   | 10211/16104 [47:15:58<28:22:20, 17.33s/it]


 63%|██████▎   | 10213/16104 [47:16:27<25:59:36, 15.88s/it]

 63%|██████▎   | 10214/16104 [47:16:49<29:12:19, 17.85s/it]

 63%|██████▎   | 10215/16104 [47:17:07<29:10:00, 17.83s/it]
{'loss': 0.3626, 'learning_rate': 6.231774271656129e-07, 'rewards/chosen': -1.2588818073272705, 'rewards/rejected': -1.9088877439498901, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6500058174133301, 'policy_logps/rejected': -423.6537170410156, 'policy_logps/chosen': -594.1002197265625, 'referece_logps/rejected': -404.5648193359375, 'referece_logps/chosen': -581.5113525390625, 'logits/rejected': 0.2874484360218048, 'logits/chosen': 0.29870155453681946, 'epoch': 3.81}

 63%|██████▎   | 10216/16104 [47:17:25<29:36:32, 18.10s/it]


 63%|██████▎   | 10218/16104 [47:18:03<30:15:36, 18.51s/it]

 63%|██████▎   | 10219/16104 [47:18:21<30:07:37, 18.43s/it]

 63%|██████▎   | 10220/16104 [47:18:34<27:26:11, 16.79s/it]
{'loss': 0.4793, 'learning_rate': 6.22246116073151e-07, 'rewards/chosen': -0.10424328595399857, 'rewards/rejected': -1.556694507598877, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4524511098861694, 'policy_logps/rejected': -404.0150146484375, 'policy_logps/chosen': -428.38885498046875, 'referece_logps/rejected': -388.44805908203125, 'referece_logps/chosen': -427.3464050292969, 'logits/rejected': -0.07896201312541962, 'logits/chosen': -0.1519366204738617, 'epoch': 3.81}


 63%|██████▎   | 10222/16104 [47:19:07<27:13:55, 16.67s/it]

 63%|██████▎   | 10223/16104 [47:19:18<24:33:01, 15.03s/it]

 63%|██████▎   | 10224/16104 [47:19:30<23:12:38, 14.21s/it]

 63%|██████▎   | 10225/16104 [47:19:47<24:21:18, 14.91s/it]

 63%|██████▎   | 10226/16104 [47:20:07<27:00:38, 16.54s/it]

 64%|██████▎   | 10227/16104 [47:20:21<25:46:43, 15.79s/it]

 64%|██████▎   | 10228/16104 [47:20:36<25:25:31, 15.58s/it]

 64%|██████▎   | 10229/16104 [47:20:49<24:02:15, 14.73s/it]

 64%|██████▎   | 10230/16104 [47:21:09<26:25:21, 16.19s/it]

 64%|██████▎   | 10231/16104 [47:21:29<28:14:28, 17.31s/it]
{'loss': 0.3251, 'learning_rate': 6.20198577707197e-07, 'rewards/chosen': -0.9693588614463806, 'rewards/rejected': -1.8879225254058838, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9185636043548584, 'policy_logps/rejected': -575.3046264648438, 'policy_logps/chosen': -567.2819213867188, 'referece_logps/rejected': -556.4254150390625, 'referece_logps/chosen': -557.5882568359375, 'logits/rejected': 0.6575028300285339, 'logits/chosen': 0.6921246647834778, 'epoch': 3.81}


 64%|██████▎   | 10233/16104 [47:22:02<27:43:57, 17.01s/it]

 64%|██████▎   | 10234/16104 [47:22:20<28:12:33, 17.30s/it]

 64%|██████▎   | 10235/16104 [47:22:39<29:01:54, 17.81s/it]

 64%|██████▎   | 10236/16104 [47:23:01<30:48:07, 18.90s/it]

 64%|██████▎   | 10237/16104 [47:23:19<30:17:37, 18.59s/it]

 64%|██████▎   | 10238/16104 [47:23:35<29:14:34, 17.95s/it]

 64%|██████▎   | 10239/16104 [47:23:49<27:04:26, 16.62s/it]

 64%|██████▎   | 10240/16104 [47:24:07<28:05:21, 17.24s/it]
{'loss': 0.4247, 'learning_rate': 6.185247013201674e-07, 'rewards/chosen': -0.2918461263179779, 'rewards/rejected': -1.479508876800537, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1876627206802368, 'policy_logps/rejected': -493.5826416015625, 'policy_logps/chosen': -557.71533203125, 'referece_logps/rejected': -478.78753662109375, 'referece_logps/chosen': -554.7969360351562, 'logits/rejected': 0.05976921319961548, 'logits/chosen': 0.09620918333530426, 'epoch': 3.82}


 64%|██████▎   | 10242/16104 [47:24:44<29:22:38, 18.04s/it]

 64%|██████▎   | 10243/16104 [47:25:01<29:11:56, 17.93s/it]

 64%|██████▎   | 10244/16104 [47:25:17<27:52:11, 17.12s/it]

 64%|██████▎   | 10245/16104 [47:25:34<27:48:05, 17.08s/it]

 64%|██████▎   | 10246/16104 [47:25:51<27:52:36, 17.13s/it]

 64%|██████▎   | 10247/16104 [47:26:13<30:16:13, 18.61s/it]

 64%|██████▎   | 10248/16104 [47:26:28<28:27:53, 17.50s/it]
{'loss': 0.3889, 'learning_rate': 6.170378603598868e-07, 'rewards/chosen': -0.8723740577697754, 'rewards/rejected': -1.526780366897583, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6544062495231628, 'policy_logps/rejected': -368.85418701171875, 'policy_logps/chosen': -306.76153564453125, 'referece_logps/rejected': -353.58642578125, 'referece_logps/chosen': -298.03778076171875, 'logits/rejected': 0.08028249442577362, 'logits/chosen': 0.10029500722885132, 'epoch': 3.82}

 64%|██████▎   | 10249/16104 [47:26:46<28:47:58, 17.71s/it]


 64%|██████▎   | 10251/16104 [47:27:16<26:33:14, 16.33s/it]
{'loss': 0.3802, 'learning_rate': 6.164805504028415e-07, 'rewards/chosen': -0.08818207681179047, 'rewards/rejected': -1.8857624530792236, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7975802421569824, 'policy_logps/rejected': -500.19647216796875, 'policy_logps/chosen': -417.4073486328125, 'referece_logps/rejected': -481.3388671875, 'referece_logps/chosen': -416.52557373046875, 'logits/rejected': -0.38176363706588745, 'logits/chosen': -0.31232067942619324, 'epoch': 3.82}


 64%|██████▎   | 10253/16104 [47:27:46<25:38:44, 15.78s/it]

 64%|██████▎   | 10254/16104 [47:28:01<25:21:31, 15.61s/it]

 64%|██████▎   | 10255/16104 [47:28:14<23:58:55, 14.76s/it]

 64%|██████▎   | 10256/16104 [47:28:34<26:29:16, 16.31s/it]

 64%|██████▎   | 10257/16104 [47:28:45<24:00:47, 14.78s/it]

 64%|██████▎   | 10258/16104 [47:28:56<22:02:36, 13.57s/it]

 64%|██████▎   | 10259/16104 [47:29:15<24:59:00, 15.39s/it]

 64%|██████▎   | 10260/16104 [47:29:35<27:12:06, 16.76s/it]

 64%|██████▎   | 10261/16104 [47:29:49<25:46:49, 15.88s/it]

 64%|██████▎   | 10262/16104 [47:30:00<23:21:37, 14.40s/it]

 64%|██████▎   | 10263/16104 [47:30:13<22:28:47, 13.86s/it]

 64%|██████▎   | 10264/16104 [47:30:26<22:00:35, 13.57s/it]

 64%|██████▎   | 10265/16104 [47:30:46<25:05:07, 15.47s/it]

 64%|██████▎   | 10266/16104 [47:31:05<27:09:50, 16.75s/it]

 64%|██████▍   | 10267/16104 [47:31:21<26:52:30, 16.58s/it]

 64%|██████▍   | 10268/16104 [47:31:41<28:29:47, 17.58s/it]

 64%|██████▍   | 10269/16104 [47:32:01<29:24:02, 18.14s/it]

 64%|██████▍   | 10270/16104 [47:32:14<27:02:17, 16.68s/it]

 64%|██████▍   | 10271/16104 [47:32:32<27:37:41, 17.05s/it]

 64%|██████▍   | 10272/16104 [47:32:52<28:51:18, 17.81s/it]
{'loss': 0.3186, 'learning_rate': 6.125833015988949e-07, 'rewards/chosen': -0.6523862481117249, 'rewards/rejected': -2.418147563934326, 'rewards/accuracies': 1.0, 'rewards/margins': 1.765761375427246, 'policy_logps/rejected': -390.296630859375, 'policy_logps/chosen': -389.9703369140625, 'referece_logps/rejected': -366.1151428222656, 'referece_logps/chosen': -383.44647216796875, 'logits/rejected': 0.08617572486400604, 'logits/chosen': 0.11161975562572479, 'epoch': 3.83}


 64%|██████▍   | 10274/16104 [47:33:30<30:04:20, 18.57s/it]

 64%|██████▍   | 10275/16104 [47:33:50<30:32:53, 18.87s/it]

 64%|██████▍   | 10276/16104 [47:34:00<26:35:07, 16.42s/it]

 64%|██████▍   | 10277/16104 [47:34:18<27:20:00, 16.89s/it]

 64%|██████▍   | 10278/16104 [47:34:37<28:20:01, 17.51s/it]

 64%|██████▍   | 10279/16104 [47:34:57<29:36:58, 18.30s/it]

 64%|██████▍   | 10280/16104 [47:35:13<28:20:10, 17.52s/it]
{'loss': 0.5258, 'learning_rate': 6.111004495323684e-07, 'rewards/chosen': -0.8464730978012085, 'rewards/rejected': -2.338407516479492, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4919345378875732, 'policy_logps/rejected': -411.4832458496094, 'policy_logps/chosen': -379.54852294921875, 'referece_logps/rejected': -388.09918212890625, 'referece_logps/chosen': -371.0837707519531, 'logits/rejected': 0.3195216655731201, 'logits/chosen': 0.3496914207935333, 'epoch': 3.83}

 64%|██████▍   | 10281/16104 [47:35:35<30:12:37, 18.68s/it]

 64%|██████▍   | 10282/16104 [47:35:47<27:00:51, 16.70s/it]


 64%|██████▍   | 10284/16104 [47:36:22<27:37:23, 17.09s/it]
{'loss': 0.5931, 'learning_rate': 6.103594008195299e-07, 'rewards/chosen': -0.22580137848854065, 'rewards/rejected': -0.999876856803894, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7740755081176758, 'policy_logps/rejected': -254.85757446289062, 'policy_logps/chosen': -311.94940185546875, 'referece_logps/rejected': -244.85879516601562, 'referece_logps/chosen': -309.69140625, 'logits/rejected': -0.8544033169746399, 'logits/chosen': -0.7833711504936218, 'epoch': 3.83}


 64%|██████▍   | 10286/16104 [47:36:46<23:00:18, 14.23s/it]

 64%|██████▍   | 10287/16104 [47:37:04<24:51:20, 15.38s/it]

 64%|██████▍   | 10288/16104 [47:37:16<23:09:10, 14.33s/it]

 64%|██████▍   | 10289/16104 [47:37:32<24:17:09, 15.04s/it]

 64%|██████▍   | 10290/16104 [47:37:52<26:25:52, 16.37s/it]

 64%|██████▍   | 10291/16104 [47:38:14<29:15:22, 18.12s/it]

 64%|██████▍   | 10292/16104 [47:38:30<28:29:38, 17.65s/it]

 64%|██████▍   | 10293/16104 [47:38:51<30:02:58, 18.62s/it]

 64%|██████▍   | 10294/16104 [47:39:12<31:08:03, 19.29s/it]

 64%|██████▍   | 10295/16104 [47:39:32<31:22:01, 19.44s/it]
{'loss': 0.4979, 'learning_rate': 6.083228186379536e-07, 'rewards/chosen': -0.8739144206047058, 'rewards/rejected': -1.8380097150802612, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9640951752662659, 'policy_logps/rejected': -394.6915588378906, 'policy_logps/chosen': -485.1951904296875, 'referece_logps/rejected': -376.3114929199219, 'referece_logps/chosen': -476.4560241699219, 'logits/rejected': 0.06093387305736542, 'logits/chosen': 0.1421404629945755, 'epoch': 3.84}

 64%|██████▍   | 10296/16104 [47:39:49<30:18:09, 18.78s/it]


 64%|██████▍   | 10298/16104 [47:40:20<28:03:06, 17.39s/it]

 64%|██████▍   | 10299/16104 [47:40:40<29:20:37, 18.20s/it]

 64%|██████▍   | 10300/16104 [47:40:53<26:43:39, 16.58s/it]
{'loss': 0.4075, 'learning_rate': 6.073977326270848e-07, 'rewards/chosen': -0.8150837421417236, 'rewards/rejected': -1.2185049057006836, 'rewards/accuracies': 0.5, 'rewards/margins': 0.40342116355895996, 'policy_logps/rejected': -404.6575927734375, 'policy_logps/chosen': -399.7018737792969, 'referece_logps/rejected': -392.4725341796875, 'referece_logps/chosen': -391.551025390625, 'logits/rejected': -0.41973820328712463, 'logits/chosen': -0.30383414030075073, 'epoch': 3.84}


 64%|██████▍   | 10302/16104 [47:41:17<22:43:51, 14.10s/it]
{'loss': 0.5164, 'learning_rate': 6.070278093405881e-07, 'rewards/chosen': -0.2539859712123871, 'rewards/rejected': -1.312427282333374, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0584412813186646, 'policy_logps/rejected': -422.6722717285156, 'policy_logps/chosen': -556.6183471679688, 'referece_logps/rejected': -409.5479736328125, 'referece_logps/chosen': -554.0784912109375, 'logits/rejected': 0.460806280374527, 'logits/chosen': 0.24981993436813354, 'epoch': 3.84}


 64%|██████▍   | 10304/16104 [47:41:42<21:51:21, 13.57s/it]

 64%|██████▍   | 10305/16104 [47:42:00<23:58:26, 14.88s/it]

 64%|██████▍   | 10306/16104 [47:42:13<22:51:40, 14.19s/it]
{'loss': 0.3567, 'learning_rate': 6.062881535845545e-07, 'rewards/chosen': -0.2355354130268097, 'rewards/rejected': -0.8494842648506165, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6139488220214844, 'policy_logps/rejected': -429.821533203125, 'policy_logps/chosen': -368.6071472167969, 'referece_logps/rejected': -421.3266906738281, 'referece_logps/chosen': -366.25177001953125, 'logits/rejected': 0.47816091775894165, 'logits/chosen': 0.4503921866416931, 'epoch': 3.84}

 64%|██████▍   | 10307/16104 [47:42:25<22:00:18, 13.67s/it]

 64%|██████▍   | 10308/16104 [47:42:37<21:19:11, 13.24s/it]

 64%|██████▍   | 10309/16104 [47:42:56<23:50:00, 14.81s/it]


 64%|██████▍   | 10311/16104 [47:43:35<27:31:49, 17.11s/it]

 64%|██████▍   | 10312/16104 [47:43:47<25:10:42, 15.65s/it]
{'loss': 0.351, 'learning_rate': 6.0517914789044e-07, 'rewards/chosen': -0.26525822281837463, 'rewards/rejected': -1.7420845031738281, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4768264293670654, 'policy_logps/rejected': -505.16717529296875, 'policy_logps/chosen': -478.1925354003906, 'referece_logps/rejected': -487.74627685546875, 'referece_logps/chosen': -475.5399475097656, 'logits/rejected': 0.04215320944786072, 'logits/chosen': 0.049867890775203705, 'epoch': 3.84}


 64%|██████▍   | 10314/16104 [47:44:22<27:09:03, 16.88s/it]

 64%|██████▍   | 10315/16104 [47:44:38<26:40:08, 16.58s/it]
{'loss': 0.351, 'learning_rate': 6.046248605537607e-07, 'rewards/chosen': -0.8410032391548157, 'rewards/rejected': -3.017820119857788, 'rewards/accuracies': 1.0, 'rewards/margins': 2.176816940307617, 'policy_logps/rejected': -557.7200927734375, 'policy_logps/chosen': -460.52423095703125, 'referece_logps/rejected': -527.5418701171875, 'referece_logps/chosen': -452.1142272949219, 'logits/rejected': -0.03646440804004669, 'logits/chosen': 0.28347712755203247, 'epoch': 3.84}


 64%|██████▍   | 10317/16104 [47:45:11<26:42:20, 16.61s/it]

 64%|██████▍   | 10318/16104 [47:45:28<27:04:00, 16.84s/it]

 64%|██████▍   | 10319/16104 [47:45:49<28:44:36, 17.89s/it]

 64%|██████▍   | 10320/16104 [47:46:09<29:40:04, 18.47s/it]
{'loss': 0.4552, 'learning_rate': 6.037013682981806e-07, 'rewards/chosen': -0.8166651725769043, 'rewards/rejected': -2.4576034545898438, 'rewards/accuracies': 0.875, 'rewards/margins': 1.640938401222229, 'policy_logps/rejected': -285.3515930175781, 'policy_logps/chosen': -247.8285369873047, 'referece_logps/rejected': -260.77557373046875, 'referece_logps/chosen': -239.6619110107422, 'logits/rejected': -0.4533940255641937, 'logits/chosen': -0.2826389670372009, 'epoch': 3.85}


 64%|██████▍   | 10322/16104 [47:46:39<27:02:26, 16.84s/it]

 64%|██████▍   | 10323/16104 [47:46:59<28:33:06, 17.78s/it]

 64%|██████▍   | 10324/16104 [47:47:12<26:19:10, 16.39s/it]
{'loss': 0.4568, 'learning_rate': 6.029628630066423e-07, 'rewards/chosen': -0.28932520747184753, 'rewards/rejected': -0.3074567914009094, 'rewards/accuracies': 0.5, 'rewards/margins': 0.01813162863254547, 'policy_logps/rejected': -412.291748046875, 'policy_logps/chosen': -478.1356201171875, 'referece_logps/rejected': -409.2171630859375, 'referece_logps/chosen': -475.24237060546875, 'logits/rejected': 0.4013075828552246, 'logits/chosen': 0.291415274143219, 'epoch': 3.85}

 64%|██████▍   | 10325/16104 [47:47:32<27:50:12, 17.34s/it]

 64%|██████▍   | 10326/16104 [47:47:52<29:06:03, 18.13s/it]


 64%|██████▍   | 10328/16104 [47:48:29<29:55:26, 18.65s/it]

 64%|██████▍   | 10329/16104 [47:48:49<30:30:42, 19.02s/it]
{'loss': 0.4423, 'learning_rate': 6.020400928175636e-07, 'rewards/chosen': -0.45068076252937317, 'rewards/rejected': -1.2489886283874512, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7983078956604004, 'policy_logps/rejected': -270.9111328125, 'policy_logps/chosen': -442.5050048828125, 'referece_logps/rejected': -258.4212341308594, 'referece_logps/chosen': -437.9981994628906, 'logits/rejected': -0.22305308282375336, 'logits/chosen': -0.25897863507270813, 'epoch': 3.85}

 64%|██████▍   | 10330/16104 [47:49:06<29:26:00, 18.35s/it]


 64%|██████▍   | 10332/16104 [47:49:33<25:12:55, 15.73s/it]

 64%|██████▍   | 10333/16104 [47:49:45<23:31:29, 14.67s/it]

 64%|██████▍   | 10334/16104 [47:50:05<25:53:12, 16.15s/it]

 64%|██████▍   | 10335/16104 [47:50:25<27:49:11, 17.36s/it]

 64%|██████▍   | 10336/16104 [47:50:39<26:08:02, 16.31s/it]
{'loss': 0.3609, 'learning_rate': 6.0074889088567e-07, 'rewards/chosen': -0.44241899251937866, 'rewards/rejected': -2.7095367908477783, 'rewards/accuracies': 0.875, 'rewards/margins': 2.267117738723755, 'policy_logps/rejected': -306.5280456542969, 'policy_logps/chosen': -333.3083801269531, 'referece_logps/rejected': -279.43267822265625, 'referece_logps/chosen': -328.8841857910156, 'logits/rejected': -0.6342260837554932, 'logits/chosen': -0.6481649279594421, 'epoch': 3.85}

 64%|██████▍   | 10337/16104 [47:50:54<25:20:46, 15.82s/it]

 64%|██████▍   | 10338/16104 [47:51:12<26:23:13, 16.47s/it]

 64%|██████▍   | 10339/16104 [47:51:30<27:12:48, 16.99s/it]


 64%|██████▍   | 10341/16104 [47:52:03<26:27:21, 16.53s/it]

 64%|██████▍   | 10342/16104 [47:52:15<24:22:06, 15.23s/it]
{'loss': 0.3356, 'learning_rate': 5.996427761419305e-07, 'rewards/chosen': -0.23152601718902588, 'rewards/rejected': -2.219214916229248, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9876890182495117, 'policy_logps/rejected': -341.2079772949219, 'policy_logps/chosen': -412.9111328125, 'referece_logps/rejected': -319.0158386230469, 'referece_logps/chosen': -410.5958251953125, 'logits/rejected': -0.5301581621170044, 'logits/chosen': -0.5423075556755066, 'epoch': 3.85}


 64%|██████▍   | 10344/16104 [47:52:45<23:40:15, 14.79s/it]
{'loss': 0.2577, 'learning_rate': 5.992742007091279e-07, 'rewards/chosen': -0.06379624456167221, 'rewards/rejected': -1.4273313283920288, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3635351657867432, 'policy_logps/rejected': -412.5324401855469, 'policy_logps/chosen': -633.643310546875, 'referece_logps/rejected': -398.25909423828125, 'referece_logps/chosen': -633.00537109375, 'logits/rejected': -0.7746687531471252, 'logits/chosen': -0.7888572216033936, 'epoch': 3.85}

 64%|██████▍   | 10345/16104 [47:52:58<22:50:38, 14.28s/it]

 64%|██████▍   | 10346/16104 [47:53:18<25:34:39, 15.99s/it]

 64%|██████▍   | 10347/16104 [47:53:38<27:25:27, 17.15s/it]

 64%|██████▍   | 10348/16104 [47:53:58<28:42:34, 17.96s/it]

 64%|██████▍   | 10349/16104 [47:54:18<29:42:50, 18.59s/it]

 64%|██████▍   | 10350/16104 [47:54:30<26:43:28, 16.72s/it]

 64%|██████▍   | 10351/16104 [47:54:50<28:20:18, 17.73s/it]

 64%|██████▍   | 10352/16104 [47:55:06<27:23:11, 17.14s/it]

 64%|██████▍   | 10353/16104 [47:55:20<25:58:08, 16.26s/it]

 64%|██████▍   | 10354/16104 [47:55:38<26:52:58, 16.83s/it]


 64%|██████▍   | 10356/16104 [47:56:06<24:07:51, 15.11s/it]
{'loss': 0.388, 'learning_rate': 5.970641118450843e-07, 'rewards/chosen': -0.7946788668632507, 'rewards/rejected': -1.683627963066101, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8889491558074951, 'policy_logps/rejected': -293.5534362792969, 'policy_logps/chosen': -392.7724304199219, 'referece_logps/rejected': -276.7171325683594, 'referece_logps/chosen': -384.8256530761719, 'logits/rejected': 0.1077871322631836, 'logits/chosen': 0.09882397949695587, 'epoch': 3.86}

 64%|██████▍   | 10357/16104 [47:56:16<21:58:44, 13.77s/it]


 64%|██████▍   | 10359/16104 [47:56:46<22:29:34, 14.09s/it]

 64%|██████▍   | 10360/16104 [47:57:05<25:11:06, 15.78s/it]
{'loss': 0.3753, 'learning_rate': 5.963279365046867e-07, 'rewards/chosen': -0.7747952938079834, 'rewards/rejected': -1.7059828042984009, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9311875104904175, 'policy_logps/rejected': -250.24964904785156, 'policy_logps/chosen': -463.3370056152344, 'referece_logps/rejected': -233.18983459472656, 'referece_logps/chosen': -455.58905029296875, 'logits/rejected': 0.2239663004875183, 'logits/chosen': 0.221555694937706, 'epoch': 3.86}

 64%|██████▍   | 10361/16104 [47:57:25<26:55:48, 16.88s/it]

 64%|██████▍   | 10362/16104 [47:57:37<24:31:23, 15.38s/it]


 64%|██████▍   | 10364/16104 [47:58:09<25:48:29, 16.19s/it]
{'loss': 0.4909, 'learning_rate': 5.955920224323609e-07, 'rewards/chosen': -0.6380525231361389, 'rewards/rejected': -1.5752111673355103, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9371585845947266, 'policy_logps/rejected': -307.14422607421875, 'policy_logps/chosen': -332.06768798828125, 'referece_logps/rejected': -291.39208984375, 'referece_logps/chosen': -325.6871643066406, 'logits/rejected': -0.4132176637649536, 'logits/chosen': -0.4299185872077942, 'epoch': 3.86}

 64%|██████▍   | 10365/16104 [47:58:20<23:21:49, 14.66s/it]


 64%|██████▍   | 10367/16104 [47:58:44<21:01:30, 13.19s/it]
{'loss': 0.3875, 'learning_rate': 5.950402586218223e-07, 'rewards/chosen': -0.16978511214256287, 'rewards/rejected': -1.469515323638916, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2997300624847412, 'policy_logps/rejected': -402.84136962890625, 'policy_logps/chosen': -670.1089477539062, 'referece_logps/rejected': -388.146240234375, 'referece_logps/chosen': -668.4111328125, 'logits/rejected': -0.5380791425704956, 'logits/chosen': -0.5287250280380249, 'epoch': 3.86}


 64%|██████▍   | 10369/16104 [47:59:14<22:19:11, 14.01s/it]

 64%|██████▍   | 10370/16104 [47:59:34<24:58:46, 15.68s/it]
{'loss': 0.5141, 'learning_rate': 5.94488642243377e-07, 'rewards/chosen': -0.9698563814163208, 'rewards/rejected': -1.7397105693817139, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7698541879653931, 'policy_logps/rejected': -386.056884765625, 'policy_logps/chosen': -506.8586730957031, 'referece_logps/rejected': -368.6597900390625, 'referece_logps/chosen': -497.16009521484375, 'logits/rejected': -0.9458725452423096, 'logits/chosen': -0.9405314326286316, 'epoch': 3.86}


 64%|██████▍   | 10372/16104 [48:00:07<25:30:38, 16.02s/it]
{'loss': 0.4017, 'learning_rate': 5.941209799969743e-07, 'rewards/chosen': -1.3929394483566284, 'rewards/rejected': -3.06984806060791, 'rewards/accuracies': 0.625, 'rewards/margins': 1.6769087314605713, 'policy_logps/rejected': -524.4600830078125, 'policy_logps/chosen': -449.9815979003906, 'referece_logps/rejected': -493.7615966796875, 'referece_logps/chosen': -436.0522155761719, 'logits/rejected': -0.4076329469680786, 'logits/chosen': -0.389851838350296, 'epoch': 3.86}

 64%|██████▍   | 10373/16104 [48:00:29<28:07:26, 17.67s/it]

 64%|██████▍   | 10374/16104 [48:00:48<29:00:18, 18.22s/it]


 64%|██████▍   | 10376/16104 [48:01:15<24:58:23, 15.70s/it]
{'loss': 0.4531, 'learning_rate': 5.933858525860136e-07, 'rewards/chosen': -1.082582950592041, 'rewards/rejected': -1.0816329717636108, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0009500086307525635, 'policy_logps/rejected': -462.4941711425781, 'policy_logps/chosen': -389.1835632324219, 'referece_logps/rejected': -451.67779541015625, 'referece_logps/chosen': -378.3577880859375, 'logits/rejected': -0.26984959840774536, 'logits/chosen': -0.171704962849617, 'epoch': 3.87}

 64%|██████▍   | 10377/16104 [48:01:35<26:53:00, 16.90s/it]


 64%|██████▍   | 10379/16104 [48:02:06<25:00:03, 15.72s/it]

 64%|██████▍   | 10380/16104 [48:02:26<27:02:14, 17.00s/it]

 64%|██████▍   | 10381/16104 [48:02:42<26:50:57, 16.89s/it]

 64%|██████▍   | 10382/16104 [48:02:59<27:01:24, 17.00s/it]

 64%|██████▍   | 10383/16104 [48:03:18<27:30:12, 17.31s/it]
{'loss': 0.4188, 'learning_rate': 5.921000131612382e-07, 'rewards/chosen': -0.5822386145591736, 'rewards/rejected': -1.880234956741333, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2979962825775146, 'policy_logps/rejected': -286.8689270019531, 'policy_logps/chosen': -389.8290100097656, 'referece_logps/rejected': -268.0666198730469, 'referece_logps/chosen': -384.0066223144531, 'logits/rejected': -0.31000760197639465, 'logits/chosen': -0.37435105443000793, 'epoch': 3.87}


 64%|██████▍   | 10385/16104 [48:03:48<26:10:23, 16.48s/it]
{'loss': 0.5336, 'learning_rate': 5.917327788595427e-07, 'rewards/chosen': -0.37800437211990356, 'rewards/rejected': -1.6102467775344849, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2322423458099365, 'policy_logps/rejected': -302.9610290527344, 'policy_logps/chosen': -406.2883605957031, 'referece_logps/rejected': -286.8585510253906, 'referece_logps/chosen': -402.50836181640625, 'logits/rejected': -0.10269330441951752, 'logits/chosen': -0.197660893201828, 'epoch': 3.87}

 64%|██████▍   | 10386/16104 [48:04:09<28:21:53, 17.86s/it]


 65%|██████▍   | 10388/16104 [48:04:38<25:52:16, 16.29s/it]
{'loss': 0.3354, 'learning_rate': 5.911820512890969e-07, 'rewards/chosen': 0.10295474529266357, 'rewards/rejected': -1.2966411113739014, 'rewards/accuracies': 0.875, 'rewards/margins': 1.399595856666565, 'policy_logps/rejected': -345.93170166015625, 'policy_logps/chosen': -422.8651123046875, 'referece_logps/rejected': -332.9653015136719, 'referece_logps/chosen': -423.8946533203125, 'logits/rejected': -0.03356136381626129, 'logits/chosen': -0.0002961158752441406, 'epoch': 3.87}


 65%|██████▍   | 10390/16104 [48:05:14<27:40:37, 17.44s/it]

 65%|██████▍   | 10391/16104 [48:05:26<25:09:28, 15.85s/it]

 65%|██████▍   | 10392/16104 [48:05:46<27:02:20, 17.04s/it]
{'loss': 0.4919, 'learning_rate': 5.904479794202936e-07, 'rewards/chosen': 0.023141860961914062, 'rewards/rejected': -1.697676658630371, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7208184003829956, 'policy_logps/rejected': -557.2469482421875, 'policy_logps/chosen': -538.2037353515625, 'referece_logps/rejected': -540.2701416015625, 'referece_logps/chosen': -538.4351806640625, 'logits/rejected': 0.39047443866729736, 'logits/chosen': 0.34237611293792725, 'epoch': 3.87}

 65%|██████▍   | 10393/16104 [48:06:07<28:57:09, 18.25s/it]


 65%|██████▍   | 10395/16104 [48:06:32<24:39:32, 15.55s/it]
{'loss': 0.4327, 'learning_rate': 5.898975994473622e-07, 'rewards/chosen': -0.04950733482837677, 'rewards/rejected': -1.7250865697860718, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6755791902542114, 'policy_logps/rejected': -355.00714111328125, 'policy_logps/chosen': -349.5951843261719, 'referece_logps/rejected': -337.75628662109375, 'referece_logps/chosen': -349.1001281738281, 'logits/rejected': -0.4989049434661865, 'logits/chosen': -0.41339150071144104, 'epoch': 3.87}

 65%|██████▍   | 10396/16104 [48:06:43<22:34:16, 14.24s/it]


 65%|██████▍   | 10398/16104 [48:07:12<22:07:00, 13.95s/it]
{'loss': 0.53, 'learning_rate': 5.89347368778792e-07, 'rewards/chosen': -0.39200329780578613, 'rewards/rejected': -1.7016830444335938, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3096798658370972, 'policy_logps/rejected': -343.4586181640625, 'policy_logps/chosen': -451.83294677734375, 'referece_logps/rejected': -326.4417419433594, 'referece_logps/chosen': -447.9129333496094, 'logits/rejected': 0.32221007347106934, 'logits/chosen': 0.31883180141448975, 'epoch': 3.87}

 65%|██████▍   | 10399/16104 [48:07:23<20:42:01, 13.06s/it]


 65%|██████▍   | 10401/16104 [48:07:56<23:30:18, 14.84s/it]
{'loss': 0.4015, 'learning_rate': 5.887972876149038e-07, 'rewards/chosen': -0.6703665256500244, 'rewards/rejected': -2.210355520248413, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5399891138076782, 'policy_logps/rejected': -267.8565979003906, 'policy_logps/chosen': -395.21875, 'referece_logps/rejected': -245.75302124023438, 'referece_logps/chosen': -388.5151062011719, 'logits/rejected': -0.3690558671951294, 'logits/chosen': -0.46182313561439514, 'epoch': 3.88}


 65%|██████▍   | 10403/16104 [48:08:30<25:07:39, 15.87s/it]
{'loss': 0.4769, 'learning_rate': 5.884306499960332e-07, 'rewards/chosen': -0.2404085099697113, 'rewards/rejected': -1.026715636253357, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7863070964813232, 'policy_logps/rejected': -410.27734375, 'policy_logps/chosen': -449.7308349609375, 'referece_logps/rejected': -400.01019287109375, 'referece_logps/chosen': -447.3267822265625, 'logits/rejected': -0.4172425866127014, 'logits/chosen': -0.534183919429779, 'epoch': 3.88}


 65%|██████▍   | 10405/16104 [48:09:03<24:56:55, 15.76s/it]
{'loss': 0.4071, 'learning_rate': 5.880640789720211e-07, 'rewards/chosen': -0.4412521421909332, 'rewards/rejected': -1.8491792678833008, 'rewards/accuracies': 0.875, 'rewards/margins': 1.40792715549469, 'policy_logps/rejected': -340.7048645019531, 'policy_logps/chosen': -656.3775024414062, 'referece_logps/rejected': -322.2130432128906, 'referece_logps/chosen': -651.9649658203125, 'logits/rejected': -0.3483368456363678, 'logits/chosen': -0.48484086990356445, 'epoch': 3.88}

 65%|██████▍   | 10406/16104 [48:09:23<27:05:58, 17.12s/it]

 65%|██████▍   | 10407/16104 [48:09:39<26:42:01, 16.87s/it]


 65%|██████▍   | 10409/16104 [48:10:21<29:59:01, 18.95s/it]

 65%|██████▍   | 10410/16104 [48:10:41<30:27:19, 19.26s/it]

 65%|██████▍   | 10411/16104 [48:10:57<28:54:17, 18.28s/it]
{'loss': 0.3641, 'learning_rate': 5.869647660622156e-07, 'rewards/chosen': -0.16983984410762787, 'rewards/rejected': -1.3833743333816528, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2135345935821533, 'policy_logps/rejected': -322.9676818847656, 'policy_logps/chosen': -375.60675048828125, 'referece_logps/rejected': -309.1339111328125, 'referece_logps/chosen': -373.9083557128906, 'logits/rejected': 0.3243226408958435, 'logits/chosen': 0.27906811237335205, 'epoch': 3.88}


 65%|██████▍   | 10413/16104 [48:11:31<27:52:08, 17.63s/it]
{'loss': 0.3452, 'learning_rate': 5.86598462010665e-07, 'rewards/chosen': -0.9581924676895142, 'rewards/rejected': -3.816542863845825, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8583505153656006, 'policy_logps/rejected': -626.9661865234375, 'policy_logps/chosen': -531.4336547851562, 'referece_logps/rejected': -588.8009033203125, 'referece_logps/chosen': -521.8516845703125, 'logits/rejected': 0.06361556798219681, 'logits/chosen': 0.07211650907993317, 'epoch': 3.88}


 65%|██████▍   | 10415/16104 [48:12:04<27:12:05, 17.21s/it]
{'loss': 0.3581, 'learning_rate': 5.862322248504337e-07, 'rewards/chosen': -0.5085287094116211, 'rewards/rejected': -1.414724349975586, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9061957001686096, 'policy_logps/rejected': -369.67730712890625, 'policy_logps/chosen': -360.11468505859375, 'referece_logps/rejected': -355.5300598144531, 'referece_logps/chosen': -355.0293884277344, 'logits/rejected': 0.2840821444988251, 'logits/chosen': 0.15977010130882263, 'epoch': 3.88}

 65%|██████▍   | 10416/16104 [48:12:19<26:01:04, 16.47s/it]

 65%|██████▍   | 10417/16104 [48:12:35<25:40:19, 16.25s/it]


 65%|██████▍   | 10419/16104 [48:13:11<27:01:49, 17.12s/it]
{'loss': 0.4124, 'learning_rate': 5.85499951440956e-07, 'rewards/chosen': -0.5634387731552124, 'rewards/rejected': -1.5732887983322144, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0098501443862915, 'policy_logps/rejected': -395.05316162109375, 'policy_logps/chosen': -532.2603759765625, 'referece_logps/rejected': -379.3202819824219, 'referece_logps/chosen': -526.6259155273438, 'logits/rejected': -0.6908182501792908, 'logits/chosen': -0.7860153317451477, 'epoch': 3.88}

 65%|██████▍   | 10420/16104 [48:13:25<25:55:27, 16.42s/it]

 65%|██████▍   | 10421/16104 [48:13:38<23:51:28, 15.11s/it]

 65%|██████▍   | 10422/16104 [48:13:58<26:15:55, 16.64s/it]

 65%|██████▍   | 10423/16104 [48:14:17<27:36:47, 17.50s/it]

 65%|██████▍   | 10424/16104 [48:14:28<24:25:11, 15.48s/it]

 65%|██████▍   | 10425/16104 [48:14:44<24:41:25, 15.65s/it]


 65%|██████▍   | 10427/16104 [48:15:11<23:15:44, 14.75s/it]
{'loss': 0.5695, 'learning_rate': 5.840362099245334e-07, 'rewards/chosen': -0.3208489418029785, 'rewards/rejected': -0.9289402961730957, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6080913543701172, 'policy_logps/rejected': -450.2160339355469, 'policy_logps/chosen': -403.2969665527344, 'referece_logps/rejected': -440.9266052246094, 'referece_logps/chosen': -400.08843994140625, 'logits/rejected': 0.4289602041244507, 'logits/chosen': 0.37568777799606323, 'epoch': 3.88}

 65%|██████▍   | 10428/16104 [48:15:24<22:34:56, 14.32s/it]

 65%|██████▍   | 10429/16104 [48:15:45<25:48:09, 16.37s/it]

 65%|██████▍   | 10430/16104 [48:15:58<24:09:41, 15.33s/it]

 65%|██████▍   | 10431/16104 [48:16:14<24:20:21, 15.45s/it]

 65%|██████▍   | 10432/16104 [48:16:26<22:47:00, 14.46s/it]

 65%|██████▍   | 10433/16104 [48:16:44<24:26:52, 15.52s/it]


 65%|██████▍   | 10435/16104 [48:17:17<24:47:08, 15.74s/it]
{'loss': 0.492, 'learning_rate': 5.82573545302448e-07, 'rewards/chosen': -0.5428085923194885, 'rewards/rejected': -1.9751349687576294, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4323265552520752, 'policy_logps/rejected': -448.026611328125, 'policy_logps/chosen': -393.47491455078125, 'referece_logps/rejected': -428.2752685546875, 'referece_logps/chosen': -388.04681396484375, 'logits/rejected': -0.7147637605667114, 'logits/chosen': -0.5329605937004089, 'epoch': 3.89}

 65%|██████▍   | 10436/16104 [48:17:29<23:16:18, 14.78s/it]

 65%|██████▍   | 10437/16104 [48:17:48<25:00:13, 15.88s/it]

 65%|██████▍   | 10438/16104 [48:18:04<25:11:22, 16.00s/it]


 65%|██████▍   | 10440/16104 [48:18:41<27:00:59, 17.17s/it]
{'loss': 0.4024, 'learning_rate': 5.81659928456739e-07, 'rewards/chosen': -0.45052793622016907, 'rewards/rejected': -2.190077304840088, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7395492792129517, 'policy_logps/rejected': -604.6047973632812, 'policy_logps/chosen': -646.5040893554688, 'referece_logps/rejected': -582.7041015625, 'referece_logps/chosen': -641.9988403320312, 'logits/rejected': 0.5702723860740662, 'logits/chosen': 0.5908163785934448, 'epoch': 3.89}

 65%|██████▍   | 10441/16104 [48:18:59<27:26:57, 17.45s/it]


 65%|██████▍   | 10443/16104 [48:19:23<22:55:11, 14.58s/it]
{'loss': 0.3261, 'learning_rate': 5.811119613614118e-07, 'rewards/chosen': -0.4209807515144348, 'rewards/rejected': -2.122140884399414, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7011600732803345, 'policy_logps/rejected': -388.23797607421875, 'policy_logps/chosen': -418.229736328125, 'referece_logps/rejected': -367.0165710449219, 'referece_logps/chosen': -414.0198974609375, 'logits/rejected': -0.6833871006965637, 'logits/chosen': -0.4904860258102417, 'epoch': 3.89}

 65%|██████▍   | 10444/16104 [48:19:34<21:22:45, 13.60s/it]

 65%|██████▍   | 10445/16104 [48:19:50<22:21:04, 14.22s/it]

 65%|██████▍   | 10446/16104 [48:20:09<24:46:49, 15.77s/it]

 65%|██████▍   | 10447/16104 [48:20:26<24:59:52, 15.91s/it]

 65%|██████▍   | 10448/16104 [48:20:42<25:12:33, 16.05s/it]

 65%|██████▍   | 10449/16104 [48:20:55<23:42:04, 15.09s/it]

 65%|██████▍   | 10450/16104 [48:21:06<21:47:11, 13.87s/it]

 65%|██████▍   | 10451/16104 [48:21:22<22:43:22, 14.47s/it]

 65%|██████▍   | 10452/16104 [48:21:33<20:58:29, 13.36s/it]


 65%|██████▍   | 10454/16104 [48:21:59<20:53:19, 13.31s/it]
{'loss': 0.4083, 'learning_rate': 5.791040549422564e-07, 'rewards/chosen': -1.0337508916854858, 'rewards/rejected': -1.9760560989379883, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9423052072525024, 'policy_logps/rejected': -447.35546875, 'policy_logps/chosen': -398.9396667480469, 'referece_logps/rejected': -427.59490966796875, 'referece_logps/chosen': -388.6021728515625, 'logits/rejected': -0.4453239142894745, 'logits/chosen': -0.13546863198280334, 'epoch': 3.89}

 65%|██████▍   | 10455/16104 [48:22:18<23:19:04, 14.86s/it]


 65%|██████▍   | 10457/16104 [48:22:55<26:11:58, 16.70s/it]
{'loss': 0.5063, 'learning_rate': 5.785568012330974e-07, 'rewards/chosen': -0.6532993316650391, 'rewards/rejected': -2.115227699279785, 'rewards/accuracies': 0.75, 'rewards/margins': 1.461928367614746, 'policy_logps/rejected': -469.29437255859375, 'policy_logps/chosen': -315.492919921875, 'referece_logps/rejected': -448.14215087890625, 'referece_logps/chosen': -308.9599304199219, 'logits/rejected': -0.8436279892921448, 'logits/chosen': -0.5724705457687378, 'epoch': 3.9}

 65%|██████▍   | 10458/16104 [48:23:12<26:14:51, 16.74s/it]

 65%|██████▍   | 10459/16104 [48:23:30<26:47:46, 17.09s/it]

 65%|██████▍   | 10460/16104 [48:23:45<25:29:03, 16.26s/it]

 65%|██████▍   | 10461/16104 [48:24:02<26:14:08, 16.74s/it]


 65%|██████▍   | 10463/16104 [48:24:36<26:32:01, 16.93s/it]
{'loss': 0.3841, 'learning_rate': 5.77462754313442e-07, 'rewards/chosen': -0.09063825011253357, 'rewards/rejected': -2.0010695457458496, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9104313850402832, 'policy_logps/rejected': -165.19171142578125, 'policy_logps/chosen': -485.9930419921875, 'referece_logps/rejected': -145.18099975585938, 'referece_logps/chosen': -485.086669921875, 'logits/rejected': -0.6223792433738708, 'logits/chosen': -0.7539241909980774, 'epoch': 3.9}

 65%|██████▍   | 10464/16104 [48:24:52<26:23:57, 16.85s/it]

 65%|██████▍   | 10465/16104 [48:25:10<27:00:30, 17.24s/it]

 65%|██████▍   | 10466/16104 [48:25:30<28:11:54, 18.01s/it]

 65%|██████▍   | 10467/16104 [48:25:47<27:42:22, 17.69s/it]


 65%|██████▌   | 10469/16104 [48:26:18<25:10:55, 16.09s/it]
{'loss': 0.5501, 'learning_rate': 5.76369322719596e-07, 'rewards/chosen': -0.10334073007106781, 'rewards/rejected': -1.261693000793457, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1583523750305176, 'policy_logps/rejected': -452.7479248046875, 'policy_logps/chosen': -492.71783447265625, 'referece_logps/rejected': -440.13104248046875, 'referece_logps/chosen': -491.6844177246094, 'logits/rejected': -0.17696473002433777, 'logits/chosen': -0.01951882243156433, 'epoch': 3.9}

 65%|██████▌   | 10470/16104 [48:26:29<23:07:04, 14.77s/it]

 65%|██████▌   | 10471/16104 [48:26:40<21:11:39, 13.55s/it]

 65%|██████▌   | 10472/16104 [48:26:57<22:37:28, 14.46s/it]

 65%|██████▌   | 10473/16104 [48:27:09<21:28:24, 13.73s/it]


 65%|██████▌   | 10475/16104 [48:27:34<20:36:19, 13.18s/it]
{'loss': 0.5345, 'learning_rate': 5.752765080438839e-07, 'rewards/chosen': -0.3674755096435547, 'rewards/rejected': -1.4818991422653198, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1144236326217651, 'policy_logps/rejected': -512.9464721679688, 'policy_logps/chosen': -678.8456420898438, 'referece_logps/rejected': -498.1274719238281, 'referece_logps/chosen': -675.1708984375, 'logits/rejected': -0.7490209341049194, 'logits/chosen': -0.6374550461769104, 'epoch': 3.9}

 65%|██████▌   | 10476/16104 [48:27:53<23:28:42, 15.02s/it]

 65%|██████▌   | 10477/16104 [48:28:08<23:38:52, 15.13s/it]

 65%|██████▌   | 10478/16104 [48:28:19<21:34:12, 13.80s/it]

 65%|██████▌   | 10479/16104 [48:28:31<20:42:44, 13.26s/it]

 65%|██████▌   | 10480/16104 [48:28:51<23:46:42, 15.22s/it]

 65%|██████▌   | 10481/16104 [48:29:01<21:37:25, 13.84s/it]

 65%|██████▌   | 10482/16104 [48:29:12<20:12:07, 12.94s/it]

 65%|██████▌   | 10483/16104 [48:29:23<19:04:58, 12.22s/it]

 65%|██████▌   | 10484/16104 [48:29:35<18:54:49, 12.12s/it]

 65%|██████▌   | 10485/16104 [48:29:51<20:44:28, 13.29s/it]

 65%|██████▌   | 10486/16104 [48:30:03<20:06:46, 12.89s/it]


 65%|██████▌   | 10488/16104 [48:30:34<22:02:01, 14.12s/it]
{'loss': 0.4935, 'learning_rate': 5.729108668664638e-07, 'rewards/chosen': 0.05484476685523987, 'rewards/rejected': -0.5267931222915649, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5816379189491272, 'policy_logps/rejected': -519.0841674804688, 'policy_logps/chosen': -368.3355407714844, 'referece_logps/rejected': -513.8162231445312, 'referece_logps/chosen': -368.8840026855469, 'logits/rejected': 0.48408564925193787, 'logits/chosen': 0.5420253872871399, 'epoch': 3.91}

 65%|██████▌   | 10489/16104 [48:30:53<24:20:59, 15.61s/it]

 65%|██████▌   | 10490/16104 [48:31:08<23:58:19, 15.37s/it]

 65%|██████▌   | 10491/16104 [48:31:28<26:33:23, 17.03s/it]

 65%|██████▌   | 10492/16104 [48:31:49<28:16:32, 18.14s/it]

 65%|██████▌   | 10493/16104 [48:32:04<26:54:47, 17.27s/it]


 65%|██████▌   | 10495/16104 [48:32:44<29:14:24, 18.77s/it]
{'loss': 0.3587, 'learning_rate': 5.71638268404419e-07, 'rewards/chosen': -0.31719017028808594, 'rewards/rejected': -1.9507042169570923, 'rewards/accuracies': 0.625, 'rewards/margins': 1.6335139274597168, 'policy_logps/rejected': -470.7406921386719, 'policy_logps/chosen': -506.8955383300781, 'referece_logps/rejected': -451.233642578125, 'referece_logps/chosen': -503.7236022949219, 'logits/rejected': 0.35971376299858093, 'logits/chosen': 0.19798260927200317, 'epoch': 3.91}

 65%|██████▌   | 10496/16104 [48:33:01<28:25:20, 18.25s/it]

 65%|██████▌   | 10497/16104 [48:33:19<28:06:34, 18.05s/it]

 65%|██████▌   | 10498/16104 [48:33:39<29:14:38, 18.78s/it]

 65%|██████▌   | 10499/16104 [48:33:58<29:16:43, 18.81s/it]

 65%|██████▌   | 10500/16104 [48:34:15<28:42:16, 18.44s/it]

 65%|██████▌   | 10501/16104 [48:34:42<32:41:01, 21.00s/it]

 65%|██████▌   | 10502/16104 [48:34:54<28:25:47, 18.27s/it]

 65%|██████▌   | 10503/16104 [48:35:06<25:29:51, 16.39s/it]

 65%|██████▌   | 10504/16104 [48:35:21<24:36:18, 15.82s/it]

 65%|██████▌   | 10505/16104 [48:35:33<23:05:38, 14.85s/it]

 65%|██████▌   | 10506/16104 [48:35:51<24:09:36, 15.54s/it]

 65%|██████▌   | 10507/16104 [48:36:01<21:49:31, 14.04s/it]

 65%|██████▌   | 10508/16104 [48:36:12<20:18:20, 13.06s/it]

 65%|██████▌   | 10509/16104 [48:36:23<19:19:21, 12.43s/it]

 65%|██████▌   | 10510/16104 [48:36:38<20:30:35, 13.20s/it]


 65%|██████▌   | 10512/16104 [48:37:16<25:12:11, 16.23s/it]
{'loss': 0.4289, 'learning_rate': 5.685512120472653e-07, 'rewards/chosen': -0.9013188481330872, 'rewards/rejected': -1.2587687969207764, 'rewards/accuracies': 0.5, 'rewards/margins': 0.35744988918304443, 'policy_logps/rejected': -444.99578857421875, 'policy_logps/chosen': -540.58349609375, 'referece_logps/rejected': -432.4081115722656, 'referece_logps/chosen': -531.5703125, 'logits/rejected': -0.8535345792770386, 'logits/chosen': -0.9121174812316895, 'epoch': 3.92}

 65%|██████▌   | 10513/16104 [48:37:36<26:51:14, 17.29s/it]

 65%|██████▌   | 10514/16104 [48:37:48<24:23:35, 15.71s/it]

 65%|██████▌   | 10515/16104 [48:38:07<26:01:02, 16.76s/it]

 65%|██████▌   | 10516/16104 [48:38:26<26:45:11, 17.24s/it]

 65%|██████▌   | 10517/16104 [48:38:38<24:39:39, 15.89s/it]

 65%|██████▌   | 10518/16104 [48:38:53<24:03:37, 15.51s/it]

 65%|██████▌   | 10519/16104 [48:39:06<22:55:04, 14.77s/it]

 65%|██████▌   | 10520/16104 [48:39:17<20:58:07, 13.52s/it]

 65%|██████▌   | 10521/16104 [48:39:27<19:42:59, 12.71s/it]

 65%|██████▌   | 10522/16104 [48:39:38<18:48:14, 12.13s/it]

 65%|██████▌   | 10523/16104 [48:39:53<20:01:21, 12.92s/it]

 65%|██████▌   | 10524/16104 [48:40:05<19:29:16, 12.57s/it]

 65%|██████▌   | 10525/16104 [48:40:24<22:44:17, 14.67s/it]

 65%|██████▌   | 10526/16104 [48:40:42<24:15:16, 15.65s/it]

 65%|██████▌   | 10527/16104 [48:40:53<22:01:11, 14.21s/it]

 65%|██████▌   | 10528/16104 [48:41:05<21:02:16, 13.58s/it]

 65%|██████▌   | 10529/16104 [48:41:26<24:12:39, 15.63s/it]

 65%|██████▌   | 10530/16104 [48:41:42<24:38:46, 15.92s/it]

 65%|██████▌   | 10531/16104 [48:42:00<25:28:39, 16.46s/it]

 65%|██████▌   | 10532/16104 [48:42:15<24:56:12, 16.11s/it]

 65%|██████▌   | 10533/16104 [48:42:26<22:26:13, 14.50s/it]

 65%|██████▌   | 10534/16104 [48:42:38<21:16:09, 13.75s/it]

 65%|██████▌   | 10535/16104 [48:42:50<20:42:29, 13.39s/it]

 65%|██████▌   | 10536/16104 [48:43:09<23:17:10, 15.06s/it]

 65%|██████▌   | 10537/16104 [48:43:31<26:07:08, 16.89s/it]

 65%|██████▌   | 10538/16104 [48:43:42<23:33:49, 15.24s/it]

 65%|██████▌   | 10539/16104 [48:44:01<25:25:05, 16.44s/it]

 65%|██████▌   | 10540/16104 [48:44:15<24:18:55, 15.73s/it]

 65%|██████▌   | 10541/16104 [48:44:31<24:24:47, 15.80s/it]

 65%|██████▌   | 10542/16104 [48:44:45<23:40:57, 15.33s/it]

 65%|██████▌   | 10543/16104 [48:45:03<24:41:36, 15.99s/it]

 65%|██████▌   | 10544/16104 [48:45:18<24:11:54, 15.67s/it]

 65%|██████▌   | 10545/16104 [48:45:32<23:19:23, 15.10s/it]

 65%|██████▌   | 10546/16104 [48:45:44<22:04:16, 14.30s/it]

 65%|██████▌   | 10547/16104 [48:45:56<21:04:43, 13.66s/it]

 65%|██████▌   | 10548/16104 [48:46:16<24:03:12, 15.59s/it]

 66%|██████▌   | 10549/16104 [48:46:37<26:15:22, 17.02s/it]

 66%|██████▌   | 10550/16104 [48:46:48<23:36:58, 15.31s/it]

 66%|██████▌   | 10551/16104 [48:47:05<24:17:30, 15.75s/it]

 66%|██████▌   | 10552/16104 [48:47:20<24:07:38, 15.64s/it]

 66%|██████▌   | 10553/16104 [48:47:40<26:10:18, 16.97s/it]

 66%|██████▌   | 10554/16104 [48:48:02<28:09:53, 18.27s/it]

 66%|██████▌   | 10555/16104 [48:48:21<28:49:47, 18.70s/it]

 66%|██████▌   | 10556/16104 [48:48:32<25:16:16, 16.40s/it]

 66%|██████▌   | 10557/16104 [48:48:49<25:34:07, 16.59s/it]

 66%|██████▌   | 10558/16104 [48:49:04<24:30:32, 15.91s/it]

 66%|██████▌   | 10559/16104 [48:49:21<25:05:15, 16.29s/it]

 66%|██████▌   | 10560/16104 [48:49:40<26:36:22, 17.28s/it]

 66%|██████▌   | 10561/16104 [48:49:51<23:34:09, 15.31s/it]

 66%|██████▌   | 10562/16104 [48:50:11<25:38:51, 16.66s/it]

 66%|██████▌   | 10563/16104 [48:50:27<25:30:43, 16.58s/it]

 66%|██████▌   | 10564/16104 [48:50:41<24:20:01, 15.81s/it]

 66%|██████▌   | 10565/16104 [48:51:01<26:11:08, 17.02s/it]

 66%|██████▌   | 10566/16104 [48:51:21<27:19:23, 17.76s/it]

 66%|██████▌   | 10567/16104 [48:51:40<28:12:38, 18.34s/it]

 66%|██████▌   | 10568/16104 [48:52:00<28:57:59, 18.84s/it]

 66%|██████▌   | 10569/16104 [48:52:13<25:54:35, 16.85s/it]

 66%|██████▌   | 10570/16104 [48:52:27<24:55:36, 16.22s/it]

 66%|██████▌   | 10571/16104 [48:52:46<26:00:01, 16.92s/it]


 66%|██████▌   | 10573/16104 [48:53:18<25:46:46, 16.78s/it]

 66%|██████▌   | 10574/16104 [48:53:34<25:36:23, 16.67s/it]

 66%|██████▌   | 10575/16104 [48:53:49<24:38:46, 16.05s/it]

 66%|██████▌   | 10576/16104 [48:54:03<23:41:18, 15.43s/it]

 66%|██████▌   | 10577/16104 [48:54:16<22:38:18, 14.75s/it]

 66%|██████▌   | 10578/16104 [48:54:27<20:57:34, 13.65s/it]

 66%|██████▌   | 10579/16104 [48:54:44<22:41:14, 14.78s/it]
{'loss': 0.435, 'learning_rate': 5.564340341818319e-07, 'rewards/chosen': -0.2372223138809204, 'rewards/rejected': -1.6352055072784424, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3979830741882324, 'policy_logps/rejected': -252.44723510742188, 'policy_logps/chosen': -314.80108642578125, 'referece_logps/rejected': -236.0951690673828, 'referece_logps/chosen': -312.4288635253906, 'logits/rejected': -0.5314895510673523, 'logits/chosen': -0.6586170792579651, 'epoch': 3.94}


 66%|██████▌   | 10581/16104 [48:55:13<21:49:16, 14.22s/it]

 66%|██████▌   | 10582/16104 [48:55:24<20:13:28, 13.19s/it]
{'loss': 0.4934, 'learning_rate': 5.558933416369097e-07, 'rewards/chosen': 0.03479252755641937, 'rewards/rejected': -0.6722202897071838, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7070127129554749, 'policy_logps/rejected': -470.8747863769531, 'policy_logps/chosen': -399.38623046875, 'referece_logps/rejected': -464.15264892578125, 'referece_logps/chosen': -399.734130859375, 'logits/rejected': 0.2027490735054016, 'logits/chosen': 0.17451037466526031, 'epoch': 3.94}


 66%|██████▌   | 10584/16104 [48:56:01<24:47:05, 16.16s/it]

 66%|██████▌   | 10585/16104 [48:56:13<22:50:35, 14.90s/it]

 66%|██████▌   | 10586/16104 [48:56:33<24:58:15, 16.29s/it]
{'loss': 0.4072, 'learning_rate': 5.551726697863839e-07, 'rewards/chosen': -0.6187602281570435, 'rewards/rejected': -2.416189670562744, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7974295616149902, 'policy_logps/rejected': -396.60833740234375, 'policy_logps/chosen': -384.90374755859375, 'referece_logps/rejected': -372.44647216796875, 'referece_logps/chosen': -378.71612548828125, 'logits/rejected': -0.31083565950393677, 'logits/chosen': -0.30358847975730896, 'epoch': 3.94}


 66%|██████▌   | 10588/16104 [48:57:03<24:33:32, 16.03s/it]

 66%|██████▌   | 10589/16104 [48:57:23<26:11:46, 17.10s/it]

 66%|██████▌   | 10590/16104 [48:57:39<25:48:49, 16.85s/it]

 66%|██████▌   | 10591/16104 [48:57:56<26:11:23, 17.10s/it]

 66%|██████▌   | 10592/16104 [48:58:11<25:06:09, 16.39s/it]

 66%|██████▌   | 10593/16104 [48:58:29<25:47:36, 16.85s/it]

 66%|██████▌   | 10594/16104 [48:58:43<24:21:01, 15.91s/it]

 66%|██████▌   | 10595/16104 [48:59:03<26:19:09, 17.20s/it]

 66%|██████▌   | 10596/16104 [48:59:17<24:40:15, 16.12s/it]

 66%|██████▌   | 10597/16104 [48:59:36<26:03:12, 17.03s/it]

 66%|██████▌   | 10598/16104 [48:59:57<27:52:45, 18.23s/it]
{'loss': 0.2637, 'learning_rate': 5.53012383529237e-07, 'rewards/chosen': -0.7726255655288696, 'rewards/rejected': -2.28823184967041, 'rewards/accuracies': 0.875, 'rewards/margins': 1.51560640335083, 'policy_logps/rejected': -337.8818664550781, 'policy_logps/chosen': -341.4748840332031, 'referece_logps/rejected': -314.99957275390625, 'referece_logps/chosen': -333.7486572265625, 'logits/rejected': -0.14921694993972778, 'logits/chosen': -0.2906959056854248, 'epoch': 3.95}


 66%|██████▌   | 10600/16104 [49:00:35<28:31:11, 18.65s/it]

 66%|██████▌   | 10601/16104 [49:00:54<28:54:33, 18.91s/it]

 66%|██████▌   | 10602/16104 [49:01:14<29:02:26, 19.00s/it]

 66%|██████▌   | 10603/16104 [49:01:27<26:35:20, 17.40s/it]

 66%|██████▌   | 10604/16104 [49:01:46<27:20:40, 17.90s/it]

 66%|██████▌   | 10605/16104 [49:01:58<24:21:48, 15.95s/it]

 66%|██████▌   | 10606/16104 [49:02:17<25:59:25, 17.02s/it]

 66%|██████▌   | 10607/16104 [49:02:37<27:10:39, 17.80s/it]

 66%|██████▌   | 10608/16104 [49:02:57<28:04:47, 18.39s/it]

 66%|██████▌   | 10609/16104 [49:03:17<28:44:16, 18.83s/it]

 66%|██████▌   | 10610/16104 [49:03:30<26:14:08, 17.19s/it]

 66%|██████▌   | 10611/16104 [49:03:51<27:52:57, 18.27s/it]

 66%|██████▌   | 10612/16104 [49:04:10<28:10:34, 18.47s/it]

 66%|██████▌   | 10613/16104 [49:04:31<29:20:45, 19.24s/it]

 66%|██████▌   | 10614/16104 [49:04:50<29:22:00, 19.26s/it]

 66%|██████▌   | 10615/16104 [49:05:08<28:43:28, 18.84s/it]

 66%|██████▌   | 10616/16104 [49:05:28<29:20:34, 19.25s/it]

 66%|██████▌   | 10617/16104 [49:05:42<26:54:13, 17.65s/it]

 66%|██████▌   | 10618/16104 [49:05:59<26:41:00, 17.51s/it]

 66%|██████▌   | 10619/16104 [49:06:12<24:24:21, 16.02s/it]

 66%|██████▌   | 10620/16104 [49:06:34<27:03:47, 17.77s/it]

 66%|██████▌   | 10621/16104 [49:06:53<27:59:08, 18.37s/it]
{'loss': 0.5927, 'learning_rate': 5.488791233832594e-07, 'rewards/chosen': -0.09772415459156036, 'rewards/rejected': -1.1980098485946655, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1002857685089111, 'policy_logps/rejected': -483.03472900390625, 'policy_logps/chosen': -463.0492858886719, 'referece_logps/rejected': -471.0545959472656, 'referece_logps/chosen': -462.072021484375, 'logits/rejected': -0.9477183818817139, 'logits/chosen': -0.9619140625, 'epoch': 3.96}


 66%|██████▌   | 10623/16104 [49:07:27<26:17:19, 17.27s/it]

 66%|██████▌   | 10624/16104 [49:07:38<23:22:58, 15.36s/it]
{'loss': 0.4478, 'learning_rate': 5.483407123028067e-07, 'rewards/chosen': -0.28290367126464844, 'rewards/rejected': -1.3767616748809814, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0938581228256226, 'policy_logps/rejected': -419.49017333984375, 'policy_logps/chosen': -504.0460205078125, 'referece_logps/rejected': -405.7225646972656, 'referece_logps/chosen': -501.2169494628906, 'logits/rejected': -0.5328930020332336, 'logits/chosen': -0.33632421493530273, 'epoch': 3.96}


 66%|██████▌   | 10626/16104 [49:08:09<23:23:46, 15.38s/it]

 66%|██████▌   | 10627/16104 [49:08:26<24:16:40, 15.96s/it]

 66%|██████▌   | 10628/16104 [49:08:37<22:00:17, 14.47s/it]

 66%|██████▌   | 10629/16104 [49:08:50<21:03:59, 13.85s/it]

 66%|██████▌   | 10630/16104 [49:09:05<21:53:21, 14.40s/it]

 66%|██████▌   | 10631/16104 [49:09:16<20:14:37, 13.32s/it]

 66%|██████▌   | 10632/16104 [49:09:28<19:27:30, 12.80s/it]
{'loss': 0.5113, 'learning_rate': 5.469057538524434e-07, 'rewards/chosen': -1.1203347444534302, 'rewards/rejected': -2.021664619445801, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9013298749923706, 'policy_logps/rejected': -445.7296447753906, 'policy_logps/chosen': -388.8241271972656, 'referece_logps/rejected': -425.5129699707031, 'referece_logps/chosen': -377.62078857421875, 'logits/rejected': -1.1941993236541748, 'logits/chosen': -1.2491395473480225, 'epoch': 3.96}


 66%|██████▌   | 10634/16104 [49:09:59<21:44:09, 14.31s/it]

 66%|██████▌   | 10635/16104 [49:10:20<24:24:24, 16.07s/it]
{'loss': 0.4647, 'learning_rate': 5.463679466538229e-07, 'rewards/chosen': 0.8193892240524292, 'rewards/rejected': -0.3193683624267578, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1387577056884766, 'policy_logps/rejected': -511.215576171875, 'policy_logps/chosen': -498.37335205078125, 'referece_logps/rejected': -508.02191162109375, 'referece_logps/chosen': -506.56719970703125, 'logits/rejected': 0.6893808841705322, 'logits/chosen': 0.6716111302375793, 'epoch': 3.96}

 66%|██████▌   | 10636/16104 [49:10:37<24:49:42, 16.35s/it]

 66%|██████▌   | 10637/16104 [49:10:53<24:54:12, 16.40s/it]


 66%|██████▌   | 10639/16104 [49:11:32<27:31:40, 18.13s/it]

 66%|██████▌   | 10640/16104 [49:11:50<27:37:49, 18.20s/it]
{'loss': 0.4024, 'learning_rate': 5.454719684239625e-07, 'rewards/chosen': 0.10484161972999573, 'rewards/rejected': -1.3609182834625244, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4657599925994873, 'policy_logps/rejected': -420.6904296875, 'policy_logps/chosen': -366.9503173828125, 'referece_logps/rejected': -407.08123779296875, 'referece_logps/chosen': -367.998779296875, 'logits/rejected': 0.02084386721253395, 'logits/chosen': 0.11526275426149368, 'epoch': 3.96}


 66%|██████▌   | 10642/16104 [49:12:27<27:42:39, 18.26s/it]
{'loss': 0.4452, 'learning_rate': 5.45113705786572e-07, 'rewards/chosen': -0.04082337021827698, 'rewards/rejected': -1.0508531332015991, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0100297927856445, 'policy_logps/rejected': -462.9132995605469, 'policy_logps/chosen': -507.48748779296875, 'referece_logps/rejected': -452.40478515625, 'referece_logps/chosen': -507.0793151855469, 'logits/rejected': -0.17893698811531067, 'logits/chosen': -0.14891763031482697, 'epoch': 3.96}

 66%|██████▌   | 10643/16104 [49:12:41<25:57:12, 17.11s/it]


 66%|██████▌   | 10645/16104 [49:13:14<25:54:39, 17.09s/it]
{'loss': 0.518, 'learning_rate': 5.445764498558146e-07, 'rewards/chosen': -0.4223720133304596, 'rewards/rejected': -1.5987530946731567, 'rewards/accuracies': 0.625, 'rewards/margins': 1.17638099193573, 'policy_logps/rejected': -488.3030090332031, 'policy_logps/chosen': -370.4715881347656, 'referece_logps/rejected': -472.3155517578125, 'referece_logps/chosen': -366.2478942871094, 'logits/rejected': -0.01951807737350464, 'logits/chosen': 0.13874630630016327, 'epoch': 3.97}


 66%|██████▌   | 10647/16104 [49:13:46<25:28:42, 16.81s/it]
{'loss': 0.4234, 'learning_rate': 5.442183713367124e-07, 'rewards/chosen': -0.12085778266191483, 'rewards/rejected': -2.516103506088257, 'rewards/accuracies': 1.0, 'rewards/margins': 2.395245313644409, 'policy_logps/rejected': -552.43505859375, 'policy_logps/chosen': -512.2371826171875, 'referece_logps/rejected': -527.2739868164062, 'referece_logps/chosen': -511.02862548828125, 'logits/rejected': 0.2897120416164398, 'logits/chosen': 0.28569701313972473, 'epoch': 3.97}


 66%|██████▌   | 10649/16104 [49:14:26<27:44:54, 18.31s/it]
{'loss': 0.3927, 'learning_rate': 5.438603665663302e-07, 'rewards/chosen': 0.04930859059095383, 'rewards/rejected': -1.806882381439209, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8561910390853882, 'policy_logps/rejected': -408.5987548828125, 'policy_logps/chosen': -374.8294677734375, 'referece_logps/rejected': -390.5299072265625, 'referece_logps/chosen': -375.3225402832031, 'logits/rejected': -0.2684970498085022, 'logits/chosen': -0.1502707302570343, 'epoch': 3.97}

 66%|██████▌   | 10650/16104 [49:14:43<27:12:21, 17.96s/it]


 66%|██████▌   | 10652/16104 [49:15:23<28:18:29, 18.69s/it]

 66%|██████▌   | 10653/16104 [49:15:34<24:46:31, 16.36s/it]

 66%|██████▌   | 10654/16104 [49:15:44<22:07:46, 14.62s/it]

 66%|██████▌   | 10655/16104 [49:16:04<24:30:34, 16.19s/it]

 66%|██████▌   | 10656/16104 [49:16:21<24:39:20, 16.29s/it]
{'loss': 0.5417, 'learning_rate': 5.426079314773869e-07, 'rewards/chosen': -0.4336519241333008, 'rewards/rejected': -1.304183006286621, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8705310225486755, 'policy_logps/rejected': -432.8109130859375, 'policy_logps/chosen': -418.1524353027344, 'referece_logps/rejected': -419.7691345214844, 'referece_logps/chosen': -413.8158874511719, 'logits/rejected': -0.11907058954238892, 'logits/chosen': 0.09370328485965729, 'epoch': 3.97}

 66%|██████▌   | 10657/16104 [49:16:33<23:00:43, 15.21s/it]


 66%|██████▌   | 10659/16104 [49:16:58<20:47:58, 13.75s/it]
{'loss': 0.4732, 'learning_rate': 5.420714509722728e-07, 'rewards/chosen': 0.06761131435632706, 'rewards/rejected': -0.7908357977867126, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8584471940994263, 'policy_logps/rejected': -583.9161987304688, 'policy_logps/chosen': -539.6939697265625, 'referece_logps/rejected': -576.0078125, 'referece_logps/chosen': -540.3700561523438, 'logits/rejected': 0.07999345660209656, 'logits/chosen': 0.12369760125875473, 'epoch': 3.97}

 66%|██████▌   | 10660/16104 [49:17:10<19:39:06, 13.00s/it]

 66%|██████▌   | 10661/16104 [49:17:31<23:34:04, 15.59s/it]

 66%|██████▌   | 10662/16104 [49:17:50<24:44:53, 16.37s/it]

 66%|██████▌   | 10663/16104 [49:18:09<26:17:21, 17.39s/it]

 66%|██████▌   | 10664/16104 [49:18:29<27:32:58, 18.23s/it]

 66%|██████▌   | 10665/16104 [49:18:47<27:15:44, 18.04s/it]


 66%|██████▌   | 10667/16104 [49:19:29<29:27:50, 19.51s/it]

 66%|██████▌   | 10668/16104 [49:19:48<29:29:10, 19.53s/it]

 66%|██████▋   | 10669/16104 [49:20:04<27:50:17, 18.44s/it]
{'loss': 0.4682, 'learning_rate': 5.402843877802954e-07, 'rewards/chosen': -0.2769243121147156, 'rewards/rejected': -1.2251852750778198, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9482609033584595, 'policy_logps/rejected': -548.7548828125, 'policy_logps/chosen': -610.1113891601562, 'referece_logps/rejected': -536.5029907226562, 'referece_logps/chosen': -607.3421020507812, 'logits/rejected': 0.9306209683418274, 'logits/chosen': 0.9330982565879822, 'epoch': 3.98}


 66%|██████▋   | 10671/16104 [49:20:37<26:24:17, 17.50s/it]

 66%|██████▋   | 10672/16104 [49:20:57<27:24:27, 18.16s/it]

 66%|██████▋   | 10673/16104 [49:21:14<27:06:21, 17.97s/it]

 66%|██████▋   | 10674/16104 [49:21:35<28:20:44, 18.79s/it]
{'loss': 0.3911, 'learning_rate': 5.393915530944382e-07, 'rewards/chosen': -0.1948004961013794, 'rewards/rejected': -1.4359036684036255, 'rewards/accuracies': 0.75, 'rewards/margins': 1.241103172302246, 'policy_logps/rejected': -499.2674865722656, 'policy_logps/chosen': -445.1322021484375, 'referece_logps/rejected': -484.9084777832031, 'referece_logps/chosen': -443.18414306640625, 'logits/rejected': -0.27442532777786255, 'logits/chosen': -0.29318416118621826, 'epoch': 3.98}


 66%|██████▋   | 10676/16104 [49:22:05<24:47:16, 16.44s/it]
{'loss': 0.4758, 'learning_rate': 5.390345495965722e-07, 'rewards/chosen': -0.016410067677497864, 'rewards/rejected': -1.091838002204895, 'rewards/accuracies': 0.75, 'rewards/margins': 1.075427770614624, 'policy_logps/rejected': -236.56964111328125, 'policy_logps/chosen': -329.3985290527344, 'referece_logps/rejected': -225.6512908935547, 'referece_logps/chosen': -329.23443603515625, 'logits/rejected': -0.20921096205711365, 'logits/chosen': -0.38993117213249207, 'epoch': 3.98}


 66%|██████▋   | 10678/16104 [49:22:41<26:16:38, 17.43s/it]
{'loss': 0.5521, 'learning_rate': 5.386776206862066e-07, 'rewards/chosen': -0.23589736223220825, 'rewards/rejected': -1.0990417003631592, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8631442189216614, 'policy_logps/rejected': -332.11065673828125, 'policy_logps/chosen': -388.9267578125, 'referece_logps/rejected': -321.1202392578125, 'referece_logps/chosen': -386.56781005859375, 'logits/rejected': -0.6672878265380859, 'logits/chosen': -0.7141309976577759, 'epoch': 3.98}


 66%|██████▋   | 10680/16104 [49:23:15<26:04:40, 17.31s/it]

 66%|██████▋   | 10681/16104 [49:23:33<26:21:22, 17.50s/it]

 66%|██████▋   | 10682/16104 [49:23:50<26:23:56, 17.53s/it]

 66%|██████▋   | 10683/16104 [49:24:01<23:20:01, 15.50s/it]
{'loss': 0.4091, 'learning_rate': 5.377856251095799e-07, 'rewards/chosen': -0.20816515386104584, 'rewards/rejected': -1.4405351877212524, 'rewards/accuracies': 0.875, 'rewards/margins': 1.232370138168335, 'policy_logps/rejected': -609.098876953125, 'policy_logps/chosen': -388.87603759765625, 'referece_logps/rejected': -594.6935424804688, 'referece_logps/chosen': -386.79437255859375, 'logits/rejected': -0.7128501534461975, 'logits/chosen': -0.6039959192276001, 'epoch': 3.98}

 66%|██████▋   | 10684/16104 [49:24:18<23:51:53, 15.85s/it]


 66%|██████▋   | 10686/16104 [49:24:55<25:26:53, 16.91s/it]
{'loss': 0.4109, 'learning_rate': 5.372506520746283e-07, 'rewards/chosen': -0.3872363269329071, 'rewards/rejected': -2.188027858734131, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8007915019989014, 'policy_logps/rejected': -430.2569274902344, 'policy_logps/chosen': -605.2071533203125, 'referece_logps/rejected': -408.37664794921875, 'referece_logps/chosen': -601.3347778320312, 'logits/rejected': -0.5257489085197449, 'logits/chosen': -0.4482842683792114, 'epoch': 3.98}

 66%|██████▋   | 10687/16104 [49:25:08<23:44:05, 15.77s/it]


 66%|██████▋   | 10689/16104 [49:25:43<25:25:48, 16.91s/it]
{'loss': 0.3924, 'learning_rate': 5.367158475110045e-07, 'rewards/chosen': -0.31076061725616455, 'rewards/rejected': -1.8186638355255127, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5079032182693481, 'policy_logps/rejected': -300.75103759765625, 'policy_logps/chosen': -308.1650085449219, 'referece_logps/rejected': -282.56439208984375, 'referece_logps/chosen': -305.057373046875, 'logits/rejected': -0.7531028985977173, 'logits/chosen': -0.8303425312042236, 'epoch': 3.98}


 66%|██████▋   | 10691/16104 [49:26:13<24:18:45, 16.17s/it]
{'loss': 0.5978, 'learning_rate': 5.363594048265898e-07, 'rewards/chosen': -1.5385398864746094, 'rewards/rejected': -1.5325254201889038, 'rewards/accuracies': 0.5, 'rewards/margins': -0.006014585494995117, 'policy_logps/rejected': -591.6937255859375, 'policy_logps/chosen': -557.3284301757812, 'referece_logps/rejected': -576.3684692382812, 'referece_logps/chosen': -541.9429931640625, 'logits/rejected': -0.015233337879180908, 'logits/chosen': 0.3753669261932373, 'epoch': 3.98}


 66%|██████▋   | 10693/16104 [49:26:50<26:13:13, 17.44s/it]
{'loss': 0.3372, 'learning_rate': 5.360030371625322e-07, 'rewards/chosen': -0.4398965835571289, 'rewards/rejected': -2.2042062282562256, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7643096446990967, 'policy_logps/rejected': -464.6498718261719, 'policy_logps/chosen': -480.35565185546875, 'referece_logps/rejected': -442.6078186035156, 'referece_logps/chosen': -475.9566650390625, 'logits/rejected': -0.37398263812065125, 'logits/chosen': -0.3008655905723572, 'epoch': 3.98}


 66%|██████▋   | 10695/16104 [49:27:27<26:33:25, 17.68s/it]
{'loss': 0.4552, 'learning_rate': 5.356467445764941e-07, 'rewards/chosen': -1.3988142013549805, 'rewards/rejected': -2.4817843437194824, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0829702615737915, 'policy_logps/rejected': -467.0986328125, 'policy_logps/chosen': -358.7691650390625, 'referece_logps/rejected': -442.28082275390625, 'referece_logps/chosen': -344.781005859375, 'logits/rejected': -0.6890220046043396, 'logits/chosen': -0.6392159461975098, 'epoch': 3.98}


 66%|██████▋   | 10697/16104 [49:28:03<26:41:47, 17.77s/it]
{'loss': 0.4725, 'learning_rate': 5.352905271261267e-07, 'rewards/chosen': -0.33733224868774414, 'rewards/rejected': -1.0299497842788696, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6926175355911255, 'policy_logps/rejected': -400.60992431640625, 'policy_logps/chosen': -305.21893310546875, 'referece_logps/rejected': -390.3104553222656, 'referece_logps/chosen': -301.8456115722656, 'logits/rejected': -0.29422128200531006, 'logits/chosen': -0.24131172895431519, 'epoch': 3.99}

 66%|██████▋   | 10698/16104 [49:28:16<24:23:34, 16.24s/it]


 66%|██████▋   | 10700/16104 [49:28:45<23:05:22, 15.38s/it]
{'loss': 0.4241, 'learning_rate': 5.347563419560392e-07, 'rewards/chosen': -0.46965330839157104, 'rewards/rejected': -1.9580368995666504, 'rewards/accuracies': 0.875, 'rewards/margins': 1.488383412361145, 'policy_logps/rejected': -489.1120300292969, 'policy_logps/chosen': -593.3479614257812, 'referece_logps/rejected': -469.53167724609375, 'referece_logps/chosen': -588.6514892578125, 'logits/rejected': -0.27492764592170715, 'logits/chosen': -0.34595417976379395, 'epoch': 3.99}


 66%|██████▋   | 10702/16104 [49:29:21<24:24:54, 16.27s/it]
{'loss': 0.4533, 'learning_rate': 5.344003125969901e-07, 'rewards/chosen': -0.3666577935218811, 'rewards/rejected': -1.6510359048843384, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2843780517578125, 'policy_logps/rejected': -433.171875, 'policy_logps/chosen': -482.5893249511719, 'referece_logps/rejected': -416.6615295410156, 'referece_logps/chosen': -478.9227600097656, 'logits/rejected': -0.6036332845687866, 'logits/chosen': -0.5830420851707458, 'epoch': 3.99}


 66%|██████▋   | 10704/16104 [49:29:59<26:27:24, 17.64s/it]
{'loss': 0.4782, 'learning_rate': 5.34044358575293e-07, 'rewards/chosen': -0.3300846219062805, 'rewards/rejected': -1.943227767944336, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6131432056427002, 'policy_logps/rejected': -446.868408203125, 'policy_logps/chosen': -348.0697021484375, 'referece_logps/rejected': -427.4361267089844, 'referece_logps/chosen': -344.76885986328125, 'logits/rejected': -0.3374294638633728, 'logits/chosen': -0.04208758473396301, 'epoch': 3.99}


 66%|██████▋   | 10706/16104 [49:30:37<27:28:46, 18.33s/it]

 66%|██████▋   | 10707/16104 [49:30:50<24:58:14, 16.66s/it]

 66%|██████▋   | 10708/16104 [49:31:09<26:23:29, 17.61s/it]

 66%|██████▋   | 10709/16104 [49:31:29<27:25:11, 18.30s/it]

 67%|██████▋   | 10710/16104 [49:31:43<25:26:41, 16.98s/it]

 67%|██████▋   | 10711/16104 [49:32:00<25:06:41, 16.76s/it]

 67%|██████▋   | 10712/16104 [49:32:18<25:44:24, 17.19s/it]

 67%|██████▋   | 10713/16104 [49:32:31<23:56:47, 15.99s/it]
{'loss': 0.5051, 'learning_rate': 5.324434993213923e-07, 'rewards/chosen': -0.5446417331695557, 'rewards/rejected': -0.9496740102767944, 'rewards/accuracies': 0.625, 'rewards/margins': 0.40503230690956116, 'policy_logps/rejected': -518.043212890625, 'policy_logps/chosen': -584.468017578125, 'referece_logps/rejected': -508.5465393066406, 'referece_logps/chosen': -579.021728515625, 'logits/rejected': 0.2704414129257202, 'logits/chosen': 0.214918851852417, 'epoch': 3.99}

 67%|██████▋   | 10714/16104 [49:32:52<26:26:29, 17.66s/it]


 67%|██████▋   | 10716/16104 [49:33:26<25:29:44, 17.03s/it]

 67%|██████▋   | 10717/16104 [49:33:46<26:43:46, 17.86s/it]

 67%|██████▋   | 10718/16104 [49:33:57<23:48:20, 15.91s/it]
{'loss': 0.4724, 'learning_rate': 5.315547947057895e-07, 'rewards/chosen': -0.30038195848464966, 'rewards/rejected': -1.1730128526687622, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8726308941841125, 'policy_logps/rejected': -353.7904052734375, 'policy_logps/chosen': -392.62249755859375, 'referece_logps/rejected': -342.0602722167969, 'referece_logps/chosen': -389.61865234375, 'logits/rejected': -0.4145253300666809, 'logits/chosen': -0.44768622517585754, 'epoch': 3.99}


 67%|██████▋   | 10720/16104 [49:34:29<23:11:18, 15.50s/it]

 67%|██████▋   | 10721/16104 [49:34:41<21:35:29, 14.44s/it]
{'loss': 0.3662, 'learning_rate': 5.310217992722437e-07, 'rewards/chosen': -1.0715333223342896, 'rewards/rejected': -1.999847173690796, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9283138513565063, 'policy_logps/rejected': -237.13037109375, 'policy_logps/chosen': -328.3307189941406, 'referece_logps/rejected': -217.13192749023438, 'referece_logps/chosen': -317.6153869628906, 'logits/rejected': -0.8100781440734863, 'logits/chosen': -1.0307170152664185, 'epoch': 3.99}

 67%|██████▋   | 10722/16104 [49:35:01<23:52:21, 15.97s/it]


 67%|██████▋   | 10724/16104 [49:35:35<25:01:13, 16.74s/it]
{'loss': 0.4949, 'learning_rate': 5.304889745777396e-07, 'rewards/chosen': -0.7999758720397949, 'rewards/rejected': -3.027430295944214, 'rewards/accuracies': 0.875, 'rewards/margins': 2.227454423904419, 'policy_logps/rejected': -508.79669189453125, 'policy_logps/chosen': -405.5115051269531, 'referece_logps/rejected': -478.5223388671875, 'referece_logps/chosen': -397.51171875, 'logits/rejected': -0.09194670617580414, 'logits/chosen': 0.015003364533185959, 'epoch': 4.0}


 67%|██████▋   | 10726/16104 [49:36:14<27:07:53, 18.16s/it]

 67%|██████▋   | 10727/16104 [49:36:34<27:46:13, 18.59s/it]

 67%|██████▋   | 10728/16104 [49:36:53<28:17:00, 18.94s/it]
{'loss': 0.4273, 'learning_rate': 5.297788075810689e-07, 'rewards/chosen': -0.5714866518974304, 'rewards/rejected': -1.413832426071167, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8423457741737366, 'policy_logps/rejected': -424.78472900390625, 'policy_logps/chosen': -557.328125, 'referece_logps/rejected': -410.6463928222656, 'referece_logps/chosen': -551.61328125, 'logits/rejected': 0.8632331490516663, 'logits/chosen': 0.6663669943809509, 'epoch': 4.0}

 67%|██████▋   | 10729/16104 [49:37:04<24:38:36, 16.51s/it]

 67%|██████▋   | 10730/16104 [49:37:26<27:10:40, 18.21s/it]

 67%|██████▋   | 10731/16104 [49:37:41<25:32:29, 17.11s/it]


 67%|██████▋   | 10733/16104 [49:38:14<25:36:23, 17.16s/it]
{'loss': 0.4526, 'learning_rate': 5.288915268679971e-07, 'rewards/chosen': -0.48763564229011536, 'rewards/rejected': -1.5433038473129272, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0556682348251343, 'policy_logps/rejected': -450.5087585449219, 'policy_logps/chosen': -557.5372924804688, 'referece_logps/rejected': -435.07574462890625, 'referece_logps/chosen': -552.6609497070312, 'logits/rejected': 0.11419297754764557, 'logits/chosen': 0.15515729784965515, 'epoch': 4.0}

 67%|██████▋   | 10734/16104 [49:38:26<23:06:50, 15.50s/it]

 67%|██████▋   | 10735/16104 [49:38:44<24:17:11, 16.28s/it]

 67%|██████▋   | 10736/16104 [49:39:03<25:49:57, 17.32s/it]


 67%|██████▋   | 10738/16104 [49:39:38<25:16:03, 16.95s/it]

 67%|██████▋   | 10739/16104 [49:39:50<22:56:26, 15.39s/it]
{'loss': 0.5316, 'learning_rate': 5.278274189780771e-07, 'rewards/chosen': -0.8149206042289734, 'rewards/rejected': -1.7533477544784546, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9384270906448364, 'policy_logps/rejected': -355.84881591796875, 'policy_logps/chosen': -488.4535217285156, 'referece_logps/rejected': -338.3153381347656, 'referece_logps/chosen': -480.3043518066406, 'logits/rejected': 0.34197407960891724, 'logits/chosen': 0.2785419523715973, 'epoch': 4.0}


 67%|██████▋   | 10741/16104 [49:40:14<20:30:11, 13.76s/it]

 67%|██████▋   | 10742/16104 [49:40:28<20:41:56, 13.90s/it]
{'loss': 0.4854, 'learning_rate': 5.272956227892912e-07, 'rewards/chosen': -0.497161865234375, 'rewards/rejected': -1.880280613899231, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3831185102462769, 'policy_logps/rejected': -481.6368408203125, 'policy_logps/chosen': -658.0942993164062, 'referece_logps/rejected': -462.8340148925781, 'referece_logps/chosen': -653.1226196289062, 'logits/rejected': 0.17523270845413208, 'logits/chosen': 0.14071068167686462, 'epoch': 4.0}

 67%|██████▋   | 10743/16104 [49:40:42<20:28:34, 13.75s/it]

 67%|██████▋   | 10744/16104 [49:41:01<23:04:36, 15.50s/it]


 67%|██████▋   | 10746/16104 [49:41:22<19:24:16, 13.04s/it]
{'loss': 0.3338, 'learning_rate': 5.265868289419895e-07, 'rewards/chosen': -0.10728128999471664, 'rewards/rejected': -1.603925347328186, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4966440200805664, 'policy_logps/rejected': -446.45147705078125, 'policy_logps/chosen': -513.8506469726562, 'referece_logps/rejected': -430.4122619628906, 'referece_logps/chosen': -512.77783203125, 'logits/rejected': -0.02783074975013733, 'logits/chosen': -0.13517868518829346, 'epoch': 4.0}


 67%|██████▋   | 10748/16104 [49:41:54<21:50:24, 14.68s/it]
{'loss': 0.3941, 'learning_rate': 5.262325468921134e-07, 'rewards/chosen': 0.006307218223810196, 'rewards/rejected': -1.4811605215072632, 'rewards/accuracies': 1.0, 'rewards/margins': 1.487467885017395, 'policy_logps/rejected': -355.7134704589844, 'policy_logps/chosen': -473.5308837890625, 'referece_logps/rejected': -340.90185546875, 'referece_logps/chosen': -473.593994140625, 'logits/rejected': -0.4080549478530884, 'logits/chosen': -0.4272545576095581, 'epoch': 4.0}


 67%|██████▋   | 10750/16104 [49:42:26<22:57:53, 15.44s/it]
{'loss': 0.5302, 'learning_rate': 5.258783415011925e-07, 'rewards/chosen': -0.42858508229255676, 'rewards/rejected': -1.0022931098937988, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5737079381942749, 'policy_logps/rejected': -413.00628662109375, 'policy_logps/chosen': -533.7990112304688, 'referece_logps/rejected': -402.9833068847656, 'referece_logps/chosen': -529.5131225585938, 'logits/rejected': 0.5686145424842834, 'logits/chosen': 0.47712600231170654, 'epoch': 4.01}


 67%|██████▋   | 10752/16104 [49:42:48<19:26:52, 13.08s/it]

 67%|██████▋   | 10753/16104 [49:43:00<18:59:29, 12.78s/it]
{'loss': 0.379, 'learning_rate': 5.253471772757201e-07, 'rewards/chosen': -0.13556614518165588, 'rewards/rejected': -1.7104603052139282, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5748943090438843, 'policy_logps/rejected': -430.9498596191406, 'policy_logps/chosen': -392.6240234375, 'referece_logps/rejected': -413.84527587890625, 'referece_logps/chosen': -391.2683410644531, 'logits/rejected': -0.28346288204193115, 'logits/chosen': -0.062484417110681534, 'epoch': 4.01}


 67%|██████▋   | 10755/16104 [49:43:31<20:23:03, 13.72s/it]
{'loss': 0.4399, 'learning_rate': 5.249931637829035e-07, 'rewards/chosen': -0.20317280292510986, 'rewards/rejected': -1.6854861974716187, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4823133945465088, 'policy_logps/rejected': -337.70220947265625, 'policy_logps/chosen': -413.6635437011719, 'referece_logps/rejected': -320.84735107421875, 'referece_logps/chosen': -411.6318359375, 'logits/rejected': -0.022617949172854424, 'logits/chosen': 0.040095776319503784, 'epoch': 4.01}


 67%|██████▋   | 10757/16104 [49:43:52<18:06:14, 12.19s/it]

 67%|██████▋   | 10758/16104 [49:44:05<18:11:16, 12.25s/it]

 67%|██████▋   | 10759/16104 [49:44:16<17:59:11, 12.11s/it]
{'loss': 0.3229, 'learning_rate': 5.242853674330276e-07, 'rewards/chosen': 0.09723358601331711, 'rewards/rejected': -1.5258952379226685, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6231286525726318, 'policy_logps/rejected': -454.53521728515625, 'policy_logps/chosen': -563.81591796875, 'referece_logps/rejected': -439.2762756347656, 'referece_logps/chosen': -564.7882690429688, 'logits/rejected': -0.5591050386428833, 'logits/chosen': -0.6164419651031494, 'epoch': 4.01}


 67%|██████▋   | 10761/16104 [49:44:43<18:42:29, 12.61s/it]

 67%|██████▋   | 10762/16104 [49:45:01<21:08:27, 14.25s/it]

 67%|██████▋   | 10763/16104 [49:45:20<23:29:07, 15.83s/it]
{'loss': 0.322, 'learning_rate': 5.235778789792287e-07, 'rewards/chosen': 0.028828613460063934, 'rewards/rejected': -1.5901782512664795, 'rewards/accuracies': 0.875, 'rewards/margins': 1.619006872177124, 'policy_logps/rejected': -340.010986328125, 'policy_logps/chosen': -592.8657836914062, 'referece_logps/rejected': -324.10919189453125, 'referece_logps/chosen': -593.154052734375, 'logits/rejected': 0.32441335916519165, 'logits/chosen': 0.32168158888816833, 'epoch': 4.01}

 67%|██████▋   | 10764/16104 [49:45:39<24:56:41, 16.82s/it]


 67%|██████▋   | 10766/16104 [49:46:10<24:23:36, 16.45s/it]

 67%|██████▋   | 10767/16104 [49:46:30<26:02:30, 17.57s/it]

 67%|██████▋   | 10768/16104 [49:46:50<27:02:01, 18.24s/it]
{'loss': 0.4301, 'learning_rate': 5.226939520884119e-07, 'rewards/chosen': -0.9584240317344666, 'rewards/rejected': -2.721388816833496, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7629648447036743, 'policy_logps/rejected': -449.26715087890625, 'policy_logps/chosen': -497.5380859375, 'referece_logps/rejected': -422.05322265625, 'referece_logps/chosen': -487.9538879394531, 'logits/rejected': -0.2513170838356018, 'logits/chosen': -0.2849217653274536, 'epoch': 4.01}


 67%|██████▋   | 10770/16104 [49:47:23<25:58:41, 17.53s/it]
{'loss': 0.4136, 'learning_rate': 5.22340516437201e-07, 'rewards/chosen': -0.6228358745574951, 'rewards/rejected': -1.611025094985962, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9881892800331116, 'policy_logps/rejected': -337.609619140625, 'policy_logps/chosen': -294.25616455078125, 'referece_logps/rejected': -321.4993896484375, 'referece_logps/chosen': -288.02777099609375, 'logits/rejected': -0.9026763439178467, 'logits/chosen': -0.8169431686401367, 'epoch': 4.01}

 67%|██████▋   | 10771/16104 [49:47:42<26:46:07, 18.07s/it]

 67%|██████▋   | 10772/16104 [49:47:55<24:31:58, 16.56s/it]

 67%|██████▋   | 10773/16104 [49:48:13<25:18:37, 17.09s/it]

 67%|██████▋   | 10774/16104 [49:48:33<26:27:30, 17.87s/it]

 67%|██████▋   | 10775/16104 [49:48:53<27:25:52, 18.53s/it]

 67%|██████▋   | 10776/16104 [49:49:10<26:46:51, 18.10s/it]


 67%|██████▋   | 10778/16104 [49:49:49<27:51:47, 18.83s/it]

 67%|██████▋   | 10779/16104 [49:50:01<24:58:08, 16.88s/it]
{'loss': 0.4679, 'learning_rate': 5.207510132799436e-07, 'rewards/chosen': -0.25457534193992615, 'rewards/rejected': -1.0238723754882812, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7692970037460327, 'policy_logps/rejected': -599.554443359375, 'policy_logps/chosen': -559.0030517578125, 'referece_logps/rejected': -589.3157348632812, 'referece_logps/chosen': -556.457275390625, 'logits/rejected': -0.5097649097442627, 'logits/chosen': -0.49121934175491333, 'epoch': 4.02}


 67%|██████▋   | 10781/16104 [49:50:37<25:47:52, 17.45s/it]
{'loss': 0.5096, 'learning_rate': 5.203980034240261e-07, 'rewards/chosen': -0.969645619392395, 'rewards/rejected': -1.796509861946106, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8268641829490662, 'policy_logps/rejected': -323.1855773925781, 'policy_logps/chosen': -348.1250915527344, 'referece_logps/rejected': -305.220458984375, 'referece_logps/chosen': -338.42864990234375, 'logits/rejected': -0.6083561778068542, 'logits/chosen': -0.6269281506538391, 'epoch': 4.02}


 67%|██████▋   | 10783/16104 [49:51:17<27:27:58, 18.58s/it]
{'loss': 0.4652, 'learning_rate': 5.200450711711347e-07, 'rewards/chosen': -0.4222637414932251, 'rewards/rejected': -0.8842552304267883, 'rewards/accuracies': 0.75, 'rewards/margins': 0.46199148893356323, 'policy_logps/rejected': -431.2207946777344, 'policy_logps/chosen': -396.3701477050781, 'referece_logps/rejected': -422.37823486328125, 'referece_logps/chosen': -392.1474914550781, 'logits/rejected': 0.03897297382354736, 'logits/chosen': -0.0012060441076755524, 'epoch': 4.02}


 67%|██████▋   | 10785/16104 [49:51:43<22:52:59, 15.49s/it]

 67%|██████▋   | 10786/16104 [49:51:59<23:16:50, 15.76s/it]
{'loss': 0.5549, 'learning_rate': 5.195158184223885e-07, 'rewards/chosen': -0.08855819702148438, 'rewards/rejected': -0.6217894554138184, 'rewards/accuracies': 0.75, 'rewards/margins': 0.533231258392334, 'policy_logps/rejected': -455.8404235839844, 'policy_logps/chosen': -434.3217468261719, 'referece_logps/rejected': -449.6224365234375, 'referece_logps/chosen': -433.4361877441406, 'logits/rejected': -0.32893797755241394, 'logits/chosen': -0.3971301317214966, 'epoch': 4.02}

 67%|██████▋   | 10787/16104 [49:52:12<22:13:24, 15.05s/it]


 67%|██████▋   | 10789/16104 [49:52:39<20:44:42, 14.05s/it]
{'loss': 0.378, 'learning_rate': 5.189867406016209e-07, 'rewards/chosen': -1.1645816564559937, 'rewards/rejected': -2.263805627822876, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0992240905761719, 'policy_logps/rejected': -484.4779968261719, 'policy_logps/chosen': -478.224365234375, 'referece_logps/rejected': -461.8399658203125, 'referece_logps/chosen': -466.57855224609375, 'logits/rejected': -0.8855035901069641, 'logits/chosen': -0.9220089912414551, 'epoch': 4.02}

 67%|██████▋   | 10790/16104 [49:52:52<20:11:52, 13.68s/it]

 67%|██████▋   | 10791/16104 [49:53:02<18:51:15, 12.78s/it]

 67%|██████▋   | 10792/16104 [49:53:18<20:15:09, 13.73s/it]

 67%|██████▋   | 10793/16104 [49:53:40<23:47:48, 16.13s/it]

 67%|██████▋   | 10794/16104 [49:54:01<26:05:17, 17.69s/it]


 67%|██████▋   | 10796/16104 [49:54:33<24:12:26, 16.42s/it]
{'loss': 0.4345, 'learning_rate': 5.177529070438455e-07, 'rewards/chosen': 0.2798423767089844, 'rewards/rejected': -1.0393462181091309, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3191885948181152, 'policy_logps/rejected': -403.076171875, 'policy_logps/chosen': -395.4654541015625, 'referece_logps/rejected': -392.6827392578125, 'referece_logps/chosen': -398.26385498046875, 'logits/rejected': -0.192376047372818, 'logits/chosen': -0.07045295089483261, 'epoch': 4.02}


 67%|██████▋   | 10798/16104 [49:55:13<26:24:21, 17.92s/it]

 67%|██████▋   | 10799/16104 [49:55:27<24:48:28, 16.83s/it]
{'loss': 0.396, 'learning_rate': 5.172244137071198e-07, 'rewards/chosen': -0.26667559146881104, 'rewards/rejected': -1.2656735181808472, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9989980459213257, 'policy_logps/rejected': -468.4732666015625, 'policy_logps/chosen': -325.255859375, 'referece_logps/rejected': -455.8165283203125, 'referece_logps/chosen': -322.589111328125, 'logits/rejected': -0.06261394917964935, 'logits/chosen': -0.030346930027008057, 'epoch': 4.02}


 67%|██████▋   | 10801/16104 [49:55:59<23:30:40, 15.96s/it]
{'loss': 0.3288, 'learning_rate': 5.168721824497627e-07, 'rewards/chosen': -0.4351890981197357, 'rewards/rejected': -1.480046272277832, 'rewards/accuracies': 0.75, 'rewards/margins': 1.044857144355774, 'policy_logps/rejected': -415.66522216796875, 'policy_logps/chosen': -424.26885986328125, 'referece_logps/rejected': -400.86474609375, 'referece_logps/chosen': -419.9169921875, 'logits/rejected': -0.14907009899616241, 'logits/chosen': 0.0024508237838745117, 'epoch': 4.02}


 67%|██████▋   | 10803/16104 [49:56:21<19:34:30, 13.29s/it]
{'loss': 0.4039, 'learning_rate': 5.165200293659336e-07, 'rewards/chosen': -0.5207594037055969, 'rewards/rejected': -1.3570557832717896, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8362964391708374, 'policy_logps/rejected': -578.0645141601562, 'policy_logps/chosen': -435.498779296875, 'referece_logps/rejected': -564.4939575195312, 'referece_logps/chosen': -430.2911682128906, 'logits/rejected': -0.12272478640079498, 'logits/chosen': -0.0852193832397461, 'epoch': 4.02}


 67%|██████▋   | 10805/16104 [49:56:51<21:40:10, 14.72s/it]
{'loss': 0.3835, 'learning_rate': 5.161679545126143e-07, 'rewards/chosen': -1.3516900539398193, 'rewards/rejected': -2.23175311088562, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8800631761550903, 'policy_logps/rejected': -261.3408203125, 'policy_logps/chosen': -332.7458190917969, 'referece_logps/rejected': -239.0233154296875, 'referece_logps/chosen': -319.2289123535156, 'logits/rejected': -0.6371318697929382, 'logits/chosen': -0.5933001637458801, 'epoch': 4.03}


 67%|██████▋   | 10807/16104 [49:57:21<21:50:19, 14.84s/it]

 67%|██████▋   | 10808/16104 [49:57:41<23:56:50, 16.28s/it]
{'loss': 0.2886, 'learning_rate': 5.156399890394552e-07, 'rewards/chosen': -0.33527296781539917, 'rewards/rejected': -2.8138515949249268, 'rewards/accuracies': 0.875, 'rewards/margins': 2.478578567504883, 'policy_logps/rejected': -424.7842102050781, 'policy_logps/chosen': -405.6146240234375, 'referece_logps/rejected': -396.6456298828125, 'referece_logps/chosen': -402.26190185546875, 'logits/rejected': -0.13922236859798431, 'logits/chosen': -0.020245902240276337, 'epoch': 4.03}

 67%|██████▋   | 10809/16104 [49:58:00<25:22:01, 17.25s/it]

 67%|██████▋   | 10810/16104 [49:58:20<26:26:53, 17.99s/it]

 67%|██████▋   | 10811/16104 [49:58:40<27:22:45, 18.62s/it]


 67%|██████▋   | 10813/16104 [49:59:20<28:08:07, 19.14s/it]
{'loss': 0.3128, 'learning_rate': 5.147604385436069e-07, 'rewards/chosen': 0.10650517791509628, 'rewards/rejected': -2.1769206523895264, 'rewards/accuracies': 0.875, 'rewards/margins': 2.28342604637146, 'policy_logps/rejected': -329.38287353515625, 'policy_logps/chosen': -625.582763671875, 'referece_logps/rejected': -307.6136474609375, 'referece_logps/chosen': -626.6477661132812, 'logits/rejected': 0.9364219903945923, 'logits/chosen': 0.9354875683784485, 'epoch': 4.03}

 67%|██████▋   | 10814/16104 [49:59:32<25:22:47, 17.27s/it]

 67%|██████▋   | 10815/16104 [49:59:48<24:50:30, 16.91s/it]

 67%|██████▋   | 10816/16104 [50:00:08<26:03:26, 17.74s/it]

 67%|██████▋   | 10817/16104 [50:00:28<26:59:16, 18.38s/it]

 67%|██████▋   | 10818/16104 [50:00:46<26:43:48, 18.20s/it]


 67%|██████▋   | 10820/16104 [50:01:16<23:54:51, 16.29s/it]

 67%|██████▋   | 10821/16104 [50:01:30<22:52:23, 15.59s/it]
{'loss': 0.3498, 'learning_rate': 5.133541788179269e-07, 'rewards/chosen': -0.7656448483467102, 'rewards/rejected': -2.0141961574554443, 'rewards/accuracies': 0.75, 'rewards/margins': 1.248551368713379, 'policy_logps/rejected': -330.93389892578125, 'policy_logps/chosen': -456.40557861328125, 'referece_logps/rejected': -310.7919616699219, 'referece_logps/chosen': -448.7491455078125, 'logits/rejected': -0.6411244869232178, 'logits/chosen': -0.7944540977478027, 'epoch': 4.03}

 67%|██████▋   | 10822/16104 [50:01:44<22:36:13, 15.41s/it]

 67%|██████▋   | 10823/16104 [50:02:00<22:35:16, 15.40s/it]

 67%|██████▋   | 10824/16104 [50:02:11<20:45:11, 14.15s/it]

 67%|██████▋   | 10825/16104 [50:02:31<23:14:17, 15.85s/it]

 67%|██████▋   | 10826/16104 [50:02:53<25:46:20, 17.58s/it]

 67%|██████▋   | 10827/16104 [50:03:12<26:37:34, 18.16s/it]

 67%|██████▋   | 10828/16104 [50:03:26<24:53:45, 16.99s/it]


 67%|██████▋   | 10830/16104 [50:04:05<26:46:37, 18.28s/it]
{'loss': 0.3565, 'learning_rate': 5.117736427628426e-07, 'rewards/chosen': -0.5031759738922119, 'rewards/rejected': -1.6101770401000977, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1070011854171753, 'policy_logps/rejected': -414.66644287109375, 'policy_logps/chosen': -219.60581970214844, 'referece_logps/rejected': -398.5646667480469, 'referece_logps/chosen': -214.57406616210938, 'logits/rejected': -0.7378329634666443, 'logits/chosen': -0.5845541954040527, 'epoch': 4.04}

 67%|██████▋   | 10831/16104 [50:04:20<25:11:01, 17.19s/it]

 67%|██████▋   | 10832/16104 [50:04:37<25:10:04, 17.19s/it]

 67%|██████▋   | 10833/16104 [50:04:48<22:26:50, 15.33s/it]

 67%|██████▋   | 10834/16104 [50:04:59<20:22:33, 13.92s/it]

 67%|██████▋   | 10835/16104 [50:05:15<21:29:50, 14.69s/it]

 67%|██████▋   | 10836/16104 [50:05:28<20:46:48, 14.20s/it]


 67%|██████▋   | 10838/16104 [50:06:00<22:25:19, 15.33s/it]
{'loss': 0.4414, 'learning_rate': 5.103700646383851e-07, 'rewards/chosen': -0.40812939405441284, 'rewards/rejected': -1.609371304512024, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2012420892715454, 'policy_logps/rejected': -646.648193359375, 'policy_logps/chosen': -495.7451171875, 'referece_logps/rejected': -630.554443359375, 'referece_logps/chosen': -491.663818359375, 'logits/rejected': -0.4103613495826721, 'logits/chosen': -0.24852879345417023, 'epoch': 4.04}

 67%|██████▋   | 10839/16104 [50:06:13<21:37:15, 14.78s/it]


 67%|██████▋   | 10841/16104 [50:06:54<25:49:27, 17.66s/it]

 67%|██████▋   | 10842/16104 [50:07:14<26:46:56, 18.32s/it]

 67%|██████▋   | 10843/16104 [50:07:34<27:32:19, 18.84s/it]

 67%|██████▋   | 10844/16104 [50:07:48<25:19:26, 17.33s/it]
{'loss': 0.4109, 'learning_rate': 5.093182127152624e-07, 'rewards/chosen': -0.44055235385894775, 'rewards/rejected': -1.9656291007995605, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5250767469406128, 'policy_logps/rejected': -422.86029052734375, 'policy_logps/chosen': -344.87176513671875, 'referece_logps/rejected': -403.2039794921875, 'referece_logps/chosen': -340.46624755859375, 'logits/rejected': -0.5581536889076233, 'logits/chosen': -0.4520019590854645, 'epoch': 4.04}

 67%|██████▋   | 10845/16104 [50:08:07<26:01:54, 17.82s/it]

 67%|██████▋   | 10846/16104 [50:08:25<26:13:43, 17.96s/it]

 67%|██████▋   | 10847/16104 [50:08:45<26:52:45, 18.41s/it]

 67%|██████▋   | 10848/16104 [50:08:58<24:54:28, 17.06s/it]

 67%|██████▋   | 10849/16104 [50:09:10<22:37:02, 15.49s/it]

 67%|██████▋   | 10850/16104 [50:09:24<21:46:48, 14.92s/it]

 67%|██████▋   | 10851/16104 [50:09:34<19:51:52, 13.61s/it]

 67%|██████▋   | 10852/16104 [50:09:47<19:34:17, 13.42s/it]

 67%|██████▋   | 10853/16104 [50:10:00<19:06:29, 13.10s/it]

 67%|██████▋   | 10854/16104 [50:10:20<22:07:09, 15.17s/it]

 67%|██████▋   | 10855/16104 [50:10:36<22:30:08, 15.43s/it]

 67%|██████▋   | 10856/16104 [50:10:58<25:19:02, 17.37s/it]

 67%|██████▋   | 10857/16104 [50:11:12<24:00:13, 16.47s/it]

 67%|██████▋   | 10858/16104 [50:11:32<25:23:45, 17.43s/it]

 67%|██████▋   | 10859/16104 [50:11:50<25:40:57, 17.63s/it]

 67%|██████▋   | 10860/16104 [50:12:07<25:25:13, 17.45s/it]

 67%|██████▋   | 10861/16104 [50:12:27<26:32:22, 18.22s/it]

 67%|██████▋   | 10862/16104 [50:12:48<27:45:25, 19.06s/it]


 67%|██████▋   | 10864/16104 [50:13:27<28:03:44, 19.28s/it]
{'loss': 0.2538, 'learning_rate': 5.058172089622075e-07, 'rewards/chosen': -0.35176602005958557, 'rewards/rejected': -1.8566007614135742, 'rewards/accuracies': 1.0, 'rewards/margins': 1.504834771156311, 'policy_logps/rejected': -395.6646423339844, 'policy_logps/chosen': -438.0828552246094, 'referece_logps/rejected': -377.0986328125, 'referece_logps/chosen': -434.56524658203125, 'logits/rejected': -0.4925094246864319, 'logits/chosen': -0.5047054886817932, 'epoch': 4.05}

 67%|██████▋   | 10865/16104 [50:13:44<27:03:25, 18.59s/it]

 67%|██████▋   | 10866/16104 [50:14:01<26:27:35, 18.19s/it]

 67%|██████▋   | 10867/16104 [50:14:18<26:06:58, 17.95s/it]

 67%|██████▋   | 10868/16104 [50:14:32<24:11:39, 16.63s/it]

 67%|██████▋   | 10869/16104 [50:14:50<24:46:27, 17.04s/it]

 67%|██████▋   | 10870/16104 [50:15:00<22:01:04, 15.14s/it]

 68%|██████▊   | 10871/16104 [50:15:22<24:57:51, 17.17s/it]

 68%|██████▊   | 10872/16104 [50:15:41<25:26:17, 17.50s/it]

 68%|██████▊   | 10873/16104 [50:15:54<23:28:05, 16.15s/it]

 68%|██████▊   | 10874/16104 [50:16:11<24:00:22, 16.52s/it]

 68%|██████▊   | 10875/16104 [50:16:26<23:08:32, 15.93s/it]

 68%|██████▊   | 10876/16104 [50:16:45<24:44:57, 17.04s/it]

 68%|██████▊   | 10877/16104 [50:16:56<21:56:28, 15.11s/it]

 68%|██████▊   | 10878/16104 [50:17:18<25:05:50, 17.29s/it]

 68%|██████▊   | 10879/16104 [50:17:39<26:35:37, 18.32s/it]

 68%|██████▊   | 10880/16104 [50:17:55<25:27:17, 17.54s/it]

 68%|██████▊   | 10881/16104 [50:18:11<25:04:55, 17.29s/it]

 68%|██████▊   | 10882/16104 [50:18:32<26:29:11, 18.26s/it]

 68%|██████▊   | 10883/16104 [50:18:49<25:48:41, 17.80s/it]

 68%|██████▊   | 10884/16104 [50:19:08<26:38:29, 18.37s/it]


 68%|██████▊   | 10886/16104 [50:19:39<23:57:26, 16.53s/it]
{'loss': 0.3642, 'learning_rate': 5.019753426445448e-07, 'rewards/chosen': -0.6065722107887268, 'rewards/rejected': -1.9981391429901123, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3915667533874512, 'policy_logps/rejected': -340.5989074707031, 'policy_logps/chosen': -317.0782165527344, 'referece_logps/rejected': -320.6175231933594, 'referece_logps/chosen': -311.012451171875, 'logits/rejected': 0.6109652519226074, 'logits/chosen': 0.662967324256897, 'epoch': 4.06}

 68%|██████▊   | 10887/16104 [50:19:58<25:15:56, 17.43s/it]

 68%|██████▊   | 10888/16104 [50:20:19<26:37:46, 18.38s/it]

 68%|██████▊   | 10889/16104 [50:20:38<26:40:40, 18.42s/it]

 68%|██████▊   | 10890/16104 [50:20:57<27:21:20, 18.89s/it]

 68%|██████▊   | 10891/16104 [50:21:10<24:31:51, 16.94s/it]

 68%|██████▊   | 10892/16104 [50:21:28<25:08:17, 17.36s/it]

 68%|██████▊   | 10893/16104 [50:21:48<26:12:23, 18.10s/it]

 68%|██████▊   | 10894/16104 [50:22:02<24:34:17, 16.98s/it]

 68%|██████▊   | 10895/16104 [50:22:21<25:08:19, 17.37s/it]

 68%|██████▊   | 10896/16104 [50:22:37<24:40:40, 17.06s/it]

 68%|██████▊   | 10897/16104 [50:22:57<25:54:22, 17.91s/it]

 68%|██████▊   | 10898/16104 [50:23:10<23:34:40, 16.30s/it]

 68%|██████▊   | 10899/16104 [50:23:24<22:41:42, 15.70s/it]

 68%|██████▊   | 10900/16104 [50:23:37<21:24:34, 14.81s/it]

 68%|██████▊   | 10901/16104 [50:23:49<20:29:27, 14.18s/it]

 68%|██████▊   | 10902/16104 [50:24:08<22:41:35, 15.70s/it]

 68%|██████▊   | 10903/16104 [50:24:29<24:55:20, 17.25s/it]

 68%|██████▊   | 10904/16104 [50:24:48<25:27:43, 17.63s/it]

 68%|██████▊   | 10905/16104 [50:25:08<26:23:40, 18.28s/it]

 68%|██████▊   | 10906/16104 [50:25:19<23:14:59, 16.10s/it]

 68%|██████▊   | 10907/16104 [50:25:30<20:59:10, 14.54s/it]

 68%|██████▊   | 10908/16104 [50:25:45<21:28:29, 14.88s/it]

 68%|██████▊   | 10909/16104 [50:26:05<23:31:59, 16.31s/it]

 68%|██████▊   | 10910/16104 [50:26:16<21:07:42, 14.64s/it]

 68%|██████▊   | 10911/16104 [50:26:26<19:24:30, 13.45s/it]

 68%|██████▊   | 10912/16104 [50:26:45<21:26:56, 14.87s/it]

 68%|██████▊   | 10913/16104 [50:26:59<21:22:56, 14.83s/it]

 68%|██████▊   | 10914/16104 [50:27:11<19:58:58, 13.86s/it]

 68%|██████▊   | 10915/16104 [50:27:30<22:28:25, 15.59s/it]

 68%|██████▊   | 10916/16104 [50:27:43<21:03:41, 14.61s/it]

 68%|██████▊   | 10917/16104 [50:28:01<22:27:03, 15.58s/it]

 68%|██████▊   | 10918/16104 [50:28:15<22:04:47, 15.33s/it]

 68%|██████▊   | 10919/16104 [50:28:26<20:00:30, 13.89s/it]

 68%|██████▊   | 10920/16104 [50:28:44<21:55:40, 15.23s/it]

 68%|██████▊   | 10921/16104 [50:29:06<24:52:32, 17.28s/it]

 68%|██████▊   | 10922/16104 [50:29:23<24:36:11, 17.09s/it]

 68%|██████▊   | 10923/16104 [50:29:39<24:05:49, 16.74s/it]

 68%|██████▊   | 10924/16104 [50:29:58<25:15:53, 17.56s/it]

 68%|██████▊   | 10925/16104 [50:30:11<22:56:14, 15.94s/it]

 68%|██████▊   | 10926/16104 [50:30:27<23:10:44, 16.12s/it]

 68%|██████▊   | 10927/16104 [50:30:38<20:50:57, 14.50s/it]

 68%|██████▊   | 10928/16104 [50:30:49<19:18:22, 13.43s/it]

 68%|██████▊   | 10929/16104 [50:31:08<21:37:25, 15.04s/it]

 68%|██████▊   | 10930/16104 [50:31:27<23:36:39, 16.43s/it]

 68%|██████▊   | 10931/16104 [50:31:46<24:47:45, 17.26s/it]

 68%|██████▊   | 10932/16104 [50:32:07<26:09:32, 18.21s/it]

 68%|██████▊   | 10933/16104 [50:32:23<25:17:33, 17.61s/it]

 68%|██████▊   | 10934/16104 [50:32:34<22:32:20, 15.69s/it]

 68%|██████▊   | 10935/16104 [50:32:45<20:22:00, 14.18s/it]

 68%|██████▊   | 10936/16104 [50:33:03<22:03:46, 15.37s/it]

 68%|██████▊   | 10937/16104 [50:33:22<23:45:54, 16.56s/it]

 68%|██████▊   | 10938/16104 [50:33:42<25:01:33, 17.44s/it]

 68%|██████▊   | 10939/16104 [50:33:59<24:41:17, 17.21s/it]

 68%|██████▊   | 10940/16104 [50:34:11<22:33:37, 15.73s/it]

 68%|██████▊   | 10941/16104 [50:34:27<22:40:00, 15.80s/it]

 68%|██████▊   | 10942/16104 [50:34:38<20:40:34, 14.42s/it]

 68%|██████▊   | 10943/16104 [50:34:49<19:05:52, 13.32s/it]


 68%|██████▊   | 10945/16104 [50:35:24<22:16:23, 15.54s/it]

 68%|██████▊   | 10946/16104 [50:35:38<21:36:25, 15.08s/it]

 68%|██████▊   | 10947/16104 [50:35:51<20:42:35, 14.46s/it]

 68%|██████▊   | 10948/16104 [50:36:03<19:30:53, 13.63s/it]

 68%|██████▊   | 10949/16104 [50:36:17<19:42:06, 13.76s/it]

 68%|██████▊   | 10950/16104 [50:36:29<19:03:16, 13.31s/it]

 68%|██████▊   | 10951/16104 [50:36:43<19:14:41, 13.44s/it]

 68%|██████▊   | 10952/16104 [50:37:01<21:26:32, 14.98s/it]

 68%|██████▊   | 10953/16104 [50:37:17<21:40:10, 15.14s/it]

 68%|██████▊   | 10954/16104 [50:37:29<20:13:20, 14.14s/it]

 68%|██████▊   | 10955/16104 [50:37:40<19:04:13, 13.33s/it]

 68%|██████▊   | 10956/16104 [50:37:51<17:57:07, 12.55s/it]

 68%|██████▊   | 10957/16104 [50:38:10<20:59:03, 14.68s/it]

 68%|██████▊   | 10958/16104 [50:38:27<21:39:04, 15.15s/it]

 68%|██████▊   | 10959/16104 [50:38:39<20:32:21, 14.37s/it]

 68%|██████▊   | 10960/16104 [50:38:54<20:47:10, 14.55s/it]

 68%|██████▊   | 10961/16104 [50:39:11<21:57:43, 15.37s/it]

 68%|██████▊   | 10962/16104 [50:39:29<22:54:13, 16.04s/it]

 68%|██████▊   | 10963/16104 [50:39:50<24:47:25, 17.36s/it]
{'loss': 0.4386, 'learning_rate': 4.886060887284893e-07, 'rewards/chosen': -1.4094719886779785, 'rewards/rejected': -2.4262583255767822, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0167862176895142, 'policy_logps/rejected': -304.1239318847656, 'policy_logps/chosen': -311.9728698730469, 'referece_logps/rejected': -279.8613586425781, 'referece_logps/chosen': -297.8781433105469, 'logits/rejected': -0.341736763715744, 'logits/chosen': -0.3107513189315796, 'epoch': 4.08}


 68%|██████▊   | 10965/16104 [50:40:13<20:55:48, 14.66s/it]

 68%|██████▊   | 10966/16104 [50:40:33<23:02:59, 16.15s/it]

 68%|██████▊   | 10967/16104 [50:40:55<25:33:10, 17.91s/it]

 68%|██████▊   | 10968/16104 [50:41:10<24:09:43, 16.94s/it]

 68%|██████▊   | 10969/16104 [50:41:28<24:55:02, 17.47s/it]

 68%|██████▊   | 10970/16104 [50:41:48<25:59:28, 18.23s/it]

 68%|██████▊   | 10971/16104 [50:42:05<25:16:36, 17.73s/it]

 68%|██████▊   | 10972/16104 [50:42:21<24:37:31, 17.27s/it]
{'loss': 0.3549, 'learning_rate': 4.870513929777598e-07, 'rewards/chosen': -1.2535887956619263, 'rewards/rejected': -2.7623071670532227, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5087182521820068, 'policy_logps/rejected': -302.1245422363281, 'policy_logps/chosen': -369.623291015625, 'referece_logps/rejected': -274.5014343261719, 'referece_logps/chosen': -357.08740234375, 'logits/rejected': -0.3201294243335724, 'logits/chosen': -0.3792971074581146, 'epoch': 4.09}

 68%|██████▊   | 10973/16104 [50:42:43<26:23:47, 18.52s/it]


 68%|██████▊   | 10975/16104 [50:43:24<28:00:17, 19.66s/it]
{'loss': 0.3859, 'learning_rate': 4.865335343037038e-07, 'rewards/chosen': -0.9120067358016968, 'rewards/rejected': -2.309502601623535, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3974958658218384, 'policy_logps/rejected': -302.11810302734375, 'policy_logps/chosen': -293.326416015625, 'referece_logps/rejected': -279.0230712890625, 'referece_logps/chosen': -284.2063293457031, 'logits/rejected': 0.02960904687643051, 'logits/chosen': -0.055668845772743225, 'epoch': 4.09}


 68%|██████▊   | 10977/16104 [50:43:58<26:10:18, 18.38s/it]

 68%|██████▊   | 10978/16104 [50:44:14<25:18:14, 17.77s/it]

 68%|██████▊   | 10979/16104 [50:44:34<26:12:28, 18.41s/it]
{'loss': 0.2948, 'learning_rate': 4.858433468930854e-07, 'rewards/chosen': -0.8877944946289062, 'rewards/rejected': -2.1207165718078613, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2329219579696655, 'policy_logps/rejected': -391.55450439453125, 'policy_logps/chosen': -295.4837951660156, 'referece_logps/rejected': -370.34735107421875, 'referece_logps/chosen': -286.6058654785156, 'logits/rejected': -0.6266309022903442, 'logits/chosen': -0.5606642365455627, 'epoch': 4.09}


 68%|██████▊   | 10981/16104 [50:45:04<23:04:11, 16.21s/it]

 68%|██████▊   | 10982/16104 [50:45:14<20:37:44, 14.50s/it]
{'loss': 0.4202, 'learning_rate': 4.853259246955074e-07, 'rewards/chosen': 0.25240227580070496, 'rewards/rejected': -1.0513010025024414, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3037033081054688, 'policy_logps/rejected': -397.2669677734375, 'policy_logps/chosen': -417.2344970703125, 'referece_logps/rejected': -386.7539978027344, 'referece_logps/chosen': -419.758544921875, 'logits/rejected': 0.2385031133890152, 'logits/chosen': 0.2760036587715149, 'epoch': 4.09}


 68%|██████▊   | 10984/16104 [50:45:40<19:51:14, 13.96s/it]

 68%|██████▊   | 10985/16104 [50:46:00<22:17:30, 15.68s/it]
{'loss': 0.3882, 'learning_rate': 4.848086898732872e-07, 'rewards/chosen': -0.6899632215499878, 'rewards/rejected': -1.8327610492706299, 'rewards/accuracies': 0.75, 'rewards/margins': 1.142797827720642, 'policy_logps/rejected': -458.8183898925781, 'policy_logps/chosen': -569.5996704101562, 'referece_logps/rejected': -440.4907531738281, 'referece_logps/chosen': -562.7000732421875, 'logits/rejected': 0.06861574947834015, 'logits/chosen': -0.024246925488114357, 'epoch': 4.09}


 68%|██████▊   | 10987/16104 [50:46:30<22:25:11, 15.77s/it]
{'loss': 0.4422, 'learning_rate': 4.844639708488894e-07, 'rewards/chosen': 0.0541376993060112, 'rewards/rejected': -1.276650309562683, 'rewards/accuracies': 0.875, 'rewards/margins': 1.330788016319275, 'policy_logps/rejected': -564.6148681640625, 'policy_logps/chosen': -442.83148193359375, 'referece_logps/rejected': -551.848388671875, 'referece_logps/chosen': -443.3728332519531, 'logits/rejected': -0.33621716499328613, 'logits/chosen': -0.29319995641708374, 'epoch': 4.09}


 68%|██████▊   | 10989/16104 [50:46:57<20:52:22, 14.69s/it]

 68%|██████▊   | 10990/16104 [50:47:14<21:42:25, 15.28s/it]

 68%|██████▊   | 10991/16104 [50:47:29<21:45:22, 15.32s/it]
{'loss': 0.3906, 'learning_rate': 4.83774783108084e-07, 'rewards/chosen': -0.45411360263824463, 'rewards/rejected': -2.2813405990600586, 'rewards/accuracies': 0.875, 'rewards/margins': 1.827226996421814, 'policy_logps/rejected': -405.70220947265625, 'policy_logps/chosen': -696.3548583984375, 'referece_logps/rejected': -382.8887939453125, 'referece_logps/chosen': -691.8137817382812, 'logits/rejected': -0.008564941585063934, 'logits/chosen': -0.24116235971450806, 'epoch': 4.1}

 68%|██████▊   | 10992/16104 [50:47:49<23:32:12, 16.58s/it]


 68%|██████▊   | 10994/16104 [50:48:23<24:05:45, 16.98s/it]

 68%|██████▊   | 10995/16104 [50:48:36<22:27:16, 15.82s/it]

 68%|██████▊   | 10996/16104 [50:48:47<20:39:26, 14.56s/it]

 68%|██████▊   | 10997/16104 [50:49:03<20:55:15, 14.75s/it]
{'loss': 0.4911, 'learning_rate': 4.827416281031151e-07, 'rewards/chosen': -0.19168145954608917, 'rewards/rejected': -1.0554524660110474, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8637710213661194, 'policy_logps/rejected': -519.3092651367188, 'policy_logps/chosen': -455.61199951171875, 'referece_logps/rejected': -508.7547607421875, 'referece_logps/chosen': -453.6951904296875, 'logits/rejected': -0.11709269136190414, 'logits/chosen': -0.13755065202713013, 'epoch': 4.1}


 68%|██████▊   | 10999/16104 [50:49:32<20:27:42, 14.43s/it]

 68%|██████▊   | 11000/16104 [50:49:51<22:32:25, 15.90s/it]

 68%|██████▊   | 11001/16104 [50:50:25<29:49:24, 21.04s/it]

 68%|██████▊   | 11002/16104 [50:50:37<26:02:23, 18.37s/it]
{'loss': 0.4527, 'learning_rate': 4.818812409457548e-07, 'rewards/chosen': -0.6227668523788452, 'rewards/rejected': -1.7243785858154297, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1016117334365845, 'policy_logps/rejected': -434.1146545410156, 'policy_logps/chosen': -444.0872802734375, 'referece_logps/rejected': -416.870849609375, 'referece_logps/chosen': -437.8596496582031, 'logits/rejected': -0.3064582049846649, 'logits/chosen': -0.22199319303035736, 'epoch': 4.1}


 68%|██████▊   | 11004/16104 [50:51:13<26:01:06, 18.37s/it]

 68%|██████▊   | 11005/16104 [50:51:24<22:52:05, 16.15s/it]

 68%|██████▊   | 11006/16104 [50:51:44<24:26:03, 17.25s/it]

 68%|██████▊   | 11007/16104 [50:51:55<21:54:13, 15.47s/it]

 68%|██████▊   | 11008/16104 [50:52:06<19:56:36, 14.09s/it]

 68%|██████▊   | 11009/16104 [50:52:22<20:53:10, 14.76s/it]

 68%|██████▊   | 11010/16104 [50:52:36<20:26:36, 14.45s/it]

 68%|██████▊   | 11011/16104 [50:52:49<19:43:55, 13.95s/it]

 68%|██████▊   | 11012/16104 [50:53:11<23:09:21, 16.37s/it]

 68%|██████▊   | 11013/16104 [50:53:31<24:37:07, 17.41s/it]
{'loss': 0.4372, 'learning_rate': 4.799902348006341e-07, 'rewards/chosen': -1.4118927717208862, 'rewards/rejected': -2.2925989627838135, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8807060718536377, 'policy_logps/rejected': -396.5216064453125, 'policy_logps/chosen': -399.832275390625, 'referece_logps/rejected': -373.5956115722656, 'referece_logps/chosen': -385.71337890625, 'logits/rejected': -0.5370246171951294, 'logits/chosen': -0.4685235321521759, 'epoch': 4.1}


 68%|██████▊   | 11015/16104 [50:54:06<25:10:40, 17.81s/it]
{'loss': 0.3517, 'learning_rate': 4.796466886895995e-07, 'rewards/chosen': -0.02178916335105896, 'rewards/rejected': -2.6859686374664307, 'rewards/accuracies': 1.0, 'rewards/margins': 2.664179801940918, 'policy_logps/rejected': -566.6970825195312, 'policy_logps/chosen': -518.906982421875, 'referece_logps/rejected': -539.83740234375, 'referece_logps/chosen': -518.6890869140625, 'logits/rejected': 0.5222303867340088, 'logits/chosen': 0.6023457050323486, 'epoch': 4.1}


 68%|██████▊   | 11017/16104 [50:54:45<26:11:03, 18.53s/it]
{'loss': 0.4486, 'learning_rate': 4.793032267754445e-07, 'rewards/chosen': -1.1670560836791992, 'rewards/rejected': -2.460125207901001, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2930693626403809, 'policy_logps/rejected': -411.2445068359375, 'policy_logps/chosen': -430.2455749511719, 'referece_logps/rejected': -386.64324951171875, 'referece_logps/chosen': -418.5749816894531, 'logits/rejected': -0.4607779085636139, 'logits/chosen': -0.47694599628448486, 'epoch': 4.1}


 68%|██████▊   | 11019/16104 [50:55:12<22:41:07, 16.06s/it]

 68%|██████▊   | 11020/16104 [50:55:26<21:49:51, 15.46s/it]

 68%|██████▊   | 11021/16104 [50:55:46<23:36:43, 16.72s/it]
{'loss': 0.3305, 'learning_rate': 4.78616555760057e-07, 'rewards/chosen': -1.3119059801101685, 'rewards/rejected': -2.7387547492980957, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4268488883972168, 'policy_logps/rejected': -394.9544677734375, 'policy_logps/chosen': -570.9154052734375, 'referece_logps/rejected': -367.5669250488281, 'referece_logps/chosen': -557.7963256835938, 'logits/rejected': 0.38891690969467163, 'logits/chosen': 0.3424380123615265, 'epoch': 4.11}


 68%|██████▊   | 11023/16104 [50:56:23<24:50:29, 17.60s/it]

 68%|██████▊   | 11024/16104 [50:56:37<23:18:01, 16.51s/it]

 68%|██████▊   | 11025/16104 [50:56:54<23:48:01, 16.87s/it]
{'loss': 0.3136, 'learning_rate': 4.779302221989039e-07, 'rewards/chosen': -0.8486281633377075, 'rewards/rejected': -2.6415326595306396, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7929043769836426, 'policy_logps/rejected': -409.24444580078125, 'policy_logps/chosen': -344.4754638671875, 'referece_logps/rejected': -382.8291015625, 'referece_logps/chosen': -335.9891662597656, 'logits/rejected': 0.5590888261795044, 'logits/chosen': 0.5543566942214966, 'epoch': 4.11}


 68%|██████▊   | 11027/16104 [50:57:26<23:09:02, 16.42s/it]

 68%|██████▊   | 11028/16104 [50:57:43<23:25:07, 16.61s/it]

 68%|██████▊   | 11029/16104 [50:57:55<21:31:07, 15.26s/it]
{'loss': 0.577, 'learning_rate': 4.772442265361996e-07, 'rewards/chosen': -0.5776113271713257, 'rewards/rejected': -0.8090283870697021, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2314169704914093, 'policy_logps/rejected': -383.5424499511719, 'policy_logps/chosen': -411.2641296386719, 'referece_logps/rejected': -375.4521789550781, 'referece_logps/chosen': -405.48797607421875, 'logits/rejected': 0.20605237782001495, 'logits/chosen': 0.1544276624917984, 'epoch': 4.11}


 68%|██████▊   | 11031/16104 [50:58:30<23:12:43, 16.47s/it]

 69%|██████▊   | 11032/16104 [50:58:50<24:40:18, 17.51s/it]
{'loss': 0.6099, 'learning_rate': 4.767299518021286e-07, 'rewards/chosen': -0.4590417742729187, 'rewards/rejected': -1.3844009637832642, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9253591299057007, 'policy_logps/rejected': -440.1910705566406, 'policy_logps/chosen': -446.74749755859375, 'referece_logps/rejected': -426.3470458984375, 'referece_logps/chosen': -442.1571044921875, 'logits/rejected': -0.984183132648468, 'logits/chosen': -1.068673849105835, 'epoch': 4.11}


 69%|██████▊   | 11034/16104 [50:59:23<24:06:34, 17.12s/it]

 69%|██████▊   | 11035/16104 [50:59:41<24:27:38, 17.37s/it]
{'loss': 0.4392, 'learning_rate': 4.762158675729175e-07, 'rewards/chosen': -0.8606997132301331, 'rewards/rejected': -2.055600166320801, 'rewards/accuracies': 0.875, 'rewards/margins': 1.194900393486023, 'policy_logps/rejected': -265.7508239746094, 'policy_logps/chosen': -329.3619384765625, 'referece_logps/rejected': -245.19482421875, 'referece_logps/chosen': -320.7549743652344, 'logits/rejected': -0.15118294954299927, 'logits/chosen': -0.060224540531635284, 'epoch': 4.11}


 69%|██████▊   | 11037/16104 [51:00:19<25:56:12, 18.43s/it]

 69%|██████▊   | 11038/16104 [51:00:31<23:02:48, 16.38s/it]

 69%|██████▊   | 11039/16104 [51:00:42<20:50:10, 14.81s/it]
{'loss': 0.4142, 'learning_rate': 4.755307185983393e-07, 'rewards/chosen': 0.02028408646583557, 'rewards/rejected': -1.2163617610931396, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2366458177566528, 'policy_logps/rejected': -378.6618957519531, 'policy_logps/chosen': -557.4794311523438, 'referece_logps/rejected': -366.49822998046875, 'referece_logps/chosen': -557.6823120117188, 'logits/rejected': 0.3046926259994507, 'logits/chosen': 0.18451014161109924, 'epoch': 4.11}

 69%|██████▊   | 11040/16104 [51:00:58<21:19:26, 15.16s/it]


 69%|██████▊   | 11042/16104 [51:01:30<21:33:43, 15.33s/it]

 69%|██████▊   | 11043/16104 [51:01:49<23:01:29, 16.38s/it]

 69%|██████▊   | 11044/16104 [51:02:09<24:20:43, 17.32s/it]
{'loss': 0.4414, 'learning_rate': 4.7467475978570136e-07, 'rewards/chosen': -0.3860428035259247, 'rewards/rejected': -2.4412941932678223, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0552515983581543, 'policy_logps/rejected': -502.2434387207031, 'policy_logps/chosen': -409.53924560546875, 'referece_logps/rejected': -477.83050537109375, 'referece_logps/chosen': -405.6788635253906, 'logits/rejected': -0.699200451374054, 'logits/chosen': -0.37197139859199524, 'epoch': 4.11}

 69%|██████▊   | 11045/16104 [51:02:24<23:23:40, 16.65s/it]


 69%|██████▊   | 11047/16104 [51:02:52<21:37:20, 15.39s/it]

 69%|██████▊   | 11048/16104 [51:03:10<23:04:20, 16.43s/it]

 69%|██████▊   | 11049/16104 [51:03:31<24:51:11, 17.70s/it]

 69%|██████▊   | 11050/16104 [51:03:51<25:42:22, 18.31s/it]

 69%|██████▊   | 11051/16104 [51:04:08<25:04:00, 17.86s/it]

 69%|██████▊   | 11052/16104 [51:04:26<25:08:18, 17.91s/it]

 69%|██████▊   | 11053/16104 [51:04:45<25:54:52, 18.47s/it]

 69%|██████▊   | 11054/16104 [51:04:57<23:08:02, 16.49s/it]

 69%|██████▊   | 11055/16104 [51:05:11<21:58:48, 15.67s/it]

 69%|██████▊   | 11056/16104 [51:05:23<20:23:38, 14.54s/it]

 69%|██████▊   | 11057/16104 [51:05:43<22:42:51, 16.20s/it]
{'loss': 0.3989, 'learning_rate': 4.7245175532188066e-07, 'rewards/chosen': -0.5007848143577576, 'rewards/rejected': -2.403193712234497, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9024090766906738, 'policy_logps/rejected': -402.12103271484375, 'policy_logps/chosen': -389.2487487792969, 'referece_logps/rejected': -378.089111328125, 'referece_logps/chosen': -384.2408752441406, 'logits/rejected': -0.18366718292236328, 'logits/chosen': -0.06862755864858627, 'epoch': 4.12}


 69%|██████▊   | 11059/16104 [51:06:17<23:05:03, 16.47s/it]

 69%|██████▊   | 11060/16104 [51:06:29<21:12:32, 15.14s/it]

 69%|██████▊   | 11061/16104 [51:06:49<23:14:18, 16.59s/it]

 69%|██████▊   | 11062/16104 [51:07:03<21:58:24, 15.69s/it]

 69%|██████▊   | 11063/16104 [51:07:21<23:05:05, 16.49s/it]

 69%|██████▊   | 11064/16104 [51:07:41<24:28:14, 17.48s/it]
{'loss': 0.4136, 'learning_rate': 4.712562457687703e-07, 'rewards/chosen': -0.7381668090820312, 'rewards/rejected': -2.8598897457122803, 'rewards/accuracies': 0.875, 'rewards/margins': 2.12172269821167, 'policy_logps/rejected': -423.5762939453125, 'policy_logps/chosen': -333.39453125, 'referece_logps/rejected': -394.9774475097656, 'referece_logps/chosen': -326.01287841796875, 'logits/rejected': -0.5648879408836365, 'logits/chosen': -0.4185682237148285, 'epoch': 4.12}


 69%|██████▊   | 11066/16104 [51:08:20<26:11:02, 18.71s/it]

 69%|██████▊   | 11067/16104 [51:08:40<26:39:15, 19.05s/it]

 69%|██████▊   | 11068/16104 [51:08:52<23:42:34, 16.95s/it]

 69%|██████▊   | 11069/16104 [51:09:05<22:19:15, 15.96s/it]

 69%|██████▊   | 11070/16104 [51:09:17<20:20:09, 14.54s/it]
{'loss': 0.5701, 'learning_rate': 4.702323573612925e-07, 'rewards/chosen': -0.882084310054779, 'rewards/rejected': -0.910849392414093, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0287650004029274, 'policy_logps/rejected': -455.62103271484375, 'policy_logps/chosen': -352.2005615234375, 'referece_logps/rejected': -446.5124816894531, 'referece_logps/chosen': -343.37969970703125, 'logits/rejected': -0.32305341958999634, 'logits/chosen': -0.3298402428627014, 'epoch': 4.12}


 69%|██████▉   | 11072/16104 [51:09:49<21:06:24, 15.10s/it]

 69%|██████▉   | 11073/16104 [51:10:06<21:37:51, 15.48s/it]

 69%|██████▉   | 11074/16104 [51:10:25<23:27:08, 16.79s/it]
{'loss': 0.3867, 'learning_rate': 4.695501935985263e-07, 'rewards/chosen': -0.1730901598930359, 'rewards/rejected': -1.6683839559555054, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4952938556671143, 'policy_logps/rejected': -462.91900634765625, 'policy_logps/chosen': -443.9779052734375, 'referece_logps/rejected': -446.23516845703125, 'referece_logps/chosen': -442.24700927734375, 'logits/rejected': 0.042182475328445435, 'logits/chosen': 0.18661090731620789, 'epoch': 4.13}

 69%|██████▉   | 11075/16104 [51:10:47<25:17:42, 18.11s/it]


 69%|██████▉   | 11077/16104 [51:11:21<24:57:42, 17.88s/it]

 69%|██████▉   | 11078/16104 [51:11:38<24:29:51, 17.55s/it]
{'loss': 0.3952, 'learning_rate': 4.6886837315800274e-07, 'rewards/chosen': -0.255693256855011, 'rewards/rejected': -1.7774513959884644, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5217583179473877, 'policy_logps/rejected': -496.9276123046875, 'policy_logps/chosen': -451.54266357421875, 'referece_logps/rejected': -479.153076171875, 'referece_logps/chosen': -448.98577880859375, 'logits/rejected': -0.05201335251331329, 'logits/chosen': 0.020509794354438782, 'epoch': 4.13}

 69%|██████▉   | 11079/16104 [51:11:51<22:18:51, 15.99s/it]


 69%|██████▉   | 11081/16104 [51:12:21<21:19:26, 15.28s/it]
{'loss': 0.4921, 'learning_rate': 4.6835723339830566e-07, 'rewards/chosen': -0.25272905826568604, 'rewards/rejected': -1.9945359230041504, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7418068647384644, 'policy_logps/rejected': -524.3554077148438, 'policy_logps/chosen': -460.17626953125, 'referece_logps/rejected': -504.4100646972656, 'referece_logps/chosen': -457.6489562988281, 'logits/rejected': -0.1343529373407364, 'logits/chosen': 0.23805832862854004, 'epoch': 4.13}

 69%|██████▉   | 11082/16104 [51:12:32<19:30:48, 13.99s/it]

 69%|██████▉   | 11083/16104 [51:12:44<18:38:43, 13.37s/it]


 69%|██████▉   | 11085/16104 [51:13:14<19:52:58, 14.26s/it]
{'loss': 0.4316, 'learning_rate': 4.6767601483343575e-07, 'rewards/chosen': -0.19977720081806183, 'rewards/rejected': -1.8986787796020508, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6989015340805054, 'policy_logps/rejected': -281.5320129394531, 'policy_logps/chosen': -651.9503173828125, 'referece_logps/rejected': -262.5451965332031, 'referece_logps/chosen': -649.9524536132812, 'logits/rejected': -0.42818546295166016, 'logits/chosen': -0.7373907566070557, 'epoch': 4.13}

 69%|██████▉   | 11086/16104 [51:13:30<20:53:29, 14.99s/it]


 69%|██████▉   | 11088/16104 [51:14:10<24:03:51, 17.27s/it]
{'loss': 0.4057, 'learning_rate': 4.6716532698694734e-07, 'rewards/chosen': -0.4567699432373047, 'rewards/rejected': -1.8523893356323242, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3956191539764404, 'policy_logps/rejected': -427.043701171875, 'policy_logps/chosen': -430.7840270996094, 'referece_logps/rejected': -408.5198059082031, 'referece_logps/chosen': -426.21636962890625, 'logits/rejected': 0.16529811918735504, 'logits/chosen': 0.10354028642177582, 'epoch': 4.13}

 69%|██████▉   | 11089/16104 [51:14:29<24:49:17, 17.82s/it]


 69%|██████▉   | 11091/16104 [51:15:02<23:28:58, 16.86s/it]

 69%|██████▉   | 11092/16104 [51:15:22<24:34:09, 17.65s/it]

 69%|██████▉   | 11093/16104 [51:15:36<22:57:39, 16.50s/it]
{'loss': 0.3579, 'learning_rate': 4.6631461175017086e-07, 'rewards/chosen': -0.8884237408638, 'rewards/rejected': -2.2814760208129883, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3930522203445435, 'policy_logps/rejected': -381.9150390625, 'policy_logps/chosen': -332.5174560546875, 'referece_logps/rejected': -359.10028076171875, 'referece_logps/chosen': -323.63323974609375, 'logits/rejected': -0.4683689475059509, 'logits/chosen': -0.3600786328315735, 'epoch': 4.13}


 69%|██████▉   | 11095/16104 [51:16:12<23:53:36, 17.17s/it]
{'loss': 0.3993, 'learning_rate': 4.659744767269721e-07, 'rewards/chosen': -0.5841255187988281, 'rewards/rejected': -2.8098134994506836, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2256882190704346, 'policy_logps/rejected': -336.5988464355469, 'policy_logps/chosen': -318.2830505371094, 'referece_logps/rejected': -308.5007019042969, 'referece_logps/chosen': -312.44183349609375, 'logits/rejected': -0.9551283121109009, 'logits/chosen': -0.860655665397644, 'epoch': 4.13}


 69%|██████▉   | 11097/16104 [51:16:38<21:02:32, 15.13s/it]
{'loss': 0.4157, 'learning_rate': 4.656344281129143e-07, 'rewards/chosen': -0.3018488883972168, 'rewards/rejected': -1.9597198963165283, 'rewards/accuracies': 0.75, 'rewards/margins': 1.657870888710022, 'policy_logps/rejected': -379.35296630859375, 'policy_logps/chosen': -287.8315124511719, 'referece_logps/rejected': -359.75579833984375, 'referece_logps/chosen': -284.81304931640625, 'logits/rejected': -0.11372919380664825, 'logits/chosen': -0.08354389667510986, 'epoch': 4.13}

 69%|██████▉   | 11098/16104 [51:16:51<19:55:50, 14.33s/it]


 69%|██████▉   | 11100/16104 [51:17:30<23:31:54, 16.93s/it]
{'loss': 0.3641, 'learning_rate': 4.6512451732932403e-07, 'rewards/chosen': -0.9550268054008484, 'rewards/rejected': -2.4232451915740967, 'rewards/accuracies': 1.0, 'rewards/margins': 1.468218207359314, 'policy_logps/rejected': -400.17645263671875, 'policy_logps/chosen': -483.3258972167969, 'referece_logps/rejected': -375.94403076171875, 'referece_logps/chosen': -473.7756652832031, 'logits/rejected': 0.013685673475265503, 'logits/chosen': -0.06728172302246094, 'epoch': 4.14}


 69%|██████▉   | 11102/16104 [51:17:56<21:06:49, 15.20s/it]
{'loss': 0.5015, 'learning_rate': 4.6478468497880984e-07, 'rewards/chosen': -0.47490519285202026, 'rewards/rejected': -1.2013509273529053, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7264457941055298, 'policy_logps/rejected': -277.3008117675781, 'policy_logps/chosen': -415.9593505859375, 'referece_logps/rejected': -265.28729248046875, 'referece_logps/chosen': -411.2103271484375, 'logits/rejected': 0.6022359132766724, 'logits/chosen': 0.592862606048584, 'epoch': 4.14}


 69%|██████▉   | 11104/16104 [51:18:31<22:45:32, 16.39s/it]

 69%|██████▉   | 11105/16104 [51:18:52<24:46:08, 17.84s/it]
{'loss': 0.4624, 'learning_rate': 4.642750988483258e-07, 'rewards/chosen': -0.119212806224823, 'rewards/rejected': -1.4038591384887695, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2846463918685913, 'policy_logps/rejected': -311.51678466796875, 'policy_logps/chosen': -300.7485656738281, 'referece_logps/rejected': -297.47821044921875, 'referece_logps/chosen': -299.5564270019531, 'logits/rejected': -0.07031171023845673, 'logits/chosen': -0.10731975734233856, 'epoch': 4.14}

 69%|██████▉   | 11106/16104 [51:19:11<25:14:53, 18.19s/it]

 69%|██████▉   | 11107/16104 [51:19:27<24:28:36, 17.63s/it]


 69%|██████▉   | 11109/16104 [51:19:54<21:14:40, 15.31s/it]
{'loss': 0.3826, 'learning_rate': 4.6359595410079e-07, 'rewards/chosen': -0.032760635018348694, 'rewards/rejected': -1.8603668212890625, 'rewards/accuracies': 0.875, 'rewards/margins': 1.827606201171875, 'policy_logps/rejected': -388.1696472167969, 'policy_logps/chosen': -360.63983154296875, 'referece_logps/rejected': -369.56597900390625, 'referece_logps/chosen': -360.312255859375, 'logits/rejected': -0.696648359298706, 'logits/chosen': -0.7129197716712952, 'epoch': 4.14}

 69%|██████▉   | 11110/16104 [51:20:11<21:50:35, 15.75s/it]


 69%|██████▉   | 11112/16104 [51:20:42<22:05:22, 15.93s/it]

 69%|██████▉   | 11113/16104 [51:21:04<24:35:09, 17.73s/it]
{'loss': 0.412, 'learning_rate': 4.6291715652925056e-07, 'rewards/chosen': -0.6657165884971619, 'rewards/rejected': -2.317674398422241, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6519579887390137, 'policy_logps/rejected': -432.9527282714844, 'policy_logps/chosen': -463.1360778808594, 'referece_logps/rejected': -409.7760009765625, 'referece_logps/chosen': -456.47894287109375, 'logits/rejected': 0.34006407856941223, 'logits/chosen': 0.3669944703578949, 'epoch': 4.14}

 69%|██████▉   | 11114/16104 [51:21:17<22:49:28, 16.47s/it]

 69%|██████▉   | 11115/16104 [51:21:36<23:35:42, 17.03s/it]

 69%|██████▉   | 11116/16104 [51:21:53<23:46:16, 17.16s/it]

 69%|██████▉   | 11117/16104 [51:22:16<25:53:24, 18.69s/it]

 69%|██████▉   | 11118/16104 [51:22:36<26:31:47, 19.16s/it]

 69%|██████▉   | 11119/16104 [51:22:52<25:16:12, 18.25s/it]


 69%|██████▉   | 11121/16104 [51:23:23<22:55:22, 16.56s/it]

 69%|██████▉   | 11122/16104 [51:23:42<24:06:39, 17.42s/it]
{'loss': 0.4106, 'learning_rate': 4.6139113363078783e-07, 'rewards/chosen': -0.7091629505157471, 'rewards/rejected': -2.0418312549591064, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3326685428619385, 'policy_logps/rejected': -381.9344482421875, 'policy_logps/chosen': -439.921142578125, 'referece_logps/rejected': -361.51611328125, 'referece_logps/chosen': -432.8294982910156, 'logits/rejected': -0.5746212005615234, 'logits/chosen': -0.5056731700897217, 'epoch': 4.14}

 69%|██████▉   | 11123/16104 [51:24:00<24:07:06, 17.43s/it]

 69%|██████▉   | 11124/16104 [51:24:13<22:31:40, 16.29s/it]

 69%|██████▉   | 11125/16104 [51:24:32<23:31:15, 17.01s/it]

 69%|██████▉   | 11126/16104 [51:24:50<24:00:03, 17.36s/it]


 69%|██████▉   | 11128/16104 [51:25:29<25:22:44, 18.36s/it]
{'loss': 0.3384, 'learning_rate': 4.603747651691746e-07, 'rewards/chosen': -0.10506933927536011, 'rewards/rejected': -2.117436647415161, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0123672485351562, 'policy_logps/rejected': -570.44970703125, 'policy_logps/chosen': -532.0953979492188, 'referece_logps/rejected': -549.275390625, 'referece_logps/chosen': -531.044677734375, 'logits/rejected': -0.5417286157608032, 'logits/chosen': -0.5592373609542847, 'epoch': 4.15}

 69%|██████▉   | 11129/16104 [51:25:44<23:49:52, 17.24s/it]


 69%|██████▉   | 11131/16104 [51:26:19<24:11:18, 17.51s/it]

 69%|██████▉   | 11132/16104 [51:26:39<24:56:28, 18.06s/it]

 69%|██████▉   | 11133/16104 [51:26:57<24:49:39, 17.98s/it]

 69%|██████▉   | 11134/16104 [51:27:12<23:33:57, 17.07s/it]

 69%|██████▉   | 11135/16104 [51:27:29<23:47:58, 17.24s/it]

 69%|██████▉   | 11136/16104 [51:27:44<22:41:08, 16.44s/it]

 69%|██████▉   | 11137/16104 [51:28:03<23:58:46, 17.38s/it]

 69%|██████▉   | 11138/16104 [51:28:23<24:56:17, 18.08s/it]

 69%|██████▉   | 11139/16104 [51:28:44<25:58:16, 18.83s/it]

 69%|██████▉   | 11140/16104 [51:29:00<24:51:41, 18.03s/it]

 69%|██████▉   | 11141/16104 [51:29:17<24:28:11, 17.75s/it]
{'loss': 0.4794, 'learning_rate': 4.5817533133230547e-07, 'rewards/chosen': -0.5666475892066956, 'rewards/rejected': -1.9152557849884033, 'rewards/accuracies': 0.75, 'rewards/margins': 1.348608136177063, 'policy_logps/rejected': -632.9447631835938, 'policy_logps/chosen': -640.429443359375, 'referece_logps/rejected': -613.7921752929688, 'referece_logps/chosen': -634.7630004882812, 'logits/rejected': -0.35945603251457214, 'logits/chosen': -0.2860848009586334, 'epoch': 4.15}


 69%|██████▉   | 11143/16104 [51:29:47<22:56:22, 16.65s/it]
{'loss': 0.4028, 'learning_rate': 4.578372852862243e-07, 'rewards/chosen': -0.413107305765152, 'rewards/rejected': -1.3245214223861694, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9114141464233398, 'policy_logps/rejected': -432.30450439453125, 'policy_logps/chosen': -336.3465576171875, 'referece_logps/rejected': -419.05926513671875, 'referece_logps/chosen': -332.2154541015625, 'logits/rejected': -0.6956603527069092, 'logits/chosen': -0.6574220061302185, 'epoch': 4.15}


 69%|██████▉   | 11145/16104 [51:30:15<21:06:49, 15.33s/it]

 69%|██████▉   | 11146/16104 [51:30:34<22:23:46, 16.26s/it]

 69%|██████▉   | 11147/16104 [51:30:51<22:43:39, 16.51s/it]

 69%|██████▉   | 11148/16104 [51:31:06<22:07:56, 16.08s/it]
{'loss': 0.3745, 'learning_rate': 4.569925540909968e-07, 'rewards/chosen': -0.3927566707134247, 'rewards/rejected': -1.925399661064148, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5326429605484009, 'policy_logps/rejected': -323.48529052734375, 'policy_logps/chosen': -255.8289337158203, 'referece_logps/rejected': -304.2312927246094, 'referece_logps/chosen': -251.90135192871094, 'logits/rejected': -0.5513607263565063, 'logits/chosen': -0.6360595226287842, 'epoch': 4.15}


 69%|██████▉   | 11150/16104 [51:31:41<22:56:16, 16.67s/it]

 69%|██████▉   | 11151/16104 [51:31:59<23:24:07, 17.01s/it]

 69%|██████▉   | 11152/16104 [51:32:17<23:45:44, 17.27s/it]
{'loss': 0.3688, 'learning_rate': 4.5631716447495925e-07, 'rewards/chosen': -1.0466039180755615, 'rewards/rejected': -1.494717001914978, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4481130838394165, 'policy_logps/rejected': -287.3787841796875, 'policy_logps/chosen': -390.7958984375, 'referece_logps/rejected': -272.43157958984375, 'referece_logps/chosen': -380.329833984375, 'logits/rejected': 0.10986264050006866, 'logits/chosen': 0.22174948453903198, 'epoch': 4.15}


 69%|██████▉   | 11154/16104 [51:32:45<21:29:58, 15.64s/it]
{'loss': 0.5743, 'learning_rate': 4.5597960159726767e-07, 'rewards/chosen': -0.3257594704627991, 'rewards/rejected': -0.8849536180496216, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5591942071914673, 'policy_logps/rejected': -544.3954467773438, 'policy_logps/chosen': -361.5030212402344, 'referece_logps/rejected': -535.5458984375, 'referece_logps/chosen': -358.24542236328125, 'logits/rejected': -0.17136240005493164, 'logits/chosen': 0.18650400638580322, 'epoch': 4.16}


 69%|██████▉   | 11156/16104 [51:33:07<18:07:59, 13.19s/it]

 69%|██████▉   | 11157/16104 [51:33:24<19:33:35, 14.23s/it]

 69%|██████▉   | 11158/16104 [51:33:43<21:47:16, 15.86s/it]

 69%|██████▉   | 11159/16104 [51:34:02<22:45:40, 16.57s/it]

 69%|██████▉   | 11160/16104 [51:34:21<23:58:23, 17.46s/it]

 69%|██████▉   | 11161/16104 [51:34:34<22:02:49, 16.06s/it]
{'loss': 0.3903, 'learning_rate': 4.5479882509142667e-07, 'rewards/chosen': -1.0478732585906982, 'rewards/rejected': -3.0968475341796875, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0489742755889893, 'policy_logps/rejected': -500.8741455078125, 'policy_logps/chosen': -443.5974426269531, 'referece_logps/rejected': -469.9056396484375, 'referece_logps/chosen': -433.11871337890625, 'logits/rejected': 0.3393923044204712, 'logits/chosen': 0.3123159110546112, 'epoch': 4.16}


 69%|██████▉   | 11163/16104 [51:35:08<22:40:16, 16.52s/it]

 69%|██████▉   | 11164/16104 [51:35:26<23:11:52, 16.91s/it]

 69%|██████▉   | 11165/16104 [51:35:45<24:13:38, 17.66s/it]

 69%|██████▉   | 11166/16104 [51:36:03<24:30:07, 17.86s/it]
{'loss': 0.4953, 'learning_rate': 4.5395607479586117e-07, 'rewards/chosen': -0.9680854082107544, 'rewards/rejected': -1.7126553058624268, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7445697784423828, 'policy_logps/rejected': -410.3809509277344, 'policy_logps/chosen': -346.2349853515625, 'referece_logps/rejected': -393.25439453125, 'referece_logps/chosen': -336.55413818359375, 'logits/rejected': 0.02902013063430786, 'logits/chosen': -0.03253105282783508, 'epoch': 4.16}


 69%|██████▉   | 11168/16104 [51:36:35<23:05:29, 16.84s/it]

 69%|██████▉   | 11169/16104 [51:36:46<20:45:00, 15.14s/it]

 69%|██████▉   | 11170/16104 [51:37:05<22:25:05, 16.36s/it]

 69%|██████▉   | 11171/16104 [51:37:25<23:51:02, 17.41s/it]

 69%|██████▉   | 11172/16104 [51:37:42<23:29:16, 17.14s/it]

 69%|██████▉   | 11173/16104 [51:38:02<24:45:43, 18.08s/it]

 69%|██████▉   | 11174/16104 [51:38:22<25:22:31, 18.53s/it]

 69%|██████▉   | 11175/16104 [51:38:34<22:47:48, 16.65s/it]
{'loss': 0.4146, 'learning_rate': 4.524405164085228e-07, 'rewards/chosen': -0.6683062314987183, 'rewards/rejected': -3.0419273376464844, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3736209869384766, 'policy_logps/rejected': -363.03045654296875, 'policy_logps/chosen': -404.54803466796875, 'referece_logps/rejected': -332.6111755371094, 'referece_logps/chosen': -397.8649597167969, 'logits/rejected': 0.1948060691356659, 'logits/chosen': 0.26972663402557373, 'epoch': 4.16}

 69%|██████▉   | 11176/16104 [51:38:51<22:56:47, 16.76s/it]


 69%|██████▉   | 11178/16104 [51:39:24<22:53:48, 16.73s/it]

 69%|██████▉   | 11179/16104 [51:39:44<24:07:07, 17.63s/it]
{'loss': 0.4226, 'learning_rate': 4.517675105016292e-07, 'rewards/chosen': -0.1247495710849762, 'rewards/rejected': -1.654883861541748, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5301343202590942, 'policy_logps/rejected': -651.95849609375, 'policy_logps/chosen': -489.0432434082031, 'referece_logps/rejected': -635.40966796875, 'referece_logps/chosen': -487.7957458496094, 'logits/rejected': -0.13091905415058136, 'logits/chosen': 0.13964734971523285, 'epoch': 4.17}

 69%|██████▉   | 11180/16104 [51:39:55<21:17:19, 15.56s/it]


 69%|██████▉   | 11182/16104 [51:40:16<17:57:13, 13.13s/it]
{'loss': 0.4258, 'learning_rate': 4.512629889059507e-07, 'rewards/chosen': 0.026557907462120056, 'rewards/rejected': -2.2655253410339355, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2920830249786377, 'policy_logps/rejected': -467.018798828125, 'policy_logps/chosen': -516.5385131835938, 'referece_logps/rejected': -444.3634948730469, 'referece_logps/chosen': -516.8040771484375, 'logits/rejected': -0.09324070066213608, 'logits/chosen': -0.392616331577301, 'epoch': 4.17}

 69%|██████▉   | 11183/16104 [51:40:37<21:04:06, 15.41s/it]


 69%|██████▉   | 11185/16104 [51:41:09<21:47:24, 15.95s/it]
{'loss': 0.3827, 'learning_rate': 4.5075866708678877e-07, 'rewards/chosen': -0.24829882383346558, 'rewards/rejected': -1.4939748048782349, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2456759214401245, 'policy_logps/rejected': -378.6435241699219, 'policy_logps/chosen': -395.3848571777344, 'referece_logps/rejected': -363.70379638671875, 'referece_logps/chosen': -392.9018859863281, 'logits/rejected': -0.7252012491226196, 'logits/chosen': -0.6483619809150696, 'epoch': 4.17}


 69%|██████▉   | 11187/16104 [51:41:30<18:14:32, 13.36s/it]
{'loss': 0.518, 'learning_rate': 4.5042256361830733e-07, 'rewards/chosen': -0.7554928064346313, 'rewards/rejected': -1.079745888710022, 'rewards/accuracies': 0.375, 'rewards/margins': 0.32425305247306824, 'policy_logps/rejected': -418.530517578125, 'policy_logps/chosen': -381.5577087402344, 'referece_logps/rejected': -407.7330322265625, 'referece_logps/chosen': -374.00274658203125, 'logits/rejected': -0.27510836720466614, 'logits/chosen': -0.22723689675331116, 'epoch': 4.17}

 69%|██████▉   | 11188/16104 [51:41:43<17:55:21, 13.12s/it]


 69%|██████▉   | 11190/16104 [51:42:22<22:42:51, 16.64s/it]

 69%|██████▉   | 11191/16104 [51:42:42<23:55:57, 17.54s/it]

 69%|██████▉   | 11192/16104 [51:42:58<23:28:01, 17.20s/it]
{'loss': 0.3403, 'learning_rate': 4.495826941153198e-07, 'rewards/chosen': -0.7185477614402771, 'rewards/rejected': -1.7839431762695312, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0653953552246094, 'policy_logps/rejected': -274.5747375488281, 'policy_logps/chosen': -299.1268615722656, 'referece_logps/rejected': -256.73529052734375, 'referece_logps/chosen': -291.9414367675781, 'logits/rejected': -0.7188476324081421, 'logits/chosen': -0.5594367980957031, 'epoch': 4.17}

 70%|██████▉   | 11193/16104 [51:43:15<23:21:01, 17.12s/it]

 70%|██████▉   | 11194/16104 [51:43:35<24:22:47, 17.88s/it]

 70%|██████▉   | 11195/16104 [51:43:57<26:06:28, 19.15s/it]

 70%|██████▉   | 11196/16104 [51:44:17<26:32:03, 19.46s/it]


 70%|██████▉   | 11198/16104 [51:44:45<22:16:34, 16.35s/it]
{'loss': 0.4003, 'learning_rate': 4.485755855433322e-07, 'rewards/chosen': -0.09334592521190643, 'rewards/rejected': -1.11874520778656, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0253993272781372, 'policy_logps/rejected': -528.5289306640625, 'policy_logps/chosen': -407.6808166503906, 'referece_logps/rejected': -517.3414306640625, 'referece_logps/chosen': -406.74737548828125, 'logits/rejected': 0.44001221656799316, 'logits/chosen': 0.45670679211616516, 'epoch': 4.17}

 70%|██████▉   | 11199/16104 [51:45:06<24:16:41, 17.82s/it]


 70%|██████▉   | 11201/16104 [51:45:37<22:11:54, 16.30s/it]

 70%|██████▉   | 11202/16104 [51:45:59<24:32:28, 18.02s/it]

 70%|██████▉   | 11203/16104 [51:46:10<21:55:48, 16.11s/it]

 70%|██████▉   | 11204/16104 [51:46:27<22:03:44, 16.21s/it]

 70%|██████▉   | 11205/16104 [51:46:43<22:01:36, 16.19s/it]
{'loss': 0.4246, 'learning_rate': 4.4740164057309727e-07, 'rewards/chosen': -0.08730458468198776, 'rewards/rejected': -2.6982617378234863, 'rewards/accuracies': 0.875, 'rewards/margins': 2.610957145690918, 'policy_logps/rejected': -411.9304504394531, 'policy_logps/chosen': -631.1392211914062, 'referece_logps/rejected': -384.9478454589844, 'referece_logps/chosen': -630.26611328125, 'logits/rejected': 0.3439442813396454, 'logits/chosen': 0.03674224019050598, 'epoch': 4.17}


 70%|██████▉   | 11207/16104 [51:47:25<25:15:27, 18.57s/it]

 70%|██████▉   | 11208/16104 [51:47:45<25:46:12, 18.95s/it]

 70%|██████▉   | 11209/16104 [51:47:57<22:52:54, 16.83s/it]

 70%|██████▉   | 11210/16104 [51:48:10<21:33:33, 15.86s/it]

 70%|██████▉   | 11211/16104 [51:48:26<21:41:55, 15.96s/it]

 70%|██████▉   | 11212/16104 [51:48:40<20:54:26, 15.39s/it]
{'loss': 0.358, 'learning_rate': 4.462287909285829e-07, 'rewards/chosen': -0.5105916261672974, 'rewards/rejected': -2.020301342010498, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5097095966339111, 'policy_logps/rejected': -335.6444396972656, 'policy_logps/chosen': -479.3951416015625, 'referece_logps/rejected': -315.44140625, 'referece_logps/chosen': -474.2892150878906, 'logits/rejected': -0.47447651624679565, 'logits/chosen': -0.46252161264419556, 'epoch': 4.18}


 70%|██████▉   | 11214/16104 [51:49:17<22:46:20, 16.76s/it]

 70%|██████▉   | 11215/16104 [51:49:37<24:08:43, 17.78s/it]
{'loss': 0.3634, 'learning_rate': 4.457264769609065e-07, 'rewards/chosen': -1.2903518676757812, 'rewards/rejected': -2.9059157371520996, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6155638694763184, 'policy_logps/rejected': -406.5385437011719, 'policy_logps/chosen': -355.83837890625, 'referece_logps/rejected': -377.4794006347656, 'referece_logps/chosen': -342.9348449707031, 'logits/rejected': -0.23711270093917847, 'logits/chosen': -0.23962098360061646, 'epoch': 4.18}

 70%|██████▉   | 11216/16104 [51:49:56<24:40:30, 18.17s/it]

 70%|██████▉   | 11217/16104 [51:50:10<22:58:24, 16.92s/it]


 70%|██████▉   | 11219/16104 [51:50:46<23:46:50, 17.53s/it]

 70%|██████▉   | 11220/16104 [51:51:04<23:56:11, 17.64s/it]
{'loss': 0.3175, 'learning_rate': 4.4488973553210483e-07, 'rewards/chosen': -0.018170446157455444, 'rewards/rejected': -2.774811267852783, 'rewards/accuracies': 0.875, 'rewards/margins': 2.756640911102295, 'policy_logps/rejected': -359.28466796875, 'policy_logps/chosen': -419.55712890625, 'referece_logps/rejected': -331.5365295410156, 'referece_logps/chosen': -419.37542724609375, 'logits/rejected': -0.46608108282089233, 'logits/chosen': -0.10899516940116882, 'epoch': 4.18}

 70%|██████▉   | 11221/16104 [51:51:24<24:35:07, 18.13s/it]


 70%|██████▉   | 11223/16104 [51:52:01<24:46:12, 18.27s/it]
{'loss': 0.3685, 'learning_rate': 4.443879600830791e-07, 'rewards/chosen': -0.42821750044822693, 'rewards/rejected': -1.1857249736785889, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7575074434280396, 'policy_logps/rejected': -382.73193359375, 'policy_logps/chosen': -326.7784118652344, 'referece_logps/rejected': -370.87469482421875, 'referece_logps/chosen': -322.4962463378906, 'logits/rejected': -0.6028500199317932, 'logits/chosen': -0.43093419075012207, 'epoch': 4.18}


 70%|██████▉   | 11225/16104 [51:52:29<21:56:21, 16.19s/it]
{'loss': 0.4534, 'learning_rate': 4.440535554832778e-07, 'rewards/chosen': -0.48408931493759155, 'rewards/rejected': -1.43886137008667, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9547721147537231, 'policy_logps/rejected': -474.7289123535156, 'policy_logps/chosen': -389.4980773925781, 'referece_logps/rejected': -460.34027099609375, 'referece_logps/chosen': -384.6571960449219, 'logits/rejected': 0.005945973098278046, 'logits/chosen': 0.08187388628721237, 'epoch': 4.18}

 70%|██████▉   | 11226/16104 [51:52:46<22:33:11, 16.64s/it]

 70%|██████▉   | 11227/16104 [51:53:06<23:43:27, 17.51s/it]

 70%|██████▉   | 11228/16104 [51:53:22<23:01:07, 16.99s/it]

 70%|██████▉   | 11229/16104 [51:53:44<25:06:11, 18.54s/it]

 70%|██████▉   | 11230/16104 [51:54:00<24:12:20, 17.88s/it]

 70%|██████▉   | 11231/16104 [51:54:21<25:17:02, 18.68s/it]

 70%|██████▉   | 11232/16104 [51:54:40<25:27:32, 18.81s/it]


 70%|██████▉   | 11234/16104 [51:55:13<24:28:53, 18.10s/it]
{'loss': 0.379, 'learning_rate': 4.425498487717935e-07, 'rewards/chosen': -0.6598323583602905, 'rewards/rejected': -1.5909287929534912, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9310962557792664, 'policy_logps/rejected': -393.9434814453125, 'policy_logps/chosen': -318.1456298828125, 'referece_logps/rejected': -378.0342102050781, 'referece_logps/chosen': -311.54730224609375, 'logits/rejected': -0.3812571167945862, 'logits/chosen': -0.19334541261196136, 'epoch': 4.19}


 70%|██████▉   | 11236/16104 [51:55:39<20:47:06, 15.37s/it]
{'loss': 0.3321, 'learning_rate': 4.42215939599763e-07, 'rewards/chosen': 0.6187469959259033, 'rewards/rejected': -1.3491898775100708, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9679367542266846, 'policy_logps/rejected': -510.5860290527344, 'policy_logps/chosen': -415.8013000488281, 'referece_logps/rejected': -497.09417724609375, 'referece_logps/chosen': -421.98876953125, 'logits/rejected': 0.22640551626682281, 'logits/chosen': 0.29825538396835327, 'epoch': 4.19}


 70%|██████▉   | 11238/16104 [51:56:13<21:33:23, 15.95s/it]
{'loss': 0.43, 'learning_rate': 4.4188212068117357e-07, 'rewards/chosen': -0.66839200258255, 'rewards/rejected': -1.420117974281311, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7517257332801819, 'policy_logps/rejected': -521.3700561523438, 'policy_logps/chosen': -512.6357421875, 'referece_logps/rejected': -507.16888427734375, 'referece_logps/chosen': -505.95184326171875, 'logits/rejected': -0.5236697196960449, 'logits/chosen': -0.41609546542167664, 'epoch': 4.19}

 70%|██████▉   | 11239/16104 [51:56:32<22:50:43, 16.91s/it]


 70%|██████▉   | 11241/16104 [51:57:09<23:51:58, 17.67s/it]
{'loss': 0.3825, 'learning_rate': 4.4138156164664496e-07, 'rewards/chosen': -0.0702209621667862, 'rewards/rejected': -1.6228141784667969, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5525932312011719, 'policy_logps/rejected': -343.1483154296875, 'policy_logps/chosen': -459.6865234375, 'referece_logps/rejected': -326.9201965332031, 'referece_logps/chosen': -458.98431396484375, 'logits/rejected': -0.5193533301353455, 'logits/chosen': -0.6994348168373108, 'epoch': 4.19}

 70%|██████▉   | 11242/16104 [51:57:30<25:08:04, 18.61s/it]

 70%|██████▉   | 11243/16104 [51:57:44<23:14:03, 17.21s/it]


 70%|██████▉   | 11245/16104 [51:58:23<25:05:34, 18.59s/it]
{'loss': 0.3411, 'learning_rate': 4.407144659916634e-07, 'rewards/chosen': -0.6516035199165344, 'rewards/rejected': -2.8368282318115234, 'rewards/accuracies': 0.625, 'rewards/margins': 2.185224771499634, 'policy_logps/rejected': -499.2271728515625, 'policy_logps/chosen': -624.8845825195312, 'referece_logps/rejected': -470.8589172363281, 'referece_logps/chosen': -618.3685913085938, 'logits/rejected': 0.35007619857788086, 'logits/chosen': 0.2594110667705536, 'epoch': 4.19}


 70%|██████▉   | 11247/16104 [51:58:57<24:25:35, 18.10s/it]
{'loss': 0.3823, 'learning_rate': 4.403810538817768e-07, 'rewards/chosen': -0.15238744020462036, 'rewards/rejected': -2.0297625064849854, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8773750066757202, 'policy_logps/rejected': -254.8263702392578, 'policy_logps/chosen': -298.6663513183594, 'referece_logps/rejected': -234.52874755859375, 'referece_logps/chosen': -297.1424560546875, 'logits/rejected': -0.2849498391151428, 'logits/chosen': -0.17198403179645538, 'epoch': 4.19}


 70%|██████▉   | 11249/16104 [51:59:29<23:12:34, 17.21s/it]
{'loss': 0.4215, 'learning_rate': 4.40047732322229e-07, 'rewards/chosen': -0.6079913973808289, 'rewards/rejected': -1.9316049814224243, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3236135244369507, 'policy_logps/rejected': -345.03839111328125, 'policy_logps/chosen': -390.26898193359375, 'referece_logps/rejected': -325.72235107421875, 'referece_logps/chosen': -384.18902587890625, 'logits/rejected': -0.147238627076149, 'logits/chosen': -0.1274813711643219, 'epoch': 4.19}

 70%|██████▉   | 11250/16104 [51:59:44<22:14:02, 16.49s/it]


 70%|██████▉   | 11252/16104 [52:00:24<24:30:37, 18.19s/it]

 70%|██████▉   | 11253/16104 [52:00:43<25:02:02, 18.58s/it]

 70%|██████▉   | 11254/16104 [52:01:03<25:40:55, 19.06s/it]

 70%|██████▉   | 11255/16104 [52:01:23<25:57:20, 19.27s/it]
{'loss': 0.4293, 'learning_rate': 4.390483114848861e-07, 'rewards/chosen': -0.18377076089382172, 'rewards/rejected': -1.667881727218628, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4841110706329346, 'policy_logps/rejected': -396.76068115234375, 'policy_logps/chosen': -478.661376953125, 'referece_logps/rejected': -380.08184814453125, 'referece_logps/chosen': -476.8236083984375, 'logits/rejected': 0.0027667656540870667, 'logits/chosen': -0.06877681612968445, 'epoch': 4.19}

 70%|██████▉   | 11256/16104 [52:01:34<22:42:12, 16.86s/it]


 70%|██████▉   | 11258/16104 [52:02:12<23:29:00, 17.45s/it]
{'loss': 0.4463, 'learning_rate': 4.3854890731046825e-07, 'rewards/chosen': -0.9704381823539734, 'rewards/rejected': -3.1373445987701416, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1669068336486816, 'policy_logps/rejected': -353.014404296875, 'policy_logps/chosen': -285.7538757324219, 'referece_logps/rejected': -321.64093017578125, 'referece_logps/chosen': -276.0495300292969, 'logits/rejected': 0.007869284600019455, 'logits/chosen': -0.019228897988796234, 'epoch': 4.19}


 70%|██████▉   | 11260/16104 [52:02:48<24:05:33, 17.91s/it]
{'loss': 0.4368, 'learning_rate': 4.3821608474145897e-07, 'rewards/chosen': -0.19866979122161865, 'rewards/rejected': -1.6201374530792236, 'rewards/accuracies': 0.875, 'rewards/margins': 1.421467661857605, 'policy_logps/rejected': -578.8162841796875, 'policy_logps/chosen': -530.7216186523438, 'referece_logps/rejected': -562.6149291992188, 'referece_logps/chosen': -528.7349853515625, 'logits/rejected': -0.2528308928012848, 'logits/chosen': -0.19092491269111633, 'epoch': 4.2}

 70%|██████▉   | 11261/16104 [52:03:07<24:36:15, 18.29s/it]

 70%|██████▉   | 11262/16104 [52:03:23<23:33:48, 17.52s/it]

 70%|██████▉   | 11263/16104 [52:03:42<24:28:10, 18.20s/it]

 70%|██████▉   | 11264/16104 [52:04:01<24:27:43, 18.19s/it]

 70%|██████▉   | 11265/16104 [52:04:13<22:01:44, 16.39s/it]


 70%|██████▉   | 11267/16104 [52:04:43<21:28:19, 15.98s/it]
{'loss': 0.4599, 'learning_rate': 4.370519219457979e-07, 'rewards/chosen': -0.13633954524993896, 'rewards/rejected': -0.7853401303291321, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6490006446838379, 'policy_logps/rejected': -481.1917419433594, 'policy_logps/chosen': -465.80712890625, 'referece_logps/rejected': -473.33831787109375, 'referece_logps/chosen': -464.4437561035156, 'logits/rejected': -0.008396953344345093, 'logits/chosen': 0.11690536141395569, 'epoch': 4.2}


 70%|██████▉   | 11269/16104 [52:05:18<22:29:54, 16.75s/it]

 70%|██████▉   | 11270/16104 [52:05:38<23:47:58, 17.72s/it]

 70%|██████▉   | 11271/16104 [52:05:52<22:27:01, 16.72s/it]
{'loss': 0.4649, 'learning_rate': 4.36387186904163e-07, 'rewards/chosen': 0.17947271466255188, 'rewards/rejected': -0.48008501529693604, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6595577001571655, 'policy_logps/rejected': -633.4304809570312, 'policy_logps/chosen': -532.0431518554688, 'referece_logps/rejected': -628.6296997070312, 'referece_logps/chosen': -533.837890625, 'logits/rejected': -0.6006899476051331, 'logits/chosen': -0.5564646124839783, 'epoch': 4.2}

 70%|██████▉   | 11272/16104 [52:06:09<22:33:21, 16.80s/it]

 70%|███████   | 11273/16104 [52:06:29<23:41:27, 17.65s/it]

 70%|███████   | 11274/16104 [52:06:45<23:12:55, 17.30s/it]

 70%|███████   | 11275/16104 [52:07:05<24:06:44, 17.98s/it]

 70%|███████   | 11276/16104 [52:07:25<25:02:39, 18.67s/it]

 70%|███████   | 11277/16104 [52:07:39<22:59:27, 17.15s/it]

 70%|███████   | 11278/16104 [52:07:59<24:17:45, 18.12s/it]


 70%|███████   | 11280/16104 [52:08:30<21:49:50, 16.29s/it]
{'loss': 0.4234, 'learning_rate': 4.348928674653998e-07, 'rewards/chosen': -0.025505438446998596, 'rewards/rejected': -1.5283643007278442, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5028588771820068, 'policy_logps/rejected': -495.22137451171875, 'policy_logps/chosen': -534.5784912109375, 'referece_logps/rejected': -479.937744140625, 'referece_logps/chosen': -534.3234252929688, 'logits/rejected': -0.06826610863208771, 'logits/chosen': -0.3053407669067383, 'epoch': 4.2}


 70%|███████   | 11282/16104 [52:09:06<23:19:16, 17.41s/it]
{'loss': 0.3071, 'learning_rate': 4.345610477621813e-07, 'rewards/chosen': -0.6163622140884399, 'rewards/rejected': -1.8103868961334229, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1940245628356934, 'policy_logps/rejected': -427.79913330078125, 'policy_logps/chosen': -541.96240234375, 'referece_logps/rejected': -409.6952209472656, 'referece_logps/chosen': -535.7987670898438, 'logits/rejected': -0.33860260248184204, 'logits/chosen': -0.47632354497909546, 'epoch': 4.2}

 70%|███████   | 11283/16104 [52:09:21<22:09:25, 16.55s/it]


 70%|███████   | 11285/16104 [52:10:02<25:00:35, 18.68s/it]
{'loss': 0.3284, 'learning_rate': 4.3406348977173623e-07, 'rewards/chosen': -0.7271360158920288, 'rewards/rejected': -2.3510384559631348, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6239025592803955, 'policy_logps/rejected': -457.63714599609375, 'policy_logps/chosen': -441.4689636230469, 'referece_logps/rejected': -434.126708984375, 'referece_logps/chosen': -434.19757080078125, 'logits/rejected': -0.042326606810092926, 'logits/chosen': 0.02675052173435688, 'epoch': 4.2}


 70%|███████   | 11287/16104 [52:10:40<25:12:41, 18.84s/it]
{'loss': 0.4444, 'learning_rate': 4.337318988993003e-07, 'rewards/chosen': -0.5303964614868164, 'rewards/rejected': -1.6100735664367676, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0796771049499512, 'policy_logps/rejected': -360.0620422363281, 'policy_logps/chosen': -323.1483154296875, 'referece_logps/rejected': -343.9613037109375, 'referece_logps/chosen': -317.8443603515625, 'logits/rejected': -0.41909259557724, 'logits/chosen': -0.46509772539138794, 'epoch': 4.21}

 70%|███████   | 11288/16104 [52:11:02<26:16:38, 19.64s/it]


 70%|███████   | 11290/16104 [52:11:36<24:33:06, 18.36s/it]
{'loss': 0.397, 'learning_rate': 4.3323468440657075e-07, 'rewards/chosen': 0.4725942611694336, 'rewards/rejected': -2.3648223876953125, 'rewards/accuracies': 0.875, 'rewards/margins': 2.837416648864746, 'policy_logps/rejected': -535.4774169921875, 'policy_logps/chosen': -521.127685546875, 'referece_logps/rejected': -511.8292236328125, 'referece_logps/chosen': -525.8536376953125, 'logits/rejected': -0.318758487701416, 'logits/chosen': -0.1940450668334961, 'epoch': 4.21}

 70%|███████   | 11291/16104 [52:11:57<25:27:10, 19.04s/it]

 70%|███████   | 11292/16104 [52:12:10<23:03:19, 17.25s/it]

 70%|███████   | 11293/16104 [52:12:30<24:09:41, 18.08s/it]

 70%|███████   | 11294/16104 [52:12:47<23:39:28, 17.71s/it]

 70%|███████   | 11295/16104 [52:13:07<24:49:35, 18.58s/it]

 70%|███████   | 11296/16104 [52:13:28<25:24:43, 19.03s/it]

 70%|███████   | 11297/16104 [52:13:47<25:28:22, 19.08s/it]

 70%|███████   | 11298/16104 [52:14:08<26:11:00, 19.61s/it]

 70%|███████   | 11299/16104 [52:14:28<26:26:49, 19.81s/it]

 70%|███████   | 11300/16104 [52:14:47<26:21:07, 19.75s/it]

 70%|███████   | 11301/16104 [52:14:59<23:11:14, 17.38s/it]

 70%|███████   | 11302/16104 [52:15:16<23:02:51, 17.28s/it]


 70%|███████   | 11304/16104 [52:15:39<18:51:21, 14.14s/it]
{'loss': 0.5407, 'learning_rate': 4.3091708130396365e-07, 'rewards/chosen': -0.7113916277885437, 'rewards/rejected': -1.5413498878479004, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8299582004547119, 'policy_logps/rejected': -308.4814147949219, 'policy_logps/chosen': -374.87139892578125, 'referece_logps/rejected': -293.0679016113281, 'referece_logps/chosen': -367.7574768066406, 'logits/rejected': -0.09056174755096436, 'logits/chosen': -0.020524397492408752, 'epoch': 4.21}


 70%|███████   | 11306/16104 [52:16:05<18:11:16, 13.65s/it]
{'loss': 0.3881, 'learning_rate': 4.3058636304478934e-07, 'rewards/chosen': -0.5258247256278992, 'rewards/rejected': -1.4584310054779053, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9326062798500061, 'policy_logps/rejected': -346.794921875, 'policy_logps/chosen': -399.63690185546875, 'referece_logps/rejected': -332.2106018066406, 'referece_logps/chosen': -394.378662109375, 'logits/rejected': 0.11479157209396362, 'logits/chosen': 0.08807305246591568, 'epoch': 4.21}

 70%|███████   | 11307/16104 [52:16:22<19:28:41, 14.62s/it]

 70%|███████   | 11308/16104 [52:16:34<18:28:36, 13.87s/it]

 70%|███████   | 11309/16104 [52:16:50<19:20:19, 14.52s/it]

 70%|███████   | 11310/16104 [52:17:11<22:02:58, 16.56s/it]

 70%|███████   | 11311/16104 [52:17:25<21:09:03, 15.89s/it]

 70%|███████   | 11312/16104 [52:17:44<22:01:51, 16.55s/it]


 70%|███████   | 11314/16104 [52:18:17<21:25:10, 16.10s/it]

 70%|███████   | 11315/16104 [52:18:35<22:07:48, 16.64s/it]
{'loss': 0.4517, 'learning_rate': 4.2909927182371895e-07, 'rewards/chosen': -0.6678954362869263, 'rewards/rejected': -2.309943437576294, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6420480012893677, 'policy_logps/rejected': -391.24078369140625, 'policy_logps/chosen': -452.61962890625, 'referece_logps/rejected': -368.14129638671875, 'referece_logps/chosen': -445.940673828125, 'logits/rejected': -0.057906657457351685, 'logits/chosen': -0.10927297174930573, 'epoch': 4.22}

 70%|███████   | 11316/16104 [52:18:50<21:39:59, 16.29s/it]

 70%|███████   | 11317/16104 [52:19:05<21:10:31, 15.92s/it]

 70%|███████   | 11318/16104 [52:19:24<22:07:42, 16.64s/it]

 70%|███████   | 11319/16104 [52:19:36<20:27:58, 15.40s/it]

 70%|███████   | 11320/16104 [52:19:57<22:28:49, 16.92s/it]

 70%|███████   | 11321/16104 [52:20:13<22:04:08, 16.61s/it]

 70%|███████   | 11322/16104 [52:20:32<23:22:21, 17.60s/it]


 70%|███████   | 11324/16104 [52:21:07<23:24:11, 17.63s/it]
{'loss': 0.3938, 'learning_rate': 4.2761405121235506e-07, 'rewards/chosen': -0.7843021750450134, 'rewards/rejected': -2.493757724761963, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7094554901123047, 'policy_logps/rejected': -302.50421142578125, 'policy_logps/chosen': -331.52618408203125, 'referece_logps/rejected': -277.5666198730469, 'referece_logps/chosen': -323.68316650390625, 'logits/rejected': -0.41760870814323425, 'logits/chosen': -0.28703466057777405, 'epoch': 4.22}

 70%|███████   | 11325/16104 [52:21:27<24:11:22, 18.22s/it]

 70%|███████   | 11326/16104 [52:21:43<23:37:52, 17.81s/it]

 70%|███████   | 11327/16104 [52:22:01<23:39:43, 17.83s/it]

 70%|███████   | 11328/16104 [52:22:13<21:19:30, 16.07s/it]

 70%|███████   | 11329/16104 [52:22:26<20:10:24, 15.21s/it]

 70%|███████   | 11330/16104 [52:22:44<20:58:52, 15.82s/it]

 70%|███████   | 11331/16104 [52:23:04<22:39:03, 17.08s/it]

 70%|███████   | 11332/16104 [52:23:20<22:11:53, 16.75s/it]

 70%|███████   | 11333/16104 [52:23:38<22:50:21, 17.23s/it]

 70%|███████   | 11334/16104 [52:23:57<23:30:23, 17.74s/it]

 70%|███████   | 11335/16104 [52:24:09<21:24:11, 16.16s/it]

 70%|███████   | 11336/16104 [52:24:25<21:00:42, 15.86s/it]

 70%|███████   | 11337/16104 [52:24:40<20:55:06, 15.80s/it]

 70%|███████   | 11338/16104 [52:24:55<20:22:19, 15.39s/it]

 70%|███████   | 11339/16104 [52:25:14<22:00:24, 16.63s/it]

 70%|███████   | 11340/16104 [52:25:28<20:54:10, 15.80s/it]


 70%|███████   | 11342/16104 [52:26:08<23:40:55, 17.90s/it]

 70%|███████   | 11343/16104 [52:26:24<22:42:55, 17.18s/it]

 70%|███████   | 11344/16104 [52:26:41<22:43:54, 17.19s/it]

 70%|███████   | 11345/16104 [52:27:00<23:20:15, 17.65s/it]

 70%|███████   | 11346/16104 [52:27:20<24:29:04, 18.53s/it]

 70%|███████   | 11347/16104 [52:27:40<24:59:20, 18.91s/it]

 70%|███████   | 11348/16104 [52:27:55<23:23:14, 17.70s/it]

 70%|███████   | 11349/16104 [52:28:17<25:00:25, 18.93s/it]

 70%|███████   | 11350/16104 [52:28:37<25:42:55, 19.47s/it]

 70%|███████   | 11351/16104 [52:28:55<25:07:23, 19.03s/it]

 70%|███████   | 11352/16104 [52:29:15<25:19:26, 19.18s/it]

 70%|███████   | 11353/16104 [52:29:35<25:27:24, 19.29s/it]

 71%|███████   | 11354/16104 [52:29:51<24:20:17, 18.45s/it]

 71%|███████   | 11355/16104 [52:30:10<24:35:35, 18.64s/it]

 71%|███████   | 11356/16104 [52:30:29<24:43:18, 18.74s/it]

 71%|███████   | 11357/16104 [52:30:48<24:53:18, 18.87s/it]

 71%|███████   | 11358/16104 [52:31:00<22:10:41, 16.82s/it]

 71%|███████   | 11359/16104 [52:31:20<23:28:58, 17.82s/it]

 71%|███████   | 11360/16104 [52:31:36<22:33:23, 17.12s/it]

 71%|███████   | 11361/16104 [52:31:49<21:07:13, 16.03s/it]

 71%|███████   | 11362/16104 [52:32:05<20:45:25, 15.76s/it]

 71%|███████   | 11363/16104 [52:32:15<18:45:25, 14.24s/it]

 71%|███████   | 11364/16104 [52:32:28<18:01:17, 13.69s/it]

 71%|███████   | 11365/16104 [52:32:44<19:00:38, 14.44s/it]

 71%|███████   | 11366/16104 [52:32:55<17:35:04, 13.36s/it]

 71%|███████   | 11367/16104 [52:33:07<16:59:11, 12.91s/it]

 71%|███████   | 11368/16104 [52:33:25<19:13:35, 14.61s/it]

 71%|███████   | 11369/16104 [52:33:36<17:56:34, 13.64s/it]

 71%|███████   | 11370/16104 [52:33:51<18:16:34, 13.90s/it]

 71%|███████   | 11371/16104 [52:34:04<18:05:31, 13.76s/it]

 71%|███████   | 11372/16104 [52:34:18<18:03:43, 13.74s/it]

 71%|███████   | 11373/16104 [52:34:35<19:13:29, 14.63s/it]

 71%|███████   | 11374/16104 [52:34:52<20:08:56, 15.34s/it]

 71%|███████   | 11375/16104 [52:35:03<18:41:58, 14.24s/it]

 71%|███████   | 11376/16104 [52:35:20<19:34:52, 14.91s/it]

 71%|███████   | 11377/16104 [52:35:42<22:24:56, 17.07s/it]

 71%|███████   | 11378/16104 [52:35:53<20:10:33, 15.37s/it]

 71%|███████   | 11379/16104 [52:36:11<20:51:09, 15.89s/it]

 71%|███████   | 11380/16104 [52:36:27<20:53:17, 15.92s/it]

 71%|███████   | 11381/16104 [52:36:45<21:43:00, 16.55s/it]

 71%|███████   | 11382/16104 [52:37:03<22:17:58, 17.00s/it]

 71%|███████   | 11383/16104 [52:37:24<24:06:40, 18.39s/it]

 71%|███████   | 11384/16104 [52:37:45<24:53:44, 18.99s/it]

 71%|███████   | 11385/16104 [52:38:00<23:20:52, 17.81s/it]

 71%|███████   | 11386/16104 [52:38:19<24:02:12, 18.34s/it]

 71%|███████   | 11387/16104 [52:38:31<21:26:46, 16.37s/it]

 71%|███████   | 11388/16104 [52:38:47<21:23:38, 16.33s/it]

 71%|███████   | 11389/16104 [52:38:59<19:36:48, 14.98s/it]

 71%|███████   | 11390/16104 [52:39:17<20:47:52, 15.88s/it]

 71%|███████   | 11391/16104 [52:39:37<22:18:19, 17.04s/it]

 71%|███████   | 11392/16104 [52:39:49<20:31:22, 15.68s/it]

 71%|███████   | 11393/16104 [52:40:06<20:51:04, 15.93s/it]

 71%|███████   | 11394/16104 [52:40:22<20:50:18, 15.93s/it]

 71%|███████   | 11395/16104 [52:40:35<19:55:45, 15.24s/it]
{'loss': 0.4709, 'learning_rate': 4.1596345885240004e-07, 'rewards/chosen': -0.1619560271501541, 'rewards/rejected': -1.183510422706604, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0215542316436768, 'policy_logps/rejected': -411.2829284667969, 'policy_logps/chosen': -577.5196533203125, 'referece_logps/rejected': -399.44781494140625, 'referece_logps/chosen': -575.9000854492188, 'logits/rejected': 0.11555447429418564, 'logits/chosen': 0.07711067795753479, 'epoch': 4.25}


 71%|███████   | 11397/16104 [52:41:14<22:37:29, 17.30s/it]
{'loss': 0.3651, 'learning_rate': 4.156369866837532e-07, 'rewards/chosen': -0.4243936836719513, 'rewards/rejected': -1.8734030723571777, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4490092992782593, 'policy_logps/rejected': -311.918701171875, 'policy_logps/chosen': -418.2181701660156, 'referece_logps/rejected': -293.1846618652344, 'referece_logps/chosen': -413.9742431640625, 'logits/rejected': -0.160974383354187, 'logits/chosen': -0.051876336336135864, 'epoch': 4.25}


 71%|███████   | 11399/16104 [52:41:48<22:17:08, 17.05s/it]

 71%|███████   | 11400/16104 [52:42:05<22:20:11, 17.09s/it]

 71%|███████   | 11401/16104 [52:42:22<22:30:08, 17.22s/it]

 71%|███████   | 11402/16104 [52:42:41<23:10:23, 17.74s/it]

 71%|███████   | 11403/16104 [52:42:59<23:17:01, 17.83s/it]

 71%|███████   | 11404/16104 [52:43:17<23:26:49, 17.96s/it]

 71%|███████   | 11405/16104 [52:43:28<20:35:40, 15.78s/it]

 71%|███████   | 11406/16104 [52:43:45<21:02:00, 16.12s/it]
{'loss': 0.3767, 'learning_rate': 4.141690327942103e-07, 'rewards/chosen': -0.20208381116390228, 'rewards/rejected': -1.0595543384552002, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8574705719947815, 'policy_logps/rejected': -484.1119079589844, 'policy_logps/chosen': -361.14801025390625, 'referece_logps/rejected': -473.516357421875, 'referece_logps/chosen': -359.1271667480469, 'logits/rejected': -0.6587836742401123, 'logits/chosen': -0.44333383440971375, 'epoch': 4.25}


 71%|███████   | 11408/16104 [52:44:09<18:15:44, 14.00s/it]
{'loss': 0.4521, 'learning_rate': 4.1384308132645064e-07, 'rewards/chosen': -0.421591579914093, 'rewards/rejected': -1.5691676139831543, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1475759744644165, 'policy_logps/rejected': -529.0082397460938, 'policy_logps/chosen': -505.8565368652344, 'referece_logps/rejected': -513.3165283203125, 'referece_logps/chosen': -501.640625, 'logits/rejected': -0.7666972875595093, 'logits/chosen': -0.6767692565917969, 'epoch': 4.25}


 71%|███████   | 11410/16104 [52:44:44<20:42:24, 15.88s/it]

 71%|███████   | 11411/16104 [52:44:57<19:35:36, 15.03s/it]

 71%|███████   | 11412/16104 [52:45:14<20:17:23, 15.57s/it]

 71%|███████   | 11413/16104 [52:45:29<20:14:29, 15.53s/it]

 71%|███████   | 11414/16104 [52:45:48<21:27:48, 16.48s/it]

 71%|███████   | 11415/16104 [52:46:08<22:42:06, 17.43s/it]

 71%|███████   | 11416/16104 [52:46:19<20:08:51, 15.47s/it]

 71%|███████   | 11417/16104 [52:46:31<18:45:27, 14.41s/it]

 71%|███████   | 11418/16104 [52:46:50<20:46:02, 15.95s/it]

 71%|███████   | 11419/16104 [52:47:12<22:57:54, 17.65s/it]

 71%|███████   | 11420/16104 [52:47:32<23:56:21, 18.40s/it]

 71%|███████   | 11421/16104 [52:47:51<24:21:02, 18.72s/it]

 71%|███████   | 11422/16104 [52:48:11<24:48:33, 19.08s/it]

 71%|███████   | 11423/16104 [52:48:31<24:58:51, 19.21s/it]

 71%|███████   | 11424/16104 [52:48:52<25:44:56, 19.81s/it]

 71%|███████   | 11425/16104 [52:49:03<22:30:10, 17.31s/it]

 71%|███████   | 11426/16104 [52:49:26<24:31:42, 18.88s/it]

 71%|███████   | 11427/16104 [52:49:40<22:41:28, 17.47s/it]

 71%|███████   | 11428/16104 [52:50:00<23:28:03, 18.07s/it]

 71%|███████   | 11429/16104 [52:50:20<24:09:31, 18.60s/it]

 71%|███████   | 11430/16104 [52:50:32<21:39:41, 16.68s/it]

 71%|███████   | 11431/16104 [52:50:48<21:30:47, 16.57s/it]

 71%|███████   | 11432/16104 [52:51:03<20:47:37, 16.02s/it]

 71%|███████   | 11433/16104 [52:51:23<22:21:25, 17.23s/it]

 71%|███████   | 11434/16104 [52:51:44<24:00:52, 18.51s/it]

 71%|███████   | 11435/16104 [52:51:59<22:40:31, 17.48s/it]

 71%|███████   | 11436/16104 [52:52:19<23:28:28, 18.10s/it]

 71%|███████   | 11437/16104 [52:52:41<24:58:40, 19.27s/it]

 71%|███████   | 11438/16104 [52:52:56<23:29:20, 18.12s/it]

 71%|███████   | 11439/16104 [52:53:09<21:31:36, 16.61s/it]

 71%|███████   | 11440/16104 [52:53:27<21:55:15, 16.92s/it]

 71%|███████   | 11441/16104 [52:53:48<23:30:45, 18.15s/it]

 71%|███████   | 11442/16104 [52:54:08<24:08:22, 18.64s/it]

 71%|███████   | 11443/16104 [52:54:29<24:57:40, 19.28s/it]

 71%|███████   | 11444/16104 [52:54:48<25:09:00, 19.43s/it]
{'loss': 0.3445, 'learning_rate': 4.07992224326272e-07, 'rewards/chosen': -0.2427908033132553, 'rewards/rejected': -2.2000248432159424, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9572340250015259, 'policy_logps/rejected': -245.2119598388672, 'policy_logps/chosen': -429.6252136230469, 'referece_logps/rejected': -223.21170043945312, 'referece_logps/chosen': -427.19732666015625, 'logits/rejected': 0.3736923933029175, 'logits/chosen': 0.18932825326919556, 'epoch': 4.26}


 71%|███████   | 11446/16104 [52:55:14<20:30:33, 15.85s/it]

 71%|███████   | 11447/16104 [52:55:25<18:32:31, 14.33s/it]
{'loss': 0.4548, 'learning_rate': 4.0750604962912593e-07, 'rewards/chosen': 0.214911088347435, 'rewards/rejected': -1.177878975868225, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3927899599075317, 'policy_logps/rejected': -485.5947265625, 'policy_logps/chosen': -344.1471862792969, 'referece_logps/rejected': -473.8159484863281, 'referece_logps/chosen': -346.2962951660156, 'logits/rejected': -0.23207244277000427, 'logits/chosen': -0.08858086168766022, 'epoch': 4.26}


 71%|███████   | 11449/16104 [52:56:06<22:31:59, 17.43s/it]

 71%|███████   | 11450/16104 [52:56:27<24:00:03, 18.57s/it]

 71%|███████   | 11451/16104 [52:56:47<24:34:28, 19.01s/it]
{'loss': 0.3416, 'learning_rate': 4.0685815227429664e-07, 'rewards/chosen': -0.8277946710586548, 'rewards/rejected': -2.6504383087158203, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8226436376571655, 'policy_logps/rejected': -440.20953369140625, 'policy_logps/chosen': -566.2703247070312, 'referece_logps/rejected': -413.7051696777344, 'referece_logps/chosen': -557.992431640625, 'logits/rejected': -0.7445642948150635, 'logits/chosen': -0.6462628841400146, 'epoch': 4.27}


 71%|███████   | 11453/16104 [52:57:21<23:09:26, 17.92s/it]
{'loss': 0.3279, 'learning_rate': 4.06534347532553e-07, 'rewards/chosen': -0.6385078430175781, 'rewards/rejected': -3.478330612182617, 'rewards/accuracies': 1.0, 'rewards/margins': 2.839822769165039, 'policy_logps/rejected': -421.1372985839844, 'policy_logps/chosen': -448.4748840332031, 'referece_logps/rejected': -386.35400390625, 'referece_logps/chosen': -442.08978271484375, 'logits/rejected': 0.8885473608970642, 'logits/chosen': 0.8414470553398132, 'epoch': 4.27}


 71%|███████   | 11455/16104 [52:57:53<22:10:49, 17.18s/it]

 71%|███████   | 11456/16104 [52:58:12<22:54:28, 17.74s/it]
{'loss': 0.2762, 'learning_rate': 4.060488204868894e-07, 'rewards/chosen': -0.24294129014015198, 'rewards/rejected': -1.7585458755493164, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5156044960021973, 'policy_logps/rejected': -371.74749755859375, 'policy_logps/chosen': -454.5672607421875, 'referece_logps/rejected': -354.16204833984375, 'referece_logps/chosen': -452.1378479003906, 'logits/rejected': 0.24569301307201385, 'logits/chosen': 0.22174526751041412, 'epoch': 4.27}

 71%|███████   | 11457/16104 [52:58:30<22:52:00, 17.71s/it]


 71%|███████   | 11459/16104 [52:59:07<23:24:17, 18.14s/it]

 71%|███████   | 11460/16104 [52:59:21<21:52:35, 16.96s/it]

 71%|███████   | 11461/16104 [52:59:33<19:51:13, 15.39s/it]

 71%|███████   | 11462/16104 [52:59:52<21:30:49, 16.68s/it]

 71%|███████   | 11463/16104 [53:00:03<19:09:19, 14.86s/it]
{'loss': 0.4442, 'learning_rate': 4.049167652758346e-07, 'rewards/chosen': 0.15869960188865662, 'rewards/rejected': -1.0908923149108887, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2495919466018677, 'policy_logps/rejected': -606.3388671875, 'policy_logps/chosen': -575.5770263671875, 'referece_logps/rejected': -595.4299926757812, 'referece_logps/chosen': -577.1640014648438, 'logits/rejected': -0.20695680379867554, 'logits/chosen': 0.12108060717582703, 'epoch': 4.27}


 71%|███████   | 11465/16104 [53:00:32<19:31:36, 15.15s/it]

 71%|███████   | 11466/16104 [53:00:53<21:29:06, 16.68s/it]

 71%|███████   | 11467/16104 [53:01:12<22:36:21, 17.55s/it]

 71%|███████   | 11468/16104 [53:01:33<23:53:01, 18.55s/it]

 71%|███████   | 11469/16104 [53:01:53<24:25:11, 18.97s/it]

 71%|███████   | 11470/16104 [53:02:06<22:07:53, 17.19s/it]

 71%|███████   | 11471/16104 [53:02:21<21:10:07, 16.45s/it]

 71%|███████   | 11472/16104 [53:02:32<18:59:34, 14.76s/it]

 71%|███████   | 11473/16104 [53:02:44<18:10:06, 14.12s/it]

 71%|███████   | 11474/16104 [53:03:04<20:27:53, 15.91s/it]

 71%|███████▏  | 11475/16104 [53:03:21<20:49:03, 16.19s/it]

 71%|███████▏  | 11476/16104 [53:03:41<22:12:10, 17.27s/it]

 71%|███████▏  | 11477/16104 [53:03:57<21:35:55, 16.80s/it]
{'loss': 0.2855, 'learning_rate': 4.0265619570498213e-07, 'rewards/chosen': -0.8178199529647827, 'rewards/rejected': -2.5640578269958496, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7462376356124878, 'policy_logps/rejected': -364.7437438964844, 'policy_logps/chosen': -481.95208740234375, 'referece_logps/rejected': -339.1031799316406, 'referece_logps/chosen': -473.77386474609375, 'logits/rejected': -0.592252790927887, 'logits/chosen': -0.33532389998435974, 'epoch': 4.28}


 71%|███████▏  | 11479/16104 [53:04:31<22:04:53, 17.19s/it]

 71%|███████▏  | 11480/16104 [53:04:41<19:32:32, 15.21s/it]
{'loss': 0.3202, 'learning_rate': 4.021724035017685e-07, 'rewards/chosen': -0.541869580745697, 'rewards/rejected': -1.8857792615890503, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3439098596572876, 'policy_logps/rejected': -260.0982360839844, 'policy_logps/chosen': -302.8177490234375, 'referece_logps/rejected': -241.24044799804688, 'referece_logps/chosen': -297.3990783691406, 'logits/rejected': -0.3660908043384552, 'logits/chosen': -0.34132546186447144, 'epoch': 4.28}

 71%|███████▏  | 11481/16104 [53:04:54<18:41:52, 14.56s/it]


 71%|███████▏  | 11483/16104 [53:05:21<18:03:24, 14.07s/it]

 71%|███████▏  | 11484/16104 [53:05:37<18:53:57, 14.73s/it]

 71%|███████▏  | 11485/16104 [53:05:54<19:32:31, 15.23s/it]
{'loss': 0.4675, 'learning_rate': 4.0136656691387114e-07, 'rewards/chosen': -0.10847511142492294, 'rewards/rejected': -0.7984718084335327, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6899967789649963, 'policy_logps/rejected': -614.9573974609375, 'policy_logps/chosen': -671.0952758789062, 'referece_logps/rejected': -606.97265625, 'referece_logps/chosen': -670.0104370117188, 'logits/rejected': 0.7748868465423584, 'logits/chosen': 0.6033037304878235, 'epoch': 4.28}


 71%|███████▏  | 11487/16104 [53:06:27<20:53:26, 16.29s/it]
{'loss': 0.515, 'learning_rate': 4.010444017436174e-07, 'rewards/chosen': 0.15517541766166687, 'rewards/rejected': -0.9694159626960754, 'rewards/accuracies': 0.75, 'rewards/margins': 1.12459135055542, 'policy_logps/rejected': -475.0539855957031, 'policy_logps/chosen': -557.8416137695312, 'referece_logps/rejected': -465.3598327636719, 'referece_logps/chosen': -559.3933715820312, 'logits/rejected': 0.4904663562774658, 'logits/chosen': 0.4857849180698395, 'epoch': 4.28}


 71%|███████▏  | 11489/16104 [53:06:51<17:47:30, 13.88s/it]

 71%|███████▏  | 11490/16104 [53:07:02<16:39:42, 13.00s/it]

 71%|███████▏  | 11491/16104 [53:07:13<16:02:07, 12.51s/it]

 71%|███████▏  | 11492/16104 [53:07:24<15:18:30, 11.95s/it]

 71%|███████▏  | 11493/16104 [53:07:43<18:17:51, 14.29s/it]
{'loss': 0.3605, 'learning_rate': 4.0007848793303155e-07, 'rewards/chosen': -0.14872878789901733, 'rewards/rejected': -2.6342854499816895, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4855566024780273, 'policy_logps/rejected': -502.3831787109375, 'policy_logps/chosen': -415.04974365234375, 'referece_logps/rejected': -476.04034423828125, 'referece_logps/chosen': -413.56243896484375, 'logits/rejected': -0.45817291736602783, 'logits/chosen': -0.30971771478652954, 'epoch': 4.28}


 71%|███████▏  | 11495/16104 [53:08:08<17:01:13, 13.29s/it]

 71%|███████▏  | 11496/16104 [53:08:25<18:43:52, 14.63s/it]

 71%|███████▏  | 11497/16104 [53:08:42<19:25:37, 15.18s/it]

 71%|███████▏  | 11498/16104 [53:09:00<20:27:01, 15.98s/it]

 71%|███████▏  | 11499/16104 [53:09:21<22:26:36, 17.55s/it]

 71%|███████▏  | 11500/16104 [53:09:42<23:42:26, 18.54s/it]

 71%|███████▏  | 11501/16104 [53:10:11<27:47:11, 21.73s/it]

 71%|███████▏  | 11502/16104 [53:10:28<25:54:55, 20.27s/it]

 71%|███████▏  | 11503/16104 [53:10:46<25:07:05, 19.65s/it]
{'loss': 0.3497, 'learning_rate': 3.984705737075377e-07, 'rewards/chosen': -0.5616468191146851, 'rewards/rejected': -2.5864760875701904, 'rewards/accuracies': 0.75, 'rewards/margins': 2.024829149246216, 'policy_logps/rejected': -694.732421875, 'policy_logps/chosen': -600.2590942382812, 'referece_logps/rejected': -668.86767578125, 'referece_logps/chosen': -594.6426391601562, 'logits/rejected': -0.5874648094177246, 'logits/chosen': -0.4890933632850647, 'epoch': 4.29}

 71%|███████▏  | 11504/16104 [53:11:02<23:48:36, 18.63s/it]


 71%|███████▏  | 11506/16104 [53:11:38<23:17:41, 18.24s/it]

 71%|███████▏  | 11507/16104 [53:11:58<23:46:13, 18.62s/it]
{'loss': 0.372, 'learning_rate': 3.978280889754867e-07, 'rewards/chosen': -0.6498650312423706, 'rewards/rejected': -3.405609607696533, 'rewards/accuracies': 0.875, 'rewards/margins': 2.755744457244873, 'policy_logps/rejected': -465.3458251953125, 'policy_logps/chosen': -476.42083740234375, 'referece_logps/rejected': -431.28973388671875, 'referece_logps/chosen': -469.92218017578125, 'logits/rejected': -0.441100537776947, 'logits/chosen': -0.3085392117500305, 'epoch': 4.29}

 71%|███████▏  | 11508/16104 [53:12:13<22:25:43, 17.57s/it]

 71%|███████▏  | 11509/16104 [53:12:32<23:11:32, 18.17s/it]


 71%|███████▏  | 11511/16104 [53:12:56<18:47:35, 14.73s/it]
{'loss': 0.3874, 'learning_rate': 3.9718599398627007e-07, 'rewards/chosen': -0.07915906608104706, 'rewards/rejected': -1.4666576385498047, 'rewards/accuracies': 0.875, 'rewards/margins': 1.387498378753662, 'policy_logps/rejected': -409.31103515625, 'policy_logps/chosen': -354.3291015625, 'referece_logps/rejected': -394.64447021484375, 'referece_logps/chosen': -353.5375061035156, 'logits/rejected': -0.9483996629714966, 'logits/chosen': -0.698754608631134, 'epoch': 4.29}


 71%|███████▏  | 11513/16104 [53:13:34<21:43:41, 17.04s/it]

 71%|███████▏  | 11514/16104 [53:13:56<23:23:06, 18.34s/it]

 72%|███████▏  | 11515/16104 [53:14:12<22:31:23, 17.67s/it]
{'loss': 0.3976, 'learning_rate': 3.965442891554697e-07, 'rewards/chosen': -0.13301660120487213, 'rewards/rejected': -2.258619785308838, 'rewards/accuracies': 0.75, 'rewards/margins': 2.125603675842285, 'policy_logps/rejected': -448.9345703125, 'policy_logps/chosen': -489.4410095214844, 'referece_logps/rejected': -426.34844970703125, 'referece_logps/chosen': -488.11090087890625, 'logits/rejected': -0.3006550669670105, 'logits/chosen': -0.16114285588264465, 'epoch': 4.29}

 72%|███████▏  | 11516/16104 [53:14:31<23:01:50, 18.07s/it]


 72%|███████▏  | 11518/16104 [53:15:04<22:16:38, 17.49s/it]
{'loss': 0.4705, 'learning_rate': 3.960632668236864e-07, 'rewards/chosen': -0.8879860043525696, 'rewards/rejected': -1.927648901939392, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0396629571914673, 'policy_logps/rejected': -333.92987060546875, 'policy_logps/chosen': -493.42938232421875, 'referece_logps/rejected': -314.65338134765625, 'referece_logps/chosen': -484.54949951171875, 'logits/rejected': -0.8310620784759521, 'logits/chosen': -0.9953068494796753, 'epoch': 4.29}

 72%|███████▏  | 11519/16104 [53:15:25<23:43:18, 18.63s/it]

 72%|███████▏  | 11520/16104 [53:15:45<24:24:02, 19.16s/it]

 72%|███████▏  | 11521/16104 [53:16:01<22:58:57, 18.05s/it]


 72%|███████▏  | 11523/16104 [53:16:38<23:18:27, 18.32s/it]

 72%|███████▏  | 11524/16104 [53:17:00<24:41:03, 19.40s/it]
{'loss': 0.5089, 'learning_rate': 3.951018819537476e-07, 'rewards/chosen': -0.3601924777030945, 'rewards/rejected': -1.4786231517791748, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1184306144714355, 'policy_logps/rejected': -497.510009765625, 'policy_logps/chosen': -455.47503662109375, 'referece_logps/rejected': -482.7237854003906, 'referece_logps/chosen': -451.87310791015625, 'logits/rejected': -0.06196904182434082, 'logits/chosen': 0.11841829121112823, 'epoch': 4.29}


 72%|███████▏  | 11526/16104 [53:17:30<22:18:20, 17.54s/it]
{'loss': 0.3727, 'learning_rate': 3.9478161601497774e-07, 'rewards/chosen': -0.0934070572257042, 'rewards/rejected': -1.531497597694397, 'rewards/accuracies': 1.0, 'rewards/margins': 1.438090443611145, 'policy_logps/rejected': -345.76806640625, 'policy_logps/chosen': -422.42779541015625, 'referece_logps/rejected': -330.45306396484375, 'referece_logps/chosen': -421.4937438964844, 'logits/rejected': -0.42588376998901367, 'logits/chosen': -0.38272374868392944, 'epoch': 4.29}


 72%|███████▏  | 11528/16104 [53:18:08<23:04:05, 18.15s/it]
{'loss': 0.3076, 'learning_rate': 3.9446144800486135e-07, 'rewards/chosen': -0.7388466000556946, 'rewards/rejected': -1.9324544668197632, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1936079263687134, 'policy_logps/rejected': -408.79302978515625, 'policy_logps/chosen': -459.8619689941406, 'referece_logps/rejected': -389.46844482421875, 'referece_logps/chosen': -452.4735412597656, 'logits/rejected': -0.4125654101371765, 'logits/chosen': -0.4344819486141205, 'epoch': 4.3}


 72%|███████▏  | 11530/16104 [53:18:34<19:37:21, 15.44s/it]
{'loss': 0.4097, 'learning_rate': 3.941413779752041e-07, 'rewards/chosen': -0.9653480052947998, 'rewards/rejected': -1.8973469734191895, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9319990277290344, 'policy_logps/rejected': -429.50531005859375, 'policy_logps/chosen': -612.16796875, 'referece_logps/rejected': -410.5318603515625, 'referece_logps/chosen': -602.514404296875, 'logits/rejected': -0.740527868270874, 'logits/chosen': -0.49598631262779236, 'epoch': 4.3}


 72%|███████▏  | 11532/16104 [53:18:58<17:31:03, 13.79s/it]
{'loss': 0.5052, 'learning_rate': 3.9382140597779544e-07, 'rewards/chosen': -0.06711998581886292, 'rewards/rejected': -0.8985700607299805, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8314501047134399, 'policy_logps/rejected': -433.0853271484375, 'policy_logps/chosen': -619.5357055664062, 'referece_logps/rejected': -424.099609375, 'referece_logps/chosen': -618.8645629882812, 'logits/rejected': -0.5355184078216553, 'logits/chosen': -0.4326893091201782, 'epoch': 4.3}


 72%|███████▏  | 11534/16104 [53:19:30<18:52:45, 14.87s/it]

 72%|███████▏  | 11535/16104 [53:19:48<20:16:36, 15.98s/it]

 72%|███████▏  | 11536/16104 [53:20:06<20:48:25, 16.40s/it]

 72%|███████▏  | 11537/16104 [53:20:26<22:08:59, 17.46s/it]

 72%|███████▏  | 11538/16104 [53:20:47<23:26:41, 18.48s/it]
{'loss': 0.4259, 'learning_rate': 3.928620786967192e-07, 'rewards/chosen': -0.666132926940918, 'rewards/rejected': -0.9739187955856323, 'rewards/accuracies': 0.625, 'rewards/margins': 0.30778586864471436, 'policy_logps/rejected': -408.1975402832031, 'policy_logps/chosen': -582.0492553710938, 'referece_logps/rejected': -398.4583740234375, 'referece_logps/chosen': -575.387939453125, 'logits/rejected': -0.009016698226332664, 'logits/chosen': 0.0036584523040801287, 'epoch': 4.3}


 72%|███████▏  | 11540/16104 [53:21:19<21:21:59, 16.85s/it]
{'loss': 0.4812, 'learning_rate': 3.925424993458839e-07, 'rewards/chosen': -0.5508562326431274, 'rewards/rejected': -2.421252489089966, 'rewards/accuracies': 0.625, 'rewards/margins': 1.8703964948654175, 'policy_logps/rejected': -502.56219482421875, 'policy_logps/chosen': -414.5816955566406, 'referece_logps/rejected': -478.34967041015625, 'referece_logps/chosen': -409.07318115234375, 'logits/rejected': -0.49114614725112915, 'logits/chosen': -0.2916504442691803, 'epoch': 4.3}


 72%|███████▏  | 11542/16104 [53:21:48<19:34:24, 15.45s/it]
{'loss': 0.4895, 'learning_rate': 3.9222301828600755e-07, 'rewards/chosen': -1.4637017250061035, 'rewards/rejected': -2.639277458190918, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1755759716033936, 'policy_logps/rejected': -444.1361083984375, 'policy_logps/chosen': -373.40972900390625, 'referece_logps/rejected': -417.74334716796875, 'referece_logps/chosen': -358.772705078125, 'logits/rejected': -0.04650743305683136, 'logits/chosen': 0.020308300852775574, 'epoch': 4.3}


 72%|███████▏  | 11544/16104 [53:22:18<18:55:29, 14.94s/it]
{'loss': 0.4316, 'learning_rate': 3.919036355687835e-07, 'rewards/chosen': -0.6721576452255249, 'rewards/rejected': -1.5459071397781372, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8737493753433228, 'policy_logps/rejected': -458.0661315917969, 'policy_logps/chosen': -545.3202514648438, 'referece_logps/rejected': -442.6070251464844, 'referece_logps/chosen': -538.5986938476562, 'logits/rejected': -0.12856587767601013, 'logits/chosen': -0.15117543935775757, 'epoch': 4.3}


 72%|███████▏  | 11546/16104 [53:22:51<19:25:16, 15.34s/it]

 72%|███████▏  | 11547/16104 [53:23:11<21:10:28, 16.73s/it]

 72%|███████▏  | 11548/16104 [53:23:30<22:14:07, 17.57s/it]
{'loss': 0.3977, 'learning_rate': 3.9126516536899245e-07, 'rewards/chosen': -0.43874871730804443, 'rewards/rejected': -1.6884243488311768, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2496756315231323, 'policy_logps/rejected': -279.88787841796875, 'policy_logps/chosen': -293.9745178222656, 'referece_logps/rejected': -263.0036315917969, 'referece_logps/chosen': -289.5870361328125, 'logits/rejected': -0.38945960998535156, 'logits/chosen': -0.3736015558242798, 'epoch': 4.3}


 72%|███████▏  | 11550/16104 [53:24:03<21:24:56, 16.93s/it]
{'loss': 0.3688, 'learning_rate': 3.909460779897339e-07, 'rewards/chosen': -0.765958309173584, 'rewards/rejected': -3.1521599292755127, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3862016201019287, 'policy_logps/rejected': -553.9955444335938, 'policy_logps/chosen': -486.12359619140625, 'referece_logps/rejected': -522.4739379882812, 'referece_logps/chosen': -478.4639892578125, 'logits/rejected': -0.07370708882808685, 'logits/chosen': -0.024097107350826263, 'epoch': 4.3}

 72%|███████▏  | 11551/16104 [53:24:20<21:19:11, 16.86s/it]

 72%|███████▏  | 11552/16104 [53:24:36<21:05:24, 16.68s/it]


 72%|███████▏  | 11554/16104 [53:25:02<18:57:46, 15.00s/it]

 72%|███████▏  | 11555/16104 [53:25:21<20:20:16, 16.10s/it]

 72%|███████▏  | 11556/16104 [53:25:39<21:13:34, 16.80s/it]

 72%|███████▏  | 11557/16104 [53:25:53<20:06:06, 15.92s/it]
{'loss': 0.4572, 'learning_rate': 3.8983004857652144e-07, 'rewards/chosen': -0.776828408241272, 'rewards/rejected': -2.0766186714172363, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2997902631759644, 'policy_logps/rejected': -484.597412109375, 'policy_logps/chosen': -421.57452392578125, 'referece_logps/rejected': -463.8312072753906, 'referece_logps/chosen': -413.8061828613281, 'logits/rejected': 0.2044270634651184, 'logits/chosen': 0.1877574324607849, 'epoch': 4.31}


 72%|███████▏  | 11559/16104 [53:26:29<21:15:46, 16.84s/it]

 72%|███████▏  | 11560/16104 [53:26:42<19:50:45, 15.72s/it]

 72%|███████▏  | 11561/16104 [53:26:59<20:11:29, 16.00s/it]
{'loss': 0.5384, 'learning_rate': 3.8919286035557655e-07, 'rewards/chosen': -0.26200446486473083, 'rewards/rejected': -2.0425071716308594, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7805025577545166, 'policy_logps/rejected': -397.4852294921875, 'policy_logps/chosen': -495.80010986328125, 'referece_logps/rejected': -377.0601806640625, 'referece_logps/chosen': -493.1800842285156, 'logits/rejected': 0.34304147958755493, 'logits/chosen': 0.3585367202758789, 'epoch': 4.31}


 72%|███████▏  | 11563/16104 [53:27:31<20:38:07, 16.36s/it]
{'loss': 0.495, 'learning_rate': 3.888744144687643e-07, 'rewards/chosen': -0.14483530819416046, 'rewards/rejected': -1.9394086599349976, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7945733070373535, 'policy_logps/rejected': -347.76788330078125, 'policy_logps/chosen': -646.2740478515625, 'referece_logps/rejected': -328.3737487792969, 'referece_logps/chosen': -644.82568359375, 'logits/rejected': 0.28297221660614014, 'logits/chosen': 0.3028642535209656, 'epoch': 4.31}


 72%|███████▏  | 11565/16104 [53:27:59<18:36:06, 14.75s/it]
{'loss': 0.5307, 'learning_rate': 3.885560674664328e-07, 'rewards/chosen': 0.3556652069091797, 'rewards/rejected': -0.16080951690673828, 'rewards/accuracies': 0.5, 'rewards/margins': 0.516474723815918, 'policy_logps/rejected': -456.49334716796875, 'policy_logps/chosen': -528.886962890625, 'referece_logps/rejected': -454.88525390625, 'referece_logps/chosen': -532.443603515625, 'logits/rejected': -0.06579647958278656, 'logits/chosen': -0.09547793865203857, 'epoch': 4.31}


 72%|███████▏  | 11567/16104 [53:28:21<16:17:33, 12.93s/it]

 72%|███████▏  | 11568/16104 [53:28:33<15:51:18, 12.58s/it]
{'loss': 0.5009, 'learning_rate': 3.8807873248401244e-07, 'rewards/chosen': -0.5798160433769226, 'rewards/rejected': -1.1275150775909424, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5476990342140198, 'policy_logps/rejected': -575.23681640625, 'policy_logps/chosen': -510.8397216796875, 'referece_logps/rejected': -563.9616088867188, 'referece_logps/chosen': -505.0415344238281, 'logits/rejected': -0.36686673760414124, 'logits/chosen': -0.2843792736530304, 'epoch': 4.31}

 72%|███████▏  | 11569/16104 [53:28:49<17:24:32, 13.82s/it]


 72%|███████▏  | 11571/16104 [53:29:14<16:33:45, 13.15s/it]

 72%|███████▏  | 11572/16104 [53:29:36<19:54:23, 15.81s/it]
{'loss': 0.3618, 'learning_rate': 3.8744263241710184e-07, 'rewards/chosen': -2.1771953105926514, 'rewards/rejected': -4.258249759674072, 'rewards/accuracies': 1.0, 'rewards/margins': 2.081054210662842, 'policy_logps/rejected': -569.2993774414062, 'policy_logps/chosen': -724.201904296875, 'referece_logps/rejected': -526.7168579101562, 'referece_logps/chosen': -702.429931640625, 'logits/rejected': -0.08665966987609863, 'logits/chosen': -0.2078370749950409, 'epoch': 4.31}

 72%|███████▏  | 11573/16104 [53:29:56<21:18:39, 16.93s/it]


 72%|███████▏  | 11575/16104 [53:30:33<21:59:58, 17.49s/it]

 72%|███████▏  | 11576/16104 [53:30:49<21:27:39, 17.06s/it]
{'loss': 0.3674, 'learning_rate': 3.868069288147898e-07, 'rewards/chosen': -0.7230334281921387, 'rewards/rejected': -2.3108432292938232, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5878102779388428, 'policy_logps/rejected': -516.68310546875, 'policy_logps/chosen': -498.76873779296875, 'referece_logps/rejected': -493.5746765136719, 'referece_logps/chosen': -491.5384216308594, 'logits/rejected': -0.3434215784072876, 'logits/chosen': -0.334857314825058, 'epoch': 4.31}

 72%|███████▏  | 11577/16104 [53:31:00<19:13:47, 15.29s/it]


 72%|███████▏  | 11579/16104 [53:31:31<18:55:46, 15.06s/it]
{'loss': 0.5421, 'learning_rate': 3.8633041154046764e-07, 'rewards/chosen': -0.27733898162841797, 'rewards/rejected': -0.8541680574417114, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5768290758132935, 'policy_logps/rejected': -385.24200439453125, 'policy_logps/chosen': -436.2225341796875, 'referece_logps/rejected': -376.7003173828125, 'referece_logps/chosen': -433.4491882324219, 'logits/rejected': -0.1259884089231491, 'logits/chosen': -0.03682135045528412, 'epoch': 4.31}

 72%|███████▏  | 11580/16104 [53:31:44<18:20:12, 14.59s/it]


 72%|███████▏  | 11582/16104 [53:32:21<21:06:39, 16.81s/it]
{'loss': 0.3955, 'learning_rate': 3.8585411768240885e-07, 'rewards/chosen': -0.377219557762146, 'rewards/rejected': -1.3195929527282715, 'rewards/accuracies': 0.875, 'rewards/margins': 0.942373514175415, 'policy_logps/rejected': -384.16156005859375, 'policy_logps/chosen': -418.04290771484375, 'referece_logps/rejected': -370.96563720703125, 'referece_logps/chosen': -414.27069091796875, 'logits/rejected': 0.2520529627799988, 'logits/chosen': 0.25778868794441223, 'epoch': 4.32}

 72%|███████▏  | 11583/16104 [53:32:42<22:26:31, 17.87s/it]


 72%|███████▏  | 11585/16104 [53:33:25<24:37:17, 19.61s/it]
{'loss': 0.3943, 'learning_rate': 3.8537804741401635e-07, 'rewards/chosen': -0.09889917820692062, 'rewards/rejected': -2.9107680320739746, 'rewards/accuracies': 0.625, 'rewards/margins': 2.811868906021118, 'policy_logps/rejected': -302.4454650878906, 'policy_logps/chosen': -427.18951416015625, 'referece_logps/rejected': -273.3377685546875, 'referece_logps/chosen': -426.20050048828125, 'logits/rejected': -0.5142641067504883, 'logits/chosen': -0.4914138913154602, 'epoch': 4.32}

 72%|███████▏  | 11586/16104 [53:33:36<21:41:10, 17.28s/it]

 72%|███████▏  | 11587/16104 [53:33:50<20:20:03, 16.21s/it]

 72%|███████▏  | 11588/16104 [53:34:07<20:24:26, 16.27s/it]


 72%|███████▏  | 11590/16104 [53:34:29<17:09:00, 13.68s/it]
{'loss': 0.497, 'learning_rate': 3.845850943033306e-07, 'rewards/chosen': -0.023014841601252556, 'rewards/rejected': -0.8313663601875305, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8083515167236328, 'policy_logps/rejected': -457.47149658203125, 'policy_logps/chosen': -404.051513671875, 'referece_logps/rejected': -449.1578063964844, 'referece_logps/chosen': -403.82135009765625, 'logits/rejected': -0.41371697187423706, 'logits/chosen': -0.3625909388065338, 'epoch': 4.32}

 72%|███████▏  | 11591/16104 [53:34:50<19:58:43, 15.94s/it]

 72%|███████▏  | 11592/16104 [53:35:09<20:47:53, 16.59s/it]


 72%|███████▏  | 11594/16104 [53:35:52<23:54:36, 19.09s/it]

 72%|███████▏  | 11595/16104 [53:36:11<24:04:36, 19.22s/it]

 72%|███████▏  | 11596/16104 [53:36:27<22:52:59, 18.27s/it]
{'loss': 0.4418, 'learning_rate': 3.836343721637928e-07, 'rewards/chosen': -0.38838061690330505, 'rewards/rejected': -1.7631983757019043, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3748176097869873, 'policy_logps/rejected': -551.2852783203125, 'policy_logps/chosen': -496.3960266113281, 'referece_logps/rejected': -533.6533203125, 'referece_logps/chosen': -492.5122375488281, 'logits/rejected': 0.3337455987930298, 'logits/chosen': 0.4564201831817627, 'epoch': 4.32}


 72%|███████▏  | 11598/16104 [53:36:53<19:11:53, 15.34s/it]
{'loss': 0.4713, 'learning_rate': 3.8331766418030686e-07, 'rewards/chosen': -0.8356582522392273, 'rewards/rejected': -1.9070374965667725, 'rewards/accuracies': 1.0, 'rewards/margins': 1.07137930393219, 'policy_logps/rejected': -373.39678955078125, 'policy_logps/chosen': -397.2778015136719, 'referece_logps/rejected': -354.326416015625, 'referece_logps/chosen': -388.92120361328125, 'logits/rejected': -0.4293632507324219, 'logits/chosen': -0.428272008895874, 'epoch': 4.32}

 72%|███████▏  | 11599/16104 [53:37:12<20:43:23, 16.56s/it]


 72%|███████▏  | 11601/16104 [53:37:41<19:40:31, 15.73s/it]
{'loss': 0.3419, 'learning_rate': 3.8284278931534275e-07, 'rewards/chosen': -0.5215574502944946, 'rewards/rejected': -1.528890609741211, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0073331594467163, 'policy_logps/rejected': -322.71942138671875, 'policy_logps/chosen': -443.3052978515625, 'referece_logps/rejected': -307.4305114746094, 'referece_logps/chosen': -438.0897521972656, 'logits/rejected': -0.025255978107452393, 'logits/chosen': -0.058643996715545654, 'epoch': 4.32}


 72%|███████▏  | 11603/16104 [53:38:11<19:28:24, 15.58s/it]
{'loss': 0.3425, 'learning_rate': 3.825263308869139e-07, 'rewards/chosen': -1.0343164205551147, 'rewards/rejected': -2.0476737022399902, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0133572816848755, 'policy_logps/rejected': -360.39111328125, 'policy_logps/chosen': -398.242919921875, 'referece_logps/rejected': -339.91436767578125, 'referece_logps/chosen': -387.89971923828125, 'logits/rejected': -0.14843414723873138, 'logits/chosen': -0.13060078024864197, 'epoch': 4.32}


 72%|███████▏  | 11605/16104 [53:38:38<18:13:46, 14.59s/it]
{'loss': 0.4964, 'learning_rate': 3.82209972370131e-07, 'rewards/chosen': 0.05299130082130432, 'rewards/rejected': -0.7848317623138428, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8378229737281799, 'policy_logps/rejected': -614.4840087890625, 'policy_logps/chosen': -513.646484375, 'referece_logps/rejected': -606.6357421875, 'referece_logps/chosen': -514.1763916015625, 'logits/rejected': 0.05550944805145264, 'logits/chosen': 0.3137502372264862, 'epoch': 4.32}

 72%|███████▏  | 11606/16104 [53:38:56<19:45:39, 15.82s/it]


 72%|███████▏  | 11608/16104 [53:39:31<21:04:13, 16.87s/it]
{'loss': 0.446, 'learning_rate': 3.817356220412653e-07, 'rewards/chosen': -0.9320423007011414, 'rewards/rejected': -1.6259756088256836, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6939331293106079, 'policy_logps/rejected': -468.69805908203125, 'policy_logps/chosen': -480.6427001953125, 'referece_logps/rejected': -452.4382629394531, 'referece_logps/chosen': -471.322265625, 'logits/rejected': -0.17404970526695251, 'logits/chosen': -0.1958906352519989, 'epoch': 4.32}

 72%|███████▏  | 11609/16104 [53:39:50<21:53:32, 17.53s/it]


 72%|███████▏  | 11611/16104 [53:40:30<23:04:06, 18.48s/it]

 72%|███████▏  | 11612/16104 [53:40:42<20:27:52, 16.40s/it]

 72%|███████▏  | 11613/16104 [53:41:03<22:29:01, 18.02s/it]

 72%|███████▏  | 11614/16104 [53:41:15<20:16:06, 16.25s/it]
{'loss': 0.3139, 'learning_rate': 3.807875968233575e-07, 'rewards/chosen': -0.39235919713974, 'rewards/rejected': -1.8753199577331543, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4829607009887695, 'policy_logps/rejected': -275.5852355957031, 'policy_logps/chosen': -420.2167663574219, 'referece_logps/rejected': -256.83203125, 'referece_logps/chosen': -416.2931823730469, 'logits/rejected': -0.11915411055088043, 'logits/chosen': -0.1277599185705185, 'epoch': 4.33}


 72%|███████▏  | 11616/16104 [53:41:54<22:17:30, 17.88s/it]

 72%|███████▏  | 11617/16104 [53:42:06<20:05:05, 16.11s/it]
{'loss': 0.3695, 'learning_rate': 3.8031392227945913e-07, 'rewards/chosen': -0.1149587631225586, 'rewards/rejected': -1.6847856044769287, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5698268413543701, 'policy_logps/rejected': -479.89886474609375, 'policy_logps/chosen': -429.1785583496094, 'referece_logps/rejected': -463.0509948730469, 'referece_logps/chosen': -428.02899169921875, 'logits/rejected': -0.21283692121505737, 'logits/chosen': -0.04384639859199524, 'epoch': 4.33}

 72%|███████▏  | 11618/16104 [53:42:21<19:44:20, 15.84s/it]


 72%|███████▏  | 11620/16104 [53:42:48<18:14:57, 14.65s/it]
{'loss': 0.4404, 'learning_rate': 3.7984047334222414e-07, 'rewards/chosen': -0.10146711766719818, 'rewards/rejected': -1.0439597368240356, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9424926042556763, 'policy_logps/rejected': -467.1984558105469, 'policy_logps/chosen': -550.2765502929688, 'referece_logps/rejected': -456.7588806152344, 'referece_logps/chosen': -549.2619018554688, 'logits/rejected': -0.3337315022945404, 'logits/chosen': -0.39269009232521057, 'epoch': 4.33}


 72%|███████▏  | 11622/16104 [53:43:14<17:02:31, 13.69s/it]
{'loss': 0.4051, 'learning_rate': 3.7952496613955833e-07, 'rewards/chosen': 0.648280680179596, 'rewards/rejected': -0.33771058917045593, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9859912395477295, 'policy_logps/rejected': -501.7045593261719, 'policy_logps/chosen': -566.8053588867188, 'referece_logps/rejected': -498.3274841308594, 'referece_logps/chosen': -573.2881469726562, 'logits/rejected': -0.4082069993019104, 'logits/chosen': -0.22028334438800812, 'epoch': 4.33}


 72%|███████▏  | 11624/16104 [53:43:36<15:13:00, 12.23s/it]

 72%|███████▏  | 11625/16104 [53:43:52<16:42:37, 13.43s/it]
{'loss': 0.4877, 'learning_rate': 3.790518935964242e-07, 'rewards/chosen': 0.03834858536720276, 'rewards/rejected': -1.0348914861679077, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0732401609420776, 'policy_logps/rejected': -491.99505615234375, 'policy_logps/chosen': -398.8503723144531, 'referece_logps/rejected': -481.6461181640625, 'referece_logps/chosen': -399.23388671875, 'logits/rejected': 0.31312936544418335, 'logits/chosen': 0.35613158345222473, 'epoch': 4.33}


 72%|███████▏  | 11627/16104 [53:44:20<16:53:57, 13.59s/it]
{'loss': 0.5542, 'learning_rate': 3.787366374826647e-07, 'rewards/chosen': 0.051943305879831314, 'rewards/rejected': -0.968641996383667, 'rewards/accuracies': 0.75, 'rewards/margins': 1.020585298538208, 'policy_logps/rejected': -505.06195068359375, 'policy_logps/chosen': -396.5595397949219, 'referece_logps/rejected': -495.3755187988281, 'referece_logps/chosen': -397.0789794921875, 'logits/rejected': -0.09955152869224548, 'logits/chosen': -0.06962423026561737, 'epoch': 4.33}

 72%|███████▏  | 11628/16104 [53:44:40<19:09:47, 15.41s/it]

 72%|███████▏  | 11629/16104 [53:45:00<20:55:14, 16.83s/it]

 72%|███████▏  | 11630/16104 [53:45:19<21:54:34, 17.63s/it]


 72%|███████▏  | 11632/16104 [53:46:00<23:44:47, 19.12s/it]
{'loss': 0.3762, 'learning_rate': 3.779489371060123e-07, 'rewards/chosen': -1.0058295726776123, 'rewards/rejected': -1.6317423582077026, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6259126663208008, 'policy_logps/rejected': -510.3141784667969, 'policy_logps/chosen': -445.05645751953125, 'referece_logps/rejected': -493.9967041015625, 'referece_logps/chosen': -434.9981689453125, 'logits/rejected': 0.3975493013858795, 'logits/chosen': 0.42882484197616577, 'epoch': 4.33}

 72%|███████▏  | 11633/16104 [53:46:18<23:11:14, 18.67s/it]


 72%|███████▏  | 11635/16104 [53:46:48<20:40:39, 16.66s/it]
{'loss': 0.4876, 'learning_rate': 3.774766187859468e-07, 'rewards/chosen': 0.080664724111557, 'rewards/rejected': -1.3514223098754883, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4320869445800781, 'policy_logps/rejected': -460.15753173828125, 'policy_logps/chosen': -452.43707275390625, 'referece_logps/rejected': -446.6432800292969, 'referece_logps/chosen': -453.2437744140625, 'logits/rejected': -0.2366301715373993, 'logits/chosen': -0.14615555107593536, 'epoch': 4.33}

 72%|███████▏  | 11636/16104 [53:46:59<18:26:25, 14.86s/it]


 72%|███████▏  | 11638/16104 [53:47:34<20:43:14, 16.70s/it]

 72%|███████▏  | 11639/16104 [53:47:51<20:36:44, 16.62s/it]
{'loss': 0.382, 'learning_rate': 3.7684721360610225e-07, 'rewards/chosen': -0.2802886962890625, 'rewards/rejected': -1.4035288095474243, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1232401132583618, 'policy_logps/rejected': -398.857421875, 'policy_logps/chosen': -514.541748046875, 'referece_logps/rejected': -384.82208251953125, 'referece_logps/chosen': -511.73883056640625, 'logits/rejected': -0.139352947473526, 'logits/chosen': -0.02423936128616333, 'epoch': 4.34}

 72%|███████▏  | 11640/16104 [53:48:11<22:00:19, 17.75s/it]

 72%|███████▏  | 11641/16104 [53:48:24<20:18:06, 16.38s/it]

 72%|███████▏  | 11642/16104 [53:48:37<18:53:38, 15.24s/it]


 72%|███████▏  | 11644/16104 [53:49:19<22:35:03, 18.23s/it]
{'loss': 0.3899, 'learning_rate': 3.760610243509317e-07, 'rewards/chosen': -0.1303083449602127, 'rewards/rejected': -1.1644740104675293, 'rewards/accuracies': 0.875, 'rewards/margins': 1.034165859222412, 'policy_logps/rejected': -346.7893981933594, 'policy_logps/chosen': -511.97357177734375, 'referece_logps/rejected': -335.1446533203125, 'referece_logps/chosen': -510.67047119140625, 'logits/rejected': -0.28300759196281433, 'logits/chosen': -0.27995821833610535, 'epoch': 4.34}

 72%|███████▏  | 11645/16104 [53:49:30<20:00:45, 16.16s/it]

 72%|███████▏  | 11646/16104 [53:49:47<20:17:15, 16.38s/it]

 72%|███████▏  | 11647/16104 [53:49:58<18:14:51, 14.74s/it]

 72%|███████▏  | 11648/16104 [53:50:17<19:52:52, 16.06s/it]

 72%|███████▏  | 11649/16104 [53:50:31<19:07:05, 15.45s/it]

 72%|███████▏  | 11650/16104 [53:50:50<20:31:46, 16.59s/it]

 72%|███████▏  | 11651/16104 [53:51:03<19:13:03, 15.54s/it]

 72%|███████▏  | 11652/16104 [53:51:18<19:00:31, 15.37s/it]

 72%|███████▏  | 11653/16104 [53:51:35<19:29:09, 15.76s/it]

 72%|███████▏  | 11654/16104 [53:51:55<21:02:32, 17.02s/it]

 72%|███████▏  | 11655/16104 [53:52:08<19:38:10, 15.89s/it]

 72%|███████▏  | 11656/16104 [53:52:27<20:42:31, 16.76s/it]

 72%|███████▏  | 11657/16104 [53:52:46<21:28:47, 17.39s/it]

 72%|███████▏  | 11658/16104 [53:52:59<20:04:12, 16.25s/it]


 72%|███████▏  | 11660/16104 [53:53:34<20:55:48, 16.96s/it]
{'loss': 0.3891, 'learning_rate': 3.735494628748082e-07, 'rewards/chosen': -1.1499565839767456, 'rewards/rejected': -1.836991310119629, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6870346069335938, 'policy_logps/rejected': -297.1830749511719, 'policy_logps/chosen': -426.4865417480469, 'referece_logps/rejected': -278.81317138671875, 'referece_logps/chosen': -414.98699951171875, 'logits/rejected': -0.31026333570480347, 'logits/chosen': -0.29760169982910156, 'epoch': 4.34}


 72%|███████▏  | 11662/16104 [53:54:07<20:59:12, 17.01s/it]

 72%|███████▏  | 11663/16104 [53:54:27<22:03:50, 17.89s/it]
{'loss': 0.4596, 'learning_rate': 3.730792665340188e-07, 'rewards/chosen': 0.109723299741745, 'rewards/rejected': -0.8159857392311096, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9257090091705322, 'policy_logps/rejected': -461.0991516113281, 'policy_logps/chosen': -576.18408203125, 'referece_logps/rejected': -452.93927001953125, 'referece_logps/chosen': -577.2813720703125, 'logits/rejected': -0.5089592337608337, 'logits/chosen': -0.5310292840003967, 'epoch': 4.35}

 72%|███████▏  | 11664/16104 [53:54:37<19:24:01, 15.73s/it]

 72%|███████▏  | 11665/16104 [53:54:58<21:18:03, 17.27s/it]

 72%|███████▏  | 11666/16104 [53:55:14<20:39:34, 16.76s/it]

 72%|███████▏  | 11667/16104 [53:55:36<22:30:29, 18.26s/it]

 72%|███████▏  | 11668/16104 [53:55:55<23:06:34, 18.75s/it]

 72%|███████▏  | 11669/16104 [53:56:10<21:32:02, 17.48s/it]


 72%|███████▏  | 11671/16104 [53:56:43<20:24:19, 16.57s/it]
{'loss': 0.391, 'learning_rate': 3.7182652593263876e-07, 'rewards/chosen': -0.43263915181159973, 'rewards/rejected': -2.387308359146118, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9546692371368408, 'policy_logps/rejected': -264.93438720703125, 'policy_logps/chosen': -401.8338623046875, 'referece_logps/rejected': -241.06130981445312, 'referece_logps/chosen': -397.5074462890625, 'logits/rejected': -0.7052969336509705, 'logits/chosen': -0.6302230358123779, 'epoch': 4.35}

 72%|███████▏  | 11672/16104 [53:57:01<21:05:23, 17.13s/it]

 72%|███████▏  | 11673/16104 [53:57:14<19:16:53, 15.67s/it]

 72%|███████▏  | 11674/16104 [53:57:30<19:38:14, 15.96s/it]


 73%|███████▎  | 11676/16104 [53:57:53<16:44:14, 13.61s/it]
{'loss': 0.3935, 'learning_rate': 3.7104438869989184e-07, 'rewards/chosen': -1.0215812921524048, 'rewards/rejected': -2.9149422645568848, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8933608531951904, 'policy_logps/rejected': -249.1199951171875, 'policy_logps/chosen': -383.804443359375, 'referece_logps/rejected': -219.97059631347656, 'referece_logps/chosen': -373.5885925292969, 'logits/rejected': -0.13164716958999634, 'logits/chosen': -0.2972523868083954, 'epoch': 4.35}

 73%|███████▎  | 11677/16104 [53:58:13<19:17:43, 15.69s/it]

 73%|███████▎  | 11678/16104 [53:58:28<18:44:37, 15.25s/it]

 73%|███████▎  | 11679/16104 [53:58:42<18:20:58, 14.93s/it]

 73%|███████▎  | 11680/16104 [53:59:02<20:10:19, 16.42s/it]

 73%|███████▎  | 11681/16104 [53:59:13<18:05:56, 14.73s/it]

 73%|███████▎  | 11682/16104 [53:59:30<18:57:23, 15.43s/it]

 73%|███████▎  | 11683/16104 [53:59:42<17:50:18, 14.53s/it]

 73%|███████▎  | 11684/16104 [54:00:00<19:17:21, 15.71s/it]


 73%|███████▎  | 11686/16104 [54:00:33<19:19:36, 15.75s/it]
{'loss': 0.4517, 'learning_rate': 3.694820232028344e-07, 'rewards/chosen': 0.40328484773635864, 'rewards/rejected': -1.257386326789856, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6606709957122803, 'policy_logps/rejected': -526.260009765625, 'policy_logps/chosen': -620.811279296875, 'referece_logps/rejected': -513.6861572265625, 'referece_logps/chosen': -624.8441162109375, 'logits/rejected': -0.30505067110061646, 'logits/chosen': -0.3814355134963989, 'epoch': 4.35}

 73%|███████▎  | 11687/16104 [54:00:46<18:06:25, 14.76s/it]

 73%|███████▎  | 11688/16104 [54:01:01<18:16:35, 14.90s/it]


 73%|███████▎  | 11690/16104 [54:01:43<22:12:24, 18.11s/it]
{'loss': 0.3036, 'learning_rate': 3.6885779080636135e-07, 'rewards/chosen': -0.3979549705982208, 'rewards/rejected': -2.529370069503784, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1314151287078857, 'policy_logps/rejected': -412.21142578125, 'policy_logps/chosen': -469.1972961425781, 'referece_logps/rejected': -386.917724609375, 'referece_logps/chosen': -465.2178039550781, 'logits/rejected': 0.468207448720932, 'logits/chosen': 0.33373787999153137, 'epoch': 4.36}

 73%|███████▎  | 11691/16104 [54:01:54<19:31:03, 15.92s/it]

 73%|███████▎  | 11692/16104 [54:02:14<21:04:54, 17.20s/it]

 73%|███████▎  | 11693/16104 [54:02:36<22:49:44, 18.63s/it]


 73%|███████▎  | 11695/16104 [54:03:15<23:08:31, 18.90s/it]
{'loss': 0.3502, 'learning_rate': 3.680780748017066e-07, 'rewards/chosen': -0.1859765201807022, 'rewards/rejected': -2.9079782962799072, 'rewards/accuracies': 1.0, 'rewards/margins': 2.722001791000366, 'policy_logps/rejected': -342.95465087890625, 'policy_logps/chosen': -273.43646240234375, 'referece_logps/rejected': -313.8748779296875, 'referece_logps/chosen': -271.57672119140625, 'logits/rejected': -0.8261092305183411, 'logits/chosen': -0.9554112553596497, 'epoch': 4.36}

 73%|███████▎  | 11696/16104 [54:03:27<20:30:24, 16.75s/it]

 73%|███████▎  | 11697/16104 [54:03:39<18:47:21, 15.35s/it]

 73%|███████▎  | 11698/16104 [54:03:58<20:04:25, 16.40s/it]


 73%|███████▎  | 11700/16104 [54:04:33<20:25:08, 16.69s/it]
{'loss': 0.4375, 'learning_rate': 3.6729899785623874e-07, 'rewards/chosen': -0.5064924359321594, 'rewards/rejected': -1.289460301399231, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7829678654670715, 'policy_logps/rejected': -317.4813232421875, 'policy_logps/chosen': -361.55462646484375, 'referece_logps/rejected': -304.58673095703125, 'referece_logps/chosen': -356.4896545410156, 'logits/rejected': -0.11296296119689941, 'logits/chosen': -0.2203192263841629, 'epoch': 4.36}


 73%|███████▎  | 11702/16104 [54:05:16<23:14:26, 19.01s/it]
{'loss': 0.4039, 'learning_rate': 3.6698754619112973e-07, 'rewards/chosen': 0.4009349048137665, 'rewards/rejected': -2.5298056602478027, 'rewards/accuracies': 1.0, 'rewards/margins': 2.9307405948638916, 'policy_logps/rejected': -462.3634948730469, 'policy_logps/chosen': -412.49835205078125, 'referece_logps/rejected': -437.0653991699219, 'referece_logps/chosen': -416.5076599121094, 'logits/rejected': 0.24536113440990448, 'logits/chosen': 0.2809120714664459, 'epoch': 4.36}

 73%|███████▎  | 11703/16104 [54:05:28<20:46:39, 17.00s/it]

 73%|███████▎  | 11704/16104 [54:05:48<21:48:22, 17.84s/it]

 73%|███████▎  | 11705/16104 [54:06:03<20:45:55, 16.99s/it]

 73%|███████▎  | 11706/16104 [54:06:16<19:19:32, 15.82s/it]

 73%|███████▎  | 11707/16104 [54:06:30<18:38:40, 15.26s/it]

 73%|███████▎  | 11708/16104 [54:06:42<17:40:15, 14.47s/it]


 73%|███████▎  | 11710/16104 [54:07:19<19:58:04, 16.36s/it]

 73%|███████▎  | 11711/16104 [54:07:32<18:26:48, 15.12s/it]
{'loss': 0.444, 'learning_rate': 3.6558728194624323e-07, 'rewards/chosen': -0.4403426945209503, 'rewards/rejected': -1.9938380718231201, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5534956455230713, 'policy_logps/rejected': -430.4941711425781, 'policy_logps/chosen': -356.87957763671875, 'referece_logps/rejected': -410.5557556152344, 'referece_logps/chosen': -352.47613525390625, 'logits/rejected': -0.2935202419757843, 'logits/chosen': -0.23538738489151, 'epoch': 4.36}

 73%|███████▎  | 11712/16104 [54:07:48<19:03:05, 15.62s/it]

 73%|███████▎  | 11713/16104 [54:08:00<17:37:46, 14.45s/it]

 73%|███████▎  | 11714/16104 [54:08:11<16:18:32, 13.37s/it]

 73%|███████▎  | 11715/16104 [54:08:26<16:57:55, 13.92s/it]

 73%|███████▎  | 11716/16104 [54:08:43<17:54:43, 14.70s/it]

 73%|███████▎  | 11717/16104 [54:08:56<17:24:50, 14.29s/it]


 73%|███████▎  | 11719/16104 [54:09:28<18:47:05, 15.42s/it]
{'loss': 0.3918, 'learning_rate': 3.643443475670861e-07, 'rewards/chosen': 0.6141145825386047, 'rewards/rejected': -0.42876505851745605, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0428798198699951, 'policy_logps/rejected': -477.87066650390625, 'policy_logps/chosen': -595.3735961914062, 'referece_logps/rejected': -473.5830078125, 'referece_logps/chosen': -601.5147094726562, 'logits/rejected': 0.39005276560783386, 'logits/chosen': 0.3257809281349182, 'epoch': 4.37}

 73%|███████▎  | 11720/16104 [54:09:44<19:07:05, 15.70s/it]

 73%|███████▎  | 11721/16104 [54:10:03<20:10:44, 16.57s/it]

 73%|███████▎  | 11722/16104 [54:10:14<18:22:48, 15.10s/it]

 73%|███████▎  | 11723/16104 [54:10:34<20:03:45, 16.49s/it]

 73%|███████▎  | 11724/16104 [54:10:47<18:37:09, 15.30s/it]

 73%|███████▎  | 11725/16104 [54:11:00<17:59:55, 14.80s/it]

 73%|███████▎  | 11726/16104 [54:11:20<19:40:03, 16.17s/it]

 73%|███████▎  | 11727/16104 [54:11:31<17:43:26, 14.58s/it]

 73%|███████▎  | 11728/16104 [54:11:41<16:19:15, 13.43s/it]

 73%|███████▎  | 11729/16104 [54:12:01<18:34:32, 15.29s/it]

 73%|███████▎  | 11730/16104 [54:12:12<16:55:51, 13.94s/it]

 73%|███████▎  | 11731/16104 [54:12:22<15:44:33, 12.96s/it]

 73%|███████▎  | 11732/16104 [54:12:33<15:03:03, 12.39s/it]

 73%|███████▎  | 11733/16104 [54:12:54<17:51:02, 14.70s/it]

 73%|███████▎  | 11734/16104 [54:13:16<20:31:38, 16.91s/it]

 73%|███████▎  | 11735/16104 [54:13:32<20:17:16, 16.72s/it]


 73%|███████▎  | 11737/16104 [54:13:57<17:43:22, 14.61s/it]

 73%|███████▎  | 11738/16104 [54:14:09<16:51:40, 13.90s/it]

 73%|███████▎  | 11739/16104 [54:14:29<18:51:52, 15.56s/it]

 73%|███████▎  | 11740/16104 [54:14:49<20:40:53, 17.06s/it]

 73%|███████▎  | 11741/16104 [54:15:07<20:41:40, 17.08s/it]

 73%|███████▎  | 11742/16104 [54:15:23<20:22:33, 16.82s/it]

 73%|███████▎  | 11743/16104 [54:15:34<18:29:15, 15.26s/it]

 73%|███████▎  | 11744/16104 [54:15:45<16:53:01, 13.94s/it]

 73%|███████▎  | 11745/16104 [54:16:06<19:22:13, 16.00s/it]

 73%|███████▎  | 11746/16104 [54:16:23<19:49:56, 16.38s/it]

 73%|███████▎  | 11747/16104 [54:16:44<21:15:42, 17.57s/it]

 73%|███████▎  | 11748/16104 [54:17:02<21:28:25, 17.75s/it]

 73%|███████▎  | 11749/16104 [54:17:21<22:05:31, 18.26s/it]

 73%|███████▎  | 11750/16104 [54:17:39<22:01:49, 18.22s/it]

 73%|███████▎  | 11751/16104 [54:17:53<20:25:48, 16.90s/it]

 73%|███████▎  | 11752/16104 [54:18:08<19:49:42, 16.40s/it]

 73%|███████▎  | 11753/16104 [54:18:24<19:26:50, 16.09s/it]

 73%|███████▎  | 11754/16104 [54:18:39<19:07:15, 15.82s/it]

 73%|███████▎  | 11755/16104 [54:18:56<19:35:08, 16.21s/it]

 73%|███████▎  | 11756/16104 [54:19:08<17:57:05, 14.86s/it]

 73%|███████▎  | 11757/16104 [54:19:28<19:44:13, 16.35s/it]

 73%|███████▎  | 11758/16104 [54:19:40<18:13:54, 15.10s/it]
{'loss': 0.4115, 'learning_rate': 3.5830866818498916e-07, 'rewards/chosen': 0.1048278659582138, 'rewards/rejected': -1.5640980005264282, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6689258813858032, 'policy_logps/rejected': -525.0892333984375, 'policy_logps/chosen': -553.003662109375, 'referece_logps/rejected': -509.44830322265625, 'referece_logps/chosen': -554.0519409179688, 'logits/rejected': -0.2734500467777252, 'logits/chosen': -0.35767051577568054, 'epoch': 4.38}


 73%|███████▎  | 11760/16104 [54:20:18<20:47:47, 17.23s/it]

 73%|███████▎  | 11761/16104 [54:20:34<20:07:55, 16.69s/it]

 73%|███████▎  | 11762/16104 [54:20:52<20:41:37, 17.16s/it]

 73%|███████▎  | 11763/16104 [54:21:09<20:42:33, 17.17s/it]

 73%|███████▎  | 11764/16104 [54:21:26<20:40:53, 17.16s/it]

 73%|███████▎  | 11765/16104 [54:21:46<21:45:02, 18.05s/it]

 73%|███████▎  | 11766/16104 [54:22:06<22:15:13, 18.47s/it]

 73%|███████▎  | 11767/16104 [54:22:26<22:46:21, 18.90s/it]

 73%|███████▎  | 11768/16104 [54:22:37<20:03:15, 16.65s/it]

 73%|███████▎  | 11769/16104 [54:22:57<21:15:23, 17.65s/it]

 73%|███████▎  | 11770/16104 [54:23:12<20:16:31, 16.84s/it]

 73%|███████▎  | 11771/16104 [54:23:29<20:07:03, 16.71s/it]

 73%|███████▎  | 11772/16104 [54:23:46<20:34:27, 17.10s/it]

 73%|███████▎  | 11773/16104 [54:24:03<20:19:21, 16.89s/it]

 73%|███████▎  | 11774/16104 [54:24:24<21:40:13, 18.02s/it]

 73%|███████▎  | 11775/16104 [54:24:38<20:26:05, 16.99s/it]

 73%|███████▎  | 11776/16104 [54:24:56<20:38:14, 17.17s/it]

 73%|███████▎  | 11777/16104 [54:25:08<18:58:52, 15.79s/it]

 73%|███████▎  | 11778/16104 [54:25:28<20:24:57, 16.99s/it]

 73%|███████▎  | 11779/16104 [54:25:49<21:59:51, 18.31s/it]

 73%|███████▎  | 11780/16104 [54:26:02<20:03:20, 16.70s/it]

 73%|███████▎  | 11781/16104 [54:26:21<20:44:58, 17.28s/it]

 73%|███████▎  | 11782/16104 [54:26:36<19:56:35, 16.61s/it]

 73%|███████▎  | 11783/16104 [54:26:56<21:06:23, 17.58s/it]

 73%|███████▎  | 11784/16104 [54:27:12<20:27:15, 17.05s/it]

 73%|███████▎  | 11785/16104 [54:27:32<21:37:53, 18.03s/it]

 73%|███████▎  | 11786/16104 [54:27:49<21:14:44, 17.71s/it]

 73%|███████▎  | 11787/16104 [54:28:04<20:14:05, 16.87s/it]

 73%|███████▎  | 11788/16104 [54:28:19<19:38:48, 16.39s/it]

 73%|███████▎  | 11789/16104 [54:28:34<18:58:33, 15.83s/it]

 73%|███████▎  | 11790/16104 [54:28:53<20:22:26, 17.00s/it]

 73%|███████▎  | 11791/16104 [54:29:07<19:15:33, 16.08s/it]

 73%|███████▎  | 11792/16104 [54:29:24<19:16:16, 16.09s/it]

 73%|███████▎  | 11793/16104 [54:29:44<20:49:00, 17.38s/it]

 73%|███████▎  | 11794/16104 [54:30:02<21:11:20, 17.70s/it]

 73%|███████▎  | 11795/16104 [54:30:18<20:17:15, 16.95s/it]

 73%|███████▎  | 11796/16104 [54:30:37<21:15:20, 17.76s/it]

 73%|███████▎  | 11797/16104 [54:30:50<19:36:02, 16.38s/it]

 73%|███████▎  | 11798/16104 [54:31:10<20:51:55, 17.44s/it]

 73%|███████▎  | 11799/16104 [54:31:31<22:03:49, 18.45s/it]

 73%|███████▎  | 11800/16104 [54:31:49<22:00:32, 18.41s/it]

 73%|███████▎  | 11801/16104 [54:32:09<22:20:00, 18.68s/it]

 73%|███████▎  | 11802/16104 [54:32:29<22:50:44, 19.12s/it]

 73%|███████▎  | 11803/16104 [54:32:50<23:35:25, 19.75s/it]

 73%|███████▎  | 11804/16104 [54:33:03<21:06:43, 17.68s/it]

 73%|███████▎  | 11805/16104 [54:33:15<19:03:25, 15.96s/it]

 73%|███████▎  | 11806/16104 [54:33:35<20:27:43, 17.14s/it]

 73%|███████▎  | 11807/16104 [54:33:51<19:58:23, 16.73s/it]

 73%|███████▎  | 11808/16104 [54:34:07<20:01:29, 16.78s/it]

 73%|███████▎  | 11809/16104 [54:34:20<18:22:18, 15.40s/it]
{'loss': 0.418, 'learning_rate': 3.5047548613839204e-07, 'rewards/chosen': -1.1673285961151123, 'rewards/rejected': -1.7486788034439087, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5813502669334412, 'policy_logps/rejected': -317.80609130859375, 'policy_logps/chosen': -363.67572021484375, 'referece_logps/rejected': -300.31927490234375, 'referece_logps/chosen': -352.00244140625, 'logits/rejected': 0.4848383069038391, 'logits/chosen': 0.3404615521430969, 'epoch': 4.4}

 73%|███████▎  | 11810/16104 [54:34:40<20:00:23, 16.77s/it]


 73%|███████▎  | 11812/16104 [54:35:19<21:38:31, 18.15s/it]

 73%|███████▎  | 11813/16104 [54:35:35<21:08:11, 17.73s/it]

 73%|███████▎  | 11814/16104 [54:35:49<19:29:37, 16.36s/it]

 73%|███████▎  | 11815/16104 [54:36:04<19:12:45, 16.13s/it]
{'loss': 0.4415, 'learning_rate': 3.4955841233369723e-07, 'rewards/chosen': -0.007037930190563202, 'rewards/rejected': -2.1077849864959717, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1007471084594727, 'policy_logps/rejected': -477.39752197265625, 'policy_logps/chosen': -610.7517700195312, 'referece_logps/rejected': -456.31964111328125, 'referece_logps/chosen': -610.681396484375, 'logits/rejected': 0.5430169105529785, 'logits/chosen': 0.4985005259513855, 'epoch': 4.4}


 73%|███████▎  | 11817/16104 [54:36:27<16:22:41, 13.75s/it]
{'loss': 0.3896, 'learning_rate': 3.492529314917132e-07, 'rewards/chosen': -0.34649068117141724, 'rewards/rejected': -1.7350391149520874, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3885482549667358, 'policy_logps/rejected': -250.93858337402344, 'policy_logps/chosen': -371.5685119628906, 'referece_logps/rejected': -233.58819580078125, 'referece_logps/chosen': -368.1036376953125, 'logits/rejected': 0.17451468110084534, 'logits/chosen': 0.13443167507648468, 'epoch': 4.4}


 73%|███████▎  | 11819/16104 [54:36:52<15:36:01, 13.11s/it]

 73%|███████▎  | 11820/16104 [54:37:05<15:39:26, 13.16s/it]

 73%|███████▎  | 11821/16104 [54:37:19<15:49:14, 13.30s/it]

 73%|███████▎  | 11822/16104 [54:37:39<18:16:43, 15.37s/it]

 73%|███████▎  | 11823/16104 [54:37:57<19:06:22, 16.07s/it]

 73%|███████▎  | 11824/16104 [54:38:10<17:58:23, 15.12s/it]

 73%|███████▎  | 11825/16104 [54:38:23<17:05:08, 14.37s/it]

 73%|███████▎  | 11826/16104 [54:38:38<17:28:30, 14.71s/it]

 73%|███████▎  | 11827/16104 [54:38:58<19:28:37, 16.39s/it]

 73%|███████▎  | 11828/16104 [54:39:11<18:17:25, 15.40s/it]

 73%|███████▎  | 11829/16104 [54:39:29<19:13:26, 16.19s/it]

 73%|███████▎  | 11830/16104 [54:39:43<18:15:20, 15.38s/it]

 73%|███████▎  | 11831/16104 [54:39:55<17:11:30, 14.48s/it]

 73%|███████▎  | 11832/16104 [54:40:12<17:59:32, 15.16s/it]

 73%|███████▎  | 11833/16104 [54:40:32<19:31:29, 16.46s/it]

 73%|███████▎  | 11834/16104 [54:40:47<19:11:57, 16.19s/it]

 73%|███████▎  | 11835/16104 [54:41:06<20:14:37, 17.07s/it]

 73%|███████▎  | 11836/16104 [54:41:22<19:51:58, 16.76s/it]

 74%|███████▎  | 11837/16104 [54:41:35<18:17:13, 15.43s/it]
{'loss': 0.4341, 'learning_rate': 3.4620392247279405e-07, 'rewards/chosen': -0.726696252822876, 'rewards/rejected': -2.319333076477051, 'rewards/accuracies': 0.875, 'rewards/margins': 1.592637300491333, 'policy_logps/rejected': -432.4469909667969, 'policy_logps/chosen': -382.38482666015625, 'referece_logps/rejected': -409.253662109375, 'referece_logps/chosen': -375.11785888671875, 'logits/rejected': -0.558847963809967, 'logits/chosen': -0.6429500579833984, 'epoch': 4.41}

 74%|███████▎  | 11838/16104 [54:41:54<19:43:09, 16.64s/it]


 74%|███████▎  | 11840/16104 [54:42:26<18:58:05, 16.01s/it]
{'loss': 0.4082, 'learning_rate': 3.4574748234436935e-07, 'rewards/chosen': -0.21194908022880554, 'rewards/rejected': -1.8098692893981934, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5979200601577759, 'policy_logps/rejected': -377.59222412109375, 'policy_logps/chosen': -362.4245300292969, 'referece_logps/rejected': -359.4935607910156, 'referece_logps/chosen': -360.3050231933594, 'logits/rejected': -0.18075230717658997, 'logits/chosen': -0.16478216648101807, 'epoch': 4.41}


 74%|███████▎  | 11842/16104 [54:42:56<18:54:24, 15.97s/it]
{'loss': 0.3943, 'learning_rate': 3.4544332124357134e-07, 'rewards/chosen': -0.07762405276298523, 'rewards/rejected': -2.2921390533447266, 'rewards/accuracies': 0.875, 'rewards/margins': 2.214515209197998, 'policy_logps/rejected': -506.427978515625, 'policy_logps/chosen': -448.4365234375, 'referece_logps/rejected': -483.506591796875, 'referece_logps/chosen': -447.6602783203125, 'logits/rejected': -0.7839542031288147, 'logits/chosen': -0.727436900138855, 'epoch': 4.41}

 74%|███████▎  | 11843/16104 [54:43:16<20:24:29, 17.24s/it]


 74%|███████▎  | 11845/16104 [54:43:49<20:14:22, 17.11s/it]

 74%|███████▎  | 11846/16104 [54:44:08<20:56:50, 17.71s/it]
{'loss': 0.4076, 'learning_rate': 3.448353168269986e-07, 'rewards/chosen': -0.159589022397995, 'rewards/rejected': -1.3050183057785034, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1454293727874756, 'policy_logps/rejected': -391.7565612792969, 'policy_logps/chosen': -495.21588134765625, 'referece_logps/rejected': -378.7063903808594, 'referece_logps/chosen': -493.6199951171875, 'logits/rejected': -0.3562418520450592, 'logits/chosen': -0.4199051260948181, 'epoch': 4.41}


 74%|███████▎  | 11848/16104 [54:44:44<21:22:41, 18.08s/it]
{'loss': 0.4199, 'learning_rate': 3.4453147360960355e-07, 'rewards/chosen': 0.059559062123298645, 'rewards/rejected': -1.681066632270813, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7406256198883057, 'policy_logps/rejected': -505.5455627441406, 'policy_logps/chosen': -450.21807861328125, 'referece_logps/rejected': -488.7348327636719, 'referece_logps/chosen': -450.8136901855469, 'logits/rejected': -0.2628840208053589, 'logits/chosen': -0.2933027446269989, 'epoch': 4.41}


 74%|███████▎  | 11850/16104 [54:45:20<21:14:59, 17.98s/it]

 74%|███████▎  | 11851/16104 [54:45:33<19:25:00, 16.44s/it]
{'loss': 0.4334, 'learning_rate': 3.440759076604046e-07, 'rewards/chosen': -0.39690321683883667, 'rewards/rejected': -1.3286869525909424, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9317837953567505, 'policy_logps/rejected': -330.4437561035156, 'policy_logps/chosen': -418.5179748535156, 'referece_logps/rejected': -317.15692138671875, 'referece_logps/chosen': -414.5489807128906, 'logits/rejected': -0.16723687946796417, 'logits/chosen': -0.20523826777935028, 'epoch': 4.42}


 74%|███████▎  | 11853/16104 [54:46:03<18:17:00, 15.48s/it]

 74%|███████▎  | 11854/16104 [54:46:14<16:40:54, 14.13s/it]

 74%|███████▎  | 11855/16104 [54:46:35<19:09:19, 16.23s/it]

 74%|███████▎  | 11856/16104 [54:46:49<18:31:40, 15.70s/it]

 74%|███████▎  | 11857/16104 [54:47:10<20:19:36, 17.23s/it]

 74%|███████▎  | 11858/16104 [54:47:21<18:03:39, 15.31s/it]

 74%|███████▎  | 11859/16104 [54:47:35<17:44:34, 15.05s/it]

 74%|███████▎  | 11860/16104 [54:47:48<16:48:42, 14.26s/it]

 74%|███████▎  | 11861/16104 [54:48:00<15:59:28, 13.57s/it]

 74%|███████▎  | 11862/16104 [54:48:13<15:52:05, 13.47s/it]
{'loss': 0.3191, 'learning_rate': 3.424075435044442e-07, 'rewards/chosen': -0.4518851339817047, 'rewards/rejected': -1.8151891231536865, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3633038997650146, 'policy_logps/rejected': -364.01861572265625, 'policy_logps/chosen': -294.52996826171875, 'referece_logps/rejected': -345.86669921875, 'referece_logps/chosen': -290.0111389160156, 'logits/rejected': -0.41213667392730713, 'logits/chosen': -0.33528226613998413, 'epoch': 4.42}


 74%|███████▎  | 11864/16104 [54:48:47<18:28:44, 15.69s/it]

 74%|███████▎  | 11865/16104 [54:49:05<19:09:37, 16.27s/it]

 74%|███████▎  | 11866/16104 [54:49:16<17:18:13, 14.70s/it]
{'loss': 0.426, 'learning_rate': 3.4180166322389516e-07, 'rewards/chosen': -0.10339069366455078, 'rewards/rejected': -2.6089706420898438, 'rewards/accuracies': 1.0, 'rewards/margins': 2.505579948425293, 'policy_logps/rejected': -375.1676025390625, 'policy_logps/chosen': -395.3096008300781, 'referece_logps/rejected': -349.077880859375, 'referece_logps/chosen': -394.2756652832031, 'logits/rejected': -0.6586024165153503, 'logits/chosen': -0.4758741557598114, 'epoch': 4.42}

 74%|███████▎  | 11867/16104 [54:49:27<15:56:33, 13.55s/it]


 74%|███████▎  | 11869/16104 [54:49:49<14:27:26, 12.29s/it]

 74%|███████▎  | 11870/16104 [54:50:00<14:02:08, 11.93s/it]

 74%|███████▎  | 11871/16104 [54:50:11<13:42:06, 11.65s/it]

 74%|███████▎  | 11872/16104 [54:50:22<13:23:40, 11.39s/it]

 74%|███████▎  | 11873/16104 [54:50:33<13:19:58, 11.34s/it]
{'loss': 0.4175, 'learning_rate': 3.407423980425701e-07, 'rewards/chosen': -0.20801782608032227, 'rewards/rejected': -0.8211025595664978, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6130847334861755, 'policy_logps/rejected': -536.4920654296875, 'policy_logps/chosen': -529.8377075195312, 'referece_logps/rejected': -528.281005859375, 'referece_logps/chosen': -527.757568359375, 'logits/rejected': 0.23189598321914673, 'logits/chosen': 0.15732309222221375, 'epoch': 4.42}

 74%|███████▎  | 11874/16104 [54:50:45<13:20:00, 11.35s/it]


 74%|███████▎  | 11876/16104 [54:51:15<15:48:27, 13.46s/it]

 74%|███████▍  | 11877/16104 [54:51:32<16:57:45, 14.45s/it]

 74%|███████▍  | 11878/16104 [54:51:46<16:45:31, 14.28s/it]

 74%|███████▍  | 11879/16104 [54:52:00<16:42:39, 14.24s/it]

 74%|███████▍  | 11880/16104 [54:52:20<18:41:03, 15.92s/it]

 74%|███████▍  | 11881/16104 [54:52:39<19:57:06, 17.01s/it]

 74%|███████▍  | 11882/16104 [54:52:53<18:34:38, 15.84s/it]

 74%|███████▍  | 11883/16104 [54:53:06<17:48:06, 15.18s/it]

 74%|███████▍  | 11884/16104 [54:53:22<17:53:40, 15.27s/it]

 74%|███████▍  | 11885/16104 [54:53:33<16:37:30, 14.19s/it]
{'loss': 0.4092, 'learning_rate': 3.3892955620450314e-07, 'rewards/chosen': -0.295457661151886, 'rewards/rejected': -1.809523344039917, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5140656232833862, 'policy_logps/rejected': -432.08880615234375, 'policy_logps/chosen': -355.5251159667969, 'referece_logps/rejected': -413.9935302734375, 'referece_logps/chosen': -352.570556640625, 'logits/rejected': -0.45373934507369995, 'logits/chosen': -0.3874196708202362, 'epoch': 4.43}


 74%|███████▍  | 11887/16104 [54:53:57<15:05:20, 12.88s/it]

 74%|███████▍  | 11888/16104 [54:54:14<16:45:31, 14.31s/it]
{'loss': 0.4261, 'learning_rate': 3.3847694701597275e-07, 'rewards/chosen': -0.5664612650871277, 'rewards/rejected': -1.6493878364562988, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0829265117645264, 'policy_logps/rejected': -507.13323974609375, 'policy_logps/chosen': -480.87420654296875, 'referece_logps/rejected': -490.63934326171875, 'referece_logps/chosen': -475.20965576171875, 'logits/rejected': -0.5021462440490723, 'logits/chosen': -0.6413410902023315, 'epoch': 4.43}

 74%|███████▍  | 11889/16104 [54:54:31<17:29:40, 14.94s/it]

 74%|███████▍  | 11890/16104 [54:54:43<16:28:18, 14.07s/it]

 74%|███████▍  | 11891/16104 [54:55:03<18:44:13, 16.01s/it]


 74%|███████▍  | 11893/16104 [54:55:40<19:59:41, 17.09s/it]

 74%|███████▍  | 11894/16104 [54:55:59<20:32:59, 17.57s/it]

 74%|███████▍  | 11895/16104 [54:56:14<19:39:59, 16.82s/it]
{'loss': 0.4342, 'learning_rate': 3.374217957865959e-07, 'rewards/chosen': -0.19713184237480164, 'rewards/rejected': -1.0122122764587402, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8150803446769714, 'policy_logps/rejected': -462.2646789550781, 'policy_logps/chosen': -558.2759399414062, 'referece_logps/rejected': -452.14251708984375, 'referece_logps/chosen': -556.3046264648438, 'logits/rejected': -0.06683023273944855, 'logits/chosen': -0.17226514220237732, 'epoch': 4.43}


 74%|███████▍  | 11897/16104 [54:56:38<17:02:50, 14.59s/it]

 74%|███████▍  | 11898/16104 [54:56:51<16:11:54, 13.86s/it]
{'loss': 0.3597, 'learning_rate': 3.3696999003200053e-07, 'rewards/chosen': -0.20912645757198334, 'rewards/rejected': -1.5350158214569092, 'rewards/accuracies': 0.5, 'rewards/margins': 1.325889229774475, 'policy_logps/rejected': -510.4036560058594, 'policy_logps/chosen': -571.03173828125, 'referece_logps/rejected': -495.053466796875, 'referece_logps/chosen': -568.9404907226562, 'logits/rejected': -0.2132672667503357, 'logits/chosen': -0.11542463302612305, 'epoch': 4.43}


 74%|███████▍  | 11900/16104 [54:57:20<16:56:18, 14.50s/it]
{'loss': 0.4638, 'learning_rate': 3.3666892028918537e-07, 'rewards/chosen': -0.20327092707157135, 'rewards/rejected': -1.0919359922409058, 'rewards/accuracies': 0.75, 'rewards/margins': 0.888664960861206, 'policy_logps/rejected': -399.2520446777344, 'policy_logps/chosen': -585.754150390625, 'referece_logps/rejected': -388.33270263671875, 'referece_logps/chosen': -583.721435546875, 'logits/rejected': -0.12356449663639069, 'logits/chosen': -0.07181145250797272, 'epoch': 4.43}


 74%|███████▍  | 11902/16104 [54:57:47<16:23:04, 14.04s/it]

 74%|███████▍  | 11903/16104 [54:58:06<18:18:36, 15.69s/it]

 74%|███████▍  | 11904/16104 [54:58:23<18:37:18, 15.96s/it]

 74%|███████▍  | 11905/16104 [54:58:34<17:06:01, 14.66s/it]

 74%|███████▍  | 11906/16104 [54:58:55<19:09:35, 16.43s/it]
{'loss': 0.3923, 'learning_rate': 3.357663552457282e-07, 'rewards/chosen': 0.2721431851387024, 'rewards/rejected': -2.5049893856048584, 'rewards/accuracies': 1.0, 'rewards/margins': 2.777132511138916, 'policy_logps/rejected': -372.727783203125, 'policy_logps/chosen': -672.436279296875, 'referece_logps/rejected': -347.6778259277344, 'referece_logps/chosen': -675.15771484375, 'logits/rejected': -0.03972679004073143, 'logits/chosen': -0.260223388671875, 'epoch': 4.44}


 74%|███████▍  | 11908/16104 [54:59:26<19:05:04, 16.37s/it]
{'loss': 0.4844, 'learning_rate': 3.354657151218404e-07, 'rewards/chosen': -0.3257139325141907, 'rewards/rejected': -1.085484266281128, 'rewards/accuracies': 0.75, 'rewards/margins': 0.759770393371582, 'policy_logps/rejected': -585.8973999023438, 'policy_logps/chosen': -489.6893615722656, 'referece_logps/rejected': -575.0426025390625, 'referece_logps/chosen': -486.4322204589844, 'logits/rejected': -0.14785651862621307, 'logits/chosen': -0.013592749834060669, 'epoch': 4.44}


 74%|███████▍  | 11910/16104 [54:59:54<17:56:00, 15.39s/it]

 74%|███████▍  | 11911/16104 [55:00:14<19:34:52, 16.81s/it]

 74%|███████▍  | 11912/16104 [55:00:33<20:21:35, 17.48s/it]
{'loss': 0.4339, 'learning_rate': 3.3486475750186206e-07, 'rewards/chosen': -0.14166755974292755, 'rewards/rejected': -1.9521431922912598, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8104755878448486, 'policy_logps/rejected': -520.367919921875, 'policy_logps/chosen': -353.69293212890625, 'referece_logps/rejected': -500.8465576171875, 'referece_logps/chosen': -352.2762756347656, 'logits/rejected': -0.8580553531646729, 'logits/chosen': -0.5294890999794006, 'epoch': 4.44}


 74%|███████▍  | 11914/16104 [55:01:11<21:17:31, 18.29s/it]

 74%|███████▍  | 11915/16104 [55:01:25<19:41:01, 16.92s/it]
{'loss': 0.3839, 'learning_rate': 3.344143217776318e-07, 'rewards/chosen': -0.3220449686050415, 'rewards/rejected': -2.025285482406616, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7032403945922852, 'policy_logps/rejected': -579.6553344726562, 'policy_logps/chosen': -482.6996765136719, 'referece_logps/rejected': -559.4025268554688, 'referece_logps/chosen': -479.4792175292969, 'logits/rejected': -0.6900258660316467, 'logits/chosen': -0.6088835000991821, 'epoch': 4.44}

 74%|███████▍  | 11916/16104 [55:01:36<17:39:27, 15.18s/it]


 74%|███████▍  | 11918/16104 [55:02:14<20:03:37, 17.25s/it]
{'loss': 0.4373, 'learning_rate': 3.3396412837055124e-07, 'rewards/chosen': -0.03401871398091316, 'rewards/rejected': -1.4809602499008179, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4469414949417114, 'policy_logps/rejected': -317.9359436035156, 'policy_logps/chosen': -416.71441650390625, 'referece_logps/rejected': -303.1263732910156, 'referece_logps/chosen': -416.374267578125, 'logits/rejected': -0.3388109505176544, 'logits/chosen': -0.5028998255729675, 'epoch': 4.44}


 74%|███████▍  | 11920/16104 [55:02:49<20:19:35, 17.49s/it]

 74%|███████▍  | 11921/16104 [55:03:10<21:36:22, 18.59s/it]

 74%|███████▍  | 11922/16104 [55:03:26<20:41:19, 17.81s/it]
{'loss': 0.3967, 'learning_rate': 3.333642477155023e-07, 'rewards/chosen': -0.7423006296157837, 'rewards/rejected': -1.5368338823318481, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7945331931114197, 'policy_logps/rejected': -440.751220703125, 'policy_logps/chosen': -369.57196044921875, 'referece_logps/rejected': -425.38287353515625, 'referece_logps/chosen': -362.1488952636719, 'logits/rejected': -0.3558630049228668, 'logits/chosen': -0.3243134021759033, 'epoch': 4.44}

 74%|███████▍  | 11923/16104 [55:03:44<20:32:37, 17.69s/it]


 74%|███████▍  | 11925/16104 [55:04:14<19:30:28, 16.81s/it]
{'loss': 0.3372, 'learning_rate': 3.3291462035234e-07, 'rewards/chosen': -0.3399254083633423, 'rewards/rejected': -2.4229495525360107, 'rewards/accuracies': 1.0, 'rewards/margins': 2.083024024963379, 'policy_logps/rejected': -285.59735107421875, 'policy_logps/chosen': -415.40802001953125, 'referece_logps/rejected': -261.3678894042969, 'referece_logps/chosen': -412.0087585449219, 'logits/rejected': 0.14280125498771667, 'logits/chosen': 0.2681121528148651, 'epoch': 4.44}


 74%|███████▍  | 11927/16104 [55:04:45<18:40:07, 16.09s/it]

 74%|███████▍  | 11928/16104 [55:05:03<19:12:53, 16.56s/it]

 74%|███████▍  | 11929/16104 [55:05:19<19:01:52, 16.41s/it]

 74%|███████▍  | 11930/16104 [55:05:33<18:16:04, 15.76s/it]
{'loss': 0.4056, 'learning_rate': 3.3216578119039796e-07, 'rewards/chosen': -1.0921611785888672, 'rewards/rejected': -2.061169147491455, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9690080285072327, 'policy_logps/rejected': -421.64080810546875, 'policy_logps/chosen': -359.27215576171875, 'referece_logps/rejected': -401.02911376953125, 'referece_logps/chosen': -348.35052490234375, 'logits/rejected': -0.15893806517124176, 'logits/chosen': -0.037997305393218994, 'epoch': 4.44}

 74%|███████▍  | 11931/16104 [55:05:54<20:00:10, 17.26s/it]


 74%|███████▍  | 11933/16104 [55:06:36<21:57:44, 18.96s/it]

 74%|███████▍  | 11934/16104 [55:06:55<22:15:13, 19.21s/it]
{'loss': 0.4349, 'learning_rate': 3.315671960960238e-07, 'rewards/chosen': -0.11890687793493271, 'rewards/rejected': -0.9830725789070129, 'rewards/accuracies': 0.625, 'rewards/margins': 0.864165723323822, 'policy_logps/rejected': -374.855224609375, 'policy_logps/chosen': -459.8701171875, 'referece_logps/rejected': -365.02447509765625, 'referece_logps/chosen': -458.6810607910156, 'logits/rejected': -0.30412420630455017, 'logits/chosen': -0.24614962935447693, 'epoch': 4.45}

 74%|███████▍  | 11935/16104 [55:07:16<22:37:40, 19.54s/it]


 74%|███████▍  | 11937/16104 [55:07:46<20:10:42, 17.43s/it]
{'loss': 0.4051, 'learning_rate': 3.3111854116669933e-07, 'rewards/chosen': 0.19059276580810547, 'rewards/rejected': -0.8444318771362305, 'rewards/accuracies': 0.625, 'rewards/margins': 1.035024642944336, 'policy_logps/rejected': -407.0368957519531, 'policy_logps/chosen': -415.70416259765625, 'referece_logps/rejected': -398.5925598144531, 'referece_logps/chosen': -417.610107421875, 'logits/rejected': 0.45729926228523254, 'logits/chosen': 0.46416813135147095, 'epoch': 4.45}

 74%|███████▍  | 11938/16104 [55:08:04<20:36:01, 17.80s/it]


 74%|███████▍  | 11940/16104 [55:08:42<20:59:56, 18.15s/it]
{'loss': 0.3051, 'learning_rate': 3.306701297544062e-07, 'rewards/chosen': -0.5949031710624695, 'rewards/rejected': -2.851043462753296, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2561404705047607, 'policy_logps/rejected': -257.3460998535156, 'policy_logps/chosen': -437.7876892089844, 'referece_logps/rejected': -228.83567810058594, 'referece_logps/chosen': -431.83868408203125, 'logits/rejected': -0.9867103099822998, 'logits/chosen': -0.9664291143417358, 'epoch': 4.45}

 74%|███████▍  | 11941/16104 [55:08:54<18:55:09, 16.36s/it]

 74%|███████▍  | 11942/16104 [55:09:10<18:51:49, 16.32s/it]

 74%|███████▍  | 11943/16104 [55:09:28<19:30:16, 16.87s/it]

 74%|███████▍  | 11944/16104 [55:09:42<18:30:33, 16.02s/it]


 74%|███████▍  | 11946/16104 [55:10:13<18:04:52, 15.65s/it]

 74%|███████▍  | 11947/16104 [55:10:31<18:46:24, 16.26s/it]

 74%|███████▍  | 11948/16104 [55:10:51<20:03:27, 17.37s/it]
{'loss': 0.4277, 'learning_rate': 3.2947555775723325e-07, 'rewards/chosen': -0.567560613155365, 'rewards/rejected': -1.9146016836166382, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3470410108566284, 'policy_logps/rejected': -508.9783630371094, 'policy_logps/chosen': -442.8616638183594, 'referece_logps/rejected': -489.83233642578125, 'referece_logps/chosen': -437.18603515625, 'logits/rejected': -0.8038086295127869, 'logits/chosen': -0.7177248001098633, 'epoch': 4.45}

 74%|███████▍  | 11949/16104 [55:11:10<20:48:41, 18.03s/it]

 74%|███████▍  | 11950/16104 [55:11:28<20:51:29, 18.08s/it]

 74%|███████▍  | 11951/16104 [55:11:47<20:58:17, 18.18s/it]

 74%|███████▍  | 11952/16104 [55:11:59<18:55:50, 16.41s/it]

 74%|███████▍  | 11953/16104 [55:12:13<18:00:34, 15.62s/it]


 74%|███████▍  | 11955/16104 [55:12:35<15:21:10, 13.32s/it]

 74%|███████▍  | 11956/16104 [55:12:47<14:58:00, 12.99s/it]
{'loss': 0.5604, 'learning_rate': 3.2828272168994677e-07, 'rewards/chosen': -0.5856149196624756, 'rewards/rejected': -0.38818496465682983, 'rewards/accuracies': 0.5, 'rewards/margins': -0.1974300593137741, 'policy_logps/rejected': -395.07171630859375, 'policy_logps/chosen': -543.4297485351562, 'referece_logps/rejected': -391.18988037109375, 'referece_logps/chosen': -537.5735473632812, 'logits/rejected': -0.39973506331443787, 'logits/chosen': -0.5299389362335205, 'epoch': 4.45}


 74%|███████▍  | 11958/16104 [55:13:17<15:52:09, 13.78s/it]
{'loss': 0.4644, 'learning_rate': 3.279847842741613e-07, 'rewards/chosen': -0.20580579340457916, 'rewards/rejected': -1.6316354274749756, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4258296489715576, 'policy_logps/rejected': -491.3849792480469, 'policy_logps/chosen': -449.6648254394531, 'referece_logps/rejected': -475.0686340332031, 'referece_logps/chosen': -447.6067810058594, 'logits/rejected': -0.568387508392334, 'logits/chosen': -0.4879951477050781, 'epoch': 4.46}


 74%|███████▍  | 11960/16104 [55:13:54<18:29:42, 16.07s/it]

 74%|███████▍  | 11961/16104 [55:14:12<19:12:23, 16.69s/it]

 74%|███████▍  | 11962/16104 [55:14:32<20:18:03, 17.64s/it]

 74%|███████▍  | 11963/16104 [55:14:50<20:25:28, 17.76s/it]
{'loss': 0.3612, 'learning_rate': 3.2724041656386204e-07, 'rewards/chosen': -0.7309364080429077, 'rewards/rejected': -2.698557138442993, 'rewards/accuracies': 0.875, 'rewards/margins': 1.967620849609375, 'policy_logps/rejected': -497.3398742675781, 'policy_logps/chosen': -454.17724609375, 'referece_logps/rejected': -470.35430908203125, 'referece_logps/chosen': -446.86785888671875, 'logits/rejected': -0.7133460640907288, 'logits/chosen': -0.669540286064148, 'epoch': 4.46}

 74%|███████▍  | 11964/16104 [55:15:11<21:29:49, 18.69s/it]


 74%|███████▍  | 11966/16104 [55:15:45<20:59:44, 18.27s/it]
{'loss': 0.3877, 'learning_rate': 3.2679412246141527e-07, 'rewards/chosen': -0.6095123887062073, 'rewards/rejected': -1.8296092748641968, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2200969457626343, 'policy_logps/rejected': -411.1902160644531, 'policy_logps/chosen': -498.43115234375, 'referece_logps/rejected': -392.8941345214844, 'referece_logps/chosen': -492.33599853515625, 'logits/rejected': 0.013355962932109833, 'logits/chosen': -0.02958996407687664, 'epoch': 4.46}

 74%|███████▍  | 11967/16104 [55:16:07<22:14:40, 19.36s/it]


 74%|███████▍  | 11969/16104 [55:16:48<22:51:43, 19.90s/it]

 74%|███████▍  | 11970/16104 [55:17:02<20:55:56, 18.23s/it]
{'loss': 0.3872, 'learning_rate': 3.261994449395201e-07, 'rewards/chosen': -0.17363512516021729, 'rewards/rejected': -1.980036735534668, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8064016103744507, 'policy_logps/rejected': -321.6831359863281, 'policy_logps/chosen': -428.05963134765625, 'referece_logps/rejected': -301.8827819824219, 'referece_logps/chosen': -426.32330322265625, 'logits/rejected': 0.3684215843677521, 'logits/chosen': 0.49876198172569275, 'epoch': 4.46}

 74%|███████▍  | 11971/16104 [55:17:21<21:17:30, 18.55s/it]

 74%|███████▍  | 11972/16104 [55:17:39<20:52:31, 18.19s/it]


 74%|███████▍  | 11974/16104 [55:18:12<19:38:57, 17.13s/it]
{'loss': 0.3731, 'learning_rate': 3.2560520352056033e-07, 'rewards/chosen': -0.45304396748542786, 'rewards/rejected': -2.156984806060791, 'rewards/accuracies': 1.0, 'rewards/margins': 1.703940749168396, 'policy_logps/rejected': -384.18682861328125, 'policy_logps/chosen': -363.02386474609375, 'referece_logps/rejected': -362.6169738769531, 'referece_logps/chosen': -358.493408203125, 'logits/rejected': -1.0050861835479736, 'logits/chosen': -1.1202946901321411, 'epoch': 4.46}


 74%|███████▍  | 11976/16104 [55:18:42<18:28:13, 16.11s/it]

 74%|███████▍  | 11977/16104 [55:18:54<16:56:25, 14.78s/it]

 74%|███████▍  | 11978/16104 [55:19:08<16:45:03, 14.62s/it]

 74%|███████▍  | 11979/16104 [55:19:26<18:00:01, 15.71s/it]
{'loss': 0.4168, 'learning_rate': 3.248630156025158e-07, 'rewards/chosen': -0.32058507204055786, 'rewards/rejected': -1.0905307531356812, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7699457406997681, 'policy_logps/rejected': -330.9932861328125, 'policy_logps/chosen': -377.41192626953125, 'referece_logps/rejected': -320.0879821777344, 'referece_logps/chosen': -374.2060546875, 'logits/rejected': -0.5605631470680237, 'logits/chosen': -0.6452373266220093, 'epoch': 4.46}

 74%|███████▍  | 11980/16104 [55:19:39<16:47:21, 14.66s/it]

 74%|███████▍  | 11981/16104 [55:19:58<18:35:20, 16.23s/it]

 74%|███████▍  | 11982/16104 [55:20:13<17:54:46, 15.64s/it]


 74%|███████▍  | 11984/16104 [55:20:48<19:05:03, 16.68s/it]

 74%|███████▍  | 11985/16104 [55:21:04<18:53:23, 16.51s/it]

 74%|███████▍  | 11986/16104 [55:21:20<18:41:46, 16.34s/it]

 74%|███████▍  | 11987/16104 [55:21:40<19:55:13, 17.42s/it]
{'loss': 0.435, 'learning_rate': 3.2367693539129015e-07, 'rewards/chosen': -1.485733151435852, 'rewards/rejected': -3.2310805320739746, 'rewards/accuracies': 0.875, 'rewards/margins': 1.745347499847412, 'policy_logps/rejected': -556.7344360351562, 'policy_logps/chosen': -438.7335205078125, 'referece_logps/rejected': -524.4236450195312, 'referece_logps/chosen': -423.8761901855469, 'logits/rejected': 0.339578777551651, 'logits/chosen': 0.33546122908592224, 'epoch': 4.47}

 74%|███████▍  | 11988/16104 [55:21:57<19:45:11, 17.28s/it]


 74%|███████▍  | 11990/16104 [55:22:32<19:45:13, 17.29s/it]
{'loss': 0.4119, 'learning_rate': 3.232326065620361e-07, 'rewards/chosen': 0.49243226647377014, 'rewards/rejected': -2.0633459091186523, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5557780265808105, 'policy_logps/rejected': -488.0281677246094, 'policy_logps/chosen': -487.46319580078125, 'referece_logps/rejected': -467.39471435546875, 'referece_logps/chosen': -492.3874816894531, 'logits/rejected': -0.18307122588157654, 'logits/chosen': -0.16051645576953888, 'epoch': 4.47}


 74%|███████▍  | 11992/16104 [55:22:58<17:24:04, 15.23s/it]

 74%|███████▍  | 11993/16104 [55:23:14<17:38:44, 15.45s/it]

 74%|███████▍  | 11994/16104 [55:23:33<18:35:48, 16.29s/it]
{'loss': 0.3957, 'learning_rate': 3.2264055142124947e-07, 'rewards/chosen': -0.67048579454422, 'rewards/rejected': -2.4747729301452637, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8042871952056885, 'policy_logps/rejected': -388.01025390625, 'policy_logps/chosen': -359.3861999511719, 'referece_logps/rejected': -363.26251220703125, 'referece_logps/chosen': -352.6813049316406, 'logits/rejected': 0.07057541608810425, 'logits/chosen': 0.23767057061195374, 'epoch': 4.47}


 74%|███████▍  | 11996/16104 [55:24:06<18:57:22, 16.61s/it]

 74%|███████▍  | 11997/16104 [55:24:27<20:09:11, 17.67s/it]

 75%|███████▍  | 11998/16104 [55:24:42<19:27:41, 17.06s/it]

 75%|███████▍  | 11999/16104 [55:24:54<17:41:03, 15.51s/it]
{'loss': 0.5573, 'learning_rate': 3.2190109904907847e-07, 'rewards/chosen': -0.13928785920143127, 'rewards/rejected': -1.337256908416748, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1979689598083496, 'policy_logps/rejected': -490.3516845703125, 'policy_logps/chosen': -555.2250366210938, 'referece_logps/rejected': -476.9791259765625, 'referece_logps/chosen': -553.8321533203125, 'logits/rejected': -0.05952239781618118, 'logits/chosen': -0.08299396932125092, 'epoch': 4.47}

 75%|███████▍  | 12000/16104 [55:25:14<19:06:14, 16.76s/it]

 75%|███████▍  | 12001/16104 [55:25:43<23:22:17, 20.51s/it]

 75%|███████▍  | 12002/16104 [55:25:58<21:23:34, 18.77s/it]


 75%|███████▍  | 12004/16104 [55:26:29<19:51:31, 17.44s/it]
{'loss': 0.4769, 'learning_rate': 3.21162332434617e-07, 'rewards/chosen': -0.6123037338256836, 'rewards/rejected': -1.3762985467910767, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7639948129653931, 'policy_logps/rejected': -456.136962890625, 'policy_logps/chosen': -454.3397216796875, 'referece_logps/rejected': -442.3740234375, 'referece_logps/chosen': -448.2166748046875, 'logits/rejected': 0.3160405158996582, 'logits/chosen': 0.49038833379745483, 'epoch': 4.47}

 75%|███████▍  | 12005/16104 [55:26:46<19:51:01, 17.43s/it]

 75%|███████▍  | 12006/16104 [55:27:06<20:34:22, 18.07s/it]

 75%|███████▍  | 12007/16104 [55:27:28<21:53:59, 19.24s/it]


 75%|███████▍  | 12009/16104 [55:28:01<20:16:51, 17.83s/it]

 75%|███████▍  | 12010/16104 [55:28:13<18:14:34, 16.04s/it]

 75%|███████▍  | 12011/16104 [55:28:33<19:32:25, 17.19s/it]
{'loss': 0.3761, 'learning_rate': 3.201292126696901e-07, 'rewards/chosen': -0.2811970114707947, 'rewards/rejected': -2.7384393215179443, 'rewards/accuracies': 1.0, 'rewards/margins': 2.457242250442505, 'policy_logps/rejected': -531.4779663085938, 'policy_logps/chosen': -419.384033203125, 'referece_logps/rejected': -504.0936279296875, 'referece_logps/chosen': -416.57208251953125, 'logits/rejected': 0.17762623727321625, 'logits/chosen': 0.291618674993515, 'epoch': 4.48}


 75%|███████▍  | 12013/16104 [55:29:04<18:46:28, 16.52s/it]

 75%|███████▍  | 12014/16104 [55:29:21<18:48:48, 16.56s/it]

 75%|███████▍  | 12015/16104 [55:29:33<17:17:20, 15.22s/it]

 75%|███████▍  | 12016/16104 [55:29:46<16:41:38, 14.70s/it]
{'loss': 0.4753, 'learning_rate': 3.1939209492062103e-07, 'rewards/chosen': -0.5689040422439575, 'rewards/rejected': -2.1240785121917725, 'rewards/accuracies': 0.875, 'rewards/margins': 1.555174469947815, 'policy_logps/rejected': -446.2249755859375, 'policy_logps/chosen': -374.3785400390625, 'referece_logps/rejected': -424.98419189453125, 'referece_logps/chosen': -368.68951416015625, 'logits/rejected': -0.6715468168258667, 'logits/chosen': -0.40969008207321167, 'epoch': 4.48}

 75%|███████▍  | 12017/16104 [55:29:58<15:30:42, 13.66s/it]

 75%|███████▍  | 12018/16104 [55:30:15<16:52:56, 14.87s/it]


 75%|███████▍  | 12020/16104 [55:30:45<16:30:40, 14.55s/it]
{'loss': 0.3051, 'learning_rate': 3.1880289625804546e-07, 'rewards/chosen': -0.4478260278701782, 'rewards/rejected': -1.614547610282898, 'rewards/accuracies': 0.5, 'rewards/margins': 1.1667217016220093, 'policy_logps/rejected': -413.8719787597656, 'policy_logps/chosen': -468.5026550292969, 'referece_logps/rejected': -397.72650146484375, 'referece_logps/chosen': -464.0244140625, 'logits/rejected': -0.7254494428634644, 'logits/chosen': -0.4792618751525879, 'epoch': 4.48}

 75%|███████▍  | 12021/16104 [55:30:58<16:02:46, 14.15s/it]

 75%|███████▍  | 12022/16104 [55:31:18<17:51:56, 15.76s/it]

 75%|███████▍  | 12023/16104 [55:31:30<16:49:10, 14.84s/it]

 75%|███████▍  | 12024/16104 [55:31:44<16:30:06, 14.56s/it]

 75%|███████▍  | 12025/16104 [55:31:58<16:08:18, 14.24s/it]

 75%|███████▍  | 12026/16104 [55:32:14<16:47:34, 14.82s/it]


 75%|███████▍  | 12028/16104 [55:32:41<15:49:06, 13.97s/it]
{'loss': 0.3949, 'learning_rate': 3.17625821984533e-07, 'rewards/chosen': 0.10245111584663391, 'rewards/rejected': -0.9558141231536865, 'rewards/accuracies': 0.875, 'rewards/margins': 1.058265209197998, 'policy_logps/rejected': -436.50286865234375, 'policy_logps/chosen': -480.10009765625, 'referece_logps/rejected': -426.9447326660156, 'referece_logps/chosen': -481.12457275390625, 'logits/rejected': -0.18503384292125702, 'logits/chosen': -0.15916885435581207, 'epoch': 4.48}

 75%|███████▍  | 12029/16104 [55:32:56<16:05:59, 14.22s/it]

 75%|███████▍  | 12030/16104 [55:33:15<17:54:55, 15.83s/it]

 75%|███████▍  | 12031/16104 [55:33:27<16:32:02, 14.61s/it]

 75%|███████▍  | 12032/16104 [55:33:42<16:35:42, 14.67s/it]

 75%|███████▍  | 12033/16104 [55:34:04<19:04:17, 16.87s/it]

 75%|███████▍  | 12034/16104 [55:34:24<19:59:07, 17.68s/it]


 75%|███████▍  | 12036/16104 [55:34:55<18:53:06, 16.71s/it]
{'loss': 0.3545, 'learning_rate': 3.1645051431884937e-07, 'rewards/chosen': -0.6700939536094666, 'rewards/rejected': -1.7805061340332031, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1104121208190918, 'policy_logps/rejected': -375.6092224121094, 'policy_logps/chosen': -516.032958984375, 'referece_logps/rejected': -357.8040771484375, 'referece_logps/chosen': -509.3320007324219, 'logits/rejected': -0.11170905828475952, 'logits/chosen': -0.13171547651290894, 'epoch': 4.48}

 75%|███████▍  | 12037/16104 [55:35:14<19:53:31, 17.61s/it]

 75%|███████▍  | 12038/16104 [55:35:34<20:39:55, 18.30s/it]

 75%|███████▍  | 12039/16104 [55:35:46<18:16:11, 16.18s/it]

 75%|███████▍  | 12040/16104 [55:35:56<16:27:15, 14.58s/it]

 75%|███████▍  | 12041/16104 [55:36:08<15:30:27, 13.74s/it]

 75%|███████▍  | 12042/16104 [55:36:20<14:47:52, 13.11s/it]

 75%|███████▍  | 12043/16104 [55:36:42<17:40:56, 15.68s/it]


 75%|███████▍  | 12045/16104 [55:37:09<16:52:19, 14.96s/it]
{'loss': 0.3551, 'learning_rate': 3.151304086318032e-07, 'rewards/chosen': -0.4378858506679535, 'rewards/rejected': -1.3338052034378052, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8959194421768188, 'policy_logps/rejected': -326.1325988769531, 'policy_logps/chosen': -390.3079833984375, 'referece_logps/rejected': -312.7945556640625, 'referece_logps/chosen': -385.9291076660156, 'logits/rejected': -0.13990245759487152, 'logits/chosen': -0.14482703804969788, 'epoch': 4.49}

 75%|███████▍  | 12046/16104 [55:37:20<15:32:25, 13.79s/it]

 75%|███████▍  | 12047/16104 [55:37:38<16:49:19, 14.93s/it]

 75%|███████▍  | 12048/16104 [55:37:50<15:46:20, 14.00s/it]

 75%|███████▍  | 12049/16104 [55:38:04<15:49:05, 14.04s/it]


 75%|███████▍  | 12051/16104 [55:38:43<18:52:57, 16.77s/it]
{'loss': 0.5046, 'learning_rate': 3.1425158459560575e-07, 'rewards/chosen': -0.4614145755767822, 'rewards/rejected': -1.1895614862442017, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7281469702720642, 'policy_logps/rejected': -378.0429992675781, 'policy_logps/chosen': -390.64593505859375, 'referece_logps/rejected': -366.1473693847656, 'referece_logps/chosen': -386.0317687988281, 'logits/rejected': 0.1937190145254135, 'logits/chosen': 0.09801682084798813, 'epoch': 4.49}


 75%|███████▍  | 12053/16104 [55:39:13<17:27:44, 15.52s/it]

 75%|███████▍  | 12054/16104 [55:39:31<18:17:23, 16.26s/it]
{'loss': 0.4085, 'learning_rate': 3.138125469841181e-07, 'rewards/chosen': 0.03996676951646805, 'rewards/rejected': -1.6025570631027222, 'rewards/accuracies': 1.0, 'rewards/margins': 1.642524003982544, 'policy_logps/rejected': -375.65460205078125, 'policy_logps/chosen': -583.029052734375, 'referece_logps/rejected': -359.6289978027344, 'referece_logps/chosen': -583.4287719726562, 'logits/rejected': -0.18348661065101624, 'logits/chosen': -0.41852858662605286, 'epoch': 4.49}

 75%|███████▍  | 12055/16104 [55:39:43<16:46:30, 14.91s/it]

 75%|███████▍  | 12056/16104 [55:39:57<16:25:19, 14.60s/it]


 75%|███████▍  | 12058/16104 [55:40:35<19:18:01, 17.17s/it]

 75%|███████▍  | 12059/16104 [55:40:55<20:14:30, 18.01s/it]

 75%|███████▍  | 12060/16104 [55:41:16<20:58:53, 18.68s/it]
{'loss': 0.4166, 'learning_rate': 3.1293522137355865e-07, 'rewards/chosen': 0.30529001355171204, 'rewards/rejected': -1.5512348413467407, 'rewards/accuracies': 0.875, 'rewards/margins': 1.85652494430542, 'policy_logps/rejected': -542.9521484375, 'policy_logps/chosen': -366.0797119140625, 'referece_logps/rejected': -527.4398193359375, 'referece_logps/chosen': -369.1325988769531, 'logits/rejected': 0.2333870232105255, 'logits/chosen': 0.2595531940460205, 'epoch': 4.49}


 75%|███████▍  | 12062/16104 [55:41:44<17:58:56, 16.02s/it]

 75%|███████▍  | 12063/16104 [55:42:04<19:15:09, 17.15s/it]
{'loss': 0.3868, 'learning_rate': 3.124969336938914e-07, 'rewards/chosen': -0.4822610318660736, 'rewards/rejected': -2.0615522861480713, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5792913436889648, 'policy_logps/rejected': -414.0999755859375, 'policy_logps/chosen': -390.5345153808594, 'referece_logps/rejected': -393.48443603515625, 'referece_logps/chosen': -385.7119445800781, 'logits/rejected': 0.22604870796203613, 'logits/chosen': 0.07772418856620789, 'epoch': 4.49}


 75%|███████▍  | 12065/16104 [55:42:42<20:14:21, 18.04s/it]

 75%|███████▍  | 12066/16104 [55:43:04<21:36:44, 19.27s/it]
{'loss': 0.4624, 'learning_rate': 3.1205889631075e-07, 'rewards/chosen': -0.8115200400352478, 'rewards/rejected': -1.3224064111709595, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5108863115310669, 'policy_logps/rejected': -530.4505615234375, 'policy_logps/chosen': -562.64794921875, 'referece_logps/rejected': -517.2265625, 'referece_logps/chosen': -554.5327758789062, 'logits/rejected': 0.30851420760154724, 'logits/chosen': 0.182810977101326, 'epoch': 4.5}

 75%|███████▍  | 12067/16104 [55:43:22<21:13:58, 18.93s/it]

 75%|███████▍  | 12068/16104 [55:43:33<18:35:54, 16.59s/it]

 75%|███████▍  | 12069/16104 [55:43:51<18:59:40, 16.95s/it]

 75%|███████▍  | 12070/16104 [55:44:03<17:19:10, 15.46s/it]

 75%|███████▍  | 12071/16104 [55:44:22<18:41:01, 16.68s/it]

 75%|███████▍  | 12072/16104 [55:44:35<17:29:34, 15.62s/it]


 75%|███████▍  | 12074/16104 [55:45:18<20:49:09, 18.60s/it]
{'loss': 0.3154, 'learning_rate': 3.1089202150678397e-07, 'rewards/chosen': -0.6352593898773193, 'rewards/rejected': -2.5132296085357666, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8779702186584473, 'policy_logps/rejected': -556.7940673828125, 'policy_logps/chosen': -579.9479370117188, 'referece_logps/rejected': -531.6618041992188, 'referece_logps/chosen': -573.5952758789062, 'logits/rejected': 0.2188006043434143, 'logits/chosen': 0.17168214917182922, 'epoch': 4.5}

 75%|███████▍  | 12075/16104 [55:45:31<18:53:07, 16.87s/it]

 75%|███████▍  | 12076/16104 [55:45:51<19:54:11, 17.79s/it]


 75%|███████▌  | 12078/16104 [55:46:26<19:57:27, 17.85s/it]
{'loss': 0.3578, 'learning_rate': 3.103092529315686e-07, 'rewards/chosen': -0.8844559192657471, 'rewards/rejected': -1.9922969341278076, 'rewards/accuracies': 0.5, 'rewards/margins': 1.1078410148620605, 'policy_logps/rejected': -322.7587890625, 'policy_logps/chosen': -341.4110412597656, 'referece_logps/rejected': -302.8358154296875, 'referece_logps/chosen': -332.5665283203125, 'logits/rejected': -0.29512837529182434, 'logits/chosen': -0.19698834419250488, 'epoch': 4.5}

 75%|███████▌  | 12079/16104 [55:46:39<18:27:04, 16.50s/it]

 75%|███████▌  | 12080/16104 [55:46:55<18:07:28, 16.21s/it]

 75%|███████▌  | 12081/16104 [55:47:13<18:41:09, 16.72s/it]

 75%|███████▌  | 12082/16104 [55:47:33<19:45:37, 17.69s/it]

 75%|███████▌  | 12083/16104 [55:47:49<19:17:27, 17.27s/it]

 75%|███████▌  | 12084/16104 [55:48:09<20:16:52, 18.16s/it]

 75%|███████▌  | 12085/16104 [55:48:22<18:37:11, 16.68s/it]

 75%|███████▌  | 12086/16104 [55:48:33<16:41:11, 14.95s/it]

 75%|███████▌  | 12087/16104 [55:48:52<17:49:19, 15.97s/it]

 75%|███████▌  | 12088/16104 [55:49:05<16:58:55, 15.22s/it]

 75%|███████▌  | 12089/16104 [55:49:16<15:24:53, 13.82s/it]

 75%|███████▌  | 12090/16104 [55:49:27<14:25:05, 12.93s/it]


 75%|███████▌  | 12092/16104 [55:49:48<13:13:33, 11.87s/it]

 75%|███████▌  | 12093/16104 [55:50:06<15:15:54, 13.70s/it]
{'loss': 0.4658, 'learning_rate': 3.081278494893359e-07, 'rewards/chosen': -0.9995971918106079, 'rewards/rejected': -1.8488149642944336, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8492177724838257, 'policy_logps/rejected': -475.04193115234375, 'policy_logps/chosen': -393.3001708984375, 'referece_logps/rejected': -456.55377197265625, 'referece_logps/chosen': -383.3041687011719, 'logits/rejected': -0.14945892989635468, 'logits/chosen': -0.190018892288208, 'epoch': 4.51}

 75%|███████▌  | 12094/16104 [55:50:24<16:28:40, 14.79s/it]

 75%|███████▌  | 12095/16104 [55:50:41<17:14:12, 15.48s/it]


 75%|███████▌  | 12097/16104 [55:51:18<19:10:46, 17.23s/it]
{'loss': 0.3889, 'learning_rate': 3.075472046092092e-07, 'rewards/chosen': -0.35329359769821167, 'rewards/rejected': -1.8180385828018188, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4647449254989624, 'policy_logps/rejected': -372.0520935058594, 'policy_logps/chosen': -315.3941955566406, 'referece_logps/rejected': -353.8717041015625, 'referece_logps/chosen': -311.86126708984375, 'logits/rejected': -0.6034896373748779, 'logits/chosen': -0.46312329173088074, 'epoch': 4.51}

 75%|███████▌  | 12098/16104 [55:51:38<19:59:42, 17.97s/it]


 75%|███████▌  | 12100/16104 [55:52:14<20:04:24, 18.05s/it]
{'loss': 0.461, 'learning_rate': 3.0711201504354623e-07, 'rewards/chosen': -0.8149943351745605, 'rewards/rejected': -1.977555751800537, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1625615358352661, 'policy_logps/rejected': -247.30992126464844, 'policy_logps/chosen': -377.7137451171875, 'referece_logps/rejected': -227.53436279296875, 'referece_logps/chosen': -369.56378173828125, 'logits/rejected': -0.6352776885032654, 'logits/chosen': -0.6830607652664185, 'epoch': 4.51}

 75%|███████▌  | 12101/16104 [55:52:31<19:42:43, 17.73s/it]

 75%|███████▌  | 12102/16104 [55:52:49<19:42:38, 17.73s/it]

 75%|███████▌  | 12103/16104 [55:53:02<18:14:18, 16.41s/it]

 75%|███████▌  | 12104/16104 [55:53:19<18:21:33, 16.52s/it]

 75%|███████▌  | 12105/16104 [55:53:39<19:21:57, 17.43s/it]

 75%|███████▌  | 12106/16104 [55:53:52<17:58:12, 16.18s/it]

 75%|███████▌  | 12107/16104 [55:54:11<19:04:47, 17.18s/it]


 75%|███████▌  | 12109/16104 [55:54:44<18:33:36, 16.72s/it]
{'loss': 0.4085, 'learning_rate': 3.0580796052180223e-07, 'rewards/chosen': -0.8904260396957397, 'rewards/rejected': -2.1443932056427, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2539671659469604, 'policy_logps/rejected': -403.5442199707031, 'policy_logps/chosen': -460.8374328613281, 'referece_logps/rejected': -382.10028076171875, 'referece_logps/chosen': -451.93316650390625, 'logits/rejected': -0.47231343388557434, 'logits/chosen': -0.49801796674728394, 'epoch': 4.51}

 75%|███████▌  | 12110/16104 [55:55:03<19:17:20, 17.39s/it]

 75%|███████▌  | 12111/16104 [55:55:20<19:02:31, 17.17s/it]

 75%|███████▌  | 12112/16104 [55:55:42<20:41:24, 18.66s/it]

 75%|███████▌  | 12113/16104 [55:56:04<21:44:11, 19.61s/it]

 75%|███████▌  | 12114/16104 [55:56:24<21:49:54, 19.70s/it]

 75%|███████▌  | 12115/16104 [55:56:43<21:35:24, 19.48s/it]

 75%|███████▌  | 12116/16104 [55:57:02<21:31:49, 19.44s/it]

 75%|███████▌  | 12117/16104 [55:57:22<21:45:44, 19.65s/it]

 75%|███████▌  | 12118/16104 [55:57:42<21:42:34, 19.61s/it]

 75%|███████▌  | 12119/16104 [55:58:04<22:31:58, 20.36s/it]

 75%|███████▌  | 12120/16104 [55:58:23<22:13:48, 20.09s/it]

 75%|███████▌  | 12121/16104 [55:58:36<19:45:18, 17.86s/it]

 75%|███████▌  | 12122/16104 [55:58:47<17:24:32, 15.74s/it]

 75%|███████▌  | 12123/16104 [55:58:58<15:50:47, 14.33s/it]

 75%|███████▌  | 12124/16104 [55:59:15<16:39:49, 15.07s/it]

 75%|███████▌  | 12125/16104 [55:59:27<15:36:10, 14.12s/it]

 75%|███████▌  | 12126/16104 [55:59:44<16:34:51, 15.01s/it]

 75%|███████▌  | 12127/16104 [56:00:03<18:09:28, 16.44s/it]

 75%|███████▌  | 12128/16104 [56:00:16<16:47:03, 15.20s/it]


 75%|███████▌  | 12130/16104 [56:00:41<15:14:20, 13.80s/it]

 75%|███████▌  | 12131/16104 [56:01:00<17:09:10, 15.54s/it]

 75%|███████▌  | 12132/16104 [56:01:20<18:30:20, 16.77s/it]

 75%|███████▌  | 12133/16104 [56:01:40<19:32:05, 17.71s/it]

 75%|███████▌  | 12134/16104 [56:01:53<17:58:48, 16.30s/it]

 75%|███████▌  | 12135/16104 [56:02:12<19:05:40, 17.32s/it]

 75%|███████▌  | 12136/16104 [56:02:23<16:54:10, 15.34s/it]

 75%|███████▌  | 12137/16104 [56:02:45<18:52:51, 17.13s/it]

 75%|███████▌  | 12138/16104 [56:03:02<19:04:22, 17.31s/it]

 75%|███████▌  | 12139/16104 [56:03:17<18:22:58, 16.69s/it]

 75%|███████▌  | 12140/16104 [56:03:37<19:17:59, 17.53s/it]

 75%|███████▌  | 12141/16104 [56:03:56<19:44:40, 17.94s/it]

 75%|███████▌  | 12142/16104 [56:04:16<20:29:16, 18.62s/it]

 75%|███████▌  | 12143/16104 [56:04:33<19:57:51, 18.14s/it]

 75%|███████▌  | 12144/16104 [56:04:46<18:10:30, 16.52s/it]

 75%|███████▌  | 12145/16104 [56:05:04<18:49:25, 17.12s/it]

 75%|███████▌  | 12146/16104 [56:05:21<18:37:51, 16.95s/it]

 75%|███████▌  | 12147/16104 [56:05:37<18:17:10, 16.64s/it]

 75%|███████▌  | 12148/16104 [56:05:53<18:03:51, 16.44s/it]

 75%|███████▌  | 12149/16104 [56:06:11<18:32:41, 16.88s/it]

 75%|███████▌  | 12150/16104 [56:06:27<18:20:53, 16.71s/it]

 75%|███████▌  | 12151/16104 [56:06:43<18:14:45, 16.62s/it]

 75%|███████▌  | 12152/16104 [56:07:03<19:11:53, 17.49s/it]

 75%|███████▌  | 12153/16104 [56:07:24<20:28:58, 18.66s/it]

 75%|███████▌  | 12154/16104 [56:07:44<20:53:41, 19.04s/it]

 75%|███████▌  | 12155/16104 [56:08:05<21:21:48, 19.48s/it]

 75%|███████▌  | 12156/16104 [56:08:23<21:01:41, 19.17s/it]

 75%|███████▌  | 12157/16104 [56:08:37<19:13:07, 17.53s/it]

 75%|███████▌  | 12158/16104 [56:08:56<19:47:32, 18.06s/it]

 76%|███████▌  | 12159/16104 [56:09:16<20:15:02, 18.48s/it]

 76%|███████▌  | 12160/16104 [56:09:30<18:58:39, 17.32s/it]

 76%|███████▌  | 12161/16104 [56:09:50<19:41:10, 17.97s/it]

 76%|███████▌  | 12162/16104 [56:10:08<19:49:20, 18.10s/it]

 76%|███████▌  | 12163/16104 [56:10:21<17:59:19, 16.43s/it]

 76%|███████▌  | 12164/16104 [56:10:37<18:04:04, 16.51s/it]

 76%|███████▌  | 12165/16104 [56:10:52<17:19:15, 15.83s/it]

 76%|███████▌  | 12166/16104 [56:11:08<17:36:06, 16.09s/it]

 76%|███████▌  | 12167/16104 [56:11:23<17:09:48, 15.69s/it]

 76%|███████▌  | 12168/16104 [56:11:41<17:43:22, 16.21s/it]

 76%|███████▌  | 12169/16104 [56:12:02<19:22:41, 17.73s/it]

 76%|███████▌  | 12170/16104 [56:12:23<20:29:50, 18.76s/it]

 76%|███████▌  | 12171/16104 [56:12:43<20:46:51, 19.02s/it]

 76%|███████▌  | 12172/16104 [56:12:59<19:53:15, 18.21s/it]

 76%|███████▌  | 12173/16104 [56:13:12<18:12:01, 16.67s/it]

 76%|███████▌  | 12174/16104 [56:13:26<17:29:23, 16.02s/it]

 76%|███████▌  | 12175/16104 [56:13:48<19:17:04, 17.67s/it]

 76%|███████▌  | 12176/16104 [56:14:08<19:53:22, 18.23s/it]

 76%|███████▌  | 12177/16104 [56:14:20<18:01:43, 16.53s/it]

 76%|███████▌  | 12178/16104 [56:14:35<17:27:29, 16.01s/it]

 76%|███████▌  | 12179/16104 [56:14:53<18:00:00, 16.51s/it]

 76%|███████▌  | 12180/16104 [56:15:07<17:11:45, 15.78s/it]

 76%|███████▌  | 12181/16104 [56:15:28<19:03:15, 17.49s/it]

 76%|███████▌  | 12182/16104 [56:15:50<20:35:32, 18.90s/it]

 76%|███████▌  | 12183/16104 [56:16:06<19:30:46, 17.92s/it]

 76%|███████▌  | 12184/16104 [56:16:24<19:42:57, 18.11s/it]

 76%|███████▌  | 12185/16104 [56:16:45<20:31:17, 18.85s/it]

 76%|███████▌  | 12186/16104 [56:17:02<19:54:52, 18.30s/it]

 76%|███████▌  | 12187/16104 [56:17:20<19:56:20, 18.33s/it]

 76%|███████▌  | 12188/16104 [56:17:36<19:08:35, 17.60s/it]
{'loss': 0.3793, 'learning_rate': 2.9445934346304703e-07, 'rewards/chosen': -0.07773041725158691, 'rewards/rejected': -1.8738057613372803, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7960752248764038, 'policy_logps/rejected': -382.0950927734375, 'policy_logps/chosen': -342.56915283203125, 'referece_logps/rejected': -363.35699462890625, 'referece_logps/chosen': -341.7918701171875, 'logits/rejected': 0.10411309450864792, 'logits/chosen': 0.035041987895965576, 'epoch': 4.54}

 76%|███████▌  | 12189/16104 [56:17:54<19:10:57, 17.64s/it]


 76%|███████▌  | 12191/16104 [56:18:22<17:19:10, 15.93s/it]

 76%|███████▌  | 12192/16104 [56:18:41<18:27:14, 16.98s/it]
{'loss': 0.4023, 'learning_rate': 2.938894436218119e-07, 'rewards/chosen': -0.9222133159637451, 'rewards/rejected': -1.4734632968902588, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5512498617172241, 'policy_logps/rejected': -319.53765869140625, 'policy_logps/chosen': -388.7124328613281, 'referece_logps/rejected': -304.8030090332031, 'referece_logps/chosen': -379.4902648925781, 'logits/rejected': 0.11091402918100357, 'logits/chosen': 0.030965179204940796, 'epoch': 4.54}


 76%|███████▌  | 12194/16104 [56:19:20<19:41:19, 18.13s/it]

 76%|███████▌  | 12195/16104 [56:19:36<19:02:47, 17.54s/it]

 76%|███████▌  | 12196/16104 [56:19:54<19:07:59, 17.63s/it]

 76%|███████▌  | 12197/16104 [56:20:15<20:14:29, 18.65s/it]

 76%|███████▌  | 12198/16104 [56:20:35<20:46:49, 19.15s/it]

 76%|███████▌  | 12199/16104 [56:20:51<19:37:43, 18.10s/it]

 76%|███████▌  | 12200/16104 [56:21:04<18:01:39, 16.62s/it]
{'loss': 0.4875, 'learning_rate': 2.9275101535257127e-07, 'rewards/chosen': -0.46566203236579895, 'rewards/rejected': -1.5429059267044067, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0772439241409302, 'policy_logps/rejected': -423.5308532714844, 'policy_logps/chosen': -373.7564697265625, 'referece_logps/rejected': -408.101806640625, 'referece_logps/chosen': -369.099853515625, 'logits/rejected': -0.026168137788772583, 'logits/chosen': -0.1125316321849823, 'epoch': 4.55}


 76%|███████▌  | 12202/16104 [56:21:34<16:56:28, 15.63s/it]

 76%|███████▌  | 12203/16104 [56:21:45<15:32:13, 14.34s/it]

 76%|███████▌  | 12204/16104 [56:22:01<16:07:04, 14.88s/it]
{'loss': 0.4286, 'learning_rate': 2.9218248766138867e-07, 'rewards/chosen': 0.05539587885141373, 'rewards/rejected': -1.6115453243255615, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6669412851333618, 'policy_logps/rejected': -374.68115234375, 'policy_logps/chosen': -611.70458984375, 'referece_logps/rejected': -358.565673828125, 'referece_logps/chosen': -612.2584838867188, 'logits/rejected': -0.16211824119091034, 'logits/chosen': -0.29867488145828247, 'epoch': 4.55}


 76%|███████▌  | 12206/16104 [56:22:25<14:21:27, 13.26s/it]

 76%|███████▌  | 12207/16104 [56:22:37<13:50:07, 12.78s/it]

 76%|███████▌  | 12208/16104 [56:22:48<13:13:29, 12.22s/it]

 76%|███████▌  | 12209/16104 [56:22:59<12:51:34, 11.89s/it]

 76%|███████▌  | 12210/16104 [56:23:15<14:21:38, 13.28s/it]

 76%|███████▌  | 12211/16104 [56:23:28<13:59:57, 12.95s/it]
{'loss': 0.3791, 'learning_rate': 2.9118866677348776e-07, 'rewards/chosen': -0.7552471160888672, 'rewards/rejected': -1.2387727499008179, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4835256040096283, 'policy_logps/rejected': -551.419189453125, 'policy_logps/chosen': -510.5255126953125, 'referece_logps/rejected': -539.0314331054688, 'referece_logps/chosen': -502.9730224609375, 'logits/rejected': -0.9225121736526489, 'logits/chosen': -0.993004560470581, 'epoch': 4.55}

 76%|███████▌  | 12212/16104 [56:23:39<13:20:32, 12.34s/it]


 76%|███████▌  | 12214/16104 [56:24:13<15:44:41, 14.57s/it]
{'loss': 0.4192, 'learning_rate': 2.9076317351123194e-07, 'rewards/chosen': -0.07286548614501953, 'rewards/rejected': -0.7550188302993774, 'rewards/accuracies': 1.0, 'rewards/margins': 0.6821534037590027, 'policy_logps/rejected': -499.26556396484375, 'policy_logps/chosen': -385.05902099609375, 'referece_logps/rejected': -491.71539306640625, 'referece_logps/chosen': -384.3303527832031, 'logits/rejected': -0.1569962054491043, 'logits/chosen': -0.17061014473438263, 'epoch': 4.55}


 76%|███████▌  | 12216/16104 [56:24:41<15:45:44, 14.59s/it]
{'loss': 0.3353, 'learning_rate': 2.904796547763092e-07, 'rewards/chosen': -0.07935237139463425, 'rewards/rejected': -1.8276584148406982, 'rewards/accuracies': 1.0, 'rewards/margins': 1.748306155204773, 'policy_logps/rejected': -460.0364074707031, 'policy_logps/chosen': -518.6019287109375, 'referece_logps/rejected': -441.759765625, 'referece_logps/chosen': -517.808349609375, 'logits/rejected': -0.2630521059036255, 'logits/chosen': -0.1484009325504303, 'epoch': 4.55}

 76%|███████▌  | 12217/16104 [56:25:01<17:22:27, 16.09s/it]


 76%|███████▌  | 12219/16104 [56:25:40<19:17:24, 17.87s/it]

 76%|███████▌  | 12220/16104 [56:26:00<19:56:31, 18.48s/it]

 76%|███████▌  | 12221/16104 [56:26:19<20:07:50, 18.66s/it]

 76%|███████▌  | 12222/16104 [56:26:38<20:08:28, 18.68s/it]

 76%|███████▌  | 12223/16104 [56:26:55<19:30:06, 18.09s/it]
{'loss': 0.4286, 'learning_rate': 2.8948824359792766e-07, 'rewards/chosen': -0.4510335922241211, 'rewards/rejected': -1.6401768922805786, 'rewards/accuracies': 0.625, 'rewards/margins': 1.189143180847168, 'policy_logps/rejected': -465.16961669921875, 'policy_logps/chosen': -406.84661865234375, 'referece_logps/rejected': -448.76788330078125, 'referece_logps/chosen': -402.3363037109375, 'logits/rejected': -0.2945702075958252, 'logits/chosen': -0.2889566421508789, 'epoch': 4.55}


 76%|███████▌  | 12225/16104 [56:27:24<17:37:21, 16.36s/it]

 76%|███████▌  | 12226/16104 [56:27:41<17:52:45, 16.60s/it]

 76%|███████▌  | 12227/16104 [56:27:58<17:47:20, 16.52s/it]

 76%|███████▌  | 12228/16104 [56:28:14<17:34:16, 16.32s/it]

 76%|███████▌  | 12229/16104 [56:28:32<18:08:39, 16.86s/it]

 76%|███████▌  | 12230/16104 [56:28:52<19:19:35, 17.96s/it]

 76%|███████▌  | 12231/16104 [56:29:10<19:12:51, 17.86s/it]

 76%|███████▌  | 12232/16104 [56:29:28<19:21:07, 17.99s/it]

 76%|███████▌  | 12233/16104 [56:29:48<19:57:59, 18.57s/it]

 76%|███████▌  | 12234/16104 [56:30:00<17:54:45, 16.66s/it]
{'loss': 0.5648, 'learning_rate': 2.879331579063956e-07, 'rewards/chosen': -0.7831606268882751, 'rewards/rejected': -1.446176528930664, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6630159020423889, 'policy_logps/rejected': -560.6815795898438, 'policy_logps/chosen': -376.00408935546875, 'referece_logps/rejected': -546.2198486328125, 'referece_logps/chosen': -368.1724853515625, 'logits/rejected': -0.4711682200431824, 'logits/chosen': -0.31000807881355286, 'epoch': 4.56}


 76%|███████▌  | 12236/16104 [56:30:28<16:39:10, 15.50s/it]
{'loss': 0.4496, 'learning_rate': 2.876507892873479e-07, 'rewards/chosen': -0.6054736971855164, 'rewards/rejected': -1.5873470306396484, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9818733334541321, 'policy_logps/rejected': -321.20526123046875, 'policy_logps/chosen': -357.8120422363281, 'referece_logps/rejected': -305.3317565917969, 'referece_logps/chosen': -351.75732421875, 'logits/rejected': -0.4005510210990906, 'logits/chosen': -0.41555678844451904, 'epoch': 4.56}

 76%|███████▌  | 12237/16104 [56:30:45<17:04:08, 15.89s/it]


 76%|███████▌  | 12239/16104 [56:31:16<16:46:37, 15.63s/it]

 76%|███████▌  | 12240/16104 [56:31:30<15:57:04, 14.86s/it]
{'loss': 0.5349, 'learning_rate': 2.870863978844816e-07, 'rewards/chosen': -0.8267116546630859, 'rewards/rejected': -2.314873456954956, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4881620407104492, 'policy_logps/rejected': -507.7652893066406, 'policy_logps/chosen': -465.5509033203125, 'referece_logps/rejected': -484.6165771484375, 'referece_logps/chosen': -457.28375244140625, 'logits/rejected': -0.6947808861732483, 'logits/chosen': -0.7462872266769409, 'epoch': 4.56}


 76%|███████▌  | 12242/16104 [56:32:00<16:03:12, 14.96s/it]

 76%|███████▌  | 12243/16104 [56:32:21<17:54:12, 16.69s/it]

 76%|███████▌  | 12244/16104 [56:32:36<17:20:47, 16.18s/it]

 76%|███████▌  | 12245/16104 [56:32:53<17:43:28, 16.53s/it]

 76%|███████▌  | 12246/16104 [56:33:10<17:46:26, 16.59s/it]

 76%|███████▌  | 12247/16104 [56:33:22<16:17:18, 15.20s/it]
{'loss': 0.3782, 'learning_rate': 2.860998234361396e-07, 'rewards/chosen': -0.32490748167037964, 'rewards/rejected': -1.9652562141418457, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6403486728668213, 'policy_logps/rejected': -402.48028564453125, 'policy_logps/chosen': -467.7925720214844, 'referece_logps/rejected': -382.8277282714844, 'referece_logps/chosen': -464.54351806640625, 'logits/rejected': 0.7356940507888794, 'logits/chosen': 0.6156633496284485, 'epoch': 4.56}


 76%|███████▌  | 12249/16104 [56:33:46<14:40:41, 13.71s/it]

 76%|███████▌  | 12250/16104 [56:33:58<14:09:31, 13.23s/it]

 76%|███████▌  | 12251/16104 [56:34:14<15:01:30, 14.04s/it]

 76%|███████▌  | 12252/16104 [56:34:32<16:16:00, 15.20s/it]

 76%|███████▌  | 12253/16104 [56:34:52<17:47:46, 16.64s/it]
{'loss': 0.5235, 'learning_rate': 2.8525531438338934e-07, 'rewards/chosen': -0.3837369680404663, 'rewards/rejected': -1.6026242971420288, 'rewards/accuracies': 0.75, 'rewards/margins': 1.218887209892273, 'policy_logps/rejected': -405.802734375, 'policy_logps/chosen': -546.820556640625, 'referece_logps/rejected': -389.7764892578125, 'referece_logps/chosen': -542.983154296875, 'logits/rejected': -0.2726612985134125, 'logits/chosen': -0.29217103123664856, 'epoch': 4.57}


 76%|███████▌  | 12255/16104 [56:35:23<17:09:24, 16.05s/it]

 76%|███████▌  | 12256/16104 [56:35:42<18:14:28, 17.07s/it]
{'loss': 0.622, 'learning_rate': 2.8483345010158557e-07, 'rewards/chosen': -0.8366659283638, 'rewards/rejected': -1.7156959772109985, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8790298700332642, 'policy_logps/rejected': -432.6922912597656, 'policy_logps/chosen': -443.49957275390625, 'referece_logps/rejected': -415.5353088378906, 'referece_logps/chosen': -435.1329345703125, 'logits/rejected': -0.6681016087532043, 'logits/chosen': -1.0291857719421387, 'epoch': 4.57}


 76%|███████▌  | 12258/16104 [56:36:09<16:28:00, 15.41s/it]

 76%|███████▌  | 12259/16104 [56:36:20<15:01:44, 14.07s/it]

 76%|███████▌  | 12260/16104 [56:36:32<14:19:15, 13.41s/it]

 76%|███████▌  | 12261/16104 [56:36:45<14:11:05, 13.29s/it]

 76%|███████▌  | 12262/16104 [56:36:56<13:36:33, 12.75s/it]

 76%|███████▌  | 12263/16104 [56:37:13<14:47:08, 13.86s/it]

 76%|███████▌  | 12264/16104 [56:37:24<14:01:55, 13.16s/it]

 76%|███████▌  | 12265/16104 [56:37:38<14:14:03, 13.35s/it]

 76%|███████▌  | 12266/16104 [56:37:58<16:18:13, 15.29s/it]

 76%|███████▌  | 12267/16104 [56:38:11<15:32:37, 14.58s/it]

 76%|███████▌  | 12268/16104 [56:38:30<16:56:39, 15.90s/it]

 76%|███████▌  | 12269/16104 [56:38:46<17:04:03, 16.02s/it]
{'loss': 0.3813, 'learning_rate': 2.830083822124363e-07, 'rewards/chosen': -0.5503896474838257, 'rewards/rejected': -1.8137651681900024, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2633755207061768, 'policy_logps/rejected': -336.4792785644531, 'policy_logps/chosen': -491.3855895996094, 'referece_logps/rejected': -318.34161376953125, 'referece_logps/chosen': -485.8816833496094, 'logits/rejected': -0.2432895451784134, 'logits/chosen': -0.26505106687545776, 'epoch': 4.57}


 76%|███████▌  | 12271/16104 [56:39:18<17:11:00, 16.14s/it]

 76%|███████▌  | 12272/16104 [56:39:38<18:25:15, 17.31s/it]
{'loss': 0.406, 'learning_rate': 2.8258790833169e-07, 'rewards/chosen': -0.14019908010959625, 'rewards/rejected': -1.6911585330963135, 'rewards/accuracies': 0.625, 'rewards/margins': 1.550959587097168, 'policy_logps/rejected': -395.2801513671875, 'policy_logps/chosen': -392.11212158203125, 'referece_logps/rejected': -378.3686218261719, 'referece_logps/chosen': -390.71014404296875, 'logits/rejected': 0.11159323155879974, 'logits/chosen': -0.02407420426607132, 'epoch': 4.57}


 76%|███████▌  | 12274/16104 [56:40:11<18:04:58, 17.00s/it]
{'loss': 0.3683, 'learning_rate': 2.8230773750473956e-07, 'rewards/chosen': -0.15151482820510864, 'rewards/rejected': -1.5322890281677246, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3807743787765503, 'policy_logps/rejected': -420.5267639160156, 'policy_logps/chosen': -536.2443237304688, 'referece_logps/rejected': -405.20391845703125, 'referece_logps/chosen': -534.7291870117188, 'logits/rejected': 0.006079956889152527, 'logits/chosen': -0.08185702562332153, 'epoch': 4.57}


 76%|███████▌  | 12276/16104 [56:40:41<16:47:17, 15.79s/it]

 76%|███████▌  | 12277/16104 [56:41:00<17:55:40, 16.86s/it]
{'loss': 0.3961, 'learning_rate': 2.818876990179687e-07, 'rewards/chosen': -0.15510940551757812, 'rewards/rejected': -2.5437331199645996, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3886237144470215, 'policy_logps/rejected': -344.3389892578125, 'policy_logps/chosen': -438.0454406738281, 'referece_logps/rejected': -318.9017028808594, 'referece_logps/chosen': -436.49432373046875, 'logits/rejected': -0.40781503915786743, 'logits/chosen': -0.48852649331092834, 'epoch': 4.57}


 76%|███████▌  | 12279/16104 [56:41:33<17:18:49, 16.30s/it]

 76%|███████▋  | 12280/16104 [56:41:49<17:09:40, 16.16s/it]

 76%|███████▋  | 12281/16104 [56:42:09<18:16:59, 17.22s/it]

 76%|███████▋  | 12282/16104 [56:42:23<17:12:38, 16.21s/it]
{'loss': 0.4778, 'learning_rate': 2.8118821592729004e-07, 'rewards/chosen': -0.35035210847854614, 'rewards/rejected': -1.460310935974121, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1099588871002197, 'policy_logps/rejected': -496.0085144042969, 'policy_logps/chosen': -481.8909606933594, 'referece_logps/rejected': -481.4053955078125, 'referece_logps/chosen': -478.387451171875, 'logits/rejected': 0.20775960385799408, 'logits/chosen': 0.26027563214302063, 'epoch': 4.58}


 76%|███████▋  | 12284/16104 [56:42:46<14:51:49, 14.01s/it]
{'loss': 0.4783, 'learning_rate': 2.8090862619194887e-07, 'rewards/chosen': -0.43954139947891235, 'rewards/rejected': -1.66969633102417, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2301549911499023, 'policy_logps/rejected': -251.5666046142578, 'policy_logps/chosen': -452.10516357421875, 'referece_logps/rejected': -234.86964416503906, 'referece_logps/chosen': -447.709716796875, 'logits/rejected': 0.41773343086242676, 'logits/chosen': 0.40310975909233093, 'epoch': 4.58}


 76%|███████▋  | 12286/16104 [56:43:18<15:37:10, 14.73s/it]
{'loss': 0.3812, 'learning_rate': 2.8062915281072365e-07, 'rewards/chosen': 0.004983516409993172, 'rewards/rejected': -1.5722683668136597, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5772520303726196, 'policy_logps/rejected': -509.0934143066406, 'policy_logps/chosen': -376.03607177734375, 'referece_logps/rejected': -493.3707275390625, 'referece_logps/chosen': -376.08587646484375, 'logits/rejected': -0.25736480951309204, 'logits/chosen': -0.17728541791439056, 'epoch': 4.58}

 76%|███████▋  | 12287/16104 [56:43:40<17:47:47, 16.78s/it]


 76%|███████▋  | 12289/16104 [56:44:16<18:36:36, 17.56s/it]

 76%|███████▋  | 12290/16104 [56:44:31<17:31:09, 16.54s/it]
{'loss': 0.4181, 'learning_rate': 2.8007055529148515e-07, 'rewards/chosen': -0.3670348823070526, 'rewards/rejected': -2.7280473709106445, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3610122203826904, 'policy_logps/rejected': -407.580078125, 'policy_logps/chosen': -615.5948486328125, 'referece_logps/rejected': -380.2996520996094, 'referece_logps/chosen': -611.9244384765625, 'logits/rejected': -0.36971551179885864, 'logits/chosen': -0.3435434103012085, 'epoch': 4.58}


 76%|███████▋  | 12292/16104 [56:45:01<16:27:48, 15.55s/it]

 76%|███████▋  | 12293/16104 [56:45:13<15:09:44, 14.32s/it]

 76%|███████▋  | 12294/16104 [56:45:27<15:15:01, 14.41s/it]

 76%|███████▋  | 12295/16104 [56:45:45<16:18:59, 15.42s/it]

 76%|███████▋  | 12296/16104 [56:46:05<17:47:43, 16.82s/it]

 76%|███████▋  | 12297/16104 [56:46:21<17:24:16, 16.46s/it]

 76%|███████▋  | 12298/16104 [56:46:41<18:34:57, 17.58s/it]

 76%|███████▋  | 12299/16104 [56:47:01<19:12:50, 18.18s/it]

 76%|███████▋  | 12300/16104 [56:47:22<20:12:01, 19.12s/it]

 76%|███████▋  | 12301/16104 [56:47:33<17:47:29, 16.84s/it]

 76%|███████▋  | 12302/16104 [56:47:54<18:52:59, 17.88s/it]

 76%|███████▋  | 12303/16104 [56:48:11<18:37:41, 17.64s/it]

 76%|███████▋  | 12304/16104 [56:48:29<18:47:57, 17.81s/it]

 76%|███████▋  | 12305/16104 [56:48:49<19:27:07, 18.43s/it]
{'loss': 0.4927, 'learning_rate': 2.7797996748861e-07, 'rewards/chosen': -0.6817898154258728, 'rewards/rejected': -1.2585973739624023, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5768077373504639, 'policy_logps/rejected': -376.3585205078125, 'policy_logps/chosen': -458.5183410644531, 'referece_logps/rejected': -363.77252197265625, 'referece_logps/chosen': -451.700439453125, 'logits/rejected': -1.0656049251556396, 'logits/chosen': -1.0620958805084229, 'epoch': 4.58}

 76%|███████▋  | 12306/16104 [56:49:09<19:53:15, 18.85s/it]

 76%|███████▋  | 12307/16104 [56:49:21<17:43:33, 16.81s/it]

 76%|███████▋  | 12308/16104 [56:49:40<18:34:23, 17.61s/it]

 76%|███████▋  | 12309/16104 [56:49:53<16:55:24, 16.05s/it]

 76%|███████▋  | 12310/16104 [56:50:05<15:36:29, 14.81s/it]

 76%|███████▋  | 12311/16104 [56:50:16<14:36:28, 13.86s/it]

 76%|███████▋  | 12312/16104 [56:50:37<16:42:49, 15.87s/it]

 76%|███████▋  | 12313/16104 [56:50:55<17:29:26, 16.61s/it]


 76%|███████▋  | 12315/16104 [56:51:34<19:05:02, 18.13s/it]

 76%|███████▋  | 12316/16104 [56:51:54<19:31:47, 18.56s/it]
{'loss': 0.4843, 'learning_rate': 2.7645104529152407e-07, 'rewards/chosen': -1.0589181184768677, 'rewards/rejected': -2.18082857131958, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1219104528427124, 'policy_logps/rejected': -330.1593322753906, 'policy_logps/chosen': -318.93212890625, 'referece_logps/rejected': -308.3510437011719, 'referece_logps/chosen': -308.3429260253906, 'logits/rejected': -0.5178936719894409, 'logits/chosen': -0.6309398412704468, 'epoch': 4.59}


 76%|███████▋  | 12318/16104 [56:52:28<18:39:43, 17.75s/it]
{'loss': 0.339, 'learning_rate': 2.761734397133566e-07, 'rewards/chosen': -0.354631245136261, 'rewards/rejected': -2.354013204574585, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9993817806243896, 'policy_logps/rejected': -366.8099060058594, 'policy_logps/chosen': -414.9005126953125, 'referece_logps/rejected': -343.2698059082031, 'referece_logps/chosen': -411.3542175292969, 'logits/rejected': 0.013977080583572388, 'logits/chosen': -0.032191842794418335, 'epoch': 4.59}

 76%|███████▋  | 12319/16104 [56:52:47<19:11:49, 18.26s/it]

 77%|███████▋  | 12320/16104 [56:53:06<19:28:31, 18.53s/it]

 77%|███████▋  | 12321/16104 [56:53:25<19:36:48, 18.66s/it]


 77%|███████▋  | 12323/16104 [56:54:03<19:55:02, 18.96s/it]

 77%|███████▋  | 12324/16104 [56:54:24<20:23:18, 19.42s/it]

 77%|███████▋  | 12325/16104 [56:54:42<19:52:22, 18.93s/it]
{'loss': 0.4408, 'learning_rate': 2.752027428067626e-07, 'rewards/chosen': -0.9899616241455078, 'rewards/rejected': -2.0903801918029785, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1004183292388916, 'policy_logps/rejected': -387.4625244140625, 'policy_logps/chosen': -350.71795654296875, 'referece_logps/rejected': -366.5587158203125, 'referece_logps/chosen': -340.8183288574219, 'logits/rejected': -0.3316231369972229, 'logits/chosen': -0.35153728723526, 'epoch': 4.59}


 77%|███████▋  | 12327/16104 [56:55:20<20:02:43, 19.11s/it]

 77%|███████▋  | 12328/16104 [56:55:40<20:17:03, 19.34s/it]

 77%|███████▋  | 12329/16104 [56:55:54<18:38:55, 17.78s/it]
{'loss': 0.4705, 'learning_rate': 2.7464870376227554e-07, 'rewards/chosen': -0.22837352752685547, 'rewards/rejected': -1.1922931671142578, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9639196395874023, 'policy_logps/rejected': -451.2980651855469, 'policy_logps/chosen': -534.292236328125, 'referece_logps/rejected': -439.3751220703125, 'referece_logps/chosen': -532.0084838867188, 'logits/rejected': -0.3090536296367645, 'logits/chosen': -0.13817459344863892, 'epoch': 4.59}

 77%|███████▋  | 12330/16104 [56:56:07<17:14:56, 16.45s/it]

 77%|███████▋  | 12331/16104 [56:56:25<17:30:08, 16.70s/it]

 77%|███████▋  | 12332/16104 [56:56:45<18:36:48, 17.76s/it]


 77%|███████▋  | 12334/16104 [56:57:24<19:35:58, 18.72s/it]

 77%|███████▋  | 12335/16104 [56:57:42<19:22:28, 18.51s/it]
{'loss': 0.4327, 'learning_rate': 2.73818525560106e-07, 'rewards/chosen': -1.5175970792770386, 'rewards/rejected': -3.369256019592285, 'rewards/accuracies': 1.0, 'rewards/margins': 1.851658582687378, 'policy_logps/rejected': -447.3179931640625, 'policy_logps/chosen': -490.12835693359375, 'referece_logps/rejected': -413.62542724609375, 'referece_logps/chosen': -474.952392578125, 'logits/rejected': -0.6884407997131348, 'logits/chosen': -0.804955244064331, 'epoch': 4.6}

 77%|███████▋  | 12336/16104 [56:58:03<19:58:24, 19.08s/it]

 77%|███████▋  | 12337/16104 [56:58:23<20:13:56, 19.34s/it]


 77%|███████▋  | 12339/16104 [56:58:52<18:03:35, 17.27s/it]
{'loss': 0.4088, 'learning_rate': 2.7326566085742386e-07, 'rewards/chosen': -1.0263723134994507, 'rewards/rejected': -1.7466886043548584, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7203161716461182, 'policy_logps/rejected': -368.104248046875, 'policy_logps/chosen': -459.9912109375, 'referece_logps/rejected': -350.6373291015625, 'referece_logps/chosen': -449.7274475097656, 'logits/rejected': 0.0994536504149437, 'logits/chosen': -0.09460985660552979, 'epoch': 4.6}


 77%|███████▋  | 12341/16104 [56:59:20<16:05:42, 15.40s/it]

 77%|███████▋  | 12342/16104 [56:59:34<15:38:41, 14.97s/it]
{'loss': 0.4066, 'learning_rate': 2.728513209866981e-07, 'rewards/chosen': -0.5886169672012329, 'rewards/rejected': -2.1351959705352783, 'rewards/accuracies': 0.5, 'rewards/margins': 1.546579122543335, 'policy_logps/rejected': -542.62646484375, 'policy_logps/chosen': -399.04901123046875, 'referece_logps/rejected': -521.2745361328125, 'referece_logps/chosen': -393.162841796875, 'logits/rejected': -0.12538619339466095, 'logits/chosen': -0.04144842177629471, 'epoch': 4.6}

 77%|███████▋  | 12343/16104 [56:59:54<17:04:11, 16.34s/it]

 77%|███████▋  | 12344/16104 [57:00:15<18:43:56, 17.94s/it]


 77%|███████▋  | 12346/16104 [57:00:54<19:37:22, 18.80s/it]

 77%|███████▋  | 12347/16104 [57:01:10<18:43:22, 17.94s/it]
{'loss': 0.4357, 'learning_rate': 2.721613428991545e-07, 'rewards/chosen': -0.2891126871109009, 'rewards/rejected': -1.4410361051559448, 'rewards/accuracies': 0.875, 'rewards/margins': 1.151923418045044, 'policy_logps/rejected': -617.0958251953125, 'policy_logps/chosen': -528.2235107421875, 'referece_logps/rejected': -602.6854858398438, 'referece_logps/chosen': -525.3323974609375, 'logits/rejected': -0.5349013209342957, 'logits/chosen': -0.5641440749168396, 'epoch': 4.6}


 77%|███████▋  | 12349/16104 [57:01:45<18:21:00, 17.59s/it]

 77%|███████▋  | 12350/16104 [57:02:03<18:28:13, 17.71s/it]

 77%|███████▋  | 12351/16104 [57:02:24<19:42:06, 18.90s/it]

 77%|███████▋  | 12352/16104 [57:02:44<19:57:53, 19.16s/it]
{'loss': 0.4102, 'learning_rate': 2.7147210087086414e-07, 'rewards/chosen': -0.15685424208641052, 'rewards/rejected': -1.83295476436615, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6761006116867065, 'policy_logps/rejected': -616.9353637695312, 'policy_logps/chosen': -450.1527404785156, 'referece_logps/rejected': -598.6057739257812, 'referece_logps/chosen': -448.584228515625, 'logits/rejected': -0.14629802107810974, 'logits/chosen': -0.15344944596290588, 'epoch': 4.6}

 77%|███████▋  | 12353/16104 [57:02:57<18:06:36, 17.38s/it]

 77%|███████▋  | 12354/16104 [57:03:17<18:49:18, 18.07s/it]

 77%|███████▋  | 12355/16104 [57:03:37<19:34:05, 18.79s/it]

 77%|███████▋  | 12356/16104 [57:03:57<19:53:31, 19.11s/it]


 77%|███████▋  | 12358/16104 [57:04:26<17:09:24, 16.49s/it]
{'loss': 0.3629, 'learning_rate': 2.7064598301649035e-07, 'rewards/chosen': -0.3936469554901123, 'rewards/rejected': -2.268735885620117, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8750886917114258, 'policy_logps/rejected': -342.4109191894531, 'policy_logps/chosen': -415.09820556640625, 'referece_logps/rejected': -319.7236022949219, 'referece_logps/chosen': -411.1617431640625, 'logits/rejected': -0.22392727434635162, 'logits/chosen': -0.11224014312028885, 'epoch': 4.6}

 77%|███████▋  | 12359/16104 [57:04:37<15:25:34, 14.83s/it]

 77%|███████▋  | 12360/16104 [57:04:57<16:55:52, 16.28s/it]

 77%|███████▋  | 12361/16104 [57:05:12<16:26:47, 15.82s/it]


 77%|███████▋  | 12363/16104 [57:05:50<18:01:43, 17.35s/it]

 77%|███████▋  | 12364/16104 [57:06:03<16:26:57, 15.83s/it]
{'loss': 0.4523, 'learning_rate': 2.6982092729416585e-07, 'rewards/chosen': -0.7598258852958679, 'rewards/rejected': -1.259484052658081, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4996582269668579, 'policy_logps/rejected': -379.739501953125, 'policy_logps/chosen': -482.519287109375, 'referece_logps/rejected': -367.1446533203125, 'referece_logps/chosen': -474.9210510253906, 'logits/rejected': 0.02836756408214569, 'logits/chosen': -0.01219845563173294, 'epoch': 4.61}


 77%|███████▋  | 12366/16104 [57:06:35<16:44:12, 16.12s/it]
{'loss': 0.4974, 'learning_rate': 2.6954614495711305e-07, 'rewards/chosen': -0.2545989751815796, 'rewards/rejected': -2.220475435256958, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9658764600753784, 'policy_logps/rejected': -444.4289855957031, 'policy_logps/chosen': -541.298828125, 'referece_logps/rejected': -422.2242126464844, 'referece_logps/chosen': -538.7528076171875, 'logits/rejected': 0.7041905522346497, 'logits/chosen': 0.549946665763855, 'epoch': 4.61}


 77%|███████▋  | 12368/16104 [57:06:59<14:45:29, 14.22s/it]
{'loss': 0.5191, 'learning_rate': 2.6927148081270646e-07, 'rewards/chosen': -0.34160175919532776, 'rewards/rejected': -0.8487188816070557, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5071170926094055, 'policy_logps/rejected': -400.96148681640625, 'policy_logps/chosen': -448.8807067871094, 'referece_logps/rejected': -392.47430419921875, 'referece_logps/chosen': -445.4646911621094, 'logits/rejected': -0.5292154550552368, 'logits/chosen': -0.6210558414459229, 'epoch': 4.61}


 77%|███████▋  | 12370/16104 [57:07:34<16:38:45, 16.05s/it]

 77%|███████▋  | 12371/16104 [57:07:46<15:22:35, 14.83s/it]
{'loss': 0.4025, 'learning_rate': 2.6885970630452235e-07, 'rewards/chosen': 0.030222728848457336, 'rewards/rejected': -2.056234359741211, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0864572525024414, 'policy_logps/rejected': -443.007568359375, 'policy_logps/chosen': -391.67230224609375, 'referece_logps/rejected': -422.4451904296875, 'referece_logps/chosen': -391.97454833984375, 'logits/rejected': -0.010421458631753922, 'logits/chosen': 0.09222309291362762, 'epoch': 4.61}

 77%|███████▋  | 12372/16104 [57:08:02<15:40:25, 15.12s/it]

 77%|███████▋  | 12373/16104 [57:08:21<16:54:01, 16.31s/it]

 77%|███████▋  | 12374/16104 [57:08:40<17:30:49, 16.90s/it]


 77%|███████▋  | 12376/16104 [57:09:11<17:09:00, 16.56s/it]
{'loss': 0.3829, 'learning_rate': 2.681740070501116e-07, 'rewards/chosen': -0.5428498387336731, 'rewards/rejected': -1.5052517652511597, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9624019861221313, 'policy_logps/rejected': -326.46868896484375, 'policy_logps/chosen': -298.0202331542969, 'referece_logps/rejected': -311.4161682128906, 'referece_logps/chosen': -292.5917053222656, 'logits/rejected': -0.4573553800582886, 'logits/chosen': -0.3404396176338196, 'epoch': 4.61}


 77%|███████▋  | 12378/16104 [57:09:43<17:13:11, 16.64s/it]
{'loss': 0.3611, 'learning_rate': 2.678999345351944e-07, 'rewards/chosen': -0.5943655371665955, 'rewards/rejected': -1.6206730604171753, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0263075828552246, 'policy_logps/rejected': -476.1906433105469, 'policy_logps/chosen': -360.8182373046875, 'referece_logps/rejected': -459.98394775390625, 'referece_logps/chosen': -354.8745422363281, 'logits/rejected': 0.24173419177532196, 'logits/chosen': 0.2563300132751465, 'epoch': 4.61}

 77%|███████▋  | 12379/16104 [57:09:54<15:30:13, 14.98s/it]


 77%|███████▋  | 12381/16104 [57:10:26<16:07:51, 15.60s/it]
{'loss': 0.368, 'learning_rate': 2.6748904788732483e-07, 'rewards/chosen': -0.8439563512802124, 'rewards/rejected': -2.5276339054107666, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6836776733398438, 'policy_logps/rejected': -456.150390625, 'policy_logps/chosen': -384.1963195800781, 'referece_logps/rejected': -430.8740234375, 'referece_logps/chosen': -375.7567138671875, 'logits/rejected': -0.8872901201248169, 'logits/chosen': -0.8337096571922302, 'epoch': 4.61}


 77%|███████▋  | 12383/16104 [57:10:59<16:24:05, 15.87s/it]

 77%|███████▋  | 12384/16104 [57:11:21<18:07:39, 17.54s/it]

 77%|███████▋  | 12385/16104 [57:11:41<19:07:58, 18.52s/it]
{'loss': 0.3392, 'learning_rate': 2.669416138885813e-07, 'rewards/chosen': -0.6943721771240234, 'rewards/rejected': -2.7858853340148926, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0915133953094482, 'policy_logps/rejected': -370.180908203125, 'policy_logps/chosen': -453.98651123046875, 'referece_logps/rejected': -342.32208251953125, 'referece_logps/chosen': -447.04278564453125, 'logits/rejected': -0.1902661770582199, 'logits/chosen': -0.3877367675304413, 'epoch': 4.61}

 77%|███████▋  | 12386/16104 [57:12:02<19:47:23, 19.16s/it]

 77%|███████▋  | 12387/16104 [57:12:22<19:54:10, 19.28s/it]

 77%|███████▋  | 12388/16104 [57:12:40<19:33:01, 18.94s/it]

 77%|███████▋  | 12389/16104 [57:12:56<18:47:15, 18.21s/it]


 77%|███████▋  | 12391/16104 [57:13:29<17:41:18, 17.15s/it]
{'loss': 0.4894, 'learning_rate': 2.6612135260665594e-07, 'rewards/chosen': -0.5418549180030823, 'rewards/rejected': -1.743489384651184, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2016345262527466, 'policy_logps/rejected': -515.972900390625, 'policy_logps/chosen': -393.27264404296875, 'referece_logps/rejected': -498.53802490234375, 'referece_logps/chosen': -387.85406494140625, 'logits/rejected': -0.23967930674552917, 'logits/chosen': -0.07339411973953247, 'epoch': 4.62}


 77%|███████▋  | 12393/16104 [57:14:03<17:57:11, 17.42s/it]
{'loss': 0.4448, 'learning_rate': 2.6584816961398294e-07, 'rewards/chosen': -0.9317785501480103, 'rewards/rejected': -2.65747332572937, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7256945371627808, 'policy_logps/rejected': -425.22271728515625, 'policy_logps/chosen': -369.7952880859375, 'referece_logps/rejected': -398.6479797363281, 'referece_logps/chosen': -360.47747802734375, 'logits/rejected': 0.3773571252822876, 'logits/chosen': 0.2934767007827759, 'epoch': 4.62}


 77%|███████▋  | 12395/16104 [57:14:39<18:08:16, 17.60s/it]

 77%|███████▋  | 12396/16104 [57:15:01<19:29:08, 18.92s/it]

 77%|███████▋  | 12397/16104 [57:15:21<19:44:10, 19.17s/it]

 77%|███████▋  | 12398/16104 [57:15:36<18:22:54, 17.86s/it]

 77%|███████▋  | 12399/16104 [57:15:53<18:12:39, 17.69s/it]
{'loss': 0.3458, 'learning_rate': 2.6502933355871124e-07, 'rewards/chosen': -0.5349420309066772, 'rewards/rejected': -2.596541166305542, 'rewards/accuracies': 0.75, 'rewards/margins': 2.061599016189575, 'policy_logps/rejected': -447.1715087890625, 'policy_logps/chosen': -545.4619750976562, 'referece_logps/rejected': -421.20611572265625, 'referece_logps/chosen': -540.1124877929688, 'logits/rejected': -0.627743124961853, 'logits/chosen': -0.598065972328186, 'epoch': 4.62}


 77%|███████▋  | 12401/16104 [57:16:29<18:10:20, 17.67s/it]

 77%|███████▋  | 12402/16104 [57:16:48<18:22:18, 17.87s/it]
{'loss': 0.4192, 'learning_rate': 2.646203168233738e-07, 'rewards/chosen': -0.4244888424873352, 'rewards/rejected': -1.7858290672302246, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3613402843475342, 'policy_logps/rejected': -468.6156921386719, 'policy_logps/chosen': -514.0813598632812, 'referece_logps/rejected': -450.75738525390625, 'referece_logps/chosen': -509.83648681640625, 'logits/rejected': 1.1605749130249023, 'logits/chosen': 1.1016969680786133, 'epoch': 4.62}

 77%|███████▋  | 12403/16104 [57:16:58<16:11:34, 15.75s/it]

 77%|███████▋  | 12404/16104 [57:17:14<16:14:40, 15.81s/it]

 77%|███████▋  | 12405/16104 [57:17:34<17:23:50, 16.93s/it]

 77%|███████▋  | 12406/16104 [57:17:48<16:31:37, 16.09s/it]

 77%|███████▋  | 12407/16104 [57:18:00<15:18:36, 14.91s/it]


 77%|███████▋  | 12409/16104 [57:18:33<16:29:00, 16.06s/it]
{'loss': 0.5535, 'learning_rate': 2.636669858577992e-07, 'rewards/chosen': -0.7501291632652283, 'rewards/rejected': -1.1101617813110352, 'rewards/accuracies': 0.5, 'rewards/margins': 0.36003267765045166, 'policy_logps/rejected': -323.562255859375, 'policy_logps/chosen': -336.2566223144531, 'referece_logps/rejected': -312.4606628417969, 'referece_logps/chosen': -328.75531005859375, 'logits/rejected': 0.2932898998260498, 'logits/chosen': 0.07698358595371246, 'epoch': 4.62}


 77%|███████▋  | 12411/16104 [57:18:58<14:23:35, 14.03s/it]
{'loss': 0.5177, 'learning_rate': 2.6339487357317235e-07, 'rewards/chosen': -0.5392526984214783, 'rewards/rejected': -2.0863699913024902, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5471172332763672, 'policy_logps/rejected': -464.113525390625, 'policy_logps/chosen': -364.2691345214844, 'referece_logps/rejected': -443.2497863769531, 'referece_logps/chosen': -358.8765869140625, 'logits/rejected': -0.2669244408607483, 'logits/chosen': -0.17859424650669098, 'epoch': 4.62}

 77%|███████▋  | 12412/16104 [57:19:11<14:13:14, 13.87s/it]

 77%|███████▋  | 12413/16104 [57:19:22<13:21:32, 13.03s/it]

 77%|███████▋  | 12414/16104 [57:19:34<13:00:29, 12.69s/it]

 77%|███████▋  | 12415/16104 [57:19:48<13:23:33, 13.07s/it]

 77%|███████▋  | 12416/16104 [57:20:00<13:04:09, 12.76s/it]


 77%|███████▋  | 12418/16104 [57:20:26<12:51:39, 12.56s/it]
{'loss': 0.4243, 'learning_rate': 2.6244341947098216e-07, 'rewards/chosen': -0.3411368727684021, 'rewards/rejected': -1.2923369407653809, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9512001276016235, 'policy_logps/rejected': -461.07281494140625, 'policy_logps/chosen': -501.7375793457031, 'referece_logps/rejected': -448.14947509765625, 'referece_logps/chosen': -498.32623291015625, 'logits/rejected': -0.9548903107643127, 'logits/chosen': -1.0911619663238525, 'epoch': 4.63}


 77%|███████▋  | 12420/16104 [57:20:52<12:52:53, 12.59s/it]

 77%|███████▋  | 12421/16104 [57:21:04<12:40:32, 12.39s/it]
{'loss': 0.4327, 'learning_rate': 2.620361008494486e-07, 'rewards/chosen': -0.11474497616291046, 'rewards/rejected': -1.227237582206726, 'rewards/accuracies': 0.625, 'rewards/margins': 1.112492561340332, 'policy_logps/rejected': -458.6778259277344, 'policy_logps/chosen': -530.9137573242188, 'referece_logps/rejected': -446.4053955078125, 'referece_logps/chosen': -529.766357421875, 'logits/rejected': 0.3758949637413025, 'logits/chosen': 0.5126864314079285, 'epoch': 4.63}

 77%|███████▋  | 12422/16104 [57:21:15<12:27:35, 12.18s/it]

 77%|███████▋  | 12423/16104 [57:21:26<12:04:19, 11.81s/it]

 77%|███████▋  | 12424/16104 [57:21:41<13:02:27, 12.76s/it]

 77%|███████▋  | 12425/16104 [57:21:57<13:56:42, 13.65s/it]

 77%|███████▋  | 12426/16104 [57:22:15<15:16:21, 14.95s/it]

 77%|███████▋  | 12427/16104 [57:22:35<16:41:22, 16.34s/it]

 77%|███████▋  | 12428/16104 [57:22:47<15:36:38, 15.29s/it]

 77%|███████▋  | 12429/16104 [57:23:04<16:09:18, 15.83s/it]

 77%|███████▋  | 12430/16104 [57:23:25<17:36:21, 17.25s/it]


 77%|███████▋  | 12432/16104 [57:24:02<18:17:18, 17.93s/it]

 77%|███████▋  | 12433/16104 [57:24:22<18:51:10, 18.49s/it]

 77%|███████▋  | 12434/16104 [57:24:40<18:45:07, 18.39s/it]
{'loss': 0.4586, 'learning_rate': 2.6027415999486533e-07, 'rewards/chosen': -1.1326558589935303, 'rewards/rejected': -2.7018840312957764, 'rewards/accuracies': 1.0, 'rewards/margins': 1.569228172302246, 'policy_logps/rejected': -495.5712585449219, 'policy_logps/chosen': -521.83447265625, 'referece_logps/rejected': -468.55242919921875, 'referece_logps/chosen': -510.5079345703125, 'logits/rejected': -0.5676580667495728, 'logits/chosen': -0.6095404624938965, 'epoch': 4.63}

 77%|███████▋  | 12435/16104 [57:25:00<19:05:20, 18.73s/it]

 77%|███████▋  | 12436/16104 [57:25:19<19:22:14, 19.01s/it]

 77%|███████▋  | 12437/16104 [57:25:37<18:51:12, 18.51s/it]

 77%|███████▋  | 12438/16104 [57:25:48<16:36:00, 16.30s/it]


 77%|███████▋  | 12440/16104 [57:26:28<18:35:52, 18.27s/it]
{'loss': 0.3913, 'learning_rate': 2.594626614187815e-07, 'rewards/chosen': -0.46495965123176575, 'rewards/rejected': -1.8817076683044434, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4167479276657104, 'policy_logps/rejected': -232.20872497558594, 'policy_logps/chosen': -420.81549072265625, 'referece_logps/rejected': -213.39166259765625, 'referece_logps/chosen': -416.1658630371094, 'logits/rejected': -0.5714563131332397, 'logits/chosen': -0.5896597504615784, 'epoch': 4.63}

 77%|███████▋  | 12441/16104 [57:26:39<16:26:25, 16.16s/it]


 77%|███████▋  | 12443/16104 [57:27:06<15:00:51, 14.76s/it]
{'loss': 0.4806, 'learning_rate': 2.590573164636607e-07, 'rewards/chosen': 0.03602256998419762, 'rewards/rejected': -1.9778661727905273, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0138885974884033, 'policy_logps/rejected': -609.4927978515625, 'policy_logps/chosen': -580.3109741210938, 'referece_logps/rejected': -589.7141723632812, 'referece_logps/chosen': -580.6712646484375, 'logits/rejected': -0.40355587005615234, 'logits/chosen': -0.22657006978988647, 'epoch': 4.64}


 77%|███████▋  | 12445/16104 [57:27:46<17:44:37, 17.46s/it]
{'loss': 0.3533, 'learning_rate': 2.5878723634673917e-07, 'rewards/chosen': -0.001399114727973938, 'rewards/rejected': -1.9547028541564941, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9533036947250366, 'policy_logps/rejected': -505.1595153808594, 'policy_logps/chosen': -420.6016845703125, 'referece_logps/rejected': -485.61248779296875, 'referece_logps/chosen': -420.5876770019531, 'logits/rejected': 0.11736246943473816, 'logits/chosen': 0.07029462605714798, 'epoch': 4.64}

 77%|███████▋  | 12446/16104 [57:28:04<17:43:59, 17.45s/it]

 77%|███████▋  | 12447/16104 [57:28:20<17:16:13, 17.00s/it]

 77%|███████▋  | 12448/16104 [57:28:38<17:41:20, 17.42s/it]

 77%|███████▋  | 12449/16104 [57:28:54<17:16:46, 17.02s/it]

 77%|███████▋  | 12450/16104 [57:29:14<18:09:15, 17.89s/it]

 77%|███████▋  | 12451/16104 [57:29:32<18:10:41, 17.91s/it]

 77%|███████▋  | 12452/16104 [57:29:47<17:15:01, 17.00s/it]

 77%|███████▋  | 12453/16104 [57:30:01<16:21:31, 16.13s/it]

 77%|███████▋  | 12454/16104 [57:30:15<15:37:55, 15.42s/it]

 77%|███████▋  | 12455/16104 [57:30:29<15:14:26, 15.04s/it]

 77%|███████▋  | 12456/16104 [57:30:41<14:27:10, 14.26s/it]

 77%|███████▋  | 12457/16104 [57:30:58<15:06:50, 14.92s/it]

 77%|███████▋  | 12458/16104 [57:31:14<15:27:07, 15.26s/it]

 77%|███████▋  | 12459/16104 [57:31:31<16:02:07, 15.84s/it]


 77%|███████▋  | 12461/16104 [57:32:01<15:14:30, 15.06s/it]
{'loss': 0.3867, 'learning_rate': 2.5663091668469604e-07, 'rewards/chosen': -0.1491168886423111, 'rewards/rejected': -2.2316627502441406, 'rewards/accuracies': 0.875, 'rewards/margins': 2.082545757293701, 'policy_logps/rejected': -398.9515380859375, 'policy_logps/chosen': -378.3291015625, 'referece_logps/rejected': -376.6348876953125, 'referece_logps/chosen': -376.83795166015625, 'logits/rejected': 0.22596368193626404, 'logits/chosen': 0.16345790028572083, 'epoch': 4.64}

 77%|███████▋  | 12462/16104 [57:32:17<15:37:18, 15.44s/it]

 77%|███████▋  | 12463/16104 [57:32:35<16:26:35, 16.26s/it]

 77%|███████▋  | 12464/16104 [57:32:55<17:28:32, 17.28s/it]

 77%|███████▋  | 12465/16104 [57:33:13<17:42:41, 17.52s/it]

 77%|███████▋  | 12466/16104 [57:33:33<18:36:24, 18.41s/it]

 77%|███████▋  | 12467/16104 [57:33:46<16:55:46, 16.76s/it]

 77%|███████▋  | 12468/16104 [57:34:06<17:44:59, 17.57s/it]

 77%|███████▋  | 12469/16104 [57:34:26<18:39:43, 18.48s/it]

 77%|███████▋  | 12470/16104 [57:34:48<19:38:35, 19.46s/it]


 77%|███████▋  | 12472/16104 [57:35:11<15:24:26, 15.27s/it]
{'loss': 0.3855, 'learning_rate': 2.5515291105212977e-07, 'rewards/chosen': -1.0607872009277344, 'rewards/rejected': -2.360755443572998, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2999682426452637, 'policy_logps/rejected': -418.850830078125, 'policy_logps/chosen': -386.0319519042969, 'referece_logps/rejected': -395.2432861328125, 'referece_logps/chosen': -375.4241027832031, 'logits/rejected': -0.8139874935150146, 'logits/chosen': -0.6579758524894714, 'epoch': 4.65}

 77%|███████▋  | 12473/16104 [57:35:30<16:40:03, 16.53s/it]


 77%|███████▋  | 12475/16104 [57:36:11<18:24:01, 18.25s/it]
{'loss': 0.4572, 'learning_rate': 2.5475045104095205e-07, 'rewards/chosen': -0.8725244402885437, 'rewards/rejected': -2.555889844894409, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6833653450012207, 'policy_logps/rejected': -577.94775390625, 'policy_logps/chosen': -741.1119384765625, 'referece_logps/rejected': -552.3888549804688, 'referece_logps/chosen': -732.38671875, 'logits/rejected': 0.32838812470436096, 'logits/chosen': 0.47069263458251953, 'epoch': 4.65}

 77%|███████▋  | 12476/16104 [57:36:28<18:06:04, 17.96s/it]

 77%|███████▋  | 12477/16104 [57:36:47<18:26:49, 18.31s/it]


 77%|███████▋  | 12479/16104 [57:37:09<14:33:34, 14.46s/it]
{'loss': 0.5198, 'learning_rate': 2.542142597714525e-07, 'rewards/chosen': -0.3811866044998169, 'rewards/rejected': -1.173583745956421, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7923972606658936, 'policy_logps/rejected': -505.80755615234375, 'policy_logps/chosen': -519.0557861328125, 'referece_logps/rejected': -494.07171630859375, 'referece_logps/chosen': -515.243896484375, 'logits/rejected': -0.3555578589439392, 'logits/chosen': -0.3238259553909302, 'epoch': 4.65}

 77%|███████▋  | 12480/16104 [57:37:20<13:40:25, 13.58s/it]

 78%|███████▊  | 12481/16104 [57:37:36<14:16:13, 14.18s/it]

 78%|███████▊  | 12482/16104 [57:37:56<16:04:13, 15.97s/it]

 78%|███████▊  | 12483/16104 [57:38:15<17:02:49, 16.95s/it]

 78%|███████▊  | 12484/16104 [57:38:27<15:36:19, 15.52s/it]

 78%|███████▊  | 12485/16104 [57:38:46<16:29:43, 16.41s/it]

 78%|███████▊  | 12486/16104 [57:39:05<17:26:34, 17.36s/it]

 78%|███████▊  | 12487/16104 [57:39:18<15:56:51, 15.87s/it]

 78%|███████▊  | 12488/16104 [57:39:40<17:48:14, 17.73s/it]

 78%|███████▊  | 12489/16104 [57:39:54<16:39:38, 16.59s/it]

 78%|███████▊  | 12490/16104 [57:40:10<16:24:11, 16.34s/it]

 78%|███████▊  | 12491/16104 [57:40:25<15:57:26, 15.90s/it]

 78%|███████▊  | 12492/16104 [57:40:41<16:02:58, 16.00s/it]

 78%|███████▊  | 12493/16104 [57:41:00<17:00:55, 16.96s/it]


 78%|███████▊  | 12495/16104 [57:41:39<18:09:25, 18.11s/it]
{'loss': 0.3524, 'learning_rate': 2.520743250971514e-07, 'rewards/chosen': -0.5815274715423584, 'rewards/rejected': -1.1651759147644043, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5836483240127563, 'policy_logps/rejected': -383.8513488769531, 'policy_logps/chosen': -566.0901489257812, 'referece_logps/rejected': -372.1996154785156, 'referece_logps/chosen': -560.27490234375, 'logits/rejected': -0.809309184551239, 'logits/chosen': -0.8534712791442871, 'epoch': 4.66}


 78%|███████▊  | 12497/16104 [57:42:17<18:34:13, 18.53s/it]
{'loss': 0.3482, 'learning_rate': 2.51807377397515e-07, 'rewards/chosen': -0.6392122507095337, 'rewards/rejected': -1.324698805809021, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6854866147041321, 'policy_logps/rejected': -349.27996826171875, 'policy_logps/chosen': -578.9774780273438, 'referece_logps/rejected': -336.0329895019531, 'referece_logps/chosen': -572.58544921875, 'logits/rejected': -0.07040679454803467, 'logits/chosen': -0.0909498780965805, 'epoch': 4.66}

 78%|███████▊  | 12498/16104 [57:42:37<18:53:20, 18.86s/it]

 78%|███████▊  | 12499/16104 [57:42:54<18:12:19, 18.18s/it]

 78%|███████▊  | 12500/16104 [57:43:12<18:18:04, 18.28s/it]

 78%|███████▊  | 12501/16104 [57:43:41<21:39:02, 21.63s/it]

 78%|███████▊  | 12502/16104 [57:43:59<20:17:51, 20.29s/it]

 78%|███████▊  | 12503/16104 [57:44:17<19:45:04, 19.75s/it]


 78%|███████▊  | 12505/16104 [57:44:53<18:47:03, 18.79s/it]
{'loss': 0.5153, 'learning_rate': 2.507407976596725e-07, 'rewards/chosen': -0.9410908222198486, 'rewards/rejected': -1.3990790843963623, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4579882025718689, 'policy_logps/rejected': -368.73065185546875, 'policy_logps/chosen': -351.7605895996094, 'referece_logps/rejected': -354.7398681640625, 'referece_logps/chosen': -342.3497009277344, 'logits/rejected': 0.7011779546737671, 'logits/chosen': 0.7133727669715881, 'epoch': 4.66}


 78%|███████▊  | 12507/16104 [57:45:19<15:40:40, 15.69s/it]
{'loss': 0.4218, 'learning_rate': 2.5047445570611303e-07, 'rewards/chosen': -0.3838402330875397, 'rewards/rejected': -2.027573823928833, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6437335014343262, 'policy_logps/rejected': -285.6883239746094, 'policy_logps/chosen': -468.062744140625, 'referece_logps/rejected': -265.4126281738281, 'referece_logps/chosen': -464.224365234375, 'logits/rejected': 0.05360402166843414, 'logits/chosen': 0.08353282511234283, 'epoch': 4.66}

 78%|███████▊  | 12508/16104 [57:45:39<16:42:13, 16.72s/it]

 78%|███████▊  | 12509/16104 [57:45:58<17:32:45, 17.57s/it]

 78%|███████▊  | 12510/16104 [57:46:16<17:33:02, 17.58s/it]

 78%|███████▊  | 12511/16104 [57:46:33<17:26:52, 17.48s/it]


 78%|███████▊  | 12513/16104 [57:47:06<16:56:51, 16.99s/it]
{'loss': 0.3707, 'learning_rate': 2.496761576892118e-07, 'rewards/chosen': -0.733243465423584, 'rewards/rejected': -3.3009142875671387, 'rewards/accuracies': 0.625, 'rewards/margins': 2.5676708221435547, 'policy_logps/rejected': -530.3655395507812, 'policy_logps/chosen': -383.28076171875, 'referece_logps/rejected': -497.35638427734375, 'referece_logps/chosen': -375.94830322265625, 'logits/rejected': 0.1674969643354416, 'logits/chosen': 0.3294903039932251, 'epoch': 4.66}

 78%|███████▊  | 12514/16104 [57:47:25<17:42:23, 17.76s/it]

 78%|███████▊  | 12515/16104 [57:47:45<18:12:10, 18.26s/it]

 78%|███████▊  | 12516/16104 [57:48:04<18:36:02, 18.66s/it]


 78%|███████▊  | 12518/16104 [57:48:45<19:32:39, 19.62s/it]

 78%|███████▊  | 12519/16104 [57:49:03<19:12:29, 19.29s/it]
{'loss': 0.4157, 'learning_rate': 2.488789523419631e-07, 'rewards/chosen': -1.3649393320083618, 'rewards/rejected': -2.0416715145111084, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6767323017120361, 'policy_logps/rejected': -378.7781677246094, 'policy_logps/chosen': -338.24749755859375, 'referece_logps/rejected': -358.3614807128906, 'referece_logps/chosen': -324.5981140136719, 'logits/rejected': -0.4508621096611023, 'logits/chosen': -0.5005536079406738, 'epoch': 4.66}


 78%|███████▊  | 12521/16104 [57:49:41<18:43:27, 18.81s/it]

 78%|███████▊  | 12522/16104 [57:49:59<18:21:34, 18.45s/it]

 78%|███████▊  | 12523/16104 [57:50:10<16:04:11, 16.16s/it]
{'loss': 0.4304, 'learning_rate': 2.483480897225297e-07, 'rewards/chosen': -0.43721961975097656, 'rewards/rejected': -1.9188477993011475, 'rewards/accuracies': 1.0, 'rewards/margins': 1.481628179550171, 'policy_logps/rejected': -490.14691162109375, 'policy_logps/chosen': -547.0706176757812, 'referece_logps/rejected': -470.9583740234375, 'referece_logps/chosen': -542.6983642578125, 'logits/rejected': -0.22224725782871246, 'logits/chosen': -0.34688228368759155, 'epoch': 4.67}


 78%|███████▊  | 12525/16104 [57:50:42<16:13:42, 16.32s/it]
{'loss': 0.4818, 'learning_rate': 2.4808284082530826e-07, 'rewards/chosen': -0.23804745078086853, 'rewards/rejected': -0.8678190112113953, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6297715902328491, 'policy_logps/rejected': -504.2357177734375, 'policy_logps/chosen': -483.8909606933594, 'referece_logps/rejected': -495.5575256347656, 'referece_logps/chosen': -481.5104675292969, 'logits/rejected': 0.09246042370796204, 'logits/chosen': 0.034062620252370834, 'epoch': 4.67}


 78%|███████▊  | 12527/16104 [57:51:15<16:34:31, 16.68s/it]

 78%|███████▊  | 12528/16104 [57:51:32<16:28:46, 16.59s/it]

 78%|███████▊  | 12529/16104 [57:51:48<16:24:04, 16.52s/it]

 78%|███████▊  | 12530/16104 [57:52:04<16:07:13, 16.24s/it]

 78%|███████▊  | 12531/16104 [57:52:19<15:45:00, 15.87s/it]

 78%|███████▊  | 12532/16104 [57:52:39<17:03:28, 17.19s/it]

 78%|███████▊  | 12533/16104 [57:52:56<17:01:27, 17.16s/it]

 78%|███████▊  | 12534/16104 [57:53:14<17:14:56, 17.39s/it]

 78%|███████▊  | 12535/16104 [57:53:29<16:41:55, 16.84s/it]
{'loss': 0.3732, 'learning_rate': 2.4675842218032904e-07, 'rewards/chosen': -0.4845385253429413, 'rewards/rejected': -1.3684014081954956, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8838630318641663, 'policy_logps/rejected': -376.1705017089844, 'policy_logps/chosen': -379.2262268066406, 'referece_logps/rejected': -362.4864501953125, 'referece_logps/chosen': -374.380859375, 'logits/rejected': -0.21705162525177002, 'logits/chosen': -0.3560757637023926, 'epoch': 4.67}


 78%|███████▊  | 12537/16104 [57:54:05<17:08:30, 17.30s/it]

 78%|███████▊  | 12538/16104 [57:54:23<17:13:12, 17.38s/it]

 78%|███████▊  | 12539/16104 [57:54:39<16:49:34, 16.99s/it]

 78%|███████▊  | 12540/16104 [57:54:49<14:53:46, 15.05s/it]

 78%|███████▊  | 12541/16104 [57:55:09<16:18:39, 16.48s/it]

 78%|███████▊  | 12542/16104 [57:55:23<15:27:28, 15.62s/it]

 78%|███████▊  | 12543/16104 [57:55:40<16:03:53, 16.24s/it]

 78%|███████▊  | 12544/16104 [57:55:56<15:48:10, 15.98s/it]

 78%|███████▊  | 12545/16104 [57:56:08<14:35:12, 14.75s/it]
{'loss': 0.4242, 'learning_rate': 2.454370505309307e-07, 'rewards/chosen': -0.8134236335754395, 'rewards/rejected': -1.3277610540390015, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5143375396728516, 'policy_logps/rejected': -502.767333984375, 'policy_logps/chosen': -534.4533081054688, 'referece_logps/rejected': -489.48974609375, 'referece_logps/chosen': -526.319091796875, 'logits/rejected': -0.3758571743965149, 'logits/chosen': -0.3213109076023102, 'epoch': 4.67}


 78%|███████▊  | 12547/16104 [57:56:35<13:51:20, 14.02s/it]
{'loss': 0.44, 'learning_rate': 2.4517314231111396e-07, 'rewards/chosen': -0.3207084834575653, 'rewards/rejected': -1.8546146154403687, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5339059829711914, 'policy_logps/rejected': -363.6918640136719, 'policy_logps/chosen': -283.1992492675781, 'referece_logps/rejected': -345.1457214355469, 'referece_logps/chosen': -279.99212646484375, 'logits/rejected': -0.6902906894683838, 'logits/chosen': -0.47599485516548157, 'epoch': 4.67}


 78%|███████▊  | 12549/16104 [57:57:13<16:23:16, 16.60s/it]

 78%|███████▊  | 12550/16104 [57:57:31<16:51:18, 17.07s/it]

 78%|███████▊  | 12551/16104 [57:57:51<17:36:00, 17.83s/it]

 78%|███████▊  | 12552/16104 [57:58:10<17:57:42, 18.20s/it]

 78%|███████▊  | 12553/16104 [57:58:30<18:26:32, 18.70s/it]

 78%|███████▊  | 12554/16104 [57:58:43<16:44:07, 16.97s/it]
{'loss': 0.4038, 'learning_rate': 2.4425042564574185e-07, 'rewards/chosen': -0.7067081928253174, 'rewards/rejected': -2.711183547973633, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0044753551483154, 'policy_logps/rejected': -399.74517822265625, 'policy_logps/chosen': -401.2492370605469, 'referece_logps/rejected': -372.6333312988281, 'referece_logps/chosen': -394.1821594238281, 'logits/rejected': 0.1791505217552185, 'logits/chosen': 0.23231840133666992, 'epoch': 4.68}


 78%|███████▊  | 12556/16104 [57:59:23<18:32:46, 18.82s/it]

 78%|███████▊  | 12557/16104 [57:59:41<18:15:43, 18.53s/it]

 78%|███████▊  | 12558/16104 [57:59:58<17:44:54, 18.02s/it]

 78%|███████▊  | 12559/16104 [58:00:18<18:26:13, 18.72s/it]

 78%|███████▊  | 12560/16104 [58:00:38<18:41:25, 18.99s/it]

 78%|███████▊  | 12561/16104 [58:01:00<19:32:59, 19.86s/it]

 78%|███████▊  | 12562/16104 [58:01:14<17:50:58, 18.14s/it]

 78%|███████▊  | 12563/16104 [58:01:30<17:10:03, 17.45s/it]

 78%|███████▊  | 12564/16104 [58:01:44<16:18:14, 16.58s/it]

 78%|███████▊  | 12565/16104 [58:02:04<17:12:40, 17.51s/it]

 78%|███████▊  | 12566/16104 [58:02:24<17:53:38, 18.21s/it]
{'loss': 0.3476, 'learning_rate': 2.4267211180074707e-07, 'rewards/chosen': -1.2454677820205688, 'rewards/rejected': -2.8773300647735596, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6318621635437012, 'policy_logps/rejected': -283.55133056640625, 'policy_logps/chosen': -207.1755828857422, 'referece_logps/rejected': -254.77801513671875, 'referece_logps/chosen': -194.72088623046875, 'logits/rejected': 0.3093142807483673, 'logits/chosen': 0.30565205216407776, 'epoch': 4.68}


 78%|███████▊  | 12568/16104 [58:03:00<17:53:34, 18.22s/it]

 78%|███████▊  | 12569/16104 [58:03:20<18:15:56, 18.60s/it]

 78%|███████▊  | 12570/16104 [58:03:33<16:44:11, 17.05s/it]

 78%|███████▊  | 12571/16104 [58:03:50<16:35:42, 16.91s/it]

 78%|███████▊  | 12572/16104 [58:04:09<17:22:27, 17.71s/it]

 78%|███████▊  | 12573/16104 [58:04:28<17:36:46, 17.96s/it]

 78%|███████▊  | 12574/16104 [58:04:40<15:56:18, 16.25s/it]

 78%|███████▊  | 12575/16104 [58:04:52<14:32:48, 14.84s/it]
{'loss': 0.4333, 'learning_rate': 2.4149127094628464e-07, 'rewards/chosen': -0.8535184860229492, 'rewards/rejected': -2.221057653427124, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3675391674041748, 'policy_logps/rejected': -378.9884033203125, 'policy_logps/chosen': -468.13470458984375, 'referece_logps/rejected': -356.77783203125, 'referece_logps/chosen': -459.5995178222656, 'logits/rejected': 0.4049970209598541, 'logits/chosen': 0.539484441280365, 'epoch': 4.69}


 78%|███████▊  | 12577/16104 [58:05:21<14:29:31, 14.79s/it]

 78%|███████▊  | 12578/16104 [58:05:44<16:41:09, 17.04s/it]

 78%|███████▊  | 12579/16104 [58:06:03<17:25:58, 17.80s/it]

 78%|███████▊  | 12580/16104 [58:06:18<16:27:43, 16.82s/it]

 78%|███████▊  | 12581/16104 [58:06:34<16:24:05, 16.76s/it]

 78%|███████▊  | 12582/16104 [58:06:56<17:56:08, 18.33s/it]

 78%|███████▊  | 12583/16104 [58:07:15<17:55:47, 18.33s/it]

 78%|███████▊  | 12584/16104 [58:07:28<16:26:31, 16.82s/it]

 78%|███████▊  | 12585/16104 [58:07:47<17:02:21, 17.43s/it]

 78%|███████▊  | 12586/16104 [58:08:00<15:51:45, 16.23s/it]

 78%|███████▊  | 12587/16104 [58:08:13<14:44:35, 15.09s/it]

 78%|███████▊  | 12588/16104 [58:08:24<13:28:41, 13.80s/it]

 78%|███████▊  | 12589/16104 [58:08:35<12:52:36, 13.19s/it]

 78%|███████▊  | 12590/16104 [58:08:56<14:58:15, 15.34s/it]

 78%|███████▊  | 12591/16104 [58:09:11<14:55:45, 15.30s/it]

 78%|███████▊  | 12592/16104 [58:09:29<15:51:32, 16.26s/it]

 78%|███████▊  | 12593/16104 [58:09:49<16:49:11, 17.25s/it]

 78%|███████▊  | 12594/16104 [58:10:05<16:34:13, 17.00s/it]

 78%|███████▊  | 12595/16104 [58:10:22<16:25:23, 16.85s/it]
{'loss': 0.4533, 'learning_rate': 2.3887608386642345e-07, 'rewards/chosen': -0.0859375, 'rewards/rejected': -1.3074110746383667, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2214736938476562, 'policy_logps/rejected': -571.3358154296875, 'policy_logps/chosen': -618.0427856445312, 'referece_logps/rejected': -558.26171875, 'referece_logps/chosen': -617.1834106445312, 'logits/rejected': 0.5183839797973633, 'logits/chosen': 0.5958669781684875, 'epoch': 4.69}


 78%|███████▊  | 12597/16104 [58:10:50<14:48:09, 15.20s/it]

 78%|███████▊  | 12598/16104 [58:11:09<16:10:29, 16.61s/it]

 78%|███████▊  | 12599/16104 [58:11:29<17:00:47, 17.47s/it]

 78%|███████▊  | 12600/16104 [58:11:42<15:42:13, 16.13s/it]

 78%|███████▊  | 12601/16104 [58:11:56<15:11:07, 15.61s/it]

 78%|███████▊  | 12602/16104 [58:12:14<15:51:29, 16.30s/it]
{'loss': 0.3772, 'learning_rate': 2.3796367576806675e-07, 'rewards/chosen': -0.28372398018836975, 'rewards/rejected': -1.6464837789535522, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3627598285675049, 'policy_logps/rejected': -439.3511047363281, 'policy_logps/chosen': -462.97576904296875, 'referece_logps/rejected': -422.8862609863281, 'referece_logps/chosen': -460.1385192871094, 'logits/rejected': -0.07718777656555176, 'logits/chosen': -0.035937584936618805, 'epoch': 4.7}


 78%|███████▊  | 12604/16104 [58:12:45<15:39:54, 16.11s/it]

 78%|███████▊  | 12605/16104 [58:12:58<14:43:33, 15.15s/it]

 78%|███████▊  | 12606/16104 [58:13:14<15:03:34, 15.50s/it]

 78%|███████▊  | 12607/16104 [58:13:36<16:55:25, 17.42s/it]
{'loss': 0.3897, 'learning_rate': 2.3731288036420306e-07, 'rewards/chosen': -1.4005638360977173, 'rewards/rejected': -2.48177170753479, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0812078714370728, 'policy_logps/rejected': -477.31085205078125, 'policy_logps/chosen': -510.79022216796875, 'referece_logps/rejected': -452.49310302734375, 'referece_logps/chosen': -496.78460693359375, 'logits/rejected': -0.27842187881469727, 'logits/chosen': -0.36243098974227905, 'epoch': 4.7}


 78%|███████▊  | 12609/16104 [58:14:12<17:03:48, 17.58s/it]

 78%|███████▊  | 12610/16104 [58:14:32<17:37:14, 18.16s/it]
{'loss': 0.3886, 'learning_rate': 2.369227733044258e-07, 'rewards/chosen': -0.15275689959526062, 'rewards/rejected': -1.7534557580947876, 'rewards/accuracies': 0.625, 'rewards/margins': 1.6006988286972046, 'policy_logps/rejected': -516.0792846679688, 'policy_logps/chosen': -507.90740966796875, 'referece_logps/rejected': -498.5447692871094, 'referece_logps/chosen': -506.3798828125, 'logits/rejected': -0.37744295597076416, 'logits/chosen': -0.454373300075531, 'epoch': 4.7}


 78%|███████▊  | 12612/16104 [58:15:05<16:38:31, 17.16s/it]

 78%|███████▊  | 12613/16104 [58:15:19<15:41:59, 16.19s/it]

 78%|███████▊  | 12614/16104 [58:15:31<14:36:00, 15.06s/it]

 78%|███████▊  | 12615/16104 [58:15:50<15:44:55, 16.25s/it]

 78%|███████▊  | 12616/16104 [58:16:05<15:18:26, 15.80s/it]

 78%|███████▊  | 12617/16104 [58:16:27<17:13:36, 17.78s/it]

 78%|███████▊  | 12618/16104 [58:16:42<16:21:02, 16.89s/it]

 78%|███████▊  | 12619/16104 [58:16:55<15:06:13, 15.60s/it]

 78%|███████▊  | 12620/16104 [58:17:13<15:52:55, 16.41s/it]

 78%|███████▊  | 12621/16104 [58:17:31<16:23:17, 16.94s/it]

 78%|███████▊  | 12622/16104 [58:17:43<14:59:53, 15.51s/it]

 78%|███████▊  | 12623/16104 [58:18:03<16:08:23, 16.69s/it]

 78%|███████▊  | 12624/16104 [58:18:24<17:32:25, 18.15s/it]

 78%|███████▊  | 12625/16104 [58:18:41<17:09:48, 17.76s/it]

 78%|███████▊  | 12626/16104 [58:19:01<17:40:21, 18.29s/it]

 78%|███████▊  | 12627/16104 [58:19:18<17:17:37, 17.91s/it]

 78%|███████▊  | 12628/16104 [58:19:30<15:34:31, 16.13s/it]

 78%|███████▊  | 12629/16104 [58:19:51<17:08:35, 17.76s/it]
{'loss': 0.4371, 'learning_rate': 2.3445855249126012e-07, 'rewards/chosen': -0.10660745203495026, 'rewards/rejected': -1.7403292655944824, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6337217092514038, 'policy_logps/rejected': -430.2334899902344, 'policy_logps/chosen': -529.7408447265625, 'referece_logps/rejected': -412.8302001953125, 'referece_logps/chosen': -528.6747436523438, 'logits/rejected': 0.7713972926139832, 'logits/chosen': 0.7908337116241455, 'epoch': 4.71}

 78%|███████▊  | 12630/16104 [58:20:04<15:47:20, 16.36s/it]


 78%|███████▊  | 12632/16104 [58:20:44<17:22:03, 18.01s/it]

 78%|███████▊  | 12633/16104 [58:21:01<17:04:17, 17.71s/it]
{'loss': 0.3581, 'learning_rate': 2.3394119246260058e-07, 'rewards/chosen': -0.804675281047821, 'rewards/rejected': -1.9631553888320923, 'rewards/accuracies': 0.875, 'rewards/margins': 1.158480167388916, 'policy_logps/rejected': -303.6104431152344, 'policy_logps/chosen': -471.95513916015625, 'referece_logps/rejected': -283.9789123535156, 'referece_logps/chosen': -463.9084167480469, 'logits/rejected': -0.09333420544862747, 'logits/chosen': -0.11632411181926727, 'epoch': 4.71}

 78%|███████▊  | 12634/16104 [58:21:14<15:48:43, 16.40s/it]


 78%|███████▊  | 12636/16104 [58:21:43<15:07:01, 15.69s/it]

 78%|███████▊  | 12637/16104 [58:22:03<16:14:12, 16.86s/it]

 78%|███████▊  | 12638/16104 [58:22:16<15:03:57, 15.65s/it]

 78%|███████▊  | 12639/16104 [58:22:27<13:57:44, 14.51s/it]

 78%|███████▊  | 12640/16104 [58:22:47<15:25:48, 16.04s/it]
{'loss': 0.395, 'learning_rate': 2.330370056688018e-07, 'rewards/chosen': -0.7502996921539307, 'rewards/rejected': -1.703712821006775, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9534132480621338, 'policy_logps/rejected': -326.0640869140625, 'policy_logps/chosen': -355.87384033203125, 'referece_logps/rejected': -309.0269775390625, 'referece_logps/chosen': -348.370849609375, 'logits/rejected': -0.6849040985107422, 'logits/chosen': -0.7905375361442566, 'epoch': 4.71}


 79%|███████▊  | 12642/16104 [58:23:24<16:30:37, 17.17s/it]

 79%|███████▊  | 12643/16104 [58:23:37<15:29:21, 16.11s/it]
{'loss': 0.4523, 'learning_rate': 2.3264996231374278e-07, 'rewards/chosen': -0.35480618476867676, 'rewards/rejected': -3.3652234077453613, 'rewards/accuracies': 1.0, 'rewards/margins': 3.0104174613952637, 'policy_logps/rejected': -514.272705078125, 'policy_logps/chosen': -464.6018981933594, 'referece_logps/rejected': -480.6204528808594, 'referece_logps/chosen': -461.0538330078125, 'logits/rejected': -0.5406798720359802, 'logits/chosen': -0.4148256480693817, 'epoch': 4.71}

 79%|███████▊  | 12644/16104 [58:23:52<15:04:17, 15.68s/it]

 79%|███████▊  | 12645/16104 [58:24:12<16:17:24, 16.95s/it]

 79%|███████▊  | 12646/16104 [58:24:34<17:45:27, 18.49s/it]


 79%|███████▊  | 12648/16104 [58:25:14<18:10:59, 18.94s/it]
{'loss': 0.4138, 'learning_rate': 2.320055109384007e-07, 'rewards/chosen': 0.6617354154586792, 'rewards/rejected': -0.4468901753425598, 'rewards/accuracies': 0.5, 'rewards/margins': 1.1086256504058838, 'policy_logps/rejected': -416.7114562988281, 'policy_logps/chosen': -490.50762939453125, 'referece_logps/rejected': -412.2425537109375, 'referece_logps/chosen': -497.12506103515625, 'logits/rejected': 0.3114174008369446, 'logits/chosen': 0.2964593172073364, 'epoch': 4.71}

 79%|███████▊  | 12649/16104 [58:25:35<18:46:01, 19.55s/it]


 79%|███████▊  | 12651/16104 [58:26:09<17:29:23, 18.23s/it]

 79%|███████▊  | 12652/16104 [58:26:27<17:19:08, 18.06s/it]
{'loss': 0.4072, 'learning_rate': 2.314905090082807e-07, 'rewards/chosen': -0.6338043212890625, 'rewards/rejected': -2.5252015590667725, 'rewards/accuracies': 0.75, 'rewards/margins': 1.89139723777771, 'policy_logps/rejected': -478.2943420410156, 'policy_logps/chosen': -382.38397216796875, 'referece_logps/rejected': -453.0423583984375, 'referece_logps/chosen': -376.0459289550781, 'logits/rejected': 0.7300445437431335, 'logits/chosen': 0.7619568705558777, 'epoch': 4.71}

 79%|███████▊  | 12653/16104 [58:26:46<17:38:24, 18.40s/it]

 79%|███████▊  | 12654/16104 [58:27:04<17:34:42, 18.34s/it]


 79%|███████▊  | 12656/16104 [58:27:43<17:56:11, 18.73s/it]
{'loss': 0.3399, 'learning_rate': 2.309760044794209e-07, 'rewards/chosen': -0.1954374462366104, 'rewards/rejected': -1.755601167678833, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5601637363433838, 'policy_logps/rejected': -564.4261474609375, 'policy_logps/chosen': -569.1920166015625, 'referece_logps/rejected': -546.8701171875, 'referece_logps/chosen': -567.2376098632812, 'logits/rejected': -0.09856387972831726, 'logits/chosen': 0.24717718362808228, 'epoch': 4.72}


 79%|███████▊  | 12658/16104 [58:28:16<16:33:47, 17.30s/it]
{'loss': 0.4284, 'learning_rate': 2.3071893884453907e-07, 'rewards/chosen': -0.7484573721885681, 'rewards/rejected': -1.5318070650100708, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7833495736122131, 'policy_logps/rejected': -406.259033203125, 'policy_logps/chosen': -337.27197265625, 'referece_logps/rejected': -390.94097900390625, 'referece_logps/chosen': -329.7873840332031, 'logits/rejected': -0.5170212984085083, 'logits/chosen': -0.45375415682792664, 'epoch': 4.72}

 79%|███████▊  | 12659/16104 [58:28:35<16:56:10, 17.70s/it]

 79%|███████▊  | 12660/16104 [58:28:53<17:04:35, 17.85s/it]

 79%|███████▊  | 12661/16104 [58:29:05<15:25:55, 16.14s/it]


 79%|███████▊  | 12663/16104 [58:29:46<17:39:22, 18.47s/it]

 79%|███████▊  | 12664/16104 [58:30:02<16:47:58, 17.58s/it]

 79%|███████▊  | 12665/16104 [58:30:12<14:48:55, 15.51s/it]

 79%|███████▊  | 12666/16104 [58:30:33<16:23:05, 17.16s/it]
{'loss': 0.3938, 'learning_rate': 2.296919214723154e-07, 'rewards/chosen': 0.17600411176681519, 'rewards/rejected': -2.3401312828063965, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5161356925964355, 'policy_logps/rejected': -713.164794921875, 'policy_logps/chosen': -593.4815063476562, 'referece_logps/rejected': -689.7634887695312, 'referece_logps/chosen': -595.241455078125, 'logits/rejected': 0.5043257474899292, 'logits/chosen': 0.6104780435562134, 'epoch': 4.72}


 79%|███████▊  | 12668/16104 [58:31:04<15:08:33, 15.87s/it]

 79%|███████▊  | 12669/16104 [58:31:16<13:53:44, 14.56s/it]
{'loss': 0.4287, 'learning_rate': 2.2930730396052768e-07, 'rewards/chosen': -0.1278892457485199, 'rewards/rejected': -1.3766510486602783, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2487616539001465, 'policy_logps/rejected': -413.24981689453125, 'policy_logps/chosen': -410.0628662109375, 'referece_logps/rejected': -399.4833068847656, 'referece_logps/chosen': -408.7839660644531, 'logits/rejected': 0.04410810023546219, 'logits/chosen': 0.10108505189418793, 'epoch': 4.72}


 79%|███████▊  | 12671/16104 [58:31:46<14:29:15, 15.19s/it]

 79%|███████▊  | 12672/16104 [58:32:07<16:07:59, 16.92s/it]
{'loss': 0.3451, 'learning_rate': 2.2892296703178592e-07, 'rewards/chosen': -1.1247081756591797, 'rewards/rejected': -1.9190658330917358, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7943576574325562, 'policy_logps/rejected': -464.3815612792969, 'policy_logps/chosen': -547.7870483398438, 'referece_logps/rejected': -445.1909484863281, 'referece_logps/chosen': -536.5400390625, 'logits/rejected': -0.2765148878097534, 'logits/chosen': -0.30227380990982056, 'epoch': 4.72}


 79%|███████▊  | 12674/16104 [58:32:34<14:22:10, 15.08s/it]
{'loss': 0.3818, 'learning_rate': 2.2866689836119702e-07, 'rewards/chosen': -0.14359283447265625, 'rewards/rejected': -1.2654242515563965, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1218312978744507, 'policy_logps/rejected': -411.3690185546875, 'policy_logps/chosen': -446.44317626953125, 'referece_logps/rejected': -398.7148132324219, 'referece_logps/chosen': -445.00726318359375, 'logits/rejected': -0.11020452529191971, 'logits/chosen': -0.225319504737854, 'epoch': 4.72}

 79%|███████▊  | 12675/16104 [58:32:53<15:37:41, 16.41s/it]

 79%|███████▊  | 12676/16104 [58:33:05<14:19:51, 15.05s/it]


 79%|███████▊  | 12678/16104 [58:33:40<15:48:44, 16.62s/it]
{'loss': 0.3401, 'learning_rate': 2.2815513548303423e-07, 'rewards/chosen': -0.3709236681461334, 'rewards/rejected': -1.2782772779464722, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9073536396026611, 'policy_logps/rejected': -402.4681396484375, 'policy_logps/chosen': -516.819580078125, 'referece_logps/rejected': -389.6853332519531, 'referece_logps/chosen': -513.1103515625, 'logits/rejected': -0.4329339861869812, 'logits/chosen': -0.3392212986946106, 'epoch': 4.72}

 79%|███████▊  | 12679/16104 [58:33:59<16:19:19, 17.16s/it]

 79%|███████▊  | 12680/16104 [58:34:19<17:05:52, 17.98s/it]


 79%|███████▉  | 12682/16104 [58:34:54<16:45:24, 17.63s/it]

 79%|███████▉  | 12683/16104 [58:35:06<15:08:33, 15.93s/it]

 79%|███████▉  | 12684/16104 [58:35:20<14:25:32, 15.19s/it]
{'loss': 0.4412, 'learning_rate': 2.273884279442263e-07, 'rewards/chosen': -0.4178001284599304, 'rewards/rejected': -2.033921718597412, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6161216497421265, 'policy_logps/rejected': -431.2637634277344, 'policy_logps/chosen': -490.2995300292969, 'referece_logps/rejected': -410.924560546875, 'referece_logps/chosen': -486.12152099609375, 'logits/rejected': -0.5511510372161865, 'logits/chosen': -0.4655348062515259, 'epoch': 4.73}

 79%|███████▉  | 12685/16104 [58:35:35<14:32:22, 15.31s/it]

 79%|███████▉  | 12686/16104 [58:35:53<15:15:31, 16.07s/it]

 79%|███████▉  | 12687/16104 [58:36:11<15:50:07, 16.68s/it]


 79%|███████▉  | 12689/16104 [58:36:45<16:11:22, 17.07s/it]

 79%|███████▉  | 12690/16104 [58:37:06<17:21:17, 18.30s/it]

 79%|███████▉  | 12691/16104 [58:37:24<17:25:51, 18.39s/it]
{'loss': 0.4002, 'learning_rate': 2.2649535792877117e-07, 'rewards/chosen': -0.621559739112854, 'rewards/rejected': -1.9025077819824219, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2809481620788574, 'policy_logps/rejected': -380.3772277832031, 'policy_logps/chosen': -337.637939453125, 'referece_logps/rejected': -361.3521423339844, 'referece_logps/chosen': -331.42236328125, 'logits/rejected': -0.719786524772644, 'logits/chosen': -0.6842614412307739, 'epoch': 4.73}

 79%|███████▉  | 12692/16104 [58:37:39<16:23:13, 17.29s/it]

 79%|███████▉  | 12693/16104 [58:37:59<17:11:39, 18.15s/it]


 79%|███████▉  | 12695/16104 [58:38:39<17:54:03, 18.90s/it]
{'loss': 0.3685, 'learning_rate': 2.259857204642761e-07, 'rewards/chosen': -0.8739585876464844, 'rewards/rejected': -1.5947030782699585, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7207444906234741, 'policy_logps/rejected': -298.4909362792969, 'policy_logps/chosen': -300.28106689453125, 'referece_logps/rejected': -282.54388427734375, 'referece_logps/chosen': -291.5414733886719, 'logits/rejected': -0.4614899754524231, 'logits/chosen': -0.47745010256767273, 'epoch': 4.73}


 79%|███████▉  | 12697/16104 [58:39:20<18:45:39, 19.82s/it]

 79%|███████▉  | 12698/16104 [58:39:34<17:04:45, 18.05s/it]

 79%|███████▉  | 12699/16104 [58:39:54<17:44:18, 18.75s/it]

 79%|███████▉  | 12700/16104 [58:40:15<18:08:56, 19.19s/it]

 79%|███████▉  | 12701/16104 [58:40:35<18:22:43, 19.44s/it]

 79%|███████▉  | 12702/16104 [58:40:46<16:12:23, 17.15s/it]
{'loss': 0.4833, 'learning_rate': 2.2509506054455708e-07, 'rewards/chosen': -0.8888397216796875, 'rewards/rejected': -1.0977351665496826, 'rewards/accuracies': 0.75, 'rewards/margins': 0.20889534056186676, 'policy_logps/rejected': -351.08544921875, 'policy_logps/chosen': -457.76324462890625, 'referece_logps/rejected': -340.1081237792969, 'referece_logps/chosen': -448.87481689453125, 'logits/rejected': 0.4884933829307556, 'logits/chosen': 0.2110905945301056, 'epoch': 4.73}


 79%|███████▉  | 12704/16104 [58:41:18<15:55:36, 16.86s/it]

 79%|███████▉  | 12705/16104 [58:41:30<14:37:17, 15.49s/it]
{'loss': 0.4092, 'learning_rate': 2.2471381924179843e-07, 'rewards/chosen': -0.4505293071269989, 'rewards/rejected': -2.8435659408569336, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3930368423461914, 'policy_logps/rejected': -468.8694763183594, 'policy_logps/chosen': -495.33892822265625, 'referece_logps/rejected': -440.43377685546875, 'referece_logps/chosen': -490.8336486816406, 'logits/rejected': -0.3755107522010803, 'logits/chosen': -0.5310794115066528, 'epoch': 4.73}


 79%|███████▉  | 12707/16104 [58:41:54<12:48:18, 13.57s/it]
{'loss': 0.3899, 'learning_rate': 2.2445981517327205e-07, 'rewards/chosen': -0.04217376187443733, 'rewards/rejected': -1.302466630935669, 'rewards/accuracies': 0.875, 'rewards/margins': 1.260292887687683, 'policy_logps/rejected': -621.6631469726562, 'policy_logps/chosen': -470.9789123535156, 'referece_logps/rejected': -608.6384887695312, 'referece_logps/chosen': -470.55718994140625, 'logits/rejected': -0.5055099725723267, 'logits/chosen': -0.34993264079093933, 'epoch': 4.73}


 79%|███████▉  | 12709/16104 [58:42:26<14:10:32, 15.03s/it]

 79%|███████▉  | 12710/16104 [58:42:39<13:36:22, 14.43s/it]
{'loss': 0.4594, 'learning_rate': 2.240790443732018e-07, 'rewards/chosen': -0.9954766035079956, 'rewards/rejected': -1.5517879724502563, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5563114285469055, 'policy_logps/rejected': -370.6265563964844, 'policy_logps/chosen': -394.48907470703125, 'referece_logps/rejected': -355.10870361328125, 'referece_logps/chosen': -384.5343017578125, 'logits/rejected': 0.18056052923202515, 'logits/chosen': 0.2411636859178543, 'epoch': 4.74}

 79%|███████▉  | 12711/16104 [58:42:51<12:56:07, 13.72s/it]


 79%|███████▉  | 12713/16104 [58:43:23<14:06:45, 14.98s/it]
{'loss': 0.3052, 'learning_rate': 2.2369855605960952e-07, 'rewards/chosen': -0.5540130138397217, 'rewards/rejected': -2.0318994522094727, 'rewards/accuracies': 0.875, 'rewards/margins': 1.477886438369751, 'policy_logps/rejected': -216.65419006347656, 'policy_logps/chosen': -356.45458984375, 'referece_logps/rejected': -196.335205078125, 'referece_logps/chosen': -350.9144592285156, 'logits/rejected': -0.8526566624641418, 'logits/chosen': -1.0549709796905518, 'epoch': 4.74}


 79%|███████▉  | 12715/16104 [58:43:53<13:56:51, 14.82s/it]
{'loss': 0.3322, 'learning_rate': 2.234450541892241e-07, 'rewards/chosen': -0.13078004121780396, 'rewards/rejected': -2.2641279697418213, 'rewards/accuracies': 1.0, 'rewards/margins': 2.133347988128662, 'policy_logps/rejected': -546.017578125, 'policy_logps/chosen': -508.2505187988281, 'referece_logps/rejected': -523.3762817382812, 'referece_logps/chosen': -506.94268798828125, 'logits/rejected': 0.16310623288154602, 'logits/chosen': 0.3197639286518097, 'epoch': 4.74}


 79%|███████▉  | 12717/16104 [58:44:27<15:11:11, 16.14s/it]
{'loss': 0.3865, 'learning_rate': 2.231916779709706e-07, 'rewards/chosen': -1.0983704328536987, 'rewards/rejected': -2.1431362628936768, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0447657108306885, 'policy_logps/rejected': -416.6941833496094, 'policy_logps/chosen': -441.60430908203125, 'referece_logps/rejected': -395.2628173828125, 'referece_logps/chosen': -430.62060546875, 'logits/rejected': -0.414864718914032, 'logits/chosen': -0.4948357939720154, 'epoch': 4.74}

 79%|███████▉  | 12718/16104 [58:44:44<15:28:29, 16.45s/it]


 79%|███████▉  | 12720/16104 [58:45:19<15:52:18, 16.88s/it]
{'loss': 0.3775, 'learning_rate': 2.2281184933101548e-07, 'rewards/chosen': -0.016611285507678986, 'rewards/rejected': -2.3560376167297363, 'rewards/accuracies': 0.875, 'rewards/margins': 2.339426279067993, 'policy_logps/rejected': -579.2936401367188, 'policy_logps/chosen': -556.2688598632812, 'referece_logps/rejected': -555.7332763671875, 'referece_logps/chosen': -556.102783203125, 'logits/rejected': -0.3164311945438385, 'logits/chosen': -0.3615649938583374, 'epoch': 4.74}


 79%|███████▉  | 12722/16104 [58:45:54<16:10:24, 17.22s/it]
{'loss': 0.4371, 'learning_rate': 2.2255878742241408e-07, 'rewards/chosen': -0.9296749830245972, 'rewards/rejected': -0.996281087398529, 'rewards/accuracies': 0.625, 'rewards/margins': 0.06660611927509308, 'policy_logps/rejected': -387.54180908203125, 'policy_logps/chosen': -363.65234375, 'referece_logps/rejected': -377.5790100097656, 'referece_logps/chosen': -354.3556213378906, 'logits/rejected': -0.21094688773155212, 'logits/chosen': -0.16621825098991394, 'epoch': 4.74}

 79%|███████▉  | 12723/16104 [58:46:16<17:27:30, 18.59s/it]

 79%|███████▉  | 12724/16104 [58:46:30<16:09:11, 17.20s/it]


 79%|███████▉  | 12726/16104 [58:47:09<17:22:05, 18.51s/it]

 79%|███████▉  | 12727/16104 [58:47:22<15:55:23, 16.97s/it]
{'loss': 0.3752, 'learning_rate': 2.2192668309590378e-07, 'rewards/chosen': -0.8091524839401245, 'rewards/rejected': -2.005390167236328, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1962378025054932, 'policy_logps/rejected': -507.68658447265625, 'policy_logps/chosen': -548.5374755859375, 'referece_logps/rejected': -487.6326904296875, 'referece_logps/chosen': -540.4459228515625, 'logits/rejected': -0.6012654304504395, 'logits/chosen': -0.6558754444122314, 'epoch': 4.74}

 79%|███████▉  | 12728/16104 [58:47:44<17:15:51, 18.41s/it]

 79%|███████▉  | 12729/16104 [58:48:04<17:36:00, 18.77s/it]

 79%|███████▉  | 12730/16104 [58:48:23<17:42:05, 18.89s/it]

 79%|███████▉  | 12731/16104 [58:48:42<17:39:43, 18.85s/it]


 79%|███████▉  | 12733/16104 [58:49:10<15:12:17, 16.24s/it]
{'loss': 0.4455, 'learning_rate': 2.211691966171908e-07, 'rewards/chosen': -1.1485544443130493, 'rewards/rejected': -3.0592496395111084, 'rewards/accuracies': 1.0, 'rewards/margins': 1.910695195198059, 'policy_logps/rejected': -344.06622314453125, 'policy_logps/chosen': -401.9659729003906, 'referece_logps/rejected': -313.4737243652344, 'referece_logps/chosen': -390.48040771484375, 'logits/rejected': -0.087164506316185, 'logits/chosen': -0.013602852821350098, 'epoch': 4.74}


 79%|███████▉  | 12735/16104 [58:49:43<15:09:39, 16.20s/it]
{'loss': 0.4875, 'learning_rate': 2.209169531105969e-07, 'rewards/chosen': -0.6282979846000671, 'rewards/rejected': -1.1684566736221313, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5401586890220642, 'policy_logps/rejected': -418.5649108886719, 'policy_logps/chosen': -446.607666015625, 'referece_logps/rejected': -406.8803405761719, 'referece_logps/chosen': -440.3246765136719, 'logits/rejected': 0.1388942003250122, 'logits/chosen': 0.10357123613357544, 'epoch': 4.74}

 79%|███████▉  | 12736/16104 [58:49:57<14:22:32, 15.37s/it]

 79%|███████▉  | 12737/16104 [58:50:12<14:30:07, 15.51s/it]

 79%|███████▉  | 12738/16104 [58:50:32<15:41:18, 16.78s/it]


 79%|███████▉  | 12740/16104 [58:50:57<13:47:50, 14.77s/it]

 79%|███████▉  | 12741/16104 [58:51:09<12:59:30, 13.91s/it]
{'loss': 0.3911, 'learning_rate': 2.2016097912115272e-07, 'rewards/chosen': -0.19094619154930115, 'rewards/rejected': -0.9448013305664062, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7538551688194275, 'policy_logps/rejected': -432.133544921875, 'policy_logps/chosen': -559.5513305664062, 'referece_logps/rejected': -422.685546875, 'referece_logps/chosen': -557.641845703125, 'logits/rejected': 0.5448300838470459, 'logits/chosen': 0.5681268572807312, 'epoch': 4.75}

 79%|███████▉  | 12742/16104 [58:51:24<13:10:00, 14.10s/it]

 79%|███████▉  | 12743/16104 [58:51:37<12:48:20, 13.72s/it]

 79%|███████▉  | 12744/16104 [58:51:50<12:45:10, 13.66s/it]


 79%|███████▉  | 12746/16104 [58:52:15<12:09:06, 13.03s/it]
{'loss': 0.4911, 'learning_rate': 2.1953186826154324e-07, 'rewards/chosen': -0.11911296844482422, 'rewards/rejected': -1.5395463705062866, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4204330444335938, 'policy_logps/rejected': -460.0635986328125, 'policy_logps/chosen': -352.6535339355469, 'referece_logps/rejected': -444.6680908203125, 'referece_logps/chosen': -351.46240234375, 'logits/rejected': -0.30843716859817505, 'logits/chosen': -0.276633083820343, 'epoch': 4.75}

 79%|███████▉  | 12747/16104 [58:52:32<13:13:14, 14.18s/it]

 79%|███████▉  | 12748/16104 [58:52:52<14:47:48, 15.87s/it]


 79%|███████▉  | 12750/16104 [58:53:20<13:52:26, 14.89s/it]
{'loss': 0.4774, 'learning_rate': 2.1902914782721425e-07, 'rewards/chosen': -0.4181433916091919, 'rewards/rejected': -0.7035451531410217, 'rewards/accuracies': 0.5, 'rewards/margins': 0.285401850938797, 'policy_logps/rejected': -511.0011901855469, 'policy_logps/chosen': -555.2069702148438, 'referece_logps/rejected': -503.9657287597656, 'referece_logps/chosen': -551.0255737304688, 'logits/rejected': -0.07574667781591415, 'logits/chosen': -0.0945679172873497, 'epoch': 4.75}

 79%|███████▉  | 12751/16104 [58:53:36<14:22:38, 15.44s/it]


 79%|███████▉  | 12753/16104 [58:54:02<12:53:32, 13.85s/it]

 79%|███████▉  | 12754/16104 [58:54:13<12:19:41, 13.25s/it]

 79%|███████▉  | 12755/16104 [58:54:26<12:00:45, 12.91s/it]
{'loss': 0.4459, 'learning_rate': 2.1840145813481926e-07, 'rewards/chosen': -0.1809547245502472, 'rewards/rejected': -2.1144280433654785, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9334733486175537, 'policy_logps/rejected': -449.6929931640625, 'policy_logps/chosen': -338.69781494140625, 'referece_logps/rejected': -428.5487060546875, 'referece_logps/chosen': -336.88824462890625, 'logits/rejected': -0.04614582285284996, 'logits/chosen': 0.024897603318095207, 'epoch': 4.75}

 79%|███████▉  | 12756/16104 [58:54:40<12:30:35, 13.45s/it]

 79%|███████▉  | 12757/16104 [58:55:00<14:23:25, 15.48s/it]


 79%|███████▉  | 12759/16104 [58:55:34<15:17:42, 16.46s/it]

 79%|███████▉  | 12760/16104 [58:55:54<16:19:05, 17.57s/it]

 79%|███████▉  | 12761/16104 [58:56:10<15:55:26, 17.15s/it]

 79%|███████▉  | 12762/16104 [58:56:30<16:41:02, 17.97s/it]

 79%|███████▉  | 12763/16104 [58:56:50<17:12:03, 18.53s/it]

 79%|███████▉  | 12764/16104 [58:57:04<15:53:34, 17.13s/it]

 79%|███████▉  | 12765/16104 [58:57:20<15:38:23, 16.86s/it]
{'loss': 0.3651, 'learning_rate': 2.1714845066300024e-07, 'rewards/chosen': 0.2605033814907074, 'rewards/rejected': -0.8474357724189758, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1079391241073608, 'policy_logps/rejected': -490.2246398925781, 'policy_logps/chosen': -581.9888305664062, 'referece_logps/rejected': -481.750244140625, 'referece_logps/chosen': -584.5938720703125, 'logits/rejected': 0.48400557041168213, 'logits/chosen': 0.42756080627441406, 'epoch': 4.76}

 79%|███████▉  | 12766/16104 [58:57:39<16:18:28, 17.59s/it]

 79%|███████▉  | 12767/16104 [58:57:59<16:56:39, 18.28s/it]

 79%|███████▉  | 12768/16104 [58:58:16<16:41:53, 18.02s/it]


 79%|███████▉  | 12770/16104 [58:58:56<17:32:22, 18.94s/it]
{'loss': 0.3398, 'learning_rate': 2.165231341507361e-07, 'rewards/chosen': -0.8751888275146484, 'rewards/rejected': -3.030540943145752, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1553521156311035, 'policy_logps/rejected': -425.4266357421875, 'policy_logps/chosen': -374.4041748046875, 'referece_logps/rejected': -395.1212463378906, 'referece_logps/chosen': -365.6523132324219, 'logits/rejected': -0.3197321593761444, 'logits/chosen': -0.2442052662372589, 'epoch': 4.76}


 79%|███████▉  | 12772/16104 [58:59:34<17:28:52, 18.89s/it]
{'loss': 0.3018, 'learning_rate': 2.1627322936168747e-07, 'rewards/chosen': -0.014652624726295471, 'rewards/rejected': -1.9190847873687744, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9044320583343506, 'policy_logps/rejected': -348.8103942871094, 'policy_logps/chosen': -335.4605712890625, 'referece_logps/rejected': -329.6195373535156, 'referece_logps/chosen': -335.3140563964844, 'logits/rejected': 0.2443636655807495, 'logits/chosen': 0.3058636784553528, 'epoch': 4.76}

 79%|███████▉  | 12773/16104 [58:59:51<17:00:01, 18.37s/it]

 79%|███████▉  | 12774/16104 [59:00:09<16:53:01, 18.25s/it]


 79%|███████▉  | 12776/16104 [59:00:42<15:59:35, 17.30s/it]
{'loss': 0.3317, 'learning_rate': 2.1577380026175896e-07, 'rewards/chosen': -0.43754300475120544, 'rewards/rejected': -2.10998272895813, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6724398136138916, 'policy_logps/rejected': -284.334716796875, 'policy_logps/chosen': -482.88970947265625, 'referece_logps/rejected': -263.23486328125, 'referece_logps/chosen': -478.5143127441406, 'logits/rejected': -0.0949302464723587, 'logits/chosen': 0.02413199096918106, 'epoch': 4.76}

 79%|███████▉  | 12777/16104 [59:01:03<17:03:15, 18.45s/it]

 79%|███████▉  | 12778/16104 [59:01:17<15:40:51, 16.97s/it]

 79%|███████▉  | 12779/16104 [59:01:35<15:58:15, 17.29s/it]

 79%|███████▉  | 12780/16104 [59:01:54<16:34:46, 17.96s/it]


 79%|███████▉  | 12782/16104 [59:02:26<15:56:05, 17.27s/it]
{'loss': 0.3821, 'learning_rate': 2.150256084132196e-07, 'rewards/chosen': -0.3684830665588379, 'rewards/rejected': -1.3536237478256226, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9851406812667847, 'policy_logps/rejected': -472.7309875488281, 'policy_logps/chosen': -509.05584716796875, 'referece_logps/rejected': -459.19476318359375, 'referece_logps/chosen': -505.3709716796875, 'logits/rejected': -0.036318838596343994, 'logits/chosen': 0.03945472836494446, 'epoch': 4.76}


 79%|███████▉  | 12784/16104 [59:03:08<17:37:28, 19.11s/it]
{'loss': 0.4493, 'learning_rate': 2.147764651055045e-07, 'rewards/chosen': -0.9660269021987915, 'rewards/rejected': -1.8529791831970215, 'rewards/accuracies': 0.875, 'rewards/margins': 0.88695228099823, 'policy_logps/rejected': -322.8992919921875, 'policy_logps/chosen': -502.3683776855469, 'referece_logps/rejected': -304.3695068359375, 'referece_logps/chosen': -492.7081298828125, 'logits/rejected': -0.4880165159702301, 'logits/chosen': -0.4479812979698181, 'epoch': 4.76}

 79%|███████▉  | 12785/16104 [59:03:23<16:33:09, 17.95s/it]


 79%|███████▉  | 12787/16104 [59:03:46<13:25:55, 14.58s/it]
{'loss': 0.4051, 'learning_rate': 2.144029883842209e-07, 'rewards/chosen': -0.4852418899536133, 'rewards/rejected': -1.6570284366607666, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1717865467071533, 'policy_logps/rejected': -399.390625, 'policy_logps/chosen': -504.5665283203125, 'referece_logps/rejected': -382.8203430175781, 'referece_logps/chosen': -499.71417236328125, 'logits/rejected': -0.2863650321960449, 'logits/chosen': -0.38382184505462646, 'epoch': 4.76}

 79%|███████▉  | 12788/16104 [59:04:06<14:48:59, 16.09s/it]

 79%|███████▉  | 12789/16104 [59:04:25<15:44:08, 17.09s/it]


 79%|███████▉  | 12791/16104 [59:04:56<14:46:17, 16.05s/it]

 79%|███████▉  | 12792/16104 [59:05:08<13:38:52, 14.83s/it]

 79%|███████▉  | 12793/16104 [59:05:24<14:01:01, 15.24s/it]

 79%|███████▉  | 12794/16104 [59:05:41<14:15:50, 15.51s/it]

 79%|███████▉  | 12795/16104 [59:05:55<13:49:41, 15.04s/it]
{'loss': 0.2733, 'learning_rate': 2.1340844909697708e-07, 'rewards/chosen': -0.606302797794342, 'rewards/rejected': -1.3683702945709229, 'rewards/accuracies': 0.625, 'rewards/margins': 0.762067437171936, 'policy_logps/rejected': -500.0367126464844, 'policy_logps/chosen': -342.646728515625, 'referece_logps/rejected': -486.3529968261719, 'referece_logps/chosen': -336.5837097167969, 'logits/rejected': 1.14656662940979, 'logits/chosen': 1.192779779434204, 'epoch': 4.77}

 79%|███████▉  | 12796/16104 [59:06:15<15:21:33, 16.72s/it]

 79%|███████▉  | 12797/16104 [59:06:32<15:22:24, 16.74s/it]

 79%|███████▉  | 12798/16104 [59:06:46<14:37:13, 15.92s/it]

 79%|███████▉  | 12799/16104 [59:06:57<13:17:36, 14.48s/it]

 79%|███████▉  | 12800/16104 [59:07:13<13:47:54, 15.03s/it]


 79%|███████▉  | 12802/16104 [59:07:44<14:21:45, 15.66s/it]

 80%|███████▉  | 12803/16104 [59:08:05<15:35:03, 17.00s/it]
{'loss': 0.4115, 'learning_rate': 2.1241594622734216e-07, 'rewards/chosen': -1.432565450668335, 'rewards/rejected': -2.0143239498138428, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5817584991455078, 'policy_logps/rejected': -422.2587890625, 'policy_logps/chosen': -461.7856750488281, 'referece_logps/rejected': -402.11553955078125, 'referece_logps/chosen': -447.4599609375, 'logits/rejected': -0.10689347982406616, 'logits/chosen': -0.2740625739097595, 'epoch': 4.77}

 80%|███████▉  | 12804/16104 [59:08:17<14:20:53, 15.65s/it]


 80%|███████▉  | 12806/16104 [59:08:52<15:23:14, 16.80s/it]

 80%|███████▉  | 12807/16104 [59:09:04<14:01:32, 15.31s/it]
{'loss': 0.4721, 'learning_rate': 2.1192045925230439e-07, 'rewards/chosen': -0.5722535252571106, 'rewards/rejected': -2.138911724090576, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5666584968566895, 'policy_logps/rejected': -387.3479309082031, 'policy_logps/chosen': -354.25628662109375, 'referece_logps/rejected': -365.9588317871094, 'referece_logps/chosen': -348.5337219238281, 'logits/rejected': -0.1377723217010498, 'logits/chosen': -0.1565639227628708, 'epoch': 4.77}

 80%|███████▉  | 12808/16104 [59:09:17<13:24:45, 14.65s/it]

 80%|███████▉  | 12809/16104 [59:09:36<14:29:15, 15.83s/it]


 80%|███████▉  | 12811/16104 [59:10:12<15:44:29, 17.21s/it]
{'loss': 0.3966, 'learning_rate': 2.114254823448204e-07, 'rewards/chosen': -0.20713314414024353, 'rewards/rejected': -2.101299524307251, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8941662311553955, 'policy_logps/rejected': -472.81390380859375, 'policy_logps/chosen': -349.1631774902344, 'referece_logps/rejected': -451.8009033203125, 'referece_logps/chosen': -347.0918884277344, 'logits/rejected': -0.6090707778930664, 'logits/chosen': -0.5851374268531799, 'epoch': 4.77}

 80%|███████▉  | 12812/16104 [59:10:32<16:27:23, 18.00s/it]

 80%|███████▉  | 12813/16104 [59:10:52<16:59:12, 18.58s/it]


 80%|███████▉  | 12815/16104 [59:11:29<16:49:05, 18.41s/it]
{'loss': 0.4414, 'learning_rate': 2.109310158252542e-07, 'rewards/chosen': -0.6137363314628601, 'rewards/rejected': -0.9425528049468994, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3288165032863617, 'policy_logps/rejected': -292.9161376953125, 'policy_logps/chosen': -331.22979736328125, 'referece_logps/rejected': -283.4906005859375, 'referece_logps/chosen': -325.0924377441406, 'logits/rejected': -0.25266504287719727, 'logits/chosen': -0.1992940753698349, 'epoch': 4.77}

 80%|███████▉  | 12816/16104 [59:11:46<16:32:09, 18.11s/it]


 80%|███████▉  | 12818/16104 [59:12:15<14:52:57, 16.30s/it]
{'loss': 0.464, 'learning_rate': 2.105605010701822e-07, 'rewards/chosen': -0.7812800407409668, 'rewards/rejected': -1.9942988157272339, 'rewards/accuracies': 0.625, 'rewards/margins': 1.213018774986267, 'policy_logps/rejected': -369.4962158203125, 'policy_logps/chosen': -305.7595520019531, 'referece_logps/rejected': -349.5531921386719, 'referece_logps/chosen': -297.94677734375, 'logits/rejected': -0.5882120132446289, 'logits/chosen': -0.7550669312477112, 'epoch': 4.78}

 80%|███████▉  | 12819/16104 [59:12:34<15:44:43, 17.26s/it]

 80%|███████▉  | 12820/16104 [59:12:54<16:32:15, 18.13s/it]

 80%|███████▉  | 12821/16104 [59:13:12<16:24:35, 17.99s/it]

 80%|███████▉  | 12822/16104 [59:13:32<16:55:45, 18.57s/it]


 80%|███████▉  | 12824/16104 [59:14:11<17:22:52, 19.08s/it]

 80%|███████▉  | 12825/16104 [59:14:31<17:30:45, 19.23s/it]

 80%|███████▉  | 12826/16104 [59:14:43<15:35:27, 17.12s/it]
{'loss': 0.5614, 'learning_rate': 2.0957386719573223e-07, 'rewards/chosen': -0.7841939926147461, 'rewards/rejected': -1.3791966438293457, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5950026512145996, 'policy_logps/rejected': -441.9703369140625, 'policy_logps/chosen': -426.22320556640625, 'referece_logps/rejected': -428.1783447265625, 'referece_logps/chosen': -418.3811950683594, 'logits/rejected': 0.09356046468019485, 'logits/chosen': 0.05607830733060837, 'epoch': 4.78}

 80%|███████▉  | 12827/16104 [59:14:59<15:24:15, 16.92s/it]

 80%|███████▉  | 12828/16104 [59:15:10<13:43:16, 15.08s/it]

 80%|███████▉  | 12829/16104 [59:15:26<14:03:15, 15.45s/it]


 80%|███████▉  | 12831/16104 [59:16:03<15:32:12, 17.09s/it]
{'loss': 0.4603, 'learning_rate': 2.08958260021858e-07, 'rewards/chosen': 0.2008506953716278, 'rewards/rejected': -2.0718295574188232, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2726802825927734, 'policy_logps/rejected': -458.60577392578125, 'policy_logps/chosen': -569.4063720703125, 'referece_logps/rejected': -437.8874206542969, 'referece_logps/chosen': -571.4149169921875, 'logits/rejected': 0.05048230290412903, 'logits/chosen': 0.004282727837562561, 'epoch': 4.78}

 80%|███████▉  | 12832/16104 [59:16:20<15:19:53, 16.87s/it]


 80%|███████▉  | 12834/16104 [59:16:49<14:29:41, 15.96s/it]
{'loss': 0.4582, 'learning_rate': 2.0858927966629215e-07, 'rewards/chosen': -0.03297271206974983, 'rewards/rejected': -2.1558451652526855, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1228725910186768, 'policy_logps/rejected': -765.427490234375, 'policy_logps/chosen': -647.877197265625, 'referece_logps/rejected': -743.8690185546875, 'referece_logps/chosen': -647.5475463867188, 'logits/rejected': -0.6088061332702637, 'logits/chosen': -0.33209267258644104, 'epoch': 4.78}

 80%|███████▉  | 12835/16104 [59:17:06<14:51:52, 16.37s/it]

 80%|███████▉  | 12836/16104 [59:17:26<15:48:37, 17.42s/it]

 80%|███████▉  | 12837/16104 [59:17:42<15:25:17, 16.99s/it]

 80%|███████▉  | 12838/16104 [59:18:00<15:45:10, 17.36s/it]

 80%|███████▉  | 12839/16104 [59:18:15<14:59:06, 16.52s/it]

 80%|███████▉  | 12840/16104 [59:18:31<14:53:54, 16.43s/it]

 80%|███████▉  | 12841/16104 [59:18:47<14:43:41, 16.25s/it]

 80%|███████▉  | 12842/16104 [59:19:03<14:44:49, 16.28s/it]

 80%|███████▉  | 12843/16104 [59:19:25<16:17:22, 17.98s/it]

 80%|███████▉  | 12844/16104 [59:19:45<16:43:37, 18.47s/it]

 80%|███████▉  | 12845/16104 [59:19:59<15:32:45, 17.17s/it]

 80%|███████▉  | 12846/16104 [59:20:20<16:37:10, 18.36s/it]

 80%|███████▉  | 12847/16104 [59:20:32<14:58:42, 16.56s/it]

 80%|███████▉  | 12848/16104 [59:20:45<13:52:26, 15.34s/it]

 80%|███████▉  | 12849/16104 [59:21:00<13:52:37, 15.35s/it]

 80%|███████▉  | 12850/16104 [59:21:15<13:47:50, 15.26s/it]

 80%|███████▉  | 12851/16104 [59:21:30<13:42:28, 15.17s/it]

 80%|███████▉  | 12852/16104 [59:21:49<14:47:18, 16.37s/it]

 80%|███████▉  | 12853/16104 [59:22:11<16:07:01, 17.85s/it]

 80%|███████▉  | 12854/16104 [59:22:30<16:30:41, 18.29s/it]

 80%|███████▉  | 12855/16104 [59:22:45<15:34:53, 17.26s/it]

 80%|███████▉  | 12856/16104 [59:23:05<16:25:04, 18.20s/it]

 80%|███████▉  | 12857/16104 [59:23:24<16:27:40, 18.25s/it]

 80%|███████▉  | 12858/16104 [59:23:43<16:52:34, 18.72s/it]


 80%|███████▉  | 12860/16104 [59:24:16<15:38:13, 17.35s/it]
{'loss': 0.4211, 'learning_rate': 2.0540353353697138e-07, 'rewards/chosen': -0.7564167976379395, 'rewards/rejected': -2.3993399143218994, 'rewards/accuracies': 1.0, 'rewards/margins': 1.64292311668396, 'policy_logps/rejected': -363.43853759765625, 'policy_logps/chosen': -442.6910705566406, 'referece_logps/rejected': -339.44512939453125, 'referece_logps/chosen': -435.12689208984375, 'logits/rejected': -0.9199597239494324, 'logits/chosen': -0.9950418472290039, 'epoch': 4.79}

 80%|███████▉  | 12861/16104 [59:24:33<15:28:33, 17.18s/it]

 80%|███████▉  | 12862/16104 [59:24:53<16:27:14, 18.27s/it]

 80%|███████▉  | 12863/16104 [59:25:07<15:12:09, 16.89s/it]

 80%|███████▉  | 12864/16104 [59:25:28<16:10:01, 17.96s/it]

 80%|███████▉  | 12865/16104 [59:25:46<16:13:01, 18.02s/it]

 80%|███████▉  | 12866/16104 [59:26:02<15:37:39, 17.37s/it]

 80%|███████▉  | 12867/16104 [59:26:21<16:14:29, 18.06s/it]

 80%|███████▉  | 12868/16104 [59:26:32<14:20:05, 15.95s/it]

 80%|███████▉  | 12869/16104 [59:26:51<15:02:37, 16.74s/it]

 80%|███████▉  | 12870/16104 [59:27:09<15:19:30, 17.06s/it]

 80%|███████▉  | 12871/16104 [59:27:22<14:16:38, 15.90s/it]

 80%|███████▉  | 12872/16104 [59:27:39<14:37:21, 16.29s/it]

 80%|███████▉  | 12873/16104 [59:27:56<14:41:17, 16.37s/it]

 80%|███████▉  | 12874/16104 [59:28:07<13:19:45, 14.86s/it]

 80%|███████▉  | 12875/16104 [59:28:25<14:12:55, 15.85s/it]

 80%|███████▉  | 12876/16104 [59:28:40<13:54:05, 15.50s/it]

 80%|███████▉  | 12877/16104 [59:28:57<14:14:41, 15.89s/it]

 80%|███████▉  | 12878/16104 [59:29:14<14:35:34, 16.28s/it]

 80%|███████▉  | 12879/16104 [59:29:26<13:32:35, 15.12s/it]

 80%|███████▉  | 12880/16104 [59:29:41<13:32:20, 15.12s/it]

 80%|███████▉  | 12881/16104 [59:29:56<13:29:58, 15.08s/it]

 80%|███████▉  | 12882/16104 [59:30:10<13:10:48, 14.73s/it]

 80%|███████▉  | 12883/16104 [59:30:25<13:17:18, 14.85s/it]

 80%|████████  | 12884/16104 [59:30:43<13:55:12, 15.56s/it]

 80%|████████  | 12885/16104 [59:31:02<14:55:23, 16.69s/it]

 80%|████████  | 12886/16104 [59:31:22<15:45:16, 17.62s/it]

 80%|████████  | 12887/16104 [59:31:39<15:38:46, 17.51s/it]

 80%|████████  | 12888/16104 [59:31:57<15:41:17, 17.56s/it]

 80%|████████  | 12889/16104 [59:32:07<13:53:02, 15.55s/it]

 80%|████████  | 12890/16104 [59:32:27<15:02:33, 16.85s/it]

 80%|████████  | 12891/16104 [59:32:40<13:51:07, 15.52s/it]

 80%|████████  | 12892/16104 [59:32:56<14:10:25, 15.89s/it]

 80%|████████  | 12893/16104 [59:33:19<15:49:41, 17.75s/it]

 80%|████████  | 12894/16104 [59:33:31<14:20:23, 16.08s/it]

 80%|████████  | 12895/16104 [59:33:48<14:38:36, 16.43s/it]

 80%|████████  | 12896/16104 [59:34:08<15:36:56, 17.52s/it]

 80%|████████  | 12897/16104 [59:34:27<16:07:22, 18.10s/it]

 80%|████████  | 12898/16104 [59:34:42<15:13:26, 17.09s/it]


 80%|████████  | 12900/16104 [59:35:15<14:44:19, 16.56s/it]

 80%|████████  | 12901/16104 [59:35:34<15:31:09, 17.44s/it]

 80%|████████  | 12902/16104 [59:35:53<15:46:58, 17.74s/it]

 80%|████████  | 12903/16104 [59:36:09<15:22:53, 17.30s/it]

 80%|████████  | 12904/16104 [59:36:21<13:57:45, 15.71s/it]

 80%|████████  | 12905/16104 [59:36:32<12:40:48, 14.27s/it]

 80%|████████  | 12906/16104 [59:36:52<14:10:11, 15.95s/it]

 80%|████████  | 12907/16104 [59:37:03<12:51:57, 14.49s/it]

 80%|████████  | 12908/16104 [59:37:23<14:26:38, 16.27s/it]

 80%|████████  | 12909/16104 [59:37:40<14:25:55, 16.26s/it]

 80%|████████  | 12910/16104 [59:37:59<15:18:37, 17.26s/it]

 80%|████████  | 12911/16104 [59:38:16<15:19:49, 17.28s/it]

 80%|████████  | 12912/16104 [59:38:39<16:39:27, 18.79s/it]

 80%|████████  | 12913/16104 [59:38:58<16:51:40, 19.02s/it]

 80%|████████  | 12914/16104 [59:39:19<17:24:55, 19.65s/it]

 80%|████████  | 12915/16104 [59:39:36<16:37:44, 18.77s/it]

 80%|████████  | 12916/16104 [59:39:55<16:43:15, 18.88s/it]

 80%|████████  | 12917/16104 [59:40:15<17:00:58, 19.22s/it]

 80%|████████  | 12918/16104 [59:40:32<16:16:18, 18.39s/it]

 80%|████████  | 12919/16104 [59:40:49<15:59:22, 18.07s/it]

 80%|████████  | 12920/16104 [59:40:59<13:53:08, 15.70s/it]

 80%|████████  | 12921/16104 [59:41:16<14:02:31, 15.88s/it]

 80%|████████  | 12922/16104 [59:41:35<15:03:50, 17.04s/it]

 80%|████████  | 12923/16104 [59:41:52<14:56:38, 16.91s/it]

 80%|████████  | 12924/16104 [59:42:12<15:40:16, 17.74s/it]

 80%|████████  | 12925/16104 [59:42:28<15:15:28, 17.28s/it]

 80%|████████  | 12926/16104 [59:42:48<15:58:08, 18.09s/it]

 80%|████████  | 12927/16104 [59:43:07<16:09:23, 18.31s/it]

 80%|████████  | 12928/16104 [59:43:24<15:52:29, 17.99s/it]

 80%|████████  | 12929/16104 [59:43:42<15:56:54, 18.08s/it]

 80%|████████  | 12930/16104 [59:43:54<14:21:30, 16.29s/it]

 80%|████████  | 12931/16104 [59:44:14<15:18:33, 17.37s/it]

 80%|████████  | 12932/16104 [59:44:34<15:55:08, 18.07s/it]

 80%|████████  | 12933/16104 [59:44:49<15:04:44, 17.12s/it]

 80%|████████  | 12934/16104 [59:45:06<15:10:35, 17.24s/it]

 80%|████████  | 12935/16104 [59:45:28<16:22:18, 18.60s/it]

 80%|████████  | 12936/16104 [59:45:48<16:43:29, 19.01s/it]

 80%|████████  | 12937/16104 [59:46:07<16:45:04, 19.04s/it]

 80%|████████  | 12938/16104 [59:46:19<14:52:30, 16.91s/it]

 80%|████████  | 12939/16104 [59:46:34<14:17:36, 16.26s/it]

 80%|████████  | 12940/16104 [59:46:50<14:15:10, 16.22s/it]

 80%|████████  | 12941/16104 [59:47:03<13:22:22, 15.22s/it]

 80%|████████  | 12942/16104 [59:47:14<12:13:53, 13.93s/it]

 80%|████████  | 12943/16104 [59:47:28<12:15:30, 13.96s/it]

 80%|████████  | 12944/16104 [59:47:39<11:26:15, 13.03s/it]

 80%|████████  | 12945/16104 [59:47:53<11:53:22, 13.55s/it]

 80%|████████  | 12946/16104 [59:48:13<13:27:35, 15.34s/it]

 80%|████████  | 12947/16104 [59:48:26<12:54:30, 14.72s/it]

 80%|████████  | 12948/16104 [59:48:39<12:17:21, 14.02s/it]

 80%|████████  | 12949/16104 [59:48:57<13:20:36, 15.23s/it]

 80%|████████  | 12950/16104 [59:49:15<14:02:42, 16.03s/it]

 80%|████████  | 12951/16104 [59:49:34<14:58:39, 17.10s/it]
{'loss': 0.4282, 'learning_rate': 1.9442510045687487e-07, 'rewards/chosen': -1.053191065788269, 'rewards/rejected': -1.9561911821365356, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9030000567436218, 'policy_logps/rejected': -446.32989501953125, 'policy_logps/chosen': -544.882080078125, 'referece_logps/rejected': -426.7679748535156, 'referece_logps/chosen': -534.3501586914062, 'logits/rejected': -0.5303163528442383, 'logits/chosen': -0.5836368203163147, 'epoch': 4.83}


 80%|████████  | 12953/16104 [59:50:01<13:23:07, 15.29s/it]

 80%|████████  | 12954/16104 [59:50:13<12:31:10, 14.31s/it]

 80%|████████  | 12955/16104 [59:50:32<13:53:40, 15.88s/it]

 80%|████████  | 12956/16104 [59:50:44<12:49:23, 14.66s/it]

 80%|████████  | 12957/16104 [59:51:03<14:03:53, 16.09s/it]
{'loss': 0.4115, 'learning_rate': 1.9371069053392742e-07, 'rewards/chosen': -0.6421867609024048, 'rewards/rejected': -2.24631929397583, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6041324138641357, 'policy_logps/rejected': -436.44622802734375, 'policy_logps/chosen': -449.294921875, 'referece_logps/rejected': -413.9830322265625, 'referece_logps/chosen': -442.873046875, 'logits/rejected': 0.2661888301372528, 'logits/chosen': 0.38390251994132996, 'epoch': 4.83}


 80%|████████  | 12959/16104 [59:51:39<14:51:34, 17.01s/it]

 80%|████████  | 12960/16104 [59:51:59<15:37:47, 17.90s/it]

 80%|████████  | 12961/16104 [59:52:20<16:26:52, 18.84s/it]

 80%|████████  | 12962/16104 [59:52:33<14:46:32, 16.93s/it]

 80%|████████  | 12963/16104 [59:52:52<15:27:05, 17.71s/it]

 81%|████████  | 12964/16104 [59:53:13<16:09:30, 18.53s/it]

 81%|████████  | 12965/16104 [59:53:25<14:22:16, 16.48s/it]

 81%|████████  | 12966/16104 [59:53:41<14:22:40, 16.49s/it]

 81%|████████  | 12967/16104 [59:54:02<15:36:37, 17.91s/it]

 81%|████████  | 12968/16104 [59:54:13<13:49:38, 15.87s/it]

 81%|████████  | 12969/16104 [59:54:25<12:39:11, 14.53s/it]

 81%|████████  | 12970/16104 [59:54:43<13:33:08, 15.57s/it]

 81%|████████  | 12971/16104 [59:55:03<14:43:10, 16.91s/it]

 81%|████████  | 12972/16104 [59:55:14<13:19:47, 15.32s/it]

 81%|████████  | 12973/16104 [59:55:35<14:46:39, 16.99s/it]

 81%|████████  | 12974/16104 [59:55:57<15:55:15, 18.31s/it]
{'loss': 0.4677, 'learning_rate': 1.9169290892760225e-07, 'rewards/chosen': -0.21550655364990234, 'rewards/rejected': -1.5031088590621948, 'rewards/accuracies': 0.5, 'rewards/margins': 1.287602186203003, 'policy_logps/rejected': -440.5946044921875, 'policy_logps/chosen': -551.6297607421875, 'referece_logps/rejected': -425.56353759765625, 'referece_logps/chosen': -549.4746704101562, 'logits/rejected': -0.3832452893257141, 'logits/chosen': -0.3539065718650818, 'epoch': 4.83}


 81%|████████  | 12976/16104 [59:56:34<16:02:44, 18.47s/it]
{'loss': 0.3472, 'learning_rate': 1.9145614365248997e-07, 'rewards/chosen': -1.223886251449585, 'rewards/rejected': -2.7277863025665283, 'rewards/accuracies': 0.875, 'rewards/margins': 1.503900170326233, 'policy_logps/rejected': -333.5592346191406, 'policy_logps/chosen': -385.7173156738281, 'referece_logps/rejected': -306.2813415527344, 'referece_logps/chosen': -373.47845458984375, 'logits/rejected': -1.2225182056427002, 'logits/chosen': -1.1842221021652222, 'epoch': 4.83}

 81%|████████  | 12977/16104 [59:56:52<16:06:25, 18.54s/it]


 81%|████████  | 12979/16104 [59:57:29<15:59:45, 18.43s/it]

 81%|████████  | 12980/16104 [59:57:41<14:14:19, 16.41s/it]

 81%|████████  | 12981/16104 [59:57:53<13:09:31, 15.17s/it]

 81%|████████  | 12982/16104 [59:58:08<13:04:16, 15.07s/it]

 81%|████████  | 12983/16104 [59:58:21<12:32:26, 14.47s/it]

 81%|████████  | 12984/16104 [59:58:33<12:04:40, 13.94s/it]

 81%|████████  | 12985/16104 [59:58:45<11:33:52, 13.35s/it]
{'loss': 0.3501, 'learning_rate': 1.9039231946564728e-07, 'rewards/chosen': 0.10942345857620239, 'rewards/rejected': -1.2162224054336548, 'rewards/accuracies': 1.0, 'rewards/margins': 1.325645923614502, 'policy_logps/rejected': -572.552978515625, 'policy_logps/chosen': -636.697265625, 'referece_logps/rejected': -560.3907470703125, 'referece_logps/chosen': -637.7914428710938, 'logits/rejected': -0.361884206533432, 'logits/chosen': -0.3673316240310669, 'epoch': 4.84}


 81%|████████  | 12987/16104 [59:59:10<10:56:02, 12.63s/it]

 81%|████████  | 12988/16104 [59:59:31<13:16:44, 15.34s/it]
{'loss': 0.4418, 'learning_rate': 1.900383007326808e-07, 'rewards/chosen': -0.6370235681533813, 'rewards/rejected': -1.3166033029556274, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6795797348022461, 'policy_logps/rejected': -352.6092529296875, 'policy_logps/chosen': -513.1900024414062, 'referece_logps/rejected': -339.4432067871094, 'referece_logps/chosen': -506.81976318359375, 'logits/rejected': -0.21867525577545166, 'logits/chosen': -0.2135220617055893, 'epoch': 4.84}

 81%|████████  | 12989/16104 [59:59:50<14:15:07, 16.47s/it]


 81%|████████  | 12991/16104 [60:00:14<12:06:30, 14.00s/it]

 81%|████████  | 12992/16104 [60:00:25<11:28:26, 13.27s/it]
{'loss': 0.4305, 'learning_rate': 1.895667344791868e-07, 'rewards/chosen': -1.0207264423370361, 'rewards/rejected': -2.3332161903381348, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3124898672103882, 'policy_logps/rejected': -280.3761901855469, 'policy_logps/chosen': -493.1094970703125, 'referece_logps/rejected': -257.04400634765625, 'referece_logps/chosen': -482.90216064453125, 'logits/rejected': 0.02657186985015869, 'logits/chosen': -0.036261677742004395, 'epoch': 4.84}

 81%|████████  | 12993/16104 [60:00:36<10:55:54, 12.65s/it]

 81%|████████  | 12994/16104 [60:00:56<12:47:48, 14.81s/it]


 81%|████████  | 12996/16104 [60:01:36<14:57:04, 17.32s/it]
{'loss': 0.3192, 'learning_rate': 1.8909569276121462e-07, 'rewards/chosen': -1.1815640926361084, 'rewards/rejected': -2.705462694168091, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5238983631134033, 'policy_logps/rejected': -539.3502197265625, 'policy_logps/chosen': -504.9732666015625, 'referece_logps/rejected': -512.2955322265625, 'referece_logps/chosen': -493.1576843261719, 'logits/rejected': -0.07605701684951782, 'logits/chosen': -0.022098898887634277, 'epoch': 4.84}


 81%|████████  | 12998/16104 [60:02:00<12:38:09, 14.65s/it]

 81%|████████  | 12999/16104 [60:02:19<13:57:12, 16.18s/it]

 81%|████████  | 13000/16104 [60:02:33<13:23:03, 15.52s/it]
{'loss': 0.3706, 'learning_rate': 1.8862517588363659e-07, 'rewards/chosen': -0.4439103901386261, 'rewards/rejected': -1.8984063863754272, 'rewards/accuracies': 0.875, 'rewards/margins': 1.454495906829834, 'policy_logps/rejected': -598.3336791992188, 'policy_logps/chosen': -325.25970458984375, 'referece_logps/rejected': -579.3495483398438, 'referece_logps/chosen': -320.82061767578125, 'logits/rejected': -0.3002167344093323, 'logits/chosen': 0.03652023524045944, 'epoch': 4.84}


 81%|████████  | 13002/16104 [60:03:27<17:44:28, 20.59s/it]

 81%|████████  | 13003/16104 [60:03:38<15:13:15, 17.67s/it]
{'loss': 0.493, 'learning_rate': 1.8827263283516937e-07, 'rewards/chosen': -0.5565422773361206, 'rewards/rejected': -2.247387170791626, 'rewards/accuracies': 0.875, 'rewards/margins': 1.690845012664795, 'policy_logps/rejected': -424.6120910644531, 'policy_logps/chosen': -485.398193359375, 'referece_logps/rejected': -402.13824462890625, 'referece_logps/chosen': -479.832763671875, 'logits/rejected': 1.213340163230896, 'logits/chosen': 1.261833667755127, 'epoch': 4.84}

 81%|████████  | 13004/16104 [60:03:53<14:22:37, 16.70s/it]


 81%|████████  | 13006/16104 [60:04:32<15:35:42, 18.12s/it]

 81%|████████  | 13007/16104 [60:04:51<15:56:40, 18.53s/it]

 81%|████████  | 13008/16104 [60:05:05<14:49:57, 17.25s/it]

 81%|████████  | 13009/16104 [60:05:26<15:35:36, 18.14s/it]

 81%|████████  | 13010/16104 [60:05:45<15:55:28, 18.53s/it]

 81%|████████  | 13011/16104 [60:05:56<13:54:24, 16.19s/it]

 81%|████████  | 13012/16104 [60:06:08<12:53:05, 15.00s/it]

 81%|████████  | 13013/16104 [60:06:24<13:11:46, 15.37s/it]
{'loss': 0.4332, 'learning_rate': 1.870996243887213e-07, 'rewards/chosen': -0.3581429719924927, 'rewards/rejected': -1.4052817821502686, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0471389293670654, 'policy_logps/rejected': -504.08428955078125, 'policy_logps/chosen': -587.62548828125, 'referece_logps/rejected': -490.031494140625, 'referece_logps/chosen': -584.0441284179688, 'logits/rejected': 0.7003967761993408, 'logits/chosen': 0.8652278184890747, 'epoch': 4.85}

 81%|████████  | 13014/16104 [60:06:41<13:31:52, 15.76s/it]


 81%|████████  | 13016/16104 [60:07:13<13:43:44, 16.01s/it]

 81%|████████  | 13017/16104 [60:07:32<14:23:44, 16.79s/it]
{'loss': 0.3488, 'learning_rate': 1.8663134147614268e-07, 'rewards/chosen': -0.1444414258003235, 'rewards/rejected': -2.1130635738372803, 'rewards/accuracies': 0.625, 'rewards/margins': 1.9686222076416016, 'policy_logps/rejected': -434.4998779296875, 'policy_logps/chosen': -490.4151611328125, 'referece_logps/rejected': -413.3692932128906, 'referece_logps/chosen': -488.9707946777344, 'logits/rejected': 0.4080626964569092, 'logits/chosen': 0.4580726623535156, 'epoch': 4.85}

 81%|████████  | 13018/16104 [60:07:51<15:01:31, 17.53s/it]


 81%|████████  | 13020/16104 [60:08:34<16:41:15, 19.48s/it]

 81%|████████  | 13021/16104 [60:08:50<15:44:05, 18.37s/it]

 81%|████████  | 13022/16104 [60:09:02<14:02:40, 16.41s/it]

 81%|████████  | 13023/16104 [60:09:20<14:41:00, 17.16s/it]
{'loss': 0.2105, 'learning_rate': 1.859299042682564e-07, 'rewards/chosen': -0.6997442245483398, 'rewards/rejected': -3.1726131439208984, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4728689193725586, 'policy_logps/rejected': -285.246826171875, 'policy_logps/chosen': -280.80377197265625, 'referece_logps/rejected': -253.52066040039062, 'referece_logps/chosen': -273.80633544921875, 'logits/rejected': -0.634709358215332, 'logits/chosen': -0.5153492093086243, 'epoch': 4.85}


 81%|████████  | 13025/16104 [60:09:47<12:45:31, 14.92s/it]
{'loss': 0.4145, 'learning_rate': 1.8569635525990779e-07, 'rewards/chosen': -0.3839467167854309, 'rewards/rejected': -2.306260585784912, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9223140478134155, 'policy_logps/rejected': -554.5205688476562, 'policy_logps/chosen': -486.1844482421875, 'referece_logps/rejected': -531.4579467773438, 'referece_logps/chosen': -482.344970703125, 'logits/rejected': -0.6938996911048889, 'logits/chosen': -0.6242557168006897, 'epoch': 4.85}

 81%|████████  | 13026/16104 [60:10:03<13:06:03, 15.32s/it]


 81%|████████  | 13028/16104 [60:10:40<14:21:22, 16.80s/it]

 81%|████████  | 13029/16104 [60:11:02<15:43:04, 18.40s/it]

 81%|████████  | 13030/16104 [60:11:18<15:10:07, 17.76s/it]

 81%|████████  | 13031/16104 [60:11:35<14:50:12, 17.38s/it]

 81%|████████  | 13032/16104 [60:11:56<15:45:54, 18.47s/it]
{'loss': 0.4209, 'learning_rate': 1.8487997158959968e-07, 'rewards/chosen': -1.2465312480926514, 'rewards/rejected': -2.911475896835327, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6649446487426758, 'policy_logps/rejected': -634.8306884765625, 'policy_logps/chosen': -450.23876953125, 'referece_logps/rejected': -605.7160034179688, 'referece_logps/chosen': -437.7734375, 'logits/rejected': -0.1898878514766693, 'logits/chosen': -0.13128185272216797, 'epoch': 4.86}

 81%|████████  | 13033/16104 [60:12:15<15:58:19, 18.72s/it]

 81%|████████  | 13034/16104 [60:12:35<16:15:50, 19.07s/it]


 81%|████████  | 13036/16104 [60:13:06<14:46:25, 17.34s/it]

 81%|████████  | 13037/16104 [60:13:24<14:55:15, 17.51s/it]

 81%|████████  | 13038/16104 [60:13:40<14:41:32, 17.25s/it]

 81%|████████  | 13039/16104 [60:14:00<15:21:30, 18.04s/it]

 81%|████████  | 13040/16104 [60:14:20<15:43:35, 18.48s/it]

 81%|████████  | 13041/16104 [60:14:36<15:07:58, 17.79s/it]

 81%|████████  | 13042/16104 [60:14:58<16:15:17, 19.11s/it]

 81%|████████  | 13043/16104 [60:15:10<14:25:11, 16.96s/it]

 81%|████████  | 13044/16104 [60:15:27<14:19:30, 16.85s/it]

 81%|████████  | 13045/16104 [60:15:45<14:39:30, 17.25s/it]

 81%|████████  | 13046/16104 [60:16:04<15:14:53, 17.95s/it]

 81%|████████  | 13047/16104 [60:16:22<15:09:37, 17.85s/it]

 81%|████████  | 13048/16104 [60:16:36<14:15:55, 16.80s/it]

 81%|████████  | 13049/16104 [60:16:54<14:33:00, 17.15s/it]

 81%|████████  | 13050/16104 [60:17:12<14:38:54, 17.27s/it]

 81%|████████  | 13051/16104 [60:17:31<15:07:48, 17.84s/it]

 81%|████████  | 13052/16104 [60:17:51<15:32:06, 18.32s/it]

 81%|████████  | 13053/16104 [60:18:11<15:59:55, 18.88s/it]

 81%|████████  | 13054/16104 [60:18:31<16:15:38, 19.19s/it]

 81%|████████  | 13055/16104 [60:18:51<16:26:11, 19.41s/it]

 81%|████████  | 13056/16104 [60:19:03<14:33:19, 17.19s/it]

 81%|████████  | 13057/16104 [60:19:17<13:44:09, 16.23s/it]
{'loss': 0.4002, 'learning_rate': 1.8197751613732139e-07, 'rewards/chosen': -1.3008825778961182, 'rewards/rejected': -2.6748604774475098, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3739778995513916, 'policy_logps/rejected': -292.6188049316406, 'policy_logps/chosen': -379.12298583984375, 'referece_logps/rejected': -265.87017822265625, 'referece_logps/chosen': -366.11419677734375, 'logits/rejected': -0.8211872577667236, 'logits/chosen': -0.7720797657966614, 'epoch': 4.86}


 81%|████████  | 13059/16104 [60:19:49<13:38:39, 16.13s/it]
{'loss': 0.346, 'learning_rate': 1.817462121733775e-07, 'rewards/chosen': -1.5105772018432617, 'rewards/rejected': -2.8334054946899414, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3228282928466797, 'policy_logps/rejected': -341.0843811035156, 'policy_logps/chosen': -451.55047607421875, 'referece_logps/rejected': -312.7503662109375, 'referece_logps/chosen': -436.44464111328125, 'logits/rejected': -1.1935324668884277, 'logits/chosen': -1.1750301122665405, 'epoch': 4.87}

 81%|████████  | 13060/16104 [60:20:08<14:28:54, 17.13s/it]


 81%|████████  | 13062/16104 [60:20:39<14:04:02, 16.65s/it]

 81%|████████  | 13063/16104 [60:20:57<14:29:06, 17.15s/it]

 81%|████████  | 13064/16104 [60:21:11<13:40:30, 16.19s/it]
{'loss': 0.4727, 'learning_rate': 1.811685315922825e-07, 'rewards/chosen': -0.5535351037979126, 'rewards/rejected': -1.2174229621887207, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6638877987861633, 'policy_logps/rejected': -366.08831787109375, 'policy_logps/chosen': -388.09857177734375, 'referece_logps/rejected': -353.91412353515625, 'referece_logps/chosen': -382.563232421875, 'logits/rejected': -0.510083794593811, 'logits/chosen': -0.41975292563438416, 'epoch': 4.87}

 81%|████████  | 13065/16104 [60:21:32<14:43:28, 17.44s/it]


 81%|████████  | 13067/16104 [60:22:15<16:35:34, 19.67s/it]
{'loss': 0.4715, 'learning_rate': 1.8082232068456827e-07, 'rewards/chosen': -0.7445405721664429, 'rewards/rejected': -2.013986825942993, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2694461345672607, 'policy_logps/rejected': -378.5310974121094, 'policy_logps/chosen': -461.94476318359375, 'referece_logps/rejected': -358.3912353515625, 'referece_logps/chosen': -454.4993896484375, 'logits/rejected': 0.5047265887260437, 'logits/chosen': 0.3518304228782654, 'epoch': 4.87}


 81%|████████  | 13069/16104 [60:22:47<15:17:26, 18.14s/it]
{'loss': 0.4428, 'learning_rate': 1.8059167909097328e-07, 'rewards/chosen': -0.12866023182868958, 'rewards/rejected': -1.9933875799179077, 'rewards/accuracies': 0.5, 'rewards/margins': 1.864727258682251, 'policy_logps/rejected': -396.96026611328125, 'policy_logps/chosen': -343.6282958984375, 'referece_logps/rejected': -377.0263671875, 'referece_logps/chosen': -342.3417053222656, 'logits/rejected': 0.12149488925933838, 'logits/chosen': 0.15595561265945435, 'epoch': 4.87}


 81%|████████  | 13071/16104 [60:23:23<14:50:42, 17.62s/it]
{'loss': 0.4416, 'learning_rate': 1.803611700834917e-07, 'rewards/chosen': -0.6595133543014526, 'rewards/rejected': -1.8729732036590576, 'rewards/accuracies': 0.75, 'rewards/margins': 1.213459849357605, 'policy_logps/rejected': -524.4927368164062, 'policy_logps/chosen': -313.0870666503906, 'referece_logps/rejected': -505.7630615234375, 'referece_logps/chosen': -306.491943359375, 'logits/rejected': -0.4456949830055237, 'logits/chosen': -0.48771271109580994, 'epoch': 4.87}

 81%|████████  | 13072/16104 [60:23:44<15:53:15, 18.86s/it]

 81%|████████  | 13073/16104 [60:23:59<14:40:30, 17.43s/it]


 81%|████████  | 13075/16104 [60:24:33<14:28:47, 17.21s/it]

 81%|████████  | 13076/16104 [60:24:49<14:04:36, 16.74s/it]
{'loss': 0.3915, 'learning_rate': 1.7978547787375176e-07, 'rewards/chosen': -0.41424793004989624, 'rewards/rejected': -1.9595829248428345, 'rewards/accuracies': 1.0, 'rewards/margins': 1.545334815979004, 'policy_logps/rejected': -576.74609375, 'policy_logps/chosen': -459.07244873046875, 'referece_logps/rejected': -557.1502685546875, 'referece_logps/chosen': -454.92999267578125, 'logits/rejected': 0.319393515586853, 'logits/chosen': 0.45409154891967773, 'epoch': 4.87}


 81%|████████  | 13078/16104 [60:25:27<15:07:48, 18.00s/it]
{'loss': 0.5725, 'learning_rate': 1.7955543321125e-07, 'rewards/chosen': -0.8633168339729309, 'rewards/rejected': -1.4751944541931152, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6118776798248291, 'policy_logps/rejected': -424.97747802734375, 'policy_logps/chosen': -398.705322265625, 'referece_logps/rejected': -410.2254943847656, 'referece_logps/chosen': -390.0722351074219, 'logits/rejected': 0.6448375582695007, 'logits/chosen': 0.6835818290710449, 'epoch': 4.87}


 81%|████████  | 13080/16104 [60:26:10<16:21:43, 19.48s/it]
{'loss': 0.5422, 'learning_rate': 1.7932552130253432e-07, 'rewards/chosen': -0.6132022738456726, 'rewards/rejected': -0.9639632105827332, 'rewards/accuracies': 0.5, 'rewards/margins': 0.35076096653938293, 'policy_logps/rejected': -632.0020751953125, 'policy_logps/chosen': -443.6553955078125, 'referece_logps/rejected': -622.3624267578125, 'referece_logps/chosen': -437.52337646484375, 'logits/rejected': -0.9339325428009033, 'logits/chosen': -0.7149195671081543, 'epoch': 4.87}

 81%|████████  | 13081/16104 [60:26:22<14:38:21, 17.43s/it]

 81%|████████  | 13082/16104 [60:26:34<13:16:04, 15.81s/it]

 81%|████████  | 13083/16104 [60:26:54<14:17:24, 17.03s/it]


 81%|████████▏ | 13085/16104 [60:27:20<12:28:02, 14.87s/it]
{'loss': 0.4094, 'learning_rate': 1.787513225726387e-07, 'rewards/chosen': -1.2884337902069092, 'rewards/rejected': -2.026996374130249, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7385624647140503, 'policy_logps/rejected': -666.671142578125, 'policy_logps/chosen': -491.16680908203125, 'referece_logps/rejected': -646.401123046875, 'referece_logps/chosen': -478.2824401855469, 'logits/rejected': -0.6362296342849731, 'logits/chosen': -0.6028814911842346, 'epoch': 4.88}


 81%|████████▏ | 13087/16104 [60:27:47<11:44:10, 14.00s/it]

 81%|████████▏ | 13088/16104 [60:28:07<13:17:28, 15.86s/it]

 81%|████████▏ | 13089/16104 [60:28:22<12:58:01, 15.48s/it]

 81%|████████▏ | 13090/16104 [60:28:43<14:24:46, 17.22s/it]

 81%|████████▏ | 13091/16104 [60:28:55<13:06:19, 15.66s/it]

 81%|████████▏ | 13092/16104 [60:29:09<12:43:12, 15.20s/it]
{'loss': 0.4044, 'learning_rate': 1.77948839761515e-07, 'rewards/chosen': -0.12005007266998291, 'rewards/rejected': -1.1855816841125488, 'rewards/accuracies': 0.75, 'rewards/margins': 1.065531611442566, 'policy_logps/rejected': -549.58642578125, 'policy_logps/chosen': -454.5315246582031, 'referece_logps/rejected': -537.7305908203125, 'referece_logps/chosen': -453.3310546875, 'logits/rejected': 0.4074939489364624, 'logits/chosen': 0.6422102451324463, 'epoch': 4.88}

 81%|████████▏ | 13093/16104 [60:29:30<14:13:04, 17.00s/it]

 81%|████████▏ | 13094/16104 [60:29:50<14:56:13, 17.86s/it]

 81%|████████▏ | 13095/16104 [60:30:04<13:59:17, 16.74s/it]

 81%|████████▏ | 13096/16104 [60:30:23<14:23:11, 17.22s/it]


 81%|████████▏ | 13098/16104 [60:31:03<15:29:31, 18.55s/it]

 81%|████████▏ | 13099/16104 [60:31:23<15:52:02, 19.01s/it]

 81%|████████▏ | 13100/16104 [60:31:41<15:39:46, 18.77s/it]
{'loss': 0.4266, 'learning_rate': 1.7703371184726178e-07, 'rewards/chosen': -1.6566953659057617, 'rewards/rejected': -2.889655590057373, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2329599857330322, 'policy_logps/rejected': -385.365478515625, 'policy_logps/chosen': -509.4583435058594, 'referece_logps/rejected': -356.4689025878906, 'referece_logps/chosen': -492.8913879394531, 'logits/rejected': 0.2159096896648407, 'logits/chosen': 0.24998317658901215, 'epoch': 4.88}

 81%|████████▏ | 13101/16104 [60:31:57<14:50:08, 17.78s/it]

 81%|████████▏ | 13102/16104 [60:32:17<15:25:32, 18.50s/it]

 81%|████████▏ | 13103/16104 [60:32:29<13:39:31, 16.39s/it]

 81%|████████▏ | 13104/16104 [60:32:40<12:32:25, 15.05s/it]

 81%|████████▏ | 13105/16104 [60:32:51<11:26:29, 13.73s/it]


 81%|████████▏ | 13107/16104 [60:33:21<11:44:30, 14.10s/it]

 81%|████████▏ | 13108/16104 [60:33:36<11:43:23, 14.09s/it]

 81%|████████▏ | 13109/16104 [60:33:47<11:10:55, 13.44s/it]
{'loss': 0.5754, 'learning_rate': 1.7600673978077051e-07, 'rewards/chosen': 0.046463195234537125, 'rewards/rejected': -0.6806398630142212, 'rewards/accuracies': 0.875, 'rewards/margins': 0.727103054523468, 'policy_logps/rejected': -284.96978759765625, 'policy_logps/chosen': -321.1778564453125, 'referece_logps/rejected': -278.16339111328125, 'referece_logps/chosen': -321.6424865722656, 'logits/rejected': -0.6736602187156677, 'logits/chosen': -0.6452912092208862, 'epoch': 4.88}

 81%|████████▏ | 13110/16104 [60:33:59<10:31:03, 12.65s/it]

 81%|████████▏ | 13111/16104 [60:34:19<12:26:47, 14.97s/it]

 81%|████████▏ | 13112/16104 [60:34:35<12:48:21, 15.41s/it]

 81%|████████▏ | 13113/16104 [60:34:52<13:17:47, 16.00s/it]

 81%|████████▏ | 13114/16104 [60:35:13<14:25:04, 17.36s/it]


 81%|████████▏ | 13116/16104 [60:35:36<11:54:18, 14.34s/it]

 81%|████████▏ | 13117/16104 [60:35:56<13:18:18, 16.04s/it]
{'loss': 0.4591, 'learning_rate': 1.7509614219247747e-07, 'rewards/chosen': 0.07941609621047974, 'rewards/rejected': -2.332091808319092, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4115078449249268, 'policy_logps/rejected': -483.3630065917969, 'policy_logps/chosen': -562.8357543945312, 'referece_logps/rejected': -460.0420837402344, 'referece_logps/chosen': -563.6298828125, 'logits/rejected': 0.03421184420585632, 'logits/chosen': -0.00868457555770874, 'epoch': 4.89}

 81%|████████▏ | 13118/16104 [60:36:15<14:06:19, 17.01s/it]

 81%|████████▏ | 13119/16104 [60:36:27<12:47:47, 15.43s/it]


 81%|████████▏ | 13121/16104 [60:37:02<13:30:50, 16.31s/it]
{'loss': 0.4398, 'learning_rate': 1.746416441030296e-07, 'rewards/chosen': -0.5985156297683716, 'rewards/rejected': -1.8808692693710327, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2823536396026611, 'policy_logps/rejected': -428.30963134765625, 'policy_logps/chosen': -424.663818359375, 'referece_logps/rejected': -409.5009765625, 'referece_logps/chosen': -418.67864990234375, 'logits/rejected': -0.39200252294540405, 'logits/chosen': -0.5036836266517639, 'epoch': 4.89}

 81%|████████▏ | 13122/16104 [60:37:13<12:09:39, 14.68s/it]


 81%|████████▏ | 13124/16104 [60:37:54<14:39:46, 17.71s/it]

 82%|████████▏ | 13125/16104 [60:38:14<15:08:22, 18.30s/it]
{'loss': 0.2844, 'learning_rate': 1.7418768020904818e-07, 'rewards/chosen': -0.5941421985626221, 'rewards/rejected': -2.8469908237457275, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2528486251831055, 'policy_logps/rejected': -412.93756103515625, 'policy_logps/chosen': -507.9037170410156, 'referece_logps/rejected': -384.4676208496094, 'referece_logps/chosen': -501.9622802734375, 'logits/rejected': 0.31868255138397217, 'logits/chosen': 0.22670544683933258, 'epoch': 4.89}

 82%|████████▏ | 13126/16104 [60:38:33<15:29:07, 18.72s/it]


 82%|████████▏ | 13128/16104 [60:39:08<14:57:31, 18.10s/it]

 82%|████████▏ | 13129/16104 [60:39:26<15:00:41, 18.17s/it]

 82%|████████▏ | 13130/16104 [60:39:44<15:01:10, 18.18s/it]
{'loss': 0.4356, 'learning_rate': 1.73620977001527e-07, 'rewards/chosen': -0.406737357378006, 'rewards/rejected': -2.436149835586548, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0294125080108643, 'policy_logps/rejected': -420.0390625, 'policy_logps/chosen': -423.1905517578125, 'referece_logps/rejected': -395.67755126953125, 'referece_logps/chosen': -419.1231689453125, 'logits/rejected': -0.5281308889389038, 'logits/chosen': -0.5785881280899048, 'epoch': 4.89}

 82%|████████▏ | 13131/16104 [60:40:01<14:36:43, 17.69s/it]


 82%|████████▏ | 13133/16104 [60:40:32<13:43:48, 16.64s/it]
{'loss': 0.3871, 'learning_rate': 1.732813561824119e-07, 'rewards/chosen': -0.2223207652568817, 'rewards/rejected': -2.060211658477783, 'rewards/accuracies': 0.875, 'rewards/margins': 1.837890863418579, 'policy_logps/rejected': -501.766357421875, 'policy_logps/chosen': -525.6056518554688, 'referece_logps/rejected': -481.1642761230469, 'referece_logps/chosen': -523.3825073242188, 'logits/rejected': -0.22871975600719452, 'logits/chosen': -0.25105735659599304, 'epoch': 4.89}


 82%|████████▏ | 13135/16104 [60:41:08<14:20:04, 17.38s/it]

 82%|████████▏ | 13136/16104 [60:41:28<15:05:01, 18.30s/it]

 82%|████████▏ | 13137/16104 [60:41:44<14:25:22, 17.50s/it]
{'loss': 0.4483, 'learning_rate': 1.7282899663635608e-07, 'rewards/chosen': -0.7176694273948669, 'rewards/rejected': -2.3258378505706787, 'rewards/accuracies': 0.875, 'rewards/margins': 1.608168363571167, 'policy_logps/rejected': -404.69110107421875, 'policy_logps/chosen': -423.66912841796875, 'referece_logps/rejected': -381.4327392578125, 'referece_logps/chosen': -416.49249267578125, 'logits/rejected': -0.5552414655685425, 'logits/chosen': -0.4306207299232483, 'epoch': 4.89}


 82%|████████▏ | 13139/16104 [60:42:18<14:02:26, 17.05s/it]
{'loss': 0.5098, 'learning_rate': 1.7260301760829188e-07, 'rewards/chosen': -0.5865844488143921, 'rewards/rejected': -2.036158561706543, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4495741128921509, 'policy_logps/rejected': -348.28271484375, 'policy_logps/chosen': -383.1166076660156, 'referece_logps/rejected': -327.921142578125, 'referece_logps/chosen': -377.2508239746094, 'logits/rejected': -0.2689051330089569, 'logits/chosen': -0.27250540256500244, 'epoch': 4.9}

 82%|████████▏ | 13140/16104 [60:42:37<14:28:43, 17.59s/it]

 82%|████████▏ | 13141/16104 [60:42:48<12:46:07, 15.51s/it]

 82%|████████▏ | 13142/16104 [60:43:04<12:55:21, 15.71s/it]

 82%|████████▏ | 13143/16104 [60:43:21<13:15:13, 16.11s/it]

 82%|████████▏ | 13144/16104 [60:43:33<12:19:21, 14.99s/it]


 82%|████████▏ | 13146/16104 [60:44:11<13:44:36, 16.73s/it]

 82%|████████▏ | 13147/16104 [60:44:30<14:30:34, 17.66s/it]

 82%|████████▏ | 13148/16104 [60:44:44<13:36:39, 16.58s/it]
{'loss': 0.4628, 'learning_rate': 1.715877692587636e-07, 'rewards/chosen': -1.2629153728485107, 'rewards/rejected': -3.1860878467559814, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9231725931167603, 'policy_logps/rejected': -348.16033935546875, 'policy_logps/chosen': -349.0804748535156, 'referece_logps/rejected': -316.2994689941406, 'referece_logps/chosen': -336.4512939453125, 'logits/rejected': -0.413108229637146, 'logits/chosen': -0.24950851500034332, 'epoch': 4.9}

 82%|████████▏ | 13149/16104 [60:45:03<14:09:14, 17.24s/it]

 82%|████████▏ | 13150/16104 [60:45:14<12:29:53, 15.23s/it]

 82%|████████▏ | 13151/16104 [60:45:36<14:11:54, 17.31s/it]

 82%|████████▏ | 13152/16104 [60:45:53<14:09:37, 17.27s/it]


 82%|████████▏ | 13154/16104 [60:46:19<12:24:51, 15.15s/it]
{'loss': 0.5119, 'learning_rate': 1.709124448042474e-07, 'rewards/chosen': -0.6715872287750244, 'rewards/rejected': -3.0864510536193848, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4148640632629395, 'policy_logps/rejected': -452.0914611816406, 'policy_logps/chosen': -362.84942626953125, 'referece_logps/rejected': -421.2269287109375, 'referece_logps/chosen': -356.133544921875, 'logits/rejected': -0.8744065761566162, 'logits/chosen': -0.6288039088249207, 'epoch': 4.9}


 82%|████████▏ | 13156/16104 [60:46:48<12:20:02, 15.06s/it]
{'loss': 0.4726, 'learning_rate': 1.7068760490876422e-07, 'rewards/chosen': -0.8772852420806885, 'rewards/rejected': -1.6839540004730225, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8066688776016235, 'policy_logps/rejected': -313.5308532714844, 'policy_logps/chosen': -379.5087890625, 'referece_logps/rejected': -296.6912841796875, 'referece_logps/chosen': -370.73590087890625, 'logits/rejected': -0.6487687230110168, 'logits/chosen': -0.5982430577278137, 'epoch': 4.9}

 82%|████████▏ | 13157/16104 [60:47:01<11:47:42, 14.41s/it]

 82%|████████▏ | 13158/16104 [60:47:12<10:53:15, 13.30s/it]

 82%|████████▏ | 13159/16104 [60:47:23<10:25:48, 12.75s/it]

 82%|████████▏ | 13160/16104 [60:47:40<11:24:01, 13.94s/it]


 82%|████████▏ | 13162/16104 [60:48:09<11:35:30, 14.18s/it]
{'loss': 0.4021, 'learning_rate': 1.7001389049971172e-07, 'rewards/chosen': -0.3114066421985626, 'rewards/rejected': -1.335973858833313, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0245672464370728, 'policy_logps/rejected': -388.3097229003906, 'policy_logps/chosen': -550.302001953125, 'referece_logps/rejected': -374.95001220703125, 'referece_logps/chosen': -547.1878662109375, 'logits/rejected': -0.5007355809211731, 'logits/chosen': -0.5780317187309265, 'epoch': 4.9}

 82%|████████▏ | 13163/16104 [60:48:26<12:15:48, 15.01s/it]


 82%|████████▏ | 13165/16104 [60:48:47<10:29:44, 12.86s/it]
{'loss': 0.4016, 'learning_rate': 1.696774864885414e-07, 'rewards/chosen': -0.3267017602920532, 'rewards/rejected': -1.1656057834625244, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8389040231704712, 'policy_logps/rejected': -666.712158203125, 'policy_logps/chosen': -677.267333984375, 'referece_logps/rejected': -655.0560913085938, 'referece_logps/chosen': -674.0003662109375, 'logits/rejected': -0.10870662331581116, 'logits/chosen': 0.038859426975250244, 'epoch': 4.9}

 82%|████████▏ | 13166/16104 [60:49:03<11:09:31, 13.67s/it]


 82%|████████▏ | 13168/16104 [60:49:33<11:28:10, 14.06s/it]
{'loss': 0.3957, 'learning_rate': 1.6934138476960924e-07, 'rewards/chosen': -0.24635763466358185, 'rewards/rejected': -1.5233172178268433, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2769593000411987, 'policy_logps/rejected': -618.22412109375, 'policy_logps/chosen': -516.9246826171875, 'referece_logps/rejected': -602.990966796875, 'referece_logps/chosen': -514.4611206054688, 'logits/rejected': 0.19523578882217407, 'logits/chosen': 0.23444829881191254, 'epoch': 4.91}

 82%|████████▏ | 13169/16104 [60:49:48<11:34:28, 14.20s/it]

 82%|████████▏ | 13170/16104 [60:50:07<12:54:33, 15.84s/it]

 82%|████████▏ | 13171/16104 [60:50:23<12:58:43, 15.93s/it]

 82%|████████▏ | 13172/16104 [60:50:45<14:17:18, 17.54s/it]


 82%|████████▏ | 13174/16104 [60:51:23<14:54:26, 18.32s/it]
{'loss': 0.4551, 'learning_rate': 1.686700886978021e-07, 'rewards/chosen': -0.6213043928146362, 'rewards/rejected': -1.242632508277893, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6213281154632568, 'policy_logps/rejected': -397.3385009765625, 'policy_logps/chosen': -411.2030944824219, 'referece_logps/rejected': -384.91217041015625, 'referece_logps/chosen': -404.99005126953125, 'logits/rejected': 0.3388722836971283, 'logits/chosen': 0.2786988317966461, 'epoch': 4.91}

 82%|████████▏ | 13175/16104 [60:51:43<15:12:49, 18.70s/it]

 82%|████████▏ | 13176/16104 [60:51:57<14:14:29, 17.51s/it]


 82%|████████▏ | 13178/16104 [60:52:27<12:51:18, 15.82s/it]
{'loss': 0.4997, 'learning_rate': 1.6822323049848087e-07, 'rewards/chosen': -0.7653321623802185, 'rewards/rejected': -1.0322414636611938, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2669093608856201, 'policy_logps/rejected': -335.0147705078125, 'policy_logps/chosen': -378.7367858886719, 'referece_logps/rejected': -324.6923828125, 'referece_logps/chosen': -371.0834655761719, 'logits/rejected': -0.6805179119110107, 'logits/chosen': -0.6723743677139282, 'epoch': 4.91}

 82%|████████▏ | 13179/16104 [60:52:47<13:46:15, 16.95s/it]

 82%|████████▏ | 13180/16104 [60:53:07<14:30:25, 17.86s/it]

 82%|████████▏ | 13181/16104 [60:53:24<14:29:42, 17.85s/it]

 82%|████████▏ | 13182/16104 [60:53:43<14:45:25, 18.18s/it]


 82%|████████▏ | 13184/16104 [60:54:09<12:33:57, 15.49s/it]
{'loss': 0.3609, 'learning_rate': 1.675539526953722e-07, 'rewards/chosen': -0.6246082782745361, 'rewards/rejected': -1.42212975025177, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7975213527679443, 'policy_logps/rejected': -490.1451110839844, 'policy_logps/chosen': -474.1750793457031, 'referece_logps/rejected': -475.923828125, 'referece_logps/chosen': -467.928955078125, 'logits/rejected': -0.7724371552467346, 'logits/chosen': -0.7248567342758179, 'epoch': 4.91}

 82%|████████▏ | 13185/16104 [60:54:29<13:35:56, 16.77s/it]


 82%|████████▏ | 13187/16104 [60:54:57<12:43:12, 15.70s/it]
{'loss': 0.4187, 'learning_rate': 1.672197683309474e-07, 'rewards/chosen': -0.753858208656311, 'rewards/rejected': -2.1003363132476807, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3464781045913696, 'policy_logps/rejected': -479.1346740722656, 'policy_logps/chosen': -380.6063232421875, 'referece_logps/rejected': -458.13128662109375, 'referece_logps/chosen': -373.0677185058594, 'logits/rejected': 0.12354667484760284, 'logits/chosen': 0.14973555505275726, 'epoch': 4.91}

 82%|████████▏ | 13188/16104 [60:55:13<12:41:43, 15.67s/it]

 82%|████████▏ | 13189/16104 [60:55:24<11:30:15, 14.21s/it]

 82%|████████▏ | 13190/16104 [60:55:41<12:14:16, 15.12s/it]

 82%|████████▏ | 13191/16104 [60:55:55<12:01:24, 14.86s/it]

 82%|████████▏ | 13192/16104 [60:56:06<11:02:04, 13.64s/it]

 82%|████████▏ | 13193/16104 [60:56:20<11:09:27, 13.80s/it]

 82%|████████▏ | 13194/16104 [60:56:40<12:35:43, 15.58s/it]

 82%|████████▏ | 13195/16104 [60:56:55<12:30:21, 15.48s/it]


 82%|████████▏ | 13197/16104 [60:57:30<13:02:19, 16.15s/it]
{'loss': 0.5035, 'learning_rate': 1.6610801081609303e-07, 'rewards/chosen': -0.4483206272125244, 'rewards/rejected': -2.0126519203186035, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5643310546875, 'policy_logps/rejected': -408.4845275878906, 'policy_logps/chosen': -444.6064147949219, 'referece_logps/rejected': -388.3580322265625, 'referece_logps/chosen': -440.12322998046875, 'logits/rejected': -0.3107927739620209, 'logits/chosen': -0.057043641805648804, 'epoch': 4.92}

 82%|████████▏ | 13198/16104 [60:57:41<11:53:31, 14.73s/it]

 82%|████████▏ | 13199/16104 [60:58:01<13:06:19, 16.24s/it]

 82%|████████▏ | 13200/16104 [60:58:13<12:02:02, 14.92s/it]

 82%|████████▏ | 13201/16104 [60:58:35<13:53:14, 17.22s/it]

 82%|████████▏ | 13202/16104 [60:58:53<14:07:40, 17.53s/it]

 82%|████████▏ | 13203/16104 [60:59:06<12:53:58, 16.01s/it]


 82%|████████▏ | 13205/16104 [60:59:30<11:06:41, 13.80s/it]
{'loss': 0.4191, 'learning_rate': 1.6522103332215975e-07, 'rewards/chosen': -0.34956780076026917, 'rewards/rejected': -1.9845569133758545, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6349892616271973, 'policy_logps/rejected': -420.05755615234375, 'policy_logps/chosen': -509.84454345703125, 'referece_logps/rejected': -400.21197509765625, 'referece_logps/chosen': -506.348876953125, 'logits/rejected': -0.5095639228820801, 'logits/chosen': -0.5291306376457214, 'epoch': 4.92}

 82%|████████▏ | 13206/16104 [60:59:42<10:44:43, 13.35s/it]

 82%|████████▏ | 13207/16104 [60:59:57<11:07:01, 13.81s/it]


 82%|████████▏ | 13209/16104 [61:00:22<10:37:40, 13.22s/it]
{'loss': 0.3224, 'learning_rate': 1.6477835487089252e-07, 'rewards/chosen': -0.11753426492214203, 'rewards/rejected': -1.7665423154830933, 'rewards/accuracies': 0.875, 'rewards/margins': 1.64900803565979, 'policy_logps/rejected': -384.486083984375, 'policy_logps/chosen': -401.4241943359375, 'referece_logps/rejected': -366.8206787109375, 'referece_logps/chosen': -400.2488708496094, 'logits/rejected': 0.3264675736427307, 'logits/chosen': 0.2524975538253784, 'epoch': 4.92}

 82%|████████▏ | 13210/16104 [61:00:41<12:12:21, 15.18s/it]

 82%|████████▏ | 13211/16104 [61:00:59<12:42:51, 15.82s/it]


 82%|████████▏ | 13213/16104 [61:01:36<13:50:17, 17.23s/it]

 82%|████████▏ | 13214/16104 [61:01:52<13:32:03, 16.86s/it]
{'loss': 0.4809, 'learning_rate': 1.6422576702994794e-07, 'rewards/chosen': 0.14261798560619354, 'rewards/rejected': -1.9580817222595215, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1006994247436523, 'policy_logps/rejected': -414.36065673828125, 'policy_logps/chosen': -405.42083740234375, 'referece_logps/rejected': -394.7798156738281, 'referece_logps/chosen': -406.8470458984375, 'logits/rejected': -0.20853926241397858, 'logits/chosen': -0.10198459029197693, 'epoch': 4.92}

 82%|████████▏ | 13215/16104 [61:02:04<12:18:08, 15.33s/it]

 82%|████████▏ | 13216/16104 [61:02:15<11:26:17, 14.26s/it]

 82%|████████▏ | 13217/16104 [61:02:30<11:34:56, 14.44s/it]

 82%|████████▏ | 13218/16104 [61:02:41<10:43:32, 13.38s/it]

 82%|████████▏ | 13219/16104 [61:02:53<10:19:04, 12.87s/it]

 82%|████████▏ | 13220/16104 [61:03:05<10:12:46, 12.75s/it]


 82%|████████▏ | 13222/16104 [61:03:44<13:02:11, 16.28s/it]
{'loss': 0.3859, 'learning_rate': 1.6334338476152288e-07, 'rewards/chosen': -0.10036961734294891, 'rewards/rejected': -1.2696385383605957, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1692688465118408, 'policy_logps/rejected': -443.6044921875, 'policy_logps/chosen': -463.5244445800781, 'referece_logps/rejected': -430.9080810546875, 'referece_logps/chosen': -462.52069091796875, 'logits/rejected': -0.2918739318847656, 'logits/chosen': -0.20370632410049438, 'epoch': 4.93}

 82%|████████▏ | 13223/16104 [61:03:55<11:42:14, 14.63s/it]

 82%|████████▏ | 13224/16104 [61:04:10<11:47:59, 14.75s/it]

 82%|████████▏ | 13225/16104 [61:04:24<11:37:04, 14.53s/it]

 82%|████████▏ | 13226/16104 [61:04:35<10:43:11, 13.41s/it]

 82%|████████▏ | 13227/16104 [61:04:52<11:43:08, 14.66s/it]

 82%|████████▏ | 13228/16104 [61:05:02<10:36:54, 13.29s/it]

 82%|████████▏ | 13229/16104 [61:05:21<11:49:51, 14.81s/it]

 82%|████████▏ | 13230/16104 [61:05:38<12:22:33, 15.50s/it]

 82%|████████▏ | 13231/16104 [61:05:48<11:11:28, 14.02s/it]

 82%|████████▏ | 13232/16104 [61:06:06<11:59:07, 15.02s/it]

 82%|████████▏ | 13233/16104 [61:06:19<11:33:15, 14.49s/it]

 82%|████████▏ | 13234/16104 [61:06:37<12:25:46, 15.59s/it]

 82%|████████▏ | 13235/16104 [61:06:51<11:57:14, 15.00s/it]

 82%|████████▏ | 13236/16104 [61:07:09<12:40:44, 15.92s/it]

 82%|████████▏ | 13237/16104 [61:07:27<13:16:20, 16.67s/it]

 82%|████████▏ | 13238/16104 [61:07:48<14:11:27, 17.83s/it]


 82%|████████▏ | 13240/16104 [61:08:26<14:45:07, 18.54s/it]
{'loss': 0.3736, 'learning_rate': 1.613659476821889e-07, 'rewards/chosen': -0.118874192237854, 'rewards/rejected': -2.27129864692688, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1524245738983154, 'policy_logps/rejected': -614.6094970703125, 'policy_logps/chosen': -396.7803039550781, 'referece_logps/rejected': -591.8965454101562, 'referece_logps/chosen': -395.5915832519531, 'logits/rejected': -1.0508357286453247, 'logits/chosen': -0.6912137269973755, 'epoch': 4.93}

 82%|████████▏ | 13241/16104 [61:08:38<13:13:53, 16.64s/it]

 82%|████████▏ | 13242/16104 [61:08:55<13:07:39, 16.51s/it]

 82%|████████▏ | 13243/16104 [61:09:09<12:39:29, 15.93s/it]


 82%|████████▏ | 13245/16104 [61:09:36<11:29:23, 14.47s/it]
{'loss': 0.4515, 'learning_rate': 1.608186091427217e-07, 'rewards/chosen': -0.9189655780792236, 'rewards/rejected': -1.5073859691619873, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5884203314781189, 'policy_logps/rejected': -295.1425476074219, 'policy_logps/chosen': -312.290283203125, 'referece_logps/rejected': -280.06866455078125, 'referece_logps/chosen': -303.1006774902344, 'logits/rejected': -0.251220166683197, 'logits/chosen': -0.1021430492401123, 'epoch': 4.93}


 82%|████████▏ | 13247/16104 [61:10:06<11:56:29, 15.05s/it]

 82%|████████▏ | 13248/16104 [61:10:22<12:11:59, 15.38s/it]
{'loss': 0.3511, 'learning_rate': 1.6049061334023617e-07, 'rewards/chosen': 0.3080955445766449, 'rewards/rejected': -1.0948200225830078, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4029157161712646, 'policy_logps/rejected': -441.3519287109375, 'policy_logps/chosen': -571.80126953125, 'referece_logps/rejected': -430.4036865234375, 'referece_logps/chosen': -574.8822021484375, 'logits/rejected': 0.04903040826320648, 'logits/chosen': 0.0622854121029377, 'epoch': 4.94}

 82%|████████▏ | 13249/16104 [61:10:34<11:12:43, 14.14s/it]

 82%|████████▏ | 13250/16104 [61:10:52<12:16:53, 15.49s/it]

 82%|████████▏ | 13251/16104 [61:11:03<11:07:47, 14.04s/it]

 82%|████████▏ | 13252/16104 [61:11:14<10:20:04, 13.05s/it]

 82%|████████▏ | 13253/16104 [61:11:26<10:12:58, 12.90s/it]

 82%|████████▏ | 13254/16104 [61:11:40<10:30:09, 13.27s/it]

 82%|████████▏ | 13255/16104 [61:11:57<11:13:37, 14.19s/it]

 82%|████████▏ | 13256/16104 [61:12:14<11:57:27, 15.11s/it]

 82%|████████▏ | 13257/16104 [61:12:28<11:42:16, 14.80s/it]

 82%|████████▏ | 13258/16104 [61:12:41<11:21:16, 14.36s/it]

 82%|████████▏ | 13259/16104 [61:12:59<12:06:55, 15.33s/it]

 82%|████████▏ | 13260/16104 [61:13:16<12:30:10, 15.83s/it]

 82%|████████▏ | 13261/16104 [61:13:34<12:56:05, 16.38s/it]

 82%|████████▏ | 13262/16104 [61:13:50<12:56:01, 16.38s/it]

 82%|████████▏ | 13263/16104 [61:14:06<12:55:35, 16.38s/it]

 82%|████████▏ | 13264/16104 [61:14:24<13:13:47, 16.77s/it]

 82%|████████▏ | 13265/16104 [61:14:36<12:09:57, 15.43s/it]

 82%|████████▏ | 13266/16104 [61:14:47<11:04:06, 14.04s/it]

 82%|████████▏ | 13267/16104 [61:15:06<12:13:51, 15.52s/it]

 82%|████████▏ | 13268/16104 [61:15:20<11:46:46, 14.95s/it]


 82%|████████▏ | 13270/16104 [61:15:45<10:52:51, 13.82s/it]
{'loss': 0.42, 'learning_rate': 1.580946573790042e-07, 'rewards/chosen': -0.3461136221885681, 'rewards/rejected': -1.4272698163986206, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0811561346054077, 'policy_logps/rejected': -568.5902099609375, 'policy_logps/chosen': -464.08441162109375, 'referece_logps/rejected': -554.3175048828125, 'referece_logps/chosen': -460.6232604980469, 'logits/rejected': 0.9263120889663696, 'logits/chosen': 0.987510621547699, 'epoch': 4.94}

 82%|████████▏ | 13271/16104 [61:16:04<12:12:38, 15.52s/it]

 82%|████████▏ | 13272/16104 [61:16:18<11:49:05, 15.02s/it]

 82%|████████▏ | 13273/16104 [61:16:37<12:45:36, 16.23s/it]

 82%|████████▏ | 13274/16104 [61:16:49<11:47:53, 15.01s/it]

 82%|████████▏ | 13275/16104 [61:17:04<11:38:53, 14.82s/it]


 82%|████████▏ | 13277/16104 [61:17:47<14:23:35, 18.33s/it]
{'loss': 0.3006, 'learning_rate': 1.573357622646808e-07, 'rewards/chosen': -0.34334880113601685, 'rewards/rejected': -2.2027223110198975, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8593735694885254, 'policy_logps/rejected': -516.4799194335938, 'policy_logps/chosen': -441.6302490234375, 'referece_logps/rejected': -494.45269775390625, 'referece_logps/chosen': -438.19677734375, 'logits/rejected': 0.2942594289779663, 'logits/chosen': 0.2658303380012512, 'epoch': 4.95}

 82%|████████▏ | 13278/16104 [61:18:08<15:02:30, 19.16s/it]

 82%|████████▏ | 13279/16104 [61:18:27<15:05:05, 19.22s/it]

 82%|████████▏ | 13280/16104 [61:18:47<15:15:38, 19.45s/it]

 82%|████████▏ | 13281/16104 [61:19:07<15:15:23, 19.46s/it]

 82%|████████▏ | 13282/16104 [61:19:25<15:02:36, 19.19s/it]

 82%|████████▏ | 13283/16104 [61:19:44<14:50:14, 18.93s/it]

 82%|████████▏ | 13284/16104 [61:19:56<13:17:13, 16.96s/it]

 82%|████████▏ | 13285/16104 [61:20:13<13:10:55, 16.83s/it]

 83%|████████▎ | 13286/16104 [61:20:33<13:59:21, 17.87s/it]

 83%|████████▎ | 13287/16104 [61:20:53<14:23:02, 18.38s/it]


 83%|████████▎ | 13289/16104 [61:21:27<14:12:00, 18.16s/it]

 83%|████████▎ | 13290/16104 [61:21:47<14:35:57, 18.68s/it]
{'loss': 0.3476, 'learning_rate': 1.5593081810627272e-07, 'rewards/chosen': -0.6568296551704407, 'rewards/rejected': -2.3112080097198486, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6543782949447632, 'policy_logps/rejected': -268.65460205078125, 'policy_logps/chosen': -425.11260986328125, 'referece_logps/rejected': -245.54251098632812, 'referece_logps/chosen': -418.5443420410156, 'logits/rejected': -0.08894559741020203, 'logits/chosen': -0.18808364868164062, 'epoch': 4.95}


 83%|████████▎ | 13292/16104 [61:22:21<14:02:21, 17.97s/it]

 83%|████████▎ | 13293/16104 [61:22:38<13:49:33, 17.71s/it]

 83%|████████▎ | 13294/16104 [61:22:54<13:20:19, 17.09s/it]

 83%|████████▎ | 13295/16104 [61:23:14<14:03:12, 18.01s/it]

 83%|████████▎ | 13296/16104 [61:23:30<13:41:52, 17.56s/it]

 83%|████████▎ | 13297/16104 [61:23:45<12:59:21, 16.66s/it]

 83%|████████▎ | 13298/16104 [61:24:01<12:51:07, 16.49s/it]

 83%|████████▎ | 13299/16104 [61:24:17<12:38:05, 16.22s/it]

 83%|████████▎ | 13300/16104 [61:24:34<12:52:14, 16.52s/it]
{'loss': 0.3635, 'learning_rate': 1.5485401789906417e-07, 'rewards/chosen': 0.29456329345703125, 'rewards/rejected': -1.8728153705596924, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1673789024353027, 'policy_logps/rejected': -494.6091003417969, 'policy_logps/chosen': -375.2934875488281, 'referece_logps/rejected': -475.88092041015625, 'referece_logps/chosen': -378.23919677734375, 'logits/rejected': 1.1280332803726196, 'logits/chosen': 1.2265090942382812, 'epoch': 4.96}

 83%|████████▎ | 13301/16104 [61:24:52<13:06:32, 16.84s/it]


 83%|████████▎ | 13303/16104 [61:25:24<12:34:06, 16.15s/it]

 83%|████████▎ | 13304/16104 [61:25:39<12:17:15, 15.80s/it]

 83%|████████▎ | 13305/16104 [61:25:55<12:16:44, 15.79s/it]

 83%|████████▎ | 13306/16104 [61:26:11<12:22:39, 15.93s/it]

 83%|████████▎ | 13307/16104 [61:26:29<12:52:58, 16.58s/it]

 83%|████████▎ | 13308/16104 [61:26:41<11:42:14, 15.07s/it]

 83%|████████▎ | 13309/16104 [61:26:56<11:49:30, 15.23s/it]

 83%|████████▎ | 13310/16104 [61:27:08<11:05:56, 14.30s/it]

 83%|████████▎ | 13311/16104 [61:27:23<11:09:24, 14.38s/it]

 83%|████████▎ | 13312/16104 [61:27:34<10:30:00, 13.54s/it]

 83%|████████▎ | 13313/16104 [61:27:45<9:50:36, 12.70s/it]

 83%|████████▎ | 13314/16104 [61:28:03<10:59:28, 14.18s/it]

 83%|████████▎ | 13315/16104 [61:28:15<10:31:25, 13.58s/it]

 83%|████████▎ | 13316/16104 [61:28:27<10:12:28, 13.18s/it]

 83%|████████▎ | 13317/16104 [61:28:39<9:57:25, 12.86s/it]
{'loss': 0.4091, 'learning_rate': 1.530313059385865e-07, 'rewards/chosen': -0.737098753452301, 'rewards/rejected': -2.1844117641448975, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4473129510879517, 'policy_logps/rejected': -310.22845458984375, 'policy_logps/chosen': -469.4756164550781, 'referece_logps/rejected': -288.38433837890625, 'referece_logps/chosen': -462.1046142578125, 'logits/rejected': -1.0862927436828613, 'logits/chosen': -1.2091693878173828, 'epoch': 4.96}


 83%|████████▎ | 13319/16104 [61:29:04<9:48:25, 12.68s/it]
{'loss': 0.5114, 'learning_rate': 1.528175197923811e-07, 'rewards/chosen': 0.14865130186080933, 'rewards/rejected': -0.5184614062309265, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6671126484870911, 'policy_logps/rejected': -377.4085693359375, 'policy_logps/chosen': -467.1065368652344, 'referece_logps/rejected': -372.2239990234375, 'referece_logps/chosen': -468.5930480957031, 'logits/rejected': 0.07514511048793793, 'logits/chosen': -0.02660788595676422, 'epoch': 4.96}


 83%|████████▎ | 13321/16104 [61:29:41<11:51:41, 15.34s/it]

 83%|████████▎ | 13322/16104 [61:29:54<11:26:28, 14.81s/it]
{'loss': 0.3721, 'learning_rate': 1.5249709760919827e-07, 'rewards/chosen': -0.1443391740322113, 'rewards/rejected': -1.805122971534729, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6607837677001953, 'policy_logps/rejected': -538.3378295898438, 'policy_logps/chosen': -449.4496765136719, 'referece_logps/rejected': -520.28662109375, 'referece_logps/chosen': -448.00628662109375, 'logits/rejected': -0.20043087005615234, 'logits/chosen': -0.33917737007141113, 'epoch': 4.96}


 83%|████████▎ | 13324/16104 [61:30:19<10:28:20, 13.56s/it]

 83%|████████▎ | 13325/16104 [61:30:38<11:53:16, 15.40s/it]
{'loss': 0.4067, 'learning_rate': 1.521769839730499e-07, 'rewards/chosen': 0.31088364124298096, 'rewards/rejected': -1.4095042943954468, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7203880548477173, 'policy_logps/rejected': -350.6688537597656, 'policy_logps/chosen': -443.5971984863281, 'referece_logps/rejected': -336.57379150390625, 'referece_logps/chosen': -446.7060546875, 'logits/rejected': -0.27709728479385376, 'logits/chosen': -0.2792682647705078, 'epoch': 4.96}


 83%|████████▎ | 13327/16104 [61:31:06<11:10:20, 14.48s/it]
{'loss': 0.4221, 'learning_rate': 1.5196374635485964e-07, 'rewards/chosen': -0.6580216884613037, 'rewards/rejected': -1.161210298538208, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5031886696815491, 'policy_logps/rejected': -402.0292053222656, 'policy_logps/chosen': -377.9081115722656, 'referece_logps/rejected': -390.4171142578125, 'referece_logps/chosen': -371.327880859375, 'logits/rejected': -0.04937097430229187, 'logits/chosen': -0.012851342558860779, 'epoch': 4.97}


 83%|████████▎ | 13329/16104 [61:31:32<10:34:54, 13.73s/it]

 83%|████████▎ | 13330/16104 [61:31:46<10:36:56, 13.78s/it]

 83%|████████▎ | 13331/16104 [61:32:03<11:23:44, 14.79s/it]

 83%|████████▎ | 13332/16104 [61:32:19<11:37:33, 15.10s/it]

 83%|████████▎ | 13333/16104 [61:32:39<12:39:22, 16.44s/it]

 83%|████████▎ | 13334/16104 [61:32:57<13:00:36, 16.91s/it]
{'loss': 0.3961, 'learning_rate': 1.5121849551167476e-07, 'rewards/chosen': -1.0817416906356812, 'rewards/rejected': -2.844451904296875, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7627103328704834, 'policy_logps/rejected': -359.5180358886719, 'policy_logps/chosen': -361.7920837402344, 'referece_logps/rejected': -331.0735168457031, 'referece_logps/chosen': -350.97467041015625, 'logits/rejected': -0.2785397171974182, 'logits/chosen': -0.18878382444381714, 'epoch': 4.97}


 83%|████████▎ | 13336/16104 [61:33:31<13:02:17, 16.96s/it]
{'loss': 0.374, 'learning_rate': 1.5100587564730794e-07, 'rewards/chosen': -0.6371904611587524, 'rewards/rejected': -2.790252923965454, 'rewards/accuracies': 0.75, 'rewards/margins': 2.153062582015991, 'policy_logps/rejected': -543.8386840820312, 'policy_logps/chosen': -498.5417785644531, 'referece_logps/rejected': -515.9362182617188, 'referece_logps/chosen': -492.1698913574219, 'logits/rejected': -0.44124671816825867, 'logits/chosen': -0.8858311176300049, 'epoch': 4.97}


 83%|████████▎ | 13338/16104 [61:33:54<10:46:06, 14.02s/it]

 83%|████████▎ | 13339/16104 [61:34:06<10:16:26, 13.38s/it]

 83%|████████▎ | 13340/16104 [61:34:19<10:21:18, 13.49s/it]
{'loss': 0.4304, 'learning_rate': 1.505810480728791e-07, 'rewards/chosen': -0.40280699729919434, 'rewards/rejected': -1.0382213592529297, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6354144811630249, 'policy_logps/rejected': -298.9941711425781, 'policy_logps/chosen': -458.74053955078125, 'referece_logps/rejected': -288.6119689941406, 'referece_logps/chosen': -454.7124938964844, 'logits/rejected': -0.7745615243911743, 'logits/chosen': -0.873563289642334, 'epoch': 4.97}


 83%|████████▎ | 13342/16104 [61:34:41<9:15:36, 12.07s/it]

 83%|████████▎ | 13343/16104 [61:34:52<9:01:08, 11.76s/it]

 83%|████████▎ | 13344/16104 [61:35:04<9:07:33, 11.90s/it]

 83%|████████▎ | 13345/16104 [61:35:24<10:55:17, 14.25s/it]

 83%|████████▎ | 13346/16104 [61:35:43<12:03:03, 15.73s/it]

 83%|████████▎ | 13347/16104 [61:36:03<12:59:28, 16.96s/it]

 83%|████████▎ | 13348/16104 [61:36:22<13:28:27, 17.60s/it]

 83%|████████▎ | 13349/16104 [61:36:43<14:17:51, 18.68s/it]

 83%|████████▎ | 13350/16104 [61:37:01<14:07:55, 18.47s/it]

 83%|████████▎ | 13351/16104 [61:37:14<12:47:05, 16.72s/it]
{'loss': 0.4066, 'learning_rate': 1.4941560781108764e-07, 'rewards/chosen': -0.4727210998535156, 'rewards/rejected': -1.6640394926071167, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1913185119628906, 'policy_logps/rejected': -579.6729736328125, 'policy_logps/chosen': -412.91400146484375, 'referece_logps/rejected': -563.0325317382812, 'referece_logps/chosen': -408.1867980957031, 'logits/rejected': 0.025913478806614876, 'logits/chosen': -0.000951151130720973, 'epoch': 4.97}


 83%|████████▎ | 13353/16104 [61:37:44<12:27:04, 16.29s/it]

 83%|████████▎ | 13354/16104 [61:38:00<12:24:45, 16.25s/it]

 83%|████████▎ | 13355/16104 [61:38:16<12:23:31, 16.23s/it]

 83%|████████▎ | 13356/16104 [61:38:36<13:07:09, 17.19s/it]

 83%|████████▎ | 13357/16104 [61:38:55<13:39:11, 17.89s/it]
{'loss': 0.4835, 'learning_rate': 1.48781667549143e-07, 'rewards/chosen': 0.10004232078790665, 'rewards/rejected': -1.4227341413497925, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5227763652801514, 'policy_logps/rejected': -414.6666259765625, 'policy_logps/chosen': -504.2796630859375, 'referece_logps/rejected': -400.4393310546875, 'referece_logps/chosen': -505.28009033203125, 'logits/rejected': -0.1495085060596466, 'logits/chosen': 0.0010703876614570618, 'epoch': 4.98}


 83%|████████▎ | 13359/16104 [61:39:31<13:34:20, 17.80s/it]

 83%|████████▎ | 13360/16104 [61:39:43<12:09:34, 15.95s/it]

 83%|████████▎ | 13361/16104 [61:40:05<13:33:37, 17.80s/it]

 83%|████████▎ | 13362/16104 [61:40:21<13:14:23, 17.38s/it]

 83%|████████▎ | 13363/16104 [61:40:41<13:48:57, 18.15s/it]

 83%|████████▎ | 13364/16104 [61:40:54<12:30:04, 16.42s/it]

 83%|████████▎ | 13365/16104 [61:41:10<12:27:00, 16.36s/it]

 83%|████████▎ | 13366/16104 [61:41:26<12:26:39, 16.36s/it]

 83%|████████▎ | 13367/16104 [61:41:40<11:54:46, 15.67s/it]

 83%|████████▎ | 13368/16104 [61:41:54<11:30:01, 15.13s/it]

 83%|████████▎ | 13369/16104 [61:42:14<12:29:20, 16.44s/it]

 83%|████████▎ | 13370/16104 [61:42:33<13:15:01, 17.45s/it]

 83%|████████▎ | 13371/16104 [61:42:46<12:12:09, 16.07s/it]

 83%|████████▎ | 13372/16104 [61:43:01<11:55:28, 15.71s/it]

 83%|████████▎ | 13373/16104 [61:43:18<12:10:10, 16.04s/it]

 83%|████████▎ | 13374/16104 [61:43:38<13:02:33, 17.20s/it]

 83%|████████▎ | 13375/16104 [61:43:58<13:49:13, 18.23s/it]

 83%|████████▎ | 13376/16104 [61:44:16<13:38:13, 18.00s/it]

 83%|████████▎ | 13377/16104 [61:44:32<13:17:52, 17.56s/it]

 83%|████████▎ | 13378/16104 [61:44:44<11:55:51, 15.76s/it]

 83%|████████▎ | 13379/16104 [61:45:04<12:56:39, 17.10s/it]

 83%|████████▎ | 13380/16104 [61:45:20<12:32:16, 16.57s/it]

 83%|████████▎ | 13381/16104 [61:45:40<13:25:23, 17.75s/it]

 83%|████████▎ | 13382/16104 [61:45:59<13:43:53, 18.16s/it]
{'loss': 0.4689, 'learning_rate': 1.461536031509075e-07, 'rewards/chosen': -0.2442573606967926, 'rewards/rejected': -1.1391983032226562, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8949409127235413, 'policy_logps/rejected': -434.772216796875, 'policy_logps/chosen': -595.9268798828125, 'referece_logps/rejected': -423.3802490234375, 'referece_logps/chosen': -593.4841918945312, 'logits/rejected': -0.2324785441160202, 'logits/chosen': -0.36931663751602173, 'epoch': 4.99}


 83%|████████▎ | 13384/16104 [61:46:27<12:08:54, 16.08s/it]
{'loss': 0.3611, 'learning_rate': 1.4594428969008011e-07, 'rewards/chosen': -0.3965005576610565, 'rewards/rejected': -1.7840567827224731, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3875560760498047, 'policy_logps/rejected': -502.0310974121094, 'policy_logps/chosen': -422.4505615234375, 'referece_logps/rejected': -484.1905517578125, 'referece_logps/chosen': -418.485595703125, 'logits/rejected': 0.20772336423397064, 'logits/chosen': 0.10961905121803284, 'epoch': 4.99}


 83%|████████▎ | 13386/16104 [61:47:08<13:48:49, 18.30s/it]

 83%|████████▎ | 13387/16104 [61:47:30<14:42:51, 19.50s/it]

 83%|████████▎ | 13388/16104 [61:47:48<14:17:57, 18.95s/it]

 83%|████████▎ | 13389/16104 [61:48:08<14:35:56, 19.36s/it]

 83%|████████▎ | 13390/16104 [61:48:24<13:52:42, 18.41s/it]

 83%|████████▎ | 13391/16104 [61:48:44<14:09:44, 18.79s/it]

 83%|████████▎ | 13392/16104 [61:48:56<12:35:27, 16.71s/it]
{'loss': 0.4385, 'learning_rate': 1.451084181082065e-07, 'rewards/chosen': -0.39128053188323975, 'rewards/rejected': -1.2950718402862549, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9037913680076599, 'policy_logps/rejected': -522.083740234375, 'policy_logps/chosen': -510.28533935546875, 'referece_logps/rejected': -509.1330261230469, 'referece_logps/chosen': -506.3725280761719, 'logits/rejected': 0.2300594449043274, 'logits/chosen': 0.46330422163009644, 'epoch': 4.99}


 83%|████████▎ | 13394/16104 [61:49:27<12:23:29, 16.46s/it]
{'loss': 0.4521, 'learning_rate': 1.4489979594715963e-07, 'rewards/chosen': -0.476296991109848, 'rewards/rejected': -2.462435483932495, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9861384630203247, 'policy_logps/rejected': -380.960205078125, 'policy_logps/chosen': -444.03692626953125, 'referece_logps/rejected': -356.3358154296875, 'referece_logps/chosen': -439.2739562988281, 'logits/rejected': 0.24497447907924652, 'logits/chosen': 0.33410391211509705, 'epoch': 4.99}


 83%|████████▎ | 13396/16104 [61:50:01<12:43:36, 16.92s/it]

 83%|████████▎ | 13397/16104 [61:50:18<12:44:16, 16.94s/it]

 83%|████████▎ | 13398/16104 [61:50:33<12:16:26, 16.33s/it]

 83%|████████▎ | 13399/16104 [61:50:49<12:14:56, 16.30s/it]

 83%|████████▎ | 13400/16104 [61:51:04<12:01:58, 16.02s/it]
{'loss': 0.4176, 'learning_rate': 1.442747597668249e-07, 'rewards/chosen': -0.5671222805976868, 'rewards/rejected': -1.480650782585144, 'rewards/accuracies': 0.75, 'rewards/margins': 0.913528561592102, 'policy_logps/rejected': -379.6716003417969, 'policy_logps/chosen': -505.6797790527344, 'referece_logps/rejected': -364.8650817871094, 'referece_logps/chosen': -500.0085144042969, 'logits/rejected': 0.453440397977829, 'logits/chosen': 0.6344244480133057, 'epoch': 4.99}


 83%|████████▎ | 13402/16104 [61:51:35<11:28:31, 15.29s/it]

 83%|████████▎ | 13403/16104 [61:51:49<11:09:18, 14.87s/it]

 83%|████████▎ | 13404/16104 [61:52:08<12:11:40, 16.26s/it]

 83%|████████▎ | 13405/16104 [61:52:27<12:41:55, 16.94s/it]
{'loss': 0.4602, 'learning_rate': 1.4375484817388428e-07, 'rewards/chosen': -0.4284299910068512, 'rewards/rejected': -1.649505615234375, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2210755348205566, 'policy_logps/rejected': -462.11663818359375, 'policy_logps/chosen': -533.2559204101562, 'referece_logps/rejected': -445.62158203125, 'referece_logps/chosen': -528.9716186523438, 'logits/rejected': -0.3832065165042877, 'logits/chosen': -0.4708893299102783, 'epoch': 4.99}


 83%|████████▎ | 13407/16104 [61:52:55<11:47:05, 15.73s/it]

 83%|████████▎ | 13408/16104 [61:53:15<12:48:40, 17.11s/it]
{'loss': 0.3864, 'learning_rate': 1.4344331682420475e-07, 'rewards/chosen': -0.2972314655780792, 'rewards/rejected': -2.148986577987671, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8517552614212036, 'policy_logps/rejected': -411.67547607421875, 'policy_logps/chosen': -423.8699645996094, 'referece_logps/rejected': -390.18560791015625, 'referece_logps/chosen': -420.89764404296875, 'logits/rejected': -0.08478173613548279, 'logits/chosen': 0.07270139455795288, 'epoch': 5.0}


 83%|████████▎ | 13410/16104 [61:53:43<11:44:06, 15.68s/it]

 83%|████████▎ | 13411/16104 [61:54:03<12:37:51, 16.89s/it]

 83%|████████▎ | 13412/16104 [61:54:23<13:23:48, 17.92s/it]

 83%|████████▎ | 13413/16104 [61:54:41<13:21:29, 17.87s/it]

 83%|████████▎ | 13414/16104 [61:54:58<13:15:22, 17.74s/it]

 83%|████████▎ | 13415/16104 [61:55:16<13:18:02, 17.81s/it]
{'loss': 0.4262, 'learning_rate': 1.4271762326102731e-07, 'rewards/chosen': -1.2357139587402344, 'rewards/rejected': -1.9684009552001953, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7326870560646057, 'policy_logps/rejected': -308.1432800292969, 'policy_logps/chosen': -422.76605224609375, 'referece_logps/rejected': -288.4592590332031, 'referece_logps/chosen': -410.4089050292969, 'logits/rejected': 0.18203981220722198, 'logits/chosen': 0.33916333317756653, 'epoch': 5.0}


 83%|████████▎ | 13417/16104 [61:55:57<14:16:55, 19.13s/it]
{'loss': 0.3151, 'learning_rate': 1.425105942875231e-07, 'rewards/chosen': -0.5792459845542908, 'rewards/rejected': -2.4561641216278076, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8769183158874512, 'policy_logps/rejected': -508.3547058105469, 'policy_logps/chosen': -387.8203430175781, 'referece_logps/rejected': -483.79315185546875, 'referece_logps/chosen': -382.02783203125, 'logits/rejected': -0.8470495939254761, 'logits/chosen': -0.8264678716659546, 'epoch': 5.0}

 83%|████████▎ | 13418/16104 [61:56:12<13:23:47, 17.95s/it]


 83%|████████▎ | 13420/16104 [61:56:51<13:59:14, 18.76s/it]
{'loss': 0.3528, 'learning_rate': 1.4220031099005092e-07, 'rewards/chosen': 0.10951270163059235, 'rewards/rejected': -1.630112648010254, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7396254539489746, 'policy_logps/rejected': -504.71942138671875, 'policy_logps/chosen': -552.9412841796875, 'referece_logps/rejected': -488.4183044433594, 'referece_logps/chosen': -554.036376953125, 'logits/rejected': -0.45447438955307007, 'logits/chosen': -0.4546065032482147, 'epoch': 5.0}


 83%|████████▎ | 13422/16104 [61:57:31<14:24:29, 19.34s/it]
{'loss': 0.4524, 'learning_rate': 1.4199362894907085e-07, 'rewards/chosen': -0.13563880324363708, 'rewards/rejected': -0.4824988842010498, 'rewards/accuracies': 0.5, 'rewards/margins': 0.34686005115509033, 'policy_logps/rejected': -472.7313232421875, 'policy_logps/chosen': -650.506591796875, 'referece_logps/rejected': -467.9063720703125, 'referece_logps/chosen': -649.150146484375, 'logits/rejected': -0.354065477848053, 'logits/chosen': -0.28967273235321045, 'epoch': 5.0}


 83%|████████▎ | 13424/16104 [61:58:06<13:48:34, 18.55s/it]

 83%|████████▎ | 13425/16104 [61:58:19<12:25:29, 16.70s/it]
{'loss': 0.3422, 'learning_rate': 1.416838662072084e-07, 'rewards/chosen': -0.40733951330184937, 'rewards/rejected': -1.6745775938034058, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2672381401062012, 'policy_logps/rejected': -565.2479248046875, 'policy_logps/chosen': -456.46160888671875, 'referece_logps/rejected': -548.5022583007812, 'referece_logps/chosen': -452.38818359375, 'logits/rejected': -0.24806928634643555, 'logits/chosen': -0.25442636013031006, 'epoch': 5.0}


 83%|████████▎ | 13427/16104 [61:58:55<13:10:11, 17.71s/it]

 83%|████████▎ | 13428/16104 [61:59:13<13:10:20, 17.72s/it]

 83%|████████▎ | 13429/16104 [61:59:23<11:35:23, 15.60s/it]

 83%|████████▎ | 13430/16104 [61:59:37<11:13:11, 15.11s/it]

 83%|████████▎ | 13431/16104 [61:59:50<10:45:48, 14.50s/it]
{'loss': 0.4295, 'learning_rate': 1.4106527828743897e-07, 'rewards/chosen': -0.848366916179657, 'rewards/rejected': -1.3767762184143066, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5284092426300049, 'policy_logps/rejected': -408.53948974609375, 'policy_logps/chosen': -435.1474914550781, 'referece_logps/rejected': -394.771728515625, 'referece_logps/chosen': -426.663818359375, 'logits/rejected': 0.44831934571266174, 'logits/chosen': 0.46101388335227966, 'epoch': 5.0}

 83%|████████▎ | 13432/16104 [62:00:06<10:59:16, 14.80s/it]


 83%|████████▎ | 13434/16104 [62:00:39<11:45:38, 15.86s/it]

 83%|████████▎ | 13435/16104 [62:00:53<11:20:24, 15.30s/it]

 83%|████████▎ | 13436/16104 [62:01:13<12:25:05, 16.76s/it]
{'loss': 0.4963, 'learning_rate': 1.4055074381567245e-07, 'rewards/chosen': -0.6803340911865234, 'rewards/rejected': -1.0256636142730713, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3453294634819031, 'policy_logps/rejected': -621.302734375, 'policy_logps/chosen': -616.5138549804688, 'referece_logps/rejected': -611.0460205078125, 'referece_logps/chosen': -609.7105712890625, 'logits/rejected': 0.6955831050872803, 'logits/chosen': 0.6818957328796387, 'epoch': 5.01}


 83%|████████▎ | 13438/16104 [62:01:41<11:08:46, 15.05s/it]
{'loss': 0.4145, 'learning_rate': 1.4034517336162888e-07, 'rewards/chosen': -0.27863943576812744, 'rewards/rejected': -2.4571480751037598, 'rewards/accuracies': 1.0, 'rewards/margins': 2.178508758544922, 'policy_logps/rejected': -334.3818054199219, 'policy_logps/chosen': -348.73193359375, 'referece_logps/rejected': -309.810302734375, 'referece_logps/chosen': -345.9455261230469, 'logits/rejected': -0.46902137994766235, 'logits/chosen': -0.21523967385292053, 'epoch': 5.01}


 83%|████████▎ | 13440/16104 [62:02:09<10:30:58, 14.21s/it]

 83%|████████▎ | 13441/16104 [62:02:29<11:45:55, 15.91s/it]

 83%|████████▎ | 13442/16104 [62:02:45<11:48:31, 15.97s/it]

 83%|████████▎ | 13443/16104 [62:02:58<11:02:52, 14.95s/it]
{'loss': 0.3465, 'learning_rate': 1.3983185585422686e-07, 'rewards/chosen': -0.6355112195014954, 'rewards/rejected': -2.0914530754089355, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4559417963027954, 'policy_logps/rejected': -443.1602478027344, 'policy_logps/chosen': -406.0634765625, 'referece_logps/rejected': -422.24566650390625, 'referece_logps/chosen': -399.7083435058594, 'logits/rejected': -0.5613082647323608, 'logits/chosen': -0.4850975275039673, 'epoch': 5.01}


 83%|████████▎ | 13445/16104 [62:03:35<12:35:41, 17.05s/it]

 83%|████████▎ | 13446/16104 [62:03:51<12:23:06, 16.77s/it]
{'loss': 0.3437, 'learning_rate': 1.395242828606018e-07, 'rewards/chosen': -0.2626660168170929, 'rewards/rejected': -2.2487986087799072, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9861327409744263, 'policy_logps/rejected': -281.5259704589844, 'policy_logps/chosen': -394.3709716796875, 'referece_logps/rejected': -259.0379943847656, 'referece_logps/chosen': -391.74432373046875, 'logits/rejected': -0.24595509469509125, 'logits/chosen': -0.21362079679965973, 'epoch': 5.01}


 84%|████████▎ | 13448/16104 [62:04:30<13:09:53, 17.84s/it]

 84%|████████▎ | 13449/16104 [62:04:52<14:05:35, 19.11s/it]

 84%|████████▎ | 13450/16104 [62:05:11<14:13:23, 19.29s/it]
{'loss': 0.4449, 'learning_rate': 1.391146728639887e-07, 'rewards/chosen': -0.7094400525093079, 'rewards/rejected': -2.5902252197265625, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8807848691940308, 'policy_logps/rejected': -354.3976135253906, 'policy_logps/chosen': -471.85113525390625, 'referece_logps/rejected': -328.495361328125, 'referece_logps/chosen': -464.7567138671875, 'logits/rejected': -0.4731976389884949, 'logits/chosen': -0.5911204814910889, 'epoch': 5.01}

 84%|████████▎ | 13451/16104 [62:05:25<12:50:17, 17.42s/it]

 84%|████████▎ | 13452/16104 [62:05:43<13:01:05, 17.67s/it]

 84%|████████▎ | 13453/16104 [62:06:02<13:27:35, 18.28s/it]


 84%|████████▎ | 13455/16104 [62:06:36<13:08:03, 17.85s/it]
{'loss': 0.2862, 'learning_rate': 1.3860344394703983e-07, 'rewards/chosen': 0.39012888073921204, 'rewards/rejected': -2.491424322128296, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8815531730651855, 'policy_logps/rejected': -322.380615234375, 'policy_logps/chosen': -389.64404296875, 'referece_logps/rejected': -297.46636962890625, 'referece_logps/chosen': -393.5453186035156, 'logits/rejected': 0.4743903875350952, 'logits/chosen': 0.5346722602844238, 'epoch': 5.01}


 84%|████████▎ | 13457/16104 [62:07:11<13:07:21, 17.85s/it]

 84%|████████▎ | 13458/16104 [62:07:32<13:42:51, 18.66s/it]

 84%|████████▎ | 13459/16104 [62:07:44<12:13:57, 16.65s/it]
{'loss': 0.3913, 'learning_rate': 1.381950879991447e-07, 'rewards/chosen': -0.3712896406650543, 'rewards/rejected': -2.0048065185546875, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6335166692733765, 'policy_logps/rejected': -544.84130859375, 'policy_logps/chosen': -462.2056884765625, 'referece_logps/rejected': -524.7933349609375, 'referece_logps/chosen': -458.49273681640625, 'logits/rejected': -0.10313929617404938, 'logits/chosen': -0.18170058727264404, 'epoch': 5.01}


 84%|████████▎ | 13461/16104 [62:08:08<10:24:08, 14.17s/it]
{'loss': 0.4443, 'learning_rate': 1.3799111917796135e-07, 'rewards/chosen': 0.11837156862020493, 'rewards/rejected': -1.4592411518096924, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5776127576828003, 'policy_logps/rejected': -581.3837890625, 'policy_logps/chosen': -435.1436767578125, 'referece_logps/rejected': -566.7913818359375, 'referece_logps/chosen': -436.3274230957031, 'logits/rejected': 0.24400129914283752, 'logits/chosen': 0.4208202660083771, 'epoch': 5.02}

 84%|████████▎ | 13462/16104 [62:08:25<11:07:05, 15.15s/it]

 84%|████████▎ | 13463/16104 [62:08:45<12:05:30, 16.48s/it]

 84%|████████▎ | 13464/16104 [62:08:59<11:32:52, 15.75s/it]

 84%|████████▎ | 13465/16104 [62:09:20<12:49:54, 17.50s/it]

 84%|████████▎ | 13466/16104 [62:09:42<13:51:27, 18.91s/it]


 84%|████████▎ | 13468/16104 [62:10:13<12:37:03, 17.23s/it]

 84%|████████▎ | 13469/16104 [62:10:26<11:38:35, 15.91s/it]
{'loss': 0.4396, 'learning_rate': 1.3717663901481058e-07, 'rewards/chosen': -0.021516814827919006, 'rewards/rejected': -0.5723732113838196, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5508564114570618, 'policy_logps/rejected': -596.769287109375, 'policy_logps/chosen': -606.9763793945312, 'referece_logps/rejected': -591.0454711914062, 'referece_logps/chosen': -606.76123046875, 'logits/rejected': 0.564458429813385, 'logits/chosen': 0.5389666557312012, 'epoch': 5.02}


 84%|████████▎ | 13471/16104 [62:10:48<9:51:51, 13.49s/it]

 84%|████████▎ | 13472/16104 [62:11:00<9:27:48, 12.94s/it]

 84%|████████▎ | 13473/16104 [62:11:19<10:54:17, 14.92s/it]
{'loss': 0.4403, 'learning_rate': 1.3677023646736584e-07, 'rewards/chosen': -0.13129942119121552, 'rewards/rejected': -2.0902798175811768, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9589804410934448, 'policy_logps/rejected': -336.82781982421875, 'policy_logps/chosen': -449.2807922363281, 'referece_logps/rejected': -315.925048828125, 'referece_logps/chosen': -447.9677734375, 'logits/rejected': 0.3351091742515564, 'logits/chosen': 0.3635370433330536, 'epoch': 5.02}


 84%|████████▎ | 13475/16104 [62:11:49<10:59:40, 15.06s/it]
{'loss': 0.4207, 'learning_rate': 1.365672446923136e-07, 'rewards/chosen': -0.8481534719467163, 'rewards/rejected': -2.652324676513672, 'rewards/accuracies': 0.875, 'rewards/margins': 1.804171085357666, 'policy_logps/rejected': -534.6736450195312, 'policy_logps/chosen': -455.31976318359375, 'referece_logps/rejected': -508.150390625, 'referece_logps/chosen': -446.83819580078125, 'logits/rejected': -0.18495580554008484, 'logits/chosen': -0.036233313381671906, 'epoch': 5.02}


 84%|████████▎ | 13477/16104 [62:12:26<12:10:44, 16.69s/it]

 84%|████████▎ | 13478/16104 [62:12:44<12:25:19, 17.03s/it]

 84%|████████▎ | 13479/16104 [62:13:04<12:58:52, 17.80s/it]

 84%|████████▎ | 13480/16104 [62:13:19<12:30:34, 17.16s/it]

 84%|████████▎ | 13481/16104 [62:13:36<12:29:08, 17.14s/it]

 84%|████████▎ | 13482/16104 [62:13:50<11:39:39, 16.01s/it]

 84%|████████▎ | 13483/16104 [62:14:06<11:47:27, 16.20s/it]

 84%|████████▎ | 13484/16104 [62:14:22<11:38:15, 15.99s/it]
{'loss': 0.4382, 'learning_rate': 1.3565551108432672e-07, 'rewards/chosen': -0.41791269183158875, 'rewards/rejected': -2.3902556896209717, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9723429679870605, 'policy_logps/rejected': -305.57269287109375, 'policy_logps/chosen': -334.33673095703125, 'referece_logps/rejected': -281.6701354980469, 'referece_logps/chosen': -330.1576232910156, 'logits/rejected': -0.653771162033081, 'logits/chosen': -0.5952488780021667, 'epoch': 5.02}


 84%|████████▎ | 13486/16104 [62:14:48<10:35:11, 14.56s/it]

 84%|████████▎ | 13487/16104 [62:14:58<9:45:54, 13.43s/it]
{'loss': 0.3481, 'learning_rate': 1.35352229091223e-07, 'rewards/chosen': 0.07598990947008133, 'rewards/rejected': -1.825559377670288, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9015491008758545, 'policy_logps/rejected': -743.8983154296875, 'policy_logps/chosen': -696.5260009765625, 'referece_logps/rejected': -725.6427001953125, 'referece_logps/chosen': -697.285888671875, 'logits/rejected': 0.2895992398262024, 'logits/chosen': 0.365631103515625, 'epoch': 5.02}


 84%|████████▍ | 13489/16104 [62:15:28<10:39:17, 14.67s/it]

 84%|████████▍ | 13490/16104 [62:15:42<10:23:45, 14.32s/it]
{'loss': 0.3609, 'learning_rate': 1.3504926188701804e-07, 'rewards/chosen': -0.0955137312412262, 'rewards/rejected': -2.135608434677124, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0400946140289307, 'policy_logps/rejected': -315.8293762207031, 'policy_logps/chosen': -445.05743408203125, 'referece_logps/rejected': -294.47332763671875, 'referece_logps/chosen': -444.10235595703125, 'logits/rejected': -0.3323849141597748, 'logits/chosen': -0.3693675994873047, 'epoch': 5.03}


 84%|████████▍ | 13492/16104 [62:16:21<12:14:46, 16.88s/it]

 84%|████████▍ | 13493/16104 [62:16:40<12:53:11, 17.77s/it]
{'loss': 0.2969, 'learning_rate': 1.3474660958201256e-07, 'rewards/chosen': -0.35332363843917847, 'rewards/rejected': -3.199852466583252, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8465287685394287, 'policy_logps/rejected': -483.28765869140625, 'policy_logps/chosen': -374.9869079589844, 'referece_logps/rejected': -451.2891845703125, 'referece_logps/chosen': -371.45367431640625, 'logits/rejected': -0.1554756760597229, 'logits/chosen': -0.15960873663425446, 'epoch': 5.03}

 84%|████████▍ | 13494/16104 [62:17:02<13:37:51, 18.80s/it]


 84%|████████▍ | 13496/16104 [62:17:36<13:16:05, 18.31s/it]
{'loss': 0.3344, 'learning_rate': 1.3444427228639154e-07, 'rewards/chosen': -0.5248374938964844, 'rewards/rejected': -2.175182342529297, 'rewards/accuracies': 0.75, 'rewards/margins': 1.650344729423523, 'policy_logps/rejected': -336.54779052734375, 'policy_logps/chosen': -325.8459777832031, 'referece_logps/rejected': -314.7959899902344, 'referece_logps/chosen': -320.59759521484375, 'logits/rejected': -0.48351243138313293, 'logits/chosen': -0.4977327585220337, 'epoch': 5.03}


 84%|████████▍ | 13498/16104 [62:18:13<13:17:28, 18.36s/it]
{'loss': 0.2816, 'learning_rate': 1.3424288914888514e-07, 'rewards/chosen': -0.9628594517707825, 'rewards/rejected': -2.367405652999878, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4045460224151611, 'policy_logps/rejected': -409.19122314453125, 'policy_logps/chosen': -348.34478759765625, 'referece_logps/rejected': -385.5171813964844, 'referece_logps/chosen': -338.71624755859375, 'logits/rejected': -0.2789376378059387, 'logits/chosen': -0.23754720389842987, 'epoch': 5.03}


 84%|████████▍ | 13500/16104 [62:18:48<13:07:57, 18.16s/it]

 84%|████████▍ | 13501/16104 [62:19:24<17:05:43, 23.64s/it]
{'loss': 0.3487, 'learning_rate': 1.3394107711345015e-07, 'rewards/chosen': -0.8280377984046936, 'rewards/rejected': -2.6007182598114014, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7726805210113525, 'policy_logps/rejected': -242.15872192382812, 'policy_logps/chosen': -383.2529296875, 'referece_logps/rejected': -216.1515350341797, 'referece_logps/chosen': -374.97259521484375, 'logits/rejected': -0.2971786856651306, 'logits/chosen': -0.1944192349910736, 'epoch': 5.03}

 84%|████████▍ | 13502/16104 [62:19:38<14:51:22, 20.55s/it]

 84%|████████▍ | 13503/16104 [62:19:53<13:49:24, 19.13s/it]


 84%|████████▍ | 13505/16104 [62:20:25<12:31:12, 17.34s/it]

 84%|████████▍ | 13506/16104 [62:20:36<11:17:14, 15.64s/it]
{'loss': 0.4657, 'learning_rate': 1.3343875778116044e-07, 'rewards/chosen': -0.577414333820343, 'rewards/rejected': -2.201181411743164, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6237668991088867, 'policy_logps/rejected': -464.7369384765625, 'policy_logps/chosen': -298.473876953125, 'referece_logps/rejected': -442.72509765625, 'referece_logps/chosen': -292.6997375488281, 'logits/rejected': -0.7680156826972961, 'logits/chosen': -0.4248266816139221, 'epoch': 5.03}

 84%|████████▍ | 13507/16104 [62:20:49<10:43:14, 14.86s/it]


 84%|████████▍ | 13509/16104 [62:21:21<11:14:00, 15.58s/it]
{'loss': 0.4297, 'learning_rate': 1.3313778679666133e-07, 'rewards/chosen': 0.5462106466293335, 'rewards/rejected': -0.502249002456665, 'rewards/accuracies': 0.75, 'rewards/margins': 1.048459768295288, 'policy_logps/rejected': -397.196533203125, 'policy_logps/chosen': -505.0684509277344, 'referece_logps/rejected': -392.174072265625, 'referece_logps/chosen': -510.530517578125, 'logits/rejected': 0.8278420567512512, 'logits/chosen': 0.8935356736183167, 'epoch': 5.03}

 84%|████████▍ | 13510/16104 [62:21:42<12:26:06, 17.26s/it]

 84%|████████▍ | 13511/16104 [62:22:02<13:02:24, 18.10s/it]

 84%|████████▍ | 13512/16104 [62:22:20<13:04:11, 18.15s/it]

 84%|████████▍ | 13513/16104 [62:22:39<13:15:23, 18.42s/it]

 84%|████████▍ | 13514/16104 [62:22:59<13:35:36, 18.89s/it]

 84%|████████▍ | 13515/16104 [62:23:17<13:14:37, 18.42s/it]

 84%|████████▍ | 13516/16104 [62:23:36<13:34:00, 18.87s/it]


 84%|████████▍ | 13518/16104 [62:24:01<11:13:43, 15.63s/it]
{'loss': 0.3894, 'learning_rate': 1.322367678514974e-07, 'rewards/chosen': -0.2899588942527771, 'rewards/rejected': -1.634059190750122, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3441001176834106, 'policy_logps/rejected': -335.5523681640625, 'policy_logps/chosen': -466.48675537109375, 'referece_logps/rejected': -319.2117919921875, 'referece_logps/chosen': -463.587158203125, 'logits/rejected': -0.042374685406684875, 'logits/chosen': -0.10215827822685242, 'epoch': 5.04}

 84%|████████▍ | 13519/16104 [62:24:12<10:13:36, 14.24s/it]

 84%|████████▍ | 13520/16104 [62:24:28<10:35:24, 14.75s/it]

 84%|████████▍ | 13521/16104 [62:24:46<11:17:47, 15.74s/it]

 84%|████████▍ | 13522/16104 [62:24:58<10:34:40, 14.75s/it]

 84%|████████▍ | 13523/16104 [62:25:18<11:33:02, 16.11s/it]


 84%|████████▍ | 13525/16104 [62:25:53<11:46:25, 16.43s/it]
{'loss': 0.4016, 'learning_rate': 1.315379409311924e-07, 'rewards/chosen': -1.128846526145935, 'rewards/rejected': -2.1899030208587646, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0610564947128296, 'policy_logps/rejected': -449.6519470214844, 'policy_logps/chosen': -413.7548522949219, 'referece_logps/rejected': -427.75286865234375, 'referece_logps/chosen': -402.4663391113281, 'logits/rejected': -0.18619213998317719, 'logits/chosen': 0.003388185054063797, 'epoch': 5.04}

 84%|████████▍ | 13526/16104 [62:26:10<11:59:06, 16.74s/it]

 84%|████████▍ | 13527/16104 [62:26:28<12:16:29, 17.15s/it]

 84%|████████▍ | 13528/16104 [62:26:46<12:28:26, 17.43s/it]

 84%|████████▍ | 13529/16104 [62:27:06<12:59:02, 18.15s/it]

 84%|████████▍ | 13530/16104 [62:27:28<13:39:52, 19.11s/it]

 84%|████████▍ | 13531/16104 [62:27:46<13:35:29, 19.02s/it]

 84%|████████▍ | 13532/16104 [62:28:06<13:41:19, 19.16s/it]

 84%|████████▍ | 13533/16104 [62:28:17<11:53:18, 16.65s/it]

 84%|████████▍ | 13534/16104 [62:28:29<10:52:14, 15.23s/it]

 84%|████████▍ | 13535/16104 [62:28:40<10:03:37, 14.10s/it]

 84%|████████▍ | 13536/16104 [62:28:56<10:25:28, 14.61s/it]


 84%|████████▍ | 13538/16104 [62:29:35<12:16:06, 17.21s/it]
{'loss': 0.4039, 'learning_rate': 1.302446875637263e-07, 'rewards/chosen': -0.7978919744491577, 'rewards/rejected': -2.8114757537841797, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0135834217071533, 'policy_logps/rejected': -509.2486572265625, 'policy_logps/chosen': -355.0560302734375, 'referece_logps/rejected': -481.1339111328125, 'referece_logps/chosen': -347.0771484375, 'logits/rejected': 0.24132433533668518, 'logits/chosen': 0.21363967657089233, 'epoch': 5.04}

 84%|████████▍ | 13539/16104 [62:29:54<12:34:24, 17.65s/it]


 84%|████████▍ | 13541/16104 [62:30:27<12:07:18, 17.03s/it]
{'loss': 0.3206, 'learning_rate': 1.299470885530456e-07, 'rewards/chosen': -0.545937716960907, 'rewards/rejected': -2.5373752117156982, 'rewards/accuracies': 1.0, 'rewards/margins': 1.991437554359436, 'policy_logps/rejected': -290.54254150390625, 'policy_logps/chosen': -335.5841979980469, 'referece_logps/rejected': -265.1687927246094, 'referece_logps/chosen': -330.12481689453125, 'logits/rejected': -0.3082185387611389, 'logits/chosen': -0.34790849685668945, 'epoch': 5.05}

 84%|████████▍ | 13542/16104 [62:30:46<12:25:42, 17.46s/it]

 84%|████████▍ | 13543/16104 [62:30:58<11:14:50, 15.81s/it]

 84%|████████▍ | 13544/16104 [62:31:11<10:36:30, 14.92s/it]

 84%|████████▍ | 13545/16104 [62:31:31<11:43:43, 16.50s/it]

 84%|████████▍ | 13546/16104 [62:31:51<12:27:20, 17.53s/it]

 84%|████████▍ | 13547/16104 [62:32:08<12:24:48, 17.48s/it]


 84%|████████▍ | 13549/16104 [62:32:43<12:43:02, 17.92s/it]

 84%|████████▍ | 13550/16104 [62:33:03<13:08:56, 18.53s/it]

 84%|████████▍ | 13551/16104 [62:33:24<13:31:07, 19.06s/it]

 84%|████████▍ | 13552/16104 [62:33:44<13:42:30, 19.34s/it]
{'loss': 0.3767, 'learning_rate': 1.288586030330474e-07, 'rewards/chosen': -1.9116086959838867, 'rewards/rejected': -3.6253859996795654, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7137770652770996, 'policy_logps/rejected': -550.5132446289062, 'policy_logps/chosen': -498.7622985839844, 'referece_logps/rejected': -514.2593994140625, 'referece_logps/chosen': -479.6462097167969, 'logits/rejected': -0.8166178464889526, 'logits/chosen': -0.648157000541687, 'epoch': 5.05}

 84%|████████▍ | 13553/16104 [62:33:55<11:56:46, 16.86s/it]

 84%|████████▍ | 13554/16104 [62:34:14<12:30:36, 17.66s/it]

 84%|████████▍ | 13555/16104 [62:34:30<12:12:53, 17.25s/it]

 84%|████████▍ | 13556/16104 [62:34:45<11:41:10, 16.51s/it]

 84%|████████▍ | 13557/16104 [62:35:01<11:27:57, 16.21s/it]

 84%|████████▍ | 13558/16104 [62:35:21<12:19:18, 17.42s/it]

 84%|████████▍ | 13559/16104 [62:35:41<12:51:24, 18.19s/it]


 84%|████████▍ | 13561/16104 [62:36:14<12:08:55, 17.20s/it]
{'loss': 0.4398, 'learning_rate': 1.2797119526060506e-07, 'rewards/chosen': -0.4912443459033966, 'rewards/rejected': -2.7825024127960205, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2912583351135254, 'policy_logps/rejected': -335.87945556640625, 'policy_logps/chosen': -388.6689453125, 'referece_logps/rejected': -308.05438232421875, 'referece_logps/chosen': -383.7564697265625, 'logits/rejected': -0.18936115503311157, 'logits/chosen': 0.07562476396560669, 'epoch': 5.05}


 84%|████████▍ | 13563/16104 [62:36:37<10:18:26, 14.60s/it]
{'loss': 0.4168, 'learning_rate': 1.2777438145743458e-07, 'rewards/chosen': 0.12002374231815338, 'rewards/rejected': -1.6176691055297852, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7376928329467773, 'policy_logps/rejected': -426.03167724609375, 'policy_logps/chosen': -394.4133605957031, 'referece_logps/rejected': -409.8549499511719, 'referece_logps/chosen': -395.61358642578125, 'logits/rejected': 0.3121560513973236, 'logits/chosen': 0.2694823443889618, 'epoch': 5.05}

 84%|████████▍ | 13564/16104 [62:36:56<11:12:52, 15.89s/it]


 84%|████████▍ | 13566/16104 [62:37:30<11:43:32, 16.63s/it]
{'loss': 0.3525, 'learning_rate': 1.2747942538574252e-07, 'rewards/chosen': -1.1582955121994019, 'rewards/rejected': -2.114943027496338, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9566475749015808, 'policy_logps/rejected': -442.58770751953125, 'policy_logps/chosen': -431.1658935546875, 'referece_logps/rejected': -421.438232421875, 'referece_logps/chosen': -419.5829162597656, 'logits/rejected': -0.47592270374298096, 'logits/chosen': -0.5030024647712708, 'epoch': 5.05}

 84%|████████▍ | 13567/16104 [62:37:45<11:17:39, 16.03s/it]

 84%|████████▍ | 13568/16104 [62:37:57<10:38:03, 15.10s/it]


 84%|████████▍ | 13570/16104 [62:38:36<12:08:23, 17.25s/it]
{'loss': 0.2946, 'learning_rate': 1.2708664477221565e-07, 'rewards/chosen': -0.35315704345703125, 'rewards/rejected': -3.0278031826019287, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6746463775634766, 'policy_logps/rejected': -266.572265625, 'policy_logps/chosen': -395.19482421875, 'referece_logps/rejected': -236.29421997070312, 'referece_logps/chosen': -391.6632080078125, 'logits/rejected': 0.3172585964202881, 'logits/chosen': 0.25714895129203796, 'epoch': 5.06}

 84%|████████▍ | 13571/16104 [62:38:55<12:31:00, 17.79s/it]

 84%|████████▍ | 13572/16104 [62:39:07<11:16:37, 16.03s/it]

 84%|████████▍ | 13573/16104 [62:39:25<11:45:54, 16.73s/it]

 84%|████████▍ | 13574/16104 [62:39:43<12:03:00, 17.15s/it]

 84%|████████▍ | 13575/16104 [62:40:00<12:00:33, 17.09s/it]

 84%|████████▍ | 13576/16104 [62:40:11<10:44:33, 15.30s/it]


 84%|████████▍ | 13578/16104 [62:40:40<10:10:38, 14.50s/it]
{'loss': 0.334, 'learning_rate': 1.2630277872227024e-07, 'rewards/chosen': -0.4782913327217102, 'rewards/rejected': -2.787747621536255, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3094563484191895, 'policy_logps/rejected': -590.8961791992188, 'policy_logps/chosen': -524.0661010742188, 'referece_logps/rejected': -563.0186767578125, 'referece_logps/chosen': -519.283203125, 'logits/rejected': -0.4557950794696808, 'logits/chosen': -0.4955368936061859, 'epoch': 5.06}


 84%|████████▍ | 13580/16104 [62:41:06<9:44:03, 13.88s/it]
{'loss': 0.4389, 'learning_rate': 1.2610716555668254e-07, 'rewards/chosen': -0.36085817217826843, 'rewards/rejected': -1.4926501512527466, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1317919492721558, 'policy_logps/rejected': -560.0921630859375, 'policy_logps/chosen': -448.0599060058594, 'referece_logps/rejected': -545.1657104492188, 'referece_logps/chosen': -444.45135498046875, 'logits/rejected': 1.103001356124878, 'logits/chosen': 1.089836597442627, 'epoch': 5.06}

 84%|████████▍ | 13581/16104 [62:41:19<9:28:11, 13.51s/it]

 84%|████████▍ | 13582/16104 [62:41:36<10:11:26, 14.55s/it]


 84%|████████▍ | 13584/16104 [62:42:06<10:29:04, 14.98s/it]
{'loss': 0.44, 'learning_rate': 1.2571636346342695e-07, 'rewards/chosen': -1.2839230298995972, 'rewards/rejected': -1.7036867141723633, 'rewards/accuracies': 0.75, 'rewards/margins': 0.41976362466812134, 'policy_logps/rejected': -418.8525695800781, 'policy_logps/chosen': -359.9383239746094, 'referece_logps/rejected': -401.815673828125, 'referece_logps/chosen': -347.0990905761719, 'logits/rejected': -0.6082399487495422, 'logits/chosen': -0.5461567044258118, 'epoch': 5.06}

 84%|████████▍ | 13585/16104 [62:42:27<11:47:09, 16.84s/it]

 84%|████████▍ | 13586/16104 [62:42:46<12:06:42, 17.32s/it]

 84%|████████▍ | 13587/16104 [62:42:59<11:15:55, 16.11s/it]

 84%|████████▍ | 13588/16104 [62:43:19<12:04:29, 17.28s/it]

 84%|████████▍ | 13589/16104 [62:43:37<12:07:06, 17.35s/it]

 84%|████████▍ | 13590/16104 [62:43:47<10:43:21, 15.35s/it]

 84%|████████▍ | 13591/16104 [62:43:58<9:44:02, 13.94s/it]


 84%|████████▍ | 13593/16104 [62:44:28<9:54:29, 14.21s/it]
{'loss': 0.4813, 'learning_rate': 1.2483912806873486e-07, 'rewards/chosen': -0.34975510835647583, 'rewards/rejected': -1.1886553764343262, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8389002084732056, 'policy_logps/rejected': -338.23590087890625, 'policy_logps/chosen': -386.06597900390625, 'referece_logps/rejected': -326.3493347167969, 'referece_logps/chosen': -382.5684509277344, 'logits/rejected': 0.4199819266796112, 'logits/chosen': 0.45673269033432007, 'epoch': 5.06}

 84%|████████▍ | 13594/16104 [62:44:41<9:43:26, 13.95s/it]

 84%|████████▍ | 13595/16104 [62:44:59<10:26:38, 14.99s/it]

 84%|████████▍ | 13596/16104 [62:45:19<11:32:25, 16.57s/it]

 84%|████████▍ | 13597/16104 [62:45:30<10:18:58, 14.81s/it]


 84%|████████▍ | 13599/16104 [62:46:00<10:45:32, 15.46s/it]
{'loss': 0.3628, 'learning_rate': 1.242558973766562e-07, 'rewards/chosen': -0.48319053649902344, 'rewards/rejected': -2.5069806575775146, 'rewards/accuracies': 1.0, 'rewards/margins': 2.023789882659912, 'policy_logps/rejected': -524.6878662109375, 'policy_logps/chosen': -568.3414306640625, 'referece_logps/rejected': -499.6180419921875, 'referece_logps/chosen': -563.5094604492188, 'logits/rejected': -0.16544757783412933, 'logits/chosen': -0.1250619888305664, 'epoch': 5.07}

 84%|████████▍ | 13600/16104 [62:46:19<11:23:34, 16.38s/it]


 84%|████████▍ | 13602/16104 [62:46:52<11:29:43, 16.54s/it]
{'loss': 0.3833, 'learning_rate': 1.2396476022060742e-07, 'rewards/chosen': 0.06304110586643219, 'rewards/rejected': -1.880577802658081, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9436190128326416, 'policy_logps/rejected': -548.1492919921875, 'policy_logps/chosen': -408.9351806640625, 'referece_logps/rejected': -529.3435668945312, 'referece_logps/chosen': -409.56561279296875, 'logits/rejected': 0.6722862720489502, 'logits/chosen': 0.7877035140991211, 'epoch': 5.07}

 84%|████████▍ | 13603/16104 [62:47:03<10:16:45, 14.80s/it]

 84%|████████▍ | 13604/16104 [62:47:23<11:21:57, 16.37s/it]

 84%|████████▍ | 13605/16104 [62:47:41<11:38:19, 16.77s/it]

 84%|████████▍ | 13606/16104 [62:48:01<12:22:46, 17.84s/it]

 84%|████████▍ | 13607/16104 [62:48:18<12:11:09, 17.57s/it]

 85%|████████▍ | 13608/16104 [62:48:31<11:18:00, 16.30s/it]


 85%|████████▍ | 13610/16104 [62:48:53<9:17:40, 13.42s/it]
{'loss': 0.4707, 'learning_rate': 1.231899539949206e-07, 'rewards/chosen': -0.2032659649848938, 'rewards/rejected': -1.6395912170410156, 'rewards/accuracies': 1.0, 'rewards/margins': 1.436325192451477, 'policy_logps/rejected': -375.7242126464844, 'policy_logps/chosen': -534.8240356445312, 'referece_logps/rejected': -359.3282775878906, 'referece_logps/chosen': -532.7913818359375, 'logits/rejected': -0.03738287091255188, 'logits/chosen': -0.024048741906881332, 'epoch': 5.07}

 85%|████████▍ | 13611/16104 [62:49:11<10:20:46, 14.94s/it]

 85%|████████▍ | 13612/16104 [62:49:22<9:27:20, 13.66s/it]

 85%|████████▍ | 13613/16104 [62:49:41<10:40:57, 15.44s/it]

 85%|████████▍ | 13614/16104 [62:50:01<11:33:20, 16.71s/it]

 85%|████████▍ | 13615/16104 [62:50:12<10:21:03, 14.97s/it]

 85%|████████▍ | 13616/16104 [62:50:28<10:37:30, 15.37s/it]

 85%|████████▍ | 13617/16104 [62:50:50<11:59:55, 17.37s/it]

 85%|████████▍ | 13618/16104 [62:51:01<10:37:07, 15.38s/it]

 85%|████████▍ | 13619/16104 [62:51:21<11:37:06, 16.83s/it]

 85%|████████▍ | 13620/16104 [62:51:34<10:51:38, 15.74s/it]

 85%|████████▍ | 13621/16104 [62:51:53<11:24:48, 16.55s/it]

 85%|████████▍ | 13622/16104 [62:52:06<10:43:26, 15.55s/it]

 85%|████████▍ | 13623/16104 [62:52:26<11:33:35, 16.77s/it]

 85%|████████▍ | 13624/16104 [62:52:45<12:09:26, 17.65s/it]

 85%|████████▍ | 13625/16104 [62:52:56<10:42:52, 15.56s/it]

 85%|████████▍ | 13626/16104 [62:53:14<11:10:42, 16.24s/it]

 85%|████████▍ | 13627/16104 [62:53:28<10:43:16, 15.58s/it]

 85%|████████▍ | 13628/16104 [62:53:48<11:35:17, 16.85s/it]

 85%|████████▍ | 13629/16104 [62:54:02<10:58:21, 15.96s/it]

 85%|████████▍ | 13630/16104 [62:54:20<11:29:22, 16.72s/it]

 85%|████████▍ | 13631/16104 [62:54:40<12:11:56, 17.76s/it]

 85%|████████▍ | 13632/16104 [62:55:00<12:32:12, 18.26s/it]

 85%|████████▍ | 13633/16104 [62:55:18<12:31:18, 18.24s/it]

 85%|████████▍ | 13634/16104 [62:55:38<12:49:36, 18.70s/it]

 85%|████████▍ | 13635/16104 [62:55:52<11:49:23, 17.24s/it]

 85%|████████▍ | 13636/16104 [62:56:11<12:20:31, 18.00s/it]

 85%|████████▍ | 13637/16104 [62:56:29<12:19:16, 17.98s/it]

 85%|████████▍ | 13638/16104 [62:56:42<11:16:11, 16.45s/it]

 85%|████████▍ | 13639/16104 [62:56:53<10:03:50, 14.70s/it]

 85%|████████▍ | 13640/16104 [62:57:07<10:02:48, 14.68s/it]

 85%|████████▍ | 13641/16104 [62:57:25<10:41:13, 15.62s/it]

 85%|████████▍ | 13642/16104 [62:57:43<11:03:29, 16.17s/it]

 85%|████████▍ | 13643/16104 [62:58:01<11:34:28, 16.93s/it]

 85%|████████▍ | 13644/16104 [62:58:21<12:05:24, 17.69s/it]

 85%|████████▍ | 13645/16104 [62:58:34<11:08:15, 16.31s/it]

 85%|████████▍ | 13646/16104 [62:58:50<11:08:07, 16.31s/it]

 85%|████████▍ | 13647/16104 [62:59:08<11:23:18, 16.69s/it]

 85%|████████▍ | 13648/16104 [62:59:27<11:50:27, 17.36s/it]

 85%|████████▍ | 13649/16104 [62:59:49<12:45:20, 18.71s/it]

 85%|████████▍ | 13650/16104 [63:00:08<12:50:20, 18.83s/it]

 85%|████████▍ | 13651/16104 [63:00:28<13:13:22, 19.41s/it]

 85%|████████▍ | 13652/16104 [63:00:44<12:23:16, 18.19s/it]

 85%|████████▍ | 13653/16104 [63:01:04<12:42:09, 18.66s/it]

 85%|████████▍ | 13654/16104 [63:01:19<12:06:29, 17.79s/it]

 85%|████████▍ | 13655/16104 [63:01:31<10:55:06, 16.05s/it]

 85%|████████▍ | 13656/16104 [63:01:50<11:20:56, 16.69s/it]

 85%|████████▍ | 13657/16104 [63:02:08<11:42:24, 17.22s/it]

 85%|████████▍ | 13658/16104 [63:02:21<10:50:57, 15.97s/it]

 85%|████████▍ | 13659/16104 [63:02:41<11:35:40, 17.07s/it]

 85%|████████▍ | 13660/16104 [63:03:01<12:16:14, 18.07s/it]

 85%|████████▍ | 13661/16104 [63:03:21<12:42:23, 18.72s/it]

 85%|████████▍ | 13662/16104 [63:03:42<13:10:10, 19.41s/it]

 85%|████████▍ | 13663/16104 [63:04:03<13:23:15, 19.74s/it]

 85%|████████▍ | 13664/16104 [63:04:21<13:06:19, 19.34s/it]

 85%|████████▍ | 13665/16104 [63:04:35<12:03:35, 17.80s/it]

 85%|████████▍ | 13666/16104 [63:04:55<12:27:46, 18.40s/it]

 85%|████████▍ | 13667/16104 [63:05:06<10:52:08, 16.06s/it]

 85%|████████▍ | 13668/16104 [63:05:27<11:54:31, 17.60s/it]

 85%|████████▍ | 13669/16104 [63:05:44<11:49:16, 17.48s/it]


 85%|████████▍ | 13671/16104 [63:06:07<9:42:35, 14.37s/it]

 85%|████████▍ | 13672/16104 [63:06:21<9:34:55, 14.18s/it]

 85%|████████▍ | 13673/16104 [63:06:33<9:13:29, 13.66s/it]

 85%|████████▍ | 13674/16104 [63:06:53<10:26:19, 15.46s/it]

 85%|████████▍ | 13675/16104 [63:07:08<10:29:50, 15.56s/it]

 85%|████████▍ | 13676/16104 [63:07:22<10:00:05, 14.83s/it]

 85%|████████▍ | 13677/16104 [63:07:44<11:28:34, 17.02s/it]

 85%|████████▍ | 13678/16104 [63:07:56<10:34:19, 15.69s/it]

 85%|████████▍ | 13679/16104 [63:08:14<10:53:29, 16.17s/it]

 85%|████████▍ | 13680/16104 [63:08:28<10:33:15, 15.67s/it]

 85%|████████▍ | 13681/16104 [63:08:40<9:50:11, 14.61s/it]

 85%|████████▍ | 13682/16104 [63:09:00<10:48:13, 16.06s/it]

 85%|████████▍ | 13683/16104 [63:09:15<10:39:50, 15.86s/it]

 85%|████████▍ | 13684/16104 [63:09:36<11:45:08, 17.48s/it]

 85%|████████▍ | 13685/16104 [63:09:50<11:01:45, 16.41s/it]

 85%|████████▍ | 13686/16104 [63:10:10<11:36:40, 17.29s/it]

 85%|████████▍ | 13687/16104 [63:10:22<10:36:24, 15.80s/it]

 85%|████████▍ | 13688/16104 [63:10:42<11:22:10, 16.94s/it]

 85%|████████▌ | 13689/16104 [63:10:55<10:39:55, 15.90s/it]

 85%|████████▌ | 13690/16104 [63:11:10<10:24:19, 15.52s/it]

 85%|████████▌ | 13691/16104 [63:11:29<11:12:41, 16.73s/it]

 85%|████████▌ | 13692/16104 [63:11:47<11:28:34, 17.13s/it]

 85%|████████▌ | 13693/16104 [63:12:04<11:21:45, 16.97s/it]

 85%|████████▌ | 13694/16104 [63:12:17<10:41:28, 15.97s/it]

 85%|████████▌ | 13695/16104 [63:12:30<9:58:08, 14.90s/it]

 85%|████████▌ | 13696/16104 [63:12:50<11:04:51, 16.57s/it]

 85%|████████▌ | 13697/16104 [63:13:08<11:23:34, 17.04s/it]

 85%|████████▌ | 13698/16104 [63:13:28<11:51:47, 17.75s/it]

 85%|████████▌ | 13699/16104 [63:13:48<12:15:28, 18.35s/it]

 85%|████████▌ | 13700/16104 [63:14:04<11:56:06, 17.87s/it]

 85%|████████▌ | 13701/16104 [63:14:16<10:43:33, 16.07s/it]

 85%|████████▌ | 13702/16104 [63:14:37<11:38:17, 17.44s/it]

 85%|████████▌ | 13703/16104 [63:14:47<10:15:36, 15.38s/it]

 85%|████████▌ | 13704/16104 [63:15:02<10:05:34, 15.14s/it]

 85%|████████▌ | 13705/16104 [63:15:22<10:58:59, 16.48s/it]

 85%|████████▌ | 13706/16104 [63:15:41<11:36:22, 17.42s/it]

 85%|████████▌ | 13707/16104 [63:15:56<11:07:11, 16.70s/it]

 85%|████████▌ | 13708/16104 [63:16:15<11:33:25, 17.36s/it]

 85%|████████▌ | 13709/16104 [63:16:34<11:53:56, 17.89s/it]

 85%|████████▌ | 13710/16104 [63:16:52<11:45:18, 17.68s/it]

 85%|████████▌ | 13711/16104 [63:17:11<12:07:29, 18.24s/it]

 85%|████████▌ | 13712/16104 [63:17:25<11:21:02, 17.08s/it]

 85%|████████▌ | 13713/16104 [63:17:38<10:24:50, 15.68s/it]

 85%|████████▌ | 13714/16104 [63:17:51<9:57:49, 15.01s/it]
{'loss': 0.5355, 'learning_rate': 1.133247638544188e-07, 'rewards/chosen': 0.109051913022995, 'rewards/rejected': -1.0395666360855103, 'rewards/accuracies': 0.875, 'rewards/margins': 1.148618459701538, 'policy_logps/rejected': -576.8944091796875, 'policy_logps/chosen': -563.9429321289062, 'referece_logps/rejected': -566.498779296875, 'referece_logps/chosen': -565.033447265625, 'logits/rejected': 0.7306089997291565, 'logits/chosen': 0.6375343203544617, 'epoch': 5.11}


 85%|████████▌ | 13716/16104 [63:18:17<9:24:06, 14.17s/it]

 85%|████████▌ | 13717/16104 [63:18:35<10:01:21, 15.12s/it]

 85%|████████▌ | 13718/16104 [63:18:51<10:18:00, 15.54s/it]

 85%|████████▌ | 13719/16104 [63:19:13<11:33:30, 17.45s/it]

 85%|████████▌ | 13720/16104 [63:19:33<12:07:41, 18.31s/it]
{'loss': 0.4118, 'learning_rate': 1.1276741361452446e-07, 'rewards/chosen': -0.24678370356559753, 'rewards/rejected': -1.5147210359573364, 'rewards/accuracies': 0.875, 'rewards/margins': 1.267937421798706, 'policy_logps/rejected': -426.48883056640625, 'policy_logps/chosen': -427.7868347167969, 'referece_logps/rejected': -411.34161376953125, 'referece_logps/chosen': -425.3189697265625, 'logits/rejected': -0.23847022652626038, 'logits/chosen': -0.17476922273635864, 'epoch': 5.11}


 85%|████████▌ | 13722/16104 [63:20:09<11:45:03, 17.76s/it]
{'loss': 0.3572, 'learning_rate': 1.1258191728229649e-07, 'rewards/chosen': -1.0058479309082031, 'rewards/rejected': -3.006396532058716, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0005483627319336, 'policy_logps/rejected': -627.1803588867188, 'policy_logps/chosen': -563.8848266601562, 'referece_logps/rejected': -597.1163940429688, 'referece_logps/chosen': -553.8263549804688, 'logits/rejected': -0.1963459849357605, 'logits/chosen': -0.1602095067501068, 'epoch': 5.11}

 85%|████████▌ | 13723/16104 [63:20:27<11:49:49, 17.89s/it]


 85%|████████▌ | 13725/16104 [63:20:59<11:01:11, 16.68s/it]

 85%|████████▌ | 13726/16104 [63:21:18<11:34:50, 17.53s/it]

 85%|████████▌ | 13727/16104 [63:21:30<10:23:45, 15.74s/it]

 85%|████████▌ | 13728/16104 [63:21:40<9:23:54, 14.24s/it]

 85%|████████▌ | 13729/16104 [63:22:02<10:46:54, 16.34s/it]
{'loss': 0.426, 'learning_rate': 1.1193381109206624e-07, 'rewards/chosen': -1.0300538539886475, 'rewards/rejected': -1.2173361778259277, 'rewards/accuracies': 0.5, 'rewards/margins': 0.18728214502334595, 'policy_logps/rejected': -352.04486083984375, 'policy_logps/chosen': -356.90673828125, 'referece_logps/rejected': -339.87152099609375, 'referece_logps/chosen': -346.606201171875, 'logits/rejected': -0.38034874200820923, 'logits/chosen': -0.3834058344364166, 'epoch': 5.12}

 85%|████████▌ | 13730/16104 [63:22:21<11:19:25, 17.17s/it]


 85%|████████▌ | 13732/16104 [63:22:48<10:00:27, 15.19s/it]

 85%|████████▌ | 13733/16104 [63:23:08<10:57:05, 16.63s/it]

 85%|████████▌ | 13734/16104 [63:23:28<11:29:36, 17.46s/it]

 85%|████████▌ | 13735/16104 [63:23:48<12:00:41, 18.25s/it]

 85%|████████▌ | 13736/16104 [63:24:06<12:03:24, 18.33s/it]

 85%|████████▌ | 13737/16104 [63:24:23<11:40:51, 17.77s/it]
{'loss': 0.4056, 'learning_rate': 1.1119527380935434e-07, 'rewards/chosen': -0.2357051968574524, 'rewards/rejected': -1.3598326444625854, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1241273880004883, 'policy_logps/rejected': -606.379150390625, 'policy_logps/chosen': -483.2694396972656, 'referece_logps/rejected': -592.7808227539062, 'referece_logps/chosen': -480.9123229980469, 'logits/rejected': -0.6206109523773193, 'logits/chosen': -0.40679872035980225, 'epoch': 5.12}

 85%|████████▌ | 13738/16104 [63:24:35<10:36:20, 16.14s/it]

 85%|████████▌ | 13739/16104 [63:24:45<9:24:18, 14.32s/it]

 85%|████████▌ | 13740/16104 [63:24:57<8:59:30, 13.69s/it]


 85%|████████▌ | 13742/16104 [63:25:38<11:17:17, 17.20s/it]

 85%|████████▌ | 13743/16104 [63:25:50<10:15:35, 15.64s/it]

 85%|████████▌ | 13744/16104 [63:26:11<11:13:02, 17.11s/it]

 85%|████████▌ | 13745/16104 [63:26:27<10:59:05, 16.76s/it]
{'loss': 0.4274, 'learning_rate': 1.1045903756533714e-07, 'rewards/chosen': -0.5254945755004883, 'rewards/rejected': -1.70268976688385, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1771950721740723, 'policy_logps/rejected': -355.8720703125, 'policy_logps/chosen': -385.2860107421875, 'referece_logps/rejected': -338.84515380859375, 'referece_logps/chosen': -380.0310363769531, 'logits/rejected': -0.7104555368423462, 'logits/chosen': -0.8166622519493103, 'epoch': 5.12}


 85%|████████▌ | 13747/16104 [63:26:59<10:41:30, 16.33s/it]

 85%|████████▌ | 13748/16104 [63:27:10<9:41:28, 14.81s/it]

 85%|████████▌ | 13749/16104 [63:27:26<9:59:42, 15.28s/it]
{'loss': 0.4483, 'learning_rate': 1.1009178292871279e-07, 'rewards/chosen': -0.42735978960990906, 'rewards/rejected': -1.2063106298446655, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7789509296417236, 'policy_logps/rejected': -375.814697265625, 'policy_logps/chosen': -419.508544921875, 'referece_logps/rejected': -363.7515869140625, 'referece_logps/chosen': -415.2349853515625, 'logits/rejected': -0.2836005687713623, 'logits/chosen': -0.2539029121398926, 'epoch': 5.12}

 85%|████████▌ | 13750/16104 [63:27:44<10:23:56, 15.90s/it]


 85%|████████▌ | 13752/16104 [63:28:17<10:24:25, 15.93s/it]

 85%|████████▌ | 13753/16104 [63:28:28<9:26:01, 14.45s/it]
{'loss': 0.5368, 'learning_rate': 1.0972510426606629e-07, 'rewards/chosen': 0.018688954412937164, 'rewards/rejected': -0.9423990249633789, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9610879421234131, 'policy_logps/rejected': -328.983642578125, 'policy_logps/chosen': -477.2798156738281, 'referece_logps/rejected': -319.5596618652344, 'referece_logps/chosen': -477.4666442871094, 'logits/rejected': 0.11135545372962952, 'logits/chosen': 0.19353650510311127, 'epoch': 5.12}


 85%|████████▌ | 13755/16104 [63:28:58<9:31:47, 14.61s/it]

 85%|████████▌ | 13756/16104 [63:29:18<10:33:50, 16.20s/it]
{'loss': 0.5349, 'learning_rate': 1.0945047339478398e-07, 'rewards/chosen': -0.7324042916297913, 'rewards/rejected': -1.6575015783309937, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9250974059104919, 'policy_logps/rejected': -295.5948486328125, 'policy_logps/chosen': -345.9869384765625, 'referece_logps/rejected': -279.0198669433594, 'referece_logps/chosen': -338.66290283203125, 'logits/rejected': -0.5944331884384155, 'logits/chosen': -0.7554260492324829, 'epoch': 5.13}

 85%|████████▌ | 13757/16104 [63:29:37<11:10:36, 17.14s/it]


 85%|████████▌ | 13759/16104 [63:30:14<11:26:05, 17.55s/it]
{'loss': 0.3084, 'learning_rate': 1.0917616674235041e-07, 'rewards/chosen': -0.4856202006340027, 'rewards/rejected': -2.336282253265381, 'rewards/accuracies': 0.75, 'rewards/margins': 1.8506619930267334, 'policy_logps/rejected': -406.1565856933594, 'policy_logps/chosen': -573.172119140625, 'referece_logps/rejected': -382.7937927246094, 'referece_logps/chosen': -568.3158569335938, 'logits/rejected': 0.43477195501327515, 'logits/chosen': 0.430968314409256, 'epoch': 5.13}


 85%|████████▌ | 13761/16104 [63:30:47<10:56:52, 16.82s/it]

 85%|████████▌ | 13762/16104 [63:31:07<11:28:38, 17.64s/it]

 85%|████████▌ | 13763/16104 [63:31:28<12:14:33, 18.83s/it]

 85%|████████▌ | 13764/16104 [63:31:49<12:29:15, 19.21s/it]

 85%|████████▌ | 13765/16104 [63:32:06<12:12:57, 18.80s/it]

 85%|████████▌ | 13766/16104 [63:32:23<11:51:43, 18.27s/it]

 85%|████████▌ | 13767/16104 [63:32:36<10:49:59, 16.69s/it]
{'loss': 0.4328, 'learning_rate': 1.0844626816488845e-07, 'rewards/chosen': -0.8367199301719666, 'rewards/rejected': -1.8845306634902954, 'rewards/accuracies': 0.625, 'rewards/margins': 1.047810673713684, 'policy_logps/rejected': -412.8256530761719, 'policy_logps/chosen': -444.27886962890625, 'referece_logps/rejected': -393.9803466796875, 'referece_logps/chosen': -435.91168212890625, 'logits/rejected': -1.0061651468276978, 'logits/chosen': -0.8896228671073914, 'epoch': 5.13}

 85%|████████▌ | 13768/16104 [63:32:54<10:58:25, 16.91s/it]

 86%|████████▌ | 13769/16104 [63:33:08<10:26:36, 16.10s/it]

 86%|████████▌ | 13770/16104 [63:33:28<11:08:32, 17.19s/it]

 86%|████████▌ | 13771/16104 [63:33:40<10:09:02, 15.66s/it]

 86%|████████▌ | 13772/16104 [63:33:56<10:12:02, 15.75s/it]


 86%|████████▌ | 13774/16104 [63:34:23<9:24:21, 14.53s/it]

 86%|████████▌ | 13775/16104 [63:34:45<10:43:09, 16.57s/it]
{'loss': 0.5086, 'learning_rate': 1.0771867774305898e-07, 'rewards/chosen': -1.6506184339523315, 'rewards/rejected': -2.510441780090332, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8598232269287109, 'policy_logps/rejected': -445.65484619140625, 'policy_logps/chosen': -640.7095947265625, 'referece_logps/rejected': -420.5504150390625, 'referece_logps/chosen': -624.203369140625, 'logits/rejected': -0.012115538120269775, 'logits/chosen': -0.057004451751708984, 'epoch': 5.13}


 86%|████████▌ | 13777/16104 [63:35:19<11:05:35, 17.16s/it]

 86%|████████▌ | 13778/16104 [63:35:35<10:48:26, 16.73s/it]

 86%|████████▌ | 13779/16104 [63:35:55<11:24:57, 17.68s/it]

 86%|████████▌ | 13780/16104 [63:36:15<11:53:56, 18.43s/it]

 86%|████████▌ | 13781/16104 [63:36:37<12:37:41, 19.57s/it]

 86%|████████▌ | 13782/16104 [63:36:57<12:37:21, 19.57s/it]

 86%|████████▌ | 13783/16104 [63:37:16<12:36:57, 19.57s/it]
{'loss': 0.4057, 'learning_rate': 1.0699339736053136e-07, 'rewards/chosen': 0.007292288821190596, 'rewards/rejected': -1.6467117071151733, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6540039777755737, 'policy_logps/rejected': -421.148193359375, 'policy_logps/chosen': -467.1412048339844, 'referece_logps/rejected': -404.6811218261719, 'referece_logps/chosen': -467.21417236328125, 'logits/rejected': -0.20893903076648712, 'logits/chosen': -0.30978065729141235, 'epoch': 5.14}


 86%|████████▌ | 13785/16104 [63:37:53<12:18:33, 19.11s/it]
{'loss': 0.4309, 'learning_rate': 1.0681243842871346e-07, 'rewards/chosen': 0.2243185043334961, 'rewards/rejected': -0.718697190284729, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9430156946182251, 'policy_logps/rejected': -481.98040771484375, 'policy_logps/chosen': -597.2252197265625, 'referece_logps/rejected': -474.79339599609375, 'referece_logps/chosen': -599.4683837890625, 'logits/rejected': -0.00811675377190113, 'logits/chosen': 0.03778550401329994, 'epoch': 5.14}

 86%|████████▌ | 13786/16104 [63:38:08<11:24:17, 17.71s/it]

 86%|████████▌ | 13787/16104 [63:38:30<12:13:15, 18.99s/it]


 86%|████████▌ | 13789/16104 [63:39:01<11:09:02, 17.34s/it]

 86%|████████▌ | 13790/16104 [63:39:13<9:57:09, 15.48s/it]

 86%|████████▌ | 13791/16104 [63:39:30<10:14:13, 15.93s/it]

 86%|████████▌ | 13792/16104 [63:39:43<9:47:59, 15.26s/it]
{'loss': 0.4971, 'learning_rate': 1.0618022048674946e-07, 'rewards/chosen': -1.0768604278564453, 'rewards/rejected': -2.800320625305176, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7234597206115723, 'policy_logps/rejected': -351.9033203125, 'policy_logps/chosen': -640.7705078125, 'referece_logps/rejected': -323.9001770019531, 'referece_logps/chosen': -630.001953125, 'logits/rejected': 0.4345585107803345, 'logits/chosen': 0.486385315656662, 'epoch': 5.14}

 86%|████████▌ | 13793/16104 [63:39:56<9:19:13, 14.52s/it]


 86%|████████▌ | 13795/16104 [63:40:28<9:31:32, 14.85s/it]
{'loss': 0.3786, 'learning_rate': 1.0590981221623685e-07, 'rewards/chosen': -0.40734612941741943, 'rewards/rejected': -1.6588565111160278, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2515102624893188, 'policy_logps/rejected': -604.3510131835938, 'policy_logps/chosen': -538.7520751953125, 'referece_logps/rejected': -587.7625122070312, 'referece_logps/chosen': -534.6785888671875, 'logits/rejected': -0.23238402605056763, 'logits/chosen': 0.020411841571331024, 'epoch': 5.14}


 86%|████████▌ | 13797/16104 [63:41:01<10:06:45, 15.78s/it]

 86%|████████▌ | 13798/16104 [63:41:18<10:17:52, 16.08s/it]

 86%|████████▌ | 13799/16104 [63:41:37<10:49:43, 16.91s/it]

 86%|████████▌ | 13800/16104 [63:41:53<10:46:11, 16.83s/it]

 86%|████████▌ | 13801/16104 [63:42:13<11:22:40, 17.79s/it]

 86%|████████▌ | 13802/16104 [63:42:27<10:31:33, 16.46s/it]

 86%|████████▌ | 13803/16104 [63:42:46<11:02:38, 17.28s/it]

 86%|████████▌ | 13804/16104 [63:43:04<11:09:57, 17.48s/it]
{'loss': 0.385, 'learning_rate': 1.0510054084519382e-07, 'rewards/chosen': -0.12122229486703873, 'rewards/rejected': -1.5506255626678467, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4294031858444214, 'policy_logps/rejected': -535.0153198242188, 'policy_logps/chosen': -518.027587890625, 'referece_logps/rejected': -519.509033203125, 'referece_logps/chosen': -516.8153686523438, 'logits/rejected': 0.18796420097351074, 'logits/chosen': 0.12320917844772339, 'epoch': 5.14}

 86%|████████▌ | 13805/16104 [63:43:21<10:59:54, 17.22s/it]


 86%|████████▌ | 13807/16104 [63:43:56<11:14:37, 17.62s/it]
{'loss': 0.4625, 'learning_rate': 1.0483143519570892e-07, 'rewards/chosen': -1.011068344116211, 'rewards/rejected': -1.1487712860107422, 'rewards/accuracies': 0.625, 'rewards/margins': 0.13770277798175812, 'policy_logps/rejected': -306.8891296386719, 'policy_logps/chosen': -435.37994384765625, 'referece_logps/rejected': -295.4013977050781, 'referece_logps/chosen': -425.26922607421875, 'logits/rejected': -0.15650293231010437, 'logits/chosen': -0.13273441791534424, 'epoch': 5.14}

 86%|████████▌ | 13808/16104 [63:44:09<10:17:55, 16.15s/it]


 86%|████████▌ | 13810/16104 [63:44:43<10:28:13, 16.43s/it]

 86%|████████▌ | 13811/16104 [63:45:00<10:32:56, 16.56s/it]

 86%|████████▌ | 13812/16104 [63:45:19<11:06:51, 17.46s/it]
{'loss': 0.2975, 'learning_rate': 1.0438365005152661e-07, 'rewards/chosen': -0.5971124768257141, 'rewards/rejected': -2.499535083770752, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9024226665496826, 'policy_logps/rejected': -303.01495361328125, 'policy_logps/chosen': -443.4076843261719, 'referece_logps/rejected': -278.0196228027344, 'referece_logps/chosen': -437.43658447265625, 'logits/rejected': -0.9554187059402466, 'logits/chosen': -0.9599343538284302, 'epoch': 5.15}

 86%|████████▌ | 13813/16104 [63:45:41<11:50:32, 18.61s/it]

 86%|████████▌ | 13814/16104 [63:45:53<10:36:22, 16.67s/it]


 86%|████████▌ | 13816/16104 [63:46:23<10:17:41, 16.20s/it]

 86%|████████▌ | 13817/16104 [63:46:42<10:47:37, 16.99s/it]

 86%|████████▌ | 13818/16104 [63:47:02<11:19:21, 17.83s/it]

 86%|████████▌ | 13819/16104 [63:47:24<12:12:14, 19.23s/it]
{'loss': 0.3625, 'learning_rate': 1.0375827258055236e-07, 'rewards/chosen': -0.5958877205848694, 'rewards/rejected': -1.7221779823303223, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1262900829315186, 'policy_logps/rejected': -505.6867980957031, 'policy_logps/chosen': -436.61712646484375, 'referece_logps/rejected': -488.46502685546875, 'referece_logps/chosen': -430.6582336425781, 'logits/rejected': -0.4532776176929474, 'logits/chosen': -0.5082474946975708, 'epoch': 5.15}


 86%|████████▌ | 13821/16104 [63:48:02<11:58:31, 18.88s/it]

 86%|████████▌ | 13822/16104 [63:48:13<10:31:24, 16.60s/it]

 86%|████████▌ | 13823/16104 [63:48:33<11:10:17, 17.63s/it]

 86%|████████▌ | 13824/16104 [63:48:54<11:44:03, 18.53s/it]

 86%|████████▌ | 13825/16104 [63:49:13<11:53:44, 18.79s/it]
{'loss': 0.4068, 'learning_rate': 1.0322364862968513e-07, 'rewards/chosen': -0.6826522350311279, 'rewards/rejected': -2.216804265975952, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5341522693634033, 'policy_logps/rejected': -555.5582275390625, 'policy_logps/chosen': -577.71533203125, 'referece_logps/rejected': -533.3901977539062, 'referece_logps/chosen': -570.8887939453125, 'logits/rejected': -0.7311574816703796, 'logits/chosen': -0.812502384185791, 'epoch': 5.15}

 86%|████████▌ | 13826/16104 [63:49:33<12:04:29, 19.08s/it]


 86%|████████▌ | 13828/16104 [63:50:04<10:52:11, 17.19s/it]
{'loss': 0.47, 'learning_rate': 1.0295682633435832e-07, 'rewards/chosen': -0.9231579303741455, 'rewards/rejected': -1.365731954574585, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4425741732120514, 'policy_logps/rejected': -415.1834716796875, 'policy_logps/chosen': -403.1802673339844, 'referece_logps/rejected': -401.526123046875, 'referece_logps/chosen': -393.9486999511719, 'logits/rejected': -0.21536174416542053, 'logits/chosen': -0.238210067152977, 'epoch': 5.15}


 86%|████████▌ | 13830/16104 [63:50:32<9:45:27, 15.45s/it]
{'loss': 0.3837, 'learning_rate': 1.027791262331299e-07, 'rewards/chosen': -0.9529345035552979, 'rewards/rejected': -2.04182505607605, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0888904333114624, 'policy_logps/rejected': -563.1920166015625, 'policy_logps/chosen': -394.881103515625, 'referece_logps/rejected': -542.773681640625, 'referece_logps/chosen': -385.3517761230469, 'logits/rejected': -0.715695321559906, 'logits/chosen': -0.7525404095649719, 'epoch': 5.15}

 86%|████████▌ | 13831/16104 [63:50:53<10:41:36, 16.94s/it]

 86%|████████▌ | 13832/16104 [63:51:11<10:54:12, 17.28s/it]

 86%|████████▌ | 13833/16104 [63:51:25<10:24:15, 16.49s/it]

 86%|████████▌ | 13834/16104 [63:51:42<10:23:41, 16.49s/it]

 86%|████████▌ | 13835/16104 [63:52:02<11:03:29, 17.55s/it]


 86%|████████▌ | 13837/16104 [63:52:30<9:47:12, 15.54s/it]
{'loss': 0.5663, 'learning_rate': 1.0215831933413999e-07, 'rewards/chosen': -0.10243721306324005, 'rewards/rejected': -0.5557701587677002, 'rewards/accuracies': 0.75, 'rewards/margins': 0.45333290100097656, 'policy_logps/rejected': -593.9461059570312, 'policy_logps/chosen': -428.5075988769531, 'referece_logps/rejected': -588.3884887695312, 'referece_logps/chosen': -427.48321533203125, 'logits/rejected': -0.5793203711509705, 'logits/chosen': -0.4722294211387634, 'epoch': 5.16}


 86%|████████▌ | 13839/16104 [63:53:01<9:47:48, 15.57s/it]
{'loss': 0.541, 'learning_rate': 1.0198127275433444e-07, 'rewards/chosen': -0.26540130376815796, 'rewards/rejected': -0.7186527252197266, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4532514214515686, 'policy_logps/rejected': -385.1627197265625, 'policy_logps/chosen': -440.76141357421875, 'referece_logps/rejected': -377.9762268066406, 'referece_logps/chosen': -438.107421875, 'logits/rejected': -0.2809481918811798, 'logits/chosen': -0.2970286011695862, 'epoch': 5.16}


 86%|████████▌ | 13841/16104 [63:53:28<9:23:59, 14.95s/it]
{'loss': 0.4065, 'learning_rate': 1.0180437148036747e-07, 'rewards/chosen': -0.6678014397621155, 'rewards/rejected': -1.7398619651794434, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0720603466033936, 'policy_logps/rejected': -386.08978271484375, 'policy_logps/chosen': -308.1289978027344, 'referece_logps/rejected': -368.691162109375, 'referece_logps/chosen': -301.4510192871094, 'logits/rejected': -0.843532145023346, 'logits/chosen': -0.8193376064300537, 'epoch': 5.16}

 86%|████████▌ | 13842/16104 [63:53:50<10:34:30, 16.83s/it]


 86%|████████▌ | 13844/16104 [63:54:29<11:26:54, 18.24s/it]
{'loss': 0.4793, 'learning_rate': 1.0153929208047285e-07, 'rewards/chosen': -0.9297584891319275, 'rewards/rejected': -2.043731689453125, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1139732599258423, 'policy_logps/rejected': -409.39764404296875, 'policy_logps/chosen': -410.78546142578125, 'referece_logps/rejected': -388.9602966308594, 'referece_logps/chosen': -401.4879150390625, 'logits/rejected': -0.3667089641094208, 'logits/chosen': -0.16459301114082336, 'epoch': 5.16}

 86%|████████▌ | 13845/16104 [63:54:48<11:35:03, 18.46s/it]

 86%|████████▌ | 13846/16104 [63:55:08<11:51:10, 18.90s/it]


 86%|████████▌ | 13848/16104 [63:55:40<10:52:56, 17.37s/it]
{'loss': 0.3451, 'learning_rate': 1.0118636171800732e-07, 'rewards/chosen': 0.3794025480747223, 'rewards/rejected': -0.9808821678161621, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3602848052978516, 'policy_logps/rejected': -520.7474365234375, 'policy_logps/chosen': -553.522705078125, 'referece_logps/rejected': -510.9385681152344, 'referece_logps/chosen': -557.3167724609375, 'logits/rejected': -0.6829887628555298, 'logits/chosen': -0.7588346004486084, 'epoch': 5.16}


 86%|████████▌ | 13850/16104 [63:56:16<10:59:59, 17.57s/it]

 86%|████████▌ | 13851/16104 [63:56:35<11:09:51, 17.84s/it]

 86%|████████▌ | 13852/16104 [63:56:54<11:29:18, 18.37s/it]
{'loss': 0.3954, 'learning_rate': 1.0083401309336203e-07, 'rewards/chosen': -0.8866082429885864, 'rewards/rejected': -2.277595281600952, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3909870386123657, 'policy_logps/rejected': -473.97314453125, 'policy_logps/chosen': -314.3190002441406, 'referece_logps/rejected': -451.1971740722656, 'referece_logps/chosen': -305.4529113769531, 'logits/rejected': 0.45529013872146606, 'logits/chosen': 0.41366150975227356, 'epoch': 5.16}


 86%|████████▌ | 13854/16104 [63:57:31<11:31:19, 18.44s/it]

 86%|████████▌ | 13855/16104 [63:57:43<10:16:01, 16.43s/it]

 86%|████████▌ | 13856/16104 [63:57:57<9:51:21, 15.78s/it]

 86%|████████▌ | 13857/16104 [63:58:17<10:36:52, 17.01s/it]
{'loss': 0.4694, 'learning_rate': 1.003943957287492e-07, 'rewards/chosen': 0.2700897455215454, 'rewards/rejected': -0.8818457722663879, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1519354581832886, 'policy_logps/rejected': -320.8038635253906, 'policy_logps/chosen': -534.6658935546875, 'referece_logps/rejected': -311.98541259765625, 'referece_logps/chosen': -537.3668212890625, 'logits/rejected': 0.1776391863822937, 'logits/chosen': 0.2512591481208801, 'epoch': 5.16}


 86%|████████▌ | 13859/16104 [63:58:50<10:31:21, 16.87s/it]
{'loss': 0.4563, 'learning_rate': 1.0021880349258172e-07, 'rewards/chosen': -0.5809054374694824, 'rewards/rejected': -2.3895492553710938, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8086438179016113, 'policy_logps/rejected': -337.14727783203125, 'policy_logps/chosen': -433.9631042480469, 'referece_logps/rejected': -313.2518005371094, 'referece_logps/chosen': -428.154052734375, 'logits/rejected': -0.41954556107521057, 'logits/chosen': -0.5214499831199646, 'epoch': 5.16}

 86%|████████▌ | 13860/16104 [63:59:04<9:50:11, 15.78s/it]

 86%|████████▌ | 13861/16104 [63:59:15<9:02:33, 14.51s/it]

 86%|████████▌ | 13862/16104 [63:59:25<8:12:19, 13.18s/it]

 86%|████████▌ | 13863/16104 [63:59:36<7:44:44, 12.44s/it]

 86%|████████▌ | 13864/16104 [63:59:51<8:17:51, 13.34s/it]


 86%|████████▌ | 13866/16104 [64:00:15<7:43:45, 12.43s/it]
{'loss': 0.4871, 'learning_rate': 9.960537738151043e-08, 'rewards/chosen': -0.533316433429718, 'rewards/rejected': -1.1386398077011108, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6053234338760376, 'policy_logps/rejected': -385.423095703125, 'policy_logps/chosen': -416.1701965332031, 'referece_logps/rejected': -374.03668212890625, 'referece_logps/chosen': -410.8370056152344, 'logits/rejected': 0.09708314388990402, 'logits/chosen': -0.18216899037361145, 'epoch': 5.17}

 86%|████████▌ | 13867/16104 [64:00:25<7:23:48, 11.90s/it]

 86%|████████▌ | 13868/16104 [64:00:36<7:10:57, 11.56s/it]

 86%|████████▌ | 13869/16104 [64:00:48<7:13:49, 11.65s/it]

 86%|████████▌ | 13870/16104 [64:01:08<8:51:41, 14.28s/it]

 86%|████████▌ | 13871/16104 [64:01:24<9:07:14, 14.70s/it]

 86%|████████▌ | 13872/16104 [64:01:44<10:01:03, 16.16s/it]

 86%|████████▌ | 13873/16104 [64:02:00<9:58:25, 16.09s/it]

 86%|████████▌ | 13874/16104 [64:02:19<10:39:12, 17.20s/it]

 86%|████████▌ | 13875/16104 [64:02:32<9:53:02, 15.96s/it]

 86%|████████▌ | 13876/16104 [64:02:52<10:32:53, 17.04s/it]

 86%|████████▌ | 13877/16104 [64:03:09<10:27:24, 16.90s/it]


 86%|████████▌ | 13879/16104 [64:03:41<9:54:54, 16.04s/it]

 86%|████████▌ | 13880/16104 [64:03:59<10:18:25, 16.68s/it]

 86%|████████▌ | 13881/16104 [64:04:11<9:27:58, 15.33s/it]

 86%|████████▌ | 13882/16104 [64:04:29<9:52:02, 15.99s/it]
{'loss': 0.2873, 'learning_rate': 9.820996425853333e-08, 'rewards/chosen': -1.1882519721984863, 'rewards/rejected': -3.5520529747009277, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3638010025024414, 'policy_logps/rejected': -429.24664306640625, 'policy_logps/chosen': -493.15130615234375, 'referece_logps/rejected': -393.72607421875, 'referece_logps/chosen': -481.2687683105469, 'logits/rejected': -0.44516974687576294, 'logits/chosen': -0.4469150900840759, 'epoch': 5.17}

 86%|████████▌ | 13883/16104 [64:04:48<10:31:26, 17.06s/it]


 86%|████████▌ | 13885/16104 [64:05:19<9:40:05, 15.69s/it]

 86%|████████▌ | 13886/16104 [64:05:35<9:44:35, 15.81s/it]

 86%|████████▌ | 13887/16104 [64:05:51<9:48:19, 15.92s/it]
{'loss': 0.4181, 'learning_rate': 9.77758121278056e-08, 'rewards/chosen': -0.43625983595848083, 'rewards/rejected': -1.3689790964126587, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9327192902565002, 'policy_logps/rejected': -492.07586669921875, 'policy_logps/chosen': -492.65264892578125, 'referece_logps/rejected': -478.3860778808594, 'referece_logps/chosen': -488.2900390625, 'logits/rejected': -0.2581242024898529, 'logits/chosen': -0.276864230632782, 'epoch': 5.17}


 86%|████████▌ | 13889/16104 [64:06:25<10:18:48, 16.76s/it]
{'loss': 0.3744, 'learning_rate': 9.760240672698672e-08, 'rewards/chosen': -0.8347532749176025, 'rewards/rejected': -2.4689042568206787, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6341513395309448, 'policy_logps/rejected': -280.20465087890625, 'policy_logps/chosen': -334.4337158203125, 'referece_logps/rejected': -255.51560974121094, 'referece_logps/chosen': -326.0861511230469, 'logits/rejected': -1.018167495727539, 'logits/chosen': -1.040054440498352, 'epoch': 5.17}

 86%|████████▋ | 13890/16104 [64:06:42<10:19:12, 16.78s/it]


 86%|████████▋ | 13892/16104 [64:07:24<11:35:01, 18.85s/it]
{'loss': 0.4142, 'learning_rate': 9.734257241146437e-08, 'rewards/chosen': 0.3470441997051239, 'rewards/rejected': -0.5634139776229858, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9104581475257874, 'policy_logps/rejected': -487.6156005859375, 'policy_logps/chosen': -506.8229064941406, 'referece_logps/rejected': -481.9814147949219, 'referece_logps/chosen': -510.2933349609375, 'logits/rejected': -0.5941683053970337, 'logits/chosen': -0.3202943205833435, 'epoch': 5.18}

 86%|████████▋ | 13893/16104 [64:07:41<11:16:03, 18.35s/it]

 86%|████████▋ | 13894/16104 [64:07:58<11:03:36, 18.02s/it]

 86%|████████▋ | 13895/16104 [64:08:14<10:40:57, 17.41s/it]

 86%|████████▋ | 13896/16104 [64:08:32<10:44:48, 17.52s/it]

 86%|████████▋ | 13897/16104 [64:08:53<11:20:51, 18.51s/it]

 86%|████████▋ | 13898/16104 [64:09:07<10:31:42, 17.18s/it]


 86%|████████▋ | 13900/16104 [64:09:39<10:14:49, 16.74s/it]

 86%|████████▋ | 13901/16104 [64:09:56<10:11:04, 16.64s/it]

 86%|████████▋ | 13902/16104 [64:10:09<9:36:52, 15.72s/it]
{'loss': 0.3725, 'learning_rate': 9.647883197354989e-08, 'rewards/chosen': -0.5340431332588196, 'rewards/rejected': -1.7913306951522827, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2572875022888184, 'policy_logps/rejected': -343.83111572265625, 'policy_logps/chosen': -355.5216064453125, 'referece_logps/rejected': -325.9178466796875, 'referece_logps/chosen': -350.1811828613281, 'logits/rejected': -0.011201098561286926, 'logits/chosen': 0.07340960204601288, 'epoch': 5.18}

 86%|████████▋ | 13903/16104 [64:10:28<10:12:50, 16.71s/it]

 86%|████████▋ | 13904/16104 [64:10:43<9:49:02, 16.06s/it]

 86%|████████▋ | 13905/16104 [64:11:00<10:03:22, 16.46s/it]

 86%|████████▋ | 13906/16104 [64:11:16<10:01:13, 16.41s/it]

 86%|████████▋ | 13907/16104 [64:11:33<10:02:11, 16.45s/it]

 86%|████████▋ | 13908/16104 [64:11:53<10:37:33, 17.42s/it]

 86%|████████▋ | 13909/16104 [64:12:09<10:22:13, 17.01s/it]

 86%|████████▋ | 13910/16104 [64:12:22<9:46:26, 16.04s/it]

 86%|████████▋ | 13911/16104 [64:12:40<10:05:05, 16.56s/it]


 86%|████████▋ | 13913/16104 [64:13:16<10:34:36, 17.38s/it]

 86%|████████▋ | 13914/16104 [64:13:28<9:34:17, 15.73s/it]
{'loss': 0.348, 'learning_rate': 9.544716822662369e-08, 'rewards/chosen': -1.0773667097091675, 'rewards/rejected': -4.135132312774658, 'rewards/accuracies': 0.875, 'rewards/margins': 3.0577659606933594, 'policy_logps/rejected': -451.5843200683594, 'policy_logps/chosen': -310.2111511230469, 'referece_logps/rejected': -410.2330017089844, 'referece_logps/chosen': -299.4375, 'logits/rejected': -0.3276819884777069, 'logits/chosen': -0.22988739609718323, 'epoch': 5.18}


 86%|████████▋ | 13916/16104 [64:14:02<10:04:37, 16.58s/it]

 86%|████████▋ | 13917/16104 [64:14:16<9:36:32, 15.82s/it]
{'loss': 0.4168, 'learning_rate': 9.519007534788803e-08, 'rewards/chosen': -0.7008455395698547, 'rewards/rejected': -2.2396295070648193, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5387839078903198, 'policy_logps/rejected': -340.32489013671875, 'policy_logps/chosen': -357.7984924316406, 'referece_logps/rejected': -317.9285888671875, 'referece_logps/chosen': -350.7900085449219, 'logits/rejected': -0.30906128883361816, 'logits/chosen': -0.09909330308437347, 'epoch': 5.19}

 86%|████████▋ | 13918/16104 [64:14:27<8:42:15, 14.33s/it]

 86%|████████▋ | 13919/16104 [64:14:43<9:02:45, 14.90s/it]

 86%|████████▋ | 13920/16104 [64:14:57<8:50:50, 14.58s/it]


 86%|████████▋ | 13922/16104 [64:15:34<9:56:23, 16.40s/it]
{'loss': 0.3725, 'learning_rate': 9.47623192863315e-08, 'rewards/chosen': -0.7571842074394226, 'rewards/rejected': -1.8272027969360352, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0700185298919678, 'policy_logps/rejected': -527.6939086914062, 'policy_logps/chosen': -466.6061096191406, 'referece_logps/rejected': -509.4218444824219, 'referece_logps/chosen': -459.03424072265625, 'logits/rejected': -0.015216507017612457, 'logits/chosen': -0.15136069059371948, 'epoch': 5.19}

 86%|████████▋ | 13923/16104 [64:15:53<10:32:28, 17.40s/it]

 86%|████████▋ | 13924/16104 [64:16:13<10:57:21, 18.09s/it]

 86%|████████▋ | 13925/16104 [64:16:28<10:27:08, 17.27s/it]

 86%|████████▋ | 13926/16104 [64:16:48<10:57:16, 18.11s/it]

 86%|████████▋ | 13927/16104 [64:17:05<10:42:29, 17.71s/it]


 86%|████████▋ | 13929/16104 [64:17:32<9:30:04, 15.73s/it]
{'loss': 0.3394, 'learning_rate': 9.416499887289297e-08, 'rewards/chosen': -0.5646327137947083, 'rewards/rejected': -1.6089740991592407, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0443415641784668, 'policy_logps/rejected': -271.339599609375, 'policy_logps/chosen': -325.4952087402344, 'referece_logps/rejected': -255.24986267089844, 'referece_logps/chosen': -319.8489074707031, 'logits/rejected': -0.20751824975013733, 'logits/chosen': -0.10813069343566895, 'epoch': 5.19}


 87%|████████▋ | 13931/16104 [64:18:08<10:17:55, 17.06s/it]

 87%|████████▋ | 13932/16104 [64:18:24<10:07:59, 16.80s/it]
{'loss': 0.2723, 'learning_rate': 9.390955398062539e-08, 'rewards/chosen': -0.1716119945049286, 'rewards/rejected': -2.873967170715332, 'rewards/accuracies': 0.875, 'rewards/margins': 2.702355146408081, 'policy_logps/rejected': -368.68463134765625, 'policy_logps/chosen': -365.4036865234375, 'referece_logps/rejected': -339.9449157714844, 'referece_logps/chosen': -363.6875915527344, 'logits/rejected': -0.7092657089233398, 'logits/chosen': -0.42566338181495667, 'epoch': 5.19}

 87%|████████▋ | 13933/16104 [64:18:44<10:41:45, 17.74s/it]

 87%|████████▋ | 13934/16104 [64:19:04<11:05:05, 18.39s/it]

 87%|████████▋ | 13935/16104 [64:19:21<10:58:42, 18.22s/it]

 87%|████████▋ | 13936/16104 [64:19:44<11:40:36, 19.39s/it]

 87%|████████▋ | 13937/16104 [64:19:59<10:58:43, 18.24s/it]

 87%|████████▋ | 13938/16104 [64:20:20<11:26:50, 19.03s/it]

 87%|████████▋ | 13939/16104 [64:20:35<10:45:58, 17.90s/it]

 87%|████████▋ | 13940/16104 [64:20:55<11:06:31, 18.48s/it]

 87%|████████▋ | 13941/16104 [64:21:10<10:28:10, 17.43s/it]

 87%|████████▋ | 13942/16104 [64:21:31<11:11:27, 18.63s/it]

 87%|████████▋ | 13943/16104 [64:21:43<9:53:51, 16.49s/it]


 87%|████████▋ | 13945/16104 [64:22:22<10:53:21, 18.16s/it]
{'loss': 0.4733, 'learning_rate': 9.280643921509346e-08, 'rewards/chosen': -0.790284276008606, 'rewards/rejected': -1.4947857856750488, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7045014500617981, 'policy_logps/rejected': -525.6880493164062, 'policy_logps/chosen': -471.20361328125, 'referece_logps/rejected': -510.7402038574219, 'referece_logps/chosen': -463.30078125, 'logits/rejected': -0.7758558988571167, 'logits/chosen': -0.6986024379730225, 'epoch': 5.2}

 87%|████████▋ | 13946/16104 [64:22:40<10:50:55, 18.10s/it]

 87%|████████▋ | 13947/16104 [64:22:54<10:05:28, 16.84s/it]

 87%|████████▋ | 13948/16104 [64:23:11<10:03:13, 16.79s/it]

 87%|████████▋ | 13949/16104 [64:23:31<10:33:56, 17.65s/it]

 87%|████████▋ | 13950/16104 [64:23:48<10:28:14, 17.50s/it]

 87%|████████▋ | 13951/16104 [64:23:58<9:13:56, 15.44s/it]

 87%|████████▋ | 13952/16104 [64:24:12<8:53:04, 14.86s/it]


 87%|████████▋ | 13954/16104 [64:24:53<10:34:26, 17.71s/it]
{'loss': 0.4533, 'learning_rate': 9.20463769862223e-08, 'rewards/chosen': -0.48818665742874146, 'rewards/rejected': -1.6392762660980225, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1510896682739258, 'policy_logps/rejected': -543.18896484375, 'policy_logps/chosen': -414.7719421386719, 'referece_logps/rejected': -526.7962036132812, 'referece_logps/chosen': -409.89013671875, 'logits/rejected': 0.02619549259543419, 'logits/chosen': 0.2039300799369812, 'epoch': 5.2}

 87%|████████▋ | 13955/16104 [64:25:09<10:24:50, 17.45s/it]

 87%|████████▋ | 13956/16104 [64:25:29<10:45:42, 18.04s/it]


 87%|████████▋ | 13958/16104 [64:26:03<10:28:21, 17.57s/it]
{'loss': 0.3799, 'learning_rate': 9.170952634018059e-08, 'rewards/chosen': -0.1159610003232956, 'rewards/rejected': -2.3822176456451416, 'rewards/accuracies': 1.0, 'rewards/margins': 2.266256809234619, 'policy_logps/rejected': -340.7886657714844, 'policy_logps/chosen': -299.7156066894531, 'referece_logps/rejected': -316.96649169921875, 'referece_logps/chosen': -298.5559997558594, 'logits/rejected': -0.4970332980155945, 'logits/chosen': -0.44930335879325867, 'epoch': 5.2}

 87%|████████▋ | 13959/16104 [64:26:21<10:36:37, 17.81s/it]

 87%|████████▋ | 13960/16104 [64:26:42<11:06:24, 18.65s/it]

 87%|████████▋ | 13961/16104 [64:27:02<11:19:54, 19.04s/it]

 87%|████████▋ | 13962/16104 [64:27:22<11:31:12, 19.36s/it]

 87%|████████▋ | 13963/16104 [64:27:38<10:55:23, 18.37s/it]

 87%|████████▋ | 13964/16104 [64:27:56<10:52:59, 18.31s/it]

 87%|████████▋ | 13965/16104 [64:28:14<10:47:40, 18.17s/it]

 87%|████████▋ | 13966/16104 [64:28:36<11:28:13, 19.31s/it]


 87%|████████▋ | 13968/16104 [64:29:11<10:50:28, 18.27s/it]
{'loss': 0.4682, 'learning_rate': 9.086997213886227e-08, 'rewards/chosen': -0.6623476147651672, 'rewards/rejected': -2.0589797496795654, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3966320753097534, 'policy_logps/rejected': -448.4139099121094, 'policy_logps/chosen': -536.9959106445312, 'referece_logps/rejected': -427.82403564453125, 'referece_logps/chosen': -530.3724365234375, 'logits/rejected': -0.1580595076084137, 'logits/chosen': -0.431490957736969, 'epoch': 5.2}

 87%|████████▋ | 13969/16104 [64:29:30<10:57:10, 18.47s/it]

 87%|████████▋ | 13970/16104 [64:29:49<11:08:49, 18.80s/it]

 87%|████████▋ | 13971/16104 [64:30:02<10:05:25, 17.03s/it]

 87%|████████▋ | 13972/16104 [64:30:20<10:12:35, 17.24s/it]

 87%|████████▋ | 13973/16104 [64:30:40<10:39:02, 17.99s/it]

 87%|████████▋ | 13974/16104 [64:30:58<10:44:27, 18.15s/it]

 87%|████████▋ | 13975/16104 [64:31:14<10:15:46, 17.35s/it]

 87%|████████▋ | 13976/16104 [64:31:34<10:47:15, 18.25s/it]

 87%|████████▋ | 13977/16104 [64:31:52<10:43:43, 18.16s/it]

 87%|████████▋ | 13978/16104 [64:32:12<10:57:59, 18.57s/it]

 87%|████████▋ | 13979/16104 [64:32:30<10:53:28, 18.45s/it]

 87%|████████▋ | 13980/16104 [64:32:43<9:52:09, 16.73s/it]

 87%|████████▋ | 13981/16104 [64:32:59<9:52:30, 16.75s/it]

 87%|████████▋ | 13982/16104 [64:33:17<9:59:18, 16.95s/it]

 87%|████████▋ | 13983/16104 [64:33:36<10:28:29, 17.78s/it]

 87%|████████▋ | 13984/16104 [64:33:56<10:46:40, 18.30s/it]

 87%|████████▋ | 13985/16104 [64:34:16<11:03:02, 18.77s/it]

 87%|████████▋ | 13986/16104 [64:34:35<11:11:29, 19.02s/it]

 87%|████████▋ | 13987/16104 [64:34:51<10:32:41, 17.93s/it]

 87%|████████▋ | 13988/16104 [64:35:06<10:06:40, 17.20s/it]

 87%|████████▋ | 13989/16104 [64:35:22<9:50:25, 16.75s/it]

 87%|████████▋ | 13990/16104 [64:35:42<10:23:27, 17.69s/it]

 87%|████████▋ | 13991/16104 [64:36:00<10:27:36, 17.82s/it]

 87%|████████▋ | 13992/16104 [64:36:11<9:12:06, 15.68s/it]

 87%|████████▋ | 13993/16104 [64:36:30<9:44:46, 16.62s/it]

 87%|████████▋ | 13994/16104 [64:36:42<9:03:12, 15.45s/it]

 87%|████████▋ | 13995/16104 [64:37:02<9:49:57, 16.78s/it]

 87%|████████▋ | 13996/16104 [64:37:20<10:00:20, 17.09s/it]

 87%|████████▋ | 13997/16104 [64:37:32<9:03:10, 15.47s/it]

 87%|████████▋ | 13998/16104 [64:37:53<10:03:01, 17.18s/it]

 87%|████████▋ | 13999/16104 [64:38:15<10:56:33, 18.71s/it]

 87%|████████▋ | 14000/16104 [64:38:34<10:54:22, 18.66s/it]

 87%|████████▋ | 14001/16104 [64:39:03<12:41:21, 21.72s/it]

 87%|████████▋ | 14002/16104 [64:39:25<12:44:13, 21.81s/it]

 87%|████████▋ | 14003/16104 [64:39:44<12:22:45, 21.21s/it]

 87%|████████▋ | 14004/16104 [64:40:01<11:32:42, 19.79s/it]

 87%|████████▋ | 14005/16104 [64:40:21<11:31:24, 19.76s/it]

 87%|████████▋ | 14006/16104 [64:40:36<10:45:49, 18.47s/it]

 87%|████████▋ | 14007/16104 [64:40:58<11:20:03, 19.46s/it]

 87%|████████▋ | 14008/16104 [64:41:14<10:48:31, 18.56s/it]

 87%|████████▋ | 14009/16104 [64:41:30<10:14:25, 17.60s/it]

 87%|████████▋ | 14010/16104 [64:41:50<10:41:57, 18.39s/it]

 87%|████████▋ | 14011/16104 [64:42:09<10:50:54, 18.66s/it]

 87%|████████▋ | 14012/16104 [64:42:29<11:06:53, 19.13s/it]

 87%|████████▋ | 14013/16104 [64:42:41<9:50:06, 16.93s/it]

 87%|████████▋ | 14014/16104 [64:43:01<10:20:41, 17.82s/it]

 87%|████████▋ | 14015/16104 [64:43:15<9:44:12, 16.78s/it]

 87%|████████▋ | 14016/16104 [64:43:31<9:36:28, 16.57s/it]

 87%|████████▋ | 14017/16104 [64:43:42<8:35:46, 14.83s/it]

 87%|████████▋ | 14018/16104 [64:43:57<8:37:59, 14.90s/it]

 87%|████████▋ | 14019/16104 [64:44:10<8:18:05, 14.33s/it]

 87%|████████▋ | 14020/16104 [64:44:24<8:16:05, 14.28s/it]

 87%|████████▋ | 14021/16104 [64:44:37<7:57:21, 13.75s/it]

 87%|████████▋ | 14022/16104 [64:44:48<7:25:40, 12.84s/it]

 87%|████████▋ | 14023/16104 [64:44:59<7:08:56, 12.37s/it]

 87%|████████▋ | 14024/16104 [64:45:14<7:31:51, 13.03s/it]

 87%|████████▋ | 14025/16104 [64:45:27<7:38:03, 13.22s/it]

 87%|████████▋ | 14026/16104 [64:45:46<8:40:45, 15.04s/it]

 87%|████████▋ | 14027/16104 [64:46:05<9:14:23, 16.02s/it]

 87%|████████▋ | 14028/16104 [64:46:18<8:40:07, 15.03s/it]


 87%|████████▋ | 14030/16104 [64:46:50<9:06:58, 15.82s/it]
{'loss': 0.3596, 'learning_rate': 8.574695015273448e-08, 'rewards/chosen': -0.47237130999565125, 'rewards/rejected': -2.965728759765625, 'rewards/accuracies': 0.875, 'rewards/margins': 2.4933574199676514, 'policy_logps/rejected': -438.1797790527344, 'policy_logps/chosen': -373.5552978515625, 'referece_logps/rejected': -408.52252197265625, 'referece_logps/chosen': -368.83160400390625, 'logits/rejected': 0.16395890712738037, 'logits/chosen': 0.4274517595767975, 'epoch': 5.23}

 87%|████████▋ | 14031/16104 [64:47:10<9:53:32, 17.18s/it]

 87%|████████▋ | 14032/16104 [64:47:23<9:01:05, 15.67s/it]

 87%|████████▋ | 14033/16104 [64:47:38<8:54:26, 15.48s/it]

 87%|████████▋ | 14034/16104 [64:47:59<9:50:59, 17.13s/it]

 87%|████████▋ | 14035/16104 [64:48:20<10:30:12, 18.28s/it]

 87%|████████▋ | 14036/16104 [64:48:39<10:38:36, 18.53s/it]

 87%|████████▋ | 14037/16104 [64:48:54<10:03:54, 17.53s/it]

 87%|████████▋ | 14038/16104 [64:49:11<9:58:06, 17.37s/it]

 87%|████████▋ | 14039/16104 [64:49:27<9:40:57, 16.88s/it]

 87%|████████▋ | 14040/16104 [64:49:44<9:47:23, 17.08s/it]

 87%|████████▋ | 14041/16104 [64:49:56<8:53:35, 15.52s/it]

 87%|████████▋ | 14042/16104 [64:50:15<9:30:33, 16.60s/it]

 87%|████████▋ | 14043/16104 [64:50:32<9:34:33, 16.73s/it]

 87%|████████▋ | 14044/16104 [64:50:45<8:55:47, 15.61s/it]

 87%|████████▋ | 14045/16104 [64:51:05<9:40:08, 16.91s/it]

 87%|████████▋ | 14046/16104 [64:51:18<8:55:51, 15.62s/it]

 87%|████████▋ | 14047/16104 [64:51:33<8:53:07, 15.55s/it]

 87%|████████▋ | 14048/16104 [64:51:46<8:26:02, 14.77s/it]


 87%|████████▋ | 14050/16104 [64:52:22<9:18:18, 16.31s/it]
{'loss': 0.4274, 'learning_rate': 8.412465046527761e-08, 'rewards/chosen': -0.5429168939590454, 'rewards/rejected': -1.299706220626831, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7567893266677856, 'policy_logps/rejected': -473.55535888671875, 'policy_logps/chosen': -388.2946472167969, 'referece_logps/rejected': -460.5583190917969, 'referece_logps/chosen': -382.865478515625, 'logits/rejected': -0.3291430175304413, 'logits/chosen': -0.2953161299228668, 'epoch': 5.23}


 87%|████████▋ | 14052/16104 [64:52:58<9:52:58, 17.34s/it]

 87%|████████▋ | 14053/16104 [64:53:17<10:10:34, 17.86s/it]

 87%|████████▋ | 14054/16104 [64:53:29<9:11:43, 16.15s/it]

 87%|████████▋ | 14055/16104 [64:53:40<8:16:14, 14.53s/it]

 87%|████████▋ | 14056/16104 [64:54:01<9:21:37, 16.45s/it]

 87%|████████▋ | 14057/16104 [64:54:22<10:04:06, 17.71s/it]

 87%|████████▋ | 14058/16104 [64:54:38<9:55:09, 17.45s/it]

 87%|████████▋ | 14059/16104 [64:54:58<10:20:43, 18.21s/it]
{'loss': 0.3462, 'learning_rate': 8.339944890551464e-08, 'rewards/chosen': 0.08066922426223755, 'rewards/rejected': -1.4278043508529663, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5084736347198486, 'policy_logps/rejected': -410.4478759765625, 'policy_logps/chosen': -380.43890380859375, 'referece_logps/rejected': -396.16986083984375, 'referece_logps/chosen': -381.24560546875, 'logits/rejected': -0.4756101965904236, 'logits/chosen': -0.3631937503814697, 'epoch': 5.24}


 87%|████████▋ | 14061/16104 [64:55:34<10:16:26, 18.10s/it]

 87%|████████▋ | 14062/16104 [64:55:48<9:33:14, 16.84s/it]
{'loss': 0.4293, 'learning_rate': 8.315838234132421e-08, 'rewards/chosen': -0.7941975593566895, 'rewards/rejected': -2.779400110244751, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9852027893066406, 'policy_logps/rejected': -317.2803649902344, 'policy_logps/chosen': -268.36285400390625, 'referece_logps/rejected': -289.486328125, 'referece_logps/chosen': -260.4208984375, 'logits/rejected': -0.40051937103271484, 'logits/chosen': -0.3283652365207672, 'epoch': 5.24}


 87%|████████▋ | 14064/16104 [64:56:24<9:49:26, 17.34s/it]

 87%|████████▋ | 14065/16104 [64:56:44<10:13:29, 18.05s/it]

 87%|████████▋ | 14066/16104 [64:56:56<9:10:02, 16.19s/it]

 87%|████████▋ | 14067/16104 [64:57:10<8:42:34, 15.39s/it]

 87%|████████▋ | 14068/16104 [64:57:23<8:19:12, 14.71s/it]

 87%|████████▋ | 14069/16104 [64:57:43<9:11:23, 16.26s/it]

 87%|████████▋ | 14070/16104 [64:58:04<10:01:36, 17.75s/it]

 87%|████████▋ | 14071/16104 [64:58:14<8:48:32, 15.60s/it]
{'loss': 0.3884, 'learning_rate': 8.243718574464254e-08, 'rewards/chosen': -0.6994878649711609, 'rewards/rejected': -1.6374495029449463, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9379616975784302, 'policy_logps/rejected': -317.0638122558594, 'policy_logps/chosen': -302.0091552734375, 'referece_logps/rejected': -300.6893005371094, 'referece_logps/chosen': -295.0143127441406, 'logits/rejected': 0.2841697931289673, 'logits/chosen': 0.340549498796463, 'epoch': 5.24}


 87%|████████▋ | 14073/16104 [64:58:51<9:28:55, 16.81s/it]

 87%|████████▋ | 14074/16104 [64:59:05<9:08:37, 16.22s/it]

 87%|████████▋ | 14075/16104 [64:59:25<9:40:05, 17.15s/it]
{'loss': 0.3163, 'learning_rate': 8.211761882691071e-08, 'rewards/chosen': -0.0023082420229911804, 'rewards/rejected': -1.5560111999511719, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5537028312683105, 'policy_logps/rejected': -390.46380615234375, 'policy_logps/chosen': -421.0752258300781, 'referece_logps/rejected': -374.9037170410156, 'referece_logps/chosen': -421.0521545410156, 'logits/rejected': -0.07577864825725555, 'logits/chosen': -0.09437848627567291, 'epoch': 5.24}


 87%|████████▋ | 14077/16104 [64:59:58<9:33:21, 16.97s/it]
{'loss': 0.4285, 'learning_rate': 8.195805813500278e-08, 'rewards/chosen': -0.6296678781509399, 'rewards/rejected': -1.5072801113128662, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8776122331619263, 'policy_logps/rejected': -389.8545227050781, 'policy_logps/chosen': -489.1156921386719, 'referece_logps/rejected': -374.7817077636719, 'referece_logps/chosen': -482.8190612792969, 'logits/rejected': 0.2229466736316681, 'logits/chosen': 0.20748573541641235, 'epoch': 5.24}


 87%|████████▋ | 14079/16104 [65:00:28<9:15:19, 16.45s/it]

 87%|████████▋ | 14080/16104 [65:00:45<9:14:17, 16.43s/it]

 87%|████████▋ | 14081/16104 [65:01:04<9:46:53, 17.41s/it]

 87%|████████▋ | 14082/16104 [65:01:22<9:49:50, 17.50s/it]

 87%|████████▋ | 14083/16104 [65:01:42<10:17:22, 18.33s/it]

 87%|████████▋ | 14084/16104 [65:01:57<9:39:44, 17.22s/it]

 87%|████████▋ | 14085/16104 [65:02:10<8:58:11, 15.99s/it]
{'loss': 0.459, 'learning_rate': 8.132130108256841e-08, 'rewards/chosen': -0.8850852847099304, 'rewards/rejected': -2.0332119464874268, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1481266021728516, 'policy_logps/rejected': -433.0579833984375, 'policy_logps/chosen': -357.752197265625, 'referece_logps/rejected': -412.72589111328125, 'referece_logps/chosen': -348.9013366699219, 'logits/rejected': 0.4204103350639343, 'logits/chosen': 0.42771095037460327, 'epoch': 5.25}


 87%|████████▋ | 14087/16104 [65:02:49<9:59:01, 17.82s/it]

 87%|████████▋ | 14088/16104 [65:03:06<9:50:08, 17.56s/it]

 87%|████████▋ | 14089/16104 [65:03:26<10:12:27, 18.24s/it]

 87%|████████▋ | 14090/16104 [65:03:46<10:28:13, 18.72s/it]

 88%|████████▊ | 14091/16104 [65:04:04<10:24:30, 18.61s/it]

 88%|████████▊ | 14092/16104 [65:04:15<9:07:55, 16.34s/it]

 88%|████████▊ | 14093/16104 [65:04:35<9:42:59, 17.39s/it]

 88%|████████▊ | 14094/16104 [65:04:55<10:08:58, 18.18s/it]

 88%|████████▊ | 14095/16104 [65:05:17<10:43:02, 19.20s/it]

 88%|████████▊ | 14096/16104 [65:05:36<10:50:01, 19.42s/it]

 88%|████████▊ | 14097/16104 [65:05:55<10:41:31, 19.18s/it]

 88%|████████▊ | 14098/16104 [65:06:06<9:15:37, 16.62s/it]

 88%|████████▊ | 14099/16104 [65:06:25<9:39:57, 17.36s/it]

 88%|████████▊ | 14100/16104 [65:06:41<9:24:21, 16.90s/it]

 88%|████████▊ | 14101/16104 [65:06:55<8:53:43, 15.99s/it]

 88%|████████▊ | 14102/16104 [65:07:13<9:22:01, 16.84s/it]

 88%|████████▊ | 14103/16104 [65:07:26<8:42:15, 15.66s/it]

 88%|████████▊ | 14104/16104 [65:07:43<8:54:39, 16.04s/it]

 88%|████████▊ | 14105/16104 [65:08:03<9:31:01, 17.14s/it]

 88%|████████▊ | 14106/16104 [65:08:22<9:50:42, 17.74s/it]

 88%|████████▊ | 14107/16104 [65:08:35<9:06:07, 16.41s/it]

 88%|████████▊ | 14108/16104 [65:08:49<8:39:18, 15.61s/it]

 88%|████████▊ | 14109/16104 [65:09:01<8:06:45, 14.64s/it]

 88%|████████▊ | 14110/16104 [65:09:20<8:47:31, 15.87s/it]

 88%|████████▊ | 14111/16104 [65:09:41<9:41:10, 17.50s/it]

 88%|████████▊ | 14112/16104 [65:10:02<10:12:02, 18.44s/it]

 88%|████████▊ | 14113/16104 [65:10:24<10:45:07, 19.44s/it]

 88%|████████▊ | 14114/16104 [65:10:42<10:29:59, 18.99s/it]

 88%|████████▊ | 14115/16104 [65:10:56<9:38:51, 17.46s/it]

 88%|████████▊ | 14116/16104 [65:11:13<9:40:02, 17.51s/it]

 88%|████████▊ | 14117/16104 [65:11:33<9:58:47, 18.08s/it]

 88%|████████▊ | 14118/16104 [65:11:48<9:32:57, 17.31s/it]

 88%|████████▊ | 14119/16104 [65:12:04<9:14:52, 16.77s/it]

 88%|████████▊ | 14120/16104 [65:12:23<9:42:21, 17.61s/it]

 88%|████████▊ | 14121/16104 [65:12:43<10:00:57, 18.18s/it]

 88%|████████▊ | 14122/16104 [65:12:55<9:03:13, 16.44s/it]

 88%|████████▊ | 14123/16104 [65:13:13<9:17:44, 16.89s/it]

 88%|████████▊ | 14124/16104 [65:13:31<9:27:06, 17.19s/it]

 88%|████████▊ | 14125/16104 [65:13:50<9:44:52, 17.73s/it]

 88%|████████▊ | 14126/16104 [65:14:03<8:57:52, 16.32s/it]

 88%|████████▊ | 14127/16104 [65:14:25<9:49:24, 17.89s/it]

 88%|████████▊ | 14128/16104 [65:14:37<8:58:05, 16.34s/it]

 88%|████████▊ | 14129/16104 [65:14:49<8:10:45, 14.91s/it]

 88%|████████▊ | 14130/16104 [65:15:00<7:32:38, 13.76s/it]

 88%|████████▊ | 14131/16104 [65:15:18<8:16:22, 15.09s/it]

 88%|████████▊ | 14132/16104 [65:15:29<7:33:29, 13.80s/it]

 88%|████████▊ | 14133/16104 [65:15:49<8:30:30, 15.54s/it]

 88%|████████▊ | 14134/16104 [65:16:05<8:36:45, 15.74s/it]

 88%|████████▊ | 14135/16104 [65:16:22<8:49:56, 16.15s/it]

 88%|████████▊ | 14136/16104 [65:16:41<9:19:17, 17.05s/it]

 88%|████████▊ | 14137/16104 [65:17:03<10:05:14, 18.46s/it]

 88%|████████▊ | 14138/16104 [65:17:14<8:52:10, 16.24s/it]

 88%|████████▊ | 14139/16104 [65:17:24<7:55:23, 14.52s/it]

 88%|████████▊ | 14140/16104 [65:17:43<8:30:42, 15.60s/it]

 88%|████████▊ | 14141/16104 [65:18:02<9:09:31, 16.80s/it]

 88%|████████▊ | 14142/16104 [65:18:18<8:56:02, 16.39s/it]

 88%|████████▊ | 14143/16104 [65:18:36<9:14:03, 16.95s/it]

 88%|████████▊ | 14144/16104 [65:18:49<8:35:01, 15.77s/it]

 88%|████████▊ | 14145/16104 [65:19:07<8:59:34, 16.53s/it]

 88%|████████▊ | 14146/16104 [65:19:23<8:54:52, 16.39s/it]

 88%|████████▊ | 14147/16104 [65:19:37<8:28:08, 15.58s/it]
{'loss': 0.5073, 'learning_rate': 7.646720048463218e-08, 'rewards/chosen': -1.7378569841384888, 'rewards/rejected': -2.853492021560669, 'rewards/accuracies': 0.5, 'rewards/margins': 1.1156352758407593, 'policy_logps/rejected': -384.8081359863281, 'policy_logps/chosen': -492.98638916015625, 'referece_logps/rejected': -356.2732238769531, 'referece_logps/chosen': -475.6078186035156, 'logits/rejected': -0.12698523700237274, 'logits/chosen': -0.025660108774900436, 'epoch': 5.27}


 88%|████████▊ | 14149/16104 [65:20:14<9:17:08, 17.10s/it]

 88%|████████▊ | 14150/16104 [65:20:27<8:28:16, 15.61s/it]
{'loss': 0.5729, 'learning_rate': 7.623596107974284e-08, 'rewards/chosen': -0.8681659698486328, 'rewards/rejected': -1.0972224473953247, 'rewards/accuracies': 0.375, 'rewards/margins': 0.22905640304088593, 'policy_logps/rejected': -318.0707092285156, 'policy_logps/chosen': -423.062744140625, 'referece_logps/rejected': -307.0984802246094, 'referece_logps/chosen': -414.3810729980469, 'logits/rejected': -0.5016105771064758, 'logits/chosen': -0.5563228726387024, 'epoch': 5.27}

 88%|████████▊ | 14151/16104 [65:20:41<8:17:04, 15.27s/it]


 88%|████████▊ | 14153/16104 [65:21:10<8:04:44, 14.91s/it]

 88%|████████▊ | 14154/16104 [65:21:29<8:48:53, 16.27s/it]
{'loss': 0.351, 'learning_rate': 7.592816503839617e-08, 'rewards/chosen': -0.582514762878418, 'rewards/rejected': -1.815006136894226, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2324912548065186, 'policy_logps/rejected': -462.0684814453125, 'policy_logps/chosen': -573.0377197265625, 'referece_logps/rejected': -443.91839599609375, 'referece_logps/chosen': -567.2125854492188, 'logits/rejected': -0.06381133943796158, 'logits/chosen': -0.07622057944536209, 'epoch': 5.27}


 88%|████████▊ | 14156/16104 [65:22:00<8:42:55, 16.11s/it]

 88%|████████▊ | 14157/16104 [65:22:20<9:15:55, 17.13s/it]

 88%|████████▊ | 14158/16104 [65:22:36<9:10:28, 16.97s/it]

 88%|████████▊ | 14159/16104 [65:22:52<8:59:31, 16.64s/it]

 88%|████████▊ | 14160/16104 [65:23:04<8:12:08, 15.19s/it]

 88%|████████▊ | 14161/16104 [65:23:21<8:26:52, 15.65s/it]

 88%|████████▊ | 14162/16104 [65:23:40<8:59:43, 16.68s/it]
{'loss': 0.3494, 'learning_rate': 7.531436741146602e-08, 'rewards/chosen': -0.37171539664268494, 'rewards/rejected': -1.6549675464630127, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2832521200180054, 'policy_logps/rejected': -415.414306640625, 'policy_logps/chosen': -356.6703796386719, 'referece_logps/rejected': -398.8645935058594, 'referece_logps/chosen': -352.95318603515625, 'logits/rejected': -0.041878484189510345, 'logits/chosen': 0.15090282261371613, 'epoch': 5.28}

 88%|████████▊ | 14163/16104 [65:23:51<8:12:04, 15.21s/it]


 88%|████████▊ | 14165/16104 [65:24:28<9:06:34, 16.91s/it]

 88%|████████▊ | 14166/16104 [65:24:48<9:32:11, 17.72s/it]

 88%|████████▊ | 14167/16104 [65:25:01<8:42:50, 16.20s/it]

 88%|████████▊ | 14168/16104 [65:25:14<8:17:32, 15.42s/it]
{'loss': 0.5296, 'learning_rate': 7.485559012199061e-08, 'rewards/chosen': -0.33232611417770386, 'rewards/rejected': -2.097668409347534, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7653422355651855, 'policy_logps/rejected': -284.4185485839844, 'policy_logps/chosen': -552.186279296875, 'referece_logps/rejected': -263.4418640136719, 'referece_logps/chosen': -548.8630981445312, 'logits/rejected': -0.5778542757034302, 'logits/chosen': -0.7963976263999939, 'epoch': 5.28}


 88%|████████▊ | 14170/16104 [65:25:51<9:01:33, 16.80s/it]
{'loss': 0.4521, 'learning_rate': 7.470296371579898e-08, 'rewards/chosen': -0.9316737651824951, 'rewards/rejected': -1.7900344133377075, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8583605885505676, 'policy_logps/rejected': -505.3905029296875, 'policy_logps/chosen': -379.9586181640625, 'referece_logps/rejected': -487.4901428222656, 'referece_logps/chosen': -370.64190673828125, 'logits/rejected': -0.4294194281101227, 'logits/chosen': -0.35477566719055176, 'epoch': 5.28}

 88%|████████▊ | 14171/16104 [65:26:01<8:01:46, 14.95s/it]


 88%|████████▊ | 14173/16104 [65:26:31<7:54:21, 14.74s/it]

 88%|████████▊ | 14174/16104 [65:26:42<7:16:42, 13.58s/it]

 88%|████████▊ | 14175/16104 [65:26:53<6:50:20, 12.76s/it]
{'loss': 0.6807, 'learning_rate': 7.432205277781179e-08, 'rewards/chosen': -0.4944133758544922, 'rewards/rejected': -1.5101838111877441, 'rewards/accuracies': 0.75, 'rewards/margins': 1.015770435333252, 'policy_logps/rejected': -562.5117797851562, 'policy_logps/chosen': -497.59295654296875, 'referece_logps/rejected': -547.4100341796875, 'referece_logps/chosen': -492.64886474609375, 'logits/rejected': 0.04605173319578171, 'logits/chosen': 0.06297214329242706, 'epoch': 5.28}


 88%|████████▊ | 14177/16104 [65:27:19<7:06:01, 13.26s/it]

 88%|████████▊ | 14178/16104 [65:27:35<7:28:55, 13.99s/it]

 88%|████████▊ | 14179/16104 [65:27:54<8:22:45, 15.67s/it]

 88%|████████▊ | 14180/16104 [65:28:05<7:34:54, 14.19s/it]

 88%|████████▊ | 14181/16104 [65:28:17<7:14:12, 13.55s/it]

 88%|████████▊ | 14182/16104 [65:28:37<8:15:58, 15.48s/it]

 88%|████████▊ | 14183/16104 [65:28:57<8:58:18, 16.81s/it]
{'loss': 0.3694, 'learning_rate': 7.371454259365972e-08, 'rewards/chosen': -0.9650322198867798, 'rewards/rejected': -2.2480878829956055, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2830557823181152, 'policy_logps/rejected': -366.0513000488281, 'policy_logps/chosen': -414.9136047363281, 'referece_logps/rejected': -343.5704345703125, 'referece_logps/chosen': -405.26324462890625, 'logits/rejected': -0.44838854670524597, 'logits/chosen': -0.27406740188598633, 'epoch': 5.28}


 88%|████████▊ | 14185/16104 [65:29:39<10:00:53, 18.79s/it]

 88%|████████▊ | 14186/16104 [65:29:54<9:27:18, 17.75s/it]

 88%|████████▊ | 14187/16104 [65:30:14<9:45:28, 18.32s/it]

 88%|████████▊ | 14188/16104 [65:30:31<9:35:51, 18.03s/it]
{'loss': 0.4545, 'learning_rate': 7.333606640046964e-08, 'rewards/chosen': -0.924856960773468, 'rewards/rejected': -2.0549533367156982, 'rewards/accuracies': 0.75, 'rewards/margins': 1.130096435546875, 'policy_logps/rejected': -336.88372802734375, 'policy_logps/chosen': -526.107177734375, 'referece_logps/rejected': -316.3341979980469, 'referece_logps/chosen': -516.8585815429688, 'logits/rejected': -0.13115674257278442, 'logits/chosen': -0.2446419596672058, 'epoch': 5.29}


 88%|████████▊ | 14190/16104 [65:31:09<9:48:22, 18.44s/it]

 88%|████████▊ | 14191/16104 [65:31:21<8:48:08, 16.56s/it]

 88%|████████▊ | 14192/16104 [65:31:41<9:20:45, 17.60s/it]

 88%|████████▊ | 14193/16104 [65:31:54<8:37:30, 16.25s/it]

 88%|████████▊ | 14194/16104 [65:32:09<8:22:57, 15.80s/it]
{'loss': 0.3328, 'learning_rate': 7.288313201407792e-08, 'rewards/chosen': 0.14795628190040588, 'rewards/rejected': -1.596670389175415, 'rewards/accuracies': 0.875, 'rewards/margins': 1.744626522064209, 'policy_logps/rejected': -307.93408203125, 'policy_logps/chosen': -463.84906005859375, 'referece_logps/rejected': -291.9673767089844, 'referece_logps/chosen': -465.32861328125, 'logits/rejected': -0.20850127935409546, 'logits/chosen': -0.16436806321144104, 'epoch': 5.29}


 88%|████████▊ | 14196/16104 [65:32:39<8:18:58, 15.69s/it]

 88%|████████▊ | 14197/16104 [65:32:57<8:42:36, 16.44s/it]
{'loss': 0.4207, 'learning_rate': 7.265717107735326e-08, 'rewards/chosen': -0.2673225402832031, 'rewards/rejected': -2.125056266784668, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8577337265014648, 'policy_logps/rejected': -414.0074462890625, 'policy_logps/chosen': -477.4838562011719, 'referece_logps/rejected': -392.7568359375, 'referece_logps/chosen': -474.81060791015625, 'logits/rejected': -0.18357178568840027, 'logits/chosen': -0.14640942215919495, 'epoch': 5.29}

 88%|████████▊ | 14198/16104 [65:33:12<8:21:18, 15.78s/it]


 88%|████████▊ | 14200/16104 [65:33:44<8:18:46, 15.72s/it]
{'loss': 0.3994, 'learning_rate': 7.243154775466976e-08, 'rewards/chosen': -0.9100778102874756, 'rewards/rejected': -1.3637808561325073, 'rewards/accuracies': 0.75, 'rewards/margins': 0.45370304584503174, 'policy_logps/rejected': -316.869384765625, 'policy_logps/chosen': -369.00341796875, 'referece_logps/rejected': -303.2315979003906, 'referece_logps/chosen': -359.90264892578125, 'logits/rejected': -0.2640184760093689, 'logits/chosen': -0.30132660269737244, 'epoch': 5.29}


 88%|████████▊ | 14202/16104 [65:34:16<8:33:30, 16.20s/it]

 88%|████████▊ | 14203/16104 [65:34:35<9:01:24, 17.09s/it]

 88%|████████▊ | 14204/16104 [65:34:51<8:45:26, 16.59s/it]
{'loss': 0.4062, 'learning_rate': 7.213124197711173e-08, 'rewards/chosen': 0.10005530714988708, 'rewards/rejected': -1.3368874788284302, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4369425773620605, 'policy_logps/rejected': -560.4000244140625, 'policy_logps/chosen': -575.6909790039062, 'referece_logps/rejected': -547.0311889648438, 'referece_logps/chosen': -576.6915283203125, 'logits/rejected': 0.0733855664730072, 'logits/chosen': 0.27829796075820923, 'epoch': 5.29}

 88%|████████▊ | 14205/16104 [65:35:12<9:29:06, 17.98s/it]


 88%|████████▊ | 14207/16104 [65:35:46<9:12:59, 17.49s/it]

 88%|████████▊ | 14208/16104 [65:36:05<9:21:05, 17.76s/it]
{'loss': 0.4654, 'learning_rate': 7.183153674267595e-08, 'rewards/chosen': -0.7892873883247375, 'rewards/rejected': -1.2032727003097534, 'rewards/accuracies': 0.25, 'rewards/margins': 0.41398534178733826, 'policy_logps/rejected': -367.26605224609375, 'policy_logps/chosen': -399.92205810546875, 'referece_logps/rejected': -355.2333068847656, 'referece_logps/chosen': -392.0291748046875, 'logits/rejected': -0.47429588437080383, 'logits/chosen': -0.4170325994491577, 'epoch': 5.29}


 88%|████████▊ | 14210/16104 [65:36:36<8:39:26, 16.46s/it]
{'loss': 0.39, 'learning_rate': 7.168190938976215e-08, 'rewards/chosen': -0.9915899038314819, 'rewards/rejected': -2.1195404529571533, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1279504299163818, 'policy_logps/rejected': -573.2168579101562, 'policy_logps/chosen': -594.4798583984375, 'referece_logps/rejected': -552.0214233398438, 'referece_logps/chosen': -584.56396484375, 'logits/rejected': 0.17576831579208374, 'logits/chosen': 0.19311043620109558, 'epoch': 5.29}


 88%|████████▊ | 14212/16104 [65:37:06<8:25:17, 16.02s/it]

 88%|████████▊ | 14213/16104 [65:37:19<7:56:54, 15.13s/it]
{'loss': 0.35, 'learning_rate': 7.145775000887277e-08, 'rewards/chosen': 0.4521852731704712, 'rewards/rejected': -0.8769432306289673, 'rewards/accuracies': 1.0, 'rewards/margins': 1.329128384590149, 'policy_logps/rejected': -512.7845458984375, 'policy_logps/chosen': -532.1423950195312, 'referece_logps/rejected': -504.01513671875, 'referece_logps/chosen': -536.6642456054688, 'logits/rejected': 0.00022224336862564087, 'logits/chosen': -0.03566823899745941, 'epoch': 5.3}


 88%|████████▊ | 14215/16104 [65:37:47<7:36:09, 14.49s/it]
{'loss': 0.4813, 'learning_rate': 7.13084982225306e-08, 'rewards/chosen': -0.4600563049316406, 'rewards/rejected': -0.9509658813476562, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4909095764160156, 'policy_logps/rejected': -452.63580322265625, 'policy_logps/chosen': -608.4651489257812, 'referece_logps/rejected': -443.1260986328125, 'referece_logps/chosen': -603.8646240234375, 'logits/rejected': -0.11922555416822433, 'logits/chosen': -0.23787765204906464, 'epoch': 5.3}


 88%|████████▊ | 14217/16104 [65:38:11<6:58:12, 13.30s/it]
{'loss': 0.3179, 'learning_rate': 7.115939670510063e-08, 'rewards/chosen': -0.4092909097671509, 'rewards/rejected': -1.5952866077423096, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1859956979751587, 'policy_logps/rejected': -373.496826171875, 'policy_logps/chosen': -351.12457275390625, 'referece_logps/rejected': -357.5439453125, 'referece_logps/chosen': -347.03167724609375, 'logits/rejected': -0.2843543589115143, 'logits/chosen': -0.19421887397766113, 'epoch': 5.3}


 88%|████████▊ | 14219/16104 [65:38:44<7:43:09, 14.74s/it]

 88%|████████▊ | 14220/16104 [65:39:03<8:28:11, 16.18s/it]
{'loss': 0.4532, 'learning_rate': 7.09360262359352e-08, 'rewards/chosen': -0.8646679520606995, 'rewards/rejected': -1.7214568853378296, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8567889928817749, 'policy_logps/rejected': -672.983642578125, 'policy_logps/chosen': -552.4020385742188, 'referece_logps/rejected': -655.76904296875, 'referece_logps/chosen': -543.7553100585938, 'logits/rejected': 0.3319307267665863, 'logits/chosen': 0.25951844453811646, 'epoch': 5.3}


 88%|████████▊ | 14222/16104 [65:39:35<8:40:03, 16.58s/it]

 88%|████████▊ | 14223/16104 [65:39:47<7:56:46, 15.21s/it]

 88%|████████▊ | 14224/16104 [65:40:07<8:40:36, 16.62s/it]

 88%|████████▊ | 14225/16104 [65:40:18<7:44:26, 14.83s/it]

 88%|████████▊ | 14226/16104 [65:40:36<8:13:30, 15.77s/it]

 88%|████████▊ | 14227/16104 [65:40:56<8:51:05, 16.98s/it]

 88%|████████▊ | 14228/16104 [65:41:12<8:44:58, 16.79s/it]

 88%|████████▊ | 14229/16104 [65:41:29<8:48:27, 16.91s/it]
{'loss': 0.3344, 'learning_rate': 7.026794459701923e-08, 'rewards/chosen': -1.1956733465194702, 'rewards/rejected': -2.455091714859009, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2594184875488281, 'policy_logps/rejected': -264.5582580566406, 'policy_logps/chosen': -615.0853271484375, 'referece_logps/rejected': -240.00733947753906, 'referece_logps/chosen': -603.128662109375, 'logits/rejected': -0.39706456661224365, 'logits/chosen': -0.31482839584350586, 'epoch': 5.3}


 88%|████████▊ | 14231/16104 [65:41:59<8:06:21, 15.58s/it]

 88%|████████▊ | 14232/16104 [65:42:20<8:54:54, 17.14s/it]

 88%|████████▊ | 14233/16104 [65:42:34<8:25:21, 16.21s/it]

 88%|████████▊ | 14234/16104 [65:42:45<7:39:53, 14.76s/it]

 88%|████████▊ | 14235/16104 [65:43:03<8:07:27, 15.65s/it]

 88%|████████▊ | 14236/16104 [65:43:19<8:11:55, 15.80s/it]

 88%|████████▊ | 14237/16104 [65:43:40<8:58:12, 17.30s/it]

 88%|████████▊ | 14238/16104 [65:44:01<9:33:42, 18.45s/it]

 88%|████████▊ | 14239/16104 [65:44:21<9:46:29, 18.87s/it]

 88%|████████▊ | 14240/16104 [65:44:40<9:47:47, 18.92s/it]

 88%|████████▊ | 14241/16104 [65:44:58<9:32:51, 18.45s/it]

 88%|████████▊ | 14242/16104 [65:45:14<9:10:12, 17.73s/it]

 88%|████████▊ | 14243/16104 [65:45:34<9:32:40, 18.46s/it]

 88%|████████▊ | 14244/16104 [65:45:46<8:34:49, 16.61s/it]

 88%|████████▊ | 14245/16104 [65:46:06<9:03:00, 17.53s/it]

 88%|████████▊ | 14246/16104 [65:46:19<8:26:52, 16.37s/it]

 88%|████████▊ | 14247/16104 [65:46:32<7:53:25, 15.30s/it]
{'loss': 0.5521, 'learning_rate': 6.894092256071283e-08, 'rewards/chosen': 0.023212049156427383, 'rewards/rejected': -0.5712636709213257, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5944756269454956, 'policy_logps/rejected': -425.455322265625, 'policy_logps/chosen': -473.62615966796875, 'referece_logps/rejected': -419.74267578125, 'referece_logps/chosen': -473.8582763671875, 'logits/rejected': -0.04658084362745285, 'logits/chosen': -0.06719540059566498, 'epoch': 5.31}


 88%|████████▊ | 14249/16104 [65:46:54<6:40:57, 12.97s/it]
{'loss': 0.4569, 'learning_rate': 6.879422861042982e-08, 'rewards/chosen': -1.111647367477417, 'rewards/rejected': -3.061285972595215, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9496383666992188, 'policy_logps/rejected': -350.66229248046875, 'policy_logps/chosen': -474.9422912597656, 'referece_logps/rejected': -320.0494384765625, 'referece_logps/chosen': -463.8257751464844, 'logits/rejected': -0.47618281841278076, 'logits/chosen': -0.253622442483902, 'epoch': 5.31}


 88%|████████▊ | 14251/16104 [65:47:15<6:06:56, 11.88s/it]

 88%|████████▊ | 14252/16104 [65:47:26<5:55:30, 11.52s/it]

 89%|████████▊ | 14253/16104 [65:47:42<6:40:12, 12.97s/it]

 89%|████████▊ | 14254/16104 [65:47:54<6:26:45, 12.54s/it]
{'loss': 0.4243, 'learning_rate': 6.842815299294446e-08, 'rewards/chosen': -0.9443666934967041, 'rewards/rejected': -2.4838361740112305, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5394692420959473, 'policy_logps/rejected': -466.1833190917969, 'policy_logps/chosen': -462.32818603515625, 'referece_logps/rejected': -441.3449401855469, 'referece_logps/chosen': -452.8845520019531, 'logits/rejected': -0.16272073984146118, 'logits/chosen': -0.13373655080795288, 'epoch': 5.31}


 89%|████████▊ | 14256/16104 [65:48:15<5:58:00, 11.62s/it]
{'loss': 0.4476, 'learning_rate': 6.828198651143424e-08, 'rewards/chosen': -0.7491167783737183, 'rewards/rejected': -1.9688934087753296, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2197763919830322, 'policy_logps/rejected': -289.91796875, 'policy_logps/chosen': -295.6396789550781, 'referece_logps/rejected': -270.2290344238281, 'referece_logps/chosen': -288.14849853515625, 'logits/rejected': -0.6909531950950623, 'logits/chosen': -0.6204054355621338, 'epoch': 5.31}

 89%|████████▊ | 14257/16104 [65:48:29<6:15:02, 12.18s/it]


 89%|████████▊ | 14259/16104 [65:49:00<6:57:27, 13.58s/it]

 89%|████████▊ | 14260/16104 [65:49:19<7:54:56, 15.45s/it]

 89%|████████▊ | 14261/16104 [65:49:35<7:59:01, 15.59s/it]

 89%|████████▊ | 14262/16104 [65:49:52<8:09:17, 15.94s/it]
{'loss': 0.4043, 'learning_rate': 6.784439171312662e-08, 'rewards/chosen': -0.23738420009613037, 'rewards/rejected': -2.248241662979126, 'rewards/accuracies': 1.0, 'rewards/margins': 2.010857343673706, 'policy_logps/rejected': -343.5174560546875, 'policy_logps/chosen': -459.74090576171875, 'referece_logps/rejected': -321.0350036621094, 'referece_logps/chosen': -457.3670654296875, 'logits/rejected': -0.0909091904759407, 'logits/chosen': -0.24519690871238708, 'epoch': 5.31}


 89%|████████▊ | 14264/16104 [65:50:24<8:00:32, 15.67s/it]
{'loss': 0.4077, 'learning_rate': 6.769882840777175e-08, 'rewards/chosen': -0.8085097670555115, 'rewards/rejected': -2.527906894683838, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7193970680236816, 'policy_logps/rejected': -373.1544189453125, 'policy_logps/chosen': -400.2340087890625, 'referece_logps/rejected': -347.87530517578125, 'referece_logps/chosen': -392.1488952636719, 'logits/rejected': -0.5906659364700317, 'logits/chosen': -0.6618691682815552, 'epoch': 5.31}

 89%|████████▊ | 14265/16104 [65:50:43<8:28:45, 16.60s/it]

 89%|████████▊ | 14266/16104 [65:50:55<7:44:14, 15.15s/it]


 89%|████████▊ | 14268/16104 [65:51:37<9:13:57, 18.10s/it]
{'loss': 0.3728, 'learning_rate': 6.740815437953895e-08, 'rewards/chosen': -1.0741207599639893, 'rewards/rejected': -3.203672409057617, 'rewards/accuracies': 0.75, 'rewards/margins': 2.129551887512207, 'policy_logps/rejected': -398.8798828125, 'policy_logps/chosen': -376.98345947265625, 'referece_logps/rejected': -366.8431396484375, 'referece_logps/chosen': -366.24224853515625, 'logits/rejected': -0.8421332240104675, 'logits/chosen': -0.7628217935562134, 'epoch': 5.32}


 89%|████████▊ | 14270/16104 [65:52:02<7:52:48, 15.47s/it]
{'loss': 0.4008, 'learning_rate': 6.726304370369407e-08, 'rewards/chosen': 0.31740668416023254, 'rewards/rejected': -1.4683408737182617, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7857475280761719, 'policy_logps/rejected': -466.95001220703125, 'policy_logps/chosen': -509.4370422363281, 'referece_logps/rejected': -452.2666015625, 'referece_logps/chosen': -512.611083984375, 'logits/rejected': 0.6159309148788452, 'logits/chosen': 0.6908133029937744, 'epoch': 5.32}


 89%|████████▊ | 14272/16104 [65:52:35<7:55:57, 15.59s/it]
{'loss': 0.4409, 'learning_rate': 6.711808395134522e-08, 'rewards/chosen': -0.5020057559013367, 'rewards/rejected': -0.924486517906189, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4224807620048523, 'policy_logps/rejected': -508.5605773925781, 'policy_logps/chosen': -528.1578369140625, 'referece_logps/rejected': -499.3157653808594, 'referece_logps/chosen': -523.1377563476562, 'logits/rejected': -0.7299652695655823, 'logits/chosen': -0.5664682984352112, 'epoch': 5.32}


 89%|████████▊ | 14274/16104 [65:52:56<6:38:35, 13.07s/it]
{'loss': 0.5033, 'learning_rate': 6.697327514594786e-08, 'rewards/chosen': -0.4385921359062195, 'rewards/rejected': -1.2984286546707153, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8598363995552063, 'policy_logps/rejected': -342.18560791015625, 'policy_logps/chosen': -479.6165771484375, 'referece_logps/rejected': -329.2013244628906, 'referece_logps/chosen': -475.23065185546875, 'logits/rejected': 0.08185490220785141, 'logits/chosen': -0.2235497087240219, 'epoch': 5.32}

 89%|████████▊ | 14275/16104 [65:53:11<7:00:42, 13.80s/it]

 89%|████████▊ | 14276/16104 [65:53:23<6:40:18, 13.14s/it]

 89%|████████▊ | 14277/16104 [65:53:37<6:47:57, 13.40s/it]


 89%|████████▊ | 14279/16104 [65:54:10<7:43:22, 15.23s/it]
{'loss': 0.3588, 'learning_rate': 6.661191367907271e-08, 'rewards/chosen': 0.007128894329071045, 'rewards/rejected': -1.1164013147354126, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1235302686691284, 'policy_logps/rejected': -599.7791137695312, 'policy_logps/chosen': -678.4198608398438, 'referece_logps/rejected': -588.6150512695312, 'referece_logps/chosen': -678.4910888671875, 'logits/rejected': 0.16358798742294312, 'logits/chosen': 0.034856896847486496, 'epoch': 5.32}

 89%|████████▊ | 14280/16104 [65:54:27<7:59:35, 15.78s/it]


 89%|████████▊ | 14282/16104 [65:54:54<7:28:43, 14.78s/it]

 89%|████████▊ | 14283/16104 [65:55:12<7:55:49, 15.68s/it]
{'loss': 0.4363, 'learning_rate': 6.632350411785514e-08, 'rewards/chosen': -0.1943558007478714, 'rewards/rejected': -2.11047101020813, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9161152839660645, 'policy_logps/rejected': -526.2264404296875, 'policy_logps/chosen': -489.8056640625, 'referece_logps/rejected': -505.1217041015625, 'referece_logps/chosen': -487.8620910644531, 'logits/rejected': 0.23624040186405182, 'logits/chosen': 0.1085541695356369, 'epoch': 5.32}


 89%|████████▊ | 14285/16104 [65:55:49<8:39:19, 17.13s/it]
{'loss': 0.3833, 'learning_rate': 6.617952593886611e-08, 'rewards/chosen': -1.2206112146377563, 'rewards/rejected': -2.7525110244750977, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5318996906280518, 'policy_logps/rejected': -441.04571533203125, 'policy_logps/chosen': -438.41717529296875, 'referece_logps/rejected': -413.5206298828125, 'referece_logps/chosen': -426.2110900878906, 'logits/rejected': -0.5125364661216736, 'logits/chosen': -0.589108943939209, 'epoch': 5.32}

 89%|████████▊ | 14286/16104 [65:56:05<8:31:19, 16.88s/it]

 89%|████████▊ | 14287/16104 [65:56:22<8:28:16, 16.78s/it]

 89%|████████▊ | 14288/16104 [65:56:41<8:55:53, 17.71s/it]

 89%|████████▊ | 14289/16104 [65:56:54<8:09:12, 16.17s/it]

 89%|████████▊ | 14290/16104 [65:57:08<7:46:44, 15.44s/it]


 89%|████████▊ | 14292/16104 [65:57:42<8:11:49, 16.29s/it]
{'loss': 0.5703, 'learning_rate': 6.567679236824964e-08, 'rewards/chosen': -0.665461003780365, 'rewards/rejected': -2.045984983444214, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3805238008499146, 'policy_logps/rejected': -473.9687194824219, 'policy_logps/chosen': -524.2858276367188, 'referece_logps/rejected': -453.50885009765625, 'referece_logps/chosen': -517.6312866210938, 'logits/rejected': -0.320121705532074, 'logits/chosen': -0.2990236282348633, 'epoch': 5.32}

 89%|████████▉ | 14293/16104 [65:57:58<8:01:31, 15.95s/it]

 89%|████████▉ | 14294/16104 [65:58:10<7:30:02, 14.92s/it]

 89%|████████▉ | 14295/16104 [65:58:23<7:15:20, 14.44s/it]

 89%|████████▉ | 14296/16104 [65:58:38<7:17:54, 14.53s/it]

 89%|████████▉ | 14297/16104 [65:58:56<7:50:26, 15.62s/it]


 89%|████████▉ | 14299/16104 [65:59:28<8:07:41, 16.21s/it]
{'loss': 0.3402, 'learning_rate': 6.51759107543447e-08, 'rewards/chosen': 0.266230970621109, 'rewards/rejected': -2.3091514110565186, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5753822326660156, 'policy_logps/rejected': -393.2518005371094, 'policy_logps/chosen': -530.9649658203125, 'referece_logps/rejected': -370.1602478027344, 'referece_logps/chosen': -533.6272583007812, 'logits/rejected': 0.20341603457927704, 'logits/chosen': 0.21878308057785034, 'epoch': 5.33}


 89%|████████▉ | 14301/16104 [66:00:00<7:55:33, 15.83s/it]

 89%|████████▉ | 14302/16104 [66:00:23<8:52:14, 17.72s/it]

 89%|████████▉ | 14303/16104 [66:00:34<7:59:07, 15.96s/it]
{'loss': 0.3972, 'learning_rate': 6.489052456225064e-08, 'rewards/chosen': -0.3542279303073883, 'rewards/rejected': -1.901852011680603, 'rewards/accuracies': 0.875, 'rewards/margins': 1.547624111175537, 'policy_logps/rejected': -507.1693115234375, 'policy_logps/chosen': -431.69757080078125, 'referece_logps/rejected': -488.1507873535156, 'referece_logps/chosen': -428.1553039550781, 'logits/rejected': 0.3121372163295746, 'logits/chosen': 0.4146004617214203, 'epoch': 5.33}


 89%|████████▉ | 14305/16104 [66:01:07<8:13:03, 16.44s/it]
{'loss': 0.4346, 'learning_rate': 6.474805841574504e-08, 'rewards/chosen': -0.5459516048431396, 'rewards/rejected': -1.62447190284729, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0785202980041504, 'policy_logps/rejected': -465.4859619140625, 'policy_logps/chosen': -413.48931884765625, 'referece_logps/rejected': -449.2412414550781, 'referece_logps/chosen': -408.02984619140625, 'logits/rejected': -0.11475685238838196, 'logits/chosen': 0.202182799577713, 'epoch': 5.33}


 89%|████████▉ | 14307/16104 [66:01:28<6:45:04, 13.53s/it]
{'loss': 0.3758, 'learning_rate': 6.460574359967796e-08, 'rewards/chosen': -0.7489492893218994, 'rewards/rejected': -1.439770221710205, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6908209323883057, 'policy_logps/rejected': -471.7899475097656, 'policy_logps/chosen': -401.7481689453125, 'referece_logps/rejected': -457.39227294921875, 'referece_logps/chosen': -394.2586975097656, 'logits/rejected': -0.9739826321601868, 'logits/chosen': -0.8780782222747803, 'epoch': 5.33}


 89%|████████▉ | 14309/16104 [66:02:03<7:49:09, 15.68s/it]
{'loss': 0.4546, 'learning_rate': 6.446358013707676e-08, 'rewards/chosen': -0.7598893642425537, 'rewards/rejected': -1.8477816581726074, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0878924131393433, 'policy_logps/rejected': -395.96435546875, 'policy_logps/chosen': -396.8829040527344, 'referece_logps/rejected': -377.486572265625, 'referece_logps/chosen': -389.28399658203125, 'logits/rejected': -0.25614213943481445, 'logits/chosen': -0.10814207047224045, 'epoch': 5.33}


 89%|████████▉ | 14311/16104 [66:02:31<7:25:01, 14.89s/it]

 89%|████████▉ | 14312/16104 [66:02:51<8:11:30, 16.46s/it]
{'loss': 0.367, 'learning_rate': 6.425061878123595e-08, 'rewards/chosen': -0.4172375798225403, 'rewards/rejected': -1.9568425416946411, 'rewards/accuracies': 0.75, 'rewards/margins': 1.539604902267456, 'policy_logps/rejected': -420.0047302246094, 'policy_logps/chosen': -461.995361328125, 'referece_logps/rejected': -400.43634033203125, 'referece_logps/chosen': -457.822998046875, 'logits/rejected': -0.09581533074378967, 'logits/chosen': -0.06421495974063873, 'epoch': 5.33}

 89%|████████▉ | 14313/16104 [66:03:10<8:29:48, 17.08s/it]

 89%|████████▉ | 14314/16104 [66:03:27<8:37:08, 17.33s/it]

 89%|████████▉ | 14315/16104 [66:03:46<8:48:14, 17.72s/it]

 89%|████████▉ | 14316/16104 [66:04:04<8:54:11, 17.93s/it]

 89%|████████▉ | 14317/16104 [66:04:26<9:28:42, 19.09s/it]


 89%|████████▉ | 14319/16104 [66:05:05<9:33:33, 19.28s/it]
{'loss': 0.3407, 'learning_rate': 6.375503393030957e-08, 'rewards/chosen': -0.24098855257034302, 'rewards/rejected': -2.0574910640716553, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8165024518966675, 'policy_logps/rejected': -455.8254699707031, 'policy_logps/chosen': -559.6702270507812, 'referece_logps/rejected': -435.2505798339844, 'referece_logps/chosen': -557.2603149414062, 'logits/rejected': -0.06536932289600372, 'logits/chosen': 0.16461524367332458, 'epoch': 5.33}

 89%|████████▉ | 14320/16104 [66:05:24<9:25:58, 19.04s/it]


 89%|████████▉ | 14322/16104 [66:05:57<8:42:47, 17.60s/it]
{'loss': 0.3971, 'learning_rate': 6.354320845722394e-08, 'rewards/chosen': -0.6617442965507507, 'rewards/rejected': -1.4152251482009888, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7534807920455933, 'policy_logps/rejected': -409.909423828125, 'policy_logps/chosen': -414.3176574707031, 'referece_logps/rejected': -395.75714111328125, 'referece_logps/chosen': -407.7001953125, 'logits/rejected': -0.06607170403003693, 'logits/chosen': -0.08398381620645523, 'epoch': 5.34}

 89%|████████▉ | 14323/16104 [66:06:18<9:14:31, 18.68s/it]

 89%|████████▉ | 14324/16104 [66:06:30<8:10:47, 16.54s/it]

 89%|████████▉ | 14325/16104 [66:06:44<7:48:25, 15.80s/it]

 89%|████████▉ | 14326/16104 [66:07:03<8:11:38, 16.59s/it]

 89%|████████▉ | 14327/16104 [66:07:22<8:39:12, 17.53s/it]


 89%|████████▉ | 14329/16104 [66:07:59<8:48:23, 17.86s/it]
{'loss': 0.3827, 'learning_rate': 6.30502750002384e-08, 'rewards/chosen': -0.16342505812644958, 'rewards/rejected': -2.179429531097412, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0160045623779297, 'policy_logps/rejected': -543.5111083984375, 'policy_logps/chosen': -485.84375, 'referece_logps/rejected': -521.7168579101562, 'referece_logps/chosen': -484.2095031738281, 'logits/rejected': -0.010295482352375984, 'logits/chosen': 0.06747830659151077, 'epoch': 5.34}

 89%|████████▉ | 14330/16104 [66:08:18<8:58:28, 18.21s/it]

 89%|████████▉ | 14331/16104 [66:08:32<8:16:23, 16.80s/it]


 89%|████████▉ | 14333/16104 [66:08:56<6:59:16, 14.20s/it]
{'loss': 0.5569, 'learning_rate': 6.27694325047956e-08, 'rewards/chosen': -0.4903409779071808, 'rewards/rejected': -1.1435970067977905, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6532560586929321, 'policy_logps/rejected': -541.0133056640625, 'policy_logps/chosen': -529.6891479492188, 'referece_logps/rejected': -529.577392578125, 'referece_logps/chosen': -524.7857666015625, 'logits/rejected': -0.31970807909965515, 'logits/chosen': -0.25230342149734497, 'epoch': 5.34}


 89%|████████▉ | 14335/16104 [66:09:22<6:33:40, 13.35s/it]
{'loss': 0.5637, 'learning_rate': 6.262923872161107e-08, 'rewards/chosen': 0.5602657794952393, 'rewards/rejected': -1.1333492994308472, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6936153173446655, 'policy_logps/rejected': -411.135009765625, 'policy_logps/chosen': -552.583740234375, 'referece_logps/rejected': -399.8014831542969, 'referece_logps/chosen': -558.1863403320312, 'logits/rejected': -0.026782002300024033, 'logits/chosen': -0.11350758373737335, 'epoch': 5.34}


 89%|████████▉ | 14337/16104 [66:09:45<6:12:34, 12.65s/it]
{'loss': 0.3981, 'learning_rate': 6.248919661170515e-08, 'rewards/chosen': -0.1621866077184677, 'rewards/rejected': -1.8903175592422485, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7281310558319092, 'policy_logps/rejected': -416.09039306640625, 'policy_logps/chosen': -407.8869934082031, 'referece_logps/rejected': -397.18719482421875, 'referece_logps/chosen': -406.26513671875, 'logits/rejected': 0.24921973049640656, 'logits/chosen': 0.1204855665564537, 'epoch': 5.34}


 89%|████████▉ | 14339/16104 [66:10:11<6:15:36, 12.77s/it]

 89%|████████▉ | 14340/16104 [66:10:27<6:40:19, 13.62s/it]

 89%|████████▉ | 14341/16104 [66:10:40<6:32:59, 13.37s/it]
{'loss': 0.3387, 'learning_rate': 6.220956750234363e-08, 'rewards/chosen': -0.7894654870033264, 'rewards/rejected': -3.1846468448638916, 'rewards/accuracies': 1.0, 'rewards/margins': 2.39518141746521, 'policy_logps/rejected': -431.513916015625, 'policy_logps/chosen': -366.30328369140625, 'referece_logps/rejected': -399.66748046875, 'referece_logps/chosen': -358.40863037109375, 'logits/rejected': -0.3672088384628296, 'logits/chosen': -0.42722851037979126, 'epoch': 5.34}


 89%|████████▉ | 14343/16104 [66:11:17<7:56:58, 16.25s/it]
{'loss': 0.3006, 'learning_rate': 6.206998054813418e-08, 'rewards/chosen': -0.13685379922389984, 'rewards/rejected': -1.5087766647338867, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3719227313995361, 'policy_logps/rejected': -432.26507568359375, 'policy_logps/chosen': -349.1154479980469, 'referece_logps/rejected': -417.17730712890625, 'referece_logps/chosen': -347.7469177246094, 'logits/rejected': -0.39327675104141235, 'logits/chosen': -0.4804370403289795, 'epoch': 5.34}


 89%|████████▉ | 14345/16104 [66:11:46<7:25:17, 15.19s/it]
{'loss': 0.5466, 'learning_rate': 6.193054535769504e-08, 'rewards/chosen': -0.6900134682655334, 'rewards/rejected': -1.3303292989730835, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6403156518936157, 'policy_logps/rejected': -420.97882080078125, 'policy_logps/chosen': -551.6537475585938, 'referece_logps/rejected': -407.6755676269531, 'referece_logps/chosen': -544.7536010742188, 'logits/rejected': 0.5058261156082153, 'logits/chosen': 0.4479810297489166, 'epoch': 5.34}

 89%|████████▉ | 14346/16104 [66:11:59<7:05:06, 14.51s/it]

 89%|████████▉ | 14347/16104 [66:12:18<7:49:14, 16.02s/it]

 89%|████████▉ | 14348/16104 [66:12:30<7:13:21, 14.81s/it]


 89%|████████▉ | 14350/16104 [66:13:10<8:24:39, 17.26s/it]
{'loss': 0.3532, 'learning_rate': 6.158262149609361e-08, 'rewards/chosen': -1.1707843542099, 'rewards/rejected': -2.595125436782837, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4243412017822266, 'policy_logps/rejected': -283.05615234375, 'policy_logps/chosen': -396.6776123046875, 'referece_logps/rejected': -257.1048889160156, 'referece_logps/chosen': -384.96978759765625, 'logits/rejected': -0.7900021076202393, 'logits/chosen': -0.8500301837921143, 'epoch': 5.35}


 89%|████████▉ | 14352/16104 [66:13:42<8:09:27, 16.76s/it]

 89%|████████▉ | 14353/16104 [66:14:03<8:51:27, 18.21s/it]
{'loss': 0.4234, 'learning_rate': 6.137432268450793e-08, 'rewards/chosen': -0.5436582565307617, 'rewards/rejected': -2.798342227935791, 'rewards/accuracies': 1.0, 'rewards/margins': 2.254683494567871, 'policy_logps/rejected': -378.814453125, 'policy_logps/chosen': -497.6593322753906, 'referece_logps/rejected': -350.8310546875, 'referece_logps/chosen': -492.2227478027344, 'logits/rejected': -0.5356377959251404, 'logits/chosen': -0.7064615488052368, 'epoch': 5.35}


 89%|████████▉ | 14355/16104 [66:14:33<7:58:27, 16.41s/it]
{'loss': 0.3143, 'learning_rate': 6.123564665085423e-08, 'rewards/chosen': -0.7674698829650879, 'rewards/rejected': -2.666527271270752, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8990575075149536, 'policy_logps/rejected': -495.0138854980469, 'policy_logps/chosen': -584.1963500976562, 'referece_logps/rejected': -468.3486633300781, 'referece_logps/chosen': -576.5216674804688, 'logits/rejected': -0.32726505398750305, 'logits/chosen': -0.20806100964546204, 'epoch': 5.35}


 89%|████████▉ | 14357/16104 [66:15:04<7:28:53, 15.42s/it]

 89%|████████▉ | 14358/16104 [66:15:15<6:53:28, 14.21s/it]
{'loss': 0.3625, 'learning_rate': 6.102791741757607e-08, 'rewards/chosen': 0.0199701189994812, 'rewards/rejected': -1.5035603046417236, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5235304832458496, 'policy_logps/rejected': -358.5436706542969, 'policy_logps/chosen': -379.5263671875, 'referece_logps/rejected': -343.508056640625, 'referece_logps/chosen': -379.72607421875, 'logits/rejected': -0.7775826454162598, 'logits/chosen': -0.5845128297805786, 'epoch': 5.35}


 89%|████████▉ | 14360/16104 [66:15:44<6:58:43, 14.41s/it]

 89%|████████▉ | 14361/16104 [66:15:58<6:56:53, 14.35s/it]

 89%|████████▉ | 14362/16104 [66:16:14<7:07:55, 14.74s/it]

 89%|████████▉ | 14363/16104 [66:16:34<7:54:32, 16.35s/it]

 89%|████████▉ | 14364/16104 [66:16:46<7:16:14, 15.04s/it]

 89%|████████▉ | 14365/16104 [66:17:02<7:28:28, 15.47s/it]

 89%|████████▉ | 14366/16104 [66:17:17<7:26:22, 15.41s/it]
{'loss': 0.4547, 'learning_rate': 6.047564425670748e-08, 'rewards/chosen': -0.28048211336135864, 'rewards/rejected': -1.0309324264526367, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7504502534866333, 'policy_logps/rejected': -337.1184997558594, 'policy_logps/chosen': -506.00872802734375, 'referece_logps/rejected': -326.8091735839844, 'referece_logps/chosen': -503.20391845703125, 'logits/rejected': 0.1736004650592804, 'logits/chosen': 0.07547993957996368, 'epoch': 5.35}


 89%|████████▉ | 14368/16104 [66:17:50<7:23:09, 15.32s/it]
{'loss': 0.4527, 'learning_rate': 6.033795596506453e-08, 'rewards/chosen': -0.5669370889663696, 'rewards/rejected': -1.9223031997680664, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3553661108016968, 'policy_logps/rejected': -370.95867919921875, 'policy_logps/chosen': -368.6544189453125, 'referece_logps/rejected': -351.73565673828125, 'referece_logps/chosen': -362.98504638671875, 'logits/rejected': -0.35699036717414856, 'logits/chosen': -0.27520155906677246, 'epoch': 5.35}


 89%|████████▉ | 14370/16104 [66:18:24<7:37:16, 15.82s/it]

 89%|████████▉ | 14371/16104 [66:18:42<7:55:51, 16.48s/it]
{'loss': 0.4665, 'learning_rate': 6.013170861710126e-08, 'rewards/chosen': -0.35712945461273193, 'rewards/rejected': -1.5219166278839111, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1647870540618896, 'policy_logps/rejected': -487.3057861328125, 'policy_logps/chosen': -518.47607421875, 'referece_logps/rejected': -472.08660888671875, 'referece_logps/chosen': -514.90478515625, 'logits/rejected': 0.36822590231895447, 'logits/chosen': 0.33312833309173584, 'epoch': 5.35}

 89%|████████▉ | 14372/16104 [66:18:54<7:16:06, 15.11s/it]


 89%|████████▉ | 14374/16104 [66:19:34<8:36:51, 17.93s/it]

 89%|████████▉ | 14375/16104 [66:19:52<8:37:07, 17.95s/it]

 89%|████████▉ | 14376/16104 [66:20:14<9:12:16, 19.18s/it]

 89%|████████▉ | 14377/16104 [66:20:34<9:17:19, 19.36s/it]
{'loss': 0.3663, 'learning_rate': 5.972024051854873e-08, 'rewards/chosen': -0.4172954559326172, 'rewards/rejected': -2.42140531539917, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0041098594665527, 'policy_logps/rejected': -537.538818359375, 'policy_logps/chosen': -545.9806518554688, 'referece_logps/rejected': -513.32470703125, 'referece_logps/chosen': -541.8077392578125, 'logits/rejected': -0.5138623118400574, 'logits/chosen': -0.4586150646209717, 'epoch': 5.36}

 89%|████████▉ | 14378/16104 [66:20:49<8:35:00, 17.90s/it]

 89%|████████▉ | 14379/16104 [66:21:11<9:11:19, 19.18s/it]


 89%|████████▉ | 14381/16104 [66:21:38<7:49:13, 16.34s/it]
{'loss': 0.3391, 'learning_rate': 5.944668913573514e-08, 'rewards/chosen': -0.42392024397850037, 'rewards/rejected': -1.946984052658081, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5230638980865479, 'policy_logps/rejected': -418.5054626464844, 'policy_logps/chosen': -445.32830810546875, 'referece_logps/rejected': -399.03558349609375, 'referece_logps/chosen': -441.089111328125, 'logits/rejected': -0.0973304808139801, 'logits/chosen': 0.001535056158900261, 'epoch': 5.36}

 89%|████████▉ | 14382/16104 [66:21:54<7:44:26, 16.18s/it]

 89%|████████▉ | 14383/16104 [66:22:14<8:16:23, 17.31s/it]

 89%|████████▉ | 14384/16104 [66:22:34<8:35:57, 18.00s/it]

 89%|████████▉ | 14385/16104 [66:22:53<8:44:31, 18.31s/it]

 89%|████████▉ | 14386/16104 [66:23:13<9:02:39, 18.95s/it]


 89%|████████▉ | 14388/16104 [66:23:54<9:26:22, 19.80s/it]
{'loss': 0.4063, 'learning_rate': 5.896943913382546e-08, 'rewards/chosen': -0.9338595867156982, 'rewards/rejected': -1.4449820518493652, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5111225843429565, 'policy_logps/rejected': -303.778564453125, 'policy_logps/chosen': -378.77459716796875, 'referece_logps/rejected': -289.3287353515625, 'referece_logps/chosen': -369.43597412109375, 'logits/rejected': -0.42336976528167725, 'logits/chosen': -0.47652482986450195, 'epoch': 5.36}

 89%|████████▉ | 14389/16104 [66:24:14<9:26:33, 19.82s/it]


 89%|████████▉ | 14391/16104 [66:24:51<9:04:11, 19.06s/it]
{'loss': 0.3759, 'learning_rate': 5.876547435908252e-08, 'rewards/chosen': -0.7329153418540955, 'rewards/rejected': -2.268179416656494, 'rewards/accuracies': 0.625, 'rewards/margins': 1.535264015197754, 'policy_logps/rejected': -548.1214599609375, 'policy_logps/chosen': -428.7973937988281, 'referece_logps/rejected': -525.439697265625, 'referece_logps/chosen': -421.46826171875, 'logits/rejected': -0.25816917419433594, 'logits/chosen': -0.02800893783569336, 'epoch': 5.36}

 89%|████████▉ | 14392/16104 [66:25:02<7:57:20, 16.73s/it]

 89%|████████▉ | 14393/16104 [66:25:20<8:08:16, 17.12s/it]

 89%|████████▉ | 14394/16104 [66:25:33<7:34:56, 15.96s/it]

 89%|████████▉ | 14395/16104 [66:25:46<7:11:36, 15.15s/it]

 89%|████████▉ | 14396/16104 [66:26:06<7:49:18, 16.49s/it]

 89%|████████▉ | 14397/16104 [66:26:20<7:25:07, 15.65s/it]

 89%|████████▉ | 14398/16104 [66:26:31<6:50:36, 14.44s/it]

 89%|████████▉ | 14399/16104 [66:26:44<6:35:36, 13.92s/it]

 89%|████████▉ | 14400/16104 [66:26:56<6:18:20, 13.32s/it]

 89%|████████▉ | 14401/16104 [66:27:11<6:35:13, 13.92s/it]

 89%|████████▉ | 14402/16104 [66:27:25<6:35:49, 13.95s/it]

 89%|████████▉ | 14403/16104 [66:27:47<7:38:07, 16.16s/it]

 89%|████████▉ | 14404/16104 [66:27:57<6:51:13, 14.51s/it]

 89%|████████▉ | 14405/16104 [66:28:10<6:34:58, 13.95s/it]

 89%|████████▉ | 14406/16104 [66:28:23<6:29:16, 13.76s/it]

 89%|████████▉ | 14407/16104 [66:28:36<6:19:37, 13.42s/it]


 89%|████████▉ | 14409/16104 [66:29:05<6:24:51, 13.62s/it]
{'loss': 0.501, 'learning_rate': 5.7548884403138877e-08, 'rewards/chosen': -0.1442764401435852, 'rewards/rejected': -0.8085394501686096, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6642629504203796, 'policy_logps/rejected': -445.8948974609375, 'policy_logps/chosen': -615.1199951171875, 'referece_logps/rejected': -437.80950927734375, 'referece_logps/chosen': -613.6773071289062, 'logits/rejected': 0.003954969346523285, 'logits/chosen': -0.03475929796695709, 'epoch': 5.37}

 89%|████████▉ | 14410/16104 [66:29:15<5:58:55, 12.71s/it]

 89%|████████▉ | 14411/16104 [66:29:26<5:40:30, 12.07s/it]

 89%|████████▉ | 14412/16104 [66:29:37<5:29:25, 11.68s/it]

 89%|████████▉ | 14413/16104 [66:29:51<5:53:37, 12.55s/it]

 90%|████████▉ | 14414/16104 [66:30:02<5:37:01, 11.97s/it]


 90%|████████▉ | 14416/16104 [66:30:29<5:55:01, 12.62s/it]
{'loss': 0.4926, 'learning_rate': 5.707910104651792e-08, 'rewards/chosen': -0.10383529216051102, 'rewards/rejected': -0.8077587485313416, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7039234638214111, 'policy_logps/rejected': -512.5855712890625, 'policy_logps/chosen': -569.91650390625, 'referece_logps/rejected': -504.5079650878906, 'referece_logps/chosen': -568.878173828125, 'logits/rejected': -0.22475600242614746, 'logits/chosen': -0.41858184337615967, 'epoch': 5.37}


 90%|████████▉ | 14418/16104 [66:31:05<7:14:14, 15.45s/it]
{'loss': 0.3179, 'learning_rate': 5.69452204751526e-08, 'rewards/chosen': -0.6435515880584717, 'rewards/rejected': -2.1946587562561035, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5511072874069214, 'policy_logps/rejected': -430.6818542480469, 'policy_logps/chosen': -345.2541198730469, 'referece_logps/rejected': -408.7352600097656, 'referece_logps/chosen': -338.818603515625, 'logits/rejected': -0.6322522163391113, 'logits/chosen': -0.4109589755535126, 'epoch': 5.37}

 90%|████████▉ | 14419/16104 [66:31:19<7:06:56, 15.20s/it]


 90%|████████▉ | 14421/16104 [66:31:53<7:38:17, 16.34s/it]
{'loss': 0.4811, 'learning_rate': 5.674468573672986e-08, 'rewards/chosen': -0.06444550305604935, 'rewards/rejected': -1.2589954137802124, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1945499181747437, 'policy_logps/rejected': -407.5380859375, 'policy_logps/chosen': -526.028564453125, 'referece_logps/rejected': -394.9481201171875, 'referece_logps/chosen': -525.3840942382812, 'logits/rejected': 0.2008838653564453, 'logits/chosen': 0.19842101633548737, 'epoch': 5.37}

 90%|████████▉ | 14422/16104 [66:32:11<7:46:35, 16.64s/it]

 90%|████████▉ | 14423/16104 [66:32:27<7:44:27, 16.58s/it]

 90%|████████▉ | 14424/16104 [66:32:40<7:11:33, 15.41s/it]

 90%|████████▉ | 14425/16104 [66:32:51<6:40:01, 14.30s/it]

 90%|████████▉ | 14426/16104 [66:33:11<7:24:24, 15.89s/it]

 90%|████████▉ | 14427/16104 [66:33:22<6:42:00, 14.38s/it]

 90%|████████▉ | 14428/16104 [66:33:32<6:10:59, 13.28s/it]

 90%|████████▉ | 14429/16104 [66:33:46<6:13:32, 13.38s/it]

 90%|████████▉ | 14430/16104 [66:33:59<6:05:15, 13.09s/it]


 90%|████████▉ | 14432/16104 [66:34:37<7:34:19, 16.30s/it]
{'loss': 0.3602, 'learning_rate': 5.601233028941388e-08, 'rewards/chosen': -1.48347806930542, 'rewards/rejected': -3.00693941116333, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5234613418579102, 'policy_logps/rejected': -583.9133911132812, 'policy_logps/chosen': -508.974365234375, 'referece_logps/rejected': -553.843994140625, 'referece_logps/chosen': -494.13958740234375, 'logits/rejected': 0.5635612607002258, 'logits/chosen': 0.6344399452209473, 'epoch': 5.38}

 90%|████████▉ | 14433/16104 [66:34:53<7:32:11, 16.24s/it]

 90%|████████▉ | 14434/16104 [66:35:11<7:44:02, 16.67s/it]


 90%|████████▉ | 14436/16104 [66:35:47<8:07:28, 17.54s/it]
{'loss': 0.3762, 'learning_rate': 5.574716460895201e-08, 'rewards/chosen': 0.013870611786842346, 'rewards/rejected': -1.4620351791381836, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4759056568145752, 'policy_logps/rejected': -506.1483154296875, 'policy_logps/chosen': -455.85919189453125, 'referece_logps/rejected': -491.5279541015625, 'referece_logps/chosen': -455.9978942871094, 'logits/rejected': 0.004759561270475388, 'logits/chosen': 0.20420145988464355, 'epoch': 5.38}

 90%|████████▉ | 14437/16104 [66:35:59<7:14:31, 15.64s/it]

 90%|████████▉ | 14438/16104 [66:36:13<7:00:32, 15.15s/it]

 90%|████████▉ | 14439/16104 [66:36:24<6:26:11, 13.92s/it]

 90%|████████▉ | 14440/16104 [66:36:35<6:04:42, 13.15s/it]


 90%|████████▉ | 14442/16104 [66:37:01<6:02:54, 13.10s/it]
{'loss': 0.36, 'learning_rate': 5.5350562043091296e-08, 'rewards/chosen': -0.13867302238941193, 'rewards/rejected': -2.0670440196990967, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9283709526062012, 'policy_logps/rejected': -279.06317138671875, 'policy_logps/chosen': -440.4553527832031, 'referece_logps/rejected': -258.39276123046875, 'referece_logps/chosen': -439.068603515625, 'logits/rejected': -1.1055660247802734, 'logits/chosen': -0.8747876882553101, 'epoch': 5.38}

 90%|████████▉ | 14443/16104 [66:37:21<6:56:49, 15.06s/it]

 90%|████████▉ | 14444/16104 [66:37:41<7:37:42, 16.54s/it]


 90%|████████▉ | 14446/16104 [66:38:19<8:16:00, 17.95s/it]

 90%|████████▉ | 14447/16104 [66:38:35<7:59:43, 17.37s/it]

 90%|████████▉ | 14448/16104 [66:38:55<8:17:11, 18.01s/it]

 90%|████████▉ | 14449/16104 [66:39:11<7:59:58, 17.40s/it]

 90%|████████▉ | 14450/16104 [66:39:23<7:13:34, 15.73s/it]

 90%|████████▉ | 14451/16104 [66:39:38<7:09:50, 15.60s/it]

 90%|████████▉ | 14452/16104 [66:40:00<7:58:20, 17.37s/it]

 90%|████████▉ | 14453/16104 [66:40:19<8:12:10, 17.89s/it]

 90%|████████▉ | 14454/16104 [66:40:35<7:55:08, 17.28s/it]

 90%|████████▉ | 14455/16104 [66:40:51<7:44:18, 16.89s/it]

 90%|████████▉ | 14456/16104 [66:41:09<7:59:30, 17.46s/it]

 90%|████████▉ | 14457/16104 [66:41:23<7:24:56, 16.21s/it]

 90%|████████▉ | 14458/16104 [66:41:39<7:25:42, 16.25s/it]

 90%|████████▉ | 14459/16104 [66:42:00<8:01:19, 17.56s/it]

 90%|████████▉ | 14460/16104 [66:42:18<8:06:45, 17.77s/it]

 90%|████████▉ | 14461/16104 [66:42:36<8:06:06, 17.75s/it]

 90%|████████▉ | 14462/16104 [66:42:54<8:10:49, 17.93s/it]

 90%|████████▉ | 14463/16104 [66:43:09<7:47:18, 17.09s/it]

 90%|████████▉ | 14464/16104 [66:43:31<8:23:33, 18.42s/it]

 90%|████████▉ | 14465/16104 [66:43:52<8:47:38, 19.32s/it]

 90%|████████▉ | 14466/16104 [66:44:11<8:47:04, 19.31s/it]

 90%|████████▉ | 14467/16104 [66:44:32<8:55:11, 19.62s/it]

 90%|████████▉ | 14468/16104 [66:44:53<9:10:04, 20.17s/it]

 90%|████████▉ | 14469/16104 [66:45:10<8:43:44, 19.22s/it]

 90%|████████▉ | 14470/16104 [66:45:28<8:29:20, 18.70s/it]

 90%|████████▉ | 14471/16104 [66:45:48<8:40:41, 19.13s/it]

 90%|████████▉ | 14472/16104 [66:46:03<8:07:57, 17.94s/it]

 90%|████████▉ | 14473/16104 [66:46:23<8:23:39, 18.53s/it]

 90%|████████▉ | 14474/16104 [66:46:42<8:33:11, 18.89s/it]

 90%|████████▉ | 14475/16104 [66:46:59<8:15:53, 18.26s/it]

 90%|████████▉ | 14476/16104 [66:47:17<8:09:43, 18.05s/it]

 90%|████████▉ | 14477/16104 [66:47:37<8:23:30, 18.57s/it]

 90%|████████▉ | 14478/16104 [66:47:56<8:30:16, 18.83s/it]

 90%|████████▉ | 14479/16104 [66:48:11<7:58:04, 17.65s/it]

 90%|████████▉ | 14480/16104 [66:48:30<8:10:32, 18.12s/it]

 90%|████████▉ | 14481/16104 [66:48:45<7:41:16, 17.05s/it]

 90%|████████▉ | 14482/16104 [66:49:04<7:57:54, 17.68s/it]

 90%|████████▉ | 14483/16104 [66:49:26<8:34:31, 19.04s/it]

 90%|████████▉ | 14484/16104 [66:49:43<8:15:37, 18.36s/it]

 90%|████████▉ | 14485/16104 [66:50:04<8:39:46, 19.26s/it]

 90%|████████▉ | 14486/16104 [66:50:23<8:38:50, 19.24s/it]

 90%|████████▉ | 14487/16104 [66:50:43<8:44:04, 19.45s/it]

 90%|████████▉ | 14488/16104 [66:50:59<8:17:20, 18.47s/it]

 90%|████████▉ | 14489/16104 [66:51:15<7:54:45, 17.64s/it]

 90%|████████▉ | 14490/16104 [66:51:35<8:11:12, 18.26s/it]

 90%|████████▉ | 14491/16104 [66:51:55<8:26:36, 18.84s/it]

 90%|████████▉ | 14492/16104 [66:52:12<8:11:14, 18.28s/it]

 90%|████████▉ | 14493/16104 [66:52:27<7:44:13, 17.29s/it]

 90%|█████████ | 14494/16104 [66:52:47<8:04:20, 18.05s/it]

 90%|█████████ | 14495/16104 [66:53:07<8:19:20, 18.62s/it]

 90%|█████████ | 14496/16104 [66:53:22<7:54:38, 17.71s/it]

 90%|█████████ | 14497/16104 [66:53:38<7:36:21, 17.04s/it]

 90%|█████████ | 14498/16104 [66:53:58<7:57:43, 17.85s/it]

 90%|█████████ | 14499/16104 [66:54:15<7:56:50, 17.83s/it]

 90%|█████████ | 14500/16104 [66:54:27<7:08:30, 16.03s/it]

 90%|█████████ | 14501/16104 [66:54:54<8:35:38, 19.30s/it]

 90%|█████████ | 14502/16104 [66:55:12<8:22:33, 18.82s/it]

 90%|█████████ | 14503/16104 [66:55:31<8:21:38, 18.80s/it]

 90%|█████████ | 14504/16104 [66:55:47<8:05:49, 18.22s/it]

 90%|█████████ | 14505/16104 [66:56:03<7:46:40, 17.51s/it]

 90%|█████████ | 14506/16104 [66:56:18<7:26:00, 16.75s/it]

 90%|█████████ | 14507/16104 [66:56:38<7:48:41, 17.61s/it]

 90%|█████████ | 14508/16104 [66:56:52<7:20:06, 16.55s/it]

 90%|█████████ | 14509/16104 [66:57:13<7:53:19, 17.81s/it]

 90%|█████████ | 14510/16104 [66:57:35<8:25:58, 19.05s/it]

 90%|█████████ | 14511/16104 [66:57:52<8:14:03, 18.61s/it]

 90%|█████████ | 14512/16104 [66:58:12<8:21:08, 18.89s/it]

 90%|█████████ | 14513/16104 [66:58:31<8:26:43, 19.11s/it]

 90%|█████████ | 14514/16104 [66:58:50<8:21:46, 18.94s/it]
{'loss': 0.4106, 'learning_rate': 5.0698795832110676e-08, 'rewards/chosen': -0.7844382524490356, 'rewards/rejected': -2.965449810028076, 'rewards/accuracies': 0.75, 'rewards/margins': 2.181011199951172, 'policy_logps/rejected': -420.48095703125, 'policy_logps/chosen': -568.6104736328125, 'referece_logps/rejected': -390.82647705078125, 'referece_logps/chosen': -560.76611328125, 'logits/rejected': -0.09729579091072083, 'logits/chosen': 0.025555700063705444, 'epoch': 5.41}


 90%|█████████ | 14516/16104 [66:59:20<7:40:07, 17.39s/it]

 90%|█████████ | 14517/16104 [66:59:42<8:10:36, 18.55s/it]

 90%|█████████ | 14518/16104 [66:59:58<7:54:41, 17.96s/it]

 90%|█████████ | 14519/16104 [67:00:12<7:23:55, 16.80s/it]

 90%|█████████ | 14520/16104 [67:00:26<6:59:19, 15.88s/it]

 90%|█████████ | 14521/16104 [67:00:42<6:58:58, 15.88s/it]

 90%|█████████ | 14522/16104 [67:00:57<6:51:13, 15.60s/it]

 90%|█████████ | 14523/16104 [67:01:08<6:13:11, 14.16s/it]

 90%|█████████ | 14524/16104 [67:01:22<6:11:46, 14.12s/it]

 90%|█████████ | 14525/16104 [67:01:34<5:56:51, 13.56s/it]

 90%|█████████ | 14526/16104 [67:01:47<5:56:07, 13.54s/it]
{'loss': 0.4279, 'learning_rate': 4.994282945896e-08, 'rewards/chosen': -0.6910755038261414, 'rewards/rejected': -1.553271770477295, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8621962070465088, 'policy_logps/rejected': -309.23492431640625, 'policy_logps/chosen': -437.9150085449219, 'referece_logps/rejected': -293.7021789550781, 'referece_logps/chosen': -431.00421142578125, 'logits/rejected': -0.3733375072479248, 'logits/chosen': -0.3168994188308716, 'epoch': 5.41}


 90%|█████████ | 14528/16104 [67:02:30<7:40:53, 17.55s/it]
{'loss': 0.4768, 'learning_rate': 4.9817372985834994e-08, 'rewards/chosen': -0.22791297733783722, 'rewards/rejected': -0.9088796973228455, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6809667348861694, 'policy_logps/rejected': -584.9157104492188, 'policy_logps/chosen': -416.1222229003906, 'referece_logps/rejected': -575.8269653320312, 'referece_logps/chosen': -413.8431396484375, 'logits/rejected': -0.33583590388298035, 'logits/chosen': -0.2438563108444214, 'epoch': 5.41}


 90%|█████████ | 14530/16104 [67:03:10<8:14:42, 18.86s/it]

 90%|█████████ | 14531/16104 [67:03:28<8:04:37, 18.49s/it]

 90%|█████████ | 14532/16104 [67:03:40<7:15:25, 16.62s/it]

 90%|█████████ | 14533/16104 [67:03:51<6:31:06, 14.94s/it]

 90%|█████████ | 14534/16104 [67:04:10<7:04:34, 16.23s/it]

 90%|█████████ | 14535/16104 [67:04:29<7:21:27, 16.88s/it]

 90%|█████████ | 14536/16104 [67:04:42<6:53:00, 15.80s/it]

 90%|█████████ | 14537/16104 [67:04:57<6:43:12, 15.44s/it]

 90%|█████████ | 14538/16104 [67:05:14<6:56:43, 15.97s/it]

 90%|█████████ | 14539/16104 [67:05:27<6:33:43, 15.09s/it]

 90%|█████████ | 14540/16104 [67:05:41<6:25:49, 14.80s/it]
{'loss': 0.3691, 'learning_rate': 4.9067863528761024e-08, 'rewards/chosen': -0.48430436849594116, 'rewards/rejected': -1.3547579050064087, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8704534769058228, 'policy_logps/rejected': -369.140380859375, 'policy_logps/chosen': -533.0970458984375, 'referece_logps/rejected': -355.5928039550781, 'referece_logps/chosen': -528.2540283203125, 'logits/rejected': -0.46769601106643677, 'logits/chosen': -0.42788708209991455, 'epoch': 5.42}


 90%|█████████ | 14542/16104 [67:06:22<7:43:39, 17.81s/it]

 90%|█████████ | 14543/16104 [67:06:41<7:51:29, 18.12s/it]

 90%|█████████ | 14544/16104 [67:06:56<7:30:11, 17.32s/it]

 90%|█████████ | 14545/16104 [67:07:14<7:38:31, 17.65s/it]

 90%|█████████ | 14546/16104 [67:07:36<8:08:27, 18.81s/it]

 90%|█████████ | 14547/16104 [67:07:53<7:53:42, 18.25s/it]

 90%|█████████ | 14548/16104 [67:08:12<8:00:24, 18.52s/it]

 90%|█████████ | 14549/16104 [67:08:23<7:02:20, 16.30s/it]

 90%|█████████ | 14550/16104 [67:08:34<6:22:55, 14.78s/it]

 90%|█████████ | 14551/16104 [67:08:47<6:01:51, 13.98s/it]

 90%|█████████ | 14552/16104 [67:09:03<6:22:35, 14.79s/it]

 90%|█████████ | 14553/16104 [67:09:14<5:53:33, 13.68s/it]

 90%|█████████ | 14554/16104 [67:09:25<5:30:46, 12.80s/it]

 90%|█████████ | 14555/16104 [67:09:36<5:16:47, 12.27s/it]

 90%|█████████ | 14556/16104 [67:09:52<5:45:04, 13.38s/it]

 90%|█████████ | 14557/16104 [67:10:03<5:27:01, 12.68s/it]

 90%|█████████ | 14558/16104 [67:10:15<5:18:12, 12.35s/it]

 90%|█████████ | 14559/16104 [67:10:27<5:13:56, 12.19s/it]

 90%|█████████ | 14560/16104 [67:10:43<5:48:15, 13.53s/it]

 90%|█████████ | 14561/16104 [67:10:54<5:29:39, 12.82s/it]

 90%|█████████ | 14562/16104 [67:11:06<5:23:37, 12.59s/it]
{'loss': 0.2886, 'learning_rate': 4.770815259931282e-08, 'rewards/chosen': -1.0689952373504639, 'rewards/rejected': -2.8772735595703125, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8082783222198486, 'policy_logps/rejected': -195.08143615722656, 'policy_logps/chosen': -452.51904296875, 'referece_logps/rejected': -166.30868530273438, 'referece_logps/chosen': -441.8291320800781, 'logits/rejected': 0.22092807292938232, 'logits/chosen': 0.2972978353500366, 'epoch': 5.43}


 90%|█████████ | 14564/16104 [67:11:31<5:16:57, 12.35s/it]

 90%|█████████ | 14565/16104 [67:11:50<6:11:53, 14.50s/it]

 90%|█████████ | 14566/16104 [67:12:11<6:56:50, 16.26s/it]

 90%|█████████ | 14567/16104 [67:12:29<7:14:07, 16.95s/it]

 90%|█████████ | 14568/16104 [67:12:46<7:08:03, 16.72s/it]

 90%|█████████ | 14569/16104 [67:13:04<7:17:41, 17.11s/it]

 90%|█████████ | 14570/16104 [67:13:17<6:49:12, 16.01s/it]

 90%|█████████ | 14571/16104 [67:13:34<6:53:04, 16.17s/it]

 90%|█████████ | 14572/16104 [67:13:44<6:11:46, 14.56s/it]
{'loss': 0.4769, 'learning_rate': 4.709626408491507e-08, 'rewards/chosen': -0.5397541522979736, 'rewards/rejected': -1.8895514011383057, 'rewards/accuracies': 0.875, 'rewards/margins': 1.349797248840332, 'policy_logps/rejected': -312.8897399902344, 'policy_logps/chosen': -494.6619873046875, 'referece_logps/rejected': -293.9942321777344, 'referece_logps/chosen': -489.2644348144531, 'logits/rejected': 0.0019632764160633087, 'logits/chosen': -0.12444766610860825, 'epoch': 5.43}


 90%|█████████ | 14574/16104 [67:14:15<6:19:54, 14.90s/it]

 91%|█████████ | 14575/16104 [67:14:36<7:09:12, 16.84s/it]

 91%|█████████ | 14576/16104 [67:14:57<7:36:08, 17.91s/it]

 91%|█████████ | 14577/16104 [67:15:08<6:42:54, 15.83s/it]

 91%|█████████ | 14578/16104 [67:15:26<6:59:16, 16.49s/it]

 91%|█████████ | 14579/16104 [67:15:43<7:07:43, 16.83s/it]

 91%|█████████ | 14580/16104 [67:15:59<7:02:07, 16.62s/it]

 91%|█████████ | 14581/16104 [67:16:11<6:19:41, 14.96s/it]

 91%|█████████ | 14582/16104 [67:16:27<6:28:27, 15.31s/it]

 91%|█████████ | 14583/16104 [67:16:47<7:07:25, 16.86s/it]

 91%|█████████ | 14584/16104 [67:17:07<7:30:11, 17.77s/it]

 91%|█████████ | 14585/16104 [67:17:23<7:15:37, 17.21s/it]

 91%|█████████ | 14586/16104 [67:17:34<6:28:50, 15.37s/it]

 91%|█████████ | 14587/16104 [67:17:45<5:57:06, 14.12s/it]

 91%|█████████ | 14588/16104 [67:17:59<5:51:20, 13.91s/it]
{'loss': 0.4451, 'learning_rate': 4.612526118761284e-08, 'rewards/chosen': -0.1484302431344986, 'rewards/rejected': -1.2918848991394043, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1434547901153564, 'policy_logps/rejected': -366.64373779296875, 'policy_logps/chosen': -570.5081176757812, 'referece_logps/rejected': -353.72491455078125, 'referece_logps/chosen': -569.0238037109375, 'logits/rejected': -0.6010041832923889, 'logits/chosen': -0.6402230262756348, 'epoch': 5.44}


 91%|█████████ | 14590/16104 [67:18:21<5:16:17, 12.53s/it]

 91%|█████████ | 14591/16104 [67:18:43<6:27:31, 15.37s/it]

 91%|█████████ | 14592/16104 [67:19:03<7:01:13, 16.72s/it]
{'loss': 0.5074, 'learning_rate': 4.588405350883429e-08, 'rewards/chosen': -1.097591757774353, 'rewards/rejected': -1.6752026081085205, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5776107311248779, 'policy_logps/rejected': -440.69000244140625, 'policy_logps/chosen': -375.89642333984375, 'referece_logps/rejected': -423.93798828125, 'referece_logps/chosen': -364.9205322265625, 'logits/rejected': 0.23638971149921417, 'logits/chosen': 0.250277042388916, 'epoch': 5.44}

 91%|█████████ | 14593/16104 [67:19:18<6:49:51, 16.27s/it]

 91%|█████████ | 14594/16104 [67:19:38<7:18:32, 17.43s/it]


 91%|█████████ | 14596/16104 [67:20:18<7:48:44, 18.65s/it]

 91%|█████████ | 14597/16104 [67:20:33<7:20:14, 17.53s/it]
{'loss': 0.4733, 'learning_rate': 4.5583412331658746e-08, 'rewards/chosen': 0.1903587430715561, 'rewards/rejected': -1.0307683944702148, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2211271524429321, 'policy_logps/rejected': -731.5460205078125, 'policy_logps/chosen': -680.9856567382812, 'referece_logps/rejected': -721.2382202148438, 'referece_logps/chosen': -682.8892822265625, 'logits/rejected': 0.03035825490951538, 'logits/chosen': 0.023302525281906128, 'epoch': 5.44}


 91%|█████████ | 14599/16104 [67:21:04<6:43:27, 16.08s/it]

 91%|█████████ | 14600/16104 [67:21:19<6:36:09, 15.80s/it]

 91%|█████████ | 14601/16104 [67:21:34<6:26:28, 15.43s/it]

 91%|█████████ | 14602/16104 [67:21:53<6:55:37, 16.60s/it]
{'loss': 0.3721, 'learning_rate': 4.5283736350757884e-08, 'rewards/chosen': -0.9323150515556335, 'rewards/rejected': -1.481909990310669, 'rewards/accuracies': 0.625, 'rewards/margins': 0.549595057964325, 'policy_logps/rejected': -285.74334716796875, 'policy_logps/chosen': -366.463134765625, 'referece_logps/rejected': -270.92425537109375, 'referece_logps/chosen': -357.1399841308594, 'logits/rejected': -0.6111105680465698, 'logits/chosen': -0.7020255327224731, 'epoch': 5.44}


 91%|█████████ | 14604/16104 [67:22:16<5:46:21, 13.85s/it]

 91%|█████████ | 14605/16104 [67:22:35<6:29:19, 15.58s/it]
{'loss': 0.2965, 'learning_rate': 4.510439418254341e-08, 'rewards/chosen': -0.8741573691368103, 'rewards/rejected': -2.66048526763916, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7863280773162842, 'policy_logps/rejected': -338.4888916015625, 'policy_logps/chosen': -268.6408996582031, 'referece_logps/rejected': -311.8840026855469, 'referece_logps/chosen': -259.8993225097656, 'logits/rejected': -0.16283519566059113, 'logits/chosen': -0.09903761744499207, 'epoch': 5.44}


 91%|█████████ | 14607/16104 [67:23:02<6:07:48, 14.74s/it]

 91%|█████████ | 14608/16104 [67:23:22<6:45:44, 16.27s/it]

 91%|█████████ | 14609/16104 [67:23:36<6:25:33, 15.47s/it]

 91%|█████████ | 14610/16104 [67:23:48<6:03:08, 14.58s/it]
{'loss': 0.3742, 'learning_rate': 4.48062631456424e-08, 'rewards/chosen': -1.0056015253067017, 'rewards/rejected': -1.816292405128479, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8106908798217773, 'policy_logps/rejected': -423.9646301269531, 'policy_logps/chosen': -392.2647705078125, 'referece_logps/rejected': -405.8016662597656, 'referece_logps/chosen': -382.208740234375, 'logits/rejected': 0.036466941237449646, 'logits/chosen': -0.027919769287109375, 'epoch': 5.44}


 91%|█████████ | 14612/16104 [67:24:26<6:58:55, 16.85s/it]

 91%|█████████ | 14613/16104 [67:24:46<7:25:07, 17.91s/it]

 91%|█████████ | 14614/16104 [67:25:06<7:37:05, 18.41s/it]

 91%|█████████ | 14615/16104 [67:25:22<7:15:12, 17.54s/it]
{'loss': 0.418, 'learning_rate': 4.450909809094305e-08, 'rewards/chosen': -0.18097993731498718, 'rewards/rejected': -2.2500803470611572, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0691006183624268, 'policy_logps/rejected': -408.7300720214844, 'policy_logps/chosen': -341.7645568847656, 'referece_logps/rejected': -386.2292785644531, 'referece_logps/chosen': -339.9547424316406, 'logits/rejected': -0.45688578486442566, 'logits/chosen': -0.5191526412963867, 'epoch': 5.45}


 91%|█████████ | 14617/16104 [67:25:58<7:20:51, 17.79s/it]
{'loss': 0.4317, 'learning_rate': 4.4390502611429407e-08, 'rewards/chosen': -0.4738949239253998, 'rewards/rejected': -1.724123239517212, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2502282857894897, 'policy_logps/rejected': -455.9515075683594, 'policy_logps/chosen': -557.5597534179688, 'referece_logps/rejected': -438.71026611328125, 'referece_logps/chosen': -552.8208618164062, 'logits/rejected': -0.32485467195510864, 'logits/chosen': -0.4963997006416321, 'epoch': 5.45}

 91%|█████████ | 14618/16104 [67:26:13<7:03:19, 17.09s/it]


 91%|█████████ | 14620/16104 [67:26:39<6:07:22, 14.85s/it]

 91%|█████████ | 14621/16104 [67:26:58<6:44:17, 16.36s/it]
{'loss': 0.301, 'learning_rate': 4.4153775544875315e-08, 'rewards/chosen': 0.5279123187065125, 'rewards/rejected': -1.2925894260406494, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8205015659332275, 'policy_logps/rejected': -473.3634033203125, 'policy_logps/chosen': -520.0086669921875, 'referece_logps/rejected': -460.4375, 'referece_logps/chosen': -525.2877807617188, 'logits/rejected': -0.3226291537284851, 'logits/chosen': -0.3307588994503021, 'epoch': 5.45}

 91%|█████████ | 14622/16104 [67:27:10<6:05:18, 14.79s/it]

 91%|█████████ | 14623/16104 [67:27:21<5:39:38, 13.76s/it]

 91%|█████████ | 14624/16104 [67:27:43<6:43:34, 16.36s/it]

 91%|█████████ | 14625/16104 [67:27:56<6:13:12, 15.14s/it]


 91%|█████████ | 14627/16104 [67:28:21<5:42:31, 13.91s/it]
{'loss': 0.3988, 'learning_rate': 4.379984496332045e-08, 'rewards/chosen': -0.41634684801101685, 'rewards/rejected': -1.5515795946121216, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1352325677871704, 'policy_logps/rejected': -416.41546630859375, 'policy_logps/chosen': -382.82147216796875, 'referece_logps/rejected': -400.899658203125, 'referece_logps/chosen': -378.6579895019531, 'logits/rejected': 0.01744093745946884, 'logits/chosen': 0.2704172730445862, 'epoch': 5.45}


 91%|█████████ | 14629/16104 [67:28:48<5:34:10, 13.59s/it]
{'loss': 0.3121, 'learning_rate': 4.368217751739245e-08, 'rewards/chosen': -0.9515838027000427, 'rewards/rejected': -3.1208298206329346, 'rewards/accuracies': 1.0, 'rewards/margins': 2.169246196746826, 'policy_logps/rejected': -452.9664306640625, 'policy_logps/chosen': -482.7120056152344, 'referece_logps/rejected': -421.75811767578125, 'referece_logps/chosen': -473.1961669921875, 'logits/rejected': 0.4353300929069519, 'logits/chosen': 0.34421056509017944, 'epoch': 5.45}

 91%|█████████ | 14630/16104 [67:29:00<5:16:37, 12.89s/it]


 91%|█████████ | 14632/16104 [67:29:22<4:55:47, 12.06s/it]
{'loss': 0.4801, 'learning_rate': 4.350596649015847e-08, 'rewards/chosen': 0.45024871826171875, 'rewards/rejected': -0.6921809911727905, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1424298286437988, 'policy_logps/rejected': -502.1436767578125, 'policy_logps/chosen': -589.7235717773438, 'referece_logps/rejected': -495.221923828125, 'referece_logps/chosen': -594.2261352539062, 'logits/rejected': -0.4431542754173279, 'logits/chosen': -0.44295263290405273, 'epoch': 5.45}


 91%|█████████ | 14634/16104 [67:29:58<6:14:25, 15.28s/it]
{'loss': 0.3894, 'learning_rate': 4.3388685927495116e-08, 'rewards/chosen': -1.0713557004928589, 'rewards/rejected': -2.241800308227539, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1704447269439697, 'policy_logps/rejected': -442.1327819824219, 'policy_logps/chosen': -407.73333740234375, 'referece_logps/rejected': -419.71478271484375, 'referece_logps/chosen': -397.019775390625, 'logits/rejected': 0.5809229612350464, 'logits/chosen': 0.6946029663085938, 'epoch': 5.45}


 91%|█████████ | 14636/16104 [67:30:38<7:15:47, 17.81s/it]
{'loss': 0.4631, 'learning_rate': 4.3271560151369014e-08, 'rewards/chosen': -0.9811975955963135, 'rewards/rejected': -1.7326841354370117, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7514864206314087, 'policy_logps/rejected': -283.6077880859375, 'policy_logps/chosen': -285.8600769042969, 'referece_logps/rejected': -266.28094482421875, 'referece_logps/chosen': -276.0481262207031, 'logits/rejected': -0.3298623561859131, 'logits/chosen': -0.5019341707229614, 'epoch': 5.45}


 91%|█████████ | 14638/16104 [67:31:02<5:59:12, 14.70s/it]

 91%|█████████ | 14639/16104 [67:31:14<5:40:19, 13.94s/it]

 91%|█████████ | 14640/16104 [67:31:26<5:26:24, 13.38s/it]

 91%|█████████ | 14641/16104 [67:31:45<6:01:17, 14.82s/it]
{'loss': 0.5976, 'learning_rate': 4.2979423026464065e-08, 'rewards/chosen': -0.9781789779663086, 'rewards/rejected': -0.9029961228370667, 'rewards/accuracies': 0.5, 'rewards/margins': -0.07518293708562851, 'policy_logps/rejected': -513.1273193359375, 'policy_logps/chosen': -418.0210876464844, 'referece_logps/rejected': -504.09735107421875, 'referece_logps/chosen': -408.2392578125, 'logits/rejected': -0.25326573848724365, 'logits/chosen': -0.3467269837856293, 'epoch': 5.45}


 91%|█████████ | 14643/16104 [67:32:06<5:11:49, 12.81s/it]
{'loss': 0.4764, 'learning_rate': 4.2862839152299604e-08, 'rewards/chosen': -0.12153645604848862, 'rewards/rejected': -1.6071733236312866, 'rewards/accuracies': 0.875, 'rewards/margins': 1.485636830329895, 'policy_logps/rejected': -406.52825927734375, 'policy_logps/chosen': -461.7479248046875, 'referece_logps/rejected': -390.45654296875, 'referece_logps/chosen': -460.5325927734375, 'logits/rejected': -0.2736186981201172, 'logits/chosen': -0.21936145424842834, 'epoch': 5.46}


 91%|█████████ | 14645/16104 [67:32:45<6:36:23, 16.30s/it]

 91%|█████████ | 14646/16104 [67:33:06<7:11:33, 17.76s/it]
{'loss': 0.3775, 'learning_rate': 4.268825373123408e-08, 'rewards/chosen': -1.3229206800460815, 'rewards/rejected': -2.555610179901123, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2326894998550415, 'policy_logps/rejected': -463.4847717285156, 'policy_logps/chosen': -386.0252990722656, 'referece_logps/rejected': -437.92864990234375, 'referece_logps/chosen': -372.7960510253906, 'logits/rejected': -0.2901080846786499, 'logits/chosen': -0.2904498875141144, 'epoch': 5.46}

 91%|█████████ | 14647/16104 [67:33:22<6:54:18, 17.06s/it]

 91%|█████████ | 14648/16104 [67:33:36<6:33:43, 16.22s/it]


 91%|█████████ | 14650/16104 [67:34:11<6:49:00, 16.88s/it]

 91%|█████████ | 14651/16104 [67:34:29<6:55:03, 17.14s/it]
{'loss': 0.3526, 'learning_rate': 4.2398052560137174e-08, 'rewards/chosen': -0.717511773109436, 'rewards/rejected': -1.9603233337402344, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2428114414215088, 'policy_logps/rejected': -436.0596618652344, 'policy_logps/chosen': -452.08526611328125, 'referece_logps/rejected': -416.4564514160156, 'referece_logps/chosen': -444.9101867675781, 'logits/rejected': -0.29670873284339905, 'logits/chosen': -0.2838698923587799, 'epoch': 5.46}

 91%|█████████ | 14652/16104 [67:34:50<7:23:04, 18.31s/it]


 91%|█████████ | 14654/16104 [67:35:21<6:48:58, 16.92s/it]

 91%|█████████ | 14655/16104 [67:35:33<6:09:15, 15.29s/it]
{'loss': 0.2408, 'learning_rate': 4.2166588869885774e-08, 'rewards/chosen': -0.47458362579345703, 'rewards/rejected': -2.4001011848449707, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9255179166793823, 'policy_logps/rejected': -428.70977783203125, 'policy_logps/chosen': -439.6365966796875, 'referece_logps/rejected': -404.708740234375, 'referece_logps/chosen': -434.8907470703125, 'logits/rejected': -0.3590400815010071, 'logits/chosen': -0.28735390305519104, 'epoch': 5.46}


 91%|█████████ | 14657/16104 [67:36:06<6:17:38, 15.66s/it]

 91%|█████████ | 14658/16104 [67:36:19<5:57:45, 14.84s/it]
{'loss': 0.3555, 'learning_rate': 4.19933979277417e-08, 'rewards/chosen': -0.576625406742096, 'rewards/rejected': -1.8915156126022339, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3148901462554932, 'policy_logps/rejected': -358.2317810058594, 'policy_logps/chosen': -478.4096984863281, 'referece_logps/rejected': -339.316650390625, 'referece_logps/chosen': -472.6434326171875, 'logits/rejected': 0.11098936200141907, 'logits/chosen': 0.315779447555542, 'epoch': 5.46}


 91%|█████████ | 14660/16104 [67:36:51<6:18:51, 15.74s/it]

 91%|█████████ | 14661/16104 [67:37:11<6:45:52, 16.88s/it]
{'loss': 0.3309, 'learning_rate': 4.182055576327792e-08, 'rewards/chosen': -1.2900141477584839, 'rewards/rejected': -2.6943342685699463, 'rewards/accuracies': 0.875, 'rewards/margins': 1.404320240020752, 'policy_logps/rejected': -214.2718048095703, 'policy_logps/chosen': -284.7370300292969, 'referece_logps/rejected': -187.3284454345703, 'referece_logps/chosen': -271.8369140625, 'logits/rejected': -0.4625941514968872, 'logits/chosen': -0.3864677846431732, 'epoch': 5.46}


 91%|█████████ | 14663/16104 [67:37:48<7:08:39, 17.85s/it]
{'loss': 0.3859, 'learning_rate': 4.170552145009287e-08, 'rewards/chosen': -0.49638062715530396, 'rewards/rejected': -1.7487695217132568, 'rewards/accuracies': 0.625, 'rewards/margins': 1.252388834953308, 'policy_logps/rejected': -336.69598388671875, 'policy_logps/chosen': -396.5751037597656, 'referece_logps/rejected': -319.20831298828125, 'referece_logps/chosen': -391.6112976074219, 'logits/rejected': 0.14480730891227722, 'logits/chosen': 0.05774492025375366, 'epoch': 5.46}


 91%|█████████ | 14665/16104 [67:38:21<6:43:14, 16.81s/it]

 91%|█████████ | 14666/16104 [67:38:39<6:53:27, 17.25s/it]
{'loss': 0.4489, 'learning_rate': 4.153326072153496e-08, 'rewards/chosen': -0.09202858805656433, 'rewards/rejected': -2.2023732662200928, 'rewards/accuracies': 1.0, 'rewards/margins': 2.110344886779785, 'policy_logps/rejected': -309.28192138671875, 'policy_logps/chosen': -297.5640563964844, 'referece_logps/rejected': -287.2582092285156, 'referece_logps/chosen': -296.6437683105469, 'logits/rejected': -0.9640548229217529, 'logits/chosen': -0.8436915874481201, 'epoch': 5.46}

 91%|█████████ | 14667/16104 [67:38:58<7:03:12, 17.67s/it]

 91%|█████████ | 14668/16104 [67:39:18<7:20:58, 18.42s/it]


 91%|█████████ | 14670/16104 [67:39:57<7:25:19, 18.63s/it]

 91%|█████████ | 14671/16104 [67:40:15<7:23:12, 18.56s/it]

 91%|█████████ | 14672/16104 [67:40:35<7:32:03, 18.94s/it]

 91%|█████████ | 14673/16104 [67:40:53<7:24:52, 18.65s/it]

 91%|█████████ | 14674/16104 [67:41:13<7:33:30, 19.03s/it]
{'loss': 0.3273, 'learning_rate': 4.1075604902959915e-08, 'rewards/chosen': -1.2852191925048828, 'rewards/rejected': -3.346686363220215, 'rewards/accuracies': 0.75, 'rewards/margins': 2.061467170715332, 'policy_logps/rejected': -399.4085998535156, 'policy_logps/chosen': -472.95684814453125, 'referece_logps/rejected': -365.94171142578125, 'referece_logps/chosen': -460.1047058105469, 'logits/rejected': 0.17837423086166382, 'logits/chosen': 0.15498805046081543, 'epoch': 5.47}

 91%|█████████ | 14675/16104 [67:41:32<7:32:03, 18.98s/it]

 91%|█████████ | 14676/16104 [67:41:54<7:55:11, 19.97s/it]

 91%|█████████ | 14677/16104 [67:42:10<7:29:43, 18.91s/it]

 91%|█████████ | 14678/16104 [67:42:24<6:50:21, 17.27s/it]


 91%|█████████ | 14680/16104 [67:43:01<7:10:08, 18.12s/it]
{'loss': 0.4287, 'learning_rate': 4.07339921626535e-08, 'rewards/chosen': -0.04313504695892334, 'rewards/rejected': -2.0131242275238037, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9699890613555908, 'policy_logps/rejected': -666.283203125, 'policy_logps/chosen': -707.5028076171875, 'referece_logps/rejected': -646.1519165039062, 'referece_logps/chosen': -707.0714721679688, 'logits/rejected': 0.007099539041519165, 'logits/chosen': 0.0013546645641326904, 'epoch': 5.47}

 91%|█████████ | 14681/16104 [67:43:21<7:20:02, 18.55s/it]

 91%|█████████ | 14682/16104 [67:43:32<6:27:14, 16.34s/it]

 91%|█████████ | 14683/16104 [67:43:43<5:48:13, 14.70s/it]

 91%|█████████ | 14684/16104 [67:44:01<6:11:54, 15.71s/it]


 91%|█████████ | 14686/16104 [67:44:31<5:56:35, 15.09s/it]

 91%|█████████ | 14687/16104 [67:44:53<6:42:58, 17.06s/it]

 91%|█████████ | 14688/16104 [67:45:14<7:09:57, 18.22s/it]
{'loss': 0.4587, 'learning_rate': 4.02806816195681e-08, 'rewards/chosen': -0.41015905141830444, 'rewards/rejected': -1.798243522644043, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3880844116210938, 'policy_logps/rejected': -414.41827392578125, 'policy_logps/chosen': -316.9449462890625, 'referece_logps/rejected': -396.435791015625, 'referece_logps/chosen': -312.8433532714844, 'logits/rejected': -0.0009641461074352264, 'logits/chosen': -0.08777757734060287, 'epoch': 5.47}

 91%|█████████ | 14689/16104 [67:45:29<6:46:08, 17.22s/it]


 91%|█████████ | 14691/16104 [67:46:07<7:11:46, 18.33s/it]
{'loss': 0.4346, 'learning_rate': 4.011133067187e-08, 'rewards/chosen': -0.5467209815979004, 'rewards/rejected': -2.6389682292938232, 'rewards/accuracies': 0.875, 'rewards/margins': 2.092247247695923, 'policy_logps/rejected': -405.71588134765625, 'policy_logps/chosen': -415.1634826660156, 'referece_logps/rejected': -379.3262023925781, 'referece_logps/chosen': -409.6962890625, 'logits/rejected': 0.1730688512325287, 'logits/chosen': 0.18572834134101868, 'epoch': 5.47}

 91%|█████████ | 14692/16104 [67:46:27<7:19:19, 18.67s/it]


 91%|█████████ | 14694/16104 [67:46:55<6:22:35, 16.28s/it]

 91%|█████████▏| 14695/16104 [67:47:15<6:49:55, 17.46s/it]

 91%|█████████▏| 14696/16104 [67:47:29<6:22:54, 16.32s/it]
{'loss': 0.387, 'learning_rate': 3.9829855706933536e-08, 'rewards/chosen': -0.13037452101707458, 'rewards/rejected': -2.038374185562134, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9079996347427368, 'policy_logps/rejected': -343.67230224609375, 'policy_logps/chosen': -368.4645690917969, 'referece_logps/rejected': -323.28851318359375, 'referece_logps/chosen': -367.1607971191406, 'logits/rejected': 0.25781989097595215, 'logits/chosen': 0.24038724601268768, 'epoch': 5.48}


 91%|█████████▏| 14698/16104 [67:48:01<6:11:27, 15.85s/it]
{'loss': 0.3285, 'learning_rate': 3.971753758919949e-08, 'rewards/chosen': -0.88701993227005, 'rewards/rejected': -2.6810734272003174, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7940534353256226, 'policy_logps/rejected': -471.85601806640625, 'policy_logps/chosen': -374.4642333984375, 'referece_logps/rejected': -445.0452575683594, 'referece_logps/chosen': -365.593994140625, 'logits/rejected': -0.41969186067581177, 'logits/chosen': -0.32129281759262085, 'epoch': 5.48}


 91%|█████████▏| 14700/16104 [67:48:37<6:33:43, 16.83s/it]
{'loss': 0.4052, 'learning_rate': 3.960537485202076e-08, 'rewards/chosen': -0.23690415918827057, 'rewards/rejected': -1.2484968900680542, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0115926265716553, 'policy_logps/rejected': -464.0660400390625, 'policy_logps/chosen': -548.4541015625, 'referece_logps/rejected': -451.5810241699219, 'referece_logps/chosen': -546.0850830078125, 'logits/rejected': -0.06471686065196991, 'logits/chosen': 0.03677929937839508, 'epoch': 5.48}


 91%|█████████▏| 14702/16104 [67:49:00<5:27:36, 14.02s/it]

 91%|█████████▏| 14703/16104 [67:49:20<6:07:35, 15.74s/it]

 91%|█████████▏| 14704/16104 [67:49:39<6:35:40, 16.96s/it]
{'loss': 0.4414, 'learning_rate': 3.938151559189895e-08, 'rewards/chosen': -0.34234389662742615, 'rewards/rejected': -1.5912384986877441, 'rewards/accuracies': 0.5, 'rewards/margins': 1.2488946914672852, 'policy_logps/rejected': -390.0525207519531, 'policy_logps/chosen': -354.29425048828125, 'referece_logps/rejected': -374.14013671875, 'referece_logps/chosen': -350.87078857421875, 'logits/rejected': -0.4321962594985962, 'logits/chosen': -0.29242265224456787, 'epoch': 5.48}

 91%|█████████▏| 14705/16104 [67:49:55<6:26:03, 16.56s/it]


 91%|█████████▏| 14707/16104 [67:50:28<6:18:17, 16.25s/it]

 91%|█████████▏| 14708/16104 [67:50:48<6:45:24, 17.42s/it]

 91%|█████████▏| 14709/16104 [67:50:59<6:02:34, 15.59s/it]
{'loss': 0.4756, 'learning_rate': 3.9102565855111405e-08, 'rewards/chosen': -0.8481857776641846, 'rewards/rejected': -1.6587765216827393, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8105907440185547, 'policy_logps/rejected': -433.1524658203125, 'policy_logps/chosen': -564.595947265625, 'referece_logps/rejected': -416.564697265625, 'referece_logps/chosen': -556.1141357421875, 'logits/rejected': -0.8299210071563721, 'logits/chosen': -0.8816936612129211, 'epoch': 5.48}

 91%|█████████▏| 14710/16104 [67:51:11<5:33:58, 14.37s/it]


 91%|█████████▏| 14712/16104 [67:51:42<5:42:49, 14.78s/it]

 91%|█████████▏| 14713/16104 [67:52:02<6:17:14, 16.27s/it]

 91%|█████████▏| 14714/16104 [67:52:14<5:48:51, 15.06s/it]
{'loss': 0.4855, 'learning_rate': 3.8824587868643176e-08, 'rewards/chosen': -0.2854677438735962, 'rewards/rejected': -0.8010990023612976, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5156313180923462, 'policy_logps/rejected': -406.1345520019531, 'policy_logps/chosen': -492.25396728515625, 'referece_logps/rejected': -398.12359619140625, 'referece_logps/chosen': -489.39935302734375, 'logits/rejected': -0.14808036386966705, 'logits/chosen': -0.22756531834602356, 'epoch': 5.48}

 91%|█████████▏| 14715/16104 [67:52:25<5:18:18, 13.75s/it]

 91%|█████████▏| 14716/16104 [67:52:46<6:12:17, 16.09s/it]

 91%|█████████▏| 14717/16104 [67:52:59<5:49:05, 15.10s/it]


 91%|█████████▏| 14719/16104 [67:53:34<6:04:33, 15.79s/it]
{'loss': 0.3468, 'learning_rate': 3.854758191361196e-08, 'rewards/chosen': -0.8256864547729492, 'rewards/rejected': -2.2551965713500977, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4295101165771484, 'policy_logps/rejected': -504.50091552734375, 'policy_logps/chosen': -445.8299865722656, 'referece_logps/rejected': -481.948974609375, 'referece_logps/chosen': -437.5731201171875, 'logits/rejected': 0.715322732925415, 'logits/chosen': 0.8037411570549011, 'epoch': 5.48}

 91%|█████████▏| 14720/16104 [67:53:53<6:26:28, 16.75s/it]


 91%|█████████▏| 14722/16104 [67:54:24<6:22:40, 16.61s/it]
{'loss': 0.3988, 'learning_rate': 3.838184503226005e-08, 'rewards/chosen': -0.32700273394584656, 'rewards/rejected': -1.6019924879074097, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2749896049499512, 'policy_logps/rejected': -519.2532348632812, 'policy_logps/chosen': -564.29638671875, 'referece_logps/rejected': -503.2332763671875, 'referece_logps/chosen': -561.0263061523438, 'logits/rejected': -0.9939744472503662, 'logits/chosen': -0.6316622495651245, 'epoch': 5.49}

 91%|█████████▏| 14723/16104 [67:54:41<6:24:18, 16.70s/it]

 91%|█████████▏| 14724/16104 [67:54:59<6:31:56, 17.04s/it]


 91%|█████████▏| 14726/16104 [67:55:24<5:39:49, 14.80s/it]

 91%|█████████▏| 14727/16104 [67:55:40<5:49:21, 15.22s/it]
{'loss': 0.4074, 'learning_rate': 3.8106394909799164e-08, 'rewards/chosen': -0.005834552459418774, 'rewards/rejected': -1.3734999895095825, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3676652908325195, 'policy_logps/rejected': -347.765625, 'policy_logps/chosen': -575.2890014648438, 'referece_logps/rejected': -334.0306396484375, 'referece_logps/chosen': -575.2306518554688, 'logits/rejected': -0.00250408798456192, 'logits/chosen': -0.28741222620010376, 'epoch': 5.49}

 91%|█████████▏| 14728/16104 [67:56:00<6:16:14, 16.41s/it]

 91%|█████████▏| 14729/16104 [67:56:19<6:37:28, 17.34s/it]

 91%|█████████▏| 14730/16104 [67:56:39<6:52:06, 18.00s/it]


 91%|█████████▏| 14732/16104 [67:57:15<6:50:24, 17.95s/it]

 91%|█████████▏| 14733/16104 [67:57:30<6:34:51, 17.28s/it]
{'loss': 0.5058, 'learning_rate': 3.777713882750944e-08, 'rewards/chosen': -0.6245352029800415, 'rewards/rejected': -2.7844655513763428, 'rewards/accuracies': 0.875, 'rewards/margins': 2.159930467605591, 'policy_logps/rejected': -434.57373046875, 'policy_logps/chosen': -434.259033203125, 'referece_logps/rejected': -406.72906494140625, 'referece_logps/chosen': -428.013671875, 'logits/rejected': -0.19278627634048462, 'logits/chosen': -0.24296124279499054, 'epoch': 5.49}

 91%|█████████▏| 14734/16104 [67:57:42<5:55:29, 15.57s/it]

 91%|█████████▏| 14735/16104 [67:57:55<5:39:38, 14.89s/it]

 92%|█████████▏| 14736/16104 [67:58:08<5:22:37, 14.15s/it]

 92%|█████████▏| 14737/16104 [67:58:27<6:00:52, 15.84s/it]

 92%|█████████▏| 14738/16104 [67:58:45<6:12:35, 16.37s/it]

 92%|█████████▏| 14739/16104 [67:59:02<6:15:08, 16.49s/it]

 92%|█████████▏| 14740/16104 [67:59:19<6:23:11, 16.86s/it]

 92%|█████████▏| 14741/16104 [67:59:40<6:47:28, 17.94s/it]

 92%|█████████▏| 14742/16104 [67:59:59<6:57:23, 18.39s/it]


 92%|█████████▏| 14744/16104 [68:00:35<6:40:07, 17.65s/it]

 92%|█████████▏| 14745/16104 [68:00:51<6:28:55, 17.17s/it]
{'loss': 0.4483, 'learning_rate': 3.7122830892112543e-08, 'rewards/chosen': -0.07649078965187073, 'rewards/rejected': -2.445549726486206, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3690590858459473, 'policy_logps/rejected': -423.77862548828125, 'policy_logps/chosen': -474.8551025390625, 'referece_logps/rejected': -399.3231506347656, 'referece_logps/chosen': -474.0902099609375, 'logits/rejected': -0.15804223716259003, 'logits/chosen': -0.12911155819892883, 'epoch': 5.49}

 92%|█████████▏| 14746/16104 [68:01:08<6:28:55, 17.18s/it]

 92%|█████████▏| 14747/16104 [68:01:28<6:49:36, 18.11s/it]

 92%|█████████▏| 14748/16104 [68:01:40<6:08:35, 16.31s/it]

 92%|█████████▏| 14749/16104 [68:01:54<5:48:20, 15.42s/it]

 92%|█████████▏| 14750/16104 [68:02:05<5:22:05, 14.27s/it]


 92%|█████████▏| 14752/16104 [68:02:35<5:19:57, 14.20s/it]
{'loss': 0.483, 'learning_rate': 3.674374120040746e-08, 'rewards/chosen': -0.4786684215068817, 'rewards/rejected': -2.057612419128418, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5789440870285034, 'policy_logps/rejected': -532.2792358398438, 'policy_logps/chosen': -596.6040649414062, 'referece_logps/rejected': -511.7030944824219, 'referece_logps/chosen': -591.8173828125, 'logits/rejected': -0.35892409086227417, 'logits/chosen': -0.001341402530670166, 'epoch': 5.5}

 92%|█████████▏| 14753/16104 [68:02:55<6:01:35, 16.06s/it]

 92%|█████████▏| 14754/16104 [68:03:11<6:01:04, 16.05s/it]

 92%|█████████▏| 14755/16104 [68:03:28<6:04:59, 16.23s/it]

 92%|█████████▏| 14756/16104 [68:03:40<5:36:57, 15.00s/it]

 92%|█████████▏| 14757/16104 [68:03:58<5:59:58, 16.03s/it]

 92%|█████████▏| 14758/16104 [68:04:18<6:23:15, 17.08s/it]

 92%|█████████▏| 14759/16104 [68:04:36<6:26:48, 17.26s/it]

 92%|█████████▏| 14760/16104 [68:04:57<6:56:50, 18.61s/it]

 92%|█████████▏| 14761/16104 [68:05:17<7:06:48, 19.07s/it]

 92%|█████████▏| 14762/16104 [68:05:35<6:58:36, 18.72s/it]


 92%|█████████▏| 14764/16104 [68:06:11<6:51:35, 18.43s/it]
{'loss': 0.2708, 'learning_rate': 3.609831563059407e-08, 'rewards/chosen': 0.013309482485055923, 'rewards/rejected': -2.1086361408233643, 'rewards/accuracies': 1.0, 'rewards/margins': 2.12194561958313, 'policy_logps/rejected': -363.55657958984375, 'policy_logps/chosen': -434.9703063964844, 'referece_logps/rejected': -342.47021484375, 'referece_logps/chosen': -435.1033935546875, 'logits/rejected': -0.7148686647415161, 'logits/chosen': -0.7108917236328125, 'epoch': 5.5}

 92%|█████████▏| 14765/16104 [68:06:24<6:17:46, 16.93s/it]

 92%|█████████▏| 14766/16104 [68:06:44<6:34:31, 17.69s/it]

 92%|█████████▏| 14767/16104 [68:06:59<6:14:40, 16.81s/it]


 92%|█████████▏| 14769/16104 [68:07:25<5:28:19, 14.76s/it]
{'loss': 0.5087, 'learning_rate': 3.5831045235001135e-08, 'rewards/chosen': -0.863115131855011, 'rewards/rejected': -1.347456932067871, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4843418002128601, 'policy_logps/rejected': -352.77130126953125, 'policy_logps/chosen': -310.33966064453125, 'referece_logps/rejected': -339.2967529296875, 'referece_logps/chosen': -301.70849609375, 'logits/rejected': -0.03807549923658371, 'logits/chosen': -0.01056169718503952, 'epoch': 5.5}

 92%|█████████▏| 14770/16104 [68:07:38<5:15:18, 14.18s/it]

 92%|█████████▏| 14771/16104 [68:07:58<5:52:28, 15.87s/it]

 92%|█████████▏| 14772/16104 [68:08:15<6:04:01, 16.40s/it]


 92%|█████████▏| 14774/16104 [68:08:39<5:14:51, 14.20s/it]
{'loss': 0.5242, 'learning_rate': 3.5564749898198466e-08, 'rewards/chosen': -0.455272912979126, 'rewards/rejected': -0.8131886124610901, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3579156994819641, 'policy_logps/rejected': -378.3130798339844, 'policy_logps/chosen': -346.5078430175781, 'referece_logps/rejected': -370.18115234375, 'referece_logps/chosen': -341.955078125, 'logits/rejected': -0.3916926383972168, 'logits/chosen': -0.48516103625297546, 'epoch': 5.5}

 92%|█████████▏| 14775/16104 [68:08:50<4:51:42, 13.17s/it]

 92%|█████████▏| 14776/16104 [68:09:09<5:29:45, 14.90s/it]

 92%|█████████▏| 14777/16104 [68:09:26<5:44:40, 15.58s/it]

 92%|█████████▏| 14778/16104 [68:09:43<5:56:18, 16.12s/it]

 92%|█████████▏| 14779/16104 [68:10:03<6:16:13, 17.04s/it]


 92%|█████████▏| 14781/16104 [68:10:43<6:53:47, 18.77s/it]
{'loss': 0.3722, 'learning_rate': 3.5193575038007795e-08, 'rewards/chosen': -1.4784210920333862, 'rewards/rejected': -2.726677179336548, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2482560873031616, 'policy_logps/rejected': -407.29949951171875, 'policy_logps/chosen': -343.013671875, 'referece_logps/rejected': -380.03271484375, 'referece_logps/chosen': -328.2294616699219, 'logits/rejected': -0.30412861704826355, 'logits/chosen': -0.20045523345470428, 'epoch': 5.51}


 92%|█████████▏| 14783/16104 [68:11:19<6:51:06, 18.67s/it]
{'loss': 0.3822, 'learning_rate': 3.5087876299091155e-08, 'rewards/chosen': -0.8765502572059631, 'rewards/rejected': -1.7340161800384521, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8574657440185547, 'policy_logps/rejected': -410.50897216796875, 'policy_logps/chosen': -358.6763916015625, 'referece_logps/rejected': -393.1688537597656, 'referece_logps/chosen': -349.9108581542969, 'logits/rejected': -0.640341579914093, 'logits/chosen': -0.6578195095062256, 'epoch': 5.51}


 92%|█████████▏| 14785/16104 [68:11:57<6:51:38, 18.73s/it]
{'loss': 0.4054, 'learning_rate': 3.498233368984182e-08, 'rewards/chosen': -0.34668615460395813, 'rewards/rejected': -2.216237783432007, 'rewards/accuracies': 0.75, 'rewards/margins': 1.869551658630371, 'policy_logps/rejected': -533.4515380859375, 'policy_logps/chosen': -404.171875, 'referece_logps/rejected': -511.2891845703125, 'referece_logps/chosen': -400.7050476074219, 'logits/rejected': 0.46645036339759827, 'logits/chosen': 0.46774712204933167, 'epoch': 5.51}


 92%|█████████▏| 14787/16104 [68:12:37<7:05:57, 19.41s/it]
{'loss': 0.4637, 'learning_rate': 3.487694722733781e-08, 'rewards/chosen': -0.7814072370529175, 'rewards/rejected': -2.6624910831451416, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8810839653015137, 'policy_logps/rejected': -467.4259948730469, 'policy_logps/chosen': -414.51190185546875, 'referece_logps/rejected': -440.8010559082031, 'referece_logps/chosen': -406.69781494140625, 'logits/rejected': 0.008086584508419037, 'logits/chosen': 0.1842043250799179, 'epoch': 5.51}

 92%|█████████▏| 14788/16104 [68:13:00<7:27:09, 20.39s/it]

 92%|█████████▏| 14789/16104 [68:13:16<7:01:05, 19.21s/it]

 92%|█████████▏| 14790/16104 [68:13:36<7:06:21, 19.47s/it]

 92%|█████████▏| 14791/16104 [68:13:56<7:05:23, 19.44s/it]

 92%|█████████▏| 14792/16104 [68:14:18<7:20:58, 20.17s/it]

 92%|█████████▏| 14793/16104 [68:14:36<7:07:58, 19.59s/it]

 92%|█████████▏| 14794/16104 [68:14:58<7:24:55, 20.38s/it]

 92%|█████████▏| 14795/16104 [68:15:15<6:59:48, 19.24s/it]

 92%|█████████▏| 14796/16104 [68:15:35<7:04:30, 19.47s/it]

 92%|█████████▏| 14797/16104 [68:15:53<6:56:37, 19.13s/it]

 92%|█████████▏| 14798/16104 [68:16:06<6:15:46, 17.26s/it]

 92%|█████████▏| 14799/16104 [68:16:23<6:11:29, 17.08s/it]

 92%|█████████▏| 14800/16104 [68:16:39<6:06:59, 16.89s/it]

 92%|█████████▏| 14801/16104 [68:16:59<6:28:07, 17.87s/it]

 92%|█████████▏| 14802/16104 [68:17:13<5:59:44, 16.58s/it]

 92%|█████████▏| 14803/16104 [68:17:33<6:20:11, 17.53s/it]

 92%|█████████▏| 14804/16104 [68:17:47<5:59:28, 16.59s/it]

 92%|█████████▏| 14805/16104 [68:18:03<5:54:58, 16.40s/it]

 92%|█████████▏| 14806/16104 [68:18:23<6:16:55, 17.42s/it]

 92%|█████████▏| 14807/16104 [68:18:34<5:37:50, 15.63s/it]

 92%|█████████▏| 14808/16104 [68:18:50<5:39:35, 15.72s/it]


 92%|█████████▏| 14810/16104 [68:19:12<4:44:59, 13.21s/it]
{'loss': 0.359, 'learning_rate': 3.367623144973331e-08, 'rewards/chosen': -0.890306830406189, 'rewards/rejected': -1.769137978553772, 'rewards/accuracies': 0.75, 'rewards/margins': 0.878831148147583, 'policy_logps/rejected': -363.3008117675781, 'policy_logps/chosen': -489.65838623046875, 'referece_logps/rejected': -345.60943603515625, 'referece_logps/chosen': -480.75531005859375, 'logits/rejected': 0.07593518495559692, 'logits/chosen': 0.06517022103071213, 'epoch': 5.52}


 92%|█████████▏| 14812/16104 [68:19:52<5:57:11, 16.59s/it]
{'loss': 0.3358, 'learning_rate': 3.3572798252154086e-08, 'rewards/chosen': -0.5994939208030701, 'rewards/rejected': -2.4067471027374268, 'rewards/accuracies': 0.875, 'rewards/margins': 1.807253122329712, 'policy_logps/rejected': -389.93939208984375, 'policy_logps/chosen': -343.6122741699219, 'referece_logps/rejected': -365.8719177246094, 'referece_logps/chosen': -337.6173095703125, 'logits/rejected': -0.19107985496520996, 'logits/chosen': 0.1887572556734085, 'epoch': 5.52}

 92%|█████████▏| 14813/16104 [68:20:11<6:11:43, 17.28s/it]

 92%|█████████▏| 14814/16104 [68:20:31<6:31:25, 18.21s/it]

 92%|█████████▏| 14815/16104 [68:20:51<6:45:05, 18.86s/it]

 92%|█████████▏| 14816/16104 [68:21:11<6:49:47, 19.09s/it]

 92%|█████████▏| 14817/16104 [68:21:22<5:59:52, 16.78s/it]

 92%|█████████▏| 14818/16104 [68:21:37<5:44:10, 16.06s/it]

 92%|█████████▏| 14819/16104 [68:21:52<5:40:06, 15.88s/it]

 92%|█████████▏| 14820/16104 [68:22:03<5:06:01, 14.30s/it]


 92%|█████████▏| 14822/16104 [68:22:38<5:44:20, 16.12s/it]
{'loss': 0.3841, 'learning_rate': 3.3057978220366266e-08, 'rewards/chosen': -0.5759796500205994, 'rewards/rejected': -1.5537941455841064, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9778144359588623, 'policy_logps/rejected': -418.28643798828125, 'policy_logps/chosen': -325.7281799316406, 'referece_logps/rejected': -402.74847412109375, 'referece_logps/chosen': -319.9684143066406, 'logits/rejected': 0.6711326837539673, 'logits/chosen': 0.7529956698417664, 'epoch': 5.52}

 92%|█████████▏| 14823/16104 [68:22:57<6:04:12, 17.06s/it]


 92%|█████████▏| 14825/16104 [68:23:30<5:59:52, 16.88s/it]
{'loss': 0.3527, 'learning_rate': 3.290429484957424e-08, 'rewards/chosen': -0.21462363004684448, 'rewards/rejected': -1.5786868333816528, 'rewards/accuracies': 0.875, 'rewards/margins': 1.364063024520874, 'policy_logps/rejected': -525.6331176757812, 'policy_logps/chosen': -567.2593994140625, 'referece_logps/rejected': -509.8462219238281, 'referece_logps/chosen': -565.1131591796875, 'logits/rejected': -0.7879111766815186, 'logits/chosen': -0.8860241174697876, 'epoch': 5.52}


 92%|█████████▏| 14827/16104 [68:24:08<6:18:29, 17.78s/it]

 92%|█████████▏| 14828/16104 [68:24:28<6:32:49, 18.47s/it]
{'loss': 0.421, 'learning_rate': 3.2750963565496114e-08, 'rewards/chosen': -0.8055294752120972, 'rewards/rejected': -0.5117250680923462, 'rewards/accuracies': 0.5, 'rewards/margins': -0.293804407119751, 'policy_logps/rejected': -464.1786193847656, 'policy_logps/chosen': -431.3485107421875, 'referece_logps/rejected': -459.0614013671875, 'referece_logps/chosen': -423.293212890625, 'logits/rejected': 0.28790515661239624, 'logits/chosen': 0.31932637095451355, 'epoch': 5.52}


 92%|█████████▏| 14830/16104 [68:25:10<6:59:23, 19.75s/it]

 92%|█████████▏| 14831/16104 [68:25:27<6:41:49, 18.94s/it]

 92%|█████████▏| 14832/16104 [68:25:46<6:42:51, 19.00s/it]
{'loss': 0.4054, 'learning_rate': 3.254706964030096e-08, 'rewards/chosen': -0.591141939163208, 'rewards/rejected': -1.7937629222869873, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2026208639144897, 'policy_logps/rejected': -402.0560607910156, 'policy_logps/chosen': -356.0632629394531, 'referece_logps/rejected': -384.118408203125, 'referece_logps/chosen': -350.15185546875, 'logits/rejected': -0.03127400577068329, 'logits/chosen': 0.0331021249294281, 'epoch': 5.53}


 92%|█████████▏| 14834/16104 [68:26:23<6:31:45, 18.51s/it]
{'loss': 0.4228, 'learning_rate': 3.2445357480644255e-08, 'rewards/chosen': -0.844974160194397, 'rewards/rejected': -1.6886913776397705, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8437172174453735, 'policy_logps/rejected': -228.3333740234375, 'policy_logps/chosen': -402.9173889160156, 'referece_logps/rejected': -211.4464569091797, 'referece_logps/chosen': -394.4676513671875, 'logits/rejected': -0.8380104303359985, 'logits/chosen': -0.9331759810447693, 'epoch': 5.53}


 92%|█████████▏| 14836/16104 [68:26:59<6:26:20, 18.28s/it]

 92%|█████████▏| 14837/16104 [68:27:17<6:27:15, 18.34s/it]

 92%|█████████▏| 14838/16104 [68:27:38<6:39:50, 18.95s/it]

 92%|█████████▏| 14839/16104 [68:27:58<6:47:45, 19.34s/it]

 92%|█████████▏| 14840/16104 [68:28:18<6:51:10, 19.52s/it]

 92%|█████████▏| 14841/16104 [68:28:36<6:43:39, 19.18s/it]

 92%|█████████▏| 14842/16104 [68:28:53<6:29:34, 18.52s/it]

 92%|█████████▏| 14843/16104 [68:29:11<6:25:04, 18.32s/it]

 92%|█████████▏| 14844/16104 [68:29:32<6:40:17, 19.06s/it]

 92%|█████████▏| 14845/16104 [68:29:52<6:44:26, 19.27s/it]
{'loss': 0.411, 'learning_rate': 3.188873950330306e-08, 'rewards/chosen': -1.116607904434204, 'rewards/rejected': -2.071794033050537, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9551860690116882, 'policy_logps/rejected': -472.81903076171875, 'policy_logps/chosen': -560.8351440429688, 'referece_logps/rejected': -452.10107421875, 'referece_logps/chosen': -549.6690063476562, 'logits/rejected': -0.18789547681808472, 'logits/chosen': -0.15206314623355865, 'epoch': 5.53}

 92%|█████████▏| 14846/16104 [68:30:09<6:29:44, 18.59s/it]


 92%|█████████▏| 14848/16104 [68:30:43<6:09:17, 17.64s/it]

 92%|█████████▏| 14849/16104 [68:31:02<6:14:28, 17.90s/it]

 92%|█████████▏| 14850/16104 [68:31:20<6:15:15, 17.95s/it]

 92%|█████████▏| 14851/16104 [68:31:40<6:31:01, 18.72s/it]

 92%|█████████▏| 14852/16104 [68:31:55<6:02:58, 17.40s/it]

 92%|█████████▏| 14853/16104 [68:32:08<5:35:24, 16.09s/it]

 92%|█████████▏| 14854/16104 [68:32:29<6:08:29, 17.69s/it]

 92%|█████████▏| 14855/16104 [68:32:47<6:07:41, 17.66s/it]

 92%|█████████▏| 14856/16104 [68:33:09<6:34:58, 18.99s/it]
{'loss': 0.3534, 'learning_rate': 3.133686010524184e-08, 'rewards/chosen': -0.18449747562408447, 'rewards/rejected': -1.3449474573135376, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1604502201080322, 'policy_logps/rejected': -456.0874938964844, 'policy_logps/chosen': -371.89239501953125, 'referece_logps/rejected': -442.6379699707031, 'referece_logps/chosen': -370.04742431640625, 'logits/rejected': 0.5954747200012207, 'logits/chosen': 0.6026487350463867, 'epoch': 5.54}


 92%|█████████▏| 14858/16104 [68:33:40<5:58:45, 17.28s/it]

 92%|█████████▏| 14859/16104 [68:33:53<5:32:05, 16.00s/it]

 92%|█████████▏| 14860/16104 [68:34:10<5:39:07, 16.36s/it]
{'loss': 0.3501, 'learning_rate': 3.113735207052304e-08, 'rewards/chosen': -0.48310643434524536, 'rewards/rejected': -2.502432107925415, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0193259716033936, 'policy_logps/rejected': -395.3117980957031, 'policy_logps/chosen': -459.3653564453125, 'referece_logps/rejected': -370.2874755859375, 'referece_logps/chosen': -454.5342712402344, 'logits/rejected': 0.4960837960243225, 'logits/chosen': 0.19953064620494843, 'epoch': 5.54}


 92%|█████████▏| 14862/16104 [68:34:40<5:24:08, 15.66s/it]

 92%|█████████▏| 14863/16104 [68:34:58<5:38:21, 16.36s/it]

 92%|█████████▏| 14864/16104 [68:35:13<5:27:55, 15.87s/it]
{'loss': 0.3231, 'learning_rate': 3.093847111134107e-08, 'rewards/chosen': -0.3328344225883484, 'rewards/rejected': -4.102996826171875, 'rewards/accuracies': 1.0, 'rewards/margins': 3.770162343978882, 'policy_logps/rejected': -437.1786804199219, 'policy_logps/chosen': -361.55078125, 'referece_logps/rejected': -396.148681640625, 'referece_logps/chosen': -358.2224426269531, 'logits/rejected': -0.7029698491096497, 'logits/chosen': -0.5020608305931091, 'epoch': 5.54}


 92%|█████████▏| 14866/16104 [68:35:51<6:00:01, 17.45s/it]
{'loss': 0.3935, 'learning_rate': 3.0839265825317594e-08, 'rewards/chosen': -0.4464365243911743, 'rewards/rejected': -1.63910710811615, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1926705837249756, 'policy_logps/rejected': -353.63751220703125, 'policy_logps/chosen': -425.2763977050781, 'referece_logps/rejected': -337.2464294433594, 'referece_logps/chosen': -420.81201171875, 'logits/rejected': -0.7055832743644714, 'logits/chosen': -0.7113300561904907, 'epoch': 5.54}


 92%|█████████▏| 14868/16104 [68:36:26<5:58:47, 17.42s/it]

 92%|█████████▏| 14869/16104 [68:36:49<6:29:08, 18.91s/it]

 92%|█████████▏| 14870/16104 [68:37:09<6:36:28, 19.28s/it]

 92%|█████████▏| 14871/16104 [68:37:26<6:23:01, 18.64s/it]

 92%|█████████▏| 14872/16104 [68:37:46<6:32:52, 19.13s/it]

 92%|█████████▏| 14873/16104 [68:38:08<6:47:16, 19.85s/it]

 92%|█████████▏| 14874/16104 [68:38:25<6:29:33, 19.00s/it]

 92%|█████████▏| 14875/16104 [68:38:40<6:05:00, 17.82s/it]

 92%|█████████▏| 14876/16104 [68:38:54<5:44:20, 16.82s/it]

 92%|█████████▏| 14877/16104 [68:39:07<5:18:14, 15.56s/it]

 92%|█████████▏| 14878/16104 [68:39:23<5:21:13, 15.72s/it]

 92%|█████████▏| 14879/16104 [68:39:39<5:20:46, 15.71s/it]

 92%|█████████▏| 14880/16104 [68:39:54<5:17:17, 15.55s/it]

 92%|█████████▏| 14881/16104 [68:40:08<5:05:14, 14.98s/it]

 92%|█████████▏| 14882/16104 [68:40:24<5:16:38, 15.55s/it]

 92%|█████████▏| 14883/16104 [68:40:46<5:55:01, 17.45s/it]
{'loss': 0.4472, 'learning_rate': 3.000235399899853e-08, 'rewards/chosen': 0.0797092542052269, 'rewards/rejected': -1.4610531330108643, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5407624244689941, 'policy_logps/rejected': -564.0650634765625, 'policy_logps/chosen': -542.1643676757812, 'referece_logps/rejected': -549.4545288085938, 'referece_logps/chosen': -542.9614868164062, 'logits/rejected': -0.005614377558231354, 'logits/chosen': -0.024339143186807632, 'epoch': 5.55}


 92%|█████████▏| 14885/16104 [68:41:25<6:12:17, 18.32s/it]

 92%|█████████▏| 14886/16104 [68:41:44<6:19:51, 18.71s/it]

 92%|█████████▏| 14887/16104 [68:41:55<5:31:23, 16.34s/it]

 92%|█████████▏| 14888/16104 [68:42:06<4:56:37, 14.64s/it]

 92%|█████████▏| 14889/16104 [68:42:16<4:32:17, 13.45s/it]

 92%|█████████▏| 14890/16104 [68:42:36<5:07:10, 15.18s/it]

 92%|█████████▏| 14891/16104 [68:42:47<4:42:01, 13.95s/it]

 92%|█████████▏| 14892/16104 [68:43:02<4:48:56, 14.30s/it]

 92%|█████████▏| 14893/16104 [68:43:13<4:26:42, 13.21s/it]

 92%|█████████▏| 14894/16104 [68:43:32<5:04:14, 15.09s/it]

 92%|█████████▏| 14895/16104 [68:43:43<4:37:19, 13.76s/it]

 92%|█████████▏| 14896/16104 [68:43:55<4:27:14, 13.27s/it]

 93%|█████████▎| 14897/16104 [68:44:05<4:11:13, 12.49s/it]

 93%|█████████▎| 14898/16104 [68:44:23<4:41:09, 13.99s/it]

 93%|█████████▎| 14899/16104 [68:44:39<4:55:59, 14.74s/it]

 93%|█████████▎| 14900/16104 [68:44:54<4:57:06, 14.81s/it]

 93%|█████████▎| 14901/16104 [68:45:10<5:01:27, 15.04s/it]

 93%|█████████▎| 14902/16104 [68:45:28<5:19:12, 15.93s/it]
{'loss': 0.286, 'learning_rate': 2.908040183646532e-08, 'rewards/chosen': -0.10182610154151917, 'rewards/rejected': -1.2145273685455322, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1127012968063354, 'policy_logps/rejected': -424.1656494140625, 'policy_logps/chosen': -456.5723876953125, 'referece_logps/rejected': -412.02044677734375, 'referece_logps/chosen': -455.55413818359375, 'logits/rejected': -0.24265974760055542, 'logits/chosen': -0.21604511141777039, 'epoch': 5.55}


 93%|█████████▎| 14904/16104 [68:45:58<5:03:55, 15.20s/it]

 93%|█████████▎| 14905/16104 [68:46:09<4:37:16, 13.88s/it]

 93%|█████████▎| 14906/16104 [68:46:21<4:25:55, 13.32s/it]

 93%|█████████▎| 14907/16104 [68:46:37<4:44:57, 14.28s/it]
{'loss': 0.4186, 'learning_rate': 2.8840138824462345e-08, 'rewards/chosen': -0.4436306953430176, 'rewards/rejected': -2.3682188987731934, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9245882034301758, 'policy_logps/rejected': -302.9287414550781, 'policy_logps/chosen': -428.85986328125, 'referece_logps/rejected': -279.2465515136719, 'referece_logps/chosen': -424.4234924316406, 'logits/rejected': 0.5243234038352966, 'logits/chosen': 0.4211678206920624, 'epoch': 5.55}


 93%|█████████▎| 14909/16104 [68:47:07<4:43:40, 14.24s/it]
{'loss': 0.4546, 'learning_rate': 2.874430860211141e-08, 'rewards/chosen': -0.929816722869873, 'rewards/rejected': -1.8610248565673828, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9312081336975098, 'policy_logps/rejected': -304.55145263671875, 'policy_logps/chosen': -349.7723083496094, 'referece_logps/rejected': -285.94122314453125, 'referece_logps/chosen': -340.4741516113281, 'logits/rejected': -0.8072054386138916, 'logits/chosen': -0.9842305183410645, 'epoch': 5.55}


 93%|█████████▎| 14911/16104 [68:47:43<5:26:51, 16.44s/it]

 93%|█████████▎| 14912/16104 [68:48:01<5:32:57, 16.76s/it]

 93%|█████████▎| 14913/16104 [68:48:18<5:38:10, 17.04s/it]
{'loss': 0.3723, 'learning_rate': 2.8553119641196334e-08, 'rewards/chosen': 0.01360950618982315, 'rewards/rejected': -2.336644411087036, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3502533435821533, 'policy_logps/rejected': -388.16180419921875, 'policy_logps/chosen': -331.263671875, 'referece_logps/rejected': -364.79541015625, 'referece_logps/chosen': -331.3997497558594, 'logits/rejected': -0.09927419573068619, 'logits/chosen': -0.0922626182436943, 'epoch': 5.56}


 93%|█████████▎| 14915/16104 [68:48:57<6:03:26, 18.34s/it]

 93%|█████████▎| 14916/16104 [68:49:19<6:20:39, 19.23s/it]

 93%|█████████▎| 14917/16104 [68:49:37<6:14:19, 18.92s/it]

 93%|█████████▎| 14918/16104 [68:49:51<5:43:18, 17.37s/it]

 93%|█████████▎| 14919/16104 [68:50:03<5:12:41, 15.83s/it]

 93%|█████████▎| 14920/16104 [68:50:23<5:34:45, 16.96s/it]

 93%|█████████▎| 14921/16104 [68:50:42<5:48:33, 17.68s/it]

 93%|█████████▎| 14922/16104 [68:50:58<5:37:02, 17.11s/it]

 93%|█████████▎| 14923/16104 [68:51:17<5:52:31, 17.91s/it]

 93%|█████████▎| 14924/16104 [68:51:37<6:00:00, 18.31s/it]
{'loss': 0.3306, 'learning_rate': 2.8030592351945492e-08, 'rewards/chosen': 0.29436877369880676, 'rewards/rejected': -1.3837177753448486, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6780864000320435, 'policy_logps/rejected': -466.86785888671875, 'policy_logps/chosen': -609.8486328125, 'referece_logps/rejected': -453.0306701660156, 'referece_logps/chosen': -612.7923583984375, 'logits/rejected': -0.3399304151535034, 'logits/chosen': -0.3678969740867615, 'epoch': 5.56}


 93%|█████████▎| 14926/16104 [68:52:16<6:12:20, 18.96s/it]

 93%|█████████▎| 14927/16104 [68:52:38<6:28:12, 19.79s/it]

 93%|█████████▎| 14928/16104 [68:52:55<6:12:52, 19.02s/it]

 93%|█████████▎| 14929/16104 [68:53:10<5:49:15, 17.83s/it]

 93%|█████████▎| 14930/16104 [68:53:29<5:57:44, 18.28s/it]

 93%|█████████▎| 14931/16104 [68:53:46<5:47:23, 17.77s/it]

 93%|█████████▎| 14932/16104 [68:54:01<5:34:06, 17.10s/it]

 93%|█████████▎| 14933/16104 [68:54:21<5:49:39, 17.92s/it]

 93%|█████████▎| 14934/16104 [68:54:32<5:08:01, 15.80s/it]

 93%|█████████▎| 14935/16104 [68:54:45<4:54:15, 15.10s/it]

 93%|█████████▎| 14936/16104 [68:55:05<5:22:39, 16.58s/it]

 93%|█████████▎| 14937/16104 [68:55:21<5:16:01, 16.25s/it]

 93%|█████████▎| 14938/16104 [68:55:35<5:05:18, 15.71s/it]

 93%|█████████▎| 14939/16104 [68:55:53<5:14:44, 16.21s/it]
{'loss': 0.4382, 'learning_rate': 2.7325722621926785e-08, 'rewards/chosen': -0.5253702402114868, 'rewards/rejected': -1.2701913118362427, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7448209524154663, 'policy_logps/rejected': -275.99041748046875, 'policy_logps/chosen': -344.3666076660156, 'referece_logps/rejected': -263.28851318359375, 'referece_logps/chosen': -339.1128845214844, 'logits/rejected': -0.8163537383079529, 'logits/chosen': -1.0230116844177246, 'epoch': 5.57}


 93%|█████████▎| 14941/16104 [68:56:15<4:23:31, 13.60s/it]

 93%|█████████▎| 14942/16104 [68:56:27<4:11:08, 12.97s/it]

 93%|█████████▎| 14943/16104 [68:56:43<4:32:12, 14.07s/it]

 93%|█████████▎| 14944/16104 [68:56:59<4:44:33, 14.72s/it]

 93%|█████████▎| 14945/16104 [68:57:12<4:32:42, 14.12s/it]

 93%|█████████▎| 14946/16104 [68:57:31<5:00:20, 15.56s/it]
{'loss': 0.3577, 'learning_rate': 2.6999812698594083e-08, 'rewards/chosen': -0.08929213881492615, 'rewards/rejected': -1.734663724899292, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6453715562820435, 'policy_logps/rejected': -348.69244384765625, 'policy_logps/chosen': -342.79205322265625, 'referece_logps/rejected': -331.3458251953125, 'referece_logps/chosen': -341.89910888671875, 'logits/rejected': -0.19065767526626587, 'logits/chosen': -0.20459291338920593, 'epoch': 5.57}


 93%|█████████▎| 14948/16104 [68:58:06<5:25:04, 16.87s/it]

 93%|█████████▎| 14949/16104 [68:58:16<4:48:29, 14.99s/it]

 93%|█████████▎| 14950/16104 [68:58:36<5:16:37, 16.46s/it]

 93%|█████████▎| 14951/16104 [68:58:48<4:51:01, 15.14s/it]

 93%|█████████▎| 14952/16104 [68:59:08<5:18:01, 16.56s/it]

 93%|█████████▎| 14953/16104 [68:59:30<5:50:33, 18.27s/it]
{'loss': 0.4088, 'learning_rate': 2.667583139504981e-08, 'rewards/chosen': -1.0255916118621826, 'rewards/rejected': -2.5571365356445312, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5315446853637695, 'policy_logps/rejected': -636.3704833984375, 'policy_logps/chosen': -457.0217590332031, 'referece_logps/rejected': -610.7991333007812, 'referece_logps/chosen': -446.765869140625, 'logits/rejected': -0.5679398775100708, 'logits/chosen': -0.6773919463157654, 'epoch': 5.57}

 93%|█████████▎| 14954/16104 [68:59:43<5:19:05, 16.65s/it]

 93%|█████████▎| 14955/16104 [68:59:57<5:03:47, 15.86s/it]


 93%|█████████▎| 14957/16104 [69:00:33<5:23:56, 16.95s/it]

 93%|█████████▎| 14958/16104 [69:00:50<5:26:40, 17.10s/it]
{'loss': 0.3437, 'learning_rate': 2.6445597321733237e-08, 'rewards/chosen': -0.7721866369247437, 'rewards/rejected': -4.497446060180664, 'rewards/accuracies': 1.0, 'rewards/margins': 3.72525954246521, 'policy_logps/rejected': -508.0946044921875, 'policy_logps/chosen': -506.03009033203125, 'referece_logps/rejected': -463.1201171875, 'referece_logps/chosen': -498.3082580566406, 'logits/rejected': -0.1756199598312378, 'logits/chosen': -0.19559063017368317, 'epoch': 5.57}

 93%|█████████▎| 14959/16104 [69:01:05<5:14:28, 16.48s/it]


 93%|█████████▎| 14961/16104 [69:01:44<5:44:19, 18.07s/it]
{'loss': 0.3492, 'learning_rate': 2.6307929446999777e-08, 'rewards/chosen': -0.7464101910591125, 'rewards/rejected': -2.382049560546875, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6356394290924072, 'policy_logps/rejected': -432.51031494140625, 'policy_logps/chosen': -410.49114990234375, 'referece_logps/rejected': -408.6898193359375, 'referece_logps/chosen': -403.02703857421875, 'logits/rejected': -0.24512453377246857, 'logits/chosen': -0.23647084832191467, 'epoch': 5.57}

 93%|█████████▎| 14962/16104 [69:01:55<5:01:58, 15.87s/it]

 93%|█████████▎| 14963/16104 [69:02:15<5:24:22, 17.06s/it]

 93%|█████████▎| 14964/16104 [69:02:35<5:40:39, 17.93s/it]


 93%|█████████▎| 14966/16104 [69:03:09<5:31:29, 17.48s/it]

 93%|█████████▎| 14967/16104 [69:03:29<5:44:41, 18.19s/it]

 93%|█████████▎| 14968/16104 [69:03:42<5:18:11, 16.81s/it]
{'loss': 0.4318, 'learning_rate': 2.5988083057666533e-08, 'rewards/chosen': -0.5729520320892334, 'rewards/rejected': -1.1691389083862305, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5961868166923523, 'policy_logps/rejected': -280.489501953125, 'policy_logps/chosen': -379.91082763671875, 'referece_logps/rejected': -268.798095703125, 'referece_logps/chosen': -374.18133544921875, 'logits/rejected': -0.19899824261665344, 'logits/chosen': -0.15088415145874023, 'epoch': 5.58}


 93%|█████████▎| 14970/16104 [69:04:21<5:41:57, 18.09s/it]
{'loss': 0.4156, 'learning_rate': 2.5897052951994402e-08, 'rewards/chosen': -0.9628782272338867, 'rewards/rejected': -1.9289169311523438, 'rewards/accuracies': 0.75, 'rewards/margins': 0.966038703918457, 'policy_logps/rejected': -300.824951171875, 'policy_logps/chosen': -421.1722717285156, 'referece_logps/rejected': -281.5357971191406, 'referece_logps/chosen': -411.5434875488281, 'logits/rejected': -0.793169379234314, 'logits/chosen': -0.8395971059799194, 'epoch': 5.58}


 93%|█████████▎| 14972/16104 [69:04:54<5:36:39, 17.84s/it]

 93%|█████████▎| 14973/16104 [69:05:06<5:02:15, 16.03s/it]

 93%|█████████▎| 14974/16104 [69:05:26<5:21:35, 17.08s/it]

 93%|█████████▎| 14975/16104 [69:05:42<5:18:01, 16.90s/it]

 93%|█████████▎| 14976/16104 [69:05:57<5:03:52, 16.16s/it]
{'loss': 0.2922, 'learning_rate': 2.562490839461817e-08, 'rewards/chosen': -0.12923413515090942, 'rewards/rejected': -1.80293607711792, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6737020015716553, 'policy_logps/rejected': -386.49078369140625, 'policy_logps/chosen': -453.1911926269531, 'referece_logps/rejected': -368.4613952636719, 'referece_logps/chosen': -451.89886474609375, 'logits/rejected': -0.5229706168174744, 'logits/chosen': -0.4632725119590759, 'epoch': 5.58}


 93%|█████████▎| 14978/16104 [69:06:34<5:28:28, 17.50s/it]
{'loss': 0.3932, 'learning_rate': 2.5534508844300305e-08, 'rewards/chosen': 0.27749061584472656, 'rewards/rejected': -1.3783656358718872, 'rewards/accuracies': 0.625, 'rewards/margins': 1.6558562517166138, 'policy_logps/rejected': -344.4449462890625, 'policy_logps/chosen': -528.1041870117188, 'referece_logps/rejected': -330.6612854003906, 'referece_logps/chosen': -530.8790283203125, 'logits/rejected': 0.35622525215148926, 'logits/chosen': 0.2607783079147339, 'epoch': 5.58}

 93%|█████████▎| 14979/16104 [69:06:51<5:26:17, 17.40s/it]


 93%|█████████▎| 14981/16104 [69:07:34<6:03:41, 19.43s/it]
{'loss': 0.4467, 'learning_rate': 2.539920516489502e-08, 'rewards/chosen': -0.5256666541099548, 'rewards/rejected': -2.9523658752441406, 'rewards/accuracies': 0.875, 'rewards/margins': 2.426699161529541, 'policy_logps/rejected': -501.08428955078125, 'policy_logps/chosen': -368.1560363769531, 'referece_logps/rejected': -471.56060791015625, 'referece_logps/chosen': -362.89935302734375, 'logits/rejected': -0.7410266399383545, 'logits/chosen': -0.6851944327354431, 'epoch': 5.58}

 93%|█████████▎| 14982/16104 [69:07:56<6:13:43, 19.99s/it]


 93%|█████████▎| 14984/16104 [69:08:27<5:25:53, 17.46s/it]

 93%|█████████▎| 14985/16104 [69:08:42<5:14:06, 16.84s/it]

 93%|█████████▎| 14986/16104 [69:08:55<4:49:15, 15.52s/it]

 93%|█████████▎| 14987/16104 [69:09:15<5:12:54, 16.81s/it]
{'loss': 0.3983, 'learning_rate': 2.5129662312401655e-08, 'rewards/chosen': -0.12818871438503265, 'rewards/rejected': -0.6474010944366455, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5192123651504517, 'policy_logps/rejected': -514.376220703125, 'policy_logps/chosen': -547.4428100585938, 'referece_logps/rejected': -507.9021911621094, 'referece_logps/chosen': -546.1609497070312, 'logits/rejected': -0.34664565324783325, 'logits/chosen': -0.26219093799591064, 'epoch': 5.58}


 93%|█████████▎| 14989/16104 [69:09:40<4:37:59, 14.96s/it]

 93%|█████████▎| 14990/16104 [69:09:58<4:54:39, 15.87s/it]

 93%|█████████▎| 14991/16104 [69:10:18<5:16:28, 17.06s/it]

 93%|█████████▎| 14992/16104 [69:10:38<5:31:32, 17.89s/it]

 93%|█████████▎| 14993/16104 [69:10:55<5:26:20, 17.62s/it]

 93%|█████████▎| 14994/16104 [69:11:06<4:49:47, 15.66s/it]

 93%|█████████▎| 14995/16104 [69:11:24<5:03:15, 16.41s/it]

 93%|█████████▎| 14996/16104 [69:11:35<4:31:33, 14.70s/it]

 93%|█████████▎| 14997/16104 [69:11:57<5:11:20, 16.88s/it]
{'loss': 0.3998, 'learning_rate': 2.4683579237028683e-08, 'rewards/chosen': -1.3446205854415894, 'rewards/rejected': -2.5947582721710205, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2501376867294312, 'policy_logps/rejected': -312.6544494628906, 'policy_logps/chosen': -498.1532897949219, 'referece_logps/rejected': -286.7068786621094, 'referece_logps/chosen': -484.70709228515625, 'logits/rejected': -0.0815659761428833, 'logits/chosen': -0.2624807059764862, 'epoch': 5.59}


 93%|█████████▎| 14999/16104 [69:12:20<4:20:03, 14.12s/it]
{'loss': 0.3558, 'learning_rate': 2.4594836003809405e-08, 'rewards/chosen': -0.4057910442352295, 'rewards/rejected': -2.8974807262420654, 'rewards/accuracies': 0.875, 'rewards/margins': 2.491689682006836, 'policy_logps/rejected': -408.979736328125, 'policy_logps/chosen': -362.9873046875, 'referece_logps/rejected': -380.00494384765625, 'referece_logps/chosen': -358.92938232421875, 'logits/rejected': -0.8784615993499756, 'logits/chosen': -0.9399410486221313, 'epoch': 5.59}

 93%|█████████▎| 15000/16104 [69:12:34<4:15:58, 13.91s/it]


 93%|█████████▎| 15002/16104 [69:13:29<6:08:36, 20.07s/it]
{'loss': 0.4015, 'learning_rate': 2.4462017085053797e-08, 'rewards/chosen': -0.3314451277256012, 'rewards/rejected': -1.6734013557434082, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3419562578201294, 'policy_logps/rejected': -343.11370849609375, 'policy_logps/chosen': -312.4888000488281, 'referece_logps/rejected': -326.3796691894531, 'referece_logps/chosen': -309.17437744140625, 'logits/rejected': -0.14026592671871185, 'logits/chosen': -0.3184097409248352, 'epoch': 5.59}

 93%|█████████▎| 15003/16104 [69:13:50<6:15:02, 20.44s/it]


 93%|█████████▎| 15005/16104 [69:14:27<5:51:22, 19.18s/it]
{'loss': 0.4187, 'learning_rate': 2.432955332655906e-08, 'rewards/chosen': -0.48632508516311646, 'rewards/rejected': -1.7388875484466553, 'rewards/accuracies': 1.0, 'rewards/margins': 1.252562403678894, 'policy_logps/rejected': -387.900390625, 'policy_logps/chosen': -510.4930114746094, 'referece_logps/rejected': -370.5115051269531, 'referece_logps/chosen': -505.62982177734375, 'logits/rejected': 0.1642272174358368, 'logits/chosen': 0.15342293679714203, 'epoch': 5.59}


 93%|█████████▎| 15007/16104 [69:15:00<5:29:11, 18.01s/it]
{'loss': 0.3396, 'learning_rate': 2.4241441489305404e-08, 'rewards/chosen': -0.02780170738697052, 'rewards/rejected': -2.533897638320923, 'rewards/accuracies': 0.875, 'rewards/margins': 2.5060958862304688, 'policy_logps/rejected': -472.27587890625, 'policy_logps/chosen': -530.0946655273438, 'referece_logps/rejected': -446.9368896484375, 'referece_logps/chosen': -529.816650390625, 'logits/rejected': -0.6800639629364014, 'logits/chosen': -0.5717042684555054, 'epoch': 5.59}


 93%|█████████▎| 15009/16104 [69:15:43<5:59:05, 19.68s/it]

 93%|█████████▎| 15010/16104 [69:16:03<5:59:46, 19.73s/it]
{'loss': 0.3947, 'learning_rate': 2.4109569771682326e-08, 'rewards/chosen': -0.8882837891578674, 'rewards/rejected': -2.1830644607543945, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2947807312011719, 'policy_logps/rejected': -320.2552490234375, 'policy_logps/chosen': -343.7838439941406, 'referece_logps/rejected': -298.42462158203125, 'referece_logps/chosen': -334.9010009765625, 'logits/rejected': -0.029500901699066162, 'logits/chosen': -0.024062685668468475, 'epoch': 5.59}

 93%|█████████▎| 15011/16104 [69:16:20<5:45:21, 18.96s/it]

 93%|█████████▎| 15012/16104 [69:16:38<5:37:57, 18.57s/it]


 93%|█████████▎| 15014/16104 [69:17:06<4:55:38, 16.27s/it]

 93%|█████████▎| 15015/16104 [69:17:25<5:05:39, 16.84s/it]
{'loss': 0.5127, 'learning_rate': 2.3890573129460077e-08, 'rewards/chosen': -0.7004218101501465, 'rewards/rejected': -2.3889102935791016, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6884887218475342, 'policy_logps/rejected': -461.5690612792969, 'policy_logps/chosen': -460.52740478515625, 'referece_logps/rejected': -437.67999267578125, 'referece_logps/chosen': -453.52313232421875, 'logits/rejected': 0.06362534314393997, 'logits/chosen': 0.1626541018486023, 'epoch': 5.59}


 93%|█████████▎| 15017/16104 [69:17:55<4:57:52, 16.44s/it]

 93%|█████████▎| 15018/16104 [69:18:14<5:08:09, 17.03s/it]
{'loss': 0.3607, 'learning_rate': 2.375964895437388e-08, 'rewards/chosen': 0.1562405228614807, 'rewards/rejected': -1.894965410232544, 'rewards/accuracies': 1.0, 'rewards/margins': 2.05120587348938, 'policy_logps/rejected': -560.2531127929688, 'policy_logps/chosen': -536.9414672851562, 'referece_logps/rejected': -541.3034057617188, 'referece_logps/chosen': -538.5038452148438, 'logits/rejected': 0.17365732789039612, 'logits/chosen': 0.13006055355072021, 'epoch': 5.6}


 93%|█████████▎| 15020/16104 [69:18:47<5:09:59, 17.16s/it]
{'loss': 0.5195, 'learning_rate': 2.3672563621362273e-08, 'rewards/chosen': -0.09274464100599289, 'rewards/rejected': -1.6147308349609375, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5219862461090088, 'policy_logps/rejected': -466.5525817871094, 'policy_logps/chosen': -547.5447998046875, 'referece_logps/rejected': -450.4052734375, 'referece_logps/chosen': -546.6173095703125, 'logits/rejected': 0.4910767078399658, 'logits/chosen': 0.42006146907806396, 'epoch': 5.6}


 93%|█████████▎| 15022/16104 [69:19:17<4:45:27, 15.83s/it]

 93%|█████████▎| 15023/16104 [69:19:35<4:56:26, 16.45s/it]

 93%|█████████▎| 15024/16104 [69:19:55<5:13:08, 17.40s/it]

 93%|█████████▎| 15025/16104 [69:20:07<4:42:25, 15.70s/it]
{'loss': 0.5273, 'learning_rate': 2.3455541467860883e-08, 'rewards/chosen': -0.5176588892936707, 'rewards/rejected': -1.0416510105133057, 'rewards/accuracies': 0.625, 'rewards/margins': 0.523992121219635, 'policy_logps/rejected': -344.11773681640625, 'policy_logps/chosen': -459.9649963378906, 'referece_logps/rejected': -333.70123291015625, 'referece_logps/chosen': -454.7884216308594, 'logits/rejected': -0.8291735053062439, 'logits/chosen': -0.7712987661361694, 'epoch': 5.6}


 93%|█████████▎| 15027/16104 [69:20:43<5:03:18, 16.90s/it]
{'loss': 0.4574, 'learning_rate': 2.3369009114942882e-08, 'rewards/chosen': -0.26205483078956604, 'rewards/rejected': -1.2355084419250488, 'rewards/accuracies': 0.75, 'rewards/margins': 0.97345370054245, 'policy_logps/rejected': -257.3893127441406, 'policy_logps/chosen': -349.1766357421875, 'referece_logps/rejected': -245.03421020507812, 'referece_logps/chosen': -346.5561218261719, 'logits/rejected': -0.16696667671203613, 'logits/chosen': -0.25391241908073425, 'epoch': 5.6}

 93%|█████████▎| 15028/16104 [69:20:57<4:43:46, 15.82s/it]

 93%|█████████▎| 15029/16104 [69:21:16<5:05:10, 17.03s/it]


 93%|█████████▎| 15031/16104 [69:21:46<4:40:50, 15.70s/it]
{'loss': 0.4543, 'learning_rate': 2.319641850067444e-08, 'rewards/chosen': -0.7562859654426575, 'rewards/rejected': -3.136249542236328, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3799636363983154, 'policy_logps/rejected': -551.3189697265625, 'policy_logps/chosen': -425.0320739746094, 'referece_logps/rejected': -519.9564819335938, 'referece_logps/chosen': -417.46923828125, 'logits/rejected': -0.28778254985809326, 'logits/chosen': -0.2693033218383789, 'epoch': 5.6}

 93%|█████████▎| 15032/16104 [69:21:58<4:22:36, 14.70s/it]

 93%|█████████▎| 15033/16104 [69:22:16<4:41:34, 15.77s/it]

 93%|█████████▎| 15034/16104 [69:22:28<4:21:18, 14.65s/it]


 93%|█████████▎| 15036/16104 [69:22:55<4:10:15, 14.06s/it]
{'loss': 0.363, 'learning_rate': 2.2981569298424764e-08, 'rewards/chosen': -1.4045590162277222, 'rewards/rejected': -2.791611909866333, 'rewards/accuracies': 0.75, 'rewards/margins': 1.38705313205719, 'policy_logps/rejected': -353.133056640625, 'policy_logps/chosen': -435.8217468261719, 'referece_logps/rejected': -325.2169494628906, 'referece_logps/chosen': -421.77618408203125, 'logits/rejected': 0.38477352261543274, 'logits/chosen': 0.4285898506641388, 'epoch': 5.6}


 93%|█████████▎| 15038/16104 [69:23:32<4:48:10, 16.22s/it]
{'loss': 0.3732, 'learning_rate': 2.2895906260341656e-08, 'rewards/chosen': -0.3749069571495056, 'rewards/rejected': -1.7050695419311523, 'rewards/accuracies': 0.875, 'rewards/margins': 1.330162763595581, 'policy_logps/rejected': -294.7042236328125, 'policy_logps/chosen': -479.53668212890625, 'referece_logps/rejected': -277.6535339355469, 'referece_logps/chosen': -475.7875671386719, 'logits/rejected': -0.5082470178604126, 'logits/chosen': -0.6108611822128296, 'epoch': 5.6}


 93%|█████████▎| 15040/16104 [69:24:05<4:59:21, 16.88s/it]

 93%|█████████▎| 15041/16104 [69:24:22<4:56:55, 16.76s/it]

 93%|█████████▎| 15042/16104 [69:24:41<5:10:08, 17.52s/it]
{'loss': 0.3447, 'learning_rate': 2.2725054505256636e-08, 'rewards/chosen': 0.11701290309429169, 'rewards/rejected': -1.2906455993652344, 'rewards/accuracies': 0.875, 'rewards/margins': 1.407658576965332, 'policy_logps/rejected': -398.79205322265625, 'policy_logps/chosen': -244.48838806152344, 'referece_logps/rejected': -385.8856201171875, 'referece_logps/chosen': -245.6585235595703, 'logits/rejected': -0.5879167318344116, 'logits/chosen': -0.42961084842681885, 'epoch': 5.6}


 93%|█████████▎| 15044/16104 [69:25:14<5:03:59, 17.21s/it]
{'loss': 0.4372, 'learning_rate': 2.2639865815899718e-08, 'rewards/chosen': -0.7528456449508667, 'rewards/rejected': -1.0748651027679443, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3220195770263672, 'policy_logps/rejected': -522.8102416992188, 'policy_logps/chosen': -520.3379516601562, 'referece_logps/rejected': -512.0615844726562, 'referece_logps/chosen': -512.8094482421875, 'logits/rejected': 0.002649083733558655, 'logits/chosen': 0.025540009140968323, 'epoch': 5.61}

 93%|█████████▎| 15045/16104 [69:25:26<4:39:49, 15.85s/it]

 93%|█████████▎| 15046/16104 [69:25:41<4:30:36, 15.35s/it]

 93%|█████████▎| 15047/16104 [69:26:00<4:52:55, 16.63s/it]


 93%|█████████▎| 15049/16104 [69:26:32<4:49:55, 16.49s/it]
{'loss': 0.4533, 'learning_rate': 2.2427586001916966e-08, 'rewards/chosen': -0.342359721660614, 'rewards/rejected': -2.0799362659454346, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7375767230987549, 'policy_logps/rejected': -514.2836303710938, 'policy_logps/chosen': -577.234130859375, 'referece_logps/rejected': -493.48431396484375, 'referece_logps/chosen': -573.810546875, 'logits/rejected': 0.179208442568779, 'logits/chosen': 0.15898674726486206, 'epoch': 5.61}


 93%|█████████▎| 15051/16104 [69:26:55<4:05:45, 14.00s/it]
{'loss': 0.4788, 'learning_rate': 2.2342950876153454e-08, 'rewards/chosen': -0.5140957832336426, 'rewards/rejected': -1.5348085165023804, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0207127332687378, 'policy_logps/rejected': -474.7151794433594, 'policy_logps/chosen': -504.6514892578125, 'referece_logps/rejected': -459.3670654296875, 'referece_logps/chosen': -499.5105285644531, 'logits/rejected': -0.07806456089019775, 'logits/chosen': -0.009449601173400879, 'epoch': 5.61}


 93%|█████████▎| 15053/16104 [69:27:27<4:30:35, 15.45s/it]

 93%|█████████▎| 15054/16104 [69:27:40<4:17:24, 14.71s/it]

 93%|█████████▎| 15055/16104 [69:28:00<4:43:55, 16.24s/it]

 93%|█████████▎| 15056/16104 [69:28:16<4:40:47, 16.08s/it]

 93%|█████████▎| 15057/16104 [69:28:34<4:52:45, 16.78s/it]

 94%|█████████▎| 15058/16104 [69:28:46<4:26:24, 15.28s/it]
{'loss': 0.4126, 'learning_rate': 2.2047973786734175e-08, 'rewards/chosen': -0.5445038080215454, 'rewards/rejected': -1.8382081985473633, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2937042713165283, 'policy_logps/rejected': -224.44583129882812, 'policy_logps/chosen': -307.2218017578125, 'referece_logps/rejected': -206.06375122070312, 'referece_logps/chosen': -301.7767333984375, 'logits/rejected': -0.23489539325237274, 'logits/chosen': -0.27274182438850403, 'epoch': 5.61}

 94%|█████████▎| 15059/16104 [69:29:07<4:58:10, 17.12s/it]


 94%|█████████▎| 15061/16104 [69:29:40<4:57:04, 17.09s/it]
{'loss': 0.4111, 'learning_rate': 2.1922148398642594e-08, 'rewards/chosen': -1.3789644241333008, 'rewards/rejected': -3.0881025791168213, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7091381549835205, 'policy_logps/rejected': -346.3568420410156, 'policy_logps/chosen': -434.3025817871094, 'referece_logps/rejected': -315.475830078125, 'referece_logps/chosen': -420.512939453125, 'logits/rejected': 0.0033330023288726807, 'logits/chosen': 0.23433849215507507, 'epoch': 5.61}


 94%|█████████▎| 15063/16104 [69:30:16<4:57:13, 17.13s/it]

 94%|█████████▎| 15064/16104 [69:30:28<4:31:21, 15.66s/it]

 94%|█████████▎| 15065/16104 [69:30:44<4:32:05, 15.71s/it]
{'loss': 0.4163, 'learning_rate': 2.1754935132326846e-08, 'rewards/chosen': 0.11414860934019089, 'rewards/rejected': -1.5347070693969727, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6488556861877441, 'policy_logps/rejected': -446.07476806640625, 'policy_logps/chosen': -464.6067810058594, 'referece_logps/rejected': -430.72772216796875, 'referece_logps/chosen': -465.74822998046875, 'logits/rejected': 0.1686040759086609, 'logits/chosen': 0.16814157366752625, 'epoch': 5.61}

 94%|█████████▎| 15066/16104 [69:31:05<5:00:06, 17.35s/it]


 94%|█████████▎| 15068/16104 [69:31:44<5:19:44, 18.52s/it]
{'loss': 0.3462, 'learning_rate': 2.1629940680130687e-08, 'rewards/chosen': -1.1817911863327026, 'rewards/rejected': -3.373290538787842, 'rewards/accuracies': 0.75, 'rewards/margins': 2.1914994716644287, 'policy_logps/rejected': -429.2698059082031, 'policy_logps/chosen': -276.20843505859375, 'referece_logps/rejected': -395.53692626953125, 'referece_logps/chosen': -264.3905334472656, 'logits/rejected': -0.38012179732322693, 'logits/chosen': -0.2840418517589569, 'epoch': 5.61}


 94%|█████████▎| 15070/16104 [69:32:18<5:00:08, 17.42s/it]

 94%|█████████▎| 15071/16104 [69:32:36<5:03:12, 17.61s/it]

 94%|█████████▎| 15072/16104 [69:32:58<5:26:30, 18.98s/it]

 94%|█████████▎| 15073/16104 [69:33:18<5:29:13, 19.16s/it]

 94%|█████████▎| 15074/16104 [69:33:36<5:24:40, 18.91s/it]

 94%|█████████▎| 15075/16104 [69:33:49<4:49:53, 16.90s/it]

 94%|█████████▎| 15076/16104 [69:34:09<5:05:39, 17.84s/it]
{'loss': 0.4101, 'learning_rate': 2.1298363643930894e-08, 'rewards/chosen': -0.7416579127311707, 'rewards/rejected': -2.38688325881958, 'rewards/accuracies': 0.875, 'rewards/margins': 1.645225167274475, 'policy_logps/rejected': -489.9136047363281, 'policy_logps/chosen': -517.9031982421875, 'referece_logps/rejected': -466.04473876953125, 'referece_logps/chosen': -510.48663330078125, 'logits/rejected': -0.2550743818283081, 'logits/chosen': -0.2849588692188263, 'epoch': 5.62}

 94%|█████████▎| 15077/16104 [69:34:22<4:40:10, 16.37s/it]

 94%|█████████▎| 15078/16104 [69:34:43<5:04:58, 17.83s/it]


 94%|█████████▎| 15080/16104 [69:35:09<4:24:09, 15.48s/it]
{'loss': 0.4579, 'learning_rate': 2.113352523769818e-08, 'rewards/chosen': 0.03937874734401703, 'rewards/rejected': -1.4832050800323486, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5225838422775269, 'policy_logps/rejected': -489.77447509765625, 'policy_logps/chosen': -499.3106689453125, 'referece_logps/rejected': -474.94244384765625, 'referece_logps/chosen': -499.70452880859375, 'logits/rejected': -0.21750760078430176, 'logits/chosen': -0.12366676330566406, 'epoch': 5.62}

 94%|█████████▎| 15081/16104 [69:35:26<4:33:28, 16.04s/it]

 94%|█████████▎| 15082/16104 [69:35:40<4:23:36, 15.48s/it]

 94%|█████████▎| 15083/16104 [69:35:54<4:13:34, 14.90s/it]

 94%|█████████▎| 15084/16104 [69:36:14<4:39:57, 16.47s/it]


 94%|█████████▎| 15086/16104 [69:36:46<4:29:04, 15.86s/it]
{'loss': 0.3625, 'learning_rate': 2.0887455568387334e-08, 'rewards/chosen': -0.411668598651886, 'rewards/rejected': -2.868231773376465, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4565629959106445, 'policy_logps/rejected': -381.7135925292969, 'policy_logps/chosen': -458.93133544921875, 'referece_logps/rejected': -353.0312805175781, 'referece_logps/chosen': -454.8146057128906, 'logits/rejected': 0.5100297927856445, 'logits/chosen': 0.4128122329711914, 'epoch': 5.62}

 94%|█████████▎| 15087/16104 [69:37:02<4:27:27, 15.78s/it]

 94%|█████████▎| 15088/16104 [69:37:19<4:34:12, 16.19s/it]


 94%|█████████▎| 15090/16104 [69:37:47<4:18:17, 15.28s/it]
{'loss': 0.434, 'learning_rate': 2.072420123704488e-08, 'rewards/chosen': -1.1072965860366821, 'rewards/rejected': -2.6445815563201904, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5372852087020874, 'policy_logps/rejected': -471.0199890136719, 'policy_logps/chosen': -437.740478515625, 'referece_logps/rejected': -444.57415771484375, 'referece_logps/chosen': -426.66754150390625, 'logits/rejected': -0.39772385358810425, 'logits/chosen': -0.24604836106300354, 'epoch': 5.62}

 94%|█████████▎| 15091/16104 [69:38:05<4:33:53, 16.22s/it]

 94%|█████████▎| 15092/16104 [69:38:22<4:35:20, 16.32s/it]


 94%|█████████▎| 15094/16104 [69:38:45<3:52:56, 13.84s/it]

 94%|█████████▎| 15095/16104 [69:39:05<4:22:13, 15.59s/it]

 94%|█████████▎| 15096/16104 [69:39:19<4:14:05, 15.12s/it]
{'loss': 0.5283, 'learning_rate': 2.0480508176485722e-08, 'rewards/chosen': -0.5488906502723694, 'rewards/rejected': -0.8799742460250854, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3310834765434265, 'policy_logps/rejected': -430.0679931640625, 'policy_logps/chosen': -359.2169189453125, 'referece_logps/rejected': -421.26824951171875, 'referece_logps/chosen': -353.72802734375, 'logits/rejected': -0.6729010343551636, 'logits/chosen': -0.7015671730041504, 'epoch': 5.62}

 94%|█████████▎| 15097/16104 [69:39:29<3:51:34, 13.80s/it]

 94%|█████████▍| 15098/16104 [69:39:40<3:35:26, 12.85s/it]


 94%|█████████▍| 15100/16104 [69:40:05<3:29:39, 12.53s/it]

 94%|█████████▍| 15101/16104 [69:40:25<4:04:42, 14.64s/it]
{'loss': 0.4187, 'learning_rate': 2.027852025195631e-08, 'rewards/chosen': -0.8405476808547974, 'rewards/rejected': -2.352605104446411, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5120571851730347, 'policy_logps/rejected': -355.3871154785156, 'policy_logps/chosen': -460.39410400390625, 'referece_logps/rejected': -331.86102294921875, 'referece_logps/chosen': -451.98870849609375, 'logits/rejected': 0.6258147954940796, 'logits/chosen': 0.5292760729789734, 'epoch': 5.63}


 94%|█████████▍| 15103/16104 [69:40:51<3:47:31, 13.64s/it]
{'loss': 0.3944, 'learning_rate': 2.0198002491091714e-08, 'rewards/chosen': -0.8353637456893921, 'rewards/rejected': -1.0927858352661133, 'rewards/accuracies': 0.5, 'rewards/margins': 0.25742214918136597, 'policy_logps/rejected': -505.3537902832031, 'policy_logps/chosen': -609.3909301757812, 'referece_logps/rejected': -494.42596435546875, 'referece_logps/chosen': -601.037353515625, 'logits/rejected': -0.2714836001396179, 'logits/chosen': -0.32921624183654785, 'epoch': 5.63}

 94%|█████████▍| 15104/16104 [69:41:10<4:13:58, 15.24s/it]

 94%|█████████▍| 15105/16104 [69:41:27<4:25:47, 15.96s/it]

 94%|█████████▍| 15106/16104 [69:41:46<4:38:48, 16.76s/it]

 94%|█████████▍| 15107/16104 [69:42:00<4:22:00, 15.77s/it]

 94%|█████████▍| 15108/16104 [69:42:10<3:56:58, 14.28s/it]

 94%|█████████▍| 15109/16104 [69:42:28<4:15:35, 15.41s/it]

 94%|█████████▍| 15110/16104 [69:42:46<4:25:38, 16.03s/it]

 94%|█████████▍| 15111/16104 [69:43:08<4:56:48, 17.93s/it]

 94%|█████████▍| 15112/16104 [69:43:28<5:06:39, 18.55s/it]

 94%|█████████▍| 15113/16104 [69:43:50<5:22:33, 19.53s/it]

 94%|█████████▍| 15114/16104 [69:44:08<5:15:35, 19.13s/it]


 94%|█████████▍| 15116/16104 [69:44:45<5:08:30, 18.73s/it]
{'loss': 0.3742, 'learning_rate': 1.967850201227794e-08, 'rewards/chosen': -0.6907848119735718, 'rewards/rejected': -1.8656818866729736, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1748970746994019, 'policy_logps/rejected': -290.9769592285156, 'policy_logps/chosen': -336.2506103515625, 'referece_logps/rejected': -272.32012939453125, 'referece_logps/chosen': -329.3427734375, 'logits/rejected': -0.3848615884780884, 'logits/chosen': -0.43513426184654236, 'epoch': 5.63}

 94%|█████████▍| 15117/16104 [69:45:06<5:17:40, 19.31s/it]

 94%|█████████▍| 15118/16104 [69:45:21<4:54:23, 17.91s/it]


 94%|█████████▍| 15120/16104 [69:45:57<4:56:50, 18.10s/it]

 94%|█████████▍| 15121/16104 [69:46:13<4:47:02, 17.52s/it]
{'loss': 0.3914, 'learning_rate': 1.9480478451238568e-08, 'rewards/chosen': -0.6842052340507507, 'rewards/rejected': -1.4832229614257812, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7990176677703857, 'policy_logps/rejected': -474.56610107421875, 'policy_logps/chosen': -463.96990966796875, 'referece_logps/rejected': -459.73394775390625, 'referece_logps/chosen': -457.12786865234375, 'logits/rejected': -0.07337743043899536, 'logits/chosen': -0.09863835573196411, 'epoch': 5.63}

 94%|█████████▍| 15122/16104 [69:46:32<4:53:28, 17.93s/it]

 94%|█████████▍| 15123/16104 [69:46:50<4:54:07, 17.99s/it]

 94%|█████████▍| 15124/16104 [69:47:09<4:56:47, 18.17s/it]

 94%|█████████▍| 15125/16104 [69:47:20<4:22:21, 16.08s/it]


 94%|█████████▍| 15127/16104 [69:47:59<4:52:13, 17.95s/it]

 94%|█████████▍| 15128/16104 [69:48:13<4:31:39, 16.70s/it]
{'loss': 0.4199, 'learning_rate': 1.920491138841995e-08, 'rewards/chosen': -0.2790536880493164, 'rewards/rejected': -1.7744550704956055, 'rewards/accuracies': 1.0, 'rewards/margins': 1.495401382446289, 'policy_logps/rejected': -444.0487365722656, 'policy_logps/chosen': -571.02978515625, 'referece_logps/rejected': -426.3041687011719, 'referece_logps/chosen': -568.2392578125, 'logits/rejected': 0.6938436031341553, 'logits/chosen': 0.6208314895629883, 'epoch': 5.64}

 94%|█████████▍| 15129/16104 [69:48:33<4:46:02, 17.60s/it]


 94%|█████████▍| 15131/16104 [69:49:11<4:59:43, 18.48s/it]

 94%|█████████▍| 15132/16104 [69:49:31<5:06:28, 18.92s/it]

 94%|█████████▍| 15133/16104 [69:49:47<4:52:13, 18.06s/it]
{'loss': 0.4687, 'learning_rate': 1.9009267987578293e-08, 'rewards/chosen': -0.34714892506599426, 'rewards/rejected': -0.9432675242424011, 'rewards/accuracies': 0.875, 'rewards/margins': 0.596118688583374, 'policy_logps/rejected': -485.7890625, 'policy_logps/chosen': -431.75042724609375, 'referece_logps/rejected': -476.3563537597656, 'referece_logps/chosen': -428.2789306640625, 'logits/rejected': -0.3448556363582611, 'logits/chosen': -0.2262309193611145, 'epoch': 5.64}

 94%|█████████▍| 15134/16104 [69:50:09<5:08:58, 19.11s/it]


 94%|█████████▍| 15136/16104 [69:50:39<4:37:07, 17.18s/it]

 94%|█████████▍| 15137/16104 [69:50:58<4:43:25, 17.59s/it]
{'loss': 0.4799, 'learning_rate': 1.8853467548246238e-08, 'rewards/chosen': 0.1415576934814453, 'rewards/rejected': -2.0670337677001953, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2085914611816406, 'policy_logps/rejected': -390.5968017578125, 'policy_logps/chosen': -473.8173522949219, 'referece_logps/rejected': -369.9264221191406, 'referece_logps/chosen': -475.23297119140625, 'logits/rejected': -0.5024464130401611, 'logits/chosen': -0.5054649710655212, 'epoch': 5.64}

 94%|█████████▍| 15138/16104 [69:51:10<4:16:53, 15.96s/it]

 94%|█████████▍| 15139/16104 [69:51:24<4:08:54, 15.48s/it]

 94%|█████████▍| 15140/16104 [69:51:37<3:53:37, 14.54s/it]


 94%|█████████▍| 15142/16104 [69:52:18<4:41:20, 17.55s/it]
{'loss': 0.424, 'learning_rate': 1.8659610016195648e-08, 'rewards/chosen': -1.0633251667022705, 'rewards/rejected': -2.6618893146514893, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5985642671585083, 'policy_logps/rejected': -447.7596435546875, 'policy_logps/chosen': -490.453369140625, 'referece_logps/rejected': -421.1407470703125, 'referece_logps/chosen': -479.82012939453125, 'logits/rejected': 0.03452449291944504, 'logits/chosen': -0.003726954571902752, 'epoch': 5.64}


 94%|█████████▍| 15144/16104 [69:52:56<4:53:34, 18.35s/it]
{'loss': 0.4168, 'learning_rate': 1.858234487119781e-08, 'rewards/chosen': -0.5818066596984863, 'rewards/rejected': -1.4519671201705933, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8701602816581726, 'policy_logps/rejected': -460.39569091796875, 'policy_logps/chosen': -409.50860595703125, 'referece_logps/rejected': -445.87603759765625, 'referece_logps/chosen': -403.6905212402344, 'logits/rejected': 0.07319427281618118, 'logits/chosen': 0.03916343301534653, 'epoch': 5.64}


 94%|█████████▍| 15146/16104 [69:53:17<3:51:00, 14.47s/it]
{'loss': 0.3959, 'learning_rate': 1.8505238526580146e-08, 'rewards/chosen': -0.5251739621162415, 'rewards/rejected': -3.0433907508850098, 'rewards/accuracies': 0.875, 'rewards/margins': 2.518216609954834, 'policy_logps/rejected': -559.8104248046875, 'policy_logps/chosen': -384.6300354003906, 'referece_logps/rejected': -529.3765258789062, 'referece_logps/chosen': -379.3782958984375, 'logits/rejected': -0.6845567226409912, 'logits/chosen': -0.3736298382282257, 'epoch': 5.64}


 94%|█████████▍| 15148/16104 [69:53:48<3:49:25, 14.40s/it]

 94%|█████████▍| 15149/16104 [69:54:03<3:55:28, 14.79s/it]
{'loss': 0.3482, 'learning_rate': 1.8389876787652025e-08, 'rewards/chosen': -0.5526455044746399, 'rewards/rejected': -2.0861237049102783, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5334782600402832, 'policy_logps/rejected': -477.614013671875, 'policy_logps/chosen': -477.32952880859375, 'referece_logps/rejected': -456.7527770996094, 'referece_logps/chosen': -471.8031005859375, 'logits/rejected': -0.15325471758842468, 'logits/chosen': -0.17125268280506134, 'epoch': 5.64}

 94%|█████████▍| 15150/16104 [69:54:16<3:46:19, 14.23s/it]


 94%|█████████▍| 15152/16104 [69:54:44<3:44:48, 14.17s/it]

 94%|█████████▍| 15153/16104 [69:55:02<4:01:40, 15.25s/it]

 94%|█████████▍| 15154/16104 [69:55:18<4:06:13, 15.55s/it]
{'loss': 0.5513, 'learning_rate': 1.8198401401054884e-08, 'rewards/chosen': -0.31192702054977417, 'rewards/rejected': -2.235292434692383, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9233653545379639, 'policy_logps/rejected': -466.0509948730469, 'policy_logps/chosen': -425.9346008300781, 'referece_logps/rejected': -443.69805908203125, 'referece_logps/chosen': -422.8153381347656, 'logits/rejected': -0.5047768354415894, 'logits/chosen': -0.356240451335907, 'epoch': 5.65}


 94%|█████████▍| 15156/16104 [69:55:47<3:59:27, 15.16s/it]
{'loss': 0.4353, 'learning_rate': 1.8122089244970273e-08, 'rewards/chosen': -0.3035505414009094, 'rewards/rejected': -1.2704919576644897, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9669414758682251, 'policy_logps/rejected': -447.83819580078125, 'policy_logps/chosen': -489.7312316894531, 'referece_logps/rejected': -435.13336181640625, 'referece_logps/chosen': -486.69573974609375, 'logits/rejected': -0.08337879925966263, 'logits/chosen': 0.053349751979112625, 'epoch': 5.65}

 94%|█████████▍| 15157/16104 [69:55:58<3:37:58, 13.81s/it]


 94%|█████████▍| 15159/16104 [69:56:30<3:59:12, 15.19s/it]
{'loss': 0.4595, 'learning_rate': 1.8007918905044495e-08, 'rewards/chosen': -0.10741138458251953, 'rewards/rejected': -0.5437380075454712, 'rewards/accuracies': 0.625, 'rewards/margins': 0.43632662296295166, 'policy_logps/rejected': -710.41845703125, 'policy_logps/chosen': -691.7588500976562, 'referece_logps/rejected': -704.9810791015625, 'referece_logps/chosen': -690.6846923828125, 'logits/rejected': -0.3787456452846527, 'logits/chosen': -0.17695558071136475, 'epoch': 5.65}

 94%|█████████▍| 15160/16104 [69:56:50<4:20:18, 16.55s/it]

 94%|█████████▍| 15161/16104 [69:57:01<3:57:39, 15.12s/it]

 94%|█████████▍| 15162/16104 [69:57:23<4:28:08, 17.08s/it]

 94%|█████████▍| 15163/16104 [69:57:41<4:30:19, 17.24s/it]

 94%|█████████▍| 15164/16104 [69:57:57<4:25:27, 16.94s/it]

 94%|█████████▍| 15165/16104 [69:58:10<4:06:34, 15.76s/it]

 94%|█████████▍| 15166/16104 [69:58:27<4:14:07, 16.26s/it]

 94%|█████████▍| 15167/16104 [69:58:44<4:13:29, 16.23s/it]

 94%|█████████▍| 15168/16104 [69:59:03<4:30:48, 17.36s/it]

 94%|█████████▍| 15169/16104 [69:59:20<4:26:19, 17.09s/it]

 94%|█████████▍| 15170/16104 [69:59:39<4:37:20, 17.82s/it]

 94%|█████████▍| 15171/16104 [69:59:57<4:33:28, 17.59s/it]

 94%|█████████▍| 15172/16104 [70:00:16<4:42:38, 18.20s/it]

 94%|█████████▍| 15173/16104 [70:00:30<4:21:32, 16.86s/it]


 94%|█████████▍| 15175/16104 [70:01:00<4:11:33, 16.25s/it]
{'loss': 0.4017, 'learning_rate': 1.7405049379918713e-08, 'rewards/chosen': -0.33843421936035156, 'rewards/rejected': -1.6865037679672241, 'rewards/accuracies': 0.75, 'rewards/margins': 1.348069667816162, 'policy_logps/rejected': -656.1385498046875, 'policy_logps/chosen': -630.561279296875, 'referece_logps/rejected': -639.2735595703125, 'referece_logps/chosen': -627.1768798828125, 'logits/rejected': -0.5814473032951355, 'logits/chosen': -0.5773913860321045, 'epoch': 5.65}

 94%|█████████▍| 15176/16104 [70:01:13<3:55:28, 15.22s/it]


 94%|█████████▍| 15178/16104 [70:01:50<4:23:08, 17.05s/it]
{'loss': 0.3961, 'learning_rate': 1.729314396647952e-08, 'rewards/chosen': -0.1986466497182846, 'rewards/rejected': -1.9785864353179932, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7799397706985474, 'policy_logps/rejected': -438.7845764160156, 'policy_logps/chosen': -491.52423095703125, 'referece_logps/rejected': -418.99871826171875, 'referece_logps/chosen': -489.53778076171875, 'logits/rejected': -0.13670983910560608, 'logits/chosen': -0.12722590565681458, 'epoch': 5.65}

 94%|█████████▍| 15179/16104 [70:02:04<4:07:34, 16.06s/it]

 94%|█████████▍| 15180/16104 [70:02:24<4:24:35, 17.18s/it]

 94%|█████████▍| 15181/16104 [70:02:44<4:36:03, 17.94s/it]

 94%|█████████▍| 15182/16104 [70:03:04<4:44:40, 18.53s/it]

 94%|█████████▍| 15183/16104 [70:03:23<4:49:35, 18.87s/it]

 94%|█████████▍| 15184/16104 [70:03:39<4:34:18, 17.89s/it]


 94%|█████████▍| 15186/16104 [70:04:13<4:27:34, 17.49s/it]
{'loss': 0.4218, 'learning_rate': 1.6996478739658593e-08, 'rewards/chosen': -0.2681625485420227, 'rewards/rejected': -2.6057229042053223, 'rewards/accuracies': 0.875, 'rewards/margins': 2.3375601768493652, 'policy_logps/rejected': -378.9303283691406, 'policy_logps/chosen': -392.863525390625, 'referece_logps/rejected': -352.8730773925781, 'referece_logps/chosen': -390.181884765625, 'logits/rejected': 0.20524290204048157, 'logits/chosen': 0.007248193025588989, 'epoch': 5.66}

 94%|█████████▍| 15187/16104 [70:04:26<4:07:43, 16.21s/it]


 94%|█████████▍| 15189/16104 [70:04:57<3:55:14, 15.43s/it]
{'loss': 0.4138, 'learning_rate': 1.6885885348488114e-08, 'rewards/chosen': -0.5142200589179993, 'rewards/rejected': -2.0633492469787598, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5491292476654053, 'policy_logps/rejected': -412.6670227050781, 'policy_logps/chosen': -359.83477783203125, 'referece_logps/rejected': -392.03350830078125, 'referece_logps/chosen': -354.6925964355469, 'logits/rejected': -0.5687080025672913, 'logits/chosen': -0.46822255849838257, 'epoch': 5.66}

 94%|█████████▍| 15190/16104 [70:05:07<3:32:42, 13.96s/it]

 94%|█████████▍| 15191/16104 [70:05:27<3:58:03, 15.64s/it]

 94%|█████████▍| 15192/16104 [70:05:46<4:15:24, 16.80s/it]

 94%|█████████▍| 15193/16104 [70:06:05<4:25:24, 17.48s/it]

 94%|█████████▍| 15194/16104 [70:06:20<4:10:45, 16.53s/it]

 94%|█████████▍| 15195/16104 [70:06:38<4:19:13, 17.11s/it]

 94%|█████████▍| 15196/16104 [70:07:00<4:39:23, 18.46s/it]

 94%|█████████▍| 15197/16104 [70:07:15<4:25:40, 17.57s/it]

 94%|█████████▍| 15198/16104 [70:07:30<4:14:12, 16.83s/it]

 94%|█████████▍| 15199/16104 [70:07:49<4:24:11, 17.52s/it]

 94%|█████████▍| 15200/16104 [70:08:06<4:18:02, 17.13s/it]

 94%|█████████▍| 15201/16104 [70:08:26<4:31:02, 18.01s/it]

 94%|█████████▍| 15202/16104 [70:08:40<4:16:08, 17.04s/it]

 94%|█████████▍| 15203/16104 [70:09:00<4:27:30, 17.81s/it]

 94%|█████████▍| 15204/16104 [70:09:15<4:15:42, 17.05s/it]

 94%|█████████▍| 15205/16104 [70:09:26<3:47:25, 15.18s/it]

 94%|█████████▍| 15206/16104 [70:09:43<3:53:22, 15.59s/it]

 94%|█████████▍| 15207/16104 [70:10:01<4:03:31, 16.29s/it]

 94%|█████████▍| 15208/16104 [70:10:11<3:38:34, 14.64s/it]

 94%|█████████▍| 15209/16104 [70:10:22<3:21:33, 13.51s/it]

 94%|█████████▍| 15210/16104 [70:10:36<3:21:51, 13.55s/it]

 94%|█████████▍| 15211/16104 [70:10:47<3:09:20, 12.72s/it]

 94%|█████████▍| 15212/16104 [70:10:57<3:00:02, 12.11s/it]

 94%|█████████▍| 15213/16104 [70:11:14<3:21:48, 13.59s/it]

 94%|█████████▍| 15214/16104 [70:11:27<3:17:53, 13.34s/it]


 94%|█████████▍| 15216/16104 [70:12:00<3:39:25, 14.83s/it]

 94%|█████████▍| 15217/16104 [70:12:11<3:20:55, 13.59s/it]

 94%|█████████▍| 15218/16104 [70:12:28<3:33:25, 14.45s/it]

 95%|█████████▍| 15219/16104 [70:12:45<3:46:15, 15.34s/it]

 95%|█████████▍| 15220/16104 [70:13:03<3:58:56, 16.22s/it]

 95%|█████████▍| 15221/16104 [70:13:18<3:50:02, 15.63s/it]

 95%|█████████▍| 15222/16104 [70:13:29<3:32:35, 14.46s/it]

 95%|█████████▍| 15223/16104 [70:13:48<3:49:21, 15.62s/it]

 95%|█████████▍| 15224/16104 [70:14:08<4:08:44, 16.96s/it]

 95%|█████████▍| 15225/16104 [70:14:20<3:47:34, 15.53s/it]

 95%|█████████▍| 15226/16104 [70:14:35<3:44:58, 15.37s/it]

 95%|█████████▍| 15227/16104 [70:14:55<4:04:31, 16.73s/it]

 95%|█████████▍| 15228/16104 [70:15:07<3:46:38, 15.52s/it]

 95%|█████████▍| 15229/16104 [70:15:22<3:42:35, 15.26s/it]

 95%|█████████▍| 15230/16104 [70:15:34<3:26:59, 14.21s/it]

 95%|█████████▍| 15231/16104 [70:15:49<3:28:52, 14.36s/it]

 95%|█████████▍| 15232/16104 [70:16:03<3:30:38, 14.49s/it]

 95%|█████████▍| 15233/16104 [70:16:25<4:00:24, 16.56s/it]

 95%|█████████▍| 15234/16104 [70:16:43<4:06:46, 17.02s/it]

 95%|█████████▍| 15235/16104 [70:17:02<4:17:15, 17.76s/it]

 95%|█████████▍| 15236/16104 [70:17:22<4:25:06, 18.32s/it]

 95%|█████████▍| 15237/16104 [70:17:42<4:32:34, 18.86s/it]

 95%|█████████▍| 15238/16104 [70:18:02<4:35:32, 19.09s/it]

 95%|█████████▍| 15239/16104 [70:18:21<4:34:07, 19.01s/it]

 95%|█████████▍| 15240/16104 [70:18:40<4:35:58, 19.17s/it]

 95%|█████████▍| 15241/16104 [70:19:00<4:38:29, 19.36s/it]

 95%|█████████▍| 15242/16104 [70:19:13<4:11:23, 17.50s/it]

 95%|█████████▍| 15243/16104 [70:19:31<4:14:26, 17.73s/it]

 95%|█████████▍| 15244/16104 [70:19:51<4:24:25, 18.45s/it]

 95%|█████████▍| 15245/16104 [70:20:11<4:29:43, 18.84s/it]

 95%|█████████▍| 15246/16104 [70:20:33<4:42:41, 19.77s/it]

 95%|█████████▍| 15247/16104 [70:20:53<4:44:07, 19.89s/it]

 95%|█████████▍| 15248/16104 [70:21:15<4:51:48, 20.45s/it]

 95%|█████████▍| 15249/16104 [70:21:35<4:49:39, 20.33s/it]

 95%|█████████▍| 15250/16104 [70:21:48<4:18:04, 18.13s/it]

 95%|█████████▍| 15251/16104 [70:22:08<4:26:17, 18.73s/it]

 95%|█████████▍| 15252/16104 [70:22:25<4:18:16, 18.19s/it]

 95%|█████████▍| 15253/16104 [70:22:41<4:07:27, 17.45s/it]

 95%|█████████▍| 15254/16104 [70:23:01<4:17:49, 18.20s/it]

 95%|█████████▍| 15255/16104 [70:23:18<4:11:12, 17.75s/it]

 95%|█████████▍| 15256/16104 [70:23:35<4:10:34, 17.73s/it]

 95%|█████████▍| 15257/16104 [70:23:50<3:58:57, 16.93s/it]

 95%|█████████▍| 15258/16104 [70:24:01<3:32:43, 15.09s/it]

 95%|█████████▍| 15259/16104 [70:24:20<3:48:04, 16.20s/it]

 95%|█████████▍| 15260/16104 [70:24:40<4:02:54, 17.27s/it]

 95%|█████████▍| 15261/16104 [70:24:55<3:53:00, 16.58s/it]

 95%|█████████▍| 15262/16104 [70:25:09<3:44:14, 15.98s/it]

 95%|█████████▍| 15263/16104 [70:25:29<4:00:29, 17.16s/it]

 95%|█████████▍| 15264/16104 [70:25:40<3:33:15, 15.23s/it]

 95%|█████████▍| 15265/16104 [70:25:54<3:29:51, 15.01s/it]

 95%|█████████▍| 15266/16104 [70:26:10<3:30:56, 15.10s/it]

 95%|█████████▍| 15267/16104 [70:26:25<3:32:08, 15.21s/it]

 95%|█████████▍| 15268/16104 [70:26:46<3:57:33, 17.05s/it]

 95%|█████████▍| 15269/16104 [70:27:03<3:55:43, 16.94s/it]

 95%|█████████▍| 15270/16104 [70:27:21<3:58:04, 17.13s/it]

 95%|█████████▍| 15271/16104 [70:27:35<3:45:19, 16.23s/it]

 95%|█████████▍| 15272/16104 [70:27:50<3:39:43, 15.85s/it]

 95%|█████████▍| 15273/16104 [70:28:01<3:18:18, 14.32s/it]
{'loss': 0.4455, 'learning_rate': 1.3934728844761324e-08, 'rewards/chosen': 0.03506898134946823, 'rewards/rejected': -1.9431164264678955, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9781856536865234, 'policy_logps/rejected': -308.4351806640625, 'policy_logps/chosen': -467.5400695800781, 'referece_logps/rejected': -289.0040283203125, 'referece_logps/chosen': -467.8907775878906, 'logits/rejected': 0.04648198187351227, 'logits/chosen': 0.141268789768219, 'epoch': 5.69}


 95%|█████████▍| 15275/16104 [70:28:36<3:39:16, 15.87s/it]
{'loss': 0.4619, 'learning_rate': 1.3867890329081644e-08, 'rewards/chosen': -0.1522846221923828, 'rewards/rejected': -0.40640488266944885, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2541202902793884, 'policy_logps/rejected': -477.99908447265625, 'policy_logps/chosen': -591.3526611328125, 'referece_logps/rejected': -473.93505859375, 'referece_logps/chosen': -589.829833984375, 'logits/rejected': 0.047894783318042755, 'logits/chosen': 0.042581863701343536, 'epoch': 5.69}


 95%|█████████▍| 15277/16104 [70:29:11<3:50:29, 16.72s/it]

 95%|█████████▍| 15278/16104 [70:29:21<3:25:42, 14.94s/it]

 95%|█████████▍| 15279/16104 [70:29:34<3:15:09, 14.19s/it]

 95%|█████████▍| 15280/16104 [70:29:54<3:37:20, 15.83s/it]
{'loss': 0.4328, 'learning_rate': 1.3701492152532134e-08, 'rewards/chosen': -0.013249203562736511, 'rewards/rejected': -1.2395727634429932, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2263236045837402, 'policy_logps/rejected': -317.69024658203125, 'policy_logps/chosen': -404.0159912109375, 'referece_logps/rejected': -305.2945556640625, 'referece_logps/chosen': -403.88348388671875, 'logits/rejected': 0.06789370626211166, 'logits/chosen': 0.1297551393508911, 'epoch': 5.69}


 95%|█████████▍| 15282/16104 [70:30:23<3:24:47, 14.95s/it]

 95%|█████████▍| 15283/16104 [70:30:37<3:20:17, 14.64s/it]

 95%|█████████▍| 15284/16104 [70:30:48<3:04:02, 13.47s/it]

 95%|█████████▍| 15285/16104 [70:31:08<3:29:19, 15.34s/it]

 95%|█████████▍| 15286/16104 [70:31:25<3:39:26, 16.10s/it]

 95%|█████████▍| 15287/16104 [70:31:45<3:54:27, 17.22s/it]
{'loss': 0.3633, 'learning_rate': 1.3470210439186059e-08, 'rewards/chosen': -1.0052130222320557, 'rewards/rejected': -2.5294132232666016, 'rewards/accuracies': 0.875, 'rewards/margins': 1.524200439453125, 'policy_logps/rejected': -442.39434814453125, 'policy_logps/chosen': -541.4375610351562, 'referece_logps/rejected': -417.1002197265625, 'referece_logps/chosen': -531.3853759765625, 'logits/rejected': 0.46208298206329346, 'logits/chosen': 0.6619904041290283, 'epoch': 5.7}


 95%|█████████▍| 15289/16104 [70:32:24<4:09:14, 18.35s/it]

 95%|█████████▍| 15290/16104 [70:32:43<4:13:49, 18.71s/it]

 95%|█████████▍| 15291/16104 [70:32:57<3:54:39, 17.32s/it]
{'loss': 0.3732, 'learning_rate': 1.3338927382334775e-08, 'rewards/chosen': -0.7691631317138672, 'rewards/rejected': -2.207185983657837, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4380228519439697, 'policy_logps/rejected': -385.0709533691406, 'policy_logps/chosen': -411.90234375, 'referece_logps/rejected': -362.9991149902344, 'referece_logps/chosen': -404.210693359375, 'logits/rejected': -0.2549423277378082, 'logits/chosen': -0.3304041028022766, 'epoch': 5.7}


 95%|█████████▍| 15293/16104 [70:33:31<3:50:03, 17.02s/it]

 95%|█████████▍| 15294/16104 [70:33:45<3:35:25, 15.96s/it]

 95%|█████████▍| 15295/16104 [70:33:58<3:23:33, 15.10s/it]

 95%|█████████▍| 15296/16104 [70:34:18<3:41:12, 16.43s/it]

 95%|█████████▍| 15297/16104 [70:34:36<3:47:21, 16.90s/it]

 95%|█████████▍| 15298/16104 [70:34:47<3:26:42, 15.39s/it]

 95%|█████████▌| 15299/16104 [70:35:07<3:43:20, 16.65s/it]

 95%|█████████▌| 15300/16104 [70:35:24<3:45:08, 16.80s/it]

 95%|█████████▌| 15301/16104 [70:35:42<3:50:00, 17.19s/it]

 95%|█████████▌| 15302/16104 [70:36:00<3:53:42, 17.48s/it]

 95%|█████████▌| 15303/16104 [70:36:13<3:31:47, 15.86s/it]

 95%|█████████▌| 15304/16104 [70:36:30<3:37:54, 16.34s/it]
{'loss': 0.3686, 'learning_rate': 1.2916668182872626e-08, 'rewards/chosen': 0.016745295375585556, 'rewards/rejected': -1.7200660705566406, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7368113994598389, 'policy_logps/rejected': -503.561279296875, 'policy_logps/chosen': -408.45013427734375, 'referece_logps/rejected': -486.3606262207031, 'referece_logps/chosen': -408.61761474609375, 'logits/rejected': 0.5808722972869873, 'logits/chosen': 0.5722476243972778, 'epoch': 5.7}

 95%|█████████▌| 15305/16104 [70:36:41<3:16:33, 14.76s/it]


 95%|█████████▌| 15307/16104 [70:37:07<3:06:07, 14.01s/it]

 95%|█████████▌| 15308/16104 [70:37:26<3:26:46, 15.59s/it]

 95%|█████████▌| 15309/16104 [70:37:46<3:41:45, 16.74s/it]

 95%|█████████▌| 15310/16104 [70:38:01<3:36:50, 16.39s/it]

 95%|█████████▌| 15311/16104 [70:38:13<3:18:33, 15.02s/it]
{'loss': 0.3847, 'learning_rate': 1.2692092710787306e-08, 'rewards/chosen': -0.39674070477485657, 'rewards/rejected': -1.561799168586731, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1650584936141968, 'policy_logps/rejected': -436.613525390625, 'policy_logps/chosen': -449.3296203613281, 'referece_logps/rejected': -420.9955139160156, 'referece_logps/chosen': -445.36224365234375, 'logits/rejected': 0.6708008050918579, 'logits/chosen': 0.7348895072937012, 'epoch': 5.7}


 95%|█████████▌| 15313/16104 [70:38:40<3:02:19, 13.83s/it]
{'loss': 0.3962, 'learning_rate': 1.2628287716063834e-08, 'rewards/chosen': -0.3825645446777344, 'rewards/rejected': -1.9878896474838257, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6053251028060913, 'policy_logps/rejected': -432.54107666015625, 'policy_logps/chosen': -537.7804565429688, 'referece_logps/rejected': -412.6622009277344, 'referece_logps/chosen': -533.954833984375, 'logits/rejected': -0.3943740725517273, 'logits/chosen': -0.523126482963562, 'epoch': 5.71}


 95%|█████████▌| 15315/16104 [70:39:02<2:43:59, 12.47s/it]

 95%|█████████▌| 15316/16104 [70:39:13<2:39:14, 12.12s/it]
{'loss': 0.3105, 'learning_rate': 1.2532879784302619e-08, 'rewards/chosen': -1.5177785158157349, 'rewards/rejected': -2.1175687313079834, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5997904539108276, 'policy_logps/rejected': -357.2323303222656, 'policy_logps/chosen': -370.0368957519531, 'referece_logps/rejected': -336.0566711425781, 'referece_logps/chosen': -354.8591003417969, 'logits/rejected': -0.18520790338516235, 'logits/chosen': 0.055235400795936584, 'epoch': 5.71}

 95%|█████████▌| 15317/16104 [70:39:33<3:08:44, 14.39s/it]


 95%|█████████▌| 15319/16104 [70:40:06<3:16:05, 14.99s/it]

 95%|█████████▌| 15320/16104 [70:40:23<3:24:02, 15.61s/it]
{'loss': 0.3741, 'learning_rate': 1.2406228441890543e-08, 'rewards/chosen': -0.5414984822273254, 'rewards/rejected': -2.733504295349121, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1920056343078613, 'policy_logps/rejected': -295.24462890625, 'policy_logps/chosen': -526.99462890625, 'referece_logps/rejected': -267.9095764160156, 'referece_logps/chosen': -521.5796508789062, 'logits/rejected': -0.1854488104581833, 'logits/chosen': -0.22342655062675476, 'epoch': 5.71}


 95%|█████████▌| 15322/16104 [70:40:53<3:25:39, 15.78s/it]
{'loss': 0.4297, 'learning_rate': 1.234314246514767e-08, 'rewards/chosen': -0.12937220931053162, 'rewards/rejected': -1.5179561376571655, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3885838985443115, 'policy_logps/rejected': -501.9293212890625, 'policy_logps/chosen': -453.1750183105469, 'referece_logps/rejected': -486.7497863769531, 'referece_logps/chosen': -451.88128662109375, 'logits/rejected': 0.12196139246225357, 'logits/chosen': 0.0735725536942482, 'epoch': 5.71}

 95%|█████████▌| 15323/16104 [70:41:09<3:27:37, 15.95s/it]


 95%|█████████▌| 15325/16104 [70:41:38<3:15:36, 15.07s/it]

 95%|█████████▌| 15326/16104 [70:41:54<3:20:06, 15.43s/it]
{'loss': 0.4049, 'learning_rate': 1.2217449951627435e-08, 'rewards/chosen': -1.0669955015182495, 'rewards/rejected': -2.7841341495513916, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7171385288238525, 'policy_logps/rejected': -391.7122802734375, 'policy_logps/chosen': -365.6180419921875, 'referece_logps/rejected': -363.8709716796875, 'referece_logps/chosen': -354.9481506347656, 'logits/rejected': -0.5197309851646423, 'logits/chosen': -0.5832806825637817, 'epoch': 5.71}

 95%|█████████▌| 15327/16104 [70:42:13<3:35:43, 16.66s/it]

 95%|█████████▌| 15328/16104 [70:42:33<3:47:09, 17.56s/it]


 95%|█████████▌| 15330/16104 [70:43:10<3:54:08, 18.15s/it]

 95%|█████████▌| 15331/16104 [70:43:25<3:38:37, 16.97s/it]

 95%|█████████▌| 15332/16104 [70:43:41<3:34:45, 16.69s/it]

 95%|█████████▌| 15333/16104 [70:44:00<3:45:46, 17.57s/it]

 95%|█████████▌| 15334/16104 [70:44:17<3:41:44, 17.28s/it]

 95%|█████████▌| 15335/16104 [70:44:37<3:51:38, 18.07s/it]

 95%|█████████▌| 15336/16104 [70:44:54<3:47:24, 17.77s/it]

 95%|█████████▌| 15337/16104 [70:45:10<3:40:17, 17.23s/it]

 95%|█████████▌| 15338/16104 [70:45:21<3:17:34, 15.48s/it]
{'loss': 0.4422, 'learning_rate': 1.1844208660626964e-08, 'rewards/chosen': -0.7496444582939148, 'rewards/rejected': -2.022033214569092, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2723888158798218, 'policy_logps/rejected': -275.8325500488281, 'policy_logps/chosen': -339.720703125, 'referece_logps/rejected': -255.61219787597656, 'referece_logps/chosen': -332.2242736816406, 'logits/rejected': -0.28323623538017273, 'logits/chosen': -0.24793016910552979, 'epoch': 5.71}


 95%|█████████▌| 15340/16104 [70:45:52<3:17:53, 15.54s/it]

 95%|█████████▌| 15341/16104 [70:46:07<3:13:52, 15.25s/it]

 95%|█████████▌| 15342/16104 [70:46:26<3:31:02, 16.62s/it]
{'loss': 0.3399, 'learning_rate': 1.1721073915227475e-08, 'rewards/chosen': -0.6178747415542603, 'rewards/rejected': -3.457331657409668, 'rewards/accuracies': 0.875, 'rewards/margins': 2.839456796646118, 'policy_logps/rejected': -515.3319091796875, 'policy_logps/chosen': -492.99505615234375, 'referece_logps/rejected': -480.75860595703125, 'referece_logps/chosen': -486.81634521484375, 'logits/rejected': 0.23982839286327362, 'logits/chosen': 0.2293836623430252, 'epoch': 5.72}


 95%|█████████▌| 15344/16104 [70:46:52<3:05:24, 14.64s/it]

 95%|█████████▌| 15345/16104 [70:47:04<2:54:50, 13.82s/it]

 95%|█████████▌| 15346/16104 [70:47:26<3:25:47, 16.29s/it]

 95%|█████████▌| 15347/16104 [70:47:41<3:20:27, 15.89s/it]
{'loss': 0.3782, 'learning_rate': 1.156805498977076e-08, 'rewards/chosen': -0.26278895139694214, 'rewards/rejected': -2.6693007946014404, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4065115451812744, 'policy_logps/rejected': -398.3020324707031, 'policy_logps/chosen': -572.8443603515625, 'referece_logps/rejected': -371.6090087890625, 'referece_logps/chosen': -570.2164306640625, 'logits/rejected': -0.2607291340827942, 'logits/chosen': -0.1980915367603302, 'epoch': 5.72}

 95%|█████████▌| 15348/16104 [70:48:02<3:38:06, 17.31s/it]

 95%|█████████▌| 15349/16104 [70:48:14<3:18:50, 15.80s/it]


 95%|█████████▌| 15351/16104 [70:48:44<3:09:34, 15.11s/it]

 95%|█████████▌| 15352/16104 [70:48:59<3:07:24, 14.95s/it]

 95%|█████████▌| 15353/16104 [70:49:13<3:03:05, 14.63s/it]
{'loss': 0.4312, 'learning_rate': 1.138575175925105e-08, 'rewards/chosen': -0.48927921056747437, 'rewards/rejected': -1.2092808485031128, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7200016975402832, 'policy_logps/rejected': -415.7812805175781, 'policy_logps/chosen': -524.6618041992188, 'referece_logps/rejected': -403.68853759765625, 'referece_logps/chosen': -519.76904296875, 'logits/rejected': -0.19454923272132874, 'logits/chosen': -0.10923221707344055, 'epoch': 5.72}

 95%|█████████▌| 15354/16104 [70:49:23<2:48:07, 13.45s/it]


 95%|█████████▌| 15356/16104 [70:49:57<3:08:09, 15.09s/it]

 95%|█████████▌| 15357/16104 [70:50:16<3:25:34, 16.51s/it]

 95%|█████████▌| 15358/16104 [70:50:36<3:36:43, 17.43s/it]

 95%|█████████▌| 15359/16104 [70:50:52<3:31:15, 17.01s/it]
{'loss': 0.3806, 'learning_rate': 1.1204888212140273e-08, 'rewards/chosen': -0.041986849159002304, 'rewards/rejected': -1.1441643238067627, 'rewards/accuracies': 1.0, 'rewards/margins': 1.102177381515503, 'policy_logps/rejected': -489.2502746582031, 'policy_logps/chosen': -426.8730773925781, 'referece_logps/rejected': -477.8086242675781, 'referece_logps/chosen': -426.45318603515625, 'logits/rejected': 0.5330444574356079, 'logits/chosen': 0.5390317440032959, 'epoch': 5.72}


 95%|█████████▌| 15361/16104 [70:51:17<3:02:07, 14.71s/it]

 95%|█████████▌| 15362/16104 [70:51:35<3:13:13, 15.62s/it]

 95%|█████████▌| 15363/16104 [70:51:53<3:24:55, 16.59s/it]

 95%|█████████▌| 15364/16104 [70:52:13<3:36:39, 17.57s/it]

 95%|█████████▌| 15365/16104 [70:52:25<3:13:58, 15.75s/it]

 95%|█████████▌| 15366/16104 [70:52:37<3:00:30, 14.68s/it]

 95%|█████████▌| 15367/16104 [70:52:54<3:11:01, 15.55s/it]

 95%|█████████▌| 15368/16104 [70:53:10<3:09:14, 15.43s/it]

 95%|█████████▌| 15369/16104 [70:53:30<3:28:55, 17.05s/it]
{'loss': 0.3918, 'learning_rate': 1.0906648977836664e-08, 'rewards/chosen': -0.5432873964309692, 'rewards/rejected': -1.8397537469863892, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2964662313461304, 'policy_logps/rejected': -314.6608581542969, 'policy_logps/chosen': -358.07489013671875, 'referece_logps/rejected': -296.2633361816406, 'referece_logps/chosen': -352.64208984375, 'logits/rejected': -0.2918991148471832, 'logits/chosen': -0.307090699672699, 'epoch': 5.73}


 95%|█████████▌| 15371/16104 [70:54:07<3:38:17, 17.87s/it]

 95%|█████████▌| 15372/16104 [70:54:22<3:24:53, 16.79s/it]

 95%|█████████▌| 15373/16104 [70:54:42<3:36:01, 17.73s/it]

 95%|█████████▌| 15374/16104 [70:54:53<3:12:42, 15.84s/it]

 95%|█████████▌| 15375/16104 [70:55:13<3:26:13, 16.97s/it]
{'loss': 0.3512, 'learning_rate': 1.0729625868446945e-08, 'rewards/chosen': -0.7147359848022461, 'rewards/rejected': -2.3896193504333496, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6748833656311035, 'policy_logps/rejected': -311.4903869628906, 'policy_logps/chosen': -261.292236328125, 'referece_logps/rejected': -287.5942077636719, 'referece_logps/chosen': -254.14488220214844, 'logits/rejected': 0.2627168893814087, 'logits/chosen': 0.20320172607898712, 'epoch': 5.73}


 95%|█████████▌| 15377/16104 [70:55:41<3:09:18, 15.62s/it]

 95%|█████████▌| 15378/16104 [70:56:00<3:19:36, 16.50s/it]

 95%|█████████▌| 15379/16104 [70:56:17<3:24:04, 16.89s/it]
{'loss': 0.4007, 'learning_rate': 1.0612410801305483e-08, 'rewards/chosen': -0.6037090420722961, 'rewards/rejected': -1.4391958713531494, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8354868292808533, 'policy_logps/rejected': -403.1056213378906, 'policy_logps/chosen': -342.283447265625, 'referece_logps/rejected': -388.71368408203125, 'referece_logps/chosen': -336.246337890625, 'logits/rejected': 0.44240450859069824, 'logits/chosen': 0.39957761764526367, 'epoch': 5.73}

 96%|█████████▌| 15380/16104 [70:56:36<3:31:09, 17.50s/it]


 96%|█████████▌| 15382/16104 [70:57:07<3:12:19, 15.98s/it]
{'loss': 0.5721, 'learning_rate': 1.0524919732976979e-08, 'rewards/chosen': -0.5362598896026611, 'rewards/rejected': -0.39586153626441956, 'rewards/accuracies': 0.375, 'rewards/margins': -0.140398308634758, 'policy_logps/rejected': -452.9010009765625, 'policy_logps/chosen': -470.81475830078125, 'referece_logps/rejected': -448.9423828125, 'referece_logps/chosen': -465.4521179199219, 'logits/rejected': 0.6362943649291992, 'logits/chosen': 0.5551081895828247, 'epoch': 5.73}

 96%|█████████▌| 15383/16104 [70:57:27<3:26:02, 17.15s/it]

 96%|█████████▌| 15384/16104 [70:57:46<3:34:14, 17.85s/it]

 96%|█████████▌| 15385/16104 [70:57:57<3:07:41, 15.66s/it]


 96%|█████████▌| 15387/16104 [70:58:32<3:19:43, 16.71s/it]

 96%|█████████▌| 15388/16104 [70:58:48<3:17:15, 16.53s/it]
{'loss': 0.4824, 'learning_rate': 1.0351018330895244e-08, 'rewards/chosen': -0.6364721655845642, 'rewards/rejected': -1.4487498998641968, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8122777938842773, 'policy_logps/rejected': -268.9113464355469, 'policy_logps/chosen': -413.3956298828125, 'referece_logps/rejected': -254.42385864257812, 'referece_logps/chosen': -407.0309143066406, 'logits/rejected': -0.6130544543266296, 'logits/chosen': -0.8061233758926392, 'epoch': 5.73}

 96%|█████████▌| 15389/16104 [70:59:04<3:17:10, 16.55s/it]


 96%|█████████▌| 15391/16104 [70:59:32<3:02:37, 15.37s/it]
{'loss': 0.3992, 'learning_rate': 1.0264608060453594e-08, 'rewards/chosen': -0.8319512009620667, 'rewards/rejected': -2.9949212074279785, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1629698276519775, 'policy_logps/rejected': -708.032958984375, 'policy_logps/chosen': -457.762451171875, 'referece_logps/rejected': -678.083740234375, 'referece_logps/chosen': -449.44293212890625, 'logits/rejected': -0.9576733112335205, 'logits/chosen': -0.8657649159431458, 'epoch': 5.73}

 96%|█████████▌| 15392/16104 [70:59:47<3:01:29, 15.29s/it]


 96%|█████████▌| 15394/16104 [71:00:20<3:13:28, 16.35s/it]

 96%|█████████▌| 15395/16104 [71:00:32<2:56:59, 14.98s/it]

 96%|█████████▌| 15396/16104 [71:00:46<2:53:03, 14.67s/it]
{'loss': 0.3892, 'learning_rate': 1.0121391689760784e-08, 'rewards/chosen': -0.6502811908721924, 'rewards/rejected': -2.9372315406799316, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2869503498077393, 'policy_logps/rejected': -478.2801818847656, 'policy_logps/chosen': -485.5445556640625, 'referece_logps/rejected': -448.9078369140625, 'referece_logps/chosen': -479.0417175292969, 'logits/rejected': 0.6303735375404358, 'logits/chosen': 0.9591254591941833, 'epoch': 5.74}


 96%|█████████▌| 15398/16104 [71:01:14<2:47:37, 14.25s/it]
{'loss': 0.2947, 'learning_rate': 1.006438542987731e-08, 'rewards/chosen': -0.6010502576828003, 'rewards/rejected': -2.725213050842285, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1241626739501953, 'policy_logps/rejected': -380.04718017578125, 'policy_logps/chosen': -449.96771240234375, 'referece_logps/rejected': -352.7950439453125, 'referece_logps/chosen': -443.9571533203125, 'logits/rejected': -0.10771584510803223, 'logits/chosen': -0.05128878355026245, 'epoch': 5.74}


 96%|█████████▌| 15400/16104 [71:01:43<2:46:16, 14.17s/it]

 96%|█████████▌| 15401/16104 [71:01:54<2:34:33, 13.19s/it]
{'loss': 0.2948, 'learning_rate': 9.979176377890363e-09, 'rewards/chosen': -0.955723762512207, 'rewards/rejected': -2.4502673149108887, 'rewards/accuracies': 0.875, 'rewards/margins': 1.494543433189392, 'policy_logps/rejected': -353.2337951660156, 'policy_logps/chosen': -420.9847412109375, 'referece_logps/rejected': -328.7311096191406, 'referece_logps/chosen': -411.4275207519531, 'logits/rejected': -0.1631125658750534, 'logits/chosen': -0.17595261335372925, 'epoch': 5.74}

 96%|█████████▌| 15402/16104 [71:02:12<2:51:30, 14.66s/it]


 96%|█████████▌| 15404/16104 [71:02:44<2:55:51, 15.07s/it]
{'loss': 0.4583, 'learning_rate': 9.894327758874776e-09, 'rewards/chosen': -0.2895435392856598, 'rewards/rejected': -1.9862560033798218, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6967123746871948, 'policy_logps/rejected': -500.1104431152344, 'policy_logps/chosen': -434.351806640625, 'referece_logps/rejected': -480.2479248046875, 'referece_logps/chosen': -431.4563293457031, 'logits/rejected': -0.3355126678943634, 'logits/chosen': -0.542779266834259, 'epoch': 5.74}


 96%|█████████▌| 15406/16104 [71:03:16<3:01:33, 15.61s/it]
{'loss': 0.4375, 'learning_rate': 9.837962268663958e-09, 'rewards/chosen': -0.7307778596878052, 'rewards/rejected': -1.9112931489944458, 'rewards/accuracies': 0.75, 'rewards/margins': 1.180514931678772, 'policy_logps/rejected': -312.2048034667969, 'policy_logps/chosen': -431.9492492675781, 'referece_logps/rejected': -293.09185791015625, 'referece_logps/chosen': -424.6414794921875, 'logits/rejected': 0.3422030806541443, 'logits/chosen': 0.2615226209163666, 'epoch': 5.74}


 96%|█████████▌| 15408/16104 [71:03:44<2:54:45, 15.07s/it]
{'loss': 0.4123, 'learning_rate': 9.781756993736845e-09, 'rewards/chosen': -0.15365451574325562, 'rewards/rejected': -1.6647875308990479, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5111329555511475, 'policy_logps/rejected': -402.0731506347656, 'policy_logps/chosen': -465.5162658691406, 'referece_logps/rejected': -385.42523193359375, 'referece_logps/chosen': -463.9797058105469, 'logits/rejected': 0.020897455513477325, 'logits/chosen': 0.3009258508682251, 'epoch': 5.74}

 96%|█████████▌| 15409/16104 [71:03:59<2:53:30, 14.98s/it]

 96%|█████████▌| 15410/16104 [71:04:19<3:09:47, 16.41s/it]


 96%|█████████▌| 15412/16104 [71:05:00<3:34:19, 18.58s/it]

 96%|█████████▌| 15413/16104 [71:05:20<3:37:56, 18.92s/it]
{'loss': 0.3419, 'learning_rate': 9.641944807904368e-09, 'rewards/chosen': -0.5367656946182251, 'rewards/rejected': -3.637537956237793, 'rewards/accuracies': 0.875, 'rewards/margins': 3.1007723808288574, 'policy_logps/rejected': -507.702392578125, 'policy_logps/chosen': -448.07989501953125, 'referece_logps/rejected': -471.32696533203125, 'referece_logps/chosen': -442.7121887207031, 'logits/rejected': 0.0016026496887207031, 'logits/chosen': -0.02246040105819702, 'epoch': 5.74}


 96%|█████████▌| 15415/16104 [71:05:58<3:41:01, 19.25s/it]

 96%|█████████▌| 15416/16104 [71:06:18<3:43:28, 19.49s/it]

 96%|█████████▌| 15417/16104 [71:06:36<3:35:42, 18.84s/it]
{'loss': 0.4554, 'learning_rate': 9.53081616393836e-09, 'rewards/chosen': -0.5931673049926758, 'rewards/rejected': -1.795729637145996, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2025620937347412, 'policy_logps/rejected': -336.4989929199219, 'policy_logps/chosen': -456.8499450683594, 'referece_logps/rejected': -318.5416564941406, 'referece_logps/chosen': -450.9182434082031, 'logits/rejected': -0.42176535725593567, 'logits/chosen': -0.4422251880168915, 'epoch': 5.74}


 96%|█████████▌| 15419/16104 [71:07:09<3:19:42, 17.49s/it]

 96%|█████████▌| 15420/16104 [71:07:22<3:05:28, 16.27s/it]
{'loss': 0.4111, 'learning_rate': 9.447890372607404e-09, 'rewards/chosen': -1.0758583545684814, 'rewards/rejected': -2.0071494579315186, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9312910437583923, 'policy_logps/rejected': -486.3428955078125, 'policy_logps/chosen': -631.7259521484375, 'referece_logps/rejected': -466.2714538574219, 'referece_logps/chosen': -620.9674072265625, 'logits/rejected': -0.6494144201278687, 'logits/chosen': -0.6482356190681458, 'epoch': 5.75}


 96%|█████████▌| 15422/16104 [71:07:54<3:02:09, 16.03s/it]
{'loss': 0.4498, 'learning_rate': 9.392806857858815e-09, 'rewards/chosen': -0.8268858194351196, 'rewards/rejected': -1.7319135665893555, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9050277471542358, 'policy_logps/rejected': -419.6861877441406, 'policy_logps/chosen': -465.2981262207031, 'referece_logps/rejected': -402.3670349121094, 'referece_logps/chosen': -457.0292663574219, 'logits/rejected': -0.14099888503551483, 'logits/chosen': -0.4218205213546753, 'epoch': 5.75}

 96%|█████████▌| 15423/16104 [71:08:11<3:06:17, 16.41s/it]

 96%|█████████▌| 15424/16104 [71:08:25<2:56:09, 15.54s/it]

 96%|█████████▌| 15425/16104 [71:08:46<3:13:54, 17.14s/it]


 96%|█████████▌| 15427/16104 [71:09:12<2:52:03, 15.25s/it]
{'loss': 0.4423, 'learning_rate': 9.255799347415494e-09, 'rewards/chosen': 0.09137289226055145, 'rewards/rejected': -1.1058391332626343, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1972119808197021, 'policy_logps/rejected': -437.7401123046875, 'policy_logps/chosen': -392.0712585449219, 'referece_logps/rejected': -426.68170166015625, 'referece_logps/chosen': -392.9849548339844, 'logits/rejected': 0.3074469566345215, 'logits/chosen': 0.3212045431137085, 'epoch': 5.75}


 96%|█████████▌| 15429/16104 [71:09:36<2:31:10, 13.44s/it]

 96%|█████████▌| 15430/16104 [71:09:47<2:21:44, 12.62s/it]
{'loss': 0.449, 'learning_rate': 9.174075760735923e-09, 'rewards/chosen': -0.1849079132080078, 'rewards/rejected': -1.80153489112854, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6166269779205322, 'policy_logps/rejected': -568.4732055664062, 'policy_logps/chosen': -545.4258422851562, 'referece_logps/rejected': -550.4578857421875, 'referece_logps/chosen': -543.5767822265625, 'logits/rejected': -0.3652966618537903, 'logits/chosen': -0.37112921476364136, 'epoch': 5.75}


 96%|█████████▌| 15432/16104 [71:10:10<2:15:56, 12.14s/it]
{'loss': 0.4318, 'learning_rate': 9.119793771163343e-09, 'rewards/chosen': -1.1275532245635986, 'rewards/rejected': -1.4798210859298706, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3522678017616272, 'policy_logps/rejected': -523.6143188476562, 'policy_logps/chosen': -298.2118225097656, 'referece_logps/rejected': -508.81610107421875, 'referece_logps/chosen': -286.9362487792969, 'logits/rejected': -0.6628426313400269, 'logits/chosen': -0.42585113644599915, 'epoch': 5.75}


 96%|█████████▌| 15434/16104 [71:10:42<2:40:39, 14.39s/it]
{'loss': 0.4333, 'learning_rate': 9.065672113079403e-09, 'rewards/chosen': -0.1414940059185028, 'rewards/rejected': -1.4183422327041626, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2768481969833374, 'policy_logps/rejected': -538.0911865234375, 'policy_logps/chosen': -531.3057250976562, 'referece_logps/rejected': -523.90771484375, 'referece_logps/chosen': -529.8907470703125, 'logits/rejected': -0.08191481232643127, 'logits/chosen': 0.043220799416303635, 'epoch': 5.75}

 96%|█████████▌| 15435/16104 [71:10:53<2:27:35, 13.24s/it]


 96%|█████████▌| 15437/16104 [71:11:32<3:04:48, 16.62s/it]

 96%|█████████▌| 15438/16104 [71:11:52<3:15:04, 17.57s/it]
{'loss': 0.4096, 'learning_rate': 8.95790982638056e-09, 'rewards/chosen': -0.7908971309661865, 'rewards/rejected': -1.7831718921661377, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9922746419906616, 'policy_logps/rejected': -349.9804382324219, 'policy_logps/chosen': -422.201171875, 'referece_logps/rejected': -332.1487121582031, 'referece_logps/chosen': -414.29217529296875, 'logits/rejected': 0.28186750411987305, 'logits/chosen': 0.2940963804721832, 'epoch': 5.75}

 96%|█████████▌| 15439/16104 [71:12:04<2:55:41, 15.85s/it]

 96%|█████████▌| 15440/16104 [71:12:19<2:53:55, 15.72s/it]


 96%|█████████▌| 15442/16104 [71:12:57<3:11:23, 17.35s/it]

 96%|█████████▌| 15443/16104 [71:13:14<3:11:15, 17.36s/it]

 96%|█████████▌| 15444/16104 [71:13:26<2:53:15, 15.75s/it]
{'loss': 0.4884, 'learning_rate': 8.79746910058543e-09, 'rewards/chosen': -0.631234884262085, 'rewards/rejected': -2.0581953525543213, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4269604682922363, 'policy_logps/rejected': -324.8782958984375, 'policy_logps/chosen': -460.8885498046875, 'referece_logps/rejected': -304.29632568359375, 'referece_logps/chosen': -454.5762023925781, 'logits/rejected': 0.19183631241321564, 'logits/chosen': 0.2525980472564697, 'epoch': 5.75}

 96%|█████████▌| 15445/16104 [71:13:47<3:10:44, 17.37s/it]

 96%|█████████▌| 15446/16104 [71:14:06<3:13:38, 17.66s/it]


 96%|█████████▌| 15448/16104 [71:14:35<2:53:13, 15.84s/it]

 96%|█████████▌| 15449/16104 [71:14:56<3:11:08, 17.51s/it]
{'loss': 0.2798, 'learning_rate': 8.664871123330808e-09, 'rewards/chosen': -1.0733832120895386, 'rewards/rejected': -2.576324701309204, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5029412508010864, 'policy_logps/rejected': -301.0138244628906, 'policy_logps/chosen': -270.8745422363281, 'referece_logps/rejected': -275.2505798339844, 'referece_logps/chosen': -260.14068603515625, 'logits/rejected': -0.6469336152076721, 'logits/chosen': -0.6172707676887512, 'epoch': 5.76}

 96%|█████████▌| 15450/16104 [71:15:16<3:17:36, 18.13s/it]


 96%|█████████▌| 15452/16104 [71:15:44<2:57:48, 16.36s/it]

 96%|█████████▌| 15453/16104 [71:16:04<3:09:14, 17.44s/it]

 96%|█████████▌| 15454/16104 [71:16:23<3:12:11, 17.74s/it]
{'loss': 0.3628, 'learning_rate': 8.533275677869877e-09, 'rewards/chosen': -0.9366052746772766, 'rewards/rejected': -2.0289266109466553, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0923212766647339, 'policy_logps/rejected': -386.7105407714844, 'policy_logps/chosen': -480.7385559082031, 'referece_logps/rejected': -366.4212646484375, 'referece_logps/chosen': -471.3725280761719, 'logits/rejected': -0.15423864126205444, 'logits/chosen': -0.22343972325325012, 'epoch': 5.76}

 96%|█████████▌| 15455/16104 [71:16:37<3:01:18, 16.76s/it]


 96%|█████████▌| 15457/16104 [71:17:17<3:17:05, 18.28s/it]

 96%|█████████▌| 15458/16104 [71:17:37<3:22:07, 18.77s/it]
{'loss': 0.2934, 'learning_rate': 8.428721233857627e-09, 'rewards/chosen': -0.6121673583984375, 'rewards/rejected': -2.2715954780578613, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6594282388687134, 'policy_logps/rejected': -469.8897399902344, 'policy_logps/chosen': -525.060302734375, 'referece_logps/rejected': -447.17376708984375, 'referece_logps/chosen': -518.9386596679688, 'logits/rejected': -0.029314517974853516, 'logits/chosen': -0.03264528512954712, 'epoch': 5.76}

 96%|█████████▌| 15459/16104 [71:17:58<3:30:01, 19.54s/it]

 96%|█████████▌| 15460/16104 [71:18:18<3:30:07, 19.58s/it]

 96%|█████████▌| 15461/16104 [71:18:30<3:05:22, 17.30s/it]

 96%|█████████▌| 15462/16104 [71:18:40<2:43:32, 15.28s/it]


 96%|█████████▌| 15464/16104 [71:19:13<2:47:52, 15.74s/it]
{'loss': 0.4257, 'learning_rate': 8.273092913642088e-09, 'rewards/chosen': -0.41186603903770447, 'rewards/rejected': -1.5350807905197144, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1232147216796875, 'policy_logps/rejected': -445.2825622558594, 'policy_logps/chosen': -443.7892761230469, 'referece_logps/rejected': -429.9317626953125, 'referece_logps/chosen': -439.670654296875, 'logits/rejected': -0.3205989599227905, 'logits/chosen': -0.2758861482143402, 'epoch': 5.76}

 96%|█████████▌| 15465/16104 [71:19:28<2:45:20, 15.53s/it]

 96%|█████████▌| 15466/16104 [71:19:48<2:59:07, 16.85s/it]

 96%|█████████▌| 15467/16104 [71:20:02<2:48:54, 15.91s/it]

 96%|█████████▌| 15468/16104 [71:20:24<3:07:03, 17.65s/it]

 96%|█████████▌| 15469/16104 [71:20:45<3:20:21, 18.93s/it]

 96%|█████████▌| 15470/16104 [71:21:02<3:12:03, 18.18s/it]

 96%|█████████▌| 15471/16104 [71:21:24<3:23:09, 19.26s/it]

 96%|█████████▌| 15472/16104 [71:21:44<3:24:50, 19.45s/it]

 96%|█████████▌| 15473/16104 [71:22:02<3:21:01, 19.12s/it]


 96%|█████████▌| 15475/16104 [71:22:35<3:04:15, 17.58s/it]

 96%|█████████▌| 15476/16104 [71:22:55<3:11:25, 18.29s/it]

 96%|█████████▌| 15477/16104 [71:23:08<2:52:02, 16.46s/it]

 96%|█████████▌| 15478/16104 [71:23:27<3:02:17, 17.47s/it]
{'loss': 0.2707, 'learning_rate': 7.915576950824788e-09, 'rewards/chosen': -0.4700900912284851, 'rewards/rejected': -2.058889150619507, 'rewards/accuracies': 0.75, 'rewards/margins': 1.588798999786377, 'policy_logps/rejected': -367.5516357421875, 'policy_logps/chosen': -431.7865905761719, 'referece_logps/rejected': -346.9627685546875, 'referece_logps/chosen': -427.085693359375, 'logits/rejected': -0.4283439815044403, 'logits/chosen': -0.4160431921482086, 'epoch': 5.77}

 96%|█████████▌| 15479/16104 [71:23:40<2:48:17, 16.16s/it]

 96%|█████████▌| 15480/16104 [71:24:00<2:58:25, 17.16s/it]

 96%|█████████▌| 15481/16104 [71:24:11<2:37:46, 15.19s/it]

 96%|█████████▌| 15482/16104 [71:24:24<2:32:49, 14.74s/it]


 96%|█████████▌| 15484/16104 [71:24:57<2:36:50, 15.18s/it]

 96%|█████████▌| 15485/16104 [71:25:14<2:39:42, 15.48s/it]
{'loss': 0.4545, 'learning_rate': 7.739768464269603e-09, 'rewards/chosen': -0.48439520597457886, 'rewards/rejected': -0.3979816734790802, 'rewards/accuracies': 0.625, 'rewards/margins': -0.08641353249549866, 'policy_logps/rejected': -505.3160400390625, 'policy_logps/chosen': -420.26007080078125, 'referece_logps/rejected': -501.3362731933594, 'referece_logps/chosen': -415.4161682128906, 'logits/rejected': 0.5061158537864685, 'logits/chosen': 0.4869347810745239, 'epoch': 5.77}

 96%|█████████▌| 15486/16104 [71:25:30<2:41:35, 15.69s/it]

 96%|█████████▌| 15487/16104 [71:25:43<2:32:42, 14.85s/it]


 96%|█████████▌| 15489/16104 [71:26:11<2:31:00, 14.73s/it]
{'loss': 0.3475, 'learning_rate': 7.640189500954019e-09, 'rewards/chosen': -0.36609452962875366, 'rewards/rejected': -1.3965733051300049, 'rewards/accuracies': 0.875, 'rewards/margins': 1.030478835105896, 'policy_logps/rejected': -400.19122314453125, 'policy_logps/chosen': -516.8314208984375, 'referece_logps/rejected': -386.2254638671875, 'referece_logps/chosen': -513.1705322265625, 'logits/rejected': 0.5007265210151672, 'logits/chosen': 0.530754804611206, 'epoch': 5.77}

 96%|█████████▌| 15490/16104 [71:26:30<2:45:39, 16.19s/it]

 96%|█████████▌| 15491/16104 [71:26:41<2:28:14, 14.51s/it]

 96%|█████████▌| 15492/16104 [71:26:53<2:19:25, 13.67s/it]

 96%|█████████▌| 15493/16104 [71:27:14<2:41:56, 15.90s/it]

 96%|█████████▌| 15494/16104 [71:27:32<2:48:58, 16.62s/it]

 96%|█████████▌| 15495/16104 [71:27:51<2:55:26, 17.29s/it]

 96%|█████████▌| 15496/16104 [71:28:06<2:47:53, 16.57s/it]

 96%|█████████▌| 15497/16104 [71:28:18<2:34:53, 15.31s/it]

 96%|█████████▌| 15498/16104 [71:28:31<2:28:12, 14.67s/it]

 96%|█████████▌| 15499/16104 [71:28:47<2:31:25, 15.02s/it]


 96%|█████████▋| 15501/16104 [71:29:40<3:32:02, 21.10s/it]
{'loss': 0.3991, 'learning_rate': 7.3453065681533536e-09, 'rewards/chosen': -0.5712207555770874, 'rewards/rejected': -1.6488659381866455, 'rewards/accuracies': 0.75, 'rewards/margins': 1.077645182609558, 'policy_logps/rejected': -515.3895874023438, 'policy_logps/chosen': -363.29754638671875, 'referece_logps/rejected': -498.9009094238281, 'referece_logps/chosen': -357.5853271484375, 'logits/rejected': -0.40109768509864807, 'logits/chosen': -0.31548646092414856, 'epoch': 5.78}


 96%|█████████▋| 15503/16104 [71:30:12<3:04:45, 18.44s/it]
{'loss': 0.4089, 'learning_rate': 7.296721531671712e-09, 'rewards/chosen': -0.7241493463516235, 'rewards/rejected': -1.5716902017593384, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8475408554077148, 'policy_logps/rejected': -388.936279296875, 'policy_logps/chosen': -517.4522705078125, 'referece_logps/rejected': -373.2193908691406, 'referece_logps/chosen': -510.2107238769531, 'logits/rejected': -0.5572502613067627, 'logits/chosen': -0.6223111152648926, 'epoch': 5.78}

 96%|█████████▋| 15504/16104 [71:30:32<3:07:49, 18.78s/it]


 96%|█████████▋| 15506/16104 [71:30:54<2:27:50, 14.83s/it]
{'loss': 0.3285, 'learning_rate': 7.2241451540390185e-09, 'rewards/chosen': -0.4106723666191101, 'rewards/rejected': -2.7047863006591797, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2941136360168457, 'policy_logps/rejected': -509.0908203125, 'policy_logps/chosen': -488.056640625, 'referece_logps/rejected': -482.04296875, 'referece_logps/chosen': -483.9499816894531, 'logits/rejected': -0.910818874835968, 'logits/chosen': -0.6829303503036499, 'epoch': 5.78}


 96%|█████████▋| 15508/16104 [71:31:30<2:47:17, 16.84s/it]
{'loss': 0.3222, 'learning_rate': 7.175961698427379e-09, 'rewards/chosen': -0.3808273375034332, 'rewards/rejected': -2.3467371463775635, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9659099578857422, 'policy_logps/rejected': -684.000732421875, 'policy_logps/chosen': -413.2850646972656, 'referece_logps/rejected': -660.5333251953125, 'referece_logps/chosen': -409.4767761230469, 'logits/rejected': 0.27921777963638306, 'logits/chosen': 0.12551768124103546, 'epoch': 5.78}

 96%|█████████▋| 15509/16104 [71:31:49<2:52:54, 17.44s/it]

 96%|█████████▋| 15510/16104 [71:32:02<2:41:08, 16.28s/it]

 96%|█████████▋| 15511/16104 [71:32:14<2:26:25, 14.82s/it]

 96%|█████████▋| 15512/16104 [71:32:29<2:27:12, 14.92s/it]

 96%|█████████▋| 15513/16104 [71:32:47<2:35:46, 15.81s/it]

 96%|█████████▋| 15514/16104 [71:33:00<2:26:51, 14.94s/it]

 96%|█████████▋| 15515/16104 [71:33:11<2:14:34, 13.71s/it]

 96%|█████████▋| 15516/16104 [71:33:32<2:36:24, 15.96s/it]

 96%|█████████▋| 15517/16104 [71:33:43<2:22:29, 14.56s/it]

 96%|█████████▋| 15518/16104 [71:34:01<2:31:42, 15.53s/it]

 96%|█████████▋| 15519/16104 [71:34:20<2:43:08, 16.73s/it]


 96%|█████████▋| 15521/16104 [71:34:48<2:25:54, 15.02s/it]
{'loss': 0.4004, 'learning_rate': 6.866685329490418e-09, 'rewards/chosen': -0.11812496185302734, 'rewards/rejected': -1.7523115873336792, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6341865062713623, 'policy_logps/rejected': -316.72955322265625, 'policy_logps/chosen': -408.07281494140625, 'referece_logps/rejected': -299.2064208984375, 'referece_logps/chosen': -406.8915710449219, 'logits/rejected': -0.2288411408662796, 'logits/chosen': -0.19440296292304993, 'epoch': 5.78}

 96%|█████████▋| 15522/16104 [71:35:08<2:39:00, 16.39s/it]


 96%|█████████▋| 15524/16104 [71:35:42<2:42:02, 16.76s/it]
{'loss': 0.4019, 'learning_rate': 6.796277959498331e-09, 'rewards/chosen': -0.6644076704978943, 'rewards/rejected': -1.9634370803833008, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2990295886993408, 'policy_logps/rejected': -441.59124755859375, 'policy_logps/chosen': -354.2449951171875, 'referece_logps/rejected': -421.9568786621094, 'referece_logps/chosen': -347.60089111328125, 'logits/rejected': -0.4120279848575592, 'logits/chosen': -0.5658463835716248, 'epoch': 5.78}

 96%|█████████▋| 15525/16104 [71:35:59<2:41:33, 16.74s/it]

 96%|█████████▋| 15526/16104 [71:36:15<2:39:29, 16.56s/it]

 96%|█████████▋| 15527/16104 [71:36:31<2:36:29, 16.27s/it]

 96%|█████████▋| 15528/16104 [71:36:50<2:44:32, 17.14s/it]

 96%|█████████▋| 15529/16104 [71:37:12<2:58:54, 18.67s/it]

 96%|█████████▋| 15530/16104 [71:37:25<2:41:54, 16.92s/it]

 96%|█████████▋| 15531/16104 [71:37:46<2:52:58, 18.11s/it]

 96%|█████████▋| 15532/16104 [71:37:59<2:39:33, 16.74s/it]


 96%|█████████▋| 15534/16104 [71:38:30<2:34:41, 16.28s/it]
{'loss': 0.368, 'learning_rate': 6.564198365212159e-09, 'rewards/chosen': -0.525684118270874, 'rewards/rejected': -2.214637517929077, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6889532804489136, 'policy_logps/rejected': -546.7855224609375, 'policy_logps/chosen': -373.158447265625, 'referece_logps/rejected': -524.63916015625, 'referece_logps/chosen': -367.901611328125, 'logits/rejected': -0.13530008494853973, 'logits/chosen': 0.0230757724493742, 'epoch': 5.79}

 96%|█████████▋| 15535/16104 [71:38:50<2:43:41, 17.26s/it]

 96%|█████████▋| 15536/16104 [71:39:12<2:57:02, 18.70s/it]

 96%|█████████▋| 15537/16104 [71:39:32<2:59:21, 18.98s/it]

 96%|█████████▋| 15538/16104 [71:39:51<3:00:56, 19.18s/it]

 96%|█████████▋| 15539/16104 [71:40:08<2:53:24, 18.42s/it]

 96%|█████████▋| 15540/16104 [71:40:26<2:51:00, 18.19s/it]

 97%|█████████▋| 15541/16104 [71:40:40<2:38:48, 16.92s/it]

 97%|█████████▋| 15542/16104 [71:40:59<2:46:45, 17.80s/it]

 97%|█████████▋| 15543/16104 [71:41:16<2:42:05, 17.34s/it]

 97%|█████████▋| 15544/16104 [71:41:34<2:43:39, 17.53s/it]

 97%|█████████▋| 15545/16104 [71:41:46<2:29:43, 16.07s/it]

 97%|█████████▋| 15546/16104 [71:41:58<2:17:06, 14.74s/it]

 97%|█████████▋| 15547/16104 [71:42:16<2:25:50, 15.71s/it]

 97%|█████████▋| 15548/16104 [71:42:31<2:23:45, 15.51s/it]

 97%|█████████▋| 15549/16104 [71:42:51<2:36:14, 16.89s/it]

 97%|█████████▋| 15550/16104 [71:43:02<2:18:56, 15.05s/it]

 97%|█████████▋| 15551/16104 [71:43:14<2:10:49, 14.19s/it]

 97%|█████████▋| 15552/16104 [71:43:34<2:25:32, 15.82s/it]

 97%|█████████▋| 15553/16104 [71:43:48<2:21:09, 15.37s/it]

 97%|█████████▋| 15554/16104 [71:44:05<2:25:37, 15.89s/it]

 97%|█████████▋| 15555/16104 [71:44:20<2:24:03, 15.74s/it]

 97%|█████████▋| 15556/16104 [71:44:39<2:32:44, 16.72s/it]

 97%|█████████▋| 15557/16104 [71:44:53<2:22:49, 15.67s/it]

 97%|█████████▋| 15558/16104 [71:45:03<2:09:01, 14.18s/it]


 97%|█████████▋| 15560/16104 [71:45:33<2:08:51, 14.21s/it]
{'loss': 0.4906, 'learning_rate': 5.979600875827384e-09, 'rewards/chosen': -0.0455126017332077, 'rewards/rejected': -0.5955122709274292, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5499997138977051, 'policy_logps/rejected': -444.6640930175781, 'policy_logps/chosen': -509.05914306640625, 'referece_logps/rejected': -438.708984375, 'referece_logps/chosen': -508.6040344238281, 'logits/rejected': -0.1491229385137558, 'logits/chosen': 0.027503985911607742, 'epoch': 5.8}

 97%|█████████▋| 15561/16104 [71:45:51<2:19:41, 15.44s/it]


 97%|█████████▋| 15563/16104 [71:46:23<2:17:37, 15.26s/it]

 97%|█████████▋| 15564/16104 [71:46:37<2:13:27, 14.83s/it]
{'loss': 0.5118, 'learning_rate': 5.89207499880684e-09, 'rewards/chosen': -0.6261773705482483, 'rewards/rejected': -0.3812847435474396, 'rewards/accuracies': 0.375, 'rewards/margins': -0.2448926866054535, 'policy_logps/rejected': -484.9649658203125, 'policy_logps/chosen': -464.2637023925781, 'referece_logps/rejected': -481.1521301269531, 'referece_logps/chosen': -458.00189208984375, 'logits/rejected': -0.4187467694282532, 'logits/chosen': -0.5424582362174988, 'epoch': 5.8}

 97%|█████████▋| 15565/16104 [71:46:57<2:26:48, 16.34s/it]

 97%|█████████▋| 15566/16104 [71:47:16<2:34:04, 17.18s/it]

 97%|█████████▋| 15567/16104 [71:47:32<2:30:15, 16.79s/it]

 97%|█████████▋| 15568/16104 [71:47:43<2:16:08, 15.24s/it]

 97%|█████████▋| 15569/16104 [71:47:58<2:14:45, 15.11s/it]

 97%|█████████▋| 15570/16104 [71:48:14<2:16:24, 15.33s/it]

 97%|█████████▋| 15571/16104 [71:48:34<2:28:38, 16.73s/it]

 97%|█████████▋| 15572/16104 [71:48:49<2:24:38, 16.31s/it]

 97%|█████████▋| 15573/16104 [71:49:09<2:33:03, 17.29s/it]

 97%|█████████▋| 15574/16104 [71:49:21<2:18:01, 15.62s/it]

 97%|█████████▋| 15575/16104 [71:49:33<2:09:53, 14.73s/it]

 97%|█████████▋| 15576/16104 [71:49:55<2:27:25, 16.75s/it]

 97%|█████████▋| 15577/16104 [71:50:12<2:27:27, 16.79s/it]

 97%|█████████▋| 15578/16104 [71:50:32<2:35:17, 17.71s/it]

 97%|█████████▋| 15579/16104 [71:50:45<2:23:46, 16.43s/it]

 97%|█████████▋| 15580/16104 [71:51:05<2:32:13, 17.43s/it]

 97%|█████████▋| 15581/16104 [71:51:24<2:35:31, 17.84s/it]

 97%|█████████▋| 15582/16104 [71:51:44<2:41:54, 18.61s/it]

 97%|█████████▋| 15583/16104 [71:51:56<2:23:26, 16.52s/it]

 97%|█████████▋| 15584/16104 [71:52:15<2:30:41, 17.39s/it]

 97%|█████████▋| 15585/16104 [71:52:34<2:35:49, 18.01s/it]


 97%|█████████▋| 15587/16104 [71:52:59<2:09:36, 15.04s/it]
{'loss': 0.4699, 'learning_rate': 5.401289194128855e-09, 'rewards/chosen': -0.25744637846946716, 'rewards/rejected': -1.8218424320220947, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5643961429595947, 'policy_logps/rejected': -431.8244323730469, 'policy_logps/chosen': -432.222412109375, 'referece_logps/rejected': -413.60601806640625, 'referece_logps/chosen': -429.6479797363281, 'logits/rejected': -0.04232390969991684, 'logits/chosen': -0.051325056701898575, 'epoch': 5.81}

 97%|█████████▋| 15588/16104 [71:53:11<2:01:11, 14.09s/it]


 97%|█████████▋| 15590/16104 [71:53:43<2:05:52, 14.69s/it]
{'loss': 0.4694, 'learning_rate': 5.3388425307668846e-09, 'rewards/chosen': -0.310873806476593, 'rewards/rejected': -2.266475200653076, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9556015729904175, 'policy_logps/rejected': -317.9772033691406, 'policy_logps/chosen': -393.95068359375, 'referece_logps/rejected': -295.31243896484375, 'referece_logps/chosen': -390.8419189453125, 'logits/rejected': -0.6441212892532349, 'logits/chosen': -0.7172389030456543, 'epoch': 5.81}


 97%|█████████▋| 15592/16104 [71:54:11<2:05:20, 14.69s/it]
{'loss': 0.4616, 'learning_rate': 5.297412599549523e-09, 'rewards/chosen': -0.8970968723297119, 'rewards/rejected': -2.1446728706359863, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2475758790969849, 'policy_logps/rejected': -255.57594299316406, 'policy_logps/chosen': -462.9671630859375, 'referece_logps/rejected': -234.1291961669922, 'referece_logps/chosen': -453.9961853027344, 'logits/rejected': -0.38421881198883057, 'logits/chosen': -0.5005375146865845, 'epoch': 5.81}

 97%|█████████▋| 15593/16104 [71:54:31<2:17:29, 16.14s/it]


 97%|█████████▋| 15595/16104 [71:55:01<2:09:33, 15.27s/it]
{'loss': 0.3162, 'learning_rate': 5.235569486018332e-09, 'rewards/chosen': -0.848412036895752, 'rewards/rejected': -1.9923901557922363, 'rewards/accuracies': 1.0, 'rewards/margins': 1.143978238105774, 'policy_logps/rejected': -285.0292663574219, 'policy_logps/chosen': -252.69827270507812, 'referece_logps/rejected': -265.1053771972656, 'referece_logps/chosen': -244.21414184570312, 'logits/rejected': -0.5682268142700195, 'logits/chosen': -0.5759842991828918, 'epoch': 5.81}

 97%|█████████▋| 15596/16104 [71:55:21<2:20:22, 16.58s/it]


 97%|█████████▋| 15598/16104 [71:56:00<2:31:25, 17.96s/it]

 97%|█████████▋| 15599/16104 [71:56:18<2:29:45, 17.79s/it]

 97%|█████████▋| 15600/16104 [71:56:39<2:38:03, 18.82s/it]

 97%|█████████▋| 15601/16104 [71:56:57<2:35:34, 18.56s/it]

 97%|█████████▋| 15602/16104 [71:57:16<2:36:33, 18.71s/it]

 97%|█████████▋| 15603/16104 [71:57:35<2:37:20, 18.84s/it]

 97%|█████████▋| 15604/16104 [71:57:55<2:39:48, 19.18s/it]

 97%|█████████▋| 15605/16104 [71:58:11<2:32:32, 18.34s/it]

 97%|█████████▋| 15606/16104 [71:58:32<2:38:03, 19.04s/it]
{'loss': 0.4556, 'learning_rate': 5.011910052511337e-09, 'rewards/chosen': -0.3614918291568756, 'rewards/rejected': -2.587791919708252, 'rewards/accuracies': 0.75, 'rewards/margins': 2.226300001144409, 'policy_logps/rejected': -463.7113037109375, 'policy_logps/chosen': -504.3489990234375, 'referece_logps/rejected': -437.8333740234375, 'referece_logps/chosen': -500.73406982421875, 'logits/rejected': -0.7520173788070679, 'logits/chosen': -0.8220959901809692, 'epoch': 5.81}


 97%|█████████▋| 15608/16104 [71:59:02<2:23:11, 17.32s/it]

 97%|█████████▋| 15609/16104 [71:59:16<2:14:17, 16.28s/it]

 97%|█████████▋| 15610/16104 [71:59:28<2:03:48, 15.04s/it]

 97%|█████████▋| 15611/16104 [71:59:40<1:56:29, 14.18s/it]

 97%|█████████▋| 15612/16104 [71:59:53<1:53:15, 13.81s/it]

 97%|█████████▋| 15613/16104 [72:00:13<2:08:10, 15.66s/it]

 97%|█████████▋| 15614/16104 [72:00:29<2:07:32, 15.62s/it]

 97%|█████████▋| 15615/16104 [72:00:46<2:09:44, 15.92s/it]

 97%|█████████▋| 15616/16104 [72:01:06<2:20:27, 17.27s/it]

 97%|█████████▋| 15617/16104 [72:01:19<2:10:10, 16.04s/it]
{'loss': 0.4405, 'learning_rate': 4.793120751332425e-09, 'rewards/chosen': -0.3414927124977112, 'rewards/rejected': -1.714575171470642, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3730826377868652, 'policy_logps/rejected': -519.8888549804688, 'policy_logps/chosen': -604.4833374023438, 'referece_logps/rejected': -502.7430725097656, 'referece_logps/chosen': -601.0684204101562, 'logits/rejected': 0.8520577549934387, 'logits/chosen': 0.7517080307006836, 'epoch': 5.82}


 97%|█████████▋| 15619/16104 [72:01:52<2:09:22, 16.01s/it]

 97%|█████████▋| 15620/16104 [72:02:03<1:56:32, 14.45s/it]

 97%|█████████▋| 15621/16104 [72:02:17<1:55:38, 14.36s/it]

 97%|█████████▋| 15622/16104 [72:02:31<1:53:59, 14.19s/it]

 97%|█████████▋| 15623/16104 [72:02:47<1:59:30, 14.91s/it]

 97%|█████████▋| 15624/16104 [72:03:07<2:10:25, 16.30s/it]

 97%|█████████▋| 15625/16104 [72:03:24<2:12:08, 16.55s/it]

 97%|█████████▋| 15626/16104 [72:03:43<2:16:31, 17.14s/it]

 97%|█████████▋| 15627/16104 [72:03:54<2:02:34, 15.42s/it]

 97%|█████████▋| 15628/16104 [72:04:05<1:51:18, 14.03s/it]

 97%|█████████▋| 15629/16104 [72:04:21<1:56:37, 14.73s/it]

 97%|█████████▋| 15630/16104 [72:04:41<2:07:38, 16.16s/it]
{'loss': 0.3043, 'learning_rate': 4.54083188836174e-09, 'rewards/chosen': -0.5677451491355896, 'rewards/rejected': -2.661390542984009, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0936453342437744, 'policy_logps/rejected': -529.6146240234375, 'policy_logps/chosen': -408.9405517578125, 'referece_logps/rejected': -503.000732421875, 'referece_logps/chosen': -403.2630615234375, 'logits/rejected': -0.964030385017395, 'logits/chosen': -0.7071641087532043, 'epoch': 5.82}

 97%|█████████▋| 15631/16104 [72:04:52<1:56:45, 14.81s/it]

 97%|█████████▋| 15632/16104 [72:05:06<1:54:55, 14.61s/it]


 97%|█████████▋| 15634/16104 [72:05:46<2:15:02, 17.24s/it]

 97%|█████████▋| 15635/16104 [72:06:06<2:21:19, 18.08s/it]

 97%|█████████▋| 15636/16104 [72:06:22<2:16:22, 17.48s/it]

 97%|█████████▋| 15637/16104 [72:06:43<2:24:07, 18.52s/it]
{'loss': 0.3806, 'learning_rate': 4.407802696430707e-09, 'rewards/chosen': -0.7287338376045227, 'rewards/rejected': -2.078606367111206, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3498724699020386, 'policy_logps/rejected': -329.3739318847656, 'policy_logps/chosen': -344.79522705078125, 'referece_logps/rejected': -308.587890625, 'referece_logps/chosen': -337.5079040527344, 'logits/rejected': -0.3884148895740509, 'logits/chosen': -0.4602280855178833, 'epoch': 5.83}


 97%|█████████▋| 15639/16104 [72:07:14<2:10:04, 16.78s/it]

 97%|█████████▋| 15640/16104 [72:07:30<2:07:12, 16.45s/it]
{'loss': 0.3557, 'learning_rate': 4.351394272483877e-09, 'rewards/chosen': -0.6239471435546875, 'rewards/rejected': -1.5530686378479004, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9291213750839233, 'policy_logps/rejected': -542.088134765625, 'policy_logps/chosen': -607.38330078125, 'referece_logps/rejected': -526.5574951171875, 'referece_logps/chosen': -601.1438598632812, 'logits/rejected': -0.18613846600055695, 'logits/chosen': -0.24085772037506104, 'epoch': 5.83}


 97%|█████████▋| 15642/16104 [72:08:00<2:04:54, 16.22s/it]

 97%|█████████▋| 15643/16104 [72:08:20<2:11:58, 17.18s/it]

 97%|█████████▋| 15644/16104 [72:08:40<2:18:07, 18.02s/it]

 97%|█████████▋| 15645/16104 [72:08:59<2:22:07, 18.58s/it]

 97%|█████████▋| 15646/16104 [72:09:11<2:06:01, 16.51s/it]

 97%|█████████▋| 15647/16104 [72:09:31<2:13:04, 17.47s/it]

 97%|█████████▋| 15648/16104 [72:09:51<2:18:35, 18.24s/it]

 97%|█████████▋| 15649/16104 [72:10:10<2:21:23, 18.65s/it]
{'loss': 0.4245, 'learning_rate': 4.18434397326306e-09, 'rewards/chosen': -0.6896630525588989, 'rewards/rejected': -1.7379385232925415, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0482755899429321, 'policy_logps/rejected': -370.9353332519531, 'policy_logps/chosen': -374.3703918457031, 'referece_logps/rejected': -353.55596923828125, 'referece_logps/chosen': -367.4737854003906, 'logits/rejected': -0.7785443663597107, 'logits/chosen': -0.830920934677124, 'epoch': 5.83}


 97%|█████████▋| 15651/16104 [72:10:43<2:13:59, 17.75s/it]

 97%|█████████▋| 15652/16104 [72:10:54<1:58:45, 15.77s/it]

 97%|█████████▋| 15653/16104 [72:11:11<2:01:19, 16.14s/it]

 97%|█████████▋| 15654/16104 [72:11:22<1:49:30, 14.60s/it]

 97%|█████████▋| 15655/16104 [72:11:41<2:00:00, 16.04s/it]
{'loss': 0.4171, 'learning_rate': 4.074789786693511e-09, 'rewards/chosen': -0.8039893507957458, 'rewards/rejected': -2.142611265182495, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3386220932006836, 'policy_logps/rejected': -265.9139099121094, 'policy_logps/chosen': -306.4302062988281, 'referece_logps/rejected': -244.48779296875, 'referece_logps/chosen': -298.39031982421875, 'logits/rejected': -0.2610747814178467, 'logits/chosen': -0.08530821651220322, 'epoch': 5.83}


 97%|█████████▋| 15657/16104 [72:12:17<2:07:26, 17.11s/it]

 97%|█████████▋| 15658/16104 [72:12:34<2:06:35, 17.03s/it]

 97%|█████████▋| 15659/16104 [72:12:46<1:54:22, 15.42s/it]

 97%|█████████▋| 15660/16104 [72:13:02<1:55:17, 15.58s/it]

 97%|█████████▋| 15661/16104 [72:13:21<2:02:11, 16.55s/it]

 97%|█████████▋| 15662/16104 [72:13:42<2:11:16, 17.82s/it]
{'loss': 0.4141, 'learning_rate': 3.948809636212358e-09, 'rewards/chosen': -0.7979873418807983, 'rewards/rejected': -2.0707106590270996, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2727233171463013, 'policy_logps/rejected': -440.2969665527344, 'policy_logps/chosen': -521.0621948242188, 'referece_logps/rejected': -419.5898742675781, 'referece_logps/chosen': -513.0823364257812, 'logits/rejected': 0.3264181911945343, 'logits/chosen': 0.2948957085609436, 'epoch': 5.84}


 97%|█████████▋| 15664/16104 [72:14:11<1:59:44, 16.33s/it]

 97%|█████████▋| 15665/16104 [72:14:26<1:55:32, 15.79s/it]

 97%|█████████▋| 15666/16104 [72:14:40<1:51:33, 15.28s/it]

 97%|█████████▋| 15667/16104 [72:14:53<1:46:45, 14.66s/it]

 97%|█████████▋| 15668/16104 [72:15:04<1:38:42, 13.58s/it]

 97%|█████████▋| 15669/16104 [72:15:15<1:32:30, 12.76s/it]

 97%|█████████▋| 15670/16104 [72:15:28<1:32:48, 12.83s/it]

 97%|█████████▋| 15671/16104 [72:15:48<1:48:17, 15.01s/it]

 97%|█████████▋| 15672/16104 [72:16:06<1:53:04, 15.70s/it]

 97%|█████████▋| 15673/16104 [72:16:18<1:45:08, 14.64s/it]

 97%|█████████▋| 15674/16104 [72:16:29<1:36:34, 13.48s/it]

 97%|█████████▋| 15675/16104 [72:16:50<1:53:37, 15.89s/it]

 97%|█████████▋| 15676/16104 [72:17:04<1:48:39, 15.23s/it]

 97%|█████████▋| 15677/16104 [72:17:20<1:51:18, 15.64s/it]
{'loss': 0.3309, 'learning_rate': 3.685500672883646e-09, 'rewards/chosen': -0.586529016494751, 'rewards/rejected': -2.175952196121216, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5894229412078857, 'policy_logps/rejected': -494.6118469238281, 'policy_logps/chosen': -500.6519775390625, 'referece_logps/rejected': -472.852294921875, 'referece_logps/chosen': -494.7866516113281, 'logits/rejected': -0.21654847264289856, 'logits/chosen': -0.242061585187912, 'epoch': 5.84}


 97%|█████████▋| 15679/16104 [72:17:51<1:51:48, 15.78s/it]
{'loss': 0.3155, 'learning_rate': 3.6510779051300843e-09, 'rewards/chosen': -1.188633918762207, 'rewards/rejected': -2.286313056945801, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0976790189743042, 'policy_logps/rejected': -450.25445556640625, 'policy_logps/chosen': -537.8883666992188, 'referece_logps/rejected': -427.39129638671875, 'referece_logps/chosen': -526.0020141601562, 'logits/rejected': 0.9455928802490234, 'logits/chosen': 0.9429690837860107, 'epoch': 5.84}


 97%|█████████▋| 15681/16104 [72:18:19<1:43:37, 14.70s/it]

 97%|█████████▋| 15682/16104 [72:18:31<1:37:10, 13.82s/it]
{'loss': 0.2986, 'learning_rate': 3.5997460359191713e-09, 'rewards/chosen': 0.3181692361831665, 'rewards/rejected': -2.4788918495178223, 'rewards/accuracies': 1.0, 'rewards/margins': 2.79706072807312, 'policy_logps/rejected': -442.2348327636719, 'policy_logps/chosen': -745.9390869140625, 'referece_logps/rejected': -417.4459228515625, 'referece_logps/chosen': -749.120849609375, 'logits/rejected': -0.3928053379058838, 'logits/chosen': -0.3781023919582367, 'epoch': 5.84}


 97%|█████████▋| 15684/16104 [72:18:58<1:34:25, 13.49s/it]

 97%|█████████▋| 15685/16104 [72:19:18<1:47:17, 15.36s/it]

 97%|█████████▋| 15686/16104 [72:19:33<1:46:16, 15.25s/it]

 97%|█████████▋| 15687/16104 [72:19:52<1:55:05, 16.56s/it]

 97%|█████████▋| 15688/16104 [72:20:06<1:49:10, 15.75s/it]

 97%|█████████▋| 15689/16104 [72:20:24<1:54:08, 16.50s/it]

 97%|█████████▋| 15690/16104 [72:20:44<2:00:51, 17.52s/it]

 97%|█████████▋| 15691/16104 [72:20:57<1:50:34, 16.06s/it]

 97%|█████████▋| 15692/16104 [72:21:09<1:41:29, 14.78s/it]
{'loss': 0.4652, 'learning_rate': 3.4312598100751934e-09, 'rewards/chosen': -0.2710891664028168, 'rewards/rejected': -0.9558207988739014, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6847317218780518, 'policy_logps/rejected': -528.4871215820312, 'policy_logps/chosen': -443.0797119140625, 'referece_logps/rejected': -518.928955078125, 'referece_logps/chosen': -440.36883544921875, 'logits/rejected': -0.1335940808057785, 'logits/chosen': -0.09452559053897858, 'epoch': 5.85}


 97%|█████████▋| 15694/16104 [72:21:49<1:59:00, 17.41s/it]

 97%|█████████▋| 15695/16104 [72:22:02<1:49:10, 16.01s/it]

 97%|█████████▋| 15696/16104 [72:22:20<1:54:43, 16.87s/it]

 97%|█████████▋| 15697/16104 [72:22:34<1:48:02, 15.93s/it]

 97%|█████████▋| 15698/16104 [72:22:55<1:57:07, 17.31s/it]

 97%|█████████▋| 15699/16104 [72:23:14<2:01:42, 18.03s/it]

 97%|█████████▋| 15700/16104 [72:23:28<1:52:24, 16.69s/it]

 97%|█████████▋| 15701/16104 [72:23:41<1:44:11, 15.51s/it]

 98%|█████████▊| 15702/16104 [72:23:53<1:36:49, 14.45s/it]
{'loss': 0.2581, 'learning_rate': 3.266804881276619e-09, 'rewards/chosen': -0.3665304481983185, 'rewards/rejected': -3.7265632152557373, 'rewards/accuracies': 1.0, 'rewards/margins': 3.360032796859741, 'policy_logps/rejected': -468.05718994140625, 'policy_logps/chosen': -505.9111022949219, 'referece_logps/rejected': -430.7915954589844, 'referece_logps/chosen': -502.24578857421875, 'logits/rejected': -0.6435999274253845, 'logits/chosen': -0.5732475519180298, 'epoch': 5.85}


 98%|█████████▊| 15704/16104 [72:24:26<1:43:48, 15.57s/it]

 98%|█████████▊| 15705/16104 [72:24:43<1:46:46, 16.06s/it]

 98%|█████████▊| 15706/16104 [72:24:59<1:45:15, 15.87s/it]

 98%|█████████▊| 15707/16104 [72:25:11<1:38:44, 14.92s/it]

 98%|█████████▊| 15708/16104 [72:25:31<1:47:29, 16.29s/it]
{'loss': 0.2596, 'learning_rate': 3.1700672240014825e-09, 'rewards/chosen': -0.5660116076469421, 'rewards/rejected': -2.661208391189575, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0951967239379883, 'policy_logps/rejected': -341.45556640625, 'policy_logps/chosen': -438.04449462890625, 'referece_logps/rejected': -314.8434753417969, 'referece_logps/chosen': -432.3843688964844, 'logits/rejected': -0.3291657567024231, 'logits/chosen': -0.27000150084495544, 'epoch': 5.85}


 98%|█████████▊| 15710/16104 [72:25:59<1:42:14, 15.57s/it]

 98%|█████████▊| 15711/16104 [72:26:11<1:33:14, 14.24s/it]

 98%|█████████▊| 15712/16104 [72:26:27<1:36:35, 14.78s/it]

 98%|█████████▊| 15713/16104 [72:26:47<1:48:15, 16.61s/it]

 98%|█████████▊| 15714/16104 [72:27:01<1:42:06, 15.71s/it]

 98%|█████████▊| 15715/16104 [72:27:17<1:43:12, 15.92s/it]

 98%|█████████▊| 15716/16104 [72:27:35<1:46:28, 16.47s/it]

 98%|█████████▊| 15717/16104 [72:27:54<1:49:51, 17.03s/it]

 98%|█████████▊| 15718/16104 [72:28:07<1:42:26, 15.92s/it]

 98%|█████████▊| 15719/16104 [72:28:27<1:49:39, 17.09s/it]
{'loss': 0.3154, 'learning_rate': 2.996485203947685e-09, 'rewards/chosen': -0.7593105435371399, 'rewards/rejected': -2.319997549057007, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5606873035430908, 'policy_logps/rejected': -379.30157470703125, 'policy_logps/chosen': -400.6865234375, 'referece_logps/rejected': -356.1015930175781, 'referece_logps/chosen': -393.09344482421875, 'logits/rejected': -0.07438050955533981, 'logits/chosen': -0.29745128750801086, 'epoch': 5.86}

 98%|█████████▊| 15720/16104 [72:28:44<1:50:40, 17.29s/it]


 98%|█████████▊| 15722/16104 [72:29:17<1:43:57, 16.33s/it]
{'loss': 0.3912, 'learning_rate': 2.949991559503151e-09, 'rewards/chosen': -0.46302586793899536, 'rewards/rejected': -1.8394534587860107, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3764277696609497, 'policy_logps/rejected': -452.4521484375, 'policy_logps/chosen': -460.1256408691406, 'referece_logps/rejected': -434.0576477050781, 'referece_logps/chosen': -455.4953308105469, 'logits/rejected': -0.33367809653282166, 'logits/chosen': -0.2626248896121979, 'epoch': 5.86}


 98%|█████████▊| 15724/16104 [72:29:53<1:46:04, 16.75s/it]

 98%|█████████▊| 15725/16104 [72:30:07<1:41:23, 16.05s/it]

 98%|█████████▊| 15726/16104 [72:30:21<1:37:26, 15.47s/it]

 98%|█████████▊| 15727/16104 [72:30:35<1:33:36, 14.90s/it]

 98%|█████████▊| 15728/16104 [72:30:49<1:32:25, 14.75s/it]
{'loss': 0.3631, 'learning_rate': 2.8580932635851042e-09, 'rewards/chosen': -0.490526407957077, 'rewards/rejected': -1.0661085844039917, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5755820870399475, 'policy_logps/rejected': -568.7114868164062, 'policy_logps/chosen': -477.4679870605469, 'referece_logps/rejected': -558.0504150390625, 'referece_logps/chosen': -472.562744140625, 'logits/rejected': 0.35823044180870056, 'logits/chosen': 0.28918424248695374, 'epoch': 5.86}


 98%|█████████▊| 15730/16104 [72:31:21<1:37:59, 15.72s/it]
{'loss': 0.4452, 'learning_rate': 2.827783181049259e-09, 'rewards/chosen': -0.2540828585624695, 'rewards/rejected': -1.0680534839630127, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8139704465866089, 'policy_logps/rejected': -504.13201904296875, 'policy_logps/chosen': -574.3028564453125, 'referece_logps/rejected': -493.45147705078125, 'referece_logps/chosen': -571.7620239257812, 'logits/rejected': 0.38234755396842957, 'logits/chosen': 0.5013009309768677, 'epoch': 5.86}


 98%|█████████▊| 15732/16104 [72:31:53<1:39:49, 16.10s/it]
{'loss': 0.4526, 'learning_rate': 2.7976344480942215e-09, 'rewards/chosen': -0.8866350650787354, 'rewards/rejected': -1.3025795221328735, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4159444272518158, 'policy_logps/rejected': -414.11181640625, 'policy_logps/chosen': -570.6070556640625, 'referece_logps/rejected': -401.08599853515625, 'referece_logps/chosen': -561.74072265625, 'logits/rejected': -0.377265602350235, 'logits/chosen': -0.4122096300125122, 'epoch': 5.86}


 98%|█████████▊| 15734/16104 [72:32:23<1:34:42, 15.36s/it]

 98%|█████████▊| 15735/16104 [72:32:36<1:28:26, 14.38s/it]

 98%|█████████▊| 15736/16104 [72:32:47<1:23:13, 13.57s/it]

 98%|█████████▊| 15737/16104 [72:33:07<1:34:15, 15.41s/it]

 98%|█████████▊| 15738/16104 [72:33:27<1:42:38, 16.83s/it]

 98%|█████████▊| 15739/16104 [72:33:44<1:41:46, 16.73s/it]

 98%|█████████▊| 15740/16104 [72:34:03<1:46:47, 17.60s/it]

 98%|█████████▊| 15741/16104 [72:34:23<1:50:28, 18.26s/it]

 98%|█████████▊| 15742/16104 [72:34:34<1:36:23, 15.98s/it]

 98%|█████████▊| 15743/16104 [72:34:50<1:36:52, 16.10s/it]

 98%|█████████▊| 15744/16104 [72:35:06<1:36:11, 16.03s/it]

 98%|█████████▊| 15745/16104 [72:35:26<1:43:24, 17.28s/it]
{'loss': 0.4948, 'learning_rate': 2.60560091434614e-09, 'rewards/chosen': -0.2808676064014435, 'rewards/rejected': -1.110525131225586, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8296575546264648, 'policy_logps/rejected': -542.14501953125, 'policy_logps/chosen': -504.3026123046875, 'referece_logps/rejected': -531.039794921875, 'referece_logps/chosen': -501.4939270019531, 'logits/rejected': -0.565660834312439, 'logits/chosen': -0.37613165378570557, 'epoch': 5.87}

 98%|█████████▊| 15746/16104 [72:35:39<1:35:04, 15.94s/it]

 98%|█████████▊| 15747/16104 [72:35:57<1:38:35, 16.57s/it]

 98%|█████████▊| 15748/16104 [72:36:11<1:33:01, 15.68s/it]


 98%|█████████▊| 15750/16104 [72:36:44<1:37:37, 16.55s/it]
{'loss': 0.4737, 'learning_rate': 2.533557378936457e-09, 'rewards/chosen': -1.2189223766326904, 'rewards/rejected': -2.12860107421875, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9096784591674805, 'policy_logps/rejected': -354.09033203125, 'policy_logps/chosen': -412.11920166015625, 'referece_logps/rejected': -332.8043212890625, 'referece_logps/chosen': -399.9299621582031, 'logits/rejected': -0.812229573726654, 'logits/chosen': -0.6517958045005798, 'epoch': 5.87}

 98%|█████████▊| 15751/16104 [72:36:59<1:34:33, 16.07s/it]

 98%|█████████▊| 15752/16104 [72:37:16<1:37:03, 16.54s/it]

 98%|█████████▊| 15753/16104 [72:37:31<1:33:25, 15.97s/it]

 98%|█████████▊| 15754/16104 [72:37:51<1:40:04, 17.16s/it]

 98%|█████████▊| 15755/16104 [72:38:07<1:37:57, 16.84s/it]

 98%|█████████▊| 15756/16104 [72:38:27<1:42:43, 17.71s/it]

 98%|█████████▊| 15757/16104 [72:38:39<1:32:04, 15.92s/it]

 98%|█████████▊| 15758/16104 [72:38:52<1:28:12, 15.30s/it]

 98%|█████████▊| 15759/16104 [72:39:09<1:30:18, 15.71s/it]

 98%|█████████▊| 15760/16104 [72:39:26<1:32:53, 16.20s/it]

 98%|█████████▊| 15761/16104 [72:39:37<1:23:13, 14.56s/it]

 98%|█████████▊| 15762/16104 [72:39:49<1:18:39, 13.80s/it]

 98%|█████████▊| 15763/16104 [72:40:01<1:14:40, 13.14s/it]


 98%|█████████▊| 15765/16104 [72:40:36<1:26:21, 15.28s/it]
{'loss': 0.4049, 'learning_rate': 2.323479453181676e-09, 'rewards/chosen': -0.3889788091182709, 'rewards/rejected': -1.9986586570739746, 'rewards/accuracies': 0.75, 'rewards/margins': 1.609679937362671, 'policy_logps/rejected': -432.23150634765625, 'policy_logps/chosen': -418.0566101074219, 'referece_logps/rejected': -412.2449035644531, 'referece_logps/chosen': -414.16680908203125, 'logits/rejected': -0.7248964905738831, 'logits/chosen': -0.6429370641708374, 'epoch': 5.87}


 98%|█████████▊| 15767/16104 [72:41:14<1:37:00, 17.27s/it]
{'loss': 0.4874, 'learning_rate': 2.296155104315467e-09, 'rewards/chosen': -0.8592827320098877, 'rewards/rejected': -2.0820467472076416, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2227636575698853, 'policy_logps/rejected': -516.5045166015625, 'policy_logps/chosen': -426.9700927734375, 'referece_logps/rejected': -495.68408203125, 'referece_logps/chosen': -418.37725830078125, 'logits/rejected': -0.3963097333908081, 'logits/chosen': -0.16341198980808258, 'epoch': 5.87}


 98%|█████████▊| 15769/16104 [72:41:40<1:22:54, 14.85s/it]
{'loss': 0.38, 'learning_rate': 2.2689921910513665e-09, 'rewards/chosen': -0.42613548040390015, 'rewards/rejected': -1.0819594860076904, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6558241248130798, 'policy_logps/rejected': -409.147705078125, 'policy_logps/chosen': -413.7700500488281, 'referece_logps/rejected': -398.32806396484375, 'referece_logps/chosen': -409.50872802734375, 'logits/rejected': 0.15748292207717896, 'logits/chosen': -0.017810553312301636, 'epoch': 5.88}

 98%|█████████▊| 15770/16104 [72:41:57<1:26:01, 15.45s/it]


 98%|█████████▊| 15772/16104 [72:42:27<1:23:19, 15.06s/it]
{'loss': 0.3808, 'learning_rate': 2.228550522516359e-09, 'rewards/chosen': -0.4548361897468567, 'rewards/rejected': -1.6877756118774414, 'rewards/accuracies': 0.75, 'rewards/margins': 1.232939600944519, 'policy_logps/rejected': -426.5372619628906, 'policy_logps/chosen': -345.8667297363281, 'referece_logps/rejected': -409.6595764160156, 'referece_logps/chosen': -341.318359375, 'logits/rejected': -0.7091751098632812, 'logits/chosen': -0.5553127527236938, 'epoch': 5.88}


 98%|█████████▊| 15774/16104 [72:43:05<1:33:55, 17.08s/it]

 98%|█████████▊| 15775/16104 [72:43:20<1:30:38, 16.53s/it]
{'loss': 0.4481, 'learning_rate': 2.188472108692219e-09, 'rewards/chosen': -1.458563208580017, 'rewards/rejected': -3.179798126220703, 'rewards/accuracies': 0.625, 'rewards/margins': 1.7212350368499756, 'policy_logps/rejected': -291.03936767578125, 'policy_logps/chosen': -296.72412109375, 'referece_logps/rejected': -259.24139404296875, 'referece_logps/chosen': -282.13848876953125, 'logits/rejected': -0.06517031043767929, 'logits/chosen': 0.038860902190208435, 'epoch': 5.88}

 98%|█████████▊| 15776/16104 [72:43:33<1:24:32, 15.46s/it]


 98%|█████████▊| 15778/16104 [72:44:00<1:18:34, 14.46s/it]

 98%|█████████▊| 15779/16104 [72:44:17<1:21:43, 15.09s/it]

 98%|█████████▊| 15780/16104 [72:44:32<1:21:37, 15.11s/it]
{'loss': 0.3637, 'learning_rate': 2.122482024580319e-09, 'rewards/chosen': -0.9330891966819763, 'rewards/rejected': -1.792319416999817, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8592301607131958, 'policy_logps/rejected': -298.77783203125, 'policy_logps/chosen': -271.95782470703125, 'referece_logps/rejected': -280.8546447753906, 'referece_logps/chosen': -262.6269226074219, 'logits/rejected': -0.06546112895011902, 'logits/chosen': -0.029457122087478638, 'epoch': 5.88}

 98%|█████████▊| 15781/16104 [72:44:53<1:30:59, 16.90s/it]


 98%|█████████▊| 15783/16104 [72:45:28<1:31:42, 17.14s/it]

 98%|█████████▊| 15784/16104 [72:45:46<1:32:36, 17.36s/it]
{'loss': 0.3242, 'learning_rate': 2.070416540736586e-09, 'rewards/chosen': -1.404233455657959, 'rewards/rejected': -2.7000949382781982, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2958612442016602, 'policy_logps/rejected': -366.25262451171875, 'policy_logps/chosen': -422.9975891113281, 'referece_logps/rejected': -339.25164794921875, 'referece_logps/chosen': -408.95526123046875, 'logits/rejected': -0.5328547954559326, 'logits/chosen': -0.5655844211578369, 'epoch': 5.88}


 98%|█████████▊| 15786/16104 [72:46:19<1:30:52, 17.15s/it]

 98%|█████████▊| 15787/16104 [72:46:39<1:34:54, 17.96s/it]

 98%|█████████▊| 15788/16104 [72:46:56<1:34:04, 17.86s/it]

 98%|█████████▊| 15789/16104 [72:47:07<1:22:24, 15.70s/it]
{'loss': 0.6154, 'learning_rate': 2.0062429705252073e-09, 'rewards/chosen': -0.23029938340187073, 'rewards/rejected': -1.7433247566223145, 'rewards/accuracies': 0.875, 'rewards/margins': 1.513025164604187, 'policy_logps/rejected': -524.0513305664062, 'policy_logps/chosen': -473.0075378417969, 'referece_logps/rejected': -506.61810302734375, 'referece_logps/chosen': -470.70458984375, 'logits/rejected': -0.16489166021347046, 'logits/chosen': -0.24307024478912354, 'epoch': 5.88}


 98%|█████████▊| 15791/16104 [72:47:35<1:17:20, 14.83s/it]

 98%|█████████▊| 15792/16104 [72:47:54<1:24:04, 16.17s/it]

 98%|█████████▊| 15793/16104 [72:48:09<1:21:21, 15.70s/it]
{'loss': 0.5706, 'learning_rate': 1.9556307825273622e-09, 'rewards/chosen': -0.14147073030471802, 'rewards/rejected': -1.0741344690322876, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9326637983322144, 'policy_logps/rejected': -539.557861328125, 'policy_logps/chosen': -489.9180908203125, 'referece_logps/rejected': -528.8165283203125, 'referece_logps/chosen': -488.5033264160156, 'logits/rejected': -0.07656353712081909, 'logits/chosen': -0.04132241755723953, 'epoch': 5.88}

 98%|█████████▊| 15794/16104 [72:48:21<1:16:24, 14.79s/it]


 98%|█████████▊| 15796/16104 [72:48:59<1:25:26, 16.64s/it]
{'loss': 0.4317, 'learning_rate': 1.9180955528270705e-09, 'rewards/chosen': -0.4887469708919525, 'rewards/rejected': -1.5838618278503418, 'rewards/accuracies': 0.875, 'rewards/margins': 1.095114827156067, 'policy_logps/rejected': -543.8521728515625, 'policy_logps/chosen': -531.274169921875, 'referece_logps/rejected': -528.0135498046875, 'referece_logps/chosen': -526.38671875, 'logits/rejected': 0.8866990804672241, 'logits/chosen': 0.9784470796585083, 'epoch': 5.89}


 98%|█████████▊| 15798/16104 [72:49:33<1:26:58, 17.05s/it]

 98%|█████████▊| 15799/16104 [72:49:53<1:31:17, 17.96s/it]
{'loss': 0.4874, 'learning_rate': 1.8809236908639002e-09, 'rewards/chosen': -0.321272075176239, 'rewards/rejected': -1.4200854301452637, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0988131761550903, 'policy_logps/rejected': -385.28875732421875, 'policy_logps/chosen': -389.061279296875, 'referece_logps/rejected': -371.087890625, 'referece_logps/chosen': -385.8485107421875, 'logits/rejected': 0.2639651298522949, 'logits/chosen': 0.2144172489643097, 'epoch': 5.89}


 98%|█████████▊| 15801/16104 [72:50:30<1:31:52, 18.19s/it]

 98%|█████████▊| 15802/16104 [72:50:51<1:34:50, 18.84s/it]

 98%|█████████▊| 15803/16104 [72:51:13<1:39:21, 19.81s/it]

 98%|█████████▊| 15804/16104 [72:51:26<1:29:09, 17.83s/it]
{'loss': 0.4476, 'learning_rate': 1.8197781081485952e-09, 'rewards/chosen': -0.9774280786514282, 'rewards/rejected': -2.1512672901153564, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1738393306732178, 'policy_logps/rejected': -487.01458740234375, 'policy_logps/chosen': -563.5579223632812, 'referece_logps/rejected': -465.50189208984375, 'referece_logps/chosen': -553.7836303710938, 'logits/rejected': -0.07307659089565277, 'logits/chosen': 0.051106154918670654, 'epoch': 5.89}


 98%|█████████▊| 15806/16104 [72:52:06<1:34:11, 18.96s/it]

 98%|█████████▊| 15807/16104 [72:52:21<1:27:59, 17.78s/it]
{'loss': 0.3591, 'learning_rate': 1.7835752926198544e-09, 'rewards/chosen': -0.19377288222312927, 'rewards/rejected': -1.4429397583007812, 'rewards/accuracies': 0.75, 'rewards/margins': 1.24916672706604, 'policy_logps/rejected': -365.3166809082031, 'policy_logps/chosen': -401.6360168457031, 'referece_logps/rejected': -350.88726806640625, 'referece_logps/chosen': -399.69830322265625, 'logits/rejected': -0.6155823469161987, 'logits/chosen': -0.5336045026779175, 'epoch': 5.89}


 98%|█████████▊| 15809/16104 [72:52:57<1:28:59, 18.10s/it]

 98%|█████████▊| 15810/16104 [72:53:11<1:22:36, 16.86s/it]

 98%|█████████▊| 15811/16104 [72:53:27<1:21:34, 16.70s/it]

 98%|█████████▊| 15812/16104 [72:53:46<1:25:17, 17.52s/it]

 98%|█████████▊| 15813/16104 [72:54:05<1:26:21, 17.81s/it]

 98%|█████████▊| 15814/16104 [72:54:25<1:29:37, 18.54s/it]
{'loss': 0.3503, 'learning_rate': 1.7005153661298067e-09, 'rewards/chosen': -0.9757856130599976, 'rewards/rejected': -2.0733444690704346, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0975589752197266, 'policy_logps/rejected': -295.8654479980469, 'policy_logps/chosen': -382.9324951171875, 'referece_logps/rejected': -275.13201904296875, 'referece_logps/chosen': -373.17462158203125, 'logits/rejected': 0.0842217355966568, 'logits/chosen': 0.04029160737991333, 'epoch': 5.89}


 98%|█████████▊| 15816/16104 [72:54:57<1:23:09, 17.32s/it]
{'loss': 0.3563, 'learning_rate': 1.6771473983611117e-09, 'rewards/chosen': -0.2681141197681427, 'rewards/rejected': -2.218339443206787, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9502253532409668, 'policy_logps/rejected': -503.0579833984375, 'policy_logps/chosen': -490.19720458984375, 'referece_logps/rejected': -480.87457275390625, 'referece_logps/chosen': -487.5160217285156, 'logits/rejected': 0.41693204641342163, 'logits/chosen': 0.4195690155029297, 'epoch': 5.89}

 98%|█████████▊| 15817/16104 [72:55:16<1:25:56, 17.97s/it]

 98%|█████████▊| 15818/16104 [72:55:28<1:16:42, 16.09s/it]

 98%|█████████▊| 15819/16104 [72:55:48<1:21:56, 17.25s/it]


 98%|█████████▊| 15821/16104 [72:56:23<1:22:05, 17.41s/it]

 98%|█████████▊| 15822/16104 [72:56:41<1:23:00, 17.66s/it]

 98%|█████████▊| 15823/16104 [72:57:01<1:25:46, 18.32s/it]

 98%|█████████▊| 15824/16104 [72:57:21<1:27:27, 18.74s/it]

 98%|█████████▊| 15825/16104 [72:57:41<1:28:52, 19.11s/it]

 98%|█████████▊| 15826/16104 [72:57:55<1:22:08, 17.73s/it]
{'loss': 0.4464, 'learning_rate': 1.5627306706533783e-09, 'rewards/chosen': -0.7670746445655823, 'rewards/rejected': -1.2307881116867065, 'rewards/accuracies': 0.625, 'rewards/margins': 0.46371349692344666, 'policy_logps/rejected': -541.4501953125, 'policy_logps/chosen': -490.6835021972656, 'referece_logps/rejected': -529.142333984375, 'referece_logps/chosen': -483.0128173828125, 'logits/rejected': 0.10168366134166718, 'logits/chosen': 0.14456532895565033, 'epoch': 5.9}

 98%|█████████▊| 15827/16104 [72:58:10<1:17:52, 16.87s/it]

 98%|█████████▊| 15828/16104 [72:58:24<1:12:50, 15.83s/it]

 98%|█████████▊| 15829/16104 [72:58:42<1:16:40, 16.73s/it]

 98%|█████████▊| 15830/16104 [72:58:56<1:12:28, 15.87s/it]

 98%|█████████▊| 15831/16104 [72:59:08<1:06:36, 14.64s/it]

 98%|█████████▊| 15832/16104 [72:59:19<1:01:02, 13.47s/it]

 98%|█████████▊| 15833/16104 [72:59:32<1:00:49, 13.47s/it]


 98%|█████████▊| 15835/16104 [73:00:03<1:06:43, 14.88s/it]
{'loss': 0.3774, 'learning_rate': 1.4632088243812236e-09, 'rewards/chosen': -0.550279974937439, 'rewards/rejected': -1.8238662481307983, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2735861539840698, 'policy_logps/rejected': -472.2002258300781, 'policy_logps/chosen': -501.8294372558594, 'referece_logps/rejected': -453.9615478515625, 'referece_logps/chosen': -496.3266296386719, 'logits/rejected': -0.463716983795166, 'logits/chosen': -0.5953618288040161, 'epoch': 5.9}


 98%|█████████▊| 15837/16104 [73:00:36<1:07:37, 15.20s/it]
{'loss': 0.4856, 'learning_rate': 1.441537165697615e-09, 'rewards/chosen': -0.32012617588043213, 'rewards/rejected': -1.943365454673767, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6232393980026245, 'policy_logps/rejected': -405.6572570800781, 'policy_logps/chosen': -525.086181640625, 'referece_logps/rejected': -386.2236022949219, 'referece_logps/chosen': -521.8849487304688, 'logits/rejected': -0.2807801365852356, 'logits/chosen': -0.2868313789367676, 'epoch': 5.9}


 98%|█████████▊| 15839/16104 [73:01:07<1:09:26, 15.72s/it]
{'loss': 0.4361, 'learning_rate': 1.4200270808993886e-09, 'rewards/chosen': -0.1726335734128952, 'rewards/rejected': -1.3711870908737183, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1985535621643066, 'policy_logps/rejected': -409.30804443359375, 'policy_logps/chosen': -478.2554931640625, 'referece_logps/rejected': -395.5961608886719, 'referece_logps/chosen': -476.5292053222656, 'logits/rejected': 0.03987990319728851, 'logits/chosen': 0.17540735006332397, 'epoch': 5.9}

 98%|█████████▊| 15840/16104 [73:01:23<1:09:27, 15.79s/it]

 98%|█████████▊| 15841/16104 [73:01:35<1:03:55, 14.58s/it]

 98%|█████████▊| 15842/16104 [73:01:48<1:02:01, 14.20s/it]


 98%|█████████▊| 15844/16104 [73:02:20<1:04:11, 14.81s/it]

{'loss': 0.4179, 'learning_rate': 1.3669587774284286e-09, 'rewards/chosen': -0.542273759841919, 'rewards/rejected': -1.6193379163742065, 'rewards/accuracies': 0.75, 'rewards/margins': 1.077064037322998, 'policy_logps/rejected': -418.6183776855469, 'policy_logps/chosen': -423.6982421875, 'referece_logps/rejected': -402.4250183105469, 'referece_logps/chosen': -418.27545166015625, 'logits/rejected': -0.24304267764091492, 'logits/chosen': -0.17890527844429016, 'epoch': 5.9}
{'loss': 0.4088, 'learning_rate': 1.356466304490711e-09, 'rewards/chosen': -0.06371576339006424, 'rewards/rejected': -0.3650772273540497, 'rewards/accuracies': 0.875, 'rewards/margins': 0.30136147141456604, 'policy_logps/rejected': -464.24139404296875, 'policy_logps/chosen': -457.4072570800781, 'referece_logps/rejected': -460.590576171875, 'referece_logps/chosen': -456.77008056640625, 'logits/rejected': 0.5750892162322998, 'logits/chosen': 0.519013524055481, 'epoch': 5.9}

 98%|█████████▊| 15846/16104 [73:02:46<59:09, 13.76s/it]
{'loss': 0.5011, 'learning_rate': 1.3460142284660304e-09, 'rewards/chosen': -0.5076881647109985, 'rewards/rejected': -1.0866219997406006, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5789339542388916, 'policy_logps/rejected': -355.381591796875, 'policy_logps/chosen': -445.314453125, 'referece_logps/rejected': -344.51531982421875, 'referece_logps/chosen': -440.237548828125, 'logits/rejected': -0.4937741160392761, 'logits/chosen': -0.480124831199646, 'epoch': 5.9}


 98%|█████████▊| 15848/16104 [73:03:10<54:21, 12.74s/it]
{'loss': 0.4785, 'learning_rate': 1.3252312688453171e-09, 'rewards/chosen': 0.005870819091796875, 'rewards/rejected': -0.9159756898880005, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9218465089797974, 'policy_logps/rejected': -449.28668212890625, 'policy_logps/chosen': -483.8909912109375, 'referece_logps/rejected': -440.1269226074219, 'referece_logps/chosen': -483.94970703125, 'logits/rejected': -0.4078294038772583, 'logits/chosen': -0.27694207429885864, 'epoch': 5.9}


 98%|█████████▊| 15850/16104 [73:03:44<1:04:32, 15.24s/it]

 98%|█████████▊| 15851/16104 [73:04:03<1:09:40, 16.52s/it]
{'loss': 0.4371, 'learning_rate': 1.2943598167788339e-09, 'rewards/chosen': -0.2641187608242035, 'rewards/rejected': -1.1364434957504272, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8723247647285461, 'policy_logps/rejected': -399.01983642578125, 'policy_logps/chosen': -425.1656188964844, 'referece_logps/rejected': -387.6553955078125, 'referece_logps/chosen': -422.52447509765625, 'logits/rejected': 0.25575071573257446, 'logits/chosen': 0.1773425042629242, 'epoch': 5.91}

 98%|█████████▊| 15852/16104 [73:04:18<1:06:58, 15.95s/it]

 98%|█████████▊| 15853/16104 [73:04:29<1:00:49, 14.54s/it]

 98%|█████████▊| 15854/16104 [73:04:43<1:00:02, 14.41s/it]


 98%|█████████▊| 15856/16104 [73:05:20<1:07:52, 16.42s/it]

 98%|█████████▊| 15857/16104 [73:05:40<1:11:52, 17.46s/it]
{'loss': 0.4186, 'learning_rate': 1.2337077082069659e-09, 'rewards/chosen': -0.43538302183151245, 'rewards/rejected': -0.8396796584129333, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4042966663837433, 'policy_logps/rejected': -526.3574829101562, 'policy_logps/chosen': -460.2144775390625, 'referece_logps/rejected': -517.9606323242188, 'referece_logps/chosen': -455.860595703125, 'logits/rejected': -0.5714718103408813, 'logits/chosen': -0.28275033831596375, 'epoch': 5.91}


 98%|█████████▊| 15859/16104 [73:06:18<1:14:59, 18.37s/it]
{'loss': 0.3898, 'learning_rate': 1.2138135493746648e-09, 'rewards/chosen': -1.11550772190094, 'rewards/rejected': -2.591761589050293, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4762537479400635, 'policy_logps/rejected': -292.24176025390625, 'policy_logps/chosen': -292.37432861328125, 'referece_logps/rejected': -266.3241271972656, 'referece_logps/chosen': -281.21923828125, 'logits/rejected': -0.9847415685653687, 'logits/chosen': -0.9266722798347473, 'epoch': 5.91}

 98%|█████████▊| 15860/16104 [73:06:31<1:08:27, 16.83s/it]

 98%|█████████▊| 15861/16104 [73:06:51<1:12:27, 17.89s/it]

 98%|█████████▊| 15862/16104 [73:07:03<1:05:06, 16.14s/it]

 99%|█████████▊| 15863/16104 [73:07:23<1:08:40, 17.10s/it]

 99%|█████████▊| 15864/16104 [73:07:39<1:07:50, 16.96s/it]

 99%|█████████▊| 15865/16104 [73:07:59<1:10:57, 17.81s/it]

 99%|█████████▊| 15866/16104 [73:08:15<1:08:53, 17.37s/it]

 99%|█████████▊| 15867/16104 [73:08:35<1:10:49, 17.93s/it]

 99%|█████████▊| 15868/16104 [73:08:49<1:06:46, 16.98s/it]


 99%|█████████▊| 15870/16104 [73:09:26<1:09:54, 17.92s/it]

 99%|█████████▊| 15871/16104 [73:09:42<1:07:03, 17.27s/it]
{'loss': 0.4573, 'learning_rate': 1.0978425326011454e-09, 'rewards/chosen': 0.08306578546762466, 'rewards/rejected': -1.947500228881836, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0305659770965576, 'policy_logps/rejected': -495.49261474609375, 'policy_logps/chosen': -543.5635375976562, 'referece_logps/rejected': -476.017578125, 'referece_logps/chosen': -544.3942260742188, 'logits/rejected': 0.034470658749341965, 'logits/chosen': -0.009267367422580719, 'epoch': 5.91}

 99%|█████████▊| 15872/16104 [73:09:57<1:03:52, 16.52s/it]

 99%|█████████▊| 15873/16104 [73:10:08<57:19, 14.89s/it]

 99%|█████████▊| 15874/16104 [73:10:21<55:16, 14.42s/it]

 99%|█████████▊| 15875/16104 [73:10:43<1:03:45, 16.70s/it]

 99%|█████████▊| 15876/16104 [73:10:55<57:43, 15.19s/it]


 99%|█████████▊| 15878/16104 [73:11:22<54:29, 14.47s/it]
{'loss': 0.4635, 'learning_rate': 1.03287982002076e-09, 'rewards/chosen': -0.7121576070785522, 'rewards/rejected': -1.9397995471954346, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2276418209075928, 'policy_logps/rejected': -362.3753662109375, 'policy_logps/chosen': -422.7820129394531, 'referece_logps/rejected': -342.9773864746094, 'referece_logps/chosen': -415.6604309082031, 'logits/rejected': -0.2150707095861435, 'logits/chosen': -0.33517318964004517, 'epoch': 5.92}

 99%|█████████▊| 15879/16104 [73:11:35<53:00, 14.14s/it]

 99%|█████████▊| 15880/16104 [73:11:55<59:24, 15.91s/it]

 99%|█████████▊| 15881/16104 [73:12:15<1:03:13, 17.01s/it]

 99%|█████████▊| 15882/16104 [73:12:35<1:06:48, 18.05s/it]

 99%|█████████▊| 15883/16104 [73:12:55<1:08:03, 18.48s/it]

 99%|█████████▊| 15884/16104 [73:13:10<1:03:38, 17.36s/it]


 99%|█████████▊| 15886/16104 [73:13:44<1:03:16, 17.42s/it]

 99%|█████████▊| 15887/16104 [73:14:04<1:05:34, 18.13s/it]
{'loss': 0.4746, 'learning_rate': 9.522658697063146e-10, 'rewards/chosen': -0.30918389558792114, 'rewards/rejected': -1.3636788129806519, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0544949769973755, 'policy_logps/rejected': -432.03497314453125, 'policy_logps/chosen': -506.93878173828125, 'referece_logps/rejected': -418.398193359375, 'referece_logps/chosen': -503.84698486328125, 'logits/rejected': 0.25492504239082336, 'logits/chosen': 0.27248483896255493, 'epoch': 5.92}

 99%|█████████▊| 15888/16104 [73:14:17<59:51, 16.63s/it]

 99%|█████████▊| 15889/16104 [73:14:35<1:00:17, 16.82s/it]

 99%|█████████▊| 15890/16104 [73:14:53<1:02:04, 17.40s/it]


 99%|█████████▊| 15892/16104 [73:15:30<1:04:20, 18.21s/it]

 99%|█████████▊| 15893/16104 [73:15:47<1:01:54, 17.60s/it]
{'loss': 0.368, 'learning_rate': 9.003418166732002e-10, 'rewards/chosen': -0.3897208869457245, 'rewards/rejected': -2.554165840148926, 'rewards/accuracies': 0.875, 'rewards/margins': 2.164445161819458, 'policy_logps/rejected': -495.93072509765625, 'policy_logps/chosen': -469.0999755859375, 'referece_logps/rejected': -470.3890380859375, 'referece_logps/chosen': -465.20281982421875, 'logits/rejected': -0.07061517983675003, 'logits/chosen': -0.1903432309627533, 'epoch': 5.92}


 99%|█████████▊| 15895/16104 [73:16:19<59:31, 17.09s/it]
{'loss': 0.3827, 'learning_rate': 8.833571181967592e-10, 'rewards/chosen': -0.841674268245697, 'rewards/rejected': -2.1484789848327637, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3068046569824219, 'policy_logps/rejected': -414.268798828125, 'policy_logps/chosen': -573.7537841796875, 'referece_logps/rejected': -392.78399658203125, 'referece_logps/chosen': -565.3370361328125, 'logits/rejected': -0.38969293236732483, 'logits/chosen': -0.3259783983230591, 'epoch': 5.92}


 99%|█████████▊| 15897/16104 [73:16:51<56:16, 16.31s/it]

 99%|█████████▊| 15898/16104 [73:17:05<53:28, 15.58s/it]
{'loss': 0.4435, 'learning_rate': 8.581831917140459e-10, 'rewards/chosen': 0.21510657668113708, 'rewards/rejected': -1.806653618812561, 'rewards/accuracies': 0.875, 'rewards/margins': 2.0217599868774414, 'policy_logps/rejected': -387.12652587890625, 'policy_logps/chosen': -368.8781433105469, 'referece_logps/rejected': -369.05999755859375, 'referece_logps/chosen': -371.0291748046875, 'logits/rejected': -0.011498624458909035, 'logits/chosen': -0.05097608640789986, 'epoch': 5.92}

 99%|█████████▊| 15899/16104 [73:17:17<50:23, 14.75s/it]

 99%|█████████▊| 15900/16104 [73:17:35<53:27, 15.72s/it]


 99%|█████████▊| 15902/16104 [73:18:07<52:43, 15.66s/it]

 99%|█████████▉| 15903/16104 [73:18:24<54:26, 16.25s/it]
{'loss': 0.4037, 'learning_rate': 8.17034993409349e-10, 'rewards/chosen': -0.5544919967651367, 'rewards/rejected': -2.418691396713257, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8641993999481201, 'policy_logps/rejected': -288.1711120605469, 'policy_logps/chosen': -356.3077697753906, 'referece_logps/rejected': -263.98419189453125, 'referece_logps/chosen': -350.76287841796875, 'logits/rejected': 0.23260895907878876, 'logits/chosen': 0.3188888430595398, 'epoch': 5.93}

 99%|█████████▉| 15904/16104 [73:18:37<50:26, 15.13s/it]

 99%|█████████▉| 15905/16104 [73:18:50<47:49, 14.42s/it]

 99%|█████████▉| 15906/16104 [73:19:03<46:45, 14.17s/it]

 99%|█████████▉| 15907/16104 [73:19:16<44:48, 13.65s/it]

 99%|█████████▉| 15908/16104 [73:19:27<42:35, 13.04s/it]

 99%|█████████▉| 15909/16104 [73:19:38<40:09, 12.36s/it]

 99%|█████████▉| 15910/16104 [73:20:00<49:13, 15.22s/it]


 99%|█████████▉| 15912/16104 [73:20:27<45:04, 14.09s/it]
{'loss': 0.4519, 'learning_rate': 7.455146438064553e-10, 'rewards/chosen': -0.07743386924266815, 'rewards/rejected': -0.9813466668128967, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9039127826690674, 'policy_logps/rejected': -498.6842956542969, 'policy_logps/chosen': -421.56103515625, 'referece_logps/rejected': -488.870849609375, 'referece_logps/chosen': -420.7867126464844, 'logits/rejected': -0.3433557450771332, 'logits/chosen': -0.28782927989959717, 'epoch': 5.93}

 99%|█████████▉| 15913/16104 [73:20:38<41:52, 13.15s/it]

 99%|█████████▉| 15914/16104 [73:20:50<40:53, 12.92s/it]

 99%|█████████▉| 15915/16104 [73:21:04<41:51, 13.29s/it]

 99%|█████████▉| 15916/16104 [73:21:17<41:14, 13.16s/it]

 99%|█████████▉| 15917/16104 [73:21:34<43:53, 14.09s/it]

 99%|█████████▉| 15918/16104 [73:21:51<47:13, 15.23s/it]

 99%|█████████▉| 15919/16104 [73:22:08<48:33, 15.75s/it]

 99%|█████████▉| 15920/16104 [73:22:28<51:50, 16.91s/it]

 99%|█████████▉| 15921/16104 [73:22:46<52:10, 17.11s/it]


 99%|█████████▉| 15923/16104 [73:23:17<48:11, 15.98s/it]
{'loss': 0.3625, 'learning_rate': 6.625472836658819e-10, 'rewards/chosen': -0.6613442897796631, 'rewards/rejected': -1.9353399276733398, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2739956378936768, 'policy_logps/rejected': -362.0187683105469, 'policy_logps/chosen': -386.3270568847656, 'referece_logps/rejected': -342.6653747558594, 'referece_logps/chosen': -379.713623046875, 'logits/rejected': 0.16539789736270905, 'logits/chosen': 0.25340691208839417, 'epoch': 5.93}

 99%|█████████▉| 15924/16104 [73:23:35<49:26, 16.48s/it]


 99%|█████████▉| 15926/16104 [73:24:05<47:56, 16.16s/it]
{'loss': 0.4142, 'learning_rate': 6.4076872960106e-10, 'rewards/chosen': -0.2559122145175934, 'rewards/rejected': -1.706422209739685, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4505099058151245, 'policy_logps/rejected': -470.2671813964844, 'policy_logps/chosen': -491.799560546875, 'referece_logps/rejected': -453.20294189453125, 'referece_logps/chosen': -489.24041748046875, 'logits/rejected': -0.5200726985931396, 'logits/chosen': -0.5173513293266296, 'epoch': 5.93}

 99%|█████████▉| 15927/16104 [73:24:17<43:46, 14.84s/it]

 99%|█████████▉| 15928/16104 [73:24:36<47:18, 16.13s/it]


 99%|█████████▉| 15930/16104 [73:25:09<46:55, 16.18s/it]
{'loss': 0.5206, 'learning_rate': 6.122966209501923e-10, 'rewards/chosen': -0.37290650606155396, 'rewards/rejected': -1.6224110126495361, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2495044469833374, 'policy_logps/rejected': -328.14239501953125, 'policy_logps/chosen': -635.32861328125, 'referece_logps/rejected': -311.9183349609375, 'referece_logps/chosen': -631.5995483398438, 'logits/rejected': -0.19046953320503235, 'logits/chosen': -0.2136881947517395, 'epoch': 5.94}

 99%|█████████▉| 15931/16104 [73:25:26<47:18, 16.41s/it]

 99%|█████████▉| 15932/16104 [73:25:38<43:34, 15.20s/it]


 99%|█████████▉| 15934/16104 [73:26:15<47:41, 16.83s/it]

 99%|█████████▉| 15935/16104 [73:26:33<48:32, 17.23s/it]
{'loss': 0.4426, 'learning_rate': 5.776160950701214e-10, 'rewards/chosen': -0.19912871718406677, 'rewards/rejected': -1.64499831199646, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4458695650100708, 'policy_logps/rejected': -380.242919921875, 'policy_logps/chosen': -408.9167785644531, 'referece_logps/rejected': -363.7929382324219, 'referece_logps/chosen': -406.925537109375, 'logits/rejected': -0.09153512120246887, 'logits/chosen': -0.2855604887008667, 'epoch': 5.94}

 99%|█████████▉| 15936/16104 [73:26:51<49:14, 17.59s/it]

 99%|█████████▉| 15937/16104 [73:27:12<51:29, 18.50s/it]

 99%|█████████▉| 15938/16104 [73:27:25<46:28, 16.80s/it]

 99%|█████████▉| 15939/16104 [73:27:37<42:30, 15.46s/it]

 99%|█████████▉| 15940/16104 [73:27:49<39:24, 14.42s/it]

 99%|█████████▉| 15941/16104 [73:28:09<43:25, 15.98s/it]

 99%|█████████▉| 15942/16104 [73:28:28<45:51, 16.98s/it]

 99%|█████████▉| 15943/16104 [73:28:46<46:22, 17.28s/it]

 99%|█████████▉| 15944/16104 [73:29:02<44:57, 16.86s/it]

 99%|█████████▉| 15945/16104 [73:29:14<40:38, 15.34s/it]

 99%|█████████▉| 15946/16104 [73:29:26<37:48, 14.36s/it]

 99%|█████████▉| 15947/16104 [73:29:44<40:09, 15.35s/it]

 99%|█████████▉| 15948/16104 [73:29:57<38:17, 14.73s/it]

 99%|█████████▉| 15949/16104 [73:30:08<35:19, 13.68s/it]

 99%|█████████▉| 15950/16104 [73:30:28<40:08, 15.64s/it]

 99%|█████████▉| 15951/16104 [73:30:39<36:20, 14.25s/it]

 99%|█████████▉| 15952/16104 [73:30:51<34:12, 13.50s/it]

 99%|█████████▉| 15953/16104 [73:31:10<37:56, 15.07s/it]

 99%|█████████▉| 15954/16104 [73:31:29<40:59, 16.40s/it]

 99%|█████████▉| 15955/16104 [73:31:49<43:02, 17.33s/it]

 99%|█████████▉| 15956/16104 [73:32:03<40:45, 16.52s/it]

 99%|█████████▉| 15957/16104 [73:32:25<44:09, 18.03s/it]

 99%|█████████▉| 15958/16104 [73:32:42<43:25, 17.85s/it]

 99%|█████████▉| 15959/16104 [73:32:56<39:44, 16.45s/it]

 99%|█████████▉| 15960/16104 [73:33:16<42:03, 17.52s/it]

 99%|█████████▉| 15961/16104 [73:33:35<43:12, 18.13s/it]

 99%|█████████▉| 15962/16104 [73:33:56<44:33, 18.83s/it]

 99%|█████████▉| 15963/16104 [73:34:15<44:32, 18.96s/it]

 99%|█████████▉| 15964/16104 [73:34:35<44:48, 19.21s/it]

 99%|█████████▉| 15965/16104 [73:34:54<44:40, 19.28s/it]

 99%|█████████▉| 15966/16104 [73:35:12<43:44, 19.02s/it]

 99%|█████████▉| 15967/16104 [73:35:24<38:31, 16.87s/it]

 99%|█████████▉| 15968/16104 [73:35:45<40:47, 18.00s/it]

 99%|█████████▉| 15969/16104 [73:36:05<41:48, 18.58s/it]

 99%|█████████▉| 15970/16104 [73:36:25<42:18, 18.95s/it]

 99%|█████████▉| 15971/16104 [73:36:43<41:40, 18.80s/it]

 99%|█████████▉| 15972/16104 [73:37:02<41:08, 18.70s/it]

 99%|█████████▉| 15973/16104 [73:37:17<38:23, 17.59s/it]

 99%|█████████▉| 15974/16104 [73:37:29<34:52, 16.09s/it]

 99%|█████████▉| 15975/16104 [73:37:49<36:53, 17.16s/it]

 99%|█████████▉| 15976/16104 [73:38:02<34:05, 15.98s/it]

 99%|█████████▉| 15977/16104 [73:38:22<36:24, 17.20s/it]

 99%|█████████▉| 15978/16104 [73:38:43<38:11, 18.19s/it]

 99%|█████████▉| 15979/16104 [73:38:55<34:00, 16.32s/it]

 99%|█████████▉| 15980/16104 [73:39:11<33:31, 16.22s/it]

 99%|█████████▉| 15981/16104 [73:39:28<33:49, 16.50s/it]

 99%|█████████▉| 15982/16104 [73:39:48<35:31, 17.48s/it]

 99%|█████████▉| 15983/16104 [73:40:08<37:12, 18.45s/it]

 99%|█████████▉| 15984/16104 [73:40:20<32:58, 16.49s/it]

 99%|█████████▉| 15985/16104 [73:40:31<29:35, 14.92s/it]

 99%|█████████▉| 15986/16104 [73:40:47<29:40, 15.09s/it]


 99%|█████████▉| 15988/16104 [73:41:22<32:12, 16.66s/it]

 99%|█████████▉| 15989/16104 [73:41:37<30:37, 15.98s/it]

 99%|█████████▉| 15990/16104 [73:41:56<32:26, 17.07s/it]

 99%|█████████▉| 15991/16104 [73:42:16<33:40, 17.88s/it]

 99%|█████████▉| 15992/16104 [73:42:28<30:12, 16.18s/it]

 99%|█████████▉| 15993/16104 [73:42:49<32:37, 17.63s/it]

 99%|█████████▉| 15994/16104 [73:43:03<30:03, 16.39s/it]

 99%|█████████▉| 15995/16104 [73:43:23<31:59, 17.61s/it]

 99%|█████████▉| 15996/16104 [73:43:39<30:34, 16.99s/it]

 99%|█████████▉| 15997/16104 [73:43:59<31:54, 17.89s/it]

 99%|█████████▉| 15998/16104 [73:44:19<32:35, 18.44s/it]

 99%|█████████▉| 15999/16104 [73:44:33<30:08, 17.22s/it]

 99%|█████████▉| 16000/16104 [73:44:50<29:34, 17.06s/it]

 99%|█████████▉| 16001/16104 [73:45:21<36:48, 21.44s/it]

 99%|█████████▉| 16002/16104 [73:45:41<35:29, 20.88s/it]

 99%|█████████▉| 16003/16104 [73:45:53<30:36, 18.18s/it]

 99%|█████████▉| 16004/16104 [73:46:06<28:02, 16.83s/it]

 99%|█████████▉| 16005/16104 [73:46:22<27:03, 16.40s/it]

 99%|█████████▉| 16006/16104 [73:46:34<24:43, 15.14s/it]

 99%|█████████▉| 16007/16104 [73:46:45<22:14, 13.76s/it]

 99%|█████████▉| 16008/16104 [73:46:58<21:35, 13.50s/it]

 99%|█████████▉| 16009/16104 [73:47:10<20:43, 13.09s/it]

 99%|█████████▉| 16010/16104 [73:47:24<21:03, 13.44s/it]

 99%|█████████▉| 16011/16104 [73:47:37<20:30, 13.23s/it]

 99%|█████████▉| 16012/16104 [73:47:49<19:40, 12.83s/it]

 99%|█████████▉| 16013/16104 [73:48:10<23:12, 15.30s/it]

 99%|█████████▉| 16014/16104 [73:48:22<21:49, 14.55s/it]

 99%|█████████▉| 16015/16104 [73:48:37<21:29, 14.49s/it]

 99%|█████████▉| 16016/16104 [73:48:50<20:53, 14.24s/it]

 99%|█████████▉| 16017/16104 [73:49:03<19:51, 13.70s/it]

 99%|█████████▉| 16018/16104 [73:49:20<21:07, 14.74s/it]

 99%|█████████▉| 16019/16104 [73:49:40<23:04, 16.29s/it]

 99%|█████████▉| 16020/16104 [73:49:59<24:06, 17.22s/it]

 99%|█████████▉| 16021/16104 [73:50:10<21:05, 15.25s/it]

 99%|█████████▉| 16022/16104 [73:50:25<20:53, 15.29s/it]

 99%|█████████▉| 16023/16104 [73:50:43<21:30, 15.94s/it]

100%|█████████▉| 16024/16104 [73:50:58<20:55, 15.69s/it]

100%|█████████▉| 16025/16104 [73:51:13<20:25, 15.51s/it]

100%|█████████▉| 16026/16104 [73:51:25<18:42, 14.39s/it]

100%|█████████▉| 16027/16104 [73:51:41<19:20, 15.07s/it]

100%|█████████▉| 16028/16104 [73:51:56<18:44, 14.80s/it]

100%|█████████▉| 16029/16104 [73:52:15<20:16, 16.22s/it]

100%|█████████▉| 16030/16104 [73:52:35<21:29, 17.43s/it]

100%|█████████▉| 16031/16104 [73:52:54<21:33, 17.72s/it]

100%|█████████▉| 16032/16104 [73:53:13<21:55, 18.27s/it]

100%|█████████▉| 16033/16104 [73:53:31<21:28, 18.15s/it]

100%|█████████▉| 16034/16104 [73:53:46<20:03, 17.20s/it]

100%|█████████▉| 16035/16104 [73:53:57<17:40, 15.37s/it]

100%|█████████▉| 16036/16104 [73:54:14<18:00, 15.88s/it]

100%|█████████▉| 16037/16104 [73:54:25<16:00, 14.34s/it]

100%|█████████▉| 16038/16104 [73:54:45<17:29, 15.90s/it]

100%|█████████▉| 16039/16104 [73:54:58<16:31, 15.26s/it]

100%|█████████▉| 16040/16104 [73:55:10<15:09, 14.22s/it]

100%|█████████▉| 16041/16104 [73:55:32<17:23, 16.56s/it]

100%|█████████▉| 16042/16104 [73:55:46<16:13, 15.70s/it]

100%|█████████▉| 16043/16104 [73:56:05<17:08, 16.85s/it]

100%|█████████▉| 16044/16104 [73:56:20<16:08, 16.15s/it]

100%|█████████▉| 16045/16104 [73:56:31<14:18, 14.55s/it]

100%|█████████▉| 16046/16104 [73:56:42<13:10, 13.64s/it]

100%|█████████▉| 16047/16104 [73:56:55<12:41, 13.35s/it]
{'loss': 0.4381, 'learning_rate': 6.571320440940109e-11, 'rewards/chosen': -0.4803469777107239, 'rewards/rejected': -2.3572325706481934, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8768856525421143, 'policy_logps/rejected': -267.55078125, 'policy_logps/chosen': -369.72613525390625, 'referece_logps/rejected': -243.97845458984375, 'referece_logps/chosen': -364.9226379394531, 'logits/rejected': 0.11787892878055573, 'logits/chosen': 0.11945068836212158, 'epoch': 5.98}

100%|█████████▉| 16048/16104 [73:57:08<12:19, 13.20s/it]

100%|█████████▉| 16049/16104 [73:57:26<13:21, 14.58s/it]

100%|█████████▉| 16050/16104 [73:57:39<12:53, 14.32s/it]

100%|█████████▉| 16051/16104 [73:57:54<12:37, 14.29s/it]


100%|█████████▉| 16053/16104 [73:58:25<12:56, 15.23s/it]
{'loss': 0.4017, 'learning_rate': 5.260708464971397e-11, 'rewards/chosen': -0.6821184754371643, 'rewards/rejected': -1.5305269956588745, 'rewards/accuracies': 0.5, 'rewards/margins': 0.848408579826355, 'policy_logps/rejected': -467.9729309082031, 'policy_logps/chosen': -441.7877197265625, 'referece_logps/rejected': -452.6676940917969, 'referece_logps/chosen': -434.966552734375, 'logits/rejected': -0.17461825907230377, 'logits/chosen': -0.06928656995296478, 'epoch': 5.98}


100%|█████████▉| 16055/16104 [73:58:54<11:52, 14.55s/it]
{'loss': 0.4651, 'learning_rate': 4.8561974395067154e-11, 'rewards/chosen': -0.5747041702270508, 'rewards/rejected': -1.585968255996704, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0112640857696533, 'policy_logps/rejected': -410.26068115234375, 'policy_logps/chosen': -460.7777099609375, 'referece_logps/rejected': -394.4010009765625, 'referece_logps/chosen': -455.0306396484375, 'logits/rejected': -0.09246604144573212, 'logits/chosen': -0.19758711755275726, 'epoch': 5.98}

100%|█████████▉| 16056/16104 [73:59:14<12:50, 16.06s/it]


100%|█████████▉| 16058/16104 [73:59:53<13:43, 17.89s/it]

100%|█████████▉| 16059/16104 [74:00:14<14:03, 18.75s/it]

100%|█████████▉| 16060/16104 [74:00:33<13:50, 18.87s/it]

100%|█████████▉| 16061/16104 [74:00:51<13:22, 18.65s/it]

100%|█████████▉| 16062/16104 [74:01:03<11:35, 16.56s/it]

100%|█████████▉| 16063/16104 [74:01:23<12:01, 17.60s/it]

100%|█████████▉| 16064/16104 [74:01:40<11:40, 17.51s/it]
{'loss': 0.4589, 'learning_rate': 3.2361253158086356e-11, 'rewards/chosen': -0.935430109500885, 'rewards/rejected': -1.794684648513794, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8592544198036194, 'policy_logps/rejected': -370.72308349609375, 'policy_logps/chosen': -386.7454833984375, 'referece_logps/rejected': -352.7762145996094, 'referece_logps/chosen': -377.39117431640625, 'logits/rejected': 0.3695937395095825, 'logits/chosen': 0.5486549139022827, 'epoch': 5.99}

100%|█████████▉| 16065/16104 [74:02:00<11:47, 18.15s/it]


100%|█████████▉| 16067/16104 [74:02:38<11:19, 18.36s/it]

100%|█████████▉| 16068/16104 [74:02:49<09:47, 16.33s/it]

100%|█████████▉| 16069/16104 [74:03:03<09:00, 15.45s/it]
{'loss': 0.4027, 'learning_rate': 2.4776615769717123e-11, 'rewards/chosen': -0.4154585003852844, 'rewards/rejected': -2.2112278938293457, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7957693338394165, 'policy_logps/rejected': -595.2486572265625, 'policy_logps/chosen': -366.3800048828125, 'referece_logps/rejected': -573.1363525390625, 'referece_logps/chosen': -362.22540283203125, 'logits/rejected': 0.4925768971443176, 'logits/chosen': 0.7174494862556458, 'epoch': 5.99}

100%|█████████▉| 16070/16104 [74:03:20<09:03, 15.98s/it]

100%|█████████▉| 16071/16104 [74:03:42<09:49, 17.86s/it]

100%|█████████▉| 16072/16104 [74:03:56<08:55, 16.74s/it]


100%|█████████▉| 16074/16104 [74:04:37<09:13, 18.44s/it]
{'loss': 0.4212, 'learning_rate': 1.8203247855397287e-11, 'rewards/chosen': -0.7186492681503296, 'rewards/rejected': -1.2641077041625977, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5454583764076233, 'policy_logps/rejected': -281.57879638671875, 'policy_logps/chosen': -362.72705078125, 'referece_logps/rejected': -268.937744140625, 'referece_logps/chosen': -355.5405578613281, 'logits/rejected': 0.02568061649799347, 'logits/chosen': 0.1144046038389206, 'epoch': 5.99}


100%|█████████▉| 16076/16104 [74:05:15<08:49, 18.91s/it]

100%|█████████▉| 16077/16104 [74:05:28<07:36, 16.91s/it]
{'loss': 0.5264, 'learning_rate': 1.4744639262209703e-11, 'rewards/chosen': -0.8232749104499817, 'rewards/rejected': -2.5980544090270996, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7747795581817627, 'policy_logps/rejected': -381.5772705078125, 'policy_logps/chosen': -332.27569580078125, 'referece_logps/rejected': -355.59674072265625, 'referece_logps/chosen': -324.04296875, 'logits/rejected': -0.697637677192688, 'logits/chosen': -0.6919718384742737, 'epoch': 5.99}


100%|█████████▉| 16079/16104 [74:06:03<07:02, 16.90s/it]
{'loss': 0.3699, 'learning_rate': 1.2641156062587199e-11, 'rewards/chosen': -0.4064503014087677, 'rewards/rejected': -1.5081428289413452, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1016925573349, 'policy_logps/rejected': -487.78961181640625, 'policy_logps/chosen': -485.12652587890625, 'referece_logps/rejected': -472.7081298828125, 'referece_logps/chosen': -481.06207275390625, 'logits/rejected': -0.47835302352905273, 'logits/chosen': -0.3149174153804779, 'epoch': 5.99}


100%|█████████▉| 16081/16104 [74:06:39<06:48, 17.77s/it]
{'loss': 0.3629, 'learning_rate': 1.0699477953957093e-11, 'rewards/chosen': -0.4594036340713501, 'rewards/rejected': -2.0137619972229004, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5543582439422607, 'policy_logps/rejected': -282.639404296875, 'policy_logps/chosen': -459.72918701171875, 'referece_logps/rejected': -262.50177001953125, 'referece_logps/chosen': -455.1351318359375, 'logits/rejected': -0.8062668442726135, 'logits/chosen': -0.8442280292510986, 'epoch': 5.99}


100%|█████████▉| 16083/16104 [74:07:18<06:27, 18.45s/it]
{'loss': 0.4133, 'learning_rate': 8.919605250290452e-12, 'rewards/chosen': -0.1316526234149933, 'rewards/rejected': -1.2127649784088135, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0811123847961426, 'policy_logps/rejected': -472.55718994140625, 'policy_logps/chosen': -503.807861328125, 'referece_logps/rejected': -460.4295349121094, 'referece_logps/chosen': -502.4913330078125, 'logits/rejected': 0.15650513768196106, 'logits/chosen': 0.24462293088436127, 'epoch': 5.99}

100%|█████████▉| 16084/16104 [74:07:30<05:35, 16.78s/it]


100%|█████████▉| 16086/16104 [74:08:02<04:54, 16.37s/it]
{'loss': 0.5549, 'learning_rate': 6.553181952195786e-12, 'rewards/chosen': -0.1739932894706726, 'rewards/rejected': -1.2026287317276, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0286355018615723, 'policy_logps/rejected': -417.1827697753906, 'policy_logps/chosen': -440.8034973144531, 'referece_logps/rejected': -405.156494140625, 'referece_logps/chosen': -439.06353759765625, 'logits/rejected': -0.02086508274078369, 'logits/chosen': -0.0002366742119193077, 'epoch': 5.99}


100%|█████████▉| 16088/16104 [74:08:27<03:55, 14.75s/it]

100%|█████████▉| 16089/16104 [74:08:47<04:02, 16.16s/it]
{'loss': 0.4421, 'learning_rate': 4.5508223188717164e-12, 'rewards/chosen': -0.7436521053314209, 'rewards/rejected': -1.6086212396621704, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8649691343307495, 'policy_logps/rejected': -455.5531005859375, 'policy_logps/chosen': -365.2255554199219, 'referece_logps/rejected': -439.46685791015625, 'referece_logps/chosen': -357.7890319824219, 'logits/rejected': -0.16306734085083008, 'logits/chosen': -0.035833731293678284, 'epoch': 5.99}


100%|█████████▉| 16091/16104 [74:09:26<03:52, 17.89s/it]

100%|█████████▉| 16092/16104 [74:09:44<03:33, 17.80s/it]

100%|█████████▉| 16093/16104 [74:09:58<03:04, 16.74s/it]

100%|█████████▉| 16094/16104 [74:10:19<03:00, 18.05s/it]
{'loss': 0.3749, 'learning_rate': 2.0225885495328555e-12, 'rewards/chosen': -0.7573690414428711, 'rewards/rejected': -1.6213358640670776, 'rewards/accuracies': 0.625, 'rewards/margins': 0.863966703414917, 'policy_logps/rejected': -378.0914611816406, 'policy_logps/chosen': -414.8262939453125, 'referece_logps/rejected': -361.87811279296875, 'referece_logps/chosen': -407.2525939941406, 'logits/rejected': -0.7560577988624573, 'logits/chosen': -0.8222408294677734, 'epoch': 6.0}


100%|█████████▉| 16096/16104 [74:10:54<02:23, 17.97s/it]

100%|█████████▉| 16097/16104 [74:11:13<02:07, 18.26s/it]

100%|█████████▉| 16098/16104 [74:11:25<01:38, 16.36s/it]

100%|█████████▉| 16099/16104 [74:11:44<01:25, 17.06s/it]

100%|█████████▉| 16100/16104 [74:12:02<01:09, 17.47s/it]
{'loss': 0.2681, 'learning_rate': 3.236142596119151e-13, 'rewards/chosen': -0.5520170331001282, 'rewards/rejected': -2.9755377769470215, 'rewards/accuracies': 1.0, 'rewards/margins': 2.423520565032959, 'policy_logps/rejected': -479.58203125, 'policy_logps/chosen': -455.9496154785156, 'referece_logps/rejected': -449.82672119140625, 'referece_logps/chosen': -450.4294738769531, 'logits/rejected': -0.26086947321891785, 'logits/chosen': -0.24546915292739868, 'epoch': 6.0}

100%|█████████▉| 16101/16104 [74:12:17<00:49, 16.61s/it]


100%|█████████▉| 16103/16104 [74:12:48<00:16, 16.18s/it]
{'loss': 0.3828, 'learning_rate': 2.0225892294334357e-14, 'rewards/chosen': -0.8330535888671875, 'rewards/rejected': -1.8582985401153564, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0252448320388794, 'policy_logps/rejected': -471.02325439453125, 'policy_logps/chosen': -427.0645446777344, 'referece_logps/rejected': -452.4403381347656, 'referece_logps/chosen': -418.7340087890625, 'logits/rejected': 0.141069233417511, 'logits/chosen': 0.09209909290075302, 'epoch': 6.0}
{'loss': 0.4175, 'learning_rate': 0.0, 'rewards/chosen': -0.8257931470870972, 'rewards/rejected': -1.411539077758789, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5857460498809814, 'policy_logps/rejected': -392.42108154296875, 'policy_logps/chosen': -401.0745849609375, 'referece_logps/rejected': -378.3056640625, 'referece_logps/chosen': -392.8166198730469, 'logits/rejected': -0.291231244802475, 'logits/chosen': -0.2578115165233612, 'epoch': 6.0}

100%|██████████| 16104/16104 [74:13:05<00:00, 16.59s/it]