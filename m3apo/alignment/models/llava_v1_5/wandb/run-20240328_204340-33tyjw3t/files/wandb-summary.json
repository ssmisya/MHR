{"train/loss": 0.4624, "train/learning_rate": 1.99859138873288e-06, "train/rewards/chosen": -0.9203264713287354, "train/rewards/rejected": -1.4006353616714478, "train/rewards/accuracies": 0.875, "train/rewards/margins": 0.4803089201450348, "train/policy_logps/rejected": -519.9261474609375, "train/policy_logps/chosen": -525.1138305664062, "train/referece_logps/rejected": -505.9197998046875, "train/referece_logps/chosen": -515.9105834960938, "train/logits/rejected": 0.061756543815135956, "train/logits/chosen": -0.04635260999202728, "train/epoch": 0.14, "train/global_step": 250, "_timestamp": 1711634464.1814787, "_runtime": 4643.202613830566, "_step": 249}