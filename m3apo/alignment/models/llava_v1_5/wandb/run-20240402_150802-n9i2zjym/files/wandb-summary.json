{"train/loss": 0.5029, "train/learning_rate": 1.975485864168765e-06, "train/rewards/chosen": -0.4497986137866974, "train/rewards/rejected": -1.779081106185913, "train/rewards/accuracies": 0.875, "train/rewards/margins": 1.329282522201538, "train/policy_logps/rejected": -330.40655517578125, "train/policy_logps/chosen": -433.7898254394531, "train/referece_logps/rejected": -312.61572265625, "train/referece_logps/chosen": -429.2918395996094, "train/logits/rejected": -0.5826718807220459, "train/logits/chosen": -0.5736237168312073, "train/epoch": 6.62, "train/global_step": 10392, "_timestamp": 1712056582.9358106, "_runtime": 14900.258605480194, "_step": 1391}