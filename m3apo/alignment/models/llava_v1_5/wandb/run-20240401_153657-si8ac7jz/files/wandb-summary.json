{"train/loss": 0.5513, "train/learning_rate": 1.9058171745152354e-06, "train/rewards/chosen": -0.5679346323013306, "train/rewards/rejected": -0.9549046754837036, "train/rewards/accuracies": 0.625, "train/rewards/margins": 0.38697007298469543, "train/policy_logps/rejected": -315.6301574707031, "train/policy_logps/chosen": -461.13092041015625, "train/referece_logps/rejected": -306.08111572265625, "train/referece_logps/chosen": -455.4515380859375, "train/logits/rejected": 0.3134905695915222, "train/logits/chosen": 0.3880326747894287, "train/epoch": 0.17, "train/global_step": 688, "_timestamp": 1711964392.5012167, "_runtime": 7374.914690732956, "_step": 687}