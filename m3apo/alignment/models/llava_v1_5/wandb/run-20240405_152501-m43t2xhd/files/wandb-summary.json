{"train/loss": 0.5521, "train/learning_rate": 6.86013909187124e-07, "train/rewards/chosen": -1.121827483177185, "train/rewards/rejected": -2.148005962371826, "train/rewards/accuracies": 0.875, "train/rewards/margins": 1.0261785984039307, "train/policy_logps/rejected": -381.5594787597656, "train/policy_logps/chosen": -609.8417358398438, "train/referece_logps/rejected": -360.0794372558594, "train/referece_logps/chosen": -598.62353515625, "train/logits/rejected": -0.6107208132743835, "train/logits/chosen": -0.9071781039237976, "train/epoch": 3.68, "train/global_step": 9882, "_timestamp": 1712466059.0112162, "_runtime": 164157.4079310894, "_step": 9881}