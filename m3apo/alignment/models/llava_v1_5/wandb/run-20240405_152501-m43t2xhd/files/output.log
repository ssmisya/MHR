  0%|          | 0/16104 [00:00<?, ?it/s]/mnt/petrelfs/songmingyang/code/mm/MAPO/m3apo/alignment/trainer/llava_dpo_trainer.py:179: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/16104 [00:15<69:03:29, 15.44s/it]

  0%|          | 2/16104 [00:31<71:14:53, 15.93s/it]

  0%|          | 3/16104 [00:49<75:15:42, 16.83s/it]
{'loss': 0.6958, 'learning_rate': 1.2396694214876033e-08, 'rewards/chosen': -0.0359717421233654, 'rewards/rejected': -0.01955394819378853, 'rewards/accuracies': 0.375, 'rewards/margins': -0.016417790204286575, 'policy_logps/rejected': -305.44354248046875, 'policy_logps/chosen': -370.4798278808594, 'referece_logps/rejected': -305.2480163574219, 'referece_logps/chosen': -370.1201171875, 'logits/rejected': 0.08709938824176788, 'logits/chosen': 0.1270720511674881, 'epoch': 0.0}


  0%|          | 5/16104 [01:23<77:02:15, 17.23s/it]
{'loss': 0.6881, 'learning_rate': 2.0661157024793388e-08, 'rewards/chosen': 0.028920460492372513, 'rewards/rejected': -0.020096588879823685, 'rewards/accuracies': 0.75, 'rewards/margins': 0.0490170493721962, 'policy_logps/rejected': -377.78411865234375, 'policy_logps/chosen': -428.95867919921875, 'referece_logps/rejected': -377.5831604003906, 'referece_logps/chosen': -429.2479248046875, 'logits/rejected': -0.25941723585128784, 'logits/chosen': -0.12334518134593964, 'epoch': 0.0}

  0%|          | 6/16104 [01:34<67:38:59, 15.13s/it]

  0%|          | 7/16104 [01:54<74:06:03, 16.57s/it]
[2024-04-05 15:27:21,910] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  0%|          | 9/16104 [02:29<75:14:06, 16.83s/it]
[2024-04-05 15:27:36,414] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6939, 'learning_rate': 3.7190082644628095e-08, 'rewards/chosen': -0.006106185726821423, 'rewards/rejected': -0.011057281866669655, 'rewards/accuracies': 0.5, 'rewards/margins': 0.00495109660550952, 'policy_logps/rejected': -345.0160217285156, 'policy_logps/chosen': -476.650634765625, 'referece_logps/rejected': -344.9054260253906, 'referece_logps/chosen': -476.5894775390625, 'logits/rejected': -0.28475597500801086, 'logits/chosen': -0.36107152700424194, 'epoch': 0.0}

  0%|          | 10/16104 [02:41<67:33:27, 15.11s/it]

  0%|          | 11/16104 [02:51<61:27:15, 13.75s/it]


  0%|          | 13/16104 [03:25<70:49:07, 15.84s/it]
{'loss': 0.6908, 'learning_rate': 5.3719008264462806e-08, 'rewards/chosen': -0.00035133352503180504, 'rewards/rejected': -0.02412738837301731, 'rewards/accuracies': 0.625, 'rewards/margins': 0.02377605438232422, 'policy_logps/rejected': -299.389404296875, 'policy_logps/chosen': -289.5956726074219, 'referece_logps/rejected': -299.14813232421875, 'referece_logps/chosen': -289.5921630859375, 'logits/rejected': -1.0111627578735352, 'logits/chosen': -1.0515532493591309, 'epoch': 0.0}

  0%|          | 14/16104 [03:39<67:46:45, 15.17s/it]
[2024-04-05 15:29:06,064] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  0%|          | 15/16104 [03:59<74:15:18, 16.61s/it]

  0%|          | 16/16104 [04:16<74:38:42, 16.70s/it]

  0%|          | 17/16104 [04:26<66:32:11, 14.89s/it]


  0%|          | 19/16104 [04:48<56:49:30, 12.72s/it]
{'loss': 0.6944, 'learning_rate': 7.851239669421488e-08, 'rewards/chosen': -0.012936212122440338, 'rewards/rejected': 0.008081436157226562, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0210176482796669, 'policy_logps/rejected': -305.750732421875, 'policy_logps/chosen': -351.52252197265625, 'referece_logps/rejected': -305.8315734863281, 'referece_logps/chosen': -351.3931579589844, 'logits/rejected': -0.23623114824295044, 'logits/chosen': -0.1983896791934967, 'epoch': 0.01}

  0%|          | 20/16104 [04:58<54:08:58, 12.12s/it]

  0%|          | 21/16104 [05:10<53:44:05, 12.03s/it]

  0%|          | 22/16104 [05:27<60:12:35, 13.48s/it]

  0%|          | 23/16104 [05:45<65:32:50, 14.67s/it]

  0%|          | 24/16104 [06:02<69:18:32, 15.52s/it]

  0%|          | 25/16104 [06:13<62:44:28, 14.05s/it]


  0%|          | 27/16104 [06:44<67:54:22, 15.21s/it]
{'loss': 0.6882, 'learning_rate': 1.115702479338843e-07, 'rewards/chosen': 0.03427696228027344, 'rewards/rejected': 0.015497017651796341, 'rewards/accuracies': 0.625, 'rewards/margins': 0.018779942765831947, 'policy_logps/rejected': -341.12493896484375, 'policy_logps/chosen': -395.6417236328125, 'referece_logps/rejected': -341.2799072265625, 'referece_logps/chosen': -395.9845275878906, 'logits/rejected': -0.42990314960479736, 'logits/chosen': -0.17781445384025574, 'epoch': 0.01}


  0%|          | 29/16104 [07:16<71:57:46, 16.12s/it]

  0%|          | 30/16104 [07:32<71:38:23, 16.04s/it]
{'loss': 0.693, 'learning_rate': 1.2396694214876034e-07, 'rewards/chosen': 0.021040059626102448, 'rewards/rejected': -0.016197562217712402, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03723762184381485, 'policy_logps/rejected': -474.6109313964844, 'policy_logps/chosen': -422.22528076171875, 'referece_logps/rejected': -474.448974609375, 'referece_logps/chosen': -422.4356994628906, 'logits/rejected': -0.3698129653930664, 'logits/chosen': -0.5836852788925171, 'epoch': 0.01}

  0%|          | 31/16104 [07:53<78:15:51, 17.53s/it]

  0%|          | 32/16104 [08:09<77:15:32, 17.31s/it]

  0%|          | 33/16104 [08:32<84:38:34, 18.96s/it]

  0%|          | 34/16104 [08:51<84:37:44, 18.96s/it]

  0%|          | 35/16104 [09:13<88:16:31, 19.78s/it]

  0%|          | 36/16104 [09:25<77:32:38, 17.37s/it]

  0%|          | 37/16104 [09:35<68:29:09, 15.35s/it]

  0%|          | 38/16104 [09:48<65:34:55, 14.70s/it]

  0%|          | 39/16104 [10:02<64:39:40, 14.49s/it]

  0%|          | 40/16104 [10:13<59:30:24, 13.34s/it]

  0%|          | 41/16104 [10:33<68:57:54, 15.46s/it]

  0%|          | 42/16104 [10:54<76:19:25, 17.11s/it]

  0%|          | 43/16104 [11:15<80:52:28, 18.13s/it]

  0%|          | 44/16104 [11:28<74:38:08, 16.73s/it]

  0%|          | 45/16104 [11:38<65:36:09, 14.71s/it]
[2024-04-05 15:37:06,108] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  0%|          | 46/16104 [11:59<73:23:23, 16.45s/it]


  0%|          | 48/16104 [12:24<64:47:12, 14.53s/it]

  0%|          | 49/16104 [12:42<69:27:03, 15.57s/it]

  0%|          | 50/16104 [12:54<64:48:02, 14.53s/it]
{'loss': 0.692, 'learning_rate': 2.0661157024793388e-07, 'rewards/chosen': 0.026340104639530182, 'rewards/rejected': -0.010614491067826748, 'rewards/accuracies': 0.75, 'rewards/margins': 0.036954596638679504, 'policy_logps/rejected': -308.4473571777344, 'policy_logps/chosen': -283.3766784667969, 'referece_logps/rejected': -308.3412170410156, 'referece_logps/chosen': -283.64007568359375, 'logits/rejected': -0.3902415633201599, 'logits/chosen': -0.4130948781967163, 'epoch': 0.02}

  0%|          | 51/16104 [13:05<60:08:54, 13.49s/it]


  0%|          | 53/16104 [13:30<58:18:38, 13.08s/it]

  0%|          | 54/16104 [13:52<70:18:29, 15.77s/it]
{'loss': 0.6924, 'learning_rate': 2.231404958677686e-07, 'rewards/chosen': -0.02467632293701172, 'rewards/rejected': -0.0026353367138653994, 'rewards/accuracies': 0.375, 'rewards/margins': -0.022040989249944687, 'policy_logps/rejected': -381.1957092285156, 'policy_logps/chosen': -459.1741027832031, 'referece_logps/rejected': -381.16937255859375, 'referece_logps/chosen': -458.9273376464844, 'logits/rejected': 0.6033498644828796, 'logits/chosen': 0.6248478293418884, 'epoch': 0.02}


  0%|          | 56/16104 [14:32<80:43:02, 18.11s/it]

  0%|          | 57/16104 [14:48<78:01:57, 17.51s/it]
{'loss': 0.691, 'learning_rate': 2.355371900826446e-07, 'rewards/chosen': -0.0039028157480061054, 'rewards/rejected': 0.0005029686726629734, 'rewards/accuracies': 0.375, 'rewards/margins': -0.0044057853519916534, 'policy_logps/rejected': -308.263671875, 'policy_logps/chosen': -303.5348205566406, 'referece_logps/rejected': -308.26873779296875, 'referece_logps/chosen': -303.49578857421875, 'logits/rejected': -1.1538138389587402, 'logits/chosen': -1.0826810598373413, 'epoch': 0.02}

  0%|          | 58/16104 [15:07<79:49:32, 17.91s/it]

  0%|          | 59/16104 [15:28<83:08:13, 18.65s/it]

  0%|          | 60/16104 [15:48<84:44:16, 19.01s/it]

  0%|          | 61/16104 [16:03<80:34:15, 18.08s/it]

  0%|          | 62/16104 [16:15<71:37:20, 16.07s/it]

  0%|          | 63/16104 [16:31<71:19:25, 16.01s/it]

  0%|          | 64/16104 [16:42<64:25:41, 14.46s/it]

  0%|          | 65/16104 [17:02<72:19:18, 16.23s/it]


  0%|          | 67/16104 [17:34<70:11:43, 15.76s/it]

  0%|          | 68/16104 [17:50<70:33:24, 15.84s/it]
{'loss': 0.6846, 'learning_rate': 2.8099173553719007e-07, 'rewards/chosen': 0.015327260829508305, 'rewards/rejected': -0.025779344141483307, 'rewards/accuracies': 0.625, 'rewards/margins': 0.041106611490249634, 'policy_logps/rejected': -329.64532470703125, 'policy_logps/chosen': -454.1938171386719, 'referece_logps/rejected': -329.3875427246094, 'referece_logps/chosen': -454.3470764160156, 'logits/rejected': -0.7312670946121216, 'logits/chosen': -0.7836592197418213, 'epoch': 0.03}

  0%|          | 69/16104 [18:10<75:16:43, 16.90s/it]
[2024-04-05 15:43:40,151] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  0%|          | 71/16104 [18:54<87:19:49, 19.61s/it]

  0%|          | 72/16104 [19:16<90:34:24, 20.34s/it]
{'loss': 0.6966, 'learning_rate': 2.9752066115702476e-07, 'rewards/chosen': 0.023758508265018463, 'rewards/rejected': -0.006698799319565296, 'rewards/accuracies': 0.875, 'rewards/margins': 0.030457310378551483, 'policy_logps/rejected': -393.1761779785156, 'policy_logps/chosen': -334.8282775878906, 'referece_logps/rejected': -393.1091613769531, 'referece_logps/chosen': -335.0658874511719, 'logits/rejected': -0.3722767233848572, 'logits/chosen': -0.4110756516456604, 'epoch': 0.03}

  0%|          | 73/16104 [19:31<82:40:28, 18.57s/it]

  0%|          | 74/16104 [19:48<80:39:33, 18.11s/it]

  0%|          | 75/16104 [20:08<83:27:57, 18.75s/it]

  0%|          | 76/16104 [20:30<87:23:28, 19.63s/it]

  0%|          | 77/16104 [20:44<80:27:56, 18.07s/it]

  0%|          | 78/16104 [20:59<76:15:09, 17.13s/it]


  0%|          | 80/16104 [21:29<70:25:12, 15.82s/it]
{'loss': 0.6996, 'learning_rate': 3.305785123966942e-07, 'rewards/chosen': 0.030475424602627754, 'rewards/rejected': 0.021302413195371628, 'rewards/accuracies': 0.625, 'rewards/margins': 0.009173012338578701, 'policy_logps/rejected': -421.993408203125, 'policy_logps/chosen': -404.8429260253906, 'referece_logps/rejected': -422.20648193359375, 'referece_logps/chosen': -405.14764404296875, 'logits/rejected': 0.18265336751937866, 'logits/chosen': 0.1697925329208374, 'epoch': 0.03}

  1%|          | 81/16104 [21:50<77:09:57, 17.34s/it]

  1%|          | 82/16104 [22:04<73:38:48, 16.55s/it]
[2024-04-05 15:47:32,914] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 83/16104 [22:26<80:05:05, 18.00s/it]
[2024-04-05 15:47:53,112] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 84/16104 [22:46<83:01:10, 18.66s/it]
[2024-04-05 15:48:14,277] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 85/16104 [23:07<86:21:46, 19.41s/it]

  1%|          | 86/16104 [23:21<79:01:57, 17.76s/it]

  1%|          | 87/16104 [23:32<69:58:49, 15.73s/it]

  1%|          | 88/16104 [23:54<79:00:20, 17.76s/it]

  1%|          | 89/16104 [24:14<80:41:54, 18.14s/it]

  1%|          | 90/16104 [24:27<75:01:01, 16.86s/it]

  1%|          | 91/16104 [24:48<80:09:26, 18.02s/it]

  1%|          | 92/16104 [25:10<84:40:49, 19.04s/it]


  1%|          | 94/16104 [25:35<70:22:23, 15.82s/it]

  1%|          | 95/16104 [25:47<65:34:03, 14.74s/it]
{'loss': 0.7049, 'learning_rate': 3.9256198347107437e-07, 'rewards/chosen': 0.04874115064740181, 'rewards/rejected': 0.027347180992364883, 'rewards/accuracies': 0.5, 'rewards/margins': 0.021393969655036926, 'policy_logps/rejected': -405.87908935546875, 'policy_logps/chosen': -458.380859375, 'referece_logps/rejected': -406.1525573730469, 'referece_logps/chosen': -458.8682556152344, 'logits/rejected': 0.062260568141937256, 'logits/chosen': 0.2189856916666031, 'epoch': 0.04}

  1%|          | 96/16104 [26:07<73:12:40, 16.46s/it]

  1%|          | 97/16104 [26:25<74:18:51, 16.71s/it]


  1%|          | 99/16104 [27:07<85:14:37, 19.17s/it]
{'loss': 0.6924, 'learning_rate': 4.090909090909091e-07, 'rewards/chosen': -0.0163134578615427, 'rewards/rejected': 0.01750049740076065, 'rewards/accuracies': 0.25, 'rewards/margins': -0.0338139533996582, 'policy_logps/rejected': -488.3917541503906, 'policy_logps/chosen': -353.25860595703125, 'referece_logps/rejected': -488.5667419433594, 'referece_logps/chosen': -353.095458984375, 'logits/rejected': -0.6097795367240906, 'logits/chosen': -0.477020263671875, 'epoch': 0.04}

  1%|          | 100/16104 [27:24<81:52:22, 18.42s/it]

  1%|          | 101/16104 [27:42<81:17:48, 18.29s/it]

  1%|          | 102/16104 [27:58<78:01:38, 17.55s/it]


  1%|          | 104/16104 [28:39<85:22:32, 19.21s/it]
{'loss': 0.6958, 'learning_rate': 4.2975206611570245e-07, 'rewards/chosen': -0.02706599235534668, 'rewards/rejected': -0.021500110626220703, 'rewards/accuracies': 0.625, 'rewards/margins': -0.0055658817291259766, 'policy_logps/rejected': -259.4141540527344, 'policy_logps/chosen': -417.0744323730469, 'referece_logps/rejected': -259.1991882324219, 'referece_logps/chosen': -416.8038024902344, 'logits/rejected': -0.0037226229906082153, 'logits/chosen': -0.07128286361694336, 'epoch': 0.04}


  1%|          | 106/16104 [29:13<82:09:58, 18.49s/it]
{'loss': 0.7004, 'learning_rate': 4.380165289256198e-07, 'rewards/chosen': -0.03330068662762642, 'rewards/rejected': 0.03986778110265732, 'rewards/accuracies': 0.375, 'rewards/margins': -0.07316847145557404, 'policy_logps/rejected': -381.63861083984375, 'policy_logps/chosen': -341.6046447753906, 'referece_logps/rejected': -382.0372619628906, 'referece_logps/chosen': -341.2716369628906, 'logits/rejected': -1.3333436250686646, 'logits/chosen': -1.3039402961730957, 'epoch': 0.04}

  1%|          | 107/16104 [29:26<73:50:23, 16.62s/it]

  1%|          | 108/16104 [29:40<70:15:17, 15.81s/it]

  1%|          | 109/16104 [29:58<73:43:34, 16.59s/it]

  1%|          | 110/16104 [30:14<73:05:30, 16.45s/it]

  1%|          | 111/16104 [30:32<75:36:08, 17.02s/it]

  1%|          | 112/16104 [30:51<77:29:15, 17.44s/it]

  1%|          | 113/16104 [31:06<75:05:02, 16.90s/it]

  1%|          | 114/16104 [31:25<76:53:50, 17.31s/it]

  1%|          | 115/16104 [31:46<82:10:43, 18.50s/it]

  1%|          | 116/16104 [32:07<85:27:00, 19.24s/it]

  1%|          | 117/16104 [32:24<82:57:20, 18.68s/it]

  1%|          | 118/16104 [32:38<76:36:52, 17.25s/it]

  1%|          | 119/16104 [32:55<75:56:02, 17.10s/it]

  1%|          | 120/16104 [33:19<84:46:36, 19.09s/it]

  1%|          | 121/16104 [33:40<86:58:55, 19.59s/it]

  1%|          | 122/16104 [33:55<81:47:51, 18.43s/it]

  1%|          | 123/16104 [34:09<76:13:25, 17.17s/it]

  1%|          | 124/16104 [34:32<83:36:39, 18.84s/it]

  1%|          | 125/16104 [34:49<81:29:57, 18.36s/it]

  1%|          | 126/16104 [35:10<83:58:24, 18.92s/it]

  1%|          | 127/16104 [35:25<78:29:01, 17.68s/it]

  1%|          | 128/16104 [35:43<80:06:47, 18.05s/it]

  1%|          | 129/16104 [36:00<78:16:25, 17.64s/it]

  1%|          | 130/16104 [36:16<76:09:17, 17.16s/it]


  1%|          | 132/16104 [36:48<72:17:12, 16.29s/it]
{'loss': 0.6844, 'learning_rate': 5.454545454545454e-07, 'rewards/chosen': 0.0009517672006040812, 'rewards/rejected': -0.0002696034498512745, 'rewards/accuracies': 0.375, 'rewards/margins': 0.0012213720474392176, 'policy_logps/rejected': -613.1531982421875, 'policy_logps/chosen': -580.195068359375, 'referece_logps/rejected': -613.1505737304688, 'referece_logps/chosen': -580.20458984375, 'logits/rejected': -1.2967822551727295, 'logits/chosen': -1.3458536863327026, 'epoch': 0.05}

  1%|          | 133/16104 [37:10<79:09:10, 17.84s/it]

  1%|          | 134/16104 [37:24<75:14:28, 16.96s/it]

  1%|          | 135/16104 [37:44<78:26:17, 17.68s/it]

  1%|          | 136/16104 [38:03<80:34:07, 18.16s/it]

  1%|          | 137/16104 [38:15<72:40:54, 16.39s/it]


  1%|          | 139/16104 [38:44<69:28:08, 15.66s/it]

  1%|          | 140/16104 [39:06<77:47:47, 17.54s/it]
{'loss': 0.6924, 'learning_rate': 5.785123966942148e-07, 'rewards/chosen': -0.0032476424239575863, 'rewards/rejected': -0.014040757901966572, 'rewards/accuracies': 0.5, 'rewards/margins': 0.010793114081025124, 'policy_logps/rejected': -377.8671569824219, 'policy_logps/chosen': -256.73577880859375, 'referece_logps/rejected': -377.726806640625, 'referece_logps/chosen': -256.70330810546875, 'logits/rejected': -0.15556633472442627, 'logits/chosen': -0.2598440647125244, 'epoch': 0.05}


  1%|          | 142/16104 [39:34<68:22:14, 15.42s/it]
{'loss': 0.6948, 'learning_rate': 5.867768595041323e-07, 'rewards/chosen': -0.013618279248476028, 'rewards/rejected': -0.018488788977265358, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0048705097287893295, 'policy_logps/rejected': -239.64483642578125, 'policy_logps/chosen': -370.8934020996094, 'referece_logps/rejected': -239.45994567871094, 'referece_logps/chosen': -370.7571716308594, 'logits/rejected': -0.8454141616821289, 'logits/chosen': -0.8323863744735718, 'epoch': 0.05}

  1%|          | 143/16104 [39:51<69:59:51, 15.79s/it]

  1%|          | 144/16104 [40:09<72:46:32, 16.42s/it]

  1%|          | 145/16104 [40:30<79:22:31, 17.91s/it]

  1%|          | 146/16104 [40:51<83:20:17, 18.80s/it]


  1%|          | 148/16104 [41:24<77:44:59, 17.54s/it]
{'loss': 0.6923, 'learning_rate': 6.115702479338843e-07, 'rewards/chosen': -0.03277282416820526, 'rewards/rejected': -2.86102294921875e-06, 'rewards/accuracies': 0.25, 'rewards/margins': -0.03276996687054634, 'policy_logps/rejected': -343.021728515625, 'policy_logps/chosen': -341.5591125488281, 'referece_logps/rejected': -343.02166748046875, 'referece_logps/chosen': -341.2313537597656, 'logits/rejected': -1.178233027458191, 'logits/chosen': -1.080641746520996, 'epoch': 0.06}


  1%|          | 150/16104 [42:03<82:19:45, 18.58s/it]
{'loss': 0.6888, 'learning_rate': 6.198347107438017e-07, 'rewards/chosen': 0.029594803228974342, 'rewards/rejected': 0.03700399398803711, 'rewards/accuracies': 0.5, 'rewards/margins': -0.007409190759062767, 'policy_logps/rejected': -431.36199951171875, 'policy_logps/chosen': -343.36712646484375, 'referece_logps/rejected': -431.7320556640625, 'referece_logps/chosen': -343.6630554199219, 'logits/rejected': -1.1210505962371826, 'logits/chosen': -1.0106770992279053, 'epoch': 0.06}

  1%|          | 151/16104 [42:26<89:02:12, 20.09s/it]


  1%|          | 153/16104 [43:01<84:09:34, 18.99s/it]

  1%|          | 154/16104 [43:16<79:52:06, 18.03s/it]
{'loss': 0.6949, 'learning_rate': 6.363636363636363e-07, 'rewards/chosen': -0.05384654924273491, 'rewards/rejected': -0.05852051451802254, 'rewards/accuracies': 0.375, 'rewards/margins': 0.00467396154999733, 'policy_logps/rejected': -663.3273315429688, 'policy_logps/chosen': -475.74737548828125, 'referece_logps/rejected': -662.7421264648438, 'referece_logps/chosen': -475.2089538574219, 'logits/rejected': -0.3319789469242096, 'logits/chosen': -0.15206614136695862, 'epoch': 0.06}

  1%|          | 155/16104 [43:30<74:24:51, 16.80s/it]

  1%|          | 156/16104 [43:42<67:50:07, 15.31s/it]

  1%|          | 157/16104 [43:57<67:49:04, 15.31s/it]

  1%|          | 158/16104 [44:14<69:56:52, 15.79s/it]

  1%|          | 159/16104 [44:30<69:42:17, 15.74s/it]

  1%|          | 160/16104 [44:42<64:31:20, 14.57s/it]

  1%|          | 161/16104 [44:56<64:12:47, 14.50s/it]

  1%|          | 162/16104 [45:19<74:44:45, 16.88s/it]

  1%|          | 163/16104 [45:41<82:34:45, 18.65s/it]

  1%|          | 164/16104 [45:58<80:29:20, 18.18s/it]

  1%|          | 165/16104 [46:11<72:51:12, 16.45s/it]

  1%|          | 166/16104 [46:22<65:22:03, 14.76s/it]

  1%|          | 167/16104 [46:32<60:08:06, 13.58s/it]

  1%|          | 168/16104 [46:43<56:27:20, 12.75s/it]

  1%|          | 169/16104 [46:56<56:43:16, 12.81s/it]

  1%|          | 170/16104 [47:12<60:41:30, 13.71s/it]

  1%|          | 171/16104 [47:23<57:31:54, 13.00s/it]

  1%|          | 172/16104 [47:41<63:37:38, 14.38s/it]
[2024-04-05 16:13:08,983] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|          | 173/16104 [48:02<72:09:44, 16.31s/it]

  1%|          | 174/16104 [48:20<75:15:37, 17.01s/it]

  1%|          | 175/16104 [48:35<72:17:28, 16.34s/it]

  1%|          | 176/16104 [48:55<77:10:39, 17.44s/it]

  1%|          | 177/16104 [49:12<76:14:54, 17.23s/it]

  1%|          | 178/16104 [49:30<76:43:13, 17.34s/it]

  1%|          | 179/16104 [49:49<79:47:38, 18.04s/it]

  1%|          | 180/16104 [50:06<77:34:11, 17.54s/it]

  1%|          | 181/16104 [50:22<76:01:56, 17.19s/it]

  1%|          | 182/16104 [50:33<67:42:19, 15.31s/it]

  1%|          | 183/16104 [50:44<61:42:39, 13.95s/it]

  1%|          | 184/16104 [50:54<57:27:49, 12.99s/it]

  1%|          | 185/16104 [51:14<65:45:06, 14.87s/it]


  1%|          | 187/16104 [51:53<75:56:53, 17.18s/it]
{'loss': 0.6922, 'learning_rate': 7.727272727272727e-07, 'rewards/chosen': -0.017035866156220436, 'rewards/rejected': -0.058870602399110794, 'rewards/accuracies': 0.75, 'rewards/margins': 0.04183473438024521, 'policy_logps/rejected': -298.550048828125, 'policy_logps/chosen': -279.28228759765625, 'referece_logps/rejected': -297.9613342285156, 'referece_logps/chosen': -279.1119384765625, 'logits/rejected': -0.8048130869865417, 'logits/chosen': -0.8216656446456909, 'epoch': 0.07}

  1%|          | 188/16104 [52:14<81:07:57, 18.35s/it]

  1%|          | 189/16104 [52:32<80:03:05, 18.11s/it]

  1%|          | 190/16104 [52:48<77:43:41, 17.58s/it]

  1%|          | 191/16104 [53:08<81:06:00, 18.35s/it]

  1%|          | 192/16104 [53:25<78:32:56, 17.77s/it]

  1%|          | 193/16104 [53:39<74:30:31, 16.86s/it]


  1%|          | 195/16104 [54:09<70:36:05, 15.98s/it]
{'loss': 0.6903, 'learning_rate': 8.057851239669421e-07, 'rewards/chosen': -0.004765320103615522, 'rewards/rejected': -0.003592110238969326, 'rewards/accuracies': 0.375, 'rewards/margins': -0.0011732105631381273, 'policy_logps/rejected': -458.64788818359375, 'policy_logps/chosen': -258.5902099609375, 'referece_logps/rejected': -458.61199951171875, 'referece_logps/chosen': -258.54254150390625, 'logits/rejected': -1.1899852752685547, 'logits/chosen': -0.9560519456863403, 'epoch': 0.07}


  1%|          | 197/16104 [54:42<70:59:45, 16.07s/it]

  1%|          | 198/16104 [54:56<68:40:14, 15.54s/it]

  1%|          | 199/16104 [55:16<75:10:03, 17.01s/it]

  1%|          | 200/16104 [55:30<70:18:05, 15.91s/it]

  1%|          | 201/16104 [55:41<63:36:51, 14.40s/it]

  1%|▏         | 202/16104 [56:01<72:05:52, 16.32s/it]

  1%|▏         | 203/16104 [56:13<66:20:52, 15.02s/it]

  1%|▏         | 204/16104 [56:30<69:02:56, 15.63s/it]

  1%|▏         | 205/16104 [56:42<63:18:46, 14.34s/it]
{'loss': 0.6803, 'learning_rate': 8.471074380165289e-07, 'rewards/chosen': 0.023965073749423027, 'rewards/rejected': -0.06248626857995987, 'rewards/accuracies': 0.875, 'rewards/margins': 0.08645133674144745, 'policy_logps/rejected': -369.35809326171875, 'policy_logps/chosen': -452.04290771484375, 'referece_logps/rejected': -368.73321533203125, 'referece_logps/chosen': -452.2825927734375, 'logits/rejected': -0.6498656272888184, 'logits/chosen': -0.7613978385925293, 'epoch': 0.08}


  1%|▏         | 207/16104 [57:07<58:51:54, 13.33s/it]

  1%|▏         | 208/16104 [57:19<58:01:49, 13.14s/it]

  1%|▏         | 209/16104 [57:40<68:09:06, 15.44s/it]

  1%|▏         | 210/16104 [57:54<65:40:38, 14.88s/it]

  1%|▏         | 211/16104 [58:09<65:43:18, 14.89s/it]
{'loss': 0.6832, 'learning_rate': 8.719008264462809e-07, 'rewards/chosen': -0.05534668266773224, 'rewards/rejected': -0.08945922553539276, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03411254286766052, 'policy_logps/rejected': -490.5029602050781, 'policy_logps/chosen': -394.38214111328125, 'referece_logps/rejected': -489.60833740234375, 'referece_logps/chosen': -393.82867431640625, 'logits/rejected': -0.8313874006271362, 'logits/chosen': -0.7613010406494141, 'epoch': 0.08}
[2024-04-05 16:23:36,436] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  1%|▏         | 213/16104 [58:50<79:18:08, 17.97s/it]

  1%|▏         | 214/16104 [59:03<72:06:13, 16.34s/it]

  1%|▏         | 215/16104 [59:16<67:24:38, 15.27s/it]

  1%|▏         | 216/16104 [59:34<71:50:41, 16.28s/it]

  1%|▏         | 217/16104 [59:46<65:34:00, 14.86s/it]
[2024-04-05 16:24:53,151] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6816, 'learning_rate': 8.96694214876033e-07, 'rewards/chosen': 0.0013871171977370977, 'rewards/rejected': -0.04266014322638512, 'rewards/accuracies': 0.5, 'rewards/margins': 0.04404726251959801, 'policy_logps/rejected': -236.18077087402344, 'policy_logps/chosen': -404.2315979003906, 'referece_logps/rejected': -235.75418090820312, 'referece_logps/chosen': -404.2454528808594, 'logits/rejected': -0.5499172806739807, 'logits/chosen': -0.594664990901947, 'epoch': 0.08}


  1%|▏         | 219/16104 [1:00:15<65:00:31, 14.73s/it]

  1%|▏         | 220/16104 [1:00:30<66:00:18, 14.96s/it]

  1%|▏         | 221/16104 [1:00:51<73:09:39, 16.58s/it]

  1%|▏         | 222/16104 [1:01:11<78:33:04, 17.81s/it]

  1%|▏         | 223/16104 [1:01:31<81:04:03, 18.38s/it]
[2024-04-05 16:26:38,234] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 224/16104 [1:01:52<84:57:45, 19.26s/it]

  1%|▏         | 225/16104 [1:02:06<77:04:33, 17.47s/it]

  1%|▏         | 226/16104 [1:02:27<82:35:22, 18.73s/it]
[2024-04-05 16:27:34,508] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 227/16104 [1:02:49<87:02:31, 19.74s/it]
[2024-04-05 16:27:56,602] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 228/16104 [1:03:03<78:48:24, 17.87s/it]
[2024-04-05 16:28:10,118] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 229/16104 [1:03:19<75:57:43, 17.23s/it]

  1%|▏         | 230/16104 [1:03:34<74:07:25, 16.81s/it]

  1%|▏         | 231/16104 [1:03:49<71:41:37, 16.26s/it]
[2024-04-05 16:28:56,658] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  1%|▏         | 232/16104 [1:04:12<80:34:22, 18.28s/it]

  1%|▏         | 233/16104 [1:04:23<70:31:31, 16.00s/it]

  1%|▏         | 234/16104 [1:04:37<67:13:01, 15.25s/it]

  1%|▏         | 235/16104 [1:04:51<66:31:13, 15.09s/it]

  1%|▏         | 236/16104 [1:05:02<60:50:10, 13.80s/it]
{'loss': 0.6905, 'learning_rate': 9.75206611570248e-07, 'rewards/chosen': 0.014683913439512253, 'rewards/rejected': -0.00729065015912056, 'rewards/accuracies': 0.375, 'rewards/margins': 0.021974561735987663, 'policy_logps/rejected': -385.4976501464844, 'policy_logps/chosen': -431.7338562011719, 'referece_logps/rejected': -385.4248046875, 'referece_logps/chosen': -431.8807373046875, 'logits/rejected': -0.9502257108688354, 'logits/chosen': -0.8833998441696167, 'epoch': 0.09}


  1%|▏         | 238/16104 [1:05:34<63:42:10, 14.45s/it]

  1%|▏         | 239/16104 [1:05:49<64:24:53, 14.62s/it]

  1%|▏         | 240/16104 [1:06:09<72:24:56, 16.43s/it]

  1%|▏         | 241/16104 [1:06:23<69:14:02, 15.71s/it]
{'loss': 0.6657, 'learning_rate': 9.958677685950413e-07, 'rewards/chosen': 0.03400077670812607, 'rewards/rejected': -0.03736744076013565, 'rewards/accuracies': 0.875, 'rewards/margins': 0.07136821746826172, 'policy_logps/rejected': -404.1317443847656, 'policy_logps/chosen': -272.8080139160156, 'referece_logps/rejected': -403.758056640625, 'referece_logps/chosen': -273.1480407714844, 'logits/rejected': -0.808629035949707, 'logits/chosen': -0.7900627851486206, 'epoch': 0.09}
[2024-04-05 16:31:46,966] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  2%|▏         | 243/16104 [1:06:59<74:22:52, 16.88s/it]

  2%|▏         | 244/16104 [1:07:19<79:15:45, 17.99s/it]

  2%|▏         | 245/16104 [1:07:36<77:57:59, 17.70s/it]

  2%|▏         | 246/16104 [1:07:50<72:09:53, 16.38s/it]

  2%|▏         | 247/16104 [1:08:09<76:01:29, 17.26s/it]
[2024-04-05 16:33:16,289] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 248/16104 [1:08:27<77:09:37, 17.52s/it]

  2%|▏         | 249/16104 [1:08:49<82:30:47, 18.74s/it]

  2%|▏         | 250/16104 [1:09:11<86:40:07, 19.68s/it]

  2%|▏         | 251/16104 [1:09:27<82:14:02, 18.67s/it]
{'loss': 0.6856, 'learning_rate': 1.037190082644628e-06, 'rewards/chosen': 0.000871085561811924, 'rewards/rejected': -0.04983654245734215, 'rewards/accuracies': 0.75, 'rewards/margins': 0.0507076270878315, 'policy_logps/rejected': -247.06246948242188, 'policy_logps/chosen': -248.69676208496094, 'referece_logps/rejected': -246.56410217285156, 'referece_logps/chosen': -248.70547485351562, 'logits/rejected': -1.1354819536209106, 'logits/chosen': -1.0745608806610107, 'epoch': 0.09}


  2%|▏         | 253/16104 [1:09:59<78:23:46, 17.80s/it]
[2024-04-05 16:35:06,374] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 254/16104 [1:10:22<84:45:06, 19.25s/it]

  2%|▏         | 255/16104 [1:10:35<77:18:54, 17.56s/it]
[2024-04-05 16:35:42,618] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6889, 'learning_rate': 1.0537190082644626e-06, 'rewards/chosen': -0.08192586898803711, 'rewards/rejected': -0.14618530869483948, 'rewards/accuracies': 0.5, 'rewards/margins': 0.06425942480564117, 'policy_logps/rejected': -566.0142822265625, 'policy_logps/chosen': -489.96405029296875, 'referece_logps/rejected': -564.5524291992188, 'referece_logps/chosen': -489.14483642578125, 'logits/rejected': -0.3244766891002655, 'logits/chosen': -0.20537810027599335, 'epoch': 0.1}


  2%|▏         | 257/16104 [1:10:59<64:03:17, 14.55s/it]

  2%|▏         | 258/16104 [1:11:18<69:30:51, 15.79s/it]

  2%|▏         | 259/16104 [1:11:40<77:38:50, 17.64s/it]

  2%|▏         | 260/16104 [1:11:53<71:51:09, 16.33s/it]
{'loss': 0.6841, 'learning_rate': 1.0743801652892562e-06, 'rewards/chosen': 0.011028480716049671, 'rewards/rejected': -0.015492439270019531, 'rewards/accuracies': 0.625, 'rewards/margins': 0.026520922780036926, 'policy_logps/rejected': -536.6513671875, 'policy_logps/chosen': -544.1886596679688, 'referece_logps/rejected': -536.4965209960938, 'referece_logps/chosen': -544.2989501953125, 'logits/rejected': -0.8627273440361023, 'logits/chosen': -0.708401083946228, 'epoch': 0.1}


  2%|▏         | 262/16104 [1:12:23<69:29:54, 15.79s/it]
{'loss': 0.6751, 'learning_rate': 1.0826446280991735e-06, 'rewards/chosen': 0.00874481163918972, 'rewards/rejected': -0.04750585928559303, 'rewards/accuracies': 0.75, 'rewards/margins': 0.056250669062137604, 'policy_logps/rejected': -388.6980895996094, 'policy_logps/chosen': -349.7801818847656, 'referece_logps/rejected': -388.2230224609375, 'referece_logps/chosen': -349.86761474609375, 'logits/rejected': 0.10583209991455078, 'logits/chosen': 0.1234181821346283, 'epoch': 0.1}


  2%|▏         | 264/16104 [1:12:55<68:57:16, 15.67s/it]

  2%|▏         | 265/16104 [1:13:07<63:27:16, 14.42s/it]

  2%|▏         | 266/16104 [1:13:25<68:50:12, 15.65s/it]
{'loss': 0.689, 'learning_rate': 1.099173553719008e-06, 'rewards/chosen': -0.027571488171815872, 'rewards/rejected': -0.05818738788366318, 'rewards/accuracies': 0.5, 'rewards/margins': 0.030615901574492455, 'policy_logps/rejected': -328.1800842285156, 'policy_logps/chosen': -309.1086120605469, 'referece_logps/rejected': -327.5982360839844, 'referece_logps/chosen': -308.8329162597656, 'logits/rejected': -0.5894614458084106, 'logits/chosen': -0.5657591223716736, 'epoch': 0.1}


  2%|▏         | 268/16104 [1:14:06<78:44:02, 17.90s/it]
{'loss': 0.6789, 'learning_rate': 1.1074380165289257e-06, 'rewards/chosen': -0.0377139076590538, 'rewards/rejected': -0.02477111667394638, 'rewards/accuracies': 0.625, 'rewards/margins': -0.012942790985107422, 'policy_logps/rejected': -378.3955993652344, 'policy_logps/chosen': -345.8635559082031, 'referece_logps/rejected': -378.1478576660156, 'referece_logps/chosen': -345.48638916015625, 'logits/rejected': -1.034818410873413, 'logits/chosen': -1.0191246271133423, 'epoch': 0.1}


  2%|▏         | 270/16104 [1:14:38<74:39:02, 16.97s/it]

  2%|▏         | 271/16104 [1:14:53<71:52:41, 16.34s/it]

  2%|▏         | 272/16104 [1:15:06<66:53:09, 15.21s/it]

  2%|▏         | 273/16104 [1:15:26<73:26:45, 16.70s/it]
{'loss': 0.6581, 'learning_rate': 1.128099173553719e-06, 'rewards/chosen': 0.006062746979296207, 'rewards/rejected': -0.06949696689844131, 'rewards/accuracies': 0.875, 'rewards/margins': 0.07555971294641495, 'policy_logps/rejected': -314.10211181640625, 'policy_logps/chosen': -368.9046630859375, 'referece_logps/rejected': -313.40716552734375, 'referece_logps/chosen': -368.96527099609375, 'logits/rejected': 0.3059377372264862, 'logits/chosen': 0.359764039516449, 'epoch': 0.1}


  2%|▏         | 275/16104 [1:16:01<75:37:57, 17.20s/it]

  2%|▏         | 276/16104 [1:16:22<79:37:18, 18.11s/it]
[2024-04-05 16:41:28,904] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6838, 'learning_rate': 1.140495867768595e-06, 'rewards/chosen': -0.14454668760299683, 'rewards/rejected': -0.14780455827713013, 'rewards/accuracies': 0.375, 'rewards/margins': 0.0032578466925770044, 'policy_logps/rejected': -333.69049072265625, 'policy_logps/chosen': -349.41497802734375, 'referece_logps/rejected': -332.21246337890625, 'referece_logps/chosen': -347.9695129394531, 'logits/rejected': -0.35687172412872314, 'logits/chosen': -0.44874194264411926, 'epoch': 0.1}


  2%|▏         | 278/16104 [1:16:48<69:21:58, 15.78s/it]
{'loss': 0.681, 'learning_rate': 1.1487603305785123e-06, 'rewards/chosen': 0.015990447252988815, 'rewards/rejected': -0.0146643640473485, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03065481036901474, 'policy_logps/rejected': -358.6011657714844, 'policy_logps/chosen': -283.34161376953125, 'referece_logps/rejected': -358.45452880859375, 'referece_logps/chosen': -283.5014953613281, 'logits/rejected': -0.5711022615432739, 'logits/chosen': -0.5212287902832031, 'epoch': 0.1}


  2%|▏         | 280/16104 [1:17:25<76:50:34, 17.48s/it]

  2%|▏         | 281/16104 [1:17:44<78:06:40, 17.77s/it]
{'loss': 0.6817, 'learning_rate': 1.1611570247933884e-06, 'rewards/chosen': -0.05057068169116974, 'rewards/rejected': -0.08833464980125427, 'rewards/accuracies': 0.625, 'rewards/margins': 0.03776397556066513, 'policy_logps/rejected': -444.44482421875, 'policy_logps/chosen': -414.9330749511719, 'referece_logps/rejected': -443.5614929199219, 'referece_logps/chosen': -414.4273681640625, 'logits/rejected': 0.40553969144821167, 'logits/chosen': 0.3857017755508423, 'epoch': 0.1}


  2%|▏         | 283/16104 [1:18:05<62:22:19, 14.19s/it]

  2%|▏         | 284/16104 [1:18:17<59:21:45, 13.51s/it]

  2%|▏         | 285/16104 [1:18:36<66:01:20, 15.02s/it]

  2%|▏         | 286/16104 [1:18:52<67:59:36, 15.47s/it]

  2%|▏         | 287/16104 [1:19:06<65:49:35, 14.98s/it]

  2%|▏         | 288/16104 [1:19:24<69:16:03, 15.77s/it]
{'loss': 0.6826, 'learning_rate': 1.190082644628099e-06, 'rewards/chosen': -0.055469706654548645, 'rewards/rejected': -0.11826801300048828, 'rewards/accuracies': 0.625, 'rewards/margins': 0.06279831379652023, 'policy_logps/rejected': -519.7831420898438, 'policy_logps/chosen': -392.2709655761719, 'referece_logps/rejected': -518.6004028320312, 'referece_logps/chosen': -391.7162780761719, 'logits/rejected': -0.45412135124206543, 'logits/chosen': -0.27961739897727966, 'epoch': 0.11}

  2%|▏         | 289/16104 [1:19:37<65:21:29, 14.88s/it]


  2%|▏         | 291/16104 [1:20:10<68:09:00, 15.52s/it]
{'loss': 0.6649, 'learning_rate': 1.2024793388429752e-06, 'rewards/chosen': 0.007835770025849342, 'rewards/rejected': -0.041941069066524506, 'rewards/accuracies': 0.625, 'rewards/margins': 0.049776840955019, 'policy_logps/rejected': -545.1439819335938, 'policy_logps/chosen': -567.9830932617188, 'referece_logps/rejected': -544.724609375, 'referece_logps/chosen': -568.0614624023438, 'logits/rejected': -0.7962433695793152, 'logits/chosen': -0.7712911367416382, 'epoch': 0.11}
[2024-04-05 16:45:37,897] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 292/16104 [1:20:31<75:00:46, 17.08s/it]
[2024-04-05 16:45:50,118] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  2%|▏         | 294/16104 [1:21:05<76:34:15, 17.44s/it]

  2%|▏         | 295/16104 [1:21:28<84:54:23, 19.33s/it]
[2024-04-05 16:46:35,551] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6648, 'learning_rate': 1.21900826446281e-06, 'rewards/chosen': -0.03601818159222603, 'rewards/rejected': -0.09158030152320862, 'rewards/accuracies': 0.625, 'rewards/margins': 0.05556211620569229, 'policy_logps/rejected': -349.22625732421875, 'policy_logps/chosen': -377.13067626953125, 'referece_logps/rejected': -348.3104553222656, 'referece_logps/chosen': -376.7705078125, 'logits/rejected': 0.5845588445663452, 'logits/chosen': 0.7999498248100281, 'epoch': 0.11}


  2%|▏         | 297/16104 [1:22:07<84:37:44, 19.27s/it]

  2%|▏         | 298/16104 [1:22:24<82:10:51, 18.72s/it]

  2%|▏         | 299/16104 [1:22:36<73:05:50, 16.65s/it]

  2%|▏         | 300/16104 [1:22:47<65:21:40, 14.89s/it]
{'loss': 0.6818, 'learning_rate': 1.2396694214876033e-06, 'rewards/chosen': -0.05249328911304474, 'rewards/rejected': -0.01599712297320366, 'rewards/accuracies': 0.5, 'rewards/margins': -0.03649616241455078, 'policy_logps/rejected': -464.70806884765625, 'policy_logps/chosen': -440.64056396484375, 'referece_logps/rejected': -464.548095703125, 'referece_logps/chosen': -440.1156311035156, 'logits/rejected': -1.0801770687103271, 'logits/chosen': -0.8685227632522583, 'epoch': 0.11}


  2%|▏         | 302/16104 [1:23:14<62:56:01, 14.34s/it]

  2%|▏         | 303/16104 [1:23:34<70:56:39, 16.16s/it]
{'loss': 0.6869, 'learning_rate': 1.2520661157024792e-06, 'rewards/chosen': -0.0097427349537611, 'rewards/rejected': 0.002208517398685217, 'rewards/accuracies': 0.375, 'rewards/margins': -0.011951254680752754, 'policy_logps/rejected': -380.1301574707031, 'policy_logps/chosen': -369.50115966796875, 'referece_logps/rejected': -380.1522521972656, 'referece_logps/chosen': -369.4036865234375, 'logits/rejected': -0.6924523115158081, 'logits/chosen': -0.7834409475326538, 'epoch': 0.11}

  2%|▏         | 304/16104 [1:23:45<64:23:47, 14.67s/it]


  2%|▏         | 306/16104 [1:24:23<74:33:57, 16.99s/it]

  2%|▏         | 307/16104 [1:24:38<72:25:54, 16.51s/it]

  2%|▏         | 308/16104 [1:24:55<72:16:11, 16.47s/it]

  2%|▏         | 309/16104 [1:25:06<66:03:05, 15.05s/it]

  2%|▏         | 310/16104 [1:25:19<62:33:37, 14.26s/it]

  2%|▏         | 311/16104 [1:25:32<61:46:14, 14.08s/it]
{'loss': 0.6775, 'learning_rate': 1.2851239669421487e-06, 'rewards/chosen': -0.10848522931337357, 'rewards/rejected': -0.029154447838664055, 'rewards/accuracies': 0.375, 'rewards/margins': -0.07933078706264496, 'policy_logps/rejected': -419.8873291015625, 'policy_logps/chosen': -529.6318359375, 'referece_logps/rejected': -419.5958251953125, 'referece_logps/chosen': -528.5469970703125, 'logits/rejected': -0.23012475669384003, 'logits/chosen': -0.11851191520690918, 'epoch': 0.12}


  2%|▏         | 313/16104 [1:25:56<57:30:07, 13.11s/it]
{'loss': 0.678, 'learning_rate': 1.293388429752066e-06, 'rewards/chosen': -0.006126117426902056, 'rewards/rejected': -0.0811278447508812, 'rewards/accuracies': 0.75, 'rewards/margins': 0.07500171661376953, 'policy_logps/rejected': -406.21209716796875, 'policy_logps/chosen': -382.60858154296875, 'referece_logps/rejected': -405.40081787109375, 'referece_logps/chosen': -382.54736328125, 'logits/rejected': -0.8945775628089905, 'logits/chosen': -0.9514021277427673, 'epoch': 0.12}

  2%|▏         | 314/16104 [1:26:15<64:54:27, 14.80s/it]

  2%|▏         | 315/16104 [1:26:31<66:42:20, 15.21s/it]


  2%|▏         | 317/16104 [1:27:10<77:10:47, 17.60s/it]
{'loss': 0.6543, 'learning_rate': 1.3099173553719007e-06, 'rewards/chosen': -0.04148407280445099, 'rewards/rejected': -0.08732195198535919, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0458378791809082, 'policy_logps/rejected': -245.64720153808594, 'policy_logps/chosen': -426.5236511230469, 'referece_logps/rejected': -244.77395629882812, 'referece_logps/chosen': -426.1087951660156, 'logits/rejected': 0.28165560960769653, 'logits/chosen': 0.19573138654232025, 'epoch': 0.12}

  2%|▏         | 318/16104 [1:27:29<78:33:42, 17.92s/it]


  2%|▏         | 320/16104 [1:28:04<75:23:30, 17.20s/it]

  2%|▏         | 321/16104 [1:28:15<66:51:38, 15.25s/it]
{'loss': 0.6598, 'learning_rate': 1.3264462809917355e-06, 'rewards/chosen': -0.05355444550514221, 'rewards/rejected': -0.025271227583289146, 'rewards/accuracies': 0.25, 'rewards/margins': -0.028283216059207916, 'policy_logps/rejected': -348.82391357421875, 'policy_logps/chosen': -336.8472595214844, 'referece_logps/rejected': -348.57122802734375, 'referece_logps/chosen': -336.3117370605469, 'logits/rejected': 0.47453153133392334, 'logits/chosen': 0.5519747734069824, 'epoch': 0.12}


  2%|▏         | 323/16104 [1:28:55<78:24:31, 17.89s/it]

  2%|▏         | 324/16104 [1:29:11<75:51:23, 17.31s/it]

  2%|▏         | 325/16104 [1:29:32<81:10:27, 18.52s/it]

  2%|▏         | 326/16104 [1:29:43<70:48:07, 16.15s/it]
{'loss': 0.6672, 'learning_rate': 1.3471074380165289e-06, 'rewards/chosen': -0.08764725178480148, 'rewards/rejected': -0.10895156860351562, 'rewards/accuracies': 0.375, 'rewards/margins': 0.02130432240664959, 'policy_logps/rejected': -382.10345458984375, 'policy_logps/chosen': -337.8616027832031, 'referece_logps/rejected': -381.013916015625, 'referece_logps/chosen': -336.9851379394531, 'logits/rejected': -0.5166929960250854, 'logits/chosen': -0.4371124505996704, 'epoch': 0.12}


  2%|▏         | 328/16104 [1:30:05<59:44:55, 13.63s/it]

  2%|▏         | 329/16104 [1:30:17<57:35:46, 13.14s/it]

  2%|▏         | 330/16104 [1:30:34<62:46:58, 14.33s/it]

  2%|▏         | 331/16104 [1:30:50<64:54:42, 14.82s/it]
{'loss': 0.6851, 'learning_rate': 1.3677685950413222e-06, 'rewards/chosen': -0.03576164320111275, 'rewards/rejected': -0.02829914167523384, 'rewards/accuracies': 0.375, 'rewards/margins': -0.007462505251169205, 'policy_logps/rejected': -480.2840270996094, 'policy_logps/chosen': -398.79119873046875, 'referece_logps/rejected': -480.00103759765625, 'referece_logps/chosen': -398.43359375, 'logits/rejected': -0.6055980920791626, 'logits/chosen': -0.44674667716026306, 'epoch': 0.12}


  2%|▏         | 333/16104 [1:31:22<68:06:29, 15.55s/it]

  2%|▏         | 334/16104 [1:31:36<65:54:48, 15.05s/it]
{'loss': 0.6404, 'learning_rate': 1.3801652892561984e-06, 'rewards/chosen': -0.16129179298877716, 'rewards/rejected': -0.11808281391859055, 'rewards/accuracies': 0.375, 'rewards/margins': -0.04320898652076721, 'policy_logps/rejected': -294.9808654785156, 'policy_logps/chosen': -275.5411682128906, 'referece_logps/rejected': -293.800048828125, 'referece_logps/chosen': -273.92828369140625, 'logits/rejected': -0.8263509273529053, 'logits/chosen': -0.7809684872627258, 'epoch': 0.12}


  2%|▏         | 336/16104 [1:32:15<75:59:38, 17.35s/it]
{'loss': 0.6603, 'learning_rate': 1.3884297520661156e-06, 'rewards/chosen': 0.06274338066577911, 'rewards/rejected': -0.11080531775951385, 'rewards/accuracies': 0.875, 'rewards/margins': 0.17354869842529297, 'policy_logps/rejected': -485.3695373535156, 'policy_logps/chosen': -504.72406005859375, 'referece_logps/rejected': -484.261474609375, 'referece_logps/chosen': -505.3515625, 'logits/rejected': 0.39349350333213806, 'logits/chosen': 0.3707500398159027, 'epoch': 0.13}


  2%|▏         | 338/16104 [1:32:48<75:37:06, 17.27s/it]

  2%|▏         | 339/16104 [1:33:09<80:30:13, 18.38s/it]

  2%|▏         | 340/16104 [1:33:27<79:46:06, 18.22s/it]

  2%|▏         | 341/16104 [1:33:38<70:35:33, 16.12s/it]
{'loss': 0.6747, 'learning_rate': 1.409090909090909e-06, 'rewards/chosen': -0.020595455542206764, 'rewards/rejected': -0.1214694082736969, 'rewards/accuracies': 0.875, 'rewards/margins': 0.10087396204471588, 'policy_logps/rejected': -253.42889404296875, 'policy_logps/chosen': -282.1635437011719, 'referece_logps/rejected': -252.21420288085938, 'referece_logps/chosen': -281.9576416015625, 'logits/rejected': -0.05891546979546547, 'logits/chosen': -0.07726627588272095, 'epoch': 0.13}


  2%|▏         | 343/16104 [1:34:11<72:39:12, 16.59s/it]
{'loss': 0.6671, 'learning_rate': 1.4173553719008265e-06, 'rewards/chosen': -0.040388159453868866, 'rewards/rejected': -0.21767747402191162, 'rewards/accuracies': 0.75, 'rewards/margins': 0.17728933691978455, 'policy_logps/rejected': -468.4656677246094, 'policy_logps/chosen': -324.3704833984375, 'referece_logps/rejected': -466.28887939453125, 'referece_logps/chosen': -323.96661376953125, 'logits/rejected': -0.01913725584745407, 'logits/chosen': -0.055466435849666595, 'epoch': 0.13}


  2%|▏         | 345/16104 [1:34:32<59:38:04, 13.62s/it]

  2%|▏         | 346/16104 [1:34:51<66:09:12, 15.11s/it]

  2%|▏         | 347/16104 [1:35:11<72:37:30, 16.59s/it]

  2%|▏         | 348/16104 [1:35:27<71:25:33, 16.32s/it]

  2%|▏         | 349/16104 [1:35:49<79:18:08, 18.12s/it]

  2%|▏         | 350/16104 [1:36:01<70:29:58, 16.11s/it]

  2%|▏         | 351/16104 [1:36:15<68:25:06, 15.64s/it]
{'loss': 0.6772, 'learning_rate': 1.4504132231404958e-06, 'rewards/chosen': -0.10318717360496521, 'rewards/rejected': -0.18309612572193146, 'rewards/accuracies': 0.75, 'rewards/margins': 0.07990895211696625, 'policy_logps/rejected': -440.58184814453125, 'policy_logps/chosen': -481.74346923828125, 'referece_logps/rejected': -438.7508544921875, 'referece_logps/chosen': -480.711669921875, 'logits/rejected': -0.13144534826278687, 'logits/chosen': -0.22532059252262115, 'epoch': 0.13}


  2%|▏         | 353/16104 [1:36:53<74:27:00, 17.02s/it]

  2%|▏         | 354/16104 [1:37:15<81:20:57, 18.59s/it]

  2%|▏         | 355/16104 [1:37:27<73:20:23, 16.76s/it]

  2%|▏         | 356/16104 [1:37:43<71:43:21, 16.40s/it]
{'loss': 0.682, 'learning_rate': 1.4710743801652892e-06, 'rewards/chosen': -0.09382285922765732, 'rewards/rejected': -0.07194328308105469, 'rewards/accuracies': 0.375, 'rewards/margins': -0.02187957800924778, 'policy_logps/rejected': -311.8318786621094, 'policy_logps/chosen': -385.0574951171875, 'referece_logps/rejected': -311.1124572753906, 'referece_logps/chosen': -384.11932373046875, 'logits/rejected': 0.011727988719940186, 'logits/chosen': -0.011674672365188599, 'epoch': 0.13}


  2%|▏         | 358/16104 [1:38:19<76:20:11, 17.45s/it]

  2%|▏         | 359/16104 [1:38:38<78:13:05, 17.88s/it]
{'loss': 0.6727, 'learning_rate': 1.4834710743801653e-06, 'rewards/chosen': -0.27259179949760437, 'rewards/rejected': -0.2782089412212372, 'rewards/accuracies': 0.5, 'rewards/margins': 0.005617139860987663, 'policy_logps/rejected': -357.7612609863281, 'policy_logps/chosen': -376.3337707519531, 'referece_logps/rejected': -354.97918701171875, 'referece_logps/chosen': -373.6078186035156, 'logits/rejected': 0.24746595323085785, 'logits/chosen': 0.16406096518039703, 'epoch': 0.13}
[2024-04-05 17:04:08,180] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  2%|▏         | 360/16104 [1:39:01<85:25:50, 19.53s/it]

  2%|▏         | 361/16104 [1:39:23<88:18:40, 20.19s/it]

  2%|▏         | 362/16104 [1:39:44<90:19:20, 20.66s/it]

  2%|▏         | 363/16104 [1:39:56<78:51:16, 18.03s/it]

  2%|▏         | 364/16104 [1:40:16<81:07:41, 18.56s/it]

  2%|▏         | 365/16104 [1:40:29<73:38:09, 16.84s/it]

  2%|▏         | 366/16104 [1:40:42<69:10:41, 15.82s/it]


  2%|▏         | 368/16104 [1:41:08<61:46:42, 14.13s/it]
[2024-04-05 17:06:15,031] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6503, 'learning_rate': 1.5206611570247934e-06, 'rewards/chosen': -0.07932167500257492, 'rewards/rejected': -0.2616473138332367, 'rewards/accuracies': 0.75, 'rewards/margins': 0.18232566118240356, 'policy_logps/rejected': -352.6028747558594, 'policy_logps/chosen': -316.3816223144531, 'referece_logps/rejected': -349.98638916015625, 'referece_logps/chosen': -315.58837890625, 'logits/rejected': -0.401863157749176, 'logits/chosen': -0.5281903743743896, 'epoch': 0.14}

  2%|▏         | 369/16104 [1:41:27<67:58:59, 15.55s/it]

  2%|▏         | 370/16104 [1:41:43<68:46:11, 15.73s/it]

  2%|▏         | 371/16104 [1:42:00<70:38:08, 16.16s/it]

  2%|▏         | 372/16104 [1:42:15<68:26:29, 15.66s/it]


  2%|▏         | 374/16104 [1:42:46<68:35:38, 15.70s/it]

  2%|▏         | 375/16104 [1:42:58<64:19:11, 14.72s/it]
{'loss': 0.692, 'learning_rate': 1.549586776859504e-06, 'rewards/chosen': -0.049616631120443344, 'rewards/rejected': -0.056424714624881744, 'rewards/accuracies': 0.375, 'rewards/margins': 0.006808089092373848, 'policy_logps/rejected': -341.0176086425781, 'policy_logps/chosen': -357.0005187988281, 'referece_logps/rejected': -340.4533996582031, 'referece_logps/chosen': -356.50433349609375, 'logits/rejected': -1.628061056137085, 'logits/chosen': -1.507319688796997, 'epoch': 0.14}


  2%|▏         | 377/16104 [1:43:26<63:24:55, 14.52s/it]
{'loss': 0.6855, 'learning_rate': 1.5578512396694213e-06, 'rewards/chosen': -0.12043800204992294, 'rewards/rejected': -0.12030105292797089, 'rewards/accuracies': 0.5, 'rewards/margins': -0.00013694725930690765, 'policy_logps/rejected': -389.48968505859375, 'policy_logps/chosen': -395.6687927246094, 'referece_logps/rejected': -388.2866516113281, 'referece_logps/chosen': -394.46441650390625, 'logits/rejected': 0.8675512075424194, 'logits/chosen': 0.8803498148918152, 'epoch': 0.14}


  2%|▏         | 379/16104 [1:44:04<73:50:07, 16.90s/it]
{'loss': 0.6743, 'learning_rate': 1.5661157024793388e-06, 'rewards/chosen': -0.1359172761440277, 'rewards/rejected': -0.17988702654838562, 'rewards/accuracies': 0.625, 'rewards/margins': 0.04396972060203552, 'policy_logps/rejected': -325.5473327636719, 'policy_logps/chosen': -312.7055969238281, 'referece_logps/rejected': -323.7484130859375, 'referece_logps/chosen': -311.3464050292969, 'logits/rejected': -0.4913589358329773, 'logits/chosen': -0.34692156314849854, 'epoch': 0.14}

  2%|▏         | 380/16104 [1:44:21<74:13:30, 16.99s/it]

  2%|▏         | 381/16104 [1:44:39<75:34:51, 17.31s/it]

  2%|▏         | 382/16104 [1:44:58<77:40:09, 17.78s/it]


  2%|▏         | 384/16104 [1:45:36<78:53:11, 18.07s/it]

  2%|▏         | 385/16104 [1:45:52<76:28:25, 17.51s/it]
{'loss': 0.6729, 'learning_rate': 1.5909090909090908e-06, 'rewards/chosen': -0.31550559401512146, 'rewards/rejected': -0.23409242928028107, 'rewards/accuracies': 0.375, 'rewards/margins': -0.08141317963600159, 'policy_logps/rejected': -343.56109619140625, 'policy_logps/chosen': -444.0401611328125, 'referece_logps/rejected': -341.22015380859375, 'referece_logps/chosen': -440.8851623535156, 'logits/rejected': -1.148207664489746, 'logits/chosen': -0.9947865009307861, 'epoch': 0.14}

  2%|▏         | 386/16104 [1:46:05<70:19:52, 16.11s/it]


  2%|▏         | 388/16104 [1:46:34<66:56:07, 15.33s/it]

  2%|▏         | 389/16104 [1:46:48<64:49:04, 14.85s/it]
{'loss': 0.6799, 'learning_rate': 1.6074380165289256e-06, 'rewards/chosen': -0.02941112220287323, 'rewards/rejected': -0.07445202022790909, 'rewards/accuracies': 0.5, 'rewards/margins': 0.04504089057445526, 'policy_logps/rejected': -246.38180541992188, 'policy_logps/chosen': -399.05584716796875, 'referece_logps/rejected': -245.63729858398438, 'referece_logps/chosen': -398.7617492675781, 'logits/rejected': -0.5235753059387207, 'logits/chosen': -0.4341709017753601, 'epoch': 0.14}


  2%|▏         | 391/16104 [1:47:24<71:56:14, 16.48s/it]
{'loss': 0.6616, 'learning_rate': 1.6157024793388429e-06, 'rewards/chosen': -0.16039620339870453, 'rewards/rejected': -0.1909063309431076, 'rewards/accuracies': 0.625, 'rewards/margins': 0.030510136857628822, 'policy_logps/rejected': -319.4263916015625, 'policy_logps/chosen': -407.3771667480469, 'referece_logps/rejected': -317.517333984375, 'referece_logps/chosen': -405.773193359375, 'logits/rejected': -0.3252972960472107, 'logits/chosen': -0.41074150800704956, 'epoch': 0.15}

  2%|▏         | 392/16104 [1:47:34<64:17:14, 14.73s/it]


  2%|▏         | 394/16104 [1:48:22<84:29:05, 19.36s/it]
{'loss': 0.6709, 'learning_rate': 1.6280991735537188e-06, 'rewards/chosen': -0.03306875377893448, 'rewards/rejected': -0.14268474280834198, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1096159964799881, 'policy_logps/rejected': -272.4150085449219, 'policy_logps/chosen': -315.58251953125, 'referece_logps/rejected': -270.9881591796875, 'referece_logps/chosen': -315.2518615722656, 'logits/rejected': -0.43453940749168396, 'logits/chosen': -0.3231903612613678, 'epoch': 0.15}


  2%|▏         | 396/16104 [1:48:52<73:45:38, 16.90s/it]

  2%|▏         | 397/16104 [1:49:10<74:44:16, 17.13s/it]

  2%|▏         | 398/16104 [1:49:24<71:04:18, 16.29s/it]
{'loss': 0.6903, 'learning_rate': 1.6446280991735537e-06, 'rewards/chosen': -0.28557661175727844, 'rewards/rejected': -0.31664031744003296, 'rewards/accuracies': 0.375, 'rewards/margins': 0.031063638627529144, 'policy_logps/rejected': -550.2415771484375, 'policy_logps/chosen': -607.9409790039062, 'referece_logps/rejected': -547.0751342773438, 'referece_logps/chosen': -605.085205078125, 'logits/rejected': -0.06645916402339935, 'logits/chosen': -0.038527101278305054, 'epoch': 0.15}


  2%|▏         | 400/16104 [1:49:54<69:52:06, 16.02s/it]

  2%|▏         | 401/16104 [1:50:08<67:11:04, 15.40s/it]
{'loss': 0.6314, 'learning_rate': 1.6570247933884296e-06, 'rewards/chosen': -0.11287002265453339, 'rewards/rejected': -0.3625185191631317, 'rewards/accuracies': 0.875, 'rewards/margins': 0.24964848160743713, 'policy_logps/rejected': -251.93214416503906, 'policy_logps/chosen': -236.27964782714844, 'referece_logps/rejected': -248.30694580078125, 'referece_logps/chosen': -235.1509246826172, 'logits/rejected': -0.8392564654350281, 'logits/chosen': -0.7390983700752258, 'epoch': 0.15}

  2%|▏         | 402/16104 [1:50:19<61:05:25, 14.01s/it]

  3%|▎         | 403/16104 [1:50:36<64:59:20, 14.90s/it]


  3%|▎         | 405/16104 [1:51:02<60:55:56, 13.97s/it]
{'loss': 0.6737, 'learning_rate': 1.6735537190082644e-06, 'rewards/chosen': -0.16417543590068817, 'rewards/rejected': -0.22269591689109802, 'rewards/accuracies': 0.625, 'rewards/margins': 0.05852050334215164, 'policy_logps/rejected': -410.3507080078125, 'policy_logps/chosen': -449.2102355957031, 'referece_logps/rejected': -408.123779296875, 'referece_logps/chosen': -447.5684814453125, 'logits/rejected': 0.218034029006958, 'logits/chosen': 0.23660778999328613, 'epoch': 0.15}

  3%|▎         | 406/16104 [1:51:17<61:58:34, 14.21s/it]

  3%|▎         | 407/16104 [1:51:28<57:51:41, 13.27s/it]

  3%|▎         | 408/16104 [1:51:45<63:02:23, 14.46s/it]

  3%|▎         | 409/16104 [1:52:07<73:29:51, 16.86s/it]


  3%|▎         | 411/16104 [1:52:42<74:09:11, 17.01s/it]

  3%|▎         | 412/16104 [1:53:01<76:02:03, 17.44s/it]
{'loss': 0.6839, 'learning_rate': 1.7024793388429753e-06, 'rewards/chosen': -0.13071118295192719, 'rewards/rejected': -0.30871695280075073, 'rewards/accuracies': 0.875, 'rewards/margins': 0.17800579965114594, 'policy_logps/rejected': -587.983154296875, 'policy_logps/chosen': -546.868408203125, 'referece_logps/rejected': -584.89599609375, 'referece_logps/chosen': -545.5613403320312, 'logits/rejected': -1.0058590173721313, 'logits/chosen': -0.9704024791717529, 'epoch': 0.15}

  3%|▎         | 413/16104 [1:53:11<67:22:49, 15.46s/it]

  3%|▎         | 414/16104 [1:53:32<74:11:42, 17.02s/it]

  3%|▎         | 415/16104 [1:53:52<78:16:21, 17.96s/it]
{'loss': 0.6749, 'learning_rate': 1.7148760330578512e-06, 'rewards/chosen': -0.14225731790065765, 'rewards/rejected': -0.1703464537858963, 'rewards/accuracies': 0.5, 'rewards/margins': 0.028089141473174095, 'policy_logps/rejected': -400.778564453125, 'policy_logps/chosen': -414.6771240234375, 'referece_logps/rejected': -399.0751037597656, 'referece_logps/chosen': -413.2545166015625, 'logits/rejected': 0.04536256194114685, 'logits/chosen': -0.09534931182861328, 'epoch': 0.15}

  3%|▎         | 416/16104 [1:54:07<74:39:28, 17.13s/it]

  3%|▎         | 417/16104 [1:54:19<67:45:48, 15.55s/it]

  3%|▎         | 418/16104 [1:54:30<61:22:12, 14.08s/it]

  3%|▎         | 419/16104 [1:54:42<58:28:35, 13.42s/it]

  3%|▎         | 420/16104 [1:54:53<55:45:30, 12.80s/it]


  3%|▎         | 422/16104 [1:55:31<68:26:37, 15.71s/it]

  3%|▎         | 423/16104 [1:55:43<63:43:28, 14.63s/it]

  3%|▎         | 424/16104 [1:55:56<62:21:30, 14.32s/it]

  3%|▎         | 425/16104 [1:56:14<67:02:31, 15.39s/it]
{'loss': 0.6373, 'learning_rate': 1.756198347107438e-06, 'rewards/chosen': 0.0013721464201807976, 'rewards/rejected': -0.11778393387794495, 'rewards/accuracies': 0.75, 'rewards/margins': 0.11915607750415802, 'policy_logps/rejected': -345.19677734375, 'policy_logps/chosen': -377.6773986816406, 'referece_logps/rejected': -344.0189208984375, 'referece_logps/chosen': -377.69110107421875, 'logits/rejected': -1.2728643417358398, 'logits/chosen': -1.186884880065918, 'epoch': 0.16}

  3%|▎         | 426/16104 [1:56:29<66:28:40, 15.26s/it]

  3%|▎         | 427/16104 [1:56:49<72:14:10, 16.59s/it]

  3%|▎         | 428/16104 [1:57:00<64:59:55, 14.93s/it]

  3%|▎         | 429/16104 [1:57:18<68:57:57, 15.84s/it]


  3%|▎         | 431/16104 [1:57:54<72:49:02, 16.73s/it]
{'loss': 0.6596, 'learning_rate': 1.78099173553719e-06, 'rewards/chosen': -0.07344285398721695, 'rewards/rejected': -0.18971291184425354, 'rewards/accuracies': 0.625, 'rewards/margins': 0.11627006530761719, 'policy_logps/rejected': -444.30438232421875, 'policy_logps/chosen': -344.4829406738281, 'referece_logps/rejected': -442.40728759765625, 'referece_logps/chosen': -343.7485046386719, 'logits/rejected': -1.9645795822143555, 'logits/chosen': -2.0926544666290283, 'epoch': 0.16}

  3%|▎         | 432/16104 [1:58:15<77:55:12, 17.90s/it]

  3%|▎         | 433/16104 [1:58:36<81:52:23, 18.81s/it]


  3%|▎         | 435/16104 [1:59:15<84:23:20, 19.39s/it]
{'loss': 0.6015, 'learning_rate': 1.7975206611570247e-06, 'rewards/chosen': -0.07444973289966583, 'rewards/rejected': -0.18179292976856232, 'rewards/accuracies': 0.625, 'rewards/margins': 0.10734321177005768, 'policy_logps/rejected': -316.82025146484375, 'policy_logps/chosen': -399.10357666015625, 'referece_logps/rejected': -315.0023193359375, 'referece_logps/chosen': -398.3591003417969, 'logits/rejected': -0.7222040295600891, 'logits/chosen': -0.8301187753677368, 'epoch': 0.16}

  3%|▎         | 436/16104 [1:59:26<73:48:27, 16.96s/it]
[2024-04-05 17:24:54,768] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 437/16104 [1:59:48<79:45:15, 18.33s/it]
[2024-04-05 17:25:10,625] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 438/16104 [2:00:03<76:31:43, 17.59s/it]

  3%|▎         | 439/16104 [2:00:14<67:37:34, 15.54s/it]


  3%|▎         | 441/16104 [2:00:51<74:19:19, 17.08s/it]

  3%|▎         | 442/16104 [2:01:15<83:17:28, 19.14s/it]
{'loss': 0.6746, 'learning_rate': 1.8264462809917353e-06, 'rewards/chosen': -0.1793343424797058, 'rewards/rejected': -0.1818668395280838, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0025324802845716476, 'policy_logps/rejected': -383.25274658203125, 'policy_logps/chosen': -325.349853515625, 'referece_logps/rejected': -381.4340515136719, 'referece_logps/chosen': -323.5564880371094, 'logits/rejected': -0.7458943128585815, 'logits/chosen': -0.8142850995063782, 'epoch': 0.16}

  3%|▎         | 443/16104 [2:01:31<79:38:28, 18.31s/it]

  3%|▎         | 444/16104 [2:01:53<84:20:36, 19.39s/it]

  3%|▎         | 445/16104 [2:02:08<77:49:59, 17.89s/it]

  3%|▎         | 446/16104 [2:02:20<70:46:55, 16.27s/it]

  3%|▎         | 447/16104 [2:02:40<75:00:24, 17.25s/it]

  3%|▎         | 448/16104 [2:02:58<76:30:34, 17.59s/it]

  3%|▎         | 449/16104 [2:03:09<68:19:51, 15.71s/it]

  3%|▎         | 450/16104 [2:03:28<71:46:46, 16.51s/it]

  3%|▎         | 451/16104 [2:03:42<68:19:55, 15.72s/it]

  3%|▎         | 452/16104 [2:04:02<74:39:59, 17.17s/it]

  3%|▎         | 453/16104 [2:04:20<75:24:36, 17.35s/it]


  3%|▎         | 455/16104 [2:04:59<81:12:31, 18.68s/it]
{'loss': 0.6677, 'learning_rate': 1.8801652892561982e-06, 'rewards/chosen': -0.1585680991411209, 'rewards/rejected': -0.23711931705474854, 'rewards/accuracies': 0.625, 'rewards/margins': 0.07855120301246643, 'policy_logps/rejected': -422.2275695800781, 'policy_logps/chosen': -342.4825439453125, 'referece_logps/rejected': -419.8563537597656, 'referece_logps/chosen': -340.8968505859375, 'logits/rejected': 0.13439051806926727, 'logits/chosen': 0.07735709100961685, 'epoch': 0.17}


  3%|▎         | 457/16104 [2:05:23<66:13:58, 15.24s/it]

  3%|▎         | 458/16104 [2:05:37<64:32:08, 14.85s/it]
{'loss': 0.6699, 'learning_rate': 1.8925619834710741e-06, 'rewards/chosen': -0.17251291871070862, 'rewards/rejected': -0.16847285628318787, 'rewards/accuracies': 0.625, 'rewards/margins': -0.004040069878101349, 'policy_logps/rejected': -279.8769836425781, 'policy_logps/chosen': -386.4679260253906, 'referece_logps/rejected': -278.1922607421875, 'referece_logps/chosen': -384.7427978515625, 'logits/rejected': -0.18855664134025574, 'logits/chosen': -0.1731269210577011, 'epoch': 0.17}

  3%|▎         | 459/16104 [2:05:50<62:04:05, 14.28s/it]

  3%|▎         | 460/16104 [2:06:08<66:35:46, 15.33s/it]

  3%|▎         | 461/16104 [2:06:26<70:10:25, 16.15s/it]
[2024-04-05 17:31:51,521] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  3%|▎         | 463/16104 [2:07:07<80:55:18, 18.63s/it]

  3%|▎         | 464/16104 [2:07:23<77:38:32, 17.87s/it]
{'loss': 0.6416, 'learning_rate': 1.9173553719008264e-06, 'rewards/chosen': -0.3166946470737457, 'rewards/rejected': -0.3389774262905121, 'rewards/accuracies': 0.625, 'rewards/margins': 0.02228279411792755, 'policy_logps/rejected': -357.22552490234375, 'policy_logps/chosen': -610.8405151367188, 'referece_logps/rejected': -353.8357849121094, 'referece_logps/chosen': -607.673583984375, 'logits/rejected': -0.1554875522851944, 'logits/chosen': -0.28949174284935, 'epoch': 0.17}

  3%|▎         | 465/16104 [2:07:34<68:25:34, 15.75s/it]

  3%|▎         | 466/16104 [2:07:52<71:02:22, 16.35s/it]

  3%|▎         | 467/16104 [2:08:03<64:08:42, 14.77s/it]


  3%|▎         | 469/16104 [2:08:27<57:58:31, 13.35s/it]
{'loss': 0.6321, 'learning_rate': 1.93801652892562e-06, 'rewards/chosen': -0.1935136914253235, 'rewards/rejected': -0.4749561548233032, 'rewards/accuracies': 1.0, 'rewards/margins': 0.28144246339797974, 'policy_logps/rejected': -317.91534423828125, 'policy_logps/chosen': -289.36187744140625, 'referece_logps/rejected': -313.165771484375, 'referece_logps/chosen': -287.4267578125, 'logits/rejected': -0.8077147603034973, 'logits/chosen': -0.8849361538887024, 'epoch': 0.17}

  3%|▎         | 470/16104 [2:08:46<64:44:52, 14.91s/it]

  3%|▎         | 471/16104 [2:08:58<61:29:58, 14.16s/it]

  3%|▎         | 472/16104 [2:09:16<66:51:32, 15.40s/it]

  3%|▎         | 473/16104 [2:09:34<70:09:18, 16.16s/it]

  3%|▎         | 474/16104 [2:09:47<66:05:12, 15.22s/it]

  3%|▎         | 475/16104 [2:10:01<63:39:38, 14.66s/it]

  3%|▎         | 476/16104 [2:10:20<70:18:59, 16.20s/it]

  3%|▎         | 477/16104 [2:10:39<72:43:09, 16.75s/it]

  3%|▎         | 478/16104 [2:11:01<79:38:16, 18.35s/it]

  3%|▎         | 479/16104 [2:11:14<73:19:05, 16.89s/it]

  3%|▎         | 480/16104 [2:11:34<76:40:46, 17.67s/it]

  3%|▎         | 481/16104 [2:11:46<70:25:05, 16.23s/it]

  3%|▎         | 482/16104 [2:12:08<77:23:12, 17.83s/it]

  3%|▎         | 483/16104 [2:12:28<79:45:46, 18.38s/it]

  3%|▎         | 484/16104 [2:12:46<80:17:33, 18.51s/it]


  3%|▎         | 486/16104 [2:13:14<70:16:15, 16.20s/it]
{'loss': 0.6731, 'learning_rate': 1.9999999190964315e-06, 'rewards/chosen': -0.11222553998231888, 'rewards/rejected': -0.24813880026340485, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13591328263282776, 'policy_logps/rejected': -391.12109375, 'policy_logps/chosen': -426.20684814453125, 'referece_logps/rejected': -388.63970947265625, 'referece_logps/chosen': -425.08453369140625, 'logits/rejected': -1.2309433221817017, 'logits/chosen': -1.3572195768356323, 'epoch': 0.18}

  3%|▎         | 487/16104 [2:13:29<68:30:32, 15.79s/it]

  3%|▎         | 488/16104 [2:13:48<72:58:32, 16.82s/it]

  3%|▎         | 489/16104 [2:14:07<76:27:16, 17.63s/it]

  3%|▎         | 490/16104 [2:14:26<77:44:36, 17.92s/it]


  3%|▎         | 492/16104 [2:14:54<67:35:49, 15.59s/it]
{'loss': 0.6693, 'learning_rate': 1.999998705543171e-06, 'rewards/chosen': -0.23266279697418213, 'rewards/rejected': -0.30539244413375854, 'rewards/accuracies': 0.625, 'rewards/margins': 0.07272969186306, 'policy_logps/rejected': -355.8130798339844, 'policy_logps/chosen': -332.3053283691406, 'referece_logps/rejected': -352.7591552734375, 'referece_logps/chosen': -329.97869873046875, 'logits/rejected': -0.8559466004371643, 'logits/chosen': -0.7224982976913452, 'epoch': 0.18}

  3%|▎         | 493/16104 [2:15:07<63:49:05, 14.72s/it]

  3%|▎         | 494/16104 [2:15:20<62:07:39, 14.33s/it]

  3%|▎         | 495/16104 [2:15:31<57:26:19, 13.25s/it]

  3%|▎         | 496/16104 [2:15:44<57:29:51, 13.26s/it]

  3%|▎         | 497/16104 [2:16:04<65:48:20, 15.18s/it]

  3%|▎         | 498/16104 [2:16:24<72:41:49, 16.77s/it]

  3%|▎         | 499/16104 [2:16:37<68:00:59, 15.69s/it]

  3%|▎         | 500/16104 [2:16:58<75:01:00, 17.31s/it]/mnt/petrelfs/songmingyang/anaconda3/envs/vcd_origin/lib/python3.9/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
{'loss': 0.6412, 'learning_rate': 1.9999941547228157e-06, 'rewards/chosen': -0.09955672174692154, 'rewards/rejected': -0.4441761374473572, 'rewards/accuracies': 0.875, 'rewards/margins': 0.34461939334869385, 'policy_logps/rejected': -272.6158447265625, 'policy_logps/chosen': -301.6727600097656, 'referece_logps/rejected': -268.174072265625, 'referece_logps/chosen': -300.67718505859375, 'logits/rejected': -0.5124058723449707, 'logits/chosen': -0.5313029289245605, 'epoch': 0.19}
  3%|▎         | 501/16104 [2:17:25<87:31:25, 20.19s/it]

  3%|▎         | 502/16104 [2:17:47<89:22:28, 20.62s/it]

  3%|▎         | 503/16104 [2:18:05<85:51:58, 19.81s/it]

  3%|▎         | 504/16104 [2:18:27<88:13:24, 20.36s/it]


  3%|▎         | 506/16104 [2:19:00<81:11:52, 18.74s/it]
{'loss': 0.6342, 'learning_rate': 1.999990210684092e-06, 'rewards/chosen': -0.2741771638393402, 'rewards/rejected': -0.5971336364746094, 'rewards/accuracies': 1.0, 'rewards/margins': 0.32295647263526917, 'policy_logps/rejected': -643.1784057617188, 'policy_logps/chosen': -440.77264404296875, 'referece_logps/rejected': -637.2070922851562, 'referece_logps/chosen': -438.0308532714844, 'logits/rejected': -0.3843587040901184, 'logits/chosen': -0.2034415304660797, 'epoch': 0.19}

  3%|▎         | 507/16104 [2:19:12<72:43:36, 16.79s/it]

  3%|▎         | 508/16104 [2:19:36<81:19:10, 18.77s/it]

  3%|▎         | 509/16104 [2:19:58<85:40:25, 19.78s/it]

  3%|▎         | 510/16104 [2:20:19<87:21:26, 20.17s/it]

  3%|▎         | 511/16104 [2:20:33<78:47:42, 18.19s/it]

  3%|▎         | 512/16104 [2:20:54<82:42:31, 19.10s/it]

  3%|▎         | 513/16104 [2:21:11<80:35:13, 18.61s/it]

  3%|▎         | 514/16104 [2:21:33<84:18:17, 19.47s/it]

  3%|▎         | 515/16104 [2:21:50<80:49:27, 18.66s/it]

  3%|▎         | 516/16104 [2:22:12<85:48:53, 19.82s/it]

  3%|▎         | 517/16104 [2:22:27<79:13:46, 18.30s/it]

  3%|▎         | 518/16104 [2:22:49<84:29:54, 19.52s/it]

  3%|▎         | 519/16104 [2:23:01<74:55:22, 17.31s/it]

  3%|▎         | 520/16104 [2:23:23<81:02:11, 18.72s/it]

  3%|▎         | 521/16104 [2:23:35<71:24:51, 16.50s/it]


  3%|▎         | 523/16104 [2:24:01<63:54:46, 14.77s/it]
{'loss': 0.6616, 'learning_rate': 1.9999692365755243e-06, 'rewards/chosen': -0.23783093690872192, 'rewards/rejected': -0.5162426233291626, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2784116864204407, 'policy_logps/rejected': -263.0099182128906, 'policy_logps/chosen': -268.0795593261719, 'referece_logps/rejected': -257.84747314453125, 'referece_logps/chosen': -265.70123291015625, 'logits/rejected': -1.4481284618377686, 'logits/chosen': -1.3358908891677856, 'epoch': 0.19}

  3%|▎         | 524/16104 [2:24:17<66:35:37, 15.39s/it]

  3%|▎         | 525/16104 [2:24:28<60:35:30, 14.00s/it]

  3%|▎         | 526/16104 [2:24:39<56:26:37, 13.04s/it]

  3%|▎         | 527/16104 [2:24:54<58:51:17, 13.60s/it]

  3%|▎         | 528/16104 [2:25:05<54:58:53, 12.71s/it]

  3%|▎         | 529/16104 [2:25:17<54:05:02, 12.50s/it]

  3%|▎         | 530/16104 [2:25:33<58:51:38, 13.61s/it]

  3%|▎         | 531/16104 [2:25:43<54:55:42, 12.70s/it]

  3%|▎         | 532/16104 [2:25:58<57:20:10, 13.26s/it]

  3%|▎         | 533/16104 [2:26:17<64:42:33, 14.96s/it]

  3%|▎         | 534/16104 [2:26:35<69:17:34, 16.02s/it]

  3%|▎         | 535/16104 [2:26:53<71:52:09, 16.62s/it]
[2024-04-05 17:52:21,018] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 536/16104 [2:27:14<76:57:25, 17.80s/it]
[2024-04-05 17:52:37,474] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 537/16104 [2:27:30<75:12:50, 17.39s/it]


  3%|▎         | 539/16104 [2:28:05<75:16:47, 17.41s/it]
{'loss': 0.6049, 'learning_rate': 1.9999388172996495e-06, 'rewards/chosen': -0.585157573223114, 'rewards/rejected': -0.5650103688240051, 'rewards/accuracies': 0.375, 'rewards/margins': -0.02014719694852829, 'policy_logps/rejected': -283.8863830566406, 'policy_logps/chosen': -405.1706237792969, 'referece_logps/rejected': -278.23626708984375, 'referece_logps/chosen': -399.31903076171875, 'logits/rejected': -0.8975858688354492, 'logits/chosen': -0.6784459352493286, 'epoch': 0.2}


  3%|▎         | 541/16104 [2:28:37<70:07:00, 16.22s/it]
{'loss': 0.6061, 'learning_rate': 1.9999342867955903e-06, 'rewards/chosen': -0.24363233149051666, 'rewards/rejected': -0.2730654776096344, 'rewards/accuracies': 0.5, 'rewards/margins': 0.029433157294988632, 'policy_logps/rejected': -310.74798583984375, 'policy_logps/chosen': -397.24224853515625, 'referece_logps/rejected': -308.017333984375, 'referece_logps/chosen': -394.8059387207031, 'logits/rejected': -0.5942739844322205, 'logits/chosen': -0.7811387181282043, 'epoch': 0.2}

  3%|▎         | 542/16104 [2:28:58<76:51:32, 17.78s/it]

  3%|▎         | 543/16104 [2:29:21<83:35:08, 19.34s/it]
[2024-04-05 17:54:48,171] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 544/16104 [2:29:41<84:04:49, 19.45s/it]
[2024-04-05 17:55:06,443] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  3%|▎         | 545/16104 [2:29:59<82:32:39, 19.10s/it]

  3%|▎         | 546/16104 [2:30:16<79:53:26, 18.49s/it]

  3%|▎         | 547/16104 [2:30:37<82:24:26, 19.07s/it]

  3%|▎         | 548/16104 [2:30:59<86:41:46, 20.06s/it]

  3%|▎         | 549/16104 [2:31:16<82:39:56, 19.13s/it]

  3%|▎         | 550/16104 [2:31:37<85:15:04, 19.73s/it]

  3%|▎         | 551/16104 [2:31:57<85:53:24, 19.88s/it]

  3%|▎         | 552/16104 [2:32:12<79:29:30, 18.40s/it]

  3%|▎         | 553/16104 [2:32:32<81:00:19, 18.75s/it]

  3%|▎         | 554/16104 [2:32:54<84:47:22, 19.63s/it]

  3%|▎         | 555/16104 [2:33:10<80:59:20, 18.75s/it]

  3%|▎         | 556/16104 [2:33:32<84:33:21, 19.58s/it]

  3%|▎         | 557/16104 [2:33:44<75:01:49, 17.37s/it]

  3%|▎         | 558/16104 [2:33:57<68:54:48, 15.96s/it]

  3%|▎         | 559/16104 [2:34:12<67:56:04, 15.73s/it]

  3%|▎         | 560/16104 [2:34:25<64:29:31, 14.94s/it]

  3%|▎         | 561/16104 [2:34:39<63:44:37, 14.76s/it]

  3%|▎         | 562/16104 [2:34:54<63:06:45, 14.62s/it]


  4%|▎         | 564/16104 [2:35:27<69:13:14, 16.04s/it]
{'loss': 0.5826, 'learning_rate': 1.9998705570818686e-06, 'rewards/chosen': -0.07466506958007812, 'rewards/rejected': -0.47945642471313477, 'rewards/accuracies': 0.75, 'rewards/margins': 0.40479135513305664, 'policy_logps/rejected': -419.3576965332031, 'policy_logps/chosen': -327.201171875, 'referece_logps/rejected': -414.5631103515625, 'referece_logps/chosen': -326.45452880859375, 'logits/rejected': -1.190413475036621, 'logits/chosen': -1.0754917860031128, 'epoch': 0.21}

  4%|▎         | 565/16104 [2:35:41<66:21:22, 15.37s/it]

  4%|▎         | 566/16104 [2:36:00<70:55:00, 16.43s/it]

  4%|▎         | 567/16104 [2:36:16<70:02:36, 16.23s/it]

  4%|▎         | 568/16104 [2:36:37<76:36:50, 17.75s/it]

  4%|▎         | 569/16104 [2:36:58<80:50:17, 18.73s/it]

  4%|▎         | 570/16104 [2:37:13<76:02:37, 17.62s/it]

  4%|▎         | 571/16104 [2:37:34<80:04:49, 18.56s/it]

  4%|▎         | 572/16104 [2:37:48<74:47:28, 17.34s/it]

  4%|▎         | 573/16104 [2:38:03<71:38:38, 16.61s/it]

  4%|▎         | 574/16104 [2:38:16<66:39:28, 15.45s/it]

  4%|▎         | 575/16104 [2:38:31<66:15:51, 15.36s/it]

  4%|▎         | 576/16104 [2:38:48<68:03:37, 15.78s/it]

  4%|▎         | 577/16104 [2:39:01<64:59:23, 15.07s/it]

  4%|▎         | 578/16104 [2:39:17<65:18:52, 15.14s/it]


  4%|▎         | 580/16104 [2:39:52<70:55:42, 16.45s/it]

  4%|▎         | 581/16104 [2:40:03<64:04:39, 14.86s/it]

  4%|▎         | 582/16104 [2:40:15<60:26:05, 14.02s/it]

  4%|▎         | 583/16104 [2:40:33<65:29:27, 15.19s/it]

  4%|▎         | 584/16104 [2:40:48<65:15:03, 15.14s/it]

  4%|▎         | 585/16104 [2:41:00<61:07:29, 14.18s/it]

  4%|▎         | 586/16104 [2:41:12<57:24:02, 13.32s/it]

  4%|▎         | 587/16104 [2:41:22<53:56:36, 12.52s/it]

  4%|▎         | 588/16104 [2:41:33<51:39:51, 11.99s/it]

  4%|▎         | 589/16104 [2:41:54<62:38:36, 14.54s/it]
{'loss': 0.6558, 'learning_rate': 1.9997770178245792e-06, 'rewards/chosen': -0.43573951721191406, 'rewards/rejected': -0.48764246702194214, 'rewards/accuracies': 0.5, 'rewards/margins': 0.05190295726060867, 'policy_logps/rejected': -403.07501220703125, 'policy_logps/chosen': -376.00433349609375, 'referece_logps/rejected': -398.1985778808594, 'referece_logps/chosen': -371.64697265625, 'logits/rejected': -0.3817141354084015, 'logits/chosen': -0.37202683091163635, 'epoch': 0.22}

  4%|▎         | 590/16104 [2:42:06<60:14:01, 13.98s/it]


  4%|▎         | 592/16104 [2:42:38<65:51:21, 15.28s/it]

  4%|▎         | 593/16104 [2:42:56<68:19:05, 15.86s/it]

  4%|▎         | 594/16104 [2:43:09<65:14:39, 15.14s/it]

  4%|▎         | 595/16104 [2:43:29<71:57:01, 16.70s/it]

  4%|▎         | 596/16104 [2:43:42<65:59:24, 15.32s/it]

  4%|▎         | 597/16104 [2:43:59<69:18:41, 16.09s/it]

  4%|▎         | 598/16104 [2:44:21<76:31:28, 17.77s/it]

  4%|▎         | 599/16104 [2:44:43<81:21:18, 18.89s/it]

  4%|▎         | 600/16104 [2:45:02<81:42:32, 18.97s/it]
{'loss': 0.6249, 'learning_rate': 1.999727852737949e-06, 'rewards/chosen': -0.6170681715011597, 'rewards/rejected': -0.8967177867889404, 'rewards/accuracies': 0.625, 'rewards/margins': 0.279649555683136, 'policy_logps/rejected': -447.4529724121094, 'policy_logps/chosen': -423.2513732910156, 'referece_logps/rejected': -438.48577880859375, 'referece_logps/chosen': -417.0806884765625, 'logits/rejected': -0.06753581017255783, 'logits/chosen': -0.002231912687420845, 'epoch': 0.22}

  4%|▎         | 601/16104 [2:45:18<78:27:03, 18.22s/it]


  4%|▎         | 603/16104 [2:45:45<67:06:00, 15.58s/it]
{'loss': 0.6179, 'learning_rate': 1.9997135948113166e-06, 'rewards/chosen': -0.4598269760608673, 'rewards/rejected': -0.43453139066696167, 'rewards/accuracies': 0.5, 'rewards/margins': -0.02529553696513176, 'policy_logps/rejected': -451.0629577636719, 'policy_logps/chosen': -412.26702880859375, 'referece_logps/rejected': -446.7176818847656, 'referece_logps/chosen': -407.6687927246094, 'logits/rejected': -0.5570635795593262, 'logits/chosen': -0.4192827045917511, 'epoch': 0.22}

  4%|▍         | 604/16104 [2:46:00<66:29:05, 15.44s/it]
[2024-04-05 18:11:29,425] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 605/16104 [2:46:22<74:54:50, 17.40s/it]


  4%|▍         | 607/16104 [2:47:01<80:06:05, 18.61s/it]

  4%|▍         | 608/16104 [2:47:18<77:39:43, 18.04s/it]
{'loss': 0.6028, 'learning_rate': 1.9996890227989294e-06, 'rewards/chosen': -0.3651271164417267, 'rewards/rejected': -0.4693363308906555, 'rewards/accuracies': 0.625, 'rewards/margins': 0.10420919954776764, 'policy_logps/rejected': -255.40081787109375, 'policy_logps/chosen': -252.64210510253906, 'referece_logps/rejected': -250.7074737548828, 'referece_logps/chosen': -248.99081420898438, 'logits/rejected': -0.5262999534606934, 'logits/chosen': -0.4939349889755249, 'epoch': 0.23}


  4%|▍         | 610/16104 [2:47:55<78:09:04, 18.16s/it]
{'loss': 0.5973, 'learning_rate': 1.999678910918137e-06, 'rewards/chosen': -0.09565220028162003, 'rewards/rejected': -0.5512220859527588, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4555698037147522, 'policy_logps/rejected': -432.6826171875, 'policy_logps/chosen': -318.9898681640625, 'referece_logps/rejected': -427.1703796386719, 'referece_logps/chosen': -318.03338623046875, 'logits/rejected': -0.7142371535301208, 'logits/chosen': -0.6599724292755127, 'epoch': 0.23}


  4%|▍         | 612/16104 [2:48:30<74:31:25, 17.32s/it]

  4%|▍         | 613/16104 [2:48:45<71:16:17, 16.56s/it]

  4%|▍         | 614/16104 [2:48:57<65:59:20, 15.34s/it]

  4%|▍         | 615/16104 [2:49:11<63:39:49, 14.80s/it]

  4%|▍         | 616/16104 [2:49:25<62:41:12, 14.57s/it]

  4%|▍         | 617/16104 [2:49:43<66:55:44, 15.56s/it]

  4%|▍         | 618/16104 [2:50:04<74:12:50, 17.25s/it]

  4%|▍         | 619/16104 [2:50:17<68:21:47, 15.89s/it]

  4%|▍         | 620/16104 [2:50:38<74:51:11, 17.40s/it]
{'loss': 0.5878, 'learning_rate': 1.9996259252200886e-06, 'rewards/chosen': -0.3490205705165863, 'rewards/rejected': -0.5303900837898254, 'rewards/accuracies': 0.375, 'rewards/margins': 0.18136949837207794, 'policy_logps/rejected': -247.19906616210938, 'policy_logps/chosen': -255.4901123046875, 'referece_logps/rejected': -241.89517211914062, 'referece_logps/chosen': -251.99990844726562, 'logits/rejected': -0.5538619160652161, 'logits/chosen': -0.557281494140625, 'epoch': 0.23}

  4%|▍         | 621/16104 [2:50:55<74:27:56, 17.31s/it]

  4%|▍         | 622/16104 [2:51:09<70:02:04, 16.29s/it]

  4%|▍         | 623/16104 [2:51:26<71:47:50, 16.70s/it]

  4%|▍         | 624/16104 [2:51:38<65:55:01, 15.33s/it]


  4%|▍         | 626/16104 [2:52:15<72:04:07, 16.76s/it]

  4%|▍         | 627/16104 [2:52:34<73:46:15, 17.16s/it]

  4%|▍         | 628/16104 [2:52:44<65:17:23, 15.19s/it]

  4%|▍         | 629/16104 [2:53:00<65:46:27, 15.30s/it]

  4%|▍         | 630/16104 [2:53:10<59:49:38, 13.92s/it]

  4%|▍         | 631/16104 [2:53:28<64:04:42, 14.91s/it]
{'loss': 0.675, 'learning_rate': 1.9995629705291703e-06, 'rewards/chosen': -0.40745970606803894, 'rewards/rejected': -0.6213943362236023, 'rewards/accuracies': 0.5, 'rewards/margins': 0.21393460035324097, 'policy_logps/rejected': -494.1096496582031, 'policy_logps/chosen': -398.6905822753906, 'referece_logps/rejected': -487.8957214355469, 'referece_logps/chosen': -394.6159362792969, 'logits/rejected': -0.2563696801662445, 'logits/chosen': -0.39709705114364624, 'epoch': 0.24}


  4%|▍         | 633/16104 [2:53:56<62:16:09, 14.49s/it]
{'loss': 0.6172, 'learning_rate': 1.999550998569155e-06, 'rewards/chosen': -0.5613191723823547, 'rewards/rejected': -0.6937056183815002, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1323864758014679, 'policy_logps/rejected': -298.7669677734375, 'policy_logps/chosen': -312.7125244140625, 'referece_logps/rejected': -291.82989501953125, 'referece_logps/chosen': -307.09930419921875, 'logits/rejected': -1.2468652725219727, 'logits/chosen': -1.2069003582000732, 'epoch': 0.24}


  4%|▍         | 635/16104 [2:54:34<72:30:48, 16.88s/it]

  4%|▍         | 636/16104 [2:54:54<77:42:50, 18.09s/it]

  4%|▍         | 637/16104 [2:55:16<82:27:02, 19.19s/it]

  4%|▍         | 638/16104 [2:55:38<85:39:14, 19.94s/it]

  4%|▍         | 639/16104 [2:56:00<89:01:02, 20.72s/it]

  4%|▍         | 640/16104 [2:56:16<82:41:35, 19.25s/it]
{'loss': 0.679, 'learning_rate': 1.999507823062984e-06, 'rewards/chosen': -0.4142632484436035, 'rewards/rejected': -0.5625762343406677, 'rewards/accuracies': 0.5, 'rewards/margins': 0.14831294119358063, 'policy_logps/rejected': -276.4369812011719, 'policy_logps/chosen': -262.35662841796875, 'referece_logps/rejected': -270.81121826171875, 'referece_logps/chosen': -258.2139892578125, 'logits/rejected': -0.5024040937423706, 'logits/chosen': -0.5324658155441284, 'epoch': 0.24}


  4%|▍         | 642/16104 [2:56:58<86:12:23, 20.07s/it]

  4%|▍         | 643/16104 [2:57:22<91:25:22, 21.29s/it]

  4%|▍         | 644/16104 [2:57:38<84:59:55, 19.79s/it]
{'loss': 0.6943, 'learning_rate': 1.9994822618384135e-06, 'rewards/chosen': -0.3347020447254181, 'rewards/rejected': -0.49050819873809814, 'rewards/accuracies': 0.625, 'rewards/margins': 0.15580615401268005, 'policy_logps/rejected': -352.2008056640625, 'policy_logps/chosen': -331.8263244628906, 'referece_logps/rejected': -347.2957458496094, 'referece_logps/chosen': -328.47930908203125, 'logits/rejected': -0.1499912142753601, 'logits/chosen': -0.30324214696884155, 'epoch': 0.24}


  4%|▍         | 646/16104 [2:58:15<81:30:21, 18.98s/it]
{'loss': 0.528, 'learning_rate': 1.9994692386400444e-06, 'rewards/chosen': -0.3734550476074219, 'rewards/rejected': -0.8998174667358398, 'rewards/accuracies': 0.875, 'rewards/margins': 0.526362419128418, 'policy_logps/rejected': -549.9361572265625, 'policy_logps/chosen': -348.9250183105469, 'referece_logps/rejected': -540.93798828125, 'referece_logps/chosen': -345.19049072265625, 'logits/rejected': -0.5130228996276855, 'logits/chosen': -0.4436632990837097, 'epoch': 0.24}
[2024-04-05 18:23:46,231] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 647/16104 [2:58:39<87:30:04, 20.38s/it]


  4%|▍         | 649/16104 [2:59:17<84:20:57, 19.65s/it]
{'loss': 0.6097, 'learning_rate': 1.9994494006158018e-06, 'rewards/chosen': -0.5609785318374634, 'rewards/rejected': -0.8501440286636353, 'rewards/accuracies': 0.75, 'rewards/margins': 0.28916555643081665, 'policy_logps/rejected': -268.496826171875, 'policy_logps/chosen': -342.7428894042969, 'referece_logps/rejected': -259.9953918457031, 'referece_logps/chosen': -337.1330871582031, 'logits/rejected': -0.13469254970550537, 'logits/chosen': -0.1466909945011139, 'epoch': 0.24}


  4%|▍         | 651/16104 [2:59:51<79:43:32, 18.57s/it]
[2024-04-05 18:24:57,962] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 652/16104 [3:00:04<72:32:10, 16.90s/it]
{'loss': 0.6347, 'learning_rate': 1.9994291987259633e-06, 'rewards/chosen': -0.4732799530029297, 'rewards/rejected': -0.5049434900283813, 'rewards/accuracies': 0.625, 'rewards/margins': 0.03166351467370987, 'policy_logps/rejected': -343.1102294921875, 'policy_logps/chosen': -313.75634765625, 'referece_logps/rejected': -338.0608215332031, 'referece_logps/chosen': -309.0235290527344, 'logits/rejected': -0.8412492275238037, 'logits/chosen': -0.8285719752311707, 'epoch': 0.24}

  4%|▍         | 653/16104 [3:00:15<65:16:36, 15.21s/it]

  4%|▍         | 654/16104 [3:00:35<71:24:42, 16.64s/it]


  4%|▍         | 656/16104 [3:01:04<66:06:36, 15.41s/it]

  4%|▍         | 657/16104 [3:01:24<72:26:21, 16.88s/it]

  4%|▍         | 658/16104 [3:01:43<74:28:32, 17.36s/it]

  4%|▍         | 659/16104 [3:01:54<65:51:48, 15.35s/it]

  4%|▍         | 660/16104 [3:02:04<59:59:32, 13.98s/it]
{'loss': 0.66, 'learning_rate': 1.99937354817761e-06, 'rewards/chosen': -0.601910412311554, 'rewards/rejected': -0.6350269317626953, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03311655670404434, 'policy_logps/rejected': -387.03497314453125, 'policy_logps/chosen': -338.9692687988281, 'referece_logps/rejected': -380.6847229003906, 'referece_logps/chosen': -332.9501953125, 'logits/rejected': -0.400992214679718, 'logits/chosen': -0.3269370496273041, 'epoch': 0.25}

  4%|▍         | 661/16104 [3:02:25<68:41:02, 16.01s/it]


  4%|▍         | 663/16104 [3:03:01<73:52:44, 17.22s/it]

  4%|▍         | 664/16104 [3:03:16<71:23:23, 16.65s/it]

  4%|▍         | 665/16104 [3:03:34<73:43:07, 17.19s/it]
{'loss': 0.6038, 'learning_rate': 1.999337452716334e-06, 'rewards/chosen': -0.2776748836040497, 'rewards/rejected': -0.4719011187553406, 'rewards/accuracies': 0.5, 'rewards/margins': 0.19422626495361328, 'policy_logps/rejected': -425.80572509765625, 'policy_logps/chosen': -405.87921142578125, 'referece_logps/rejected': -421.086669921875, 'referece_logps/chosen': -403.1024475097656, 'logits/rejected': -0.6954910159111023, 'logits/chosen': -0.5649592280387878, 'epoch': 0.25}


  4%|▍         | 667/16104 [3:04:16<82:06:00, 19.15s/it]
{'loss': 0.571, 'learning_rate': 1.999322731554885e-06, 'rewards/chosen': -0.28879499435424805, 'rewards/rejected': -0.3047468960285187, 'rewards/accuracies': 0.375, 'rewards/margins': 0.01595192402601242, 'policy_logps/rejected': -252.75563049316406, 'policy_logps/chosen': -432.38507080078125, 'referece_logps/rejected': -249.70816040039062, 'referece_logps/chosen': -429.4971008300781, 'logits/rejected': -0.6854228377342224, 'logits/chosen': -0.7321637272834778, 'epoch': 0.25}


  4%|▍         | 669/16104 [3:04:54<80:22:28, 18.75s/it]

  4%|▍         | 670/16104 [3:05:14<82:38:37, 19.28s/it]

  4%|▍         | 671/16104 [3:05:34<83:03:22, 19.37s/it]
{'loss': 0.5759, 'learning_rate': 1.9992928041417465e-06, 'rewards/chosen': -0.44039860367774963, 'rewards/rejected': -0.7372708320617676, 'rewards/accuracies': 0.5, 'rewards/margins': 0.29687222838401794, 'policy_logps/rejected': -428.1573181152344, 'policy_logps/chosen': -378.43408203125, 'referece_logps/rejected': -420.7846374511719, 'referece_logps/chosen': -374.03009033203125, 'logits/rejected': 0.3778032958507538, 'logits/chosen': 0.4284142851829529, 'epoch': 0.25}
[2024-04-05 18:31:02,665] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  4%|▍         | 673/16104 [3:06:13<81:54:51, 19.11s/it]
[2024-04-05 18:31:19,716] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 674/16104 [3:06:26<74:40:26, 17.42s/it]

  4%|▍         | 675/16104 [3:06:38<67:32:00, 15.76s/it]

  4%|▍         | 676/16104 [3:06:54<68:31:44, 15.99s/it]

  4%|▍         | 677/16104 [3:07:09<66:16:52, 15.47s/it]

  4%|▍         | 678/16104 [3:07:23<65:09:09, 15.20s/it]

  4%|▍         | 679/16104 [3:07:35<61:06:20, 14.26s/it]
{'loss': 0.6998, 'learning_rate': 1.999231009022853e-06, 'rewards/chosen': -0.27861112356185913, 'rewards/rejected': -0.19233065843582153, 'rewards/accuracies': 0.375, 'rewards/margins': -0.0862804427742958, 'policy_logps/rejected': -500.8701171875, 'policy_logps/chosen': -307.4342346191406, 'referece_logps/rejected': -498.94683837890625, 'referece_logps/chosen': -304.6481018066406, 'logits/rejected': -1.0634657144546509, 'logits/chosen': -1.1713086366653442, 'epoch': 0.25}


  4%|▍         | 681/16104 [3:08:03<59:36:31, 13.91s/it]

  4%|▍         | 682/16104 [3:08:23<67:16:56, 15.71s/it]

  4%|▍         | 683/16104 [3:08:44<75:00:12, 17.51s/it]
{'loss': 0.5919, 'learning_rate': 1.9991991413570934e-06, 'rewards/chosen': -0.2672497034072876, 'rewards/rejected': -0.8699893355369568, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6027395725250244, 'policy_logps/rejected': -319.5513610839844, 'policy_logps/chosen': -464.8580322265625, 'referece_logps/rejected': -310.8514709472656, 'referece_logps/chosen': -462.1855163574219, 'logits/rejected': -0.8654875755310059, 'logits/chosen': -0.803307294845581, 'epoch': 0.25}
[2024-04-05 18:34:08,757] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  4%|▍         | 685/16104 [3:09:21<76:45:01, 17.92s/it]

  4%|▍         | 686/16104 [3:09:37<74:48:37, 17.47s/it]

  4%|▍         | 687/16104 [3:09:54<74:45:53, 17.46s/it]
[2024-04-05 18:35:01,670] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 688/16104 [3:10:10<72:21:55, 16.90s/it]

  4%|▍         | 689/16104 [3:10:31<78:03:38, 18.23s/it]
{'loss': 0.6498, 'learning_rate': 1.9991501272834256e-06, 'rewards/chosen': -0.4711686968803406, 'rewards/rejected': -0.9740128517150879, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5028440356254578, 'policy_logps/rejected': -368.4869384765625, 'policy_logps/chosen': -316.18408203125, 'referece_logps/rejected': -358.7467956542969, 'referece_logps/chosen': -311.472412109375, 'logits/rejected': -0.14926055073738098, 'logits/chosen': -0.04110526293516159, 'epoch': 0.26}


  4%|▍         | 691/16104 [3:11:06<75:28:42, 17.63s/it]

  4%|▍         | 692/16104 [3:11:25<76:31:40, 17.88s/it]
{'loss': 0.6033, 'learning_rate': 1.999125074607136e-06, 'rewards/chosen': -0.8661870360374451, 'rewards/rejected': -0.7764705419540405, 'rewards/accuracies': 0.25, 'rewards/margins': -0.08971640467643738, 'policy_logps/rejected': -337.5539855957031, 'policy_logps/chosen': -360.28387451171875, 'referece_logps/rejected': -329.7892761230469, 'referece_logps/chosen': -351.62200927734375, 'logits/rejected': -0.6218160390853882, 'logits/chosen': -0.6498326063156128, 'epoch': 0.26}


  4%|▍         | 694/16104 [3:12:01<77:45:32, 18.17s/it]
{'loss': 0.5823, 'learning_rate': 1.9991081707404193e-06, 'rewards/chosen': -0.3016563355922699, 'rewards/rejected': -0.7138105630874634, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4121541976928711, 'policy_logps/rejected': -387.564453125, 'policy_logps/chosen': -386.28656005859375, 'referece_logps/rejected': -380.4263610839844, 'referece_logps/chosen': -383.27001953125, 'logits/rejected': 0.12410704046487808, 'logits/chosen': 0.18100005388259888, 'epoch': 0.26}


  4%|▍         | 696/16104 [3:12:25<64:59:09, 15.18s/it]

  4%|▍         | 697/16104 [3:12:43<68:50:12, 16.08s/it]

  4%|▍         | 698/16104 [3:12:55<62:44:30, 14.66s/it]

  4%|▍         | 699/16104 [3:13:15<70:10:37, 16.40s/it]
{'loss': 0.6556, 'learning_rate': 1.9990652038047844e-06, 'rewards/chosen': -0.5056591629981995, 'rewards/rejected': -0.37957850098609924, 'rewards/accuracies': 0.5, 'rewards/margins': -0.1260806918144226, 'policy_logps/rejected': -338.63189697265625, 'policy_logps/chosen': -317.5684814453125, 'referece_logps/rejected': -334.83612060546875, 'referece_logps/chosen': -312.5118713378906, 'logits/rejected': -0.1723456084728241, 'logits/chosen': -0.22831140458583832, 'epoch': 0.26}


  4%|▍         | 701/16104 [3:13:37<58:07:25, 13.58s/it]

  4%|▍         | 702/16104 [3:13:49<56:44:06, 13.26s/it]

  4%|▍         | 703/16104 [3:14:06<60:42:28, 14.19s/it]

  4%|▍         | 704/16104 [3:14:22<62:56:44, 14.71s/it]

  4%|▍         | 705/16104 [3:14:41<69:29:54, 16.25s/it]

  4%|▍         | 706/16104 [3:15:05<78:55:46, 18.45s/it]
{'loss': 0.5893, 'learning_rate': 1.9990033527182074e-06, 'rewards/chosen': -0.6092836856842041, 'rewards/rejected': -0.9470547437667847, 'rewards/accuracies': 0.625, 'rewards/margins': 0.33777111768722534, 'policy_logps/rejected': -324.7903137207031, 'policy_logps/chosen': -348.1043701171875, 'referece_logps/rejected': -315.3197937011719, 'referece_logps/chosen': -342.01153564453125, 'logits/rejected': -0.6801648736000061, 'logits/chosen': -0.6424919962882996, 'epoch': 0.26}

  4%|▍         | 707/16104 [3:15:18<71:53:35, 16.81s/it]
[2024-04-05 18:40:45,978] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  4%|▍         | 708/16104 [3:15:39<76:56:01, 17.99s/it]

  4%|▍         | 709/16104 [3:15:56<76:09:25, 17.81s/it]


  4%|▍         | 711/16104 [3:16:38<82:39:30, 19.33s/it]

  4%|▍         | 712/16104 [3:16:59<85:33:24, 20.01s/it]
{'loss': 0.5849, 'learning_rate': 1.9989487614493796e-06, 'rewards/chosen': -0.400084912776947, 'rewards/rejected': -0.5683032870292664, 'rewards/accuracies': 0.625, 'rewards/margins': 0.16821841895580292, 'policy_logps/rejected': -453.15692138671875, 'policy_logps/chosen': -487.25396728515625, 'referece_logps/rejected': -447.4738464355469, 'referece_logps/chosen': -483.253173828125, 'logits/rejected': -0.24291327595710754, 'logits/chosen': -0.18194982409477234, 'epoch': 0.27}

  4%|▍         | 713/16104 [3:17:15<79:47:48, 18.66s/it]


  4%|▍         | 715/16104 [3:17:40<66:54:30, 15.65s/it]

  4%|▍         | 716/16104 [3:17:56<67:08:41, 15.71s/it]
{'loss': 0.6472, 'learning_rate': 1.998911559080061e-06, 'rewards/chosen': -0.3849582374095917, 'rewards/rejected': -0.6474999785423279, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2625417709350586, 'policy_logps/rejected': -296.2738952636719, 'policy_logps/chosen': -264.9276428222656, 'referece_logps/rejected': -289.79888916015625, 'referece_logps/chosen': -261.07806396484375, 'logits/rejected': -0.29090261459350586, 'logits/chosen': -0.28474757075309753, 'epoch': 0.27}

  4%|▍         | 717/16104 [3:18:14<70:47:38, 16.56s/it]

  4%|▍         | 718/16104 [3:18:35<76:14:33, 17.84s/it]

  4%|▍         | 719/16104 [3:18:46<67:55:34, 15.89s/it]

  4%|▍         | 720/16104 [3:19:03<68:24:48, 16.01s/it]

  4%|▍         | 721/16104 [3:19:21<71:29:39, 16.73s/it]

  4%|▍         | 722/16104 [3:19:33<65:28:04, 15.32s/it]


  4%|▍         | 724/16104 [3:20:04<65:24:07, 15.31s/it]

  5%|▍         | 725/16104 [3:20:25<73:06:57, 17.12s/it]

  5%|▍         | 726/16104 [3:20:46<77:25:07, 18.12s/it]

  5%|▍         | 727/16104 [3:21:04<77:17:58, 18.10s/it]

  5%|▍         | 728/16104 [3:21:18<72:02:01, 16.87s/it]
{'loss': 0.5866, 'learning_rate': 1.998796072926217e-06, 'rewards/chosen': -0.5336739420890808, 'rewards/rejected': -0.7004104852676392, 'rewards/accuracies': 0.625, 'rewards/margins': 0.16673651337623596, 'policy_logps/rejected': -455.8203125, 'policy_logps/chosen': -375.2170104980469, 'referece_logps/rejected': -448.81622314453125, 'referece_logps/chosen': -369.8802490234375, 'logits/rejected': -0.1199842095375061, 'logits/chosen': -0.1270640343427658, 'epoch': 0.27}


  5%|▍         | 730/16104 [3:21:55<76:02:08, 17.80s/it]

  5%|▍         | 731/16104 [3:22:10<71:41:46, 16.79s/it]
{'loss': 0.6043, 'learning_rate': 1.998766292291793e-06, 'rewards/chosen': -0.30435627698898315, 'rewards/rejected': -0.7322673797607422, 'rewards/accuracies': 0.625, 'rewards/margins': 0.42791107296943665, 'policy_logps/rejected': -293.7107238769531, 'policy_logps/chosen': -321.3279724121094, 'referece_logps/rejected': -286.3880615234375, 'referece_logps/chosen': -318.284423828125, 'logits/rejected': 0.6681547164916992, 'logits/chosen': 0.5853087902069092, 'epoch': 0.27}

  5%|▍         | 732/16104 [3:22:31<77:34:34, 18.17s/it]

  5%|▍         | 733/16104 [3:22:47<74:35:06, 17.47s/it]

  5%|▍         | 734/16104 [3:22:59<67:12:01, 15.74s/it]

  5%|▍         | 735/16104 [3:23:11<62:22:12, 14.61s/it]


  5%|▍         | 737/16104 [3:23:44<67:53:35, 15.91s/it]
{'loss': 0.6019, 'learning_rate': 1.998705640183221e-06, 'rewards/chosen': -0.5596290826797485, 'rewards/rejected': -0.49892139434814453, 'rewards/accuracies': 0.375, 'rewards/margins': -0.06070765107870102, 'policy_logps/rejected': -437.26519775390625, 'policy_logps/chosen': -315.4654541015625, 'referece_logps/rejected': -432.2760009765625, 'referece_logps/chosen': -309.8691711425781, 'logits/rejected': -0.8219251036643982, 'logits/chosen': -0.9562303423881531, 'epoch': 0.27}

  5%|▍         | 738/16104 [3:24:03<72:43:25, 17.04s/it]

  5%|▍         | 739/16104 [3:24:21<74:06:19, 17.36s/it]

  5%|▍         | 740/16104 [3:24:32<65:54:43, 15.44s/it]


  5%|▍         | 742/16104 [3:25:12<75:13:58, 17.63s/it]
{'loss': 0.6463, 'learning_rate': 1.998653985771534e-06, 'rewards/chosen': -0.4746282398700714, 'rewards/rejected': -0.5137909650802612, 'rewards/accuracies': 0.625, 'rewards/margins': 0.03916272521018982, 'policy_logps/rejected': -382.0799865722656, 'policy_logps/chosen': -488.164794921875, 'referece_logps/rejected': -376.94207763671875, 'referece_logps/chosen': -483.41851806640625, 'logits/rejected': -0.3668738603591919, 'logits/chosen': -0.6538633108139038, 'epoch': 0.28}


  5%|▍         | 744/16104 [3:25:40<66:04:16, 15.49s/it]
{'loss': 0.6129, 'learning_rate': 1.998633041222571e-06, 'rewards/chosen': -0.5758786201477051, 'rewards/rejected': -1.0175789594650269, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4417003095149994, 'policy_logps/rejected': -298.1806945800781, 'policy_logps/chosen': -344.7325134277344, 'referece_logps/rejected': -288.0049133300781, 'referece_logps/chosen': -338.9737548828125, 'logits/rejected': -1.0512820482254028, 'logits/chosen': -1.1416099071502686, 'epoch': 0.28}
[2024-04-05 18:51:07,782] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 745/16104 [3:26:01<72:39:46, 17.03s/it]

  5%|▍         | 746/16104 [3:26:23<79:52:48, 18.72s/it]
[2024-04-05 18:51:46,192] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 747/16104 [3:26:39<76:03:03, 17.83s/it]
[2024-04-05 18:52:06,494] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 748/16104 [3:26:59<79:12:44, 18.57s/it]


  5%|▍         | 750/16104 [3:27:30<71:47:44, 16.83s/it]
[2024-04-05 18:52:37,174] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6783, 'learning_rate': 1.9985692380736553e-06, 'rewards/chosen': -0.48793306946754456, 'rewards/rejected': -0.8798190951347351, 'rewards/accuracies': 0.625, 'rewards/margins': 0.39188605546951294, 'policy_logps/rejected': -357.5831604003906, 'policy_logps/chosen': -305.7612609863281, 'referece_logps/rejected': -348.78497314453125, 'referece_logps/chosen': -300.8819580078125, 'logits/rejected': 0.3218609392642975, 'logits/chosen': 0.5348502993583679, 'epoch': 0.28}

  5%|▍         | 751/16104 [3:27:41<63:53:14, 14.98s/it]


  5%|▍         | 753/16104 [3:28:12<64:58:01, 15.24s/it]
{'loss': 0.6562, 'learning_rate': 1.998536791175619e-06, 'rewards/chosen': -0.25776559114456177, 'rewards/rejected': -0.4664058983325958, 'rewards/accuracies': 0.75, 'rewards/margins': 0.20864029228687286, 'policy_logps/rejected': -422.0470886230469, 'policy_logps/chosen': -396.6115417480469, 'referece_logps/rejected': -417.383056640625, 'referece_logps/chosen': -394.0338439941406, 'logits/rejected': -0.2985905408859253, 'logits/chosen': -0.1385800838470459, 'epoch': 0.28}

  5%|▍         | 754/16104 [3:28:23<59:38:52, 13.99s/it]


  5%|▍         | 756/16104 [3:28:50<57:43:56, 13.54s/it]

  5%|▍         | 757/16104 [3:29:10<65:34:22, 15.38s/it]

  5%|▍         | 758/16104 [3:29:21<59:42:40, 14.01s/it]
{'loss': 0.617, 'learning_rate': 1.998481905166238e-06, 'rewards/chosen': -0.7548286318778992, 'rewards/rejected': -0.7997073531150818, 'rewards/accuracies': 0.5, 'rewards/margins': 0.044878795742988586, 'policy_logps/rejected': -450.48992919921875, 'policy_logps/chosen': -543.4090576171875, 'referece_logps/rejected': -442.49285888671875, 'referece_logps/chosen': -535.8607788085938, 'logits/rejected': -0.038772374391555786, 'logits/chosen': -0.2610042095184326, 'epoch': 0.28}


  5%|▍         | 760/16104 [3:29:48<60:26:23, 14.18s/it]
{'loss': 0.6696, 'learning_rate': 1.9984596680267423e-06, 'rewards/chosen': -0.5406456589698792, 'rewards/rejected': -0.7952504754066467, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2546048164367676, 'policy_logps/rejected': -291.94287109375, 'policy_logps/chosen': -320.1200866699219, 'referece_logps/rejected': -283.9903564453125, 'referece_logps/chosen': -314.713623046875, 'logits/rejected': -0.19196870923042297, 'logits/chosen': -0.012887135148048401, 'epoch': 0.28}

  5%|▍         | 761/16104 [3:30:09<68:53:07, 16.16s/it]

  5%|▍         | 762/16104 [3:30:27<70:51:23, 16.63s/it]

  5%|▍         | 763/16104 [3:30:38<63:19:45, 14.86s/it]

  5%|▍         | 764/16104 [3:30:55<67:04:47, 15.74s/it]
[2024-04-05 18:56:24,387] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 765/16104 [3:31:17<74:54:11, 17.58s/it]


  5%|▍         | 767/16104 [3:31:55<78:15:14, 18.37s/it]
{'loss': 0.6445, 'learning_rate': 1.9983805657938955e-06, 'rewards/chosen': -0.3937768042087555, 'rewards/rejected': -0.9898437857627869, 'rewards/accuracies': 0.875, 'rewards/margins': 0.596066951751709, 'policy_logps/rejected': -307.7146301269531, 'policy_logps/chosen': -498.28594970703125, 'referece_logps/rejected': -297.81622314453125, 'referece_logps/chosen': -494.3481750488281, 'logits/rejected': 0.10745254158973694, 'logits/chosen': -0.06669086217880249, 'epoch': 0.29}


  5%|▍         | 769/16104 [3:32:28<73:10:15, 17.18s/it]

  5%|▍         | 770/16104 [3:32:42<69:15:56, 16.26s/it]
{'loss': 0.5605, 'learning_rate': 1.9983460590336457e-06, 'rewards/chosen': -0.36346763372421265, 'rewards/rejected': -1.0921123027801514, 'rewards/accuracies': 0.75, 'rewards/margins': 0.728644609451294, 'policy_logps/rejected': -354.5618591308594, 'policy_logps/chosen': -421.80450439453125, 'referece_logps/rejected': -343.6407775878906, 'referece_logps/chosen': -418.1697998046875, 'logits/rejected': -0.8362212181091309, 'logits/chosen': -0.71037358045578, 'epoch': 0.29}

  5%|▍         | 771/16104 [3:33:03<75:06:57, 17.64s/it]

  5%|▍         | 772/16104 [3:33:25<80:51:09, 18.98s/it]

  5%|▍         | 773/16104 [3:33:42<77:43:04, 18.25s/it]

  5%|▍         | 774/16104 [3:33:55<71:12:40, 16.72s/it]


  5%|▍         | 776/16104 [3:34:33<74:22:33, 17.47s/it]

  5%|▍         | 777/16104 [3:34:48<72:16:44, 16.98s/it]
{'loss': 0.5737, 'learning_rate': 1.998264129810942e-06, 'rewards/chosen': -0.4969000220298767, 'rewards/rejected': -1.0075424909591675, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5106423497200012, 'policy_logps/rejected': -315.43353271484375, 'policy_logps/chosen': -383.5963134765625, 'referece_logps/rejected': -305.35809326171875, 'referece_logps/chosen': -378.6273193359375, 'logits/rejected': -1.245375156402588, 'logits/chosen': -1.4112423658370972, 'epoch': 0.29}


  5%|▍         | 779/16104 [3:35:27<76:34:57, 17.99s/it]

  5%|▍         | 780/16104 [3:35:47<78:57:51, 18.55s/it]

  5%|▍         | 781/16104 [3:36:07<80:45:24, 18.97s/it]
[2024-04-05 19:01:13,950] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6499, 'learning_rate': 1.99821642470738e-06, 'rewards/chosen': -0.526402473449707, 'rewards/rejected': -0.5324150323867798, 'rewards/accuracies': 0.625, 'rewards/margins': 0.00601254403591156, 'policy_logps/rejected': -455.61602783203125, 'policy_logps/chosen': -404.44036865234375, 'referece_logps/rejected': -450.2919006347656, 'referece_logps/chosen': -399.17633056640625, 'logits/rejected': -0.6302544474601746, 'logits/chosen': -0.5990113019943237, 'epoch': 0.29}

  5%|▍         | 782/16104 [3:36:20<73:08:51, 17.19s/it]


  5%|▍         | 784/16104 [3:36:44<62:27:30, 14.68s/it]
{'loss': 0.6598, 'learning_rate': 1.9981802218918515e-06, 'rewards/chosen': -0.2950838506221771, 'rewards/rejected': -0.5037301778793335, 'rewards/accuracies': 0.5, 'rewards/margins': 0.20864638686180115, 'policy_logps/rejected': -472.83197021484375, 'policy_logps/chosen': -356.02618408203125, 'referece_logps/rejected': -467.794677734375, 'referece_logps/chosen': -353.0753479003906, 'logits/rejected': -0.9047390222549438, 'logits/chosen': -0.8335290551185608, 'epoch': 0.29}
[2024-04-05 19:02:13,450] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  5%|▍         | 786/16104 [3:37:25<73:45:33, 17.33s/it]
[2024-04-05 19:02:31,925] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▍         | 787/16104 [3:37:43<75:06:08, 17.65s/it]
{'loss': 0.6257, 'learning_rate': 1.998143655672791e-06, 'rewards/chosen': -0.8129227161407471, 'rewards/rejected': -0.6205838918685913, 'rewards/accuracies': 0.25, 'rewards/margins': -0.1923387497663498, 'policy_logps/rejected': -583.9471435546875, 'policy_logps/chosen': -664.162353515625, 'referece_logps/rejected': -577.7413330078125, 'referece_logps/chosen': -656.0331420898438, 'logits/rejected': -0.6501503586769104, 'logits/chosen': -0.6157993078231812, 'epoch': 0.29}


  5%|▍         | 789/16104 [3:38:13<69:15:46, 16.28s/it]
{'loss': 0.5894, 'learning_rate': 1.998119076309136e-06, 'rewards/chosen': -0.5380344986915588, 'rewards/rejected': -0.6391289234161377, 'rewards/accuracies': 0.5, 'rewards/margins': 0.10109442472457886, 'policy_logps/rejected': -219.41525268554688, 'policy_logps/chosen': -305.746826171875, 'referece_logps/rejected': -213.02395629882812, 'referece_logps/chosen': -300.366455078125, 'logits/rejected': -0.7554873824119568, 'logits/chosen': -0.767945408821106, 'epoch': 0.29}


  5%|▍         | 791/16104 [3:38:51<74:31:59, 17.52s/it]

  5%|▍         | 792/16104 [3:39:09<75:01:18, 17.64s/it]
{'loss': 0.6473, 'learning_rate': 1.998081904447173e-06, 'rewards/chosen': -0.7615259289741516, 'rewards/rejected': -0.8262612819671631, 'rewards/accuracies': 0.5, 'rewards/margins': 0.06473540514707565, 'policy_logps/rejected': -402.3367919921875, 'policy_logps/chosen': -303.166015625, 'referece_logps/rejected': -394.07421875, 'referece_logps/chosen': -295.5507507324219, 'logits/rejected': -0.325093150138855, 'logits/chosen': -0.24776779115200043, 'epoch': 0.3}


  5%|▍         | 794/16104 [3:39:47<77:43:10, 18.28s/it]

  5%|▍         | 795/16104 [3:40:03<75:17:39, 17.71s/it]

  5%|▍         | 796/16104 [3:40:21<75:18:50, 17.71s/it]

  5%|▍         | 797/16104 [3:40:37<73:05:36, 17.19s/it]
{'loss': 0.564, 'learning_rate': 1.9980191438667835e-06, 'rewards/chosen': -0.5066944360733032, 'rewards/rejected': -0.685681164264679, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17898672819137573, 'policy_logps/rejected': -495.2057800292969, 'policy_logps/chosen': -409.2289123535156, 'referece_logps/rejected': -488.34893798828125, 'referece_logps/chosen': -404.1619873046875, 'logits/rejected': -1.412540078163147, 'logits/chosen': -1.2081513404846191, 'epoch': 0.3}


  5%|▍         | 799/16104 [3:41:01<61:51:11, 14.55s/it]

  5%|▍         | 800/16104 [3:41:13<58:57:32, 13.87s/it]
{'loss': 0.5994, 'learning_rate': 1.997981003054621e-06, 'rewards/chosen': -0.2948010563850403, 'rewards/rejected': -0.41995611786842346, 'rewards/accuracies': 0.75, 'rewards/margins': 0.12515506148338318, 'policy_logps/rejected': -410.1153869628906, 'policy_logps/chosen': -298.4290771484375, 'referece_logps/rejected': -405.91583251953125, 'referece_logps/chosen': -295.4810791015625, 'logits/rejected': -1.1589070558547974, 'logits/chosen': -1.1877890825271606, 'epoch': 0.3}

  5%|▍         | 801/16104 [3:41:34<67:42:08, 15.93s/it]


  5%|▍         | 803/16104 [3:42:09<71:16:58, 16.77s/it]

  5%|▍         | 804/16104 [3:42:27<72:51:41, 17.14s/it]

  5%|▍         | 805/16104 [3:42:47<76:48:32, 18.07s/it]

  5%|▌         | 806/16104 [3:43:02<71:52:53, 16.92s/it]

  5%|▌         | 807/16104 [3:43:17<69:53:23, 16.45s/it]

  5%|▌         | 808/16104 [3:43:33<69:54:36, 16.45s/it]
{'loss': 0.7037, 'learning_rate': 1.99787751797542e-06, 'rewards/chosen': -0.72568279504776, 'rewards/rejected': -0.5913947820663452, 'rewards/accuracies': 0.5, 'rewards/margins': -0.13428811728954315, 'policy_logps/rejected': -385.6297607421875, 'policy_logps/chosen': -285.8871154785156, 'referece_logps/rejected': -379.7157897949219, 'referece_logps/chosen': -278.63031005859375, 'logits/rejected': -1.2637537717819214, 'logits/chosen': -1.2430751323699951, 'epoch': 0.3}


  5%|▌         | 810/16104 [3:44:09<73:26:47, 17.29s/it]

  5%|▌         | 811/16104 [3:44:26<72:30:11, 17.07s/it]

  5%|▌         | 812/16104 [3:44:49<81:11:05, 19.11s/it]
{'loss': 0.6166, 'learning_rate': 1.9978248066367877e-06, 'rewards/chosen': -0.6546801328659058, 'rewards/rejected': -1.1725361347198486, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5178560614585876, 'policy_logps/rejected': -308.111328125, 'policy_logps/chosen': -352.5163269042969, 'referece_logps/rejected': -296.3859558105469, 'referece_logps/chosen': -345.96954345703125, 'logits/rejected': -0.7014908194541931, 'logits/chosen': -0.6199998259544373, 'epoch': 0.3}

  5%|▌         | 813/16104 [3:45:08<80:22:34, 18.92s/it]


  5%|▌         | 815/16104 [3:45:39<72:51:46, 17.16s/it]

  5%|▌         | 816/16104 [3:45:55<71:12:40, 16.77s/it]
{'loss': 0.5441, 'learning_rate': 1.9977714494774837e-06, 'rewards/chosen': -0.483699768781662, 'rewards/rejected': -0.7601533532142639, 'rewards/accuracies': 0.75, 'rewards/margins': 0.27645349502563477, 'policy_logps/rejected': -202.3785400390625, 'policy_logps/chosen': -342.026611328125, 'referece_logps/rejected': -194.7770233154297, 'referece_logps/chosen': -337.1896057128906, 'logits/rejected': -1.395684003829956, 'logits/chosen': -1.3386470079421997, 'epoch': 0.3}


  5%|▌         | 818/16104 [3:46:27<69:22:57, 16.34s/it]
{'loss': 0.6075, 'learning_rate': 1.9977445287258553e-06, 'rewards/chosen': -0.5697528719902039, 'rewards/rejected': -0.6813331842422485, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1115802675485611, 'policy_logps/rejected': -508.50042724609375, 'policy_logps/chosen': -404.6429138183594, 'referece_logps/rejected': -501.6870422363281, 'referece_logps/chosen': -398.9453125, 'logits/rejected': 0.20802970230579376, 'logits/chosen': 0.29174572229385376, 'epoch': 0.3}

  5%|▌         | 819/16104 [3:46:41<65:14:12, 15.36s/it]

  5%|▌         | 820/16104 [3:46:51<59:23:22, 13.99s/it]


  5%|▌         | 822/16104 [3:47:22<60:17:18, 14.20s/it]
{'loss': 0.6717, 'learning_rate': 1.997690202900426e-06, 'rewards/chosen': -0.4620155394077301, 'rewards/rejected': -0.6434603333473206, 'rewards/accuracies': 0.625, 'rewards/margins': 0.18144476413726807, 'policy_logps/rejected': -382.4144287109375, 'policy_logps/chosen': -375.9533996582031, 'referece_logps/rejected': -375.97979736328125, 'referece_logps/chosen': -371.33319091796875, 'logits/rejected': -1.0598533153533936, 'logits/chosen': -1.049883484840393, 'epoch': 0.31}

  5%|▌         | 823/16104 [3:47:32<55:45:00, 13.13s/it]

  5%|▌         | 824/16104 [3:47:43<52:57:49, 12.48s/it]

  5%|▌         | 825/16104 [3:47:57<54:23:50, 12.82s/it]

  5%|▌         | 826/16104 [3:48:10<54:58:29, 12.95s/it]


  5%|▌         | 828/16104 [3:48:46<67:04:55, 15.81s/it]
{'loss': 0.5694, 'learning_rate': 1.997607503422973e-06, 'rewards/chosen': -0.39589378237724304, 'rewards/rejected': -1.1036813259124756, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7077876329421997, 'policy_logps/rejected': -244.71421813964844, 'policy_logps/chosen': -401.5691833496094, 'referece_logps/rejected': -233.67742919921875, 'referece_logps/chosen': -397.61016845703125, 'logits/rejected': 0.4052443504333496, 'logits/chosen': 0.39446061849594116, 'epoch': 0.31}

  5%|▌         | 829/16104 [3:49:08<74:50:48, 17.64s/it]

  5%|▌         | 830/16104 [3:49:25<73:56:20, 17.43s/it]
[2024-04-05 19:14:48,500] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▌         | 831/16104 [3:49:41<73:05:11, 17.23s/it]


  5%|▌         | 833/16104 [3:50:10<65:27:05, 15.43s/it]
{'loss': 0.6475, 'learning_rate': 1.9975374774241156e-06, 'rewards/chosen': -0.3646995723247528, 'rewards/rejected': -0.39068394899368286, 'rewards/accuracies': 0.625, 'rewards/margins': 0.025984395295381546, 'policy_logps/rejected': -476.6295166015625, 'policy_logps/chosen': -539.4844360351562, 'referece_logps/rejected': -472.7226867675781, 'referece_logps/chosen': -535.8374633789062, 'logits/rejected': 0.6385913491249084, 'logits/chosen': 0.6426946520805359, 'epoch': 0.31}

  5%|▌         | 834/16104 [3:50:21<59:29:24, 14.03s/it]


  5%|▌         | 836/16104 [3:50:42<52:05:26, 12.28s/it]

  5%|▌         | 837/16104 [3:50:54<51:40:19, 12.18s/it]

  5%|▌         | 838/16104 [3:51:14<61:34:55, 14.52s/it]
{'loss': 0.6049, 'learning_rate': 1.9974664426210636e-06, 'rewards/chosen': -0.5408788919448853, 'rewards/rejected': -0.5226744413375854, 'rewards/accuracies': 0.375, 'rewards/margins': -0.018204402178525925, 'policy_logps/rejected': -310.1260681152344, 'policy_logps/chosen': -470.56927490234375, 'referece_logps/rejected': -304.8993225097656, 'referece_logps/chosen': -465.1605224609375, 'logits/rejected': -0.2052064687013626, 'logits/chosen': -0.11552713811397552, 'epoch': 0.31}

  5%|▌         | 839/16104 [3:51:25<57:19:02, 13.52s/it]

  5%|▌         | 840/16104 [3:51:48<68:45:53, 16.22s/it]

  5%|▌         | 841/16104 [3:51:59<63:15:13, 14.92s/it]

  5%|▌         | 842/16104 [3:52:13<61:15:24, 14.45s/it]

  5%|▌         | 843/16104 [3:52:32<67:42:58, 15.97s/it]

  5%|▌         | 844/16104 [3:52:45<63:26:51, 14.97s/it]

  5%|▌         | 845/16104 [3:53:03<66:42:56, 15.74s/it]

  5%|▌         | 846/16104 [3:53:19<67:45:42, 15.99s/it]

  5%|▌         | 847/16104 [3:53:39<73:14:05, 17.28s/it]

  5%|▌         | 848/16104 [3:53:55<70:36:54, 16.66s/it]


  5%|▌         | 850/16104 [3:54:34<77:53:34, 18.38s/it]
{'loss': 0.5972, 'learning_rate': 1.9972918436046334e-06, 'rewards/chosen': -0.15882986783981323, 'rewards/rejected': -0.43837469816207886, 'rewards/accuracies': 0.5, 'rewards/margins': 0.27954477071762085, 'policy_logps/rejected': -318.22064208984375, 'policy_logps/chosen': -512.7020874023438, 'referece_logps/rejected': -313.8368835449219, 'referece_logps/chosen': -511.1138000488281, 'logits/rejected': -0.28594234585762024, 'logits/chosen': -0.49955955147743225, 'epoch': 0.32}

  5%|▌         | 851/16104 [3:54:56<81:33:34, 19.25s/it]

  5%|▌         | 852/16104 [3:55:08<72:56:59, 17.22s/it]

  5%|▌         | 853/16104 [3:55:27<75:00:59, 17.71s/it]
[2024-04-05 19:20:52,906] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▌         | 854/16104 [3:55:46<76:29:48, 18.06s/it]

  5%|▌         | 855/16104 [3:56:03<75:29:59, 17.82s/it]

  5%|▌         | 856/16104 [3:56:25<80:18:16, 18.96s/it]

  5%|▌         | 857/16104 [3:56:43<80:03:32, 18.90s/it]

  5%|▌         | 858/16104 [3:57:02<79:49:40, 18.85s/it]

  5%|▌         | 859/16104 [3:57:25<84:50:37, 20.04s/it]

  5%|▌         | 860/16104 [3:57:41<79:42:57, 18.83s/it]

  5%|▌         | 861/16104 [3:58:02<82:13:22, 19.42s/it]

  5%|▌         | 862/16104 [3:58:23<84:37:51, 19.99s/it]

  5%|▌         | 863/16104 [3:58:42<83:29:51, 19.72s/it]

  5%|▌         | 864/16104 [3:58:54<73:33:54, 17.38s/it]

  5%|▌         | 865/16104 [3:59:17<80:28:52, 19.01s/it]

  5%|▌         | 866/16104 [3:59:33<77:23:43, 18.28s/it]

  5%|▌         | 867/16104 [3:59:50<75:07:36, 17.75s/it]

  5%|▌         | 868/16104 [4:00:06<73:08:32, 17.28s/it]

  5%|▌         | 869/16104 [4:00:17<65:25:31, 15.46s/it]

  5%|▌         | 870/16104 [4:00:34<66:34:25, 15.73s/it]

  5%|▌         | 871/16104 [4:00:45<61:08:32, 14.45s/it]


  5%|▌         | 873/16104 [4:01:15<61:47:34, 14.61s/it]
{'loss': 0.5563, 'learning_rate': 1.9969409586450876e-06, 'rewards/chosen': -0.7601074576377869, 'rewards/rejected': -1.3416244983673096, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5815170407295227, 'policy_logps/rejected': -424.3758544921875, 'policy_logps/chosen': -455.5442199707031, 'referece_logps/rejected': -410.9596252441406, 'referece_logps/chosen': -447.9431457519531, 'logits/rejected': -0.8891474604606628, 'logits/chosen': -0.776702344417572, 'epoch': 0.33}
[2024-04-05 19:26:40,657] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  5%|▌         | 875/16104 [4:01:53<71:26:32, 16.89s/it]
{'loss': 0.5478, 'learning_rate': 1.9969094385988256e-06, 'rewards/chosen': -0.3674188256263733, 'rewards/rejected': -0.9816232919692993, 'rewards/accuracies': 1.0, 'rewards/margins': 0.6142044067382812, 'policy_logps/rejected': -313.7889709472656, 'policy_logps/chosen': -382.5203857421875, 'referece_logps/rejected': -303.97271728515625, 'referece_logps/chosen': -378.84619140625, 'logits/rejected': -0.10870399326086044, 'logits/chosen': -0.09124008566141129, 'epoch': 0.33}

  5%|▌         | 876/16104 [4:02:10<71:57:02, 17.01s/it]

  5%|▌         | 877/16104 [4:02:24<68:48:28, 16.27s/it]
[2024-04-05 19:27:52,813] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  5%|▌         | 878/16104 [4:02:46<74:59:08, 17.73s/it]


  5%|▌         | 880/16104 [4:03:17<70:07:55, 16.58s/it]
{'loss': 0.6285, 'learning_rate': 1.9968299327759985e-06, 'rewards/chosen': -0.632591962814331, 'rewards/rejected': -0.9984245896339417, 'rewards/accuracies': 0.75, 'rewards/margins': 0.36583250761032104, 'policy_logps/rejected': -338.1602478027344, 'policy_logps/chosen': -327.3827819824219, 'referece_logps/rejected': -328.176025390625, 'referece_logps/chosen': -321.056884765625, 'logits/rejected': -0.8069490790367126, 'logits/chosen': -0.9225326776504517, 'epoch': 0.33}

  5%|▌         | 881/16104 [4:03:34<71:20:04, 16.87s/it]

  5%|▌         | 882/16104 [4:03:49<68:52:00, 16.29s/it]

  5%|▌         | 883/16104 [4:04:06<69:13:10, 16.37s/it]

  5%|▌         | 884/16104 [4:04:28<76:21:19, 18.06s/it]

  5%|▌         | 885/16104 [4:04:46<76:09:30, 18.02s/it]

  6%|▌         | 886/16104 [4:05:06<78:35:44, 18.59s/it]

  6%|▌         | 887/16104 [4:05:24<78:51:20, 18.66s/it]


  6%|▌         | 889/16104 [4:05:53<70:34:21, 16.70s/it]
{'loss': 0.5913, 'learning_rate': 1.9966842819661714e-06, 'rewards/chosen': -0.43122193217277527, 'rewards/rejected': -0.8033703565597534, 'rewards/accuracies': 0.625, 'rewards/margins': 0.37214839458465576, 'policy_logps/rejected': -330.27252197265625, 'policy_logps/chosen': -428.28350830078125, 'referece_logps/rejected': -322.2388000488281, 'referece_logps/chosen': -423.9713134765625, 'logits/rejected': -0.7258758544921875, 'logits/chosen': -0.7354088425636292, 'epoch': 0.33}

  6%|▌         | 890/16104 [4:06:11<72:54:51, 17.25s/it]

  6%|▌         | 891/16104 [4:06:26<69:23:33, 16.42s/it]

  6%|▌         | 892/16104 [4:06:49<77:43:42, 18.39s/it]

  6%|▌         | 893/16104 [4:07:12<84:20:52, 19.96s/it]


  6%|▌         | 895/16104 [4:07:55<87:13:17, 20.65s/it]
{'loss': 0.5946, 'learning_rate': 1.9965853671022763e-06, 'rewards/chosen': -0.742932140827179, 'rewards/rejected': -0.9518165588378906, 'rewards/accuracies': 0.75, 'rewards/margins': 0.20888444781303406, 'policy_logps/rejected': -331.5059814453125, 'policy_logps/chosen': -337.0052490234375, 'referece_logps/rejected': -321.9878234863281, 'referece_logps/chosen': -329.575927734375, 'logits/rejected': -0.3866819739341736, 'logits/chosen': -0.18365374207496643, 'epoch': 0.33}

  6%|▌         | 896/16104 [4:08:13<84:11:50, 19.93s/it]

  6%|▌         | 897/16104 [4:08:33<83:24:59, 19.75s/it]
[2024-04-05 19:34:01,136] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 898/16104 [4:08:54<85:26:25, 20.23s/it]
[2024-04-05 19:34:17,068] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  6%|▌         | 900/16104 [4:09:31<83:02:13, 19.66s/it]
[2024-04-05 19:34:38,415] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 901/16104 [4:09:53<85:54:44, 20.34s/it]
[2024-04-05 19:35:00,350] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 902/16104 [4:10:05<75:17:08, 17.83s/it]

  6%|▌         | 903/16104 [4:10:19<70:38:03, 16.73s/it]

  6%|▌         | 904/16104 [4:10:32<65:02:54, 15.41s/it]
{'loss': 0.6375, 'learning_rate': 1.996434273680533e-06, 'rewards/chosen': -0.6935186386108398, 'rewards/rejected': -0.9055505990982056, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21203196048736572, 'policy_logps/rejected': -437.7814636230469, 'policy_logps/chosen': -296.98089599609375, 'referece_logps/rejected': -428.7259521484375, 'referece_logps/chosen': -290.04571533203125, 'logits/rejected': -0.5645344257354736, 'logits/chosen': -0.371466726064682, 'epoch': 0.34}

  6%|▌         | 905/16104 [4:10:50<68:55:26, 16.33s/it]

  6%|▌         | 906/16104 [4:11:08<70:43:22, 16.75s/it]

  6%|▌         | 907/16104 [4:11:24<69:56:51, 16.57s/it]
[2024-04-05 19:36:49,037] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 908/16104 [4:11:42<71:36:19, 16.96s/it]

  6%|▌         | 909/16104 [4:11:52<63:32:56, 15.06s/it]


  6%|▌         | 911/16104 [4:12:28<69:50:20, 16.55s/it]
{'loss': 0.6841, 'learning_rate': 1.9963144993271165e-06, 'rewards/chosen': -0.4073030948638916, 'rewards/rejected': -0.6902018785476685, 'rewards/accuracies': 0.625, 'rewards/margins': 0.28289881348609924, 'policy_logps/rejected': -295.16986083984375, 'policy_logps/chosen': -530.882568359375, 'referece_logps/rejected': -288.267822265625, 'referece_logps/chosen': -526.8095092773438, 'logits/rejected': -0.9611835479736328, 'logits/chosen': -1.1092519760131836, 'epoch': 0.34}

  6%|▌         | 912/16104 [4:12:39<62:38:34, 14.84s/it]

  6%|▌         | 913/16104 [4:12:57<66:36:44, 15.79s/it]

  6%|▌         | 914/16104 [4:13:17<72:27:06, 17.17s/it]


  6%|▌         | 916/16104 [4:13:56<77:16:26, 18.32s/it]

  6%|▌         | 917/16104 [4:14:14<76:38:33, 18.17s/it]
{'loss': 0.6518, 'learning_rate': 1.9962102637814892e-06, 'rewards/chosen': -0.3820284605026245, 'rewards/rejected': -0.7244985699653625, 'rewards/accuracies': 0.75, 'rewards/margins': 0.34247010946273804, 'policy_logps/rejected': -414.08740234375, 'policy_logps/chosen': -383.16925048828125, 'referece_logps/rejected': -406.8423767089844, 'referece_logps/chosen': -379.34893798828125, 'logits/rejected': -0.8425348997116089, 'logits/chosen': -0.746808648109436, 'epoch': 0.34}


  6%|▌         | 919/16104 [4:14:53<81:15:38, 19.26s/it]

  6%|▌         | 920/16104 [4:15:16<85:14:10, 20.21s/it]
{'loss': 0.6646, 'learning_rate': 1.996157601969651e-06, 'rewards/chosen': -0.43244868516921997, 'rewards/rejected': -0.625849723815918, 'rewards/accuracies': 0.375, 'rewards/margins': 0.193401038646698, 'policy_logps/rejected': -282.1374816894531, 'policy_logps/chosen': -286.04364013671875, 'referece_logps/rejected': -275.8789367675781, 'referece_logps/chosen': -281.7191467285156, 'logits/rejected': 0.027103722095489502, 'logits/chosen': -0.044072628021240234, 'epoch': 0.34}

  6%|▌         | 921/16104 [4:15:31<78:58:42, 18.73s/it]

  6%|▌         | 922/16104 [4:15:47<75:22:07, 17.87s/it]

  6%|▌         | 923/16104 [4:16:07<78:01:19, 18.50s/it]

  6%|▌         | 924/16104 [4:16:28<81:58:57, 19.44s/it]

  6%|▌         | 925/16104 [4:16:39<70:59:46, 16.84s/it]


  6%|▌         | 927/16104 [4:17:08<63:59:36, 15.18s/it]
{'loss': 0.597, 'learning_rate': 1.996033314069776e-06, 'rewards/chosen': -0.6672623157501221, 'rewards/rejected': -0.680529773235321, 'rewards/accuracies': 0.375, 'rewards/margins': 0.013267509639263153, 'policy_logps/rejected': -378.51666259765625, 'policy_logps/chosen': -468.63726806640625, 'referece_logps/rejected': -371.71136474609375, 'referece_logps/chosen': -461.964599609375, 'logits/rejected': -0.1425589621067047, 'logits/chosen': -0.06579897552728653, 'epoch': 0.35}

  6%|▌         | 928/16104 [4:17:20<60:46:39, 14.42s/it]

  6%|▌         | 929/16104 [4:17:35<61:01:33, 14.48s/it]


  6%|▌         | 931/16104 [4:18:08<64:28:22, 15.30s/it]

  6%|▌         | 932/16104 [4:18:24<65:34:59, 15.56s/it]
{'loss': 0.5833, 'learning_rate': 1.9959433282443638e-06, 'rewards/chosen': -0.34269848465919495, 'rewards/rejected': -0.6843550801277161, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3416565954685211, 'policy_logps/rejected': -229.6251678466797, 'policy_logps/chosen': -270.90032958984375, 'referece_logps/rejected': -222.7816162109375, 'referece_logps/chosen': -267.47332763671875, 'logits/rejected': -0.014966115355491638, 'logits/chosen': -0.005473285913467407, 'epoch': 0.35}

  6%|▌         | 933/16104 [4:18:37<62:16:49, 14.78s/it]


  6%|▌         | 935/16104 [4:19:20<76:36:42, 18.18s/it]
{'loss': 0.5518, 'learning_rate': 1.9958888532910705e-06, 'rewards/chosen': -0.7149183750152588, 'rewards/rejected': -0.8058711290359497, 'rewards/accuracies': 0.5, 'rewards/margins': 0.09095270186662674, 'policy_logps/rejected': -223.46823120117188, 'policy_logps/chosen': -234.43865966796875, 'referece_logps/rejected': -215.4095458984375, 'referece_logps/chosen': -227.2894744873047, 'logits/rejected': -1.1779533624649048, 'logits/chosen': -1.2618874311447144, 'epoch': 0.35}

  6%|▌         | 936/16104 [4:19:31<67:36:18, 16.05s/it]

  6%|▌         | 937/16104 [4:19:54<76:06:33, 18.07s/it]

  6%|▌         | 938/16104 [4:20:15<79:32:41, 18.88s/it]


  6%|▌         | 940/16104 [4:20:46<70:50:30, 16.82s/it]
{'loss': 0.5363, 'learning_rate': 1.995797256002498e-06, 'rewards/chosen': -0.5103243589401245, 'rewards/rejected': -0.8871253132820129, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3768009841442108, 'policy_logps/rejected': -256.1561279296875, 'policy_logps/chosen': -290.9244689941406, 'referece_logps/rejected': -247.28485107421875, 'referece_logps/chosen': -285.82122802734375, 'logits/rejected': -1.0464799404144287, 'logits/chosen': -1.0998743772506714, 'epoch': 0.35}

  6%|▌         | 941/16104 [4:21:02<68:51:50, 16.35s/it]

  6%|▌         | 942/16104 [4:21:19<70:11:37, 16.67s/it]

  6%|▌         | 943/16104 [4:21:40<75:58:27, 18.04s/it]

  6%|▌         | 944/16104 [4:21:53<68:56:33, 16.37s/it]

  6%|▌         | 945/16104 [4:22:15<76:35:27, 18.19s/it]

  6%|▌         | 946/16104 [4:22:27<68:19:57, 16.23s/it]

  6%|▌         | 947/16104 [4:22:44<69:02:19, 16.40s/it]

  6%|▌         | 948/16104 [4:22:54<61:47:12, 14.68s/it]

  6%|▌         | 949/16104 [4:23:16<70:21:25, 16.71s/it]

  6%|▌         | 950/16104 [4:23:35<74:04:40, 17.60s/it]


  6%|▌         | 952/16104 [4:24:07<70:32:08, 16.76s/it]
{'loss': 0.6357, 'learning_rate': 1.9955733139476093e-06, 'rewards/chosen': -0.566288948059082, 'rewards/rejected': -0.7300615906715393, 'rewards/accuracies': 0.5, 'rewards/margins': 0.16377268731594086, 'policy_logps/rejected': -363.9837341308594, 'policy_logps/chosen': -476.7882080078125, 'referece_logps/rejected': -356.68310546875, 'referece_logps/chosen': -471.12530517578125, 'logits/rejected': -0.4993327856063843, 'logits/chosen': -0.6285181045532227, 'epoch': 0.35}

  6%|▌         | 953/16104 [4:24:20<66:00:36, 15.68s/it]

  6%|▌         | 954/16104 [4:24:40<71:24:40, 16.97s/it]

  6%|▌         | 955/16104 [4:24:51<64:18:55, 15.28s/it]

  6%|▌         | 956/16104 [4:25:07<65:00:54, 15.45s/it]

  6%|▌         | 957/16104 [4:25:18<59:59:05, 14.26s/it]

  6%|▌         | 958/16104 [4:25:36<63:54:07, 15.19s/it]


  6%|▌         | 960/16104 [4:26:03<60:04:14, 14.28s/it]

  6%|▌         | 961/16104 [4:26:25<69:44:52, 16.58s/it]
{'loss': 0.5288, 'learning_rate': 1.995401551563899e-06, 'rewards/chosen': -0.4481441378593445, 'rewards/rejected': -0.9286771416664124, 'rewards/accuracies': 0.75, 'rewards/margins': 0.48053300380706787, 'policy_logps/rejected': -277.4874267578125, 'policy_logps/chosen': -320.5912780761719, 'referece_logps/rejected': -268.2006530761719, 'referece_logps/chosen': -316.10986328125, 'logits/rejected': 0.8743687868118286, 'logits/chosen': 0.8723928928375244, 'epoch': 0.36}

  6%|▌         | 962/16104 [4:26:39<67:25:13, 16.03s/it]

  6%|▌         | 963/16104 [4:27:00<73:09:48, 17.40s/it]

  6%|▌         | 964/16104 [4:27:15<70:15:34, 16.71s/it]

  6%|▌         | 965/16104 [4:27:30<68:33:12, 16.30s/it]

  6%|▌         | 966/16104 [4:27:50<73:06:10, 17.38s/it]
[2024-04-05 19:53:20,236] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▌         | 967/16104 [4:28:13<79:51:37, 18.99s/it]

  6%|▌         | 968/16104 [4:28:31<78:05:01, 18.57s/it]

  6%|▌         | 969/16104 [4:28:51<80:30:54, 19.15s/it]

  6%|▌         | 970/16104 [4:29:05<73:25:12, 17.46s/it]

  6%|▌         | 971/16104 [4:29:22<73:11:21, 17.41s/it]


  6%|▌         | 973/16104 [4:29:58<75:50:18, 18.04s/it]

  6%|▌         | 974/16104 [4:30:20<79:41:49, 18.96s/it]

  6%|▌         | 975/16104 [4:30:38<79:42:07, 18.97s/it]

  6%|▌         | 976/16104 [4:30:59<81:48:04, 19.47s/it]

  6%|▌         | 977/16104 [4:31:19<81:53:16, 19.49s/it]

  6%|▌         | 978/16104 [4:31:34<76:17:28, 18.16s/it]

  6%|▌         | 979/16104 [4:31:49<72:42:56, 17.31s/it]

  6%|▌         | 980/16104 [4:32:10<77:13:00, 18.38s/it]

  6%|▌         | 981/16104 [4:32:21<68:11:41, 16.23s/it]

  6%|▌         | 982/16104 [4:32:33<62:46:03, 14.94s/it]

  6%|▌         | 983/16104 [4:32:49<63:30:17, 15.12s/it]

  6%|▌         | 984/16104 [4:33:09<69:52:03, 16.64s/it]

  6%|▌         | 985/16104 [4:33:24<68:24:48, 16.29s/it]

  6%|▌         | 986/16104 [4:33:36<62:24:08, 14.86s/it]

  6%|▌         | 987/16104 [4:33:48<59:01:10, 14.06s/it]

  6%|▌         | 988/16104 [4:34:06<64:33:47, 15.38s/it]

  6%|▌         | 989/16104 [4:34:21<63:04:54, 15.02s/it]

  6%|▌         | 990/16104 [4:34:39<67:35:23, 16.10s/it]

  6%|▌         | 991/16104 [4:34:50<61:14:39, 14.59s/it]

  6%|▌         | 992/16104 [4:35:03<58:36:01, 13.96s/it]

  6%|▌         | 993/16104 [4:35:21<63:45:10, 15.19s/it]

  6%|▌         | 994/16104 [4:35:36<63:37:59, 15.16s/it]

  6%|▌         | 995/16104 [4:35:55<68:19:38, 16.28s/it]

  6%|▌         | 996/16104 [4:36:11<68:41:43, 16.37s/it]

  6%|▌         | 997/16104 [4:36:34<76:13:17, 18.16s/it]

  6%|▌         | 998/16104 [4:36:51<74:26:55, 17.74s/it]

  6%|▌         | 999/16104 [4:37:04<69:34:06, 16.58s/it]

  6%|▌         | 1000/16104 [4:37:24<73:56:48, 17.63s/it]

  6%|▌         | 1001/16104 [4:37:51<85:12:37, 20.31s/it]

  6%|▌         | 1002/16104 [4:38:12<86:19:38, 20.58s/it]

  6%|▌         | 1003/16104 [4:38:34<87:17:22, 20.81s/it]

  6%|▌         | 1004/16104 [4:38:50<81:14:57, 19.37s/it]

  6%|▌         | 1005/16104 [4:39:03<73:45:55, 17.59s/it]

  6%|▌         | 1006/16104 [4:39:20<72:25:02, 17.27s/it]

  6%|▋         | 1007/16104 [4:39:33<67:14:52, 16.04s/it]

  6%|▋         | 1008/16104 [4:39:49<68:01:58, 16.22s/it]

  6%|▋         | 1009/16104 [4:40:10<73:59:43, 17.65s/it]

  6%|▋         | 1010/16104 [4:40:32<78:59:13, 18.84s/it]

  6%|▋         | 1011/16104 [4:40:46<72:35:21, 17.31s/it]

  6%|▋         | 1012/16104 [4:41:06<76:56:43, 18.35s/it]

  6%|▋         | 1013/16104 [4:41:28<80:23:29, 19.18s/it]

  6%|▋         | 1014/16104 [4:41:50<84:09:44, 20.08s/it]

  6%|▋         | 1015/16104 [4:42:08<81:42:28, 19.49s/it]

  6%|▋         | 1016/16104 [4:42:25<78:12:46, 18.66s/it]

  6%|▋         | 1017/16104 [4:42:49<84:58:43, 20.28s/it]
[2024-04-05 20:07:55,855] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1018/16104 [4:43:05<79:46:04, 19.04s/it]
[2024-04-05 20:08:11,993] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1019/16104 [4:43:26<82:40:03, 19.73s/it]

  6%|▋         | 1020/16104 [4:43:48<85:07:39, 20.32s/it]

  6%|▋         | 1021/16104 [4:43:59<73:20:08, 17.50s/it]

  6%|▋         | 1022/16104 [4:44:11<66:57:27, 15.98s/it]

  6%|▋         | 1023/16104 [4:44:35<76:40:33, 18.30s/it]
[2024-04-05 20:09:42,120] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  6%|▋         | 1024/16104 [4:44:58<82:09:18, 19.61s/it]

  6%|▋         | 1025/16104 [4:45:14<77:45:04, 18.56s/it]

  6%|▋         | 1026/16104 [4:45:35<80:41:20, 19.27s/it]

  6%|▋         | 1027/16104 [4:45:51<76:58:59, 18.38s/it]

  6%|▋         | 1028/16104 [4:46:03<69:30:12, 16.60s/it]

  6%|▋         | 1029/16104 [4:46:18<67:04:36, 16.02s/it]

  6%|▋         | 1030/16104 [4:46:37<70:46:51, 16.90s/it]

  6%|▋         | 1031/16104 [4:46:57<74:58:18, 17.91s/it]

  6%|▋         | 1032/16104 [4:47:11<69:56:29, 16.71s/it]

  6%|▋         | 1033/16104 [4:47:24<65:31:58, 15.65s/it]

  6%|▋         | 1034/16104 [4:47:39<64:16:25, 15.35s/it]

  6%|▋         | 1035/16104 [4:47:52<61:26:51, 14.68s/it]

  6%|▋         | 1036/16104 [4:48:03<56:22:31, 13.47s/it]

  6%|▋         | 1037/16104 [4:48:18<58:18:02, 13.93s/it]

  6%|▋         | 1038/16104 [4:48:31<57:50:33, 13.82s/it]

  6%|▋         | 1039/16104 [4:48:47<60:14:18, 14.39s/it]

  6%|▋         | 1040/16104 [4:49:09<69:56:25, 16.71s/it]

  6%|▋         | 1041/16104 [4:49:25<68:46:07, 16.44s/it]

  6%|▋         | 1042/16104 [4:49:46<75:01:32, 17.93s/it]

  6%|▋         | 1043/16104 [4:50:02<72:37:52, 17.36s/it]

  6%|▋         | 1044/16104 [4:50:13<64:12:05, 15.35s/it]

  6%|▋         | 1045/16104 [4:50:32<69:10:48, 16.54s/it]

  6%|▋         | 1046/16104 [4:50:50<70:47:32, 16.92s/it]

  7%|▋         | 1047/16104 [4:51:12<76:44:23, 18.35s/it]

  7%|▋         | 1048/16104 [4:51:26<71:31:06, 17.10s/it]

  7%|▋         | 1049/16104 [4:51:47<75:52:50, 18.14s/it]

  7%|▋         | 1050/16104 [4:51:59<68:47:02, 16.45s/it]

  7%|▋         | 1051/16104 [4:52:10<62:08:30, 14.86s/it]

  7%|▋         | 1052/16104 [4:52:26<62:39:54, 14.99s/it]
{'loss': 0.636, 'learning_rate': 1.9934817353485502e-06, 'rewards/chosen': -1.1163209676742554, 'rewards/rejected': -1.0643850564956665, 'rewards/accuracies': 0.5, 'rewards/margins': -0.05193597823381424, 'policy_logps/rejected': -497.0789489746094, 'policy_logps/chosen': -548.584716796875, 'referece_logps/rejected': -486.4350891113281, 'referece_logps/chosen': -537.4215087890625, 'logits/rejected': -1.0933551788330078, 'logits/chosen': -1.1162660121917725, 'epoch': 0.39}


  7%|▋         | 1054/16104 [4:52:50<56:55:30, 13.62s/it]

  7%|▋         | 1055/16104 [4:53:04<56:35:39, 13.54s/it]
{'loss': 0.6647, 'learning_rate': 1.9934127744980653e-06, 'rewards/chosen': -0.805131196975708, 'rewards/rejected': -0.7939763069152832, 'rewards/accuracies': 0.75, 'rewards/margins': -0.011154849082231522, 'policy_logps/rejected': -281.1504211425781, 'policy_logps/chosen': -368.7662353515625, 'referece_logps/rejected': -273.210693359375, 'referece_logps/chosen': -360.7149353027344, 'logits/rejected': -1.3232600688934326, 'logits/chosen': -1.3585820198059082, 'epoch': 0.39}


  7%|▋         | 1057/16104 [4:53:36<64:18:33, 15.39s/it]
[2024-04-05 20:18:43,340] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1058/16104 [4:53:53<66:18:31, 15.87s/it]
[2024-04-05 20:19:00,323] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1059/16104 [4:54:10<67:52:27, 16.24s/it]

  7%|▋         | 1060/16104 [4:54:28<69:50:55, 16.71s/it]
{'loss': 0.6004, 'learning_rate': 1.9932970360533473e-06, 'rewards/chosen': -1.0449508428573608, 'rewards/rejected': -1.2523534297943115, 'rewards/accuracies': 0.75, 'rewards/margins': 0.20740258693695068, 'policy_logps/rejected': -324.11383056640625, 'policy_logps/chosen': -393.9416198730469, 'referece_logps/rejected': -311.5903015136719, 'referece_logps/chosen': -383.4920654296875, 'logits/rejected': -0.44401293992996216, 'logits/chosen': -0.43537843227386475, 'epoch': 0.39}


  7%|▋         | 1062/16104 [4:55:05<74:20:12, 17.79s/it]
{'loss': 0.6156, 'learning_rate': 1.9932504594044307e-06, 'rewards/chosen': -0.8020282983779907, 'rewards/rejected': -1.0535352230072021, 'rewards/accuracies': 0.375, 'rewards/margins': 0.2515068054199219, 'policy_logps/rejected': -372.8022766113281, 'policy_logps/chosen': -327.7445983886719, 'referece_logps/rejected': -362.26690673828125, 'referece_logps/chosen': -319.72430419921875, 'logits/rejected': 0.04393540322780609, 'logits/chosen': 0.08247224986553192, 'epoch': 0.4}


  7%|▋         | 1064/16104 [4:55:43<77:00:47, 18.43s/it]

  7%|▋         | 1065/16104 [4:56:00<75:04:22, 17.97s/it]

  7%|▋         | 1066/16104 [4:56:18<75:19:02, 18.03s/it]

  7%|▋         | 1067/16104 [4:56:33<70:25:01, 16.86s/it]

  7%|▋         | 1068/16104 [4:56:50<71:23:51, 17.09s/it]

  7%|▋         | 1069/16104 [4:57:10<74:47:59, 17.91s/it]

  7%|▋         | 1070/16104 [4:57:28<75:12:10, 18.01s/it]

  7%|▋         | 1071/16104 [4:57:47<75:29:13, 18.08s/it]

  7%|▋         | 1072/16104 [4:58:08<79:34:23, 19.06s/it]
[2024-04-05 20:23:15,069] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1073/16104 [4:58:20<71:00:39, 17.01s/it]
[2024-04-05 20:23:27,294] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1074/16104 [4:58:32<64:33:54, 15.46s/it]

  7%|▋         | 1075/16104 [4:58:50<68:19:25, 16.37s/it]

  7%|▋         | 1076/16104 [4:59:04<64:37:04, 15.48s/it]
{'loss': 0.6154, 'learning_rate': 1.9929199232669814e-06, 'rewards/chosen': -0.7377811670303345, 'rewards/rejected': -0.5593643188476562, 'rewards/accuracies': 0.5, 'rewards/margins': -0.17841683328151703, 'policy_logps/rejected': -394.05511474609375, 'policy_logps/chosen': -332.8436584472656, 'referece_logps/rejected': -388.46148681640625, 'referece_logps/chosen': -325.4658203125, 'logits/rejected': -0.15481415390968323, 'logits/chosen': -0.21962884068489075, 'epoch': 0.4}


  7%|▋         | 1078/16104 [4:59:38<66:41:25, 15.98s/it]
{'loss': 0.5576, 'learning_rate': 1.9928720611111695e-06, 'rewards/chosen': -0.6296148300170898, 'rewards/rejected': -0.7325737476348877, 'rewards/accuracies': 0.375, 'rewards/margins': 0.10295887291431427, 'policy_logps/rejected': -375.25531005859375, 'policy_logps/chosen': -407.04498291015625, 'referece_logps/rejected': -367.9295959472656, 'referece_logps/chosen': -400.7488098144531, 'logits/rejected': 0.938871443271637, 'logits/chosen': 1.0340955257415771, 'epoch': 0.4}


  7%|▋         | 1080/16104 [5:00:09<65:19:45, 15.65s/it]

  7%|▋         | 1081/16104 [5:00:24<64:41:57, 15.50s/it]

  7%|▋         | 1082/16104 [5:00:42<68:27:05, 16.40s/it]
{'loss': 0.6694, 'learning_rate': 1.992775854845961e-06, 'rewards/chosen': -1.0971072912216187, 'rewards/rejected': -1.0047760009765625, 'rewards/accuracies': 0.375, 'rewards/margins': -0.09233130514621735, 'policy_logps/rejected': -345.5775146484375, 'policy_logps/chosen': -487.9161682128906, 'referece_logps/rejected': -335.52972412109375, 'referece_logps/chosen': -476.94512939453125, 'logits/rejected': -0.6757592558860779, 'logits/chosen': -0.7188539505004883, 'epoch': 0.4}


  7%|▋         | 1084/16104 [5:01:16<67:21:04, 16.14s/it]

  7%|▋         | 1085/16104 [5:01:32<67:53:57, 16.28s/it]

  7%|▋         | 1086/16104 [5:01:52<71:59:14, 17.26s/it]
{'loss': 0.6178, 'learning_rate': 1.9926790060279058e-06, 'rewards/chosen': -0.5119926333427429, 'rewards/rejected': -0.5251306891441345, 'rewards/accuracies': 0.375, 'rewards/margins': 0.013138018548488617, 'policy_logps/rejected': -419.1050720214844, 'policy_logps/chosen': -440.7377014160156, 'referece_logps/rejected': -413.8537292480469, 'referece_logps/chosen': -435.61773681640625, 'logits/rejected': -0.6279383897781372, 'logits/chosen': -0.7179276943206787, 'epoch': 0.4}


  7%|▋         | 1088/16104 [5:02:20<64:11:35, 15.39s/it]

  7%|▋         | 1089/16104 [5:02:35<62:59:21, 15.10s/it]
{'loss': 0.5454, 'learning_rate': 1.992605947776752e-06, 'rewards/chosen': -0.5820934176445007, 'rewards/rejected': -1.1675167083740234, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5854232907295227, 'policy_logps/rejected': -373.768310546875, 'policy_logps/chosen': -428.9945068359375, 'referece_logps/rejected': -362.0931091308594, 'referece_logps/chosen': -423.173583984375, 'logits/rejected': -6.0364603996276855e-05, 'logits/chosen': -0.07273410260677338, 'epoch': 0.41}

  7%|▋         | 1090/16104 [5:02:55<70:03:24, 16.80s/it]

  7%|▋         | 1091/16104 [5:03:17<76:18:31, 18.30s/it]

  7%|▋         | 1092/16104 [5:03:35<75:57:48, 18.22s/it]


  7%|▋         | 1094/16104 [5:04:16<80:44:28, 19.37s/it]
{'loss': 0.6043, 'learning_rate': 1.9924833809844063e-06, 'rewards/chosen': -0.7763111591339111, 'rewards/rejected': -1.2102278470993042, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4339166283607483, 'policy_logps/rejected': -415.9630126953125, 'policy_logps/chosen': -405.7370300292969, 'referece_logps/rejected': -403.8607177734375, 'referece_logps/chosen': -397.97393798828125, 'logits/rejected': -0.29155176877975464, 'logits/chosen': -0.17986972630023956, 'epoch': 0.41}

  7%|▋         | 1095/16104 [5:04:39<85:36:07, 20.53s/it]


  7%|▋         | 1097/16104 [5:05:08<73:19:49, 17.59s/it]

  7%|▋         | 1098/16104 [5:05:24<71:40:33, 17.20s/it]
{'loss': 0.5629, 'learning_rate': 1.9923846048855753e-06, 'rewards/chosen': -0.5815486907958984, 'rewards/rejected': -1.0580734014511108, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4765246510505676, 'policy_logps/rejected': -328.08758544921875, 'policy_logps/chosen': -367.5179748535156, 'referece_logps/rejected': -317.5068359375, 'referece_logps/chosen': -361.7025146484375, 'logits/rejected': -0.39377281069755554, 'logits/chosen': -0.3300257623195648, 'epoch': 0.41}


  7%|▋         | 1100/16104 [5:05:58<71:08:25, 17.07s/it]

  7%|▋         | 1101/16104 [5:06:22<79:32:20, 19.09s/it]
[2024-04-05 20:31:29,221] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1102/16104 [5:06:43<81:46:21, 19.62s/it]

  7%|▋         | 1103/16104 [5:07:02<81:05:45, 19.46s/it]

  7%|▋         | 1104/16104 [5:07:20<79:40:04, 19.12s/it]

  7%|▋         | 1105/16104 [5:07:36<75:56:27, 18.23s/it]

  7%|▋         | 1106/16104 [5:07:52<72:51:24, 17.49s/it]

  7%|▋         | 1107/16104 [5:08:12<75:34:57, 18.14s/it]
{'loss': 0.6023, 'learning_rate': 1.9921600103532942e-06, 'rewards/chosen': -0.9354472756385803, 'rewards/rejected': -1.3171693086624146, 'rewards/accuracies': 0.625, 'rewards/margins': 0.38172197341918945, 'policy_logps/rejected': -404.8826904296875, 'policy_logps/chosen': -481.10089111328125, 'referece_logps/rejected': -391.71099853515625, 'referece_logps/chosen': -471.7464294433594, 'logits/rejected': -0.18574002385139465, 'logits/chosen': -0.23187333345413208, 'epoch': 0.41}


  7%|▋         | 1109/16104 [5:08:47<75:35:38, 18.15s/it]

  7%|▋         | 1110/16104 [5:09:10<82:11:31, 19.73s/it]
{'loss': 0.5663, 'learning_rate': 1.9920844230491752e-06, 'rewards/chosen': -0.8888489007949829, 'rewards/rejected': -1.1011555194854736, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21230661869049072, 'policy_logps/rejected': -382.0796203613281, 'policy_logps/chosen': -435.90789794921875, 'referece_logps/rejected': -371.06805419921875, 'referece_logps/chosen': -427.0194396972656, 'logits/rejected': 0.4702492356300354, 'logits/chosen': 0.47829166054725647, 'epoch': 0.41}


  7%|▋         | 1112/16104 [5:09:48<79:39:07, 19.13s/it]
{'loss': 0.6166, 'learning_rate': 1.9920338308534707e-06, 'rewards/chosen': -1.2857304811477661, 'rewards/rejected': -1.626922845840454, 'rewards/accuracies': 0.75, 'rewards/margins': 0.34119242429733276, 'policy_logps/rejected': -314.7663269042969, 'policy_logps/chosen': -295.6043701171875, 'referece_logps/rejected': -298.4970703125, 'referece_logps/chosen': -282.7470703125, 'logits/rejected': 0.11228641122579575, 'logits/chosen': 0.22356432676315308, 'epoch': 0.41}

  7%|▋         | 1113/16104 [5:10:06<77:44:26, 18.67s/it]


  7%|▋         | 1115/16104 [5:10:43<77:25:56, 18.60s/it]

  7%|▋         | 1116/16104 [5:11:00<75:13:51, 18.07s/it]
{'loss': 0.517, 'learning_rate': 1.9919321649158134e-06, 'rewards/chosen': -0.458262175321579, 'rewards/rejected': -1.0636249780654907, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6053627729415894, 'policy_logps/rejected': -263.70611572265625, 'policy_logps/chosen': -287.9314880371094, 'referece_logps/rejected': -253.0698699951172, 'referece_logps/chosen': -283.3489074707031, 'logits/rejected': -0.21665515005588531, 'logits/chosen': -0.320745587348938, 'epoch': 0.42}

  7%|▋         | 1117/16104 [5:11:14<69:45:50, 16.76s/it]
[2024-04-05 20:36:43,108] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  7%|▋         | 1119/16104 [5:11:50<71:29:01, 17.17s/it]

  7%|▋         | 1120/16104 [5:12:07<71:15:16, 17.12s/it]

  7%|▋         | 1121/16104 [5:12:29<76:20:55, 18.34s/it]

  7%|▋         | 1122/16104 [5:12:49<79:13:50, 19.04s/it]
[2024-04-05 20:37:56,371] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.549, 'learning_rate': 1.9917784622672805e-06, 'rewards/chosen': -1.01222825050354, 'rewards/rejected': -1.424157977104187, 'rewards/accuracies': 0.5, 'rewards/margins': 0.411929726600647, 'policy_logps/rejected': -504.8077392578125, 'policy_logps/chosen': -423.58953857421875, 'referece_logps/rejected': -490.566162109375, 'referece_logps/chosen': -413.46728515625, 'logits/rejected': 0.3465251326560974, 'logits/chosen': 0.42005470395088196, 'epoch': 0.42}


  7%|▋         | 1124/16104 [5:13:27<78:44:32, 18.92s/it]

  7%|▋         | 1125/16104 [5:13:47<79:09:46, 19.03s/it]

  7%|▋         | 1126/16104 [5:14:03<75:51:49, 18.23s/it]

  7%|▋         | 1127/16104 [5:14:17<70:00:51, 16.83s/it]

  7%|▋         | 1128/16104 [5:14:39<76:22:03, 18.36s/it]

  7%|▋         | 1129/16104 [5:14:51<68:33:31, 16.48s/it]

  7%|▋         | 1130/16104 [5:15:03<63:29:08, 15.26s/it]
{'loss': 0.6198, 'learning_rate': 1.9915712787661425e-06, 'rewards/chosen': -0.9276657700538635, 'rewards/rejected': -1.3341953754425049, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4065295457839966, 'policy_logps/rejected': -351.7813415527344, 'policy_logps/chosen': -303.6191101074219, 'referece_logps/rejected': -338.43939208984375, 'referece_logps/chosen': -294.3424377441406, 'logits/rejected': -1.2421982288360596, 'logits/chosen': -1.2044572830200195, 'epoch': 0.42}


  7%|▋         | 1132/16104 [5:15:43<73:29:06, 17.67s/it]

  7%|▋         | 1133/16104 [5:15:55<66:02:33, 15.88s/it]

  7%|▋         | 1134/16104 [5:16:06<59:39:53, 14.35s/it]

  7%|▋         | 1135/16104 [5:16:16<55:00:54, 13.23s/it]

  7%|▋         | 1136/16104 [5:16:30<54:54:34, 13.21s/it]
{'loss': 0.5791, 'learning_rate': 1.991414206456301e-06, 'rewards/chosen': -0.4819417893886566, 'rewards/rejected': -0.7563233971595764, 'rewards/accuracies': 0.875, 'rewards/margins': 0.2743816375732422, 'policy_logps/rejected': -533.9544677734375, 'policy_logps/chosen': -573.9635620117188, 'referece_logps/rejected': -526.3911743164062, 'referece_logps/chosen': -569.1441650390625, 'logits/rejected': -0.3713119626045227, 'logits/chosen': -0.5512842535972595, 'epoch': 0.42}


  7%|▋         | 1138/16104 [5:17:05<62:20:48, 15.00s/it]
{'loss': 0.705, 'learning_rate': 1.9913615281725778e-06, 'rewards/chosen': -0.6902639269828796, 'rewards/rejected': -1.1396232843399048, 'rewards/accuracies': 0.625, 'rewards/margins': 0.44935935735702515, 'policy_logps/rejected': -448.3162536621094, 'policy_logps/chosen': -351.9649963378906, 'referece_logps/rejected': -436.9200439453125, 'referece_logps/chosen': -345.0623474121094, 'logits/rejected': -0.5258915424346924, 'logits/chosen': -0.17607474327087402, 'epoch': 0.42}


  7%|▋         | 1140/16104 [5:17:27<53:42:03, 12.92s/it]
{'loss': 0.7209, 'learning_rate': 1.9913086894794854e-06, 'rewards/chosen': -0.5618651509284973, 'rewards/rejected': -0.7415563464164734, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17969122529029846, 'policy_logps/rejected': -390.8085021972656, 'policy_logps/chosen': -314.9049072265625, 'referece_logps/rejected': -383.3929138183594, 'referece_logps/chosen': -309.2862548828125, 'logits/rejected': -0.7220390439033508, 'logits/chosen': -0.8149791359901428, 'epoch': 0.42}


  7%|▋         | 1142/16104 [5:18:02<64:32:37, 15.53s/it]

  7%|▋         | 1143/16104 [5:18:13<59:56:52, 14.42s/it]

  7%|▋         | 1144/16104 [5:18:25<56:30:16, 13.60s/it]

  7%|▋         | 1145/16104 [5:18:40<58:13:41, 14.01s/it]

  7%|▋         | 1146/16104 [5:18:59<64:47:00, 15.59s/it]

  7%|▋         | 1147/16104 [5:19:19<70:23:01, 16.94s/it]

  7%|▋         | 1148/16104 [5:19:36<69:48:29, 16.80s/it]

  7%|▋         | 1149/16104 [5:19:54<71:13:41, 17.15s/it]

  7%|▋         | 1150/16104 [5:20:09<68:24:06, 16.47s/it]
{'loss': 0.5537, 'learning_rate': 1.9910420901736194e-06, 'rewards/chosen': -0.7517727017402649, 'rewards/rejected': -1.1476998329162598, 'rewards/accuracies': 0.75, 'rewards/margins': 0.39592719078063965, 'policy_logps/rejected': -406.07586669921875, 'policy_logps/chosen': -347.367919921875, 'referece_logps/rejected': -394.5988464355469, 'referece_logps/chosen': -339.8501892089844, 'logits/rejected': -0.7962925434112549, 'logits/chosen': -0.8893171548843384, 'epoch': 0.43}


  7%|▋         | 1152/16104 [5:20:50<77:02:03, 18.55s/it]

  7%|▋         | 1153/16104 [5:21:09<78:44:07, 18.96s/it]

  7%|▋         | 1154/16104 [5:21:29<80:01:44, 19.27s/it]
{'loss': 0.6313, 'learning_rate': 1.9909343278869205e-06, 'rewards/chosen': -0.9091554880142212, 'rewards/rejected': -1.1807018518447876, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2715463638305664, 'policy_logps/rejected': -229.04330444335938, 'policy_logps/chosen': -291.2876892089844, 'referece_logps/rejected': -217.23629760742188, 'referece_logps/chosen': -282.1961364746094, 'logits/rejected': -1.4076261520385742, 'logits/chosen': -1.4124614000320435, 'epoch': 0.43}


  7%|▋         | 1156/16104 [5:22:04<74:20:27, 17.90s/it]

  7%|▋         | 1157/16104 [5:22:22<73:53:24, 17.80s/it]

  7%|▋         | 1158/16104 [5:22:36<69:48:44, 16.82s/it]

  7%|▋         | 1159/16104 [5:22:57<74:48:27, 18.02s/it]

  7%|▋         | 1160/16104 [5:23:17<77:36:07, 18.69s/it]
{'loss': 0.5965, 'learning_rate': 1.990771481926986e-06, 'rewards/chosen': -0.6050008535385132, 'rewards/rejected': -1.1332311630249023, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5282303094863892, 'policy_logps/rejected': -261.8712463378906, 'policy_logps/chosen': -414.7174987792969, 'referece_logps/rejected': -250.53895568847656, 'referece_logps/chosen': -408.66748046875, 'logits/rejected': -0.3989795446395874, 'logits/chosen': -0.4163285493850708, 'epoch': 0.43}

  7%|▋         | 1161/16104 [5:23:38<80:47:07, 19.46s/it]


  7%|▋         | 1163/16104 [5:24:19<83:30:26, 20.12s/it]
{'loss': 0.7304, 'learning_rate': 1.9906895178727737e-06, 'rewards/chosen': -0.7697582244873047, 'rewards/rejected': -0.8593507409095764, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08959245681762695, 'policy_logps/rejected': -332.577880859375, 'policy_logps/chosen': -266.9505615234375, 'referece_logps/rejected': -323.9843444824219, 'referece_logps/chosen': -259.2529602050781, 'logits/rejected': -0.25297173857688904, 'logits/chosen': -0.15552131831645966, 'epoch': 0.43}
[2024-04-05 20:49:47,884] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  7%|▋         | 1165/16104 [5:25:00<83:27:21, 20.11s/it]
[2024-04-05 20:50:06,998] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6583, 'learning_rate': 1.990634674792329e-06, 'rewards/chosen': -0.635088324546814, 'rewards/rejected': -0.9740996956825256, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3390112817287445, 'policy_logps/rejected': -383.9491271972656, 'policy_logps/chosen': -557.0798950195312, 'referece_logps/rejected': -374.2081298828125, 'referece_logps/chosen': -550.72900390625, 'logits/rejected': -1.0928623676300049, 'logits/chosen': -1.2505251169204712, 'epoch': 0.43}

  7%|▋         | 1166/16104 [5:25:13<74:56:14, 18.06s/it]

  7%|▋         | 1167/16104 [5:25:35<79:21:35, 19.13s/it]
[2024-04-05 20:50:57,756] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  7%|▋         | 1169/16104 [5:26:06<72:18:14, 17.43s/it]

  7%|▋         | 1170/16104 [5:26:26<75:41:30, 18.25s/it]
{'loss': 0.7255, 'learning_rate': 1.9904968658342434e-06, 'rewards/chosen': -0.42114049196243286, 'rewards/rejected': -0.5651956796646118, 'rewards/accuracies': 0.625, 'rewards/margins': 0.14405518770217896, 'policy_logps/rejected': -366.9604187011719, 'policy_logps/chosen': -645.98583984375, 'referece_logps/rejected': -361.3085021972656, 'referece_logps/chosen': -641.7744140625, 'logits/rejected': 0.17623651027679443, 'logits/chosen': 0.024195313453674316, 'epoch': 0.44}

  7%|▋         | 1171/16104 [5:26:37<66:24:40, 16.01s/it]

  7%|▋         | 1172/16104 [5:26:49<60:56:02, 14.69s/it]


  7%|▋         | 1174/16104 [5:27:16<57:28:30, 13.86s/it]
{'loss': 0.6948, 'learning_rate': 1.990385897448527e-06, 'rewards/chosen': -0.6966728568077087, 'rewards/rejected': -0.8607639074325562, 'rewards/accuracies': 0.625, 'rewards/margins': 0.16409112513065338, 'policy_logps/rejected': -280.22674560546875, 'policy_logps/chosen': -407.00726318359375, 'referece_logps/rejected': -271.619140625, 'referece_logps/chosen': -400.04058837890625, 'logits/rejected': -0.30809998512268066, 'logits/chosen': -0.3406786024570465, 'epoch': 0.44}


  7%|▋         | 1176/16104 [5:27:38<51:02:10, 12.31s/it]

  7%|▋         | 1177/16104 [5:28:00<63:32:04, 15.32s/it]
{'loss': 0.7204, 'learning_rate': 1.9903022504951095e-06, 'rewards/chosen': -0.5413387417793274, 'rewards/rejected': -0.9391578435897827, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3978191614151001, 'policy_logps/rejected': -551.0556640625, 'policy_logps/chosen': -422.27838134765625, 'referece_logps/rejected': -541.6640625, 'referece_logps/chosen': -416.8650207519531, 'logits/rejected': -0.37438297271728516, 'logits/chosen': -0.24295392632484436, 'epoch': 0.44}

  7%|▋         | 1178/16104 [5:28:17<65:59:42, 15.92s/it]


  7%|▋         | 1180/16104 [5:28:46<62:58:42, 15.19s/it]
{'loss': 0.6791, 'learning_rate': 1.990218243006263e-06, 'rewards/chosen': -0.5793533325195312, 'rewards/rejected': -0.5759725570678711, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0033807624131441116, 'policy_logps/rejected': -456.17694091796875, 'policy_logps/chosen': -545.5987548828125, 'referece_logps/rejected': -450.4172058105469, 'referece_logps/chosen': -539.8052368164062, 'logits/rejected': -0.12743337452411652, 'logits/chosen': -0.06023330241441727, 'epoch': 0.44}


  7%|▋         | 1182/16104 [5:29:16<61:51:48, 14.92s/it]
{'loss': 0.6107, 'learning_rate': 1.990162037731336e-06, 'rewards/chosen': -0.6783063411712646, 'rewards/rejected': -0.4956846237182617, 'rewards/accuracies': 0.5, 'rewards/margins': -0.1826217621564865, 'policy_logps/rejected': -294.67279052734375, 'policy_logps/chosen': -290.60894775390625, 'referece_logps/rejected': -289.7159729003906, 'referece_logps/chosen': -283.82586669921875, 'logits/rejected': -1.5946720838546753, 'logits/chosen': -1.5654833316802979, 'epoch': 0.44}

  7%|▋         | 1183/16104 [5:29:38<69:48:11, 16.84s/it]


  7%|▋         | 1185/16104 [5:30:12<70:34:19, 17.03s/it]

  7%|▋         | 1186/16104 [5:30:33<74:53:37, 18.07s/it]

  7%|▋         | 1187/16104 [5:30:48<71:50:55, 17.34s/it]

  7%|▋         | 1188/16104 [5:31:10<77:08:45, 18.62s/it]

  7%|▋         | 1189/16104 [5:31:25<72:27:52, 17.49s/it]
{'loss': 0.5882, 'learning_rate': 1.989964057633647e-06, 'rewards/chosen': -0.5997255444526672, 'rewards/rejected': -0.862853467464447, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2631279230117798, 'policy_logps/rejected': -457.28228759765625, 'policy_logps/chosen': -322.6735534667969, 'referece_logps/rejected': -448.6537170410156, 'referece_logps/chosen': -316.6763000488281, 'logits/rejected': -1.1963821649551392, 'logits/chosen': -1.0181834697723389, 'epoch': 0.44}


  7%|▋         | 1191/16104 [5:32:00<72:35:34, 17.52s/it]

  7%|▋         | 1192/16104 [5:32:11<63:51:41, 15.42s/it]
{'loss': 0.5258, 'learning_rate': 1.989878608310239e-06, 'rewards/chosen': -0.40199851989746094, 'rewards/rejected': -0.7532935738563538, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3512951135635376, 'policy_logps/rejected': -372.5262756347656, 'policy_logps/chosen': -409.00115966796875, 'referece_logps/rejected': -364.9933166503906, 'referece_logps/chosen': -404.981201171875, 'logits/rejected': -0.7124814987182617, 'logits/chosen': -0.7172096371650696, 'epoch': 0.44}

  7%|▋         | 1193/16104 [5:32:32<70:41:40, 17.07s/it]

  7%|▋         | 1194/16104 [5:32:45<66:23:37, 16.03s/it]

  7%|▋         | 1195/16104 [5:33:00<64:23:44, 15.55s/it]

  7%|▋         | 1196/16104 [5:33:19<69:24:25, 16.76s/it]


  7%|▋         | 1198/16104 [5:33:52<67:51:31, 16.39s/it]

  7%|▋         | 1199/16104 [5:34:04<62:11:05, 15.02s/it]

  7%|▋         | 1200/16104 [5:34:24<68:16:44, 16.49s/it]

  7%|▋         | 1201/16104 [5:34:45<73:08:09, 17.67s/it]

  7%|▋         | 1202/16104 [5:35:06<78:06:56, 18.87s/it]
[2024-04-05 21:00:13,482] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  7%|▋         | 1203/16104 [5:35:29<82:42:12, 19.98s/it]
{'loss': 0.5862, 'learning_rate': 1.989562211101067e-06, 'rewards/chosen': -0.6759634613990784, 'rewards/rejected': -0.9286741614341736, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2527107000350952, 'policy_logps/rejected': -528.6756591796875, 'policy_logps/chosen': -421.8675842285156, 'referece_logps/rejected': -519.388916015625, 'referece_logps/chosen': -415.10791015625, 'logits/rejected': -0.48603105545043945, 'logits/chosen': -0.0995149090886116, 'epoch': 0.45}

  7%|▋         | 1204/16104 [5:35:49<83:09:42, 20.09s/it]


  7%|▋         | 1206/16104 [5:36:20<74:55:31, 18.11s/it]
{'loss': 0.6332, 'learning_rate': 1.989475080267023e-06, 'rewards/chosen': -0.6664962768554688, 'rewards/rejected': -0.8726557493209839, 'rewards/accuracies': 0.875, 'rewards/margins': 0.20615939795970917, 'policy_logps/rejected': -428.3975524902344, 'policy_logps/chosen': -570.8547973632812, 'referece_logps/rejected': -419.6710205078125, 'referece_logps/chosen': -564.1898193359375, 'logits/rejected': 0.26129603385925293, 'logits/chosen': 0.26838940382003784, 'epoch': 0.45}


  8%|▊         | 1208/16104 [5:36:52<71:22:05, 17.25s/it]

  8%|▊         | 1209/16104 [5:37:04<65:00:57, 15.71s/it]

  8%|▊         | 1210/16104 [5:37:25<70:28:29, 17.03s/it]
{'loss': 0.5867, 'learning_rate': 1.98935834546269e-06, 'rewards/chosen': -0.941916823387146, 'rewards/rejected': -1.3096871376037598, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3677701950073242, 'policy_logps/rejected': -300.1815185546875, 'policy_logps/chosen': -317.9809265136719, 'referece_logps/rejected': -287.08465576171875, 'referece_logps/chosen': -308.561767578125, 'logits/rejected': -0.18107907474040985, 'logits/chosen': -0.04094262421131134, 'epoch': 0.45}

  8%|▊         | 1211/16104 [5:37:46<75:23:47, 18.23s/it]

  8%|▊         | 1212/16104 [5:38:06<77:46:05, 18.80s/it]

  8%|▊         | 1213/16104 [5:38:23<76:24:26, 18.47s/it]


  8%|▊         | 1215/16104 [5:38:59<73:26:29, 17.76s/it]

  8%|▊         | 1216/16104 [5:39:21<79:21:10, 19.19s/it]

  8%|▊         | 1217/16104 [5:39:33<70:10:35, 16.97s/it]
{'loss': 0.5838, 'learning_rate': 1.989152518780412e-06, 'rewards/chosen': -0.37247079610824585, 'rewards/rejected': -0.4472947418689728, 'rewards/accuracies': 0.625, 'rewards/margins': 0.07482396066188812, 'policy_logps/rejected': -316.6007080078125, 'policy_logps/chosen': -387.19189453125, 'referece_logps/rejected': -312.12774658203125, 'referece_logps/chosen': -383.4671630859375, 'logits/rejected': -0.9586851596832275, 'logits/chosen': -1.0449748039245605, 'epoch': 0.45}

  8%|▊         | 1218/16104 [5:39:58<79:48:17, 19.30s/it]

  8%|▊         | 1219/16104 [5:40:16<78:29:26, 18.98s/it]

  8%|▊         | 1220/16104 [5:40:27<69:25:28, 16.79s/it]


  8%|▊         | 1222/16104 [5:41:05<72:07:08, 17.45s/it]
{'loss': 0.6039, 'learning_rate': 1.9890042993083585e-06, 'rewards/chosen': -0.26980113983154297, 'rewards/rejected': -1.0654168128967285, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7956156134605408, 'policy_logps/rejected': -354.0955810546875, 'policy_logps/chosen': -473.9674987792969, 'referece_logps/rejected': -343.44140625, 'referece_logps/chosen': -471.26953125, 'logits/rejected': -0.19897443056106567, 'logits/chosen': -0.019919708371162415, 'epoch': 0.46}

  8%|▊         | 1223/16104 [5:41:18<67:03:56, 16.22s/it]


  8%|▊         | 1225/16104 [5:41:41<57:03:23, 13.80s/it]
{'loss': 0.702, 'learning_rate': 1.988914887531665e-06, 'rewards/chosen': -0.6742498278617859, 'rewards/rejected': -0.49654000997543335, 'rewards/accuracies': 0.375, 'rewards/margins': -0.17770984768867493, 'policy_logps/rejected': -319.7784423828125, 'policy_logps/chosen': -301.35662841796875, 'referece_logps/rejected': -314.8130187988281, 'referece_logps/chosen': -294.6141357421875, 'logits/rejected': -0.7567851543426514, 'logits/chosen': -0.8534054160118103, 'epoch': 0.46}

  8%|▊         | 1226/16104 [5:41:52<53:11:45, 12.87s/it]


  8%|▊         | 1228/16104 [5:42:21<57:46:07, 13.98s/it]

  8%|▊         | 1229/16104 [5:42:33<55:58:19, 13.55s/it]

  8%|▊         | 1230/16104 [5:42:55<66:18:51, 16.05s/it]
{'loss': 0.5151, 'learning_rate': 1.9887650678525593e-06, 'rewards/chosen': -0.6184191107749939, 'rewards/rejected': -0.9831697344779968, 'rewards/accuracies': 0.875, 'rewards/margins': 0.36475056409835815, 'policy_logps/rejected': -248.40188598632812, 'policy_logps/chosen': -300.8173522949219, 'referece_logps/rejected': -238.57015991210938, 'referece_logps/chosen': -294.6331481933594, 'logits/rejected': -0.8169475197792053, 'logits/chosen': -0.8562496304512024, 'epoch': 0.46}

  8%|▊         | 1231/16104 [5:43:08<62:33:40, 15.14s/it]

  8%|▊         | 1232/16104 [5:43:22<61:28:46, 14.88s/it]

  8%|▊         | 1233/16104 [5:43:42<67:51:39, 16.43s/it]


  8%|▊         | 1235/16104 [5:44:19<71:47:47, 17.38s/it]

  8%|▊         | 1236/16104 [5:44:39<74:17:03, 17.99s/it]

  8%|▊         | 1237/16104 [5:44:57<74:11:36, 17.97s/it]

  8%|▊         | 1238/16104 [5:45:15<74:12:02, 17.97s/it]

  8%|▊         | 1239/16104 [5:45:26<65:14:24, 15.80s/it]
{'loss': 0.5983, 'learning_rate': 1.9884928727022145e-06, 'rewards/chosen': -0.6646518111228943, 'rewards/rejected': -0.5270683169364929, 'rewards/accuracies': 0.5, 'rewards/margins': -0.13758346438407898, 'policy_logps/rejected': -356.72943115234375, 'policy_logps/chosen': -341.3450927734375, 'referece_logps/rejected': -351.458740234375, 'referece_logps/chosen': -334.6985778808594, 'logits/rejected': -1.1060103178024292, 'logits/chosen': -0.9490302801132202, 'epoch': 0.46}


  8%|▊         | 1241/16104 [5:45:58<63:58:59, 15.50s/it]

  8%|▊         | 1242/16104 [5:46:09<58:40:35, 14.21s/it]

  8%|▊         | 1243/16104 [5:46:21<55:59:31, 13.56s/it]

  8%|▊         | 1244/16104 [5:46:32<52:34:35, 12.74s/it]
{'loss': 0.5803, 'learning_rate': 1.9883402535965724e-06, 'rewards/chosen': -0.6916302442550659, 'rewards/rejected': -0.9992760419845581, 'rewards/accuracies': 0.875, 'rewards/margins': 0.30764588713645935, 'policy_logps/rejected': -488.7291259765625, 'policy_logps/chosen': -333.1244812011719, 'referece_logps/rejected': -478.7363586425781, 'referece_logps/chosen': -326.2082214355469, 'logits/rejected': -0.6688699722290039, 'logits/chosen': -0.6159321069717407, 'epoch': 0.46}

  8%|▊         | 1245/16104 [5:46:42<50:01:51, 12.12s/it]

  8%|▊         | 1246/16104 [5:47:05<62:16:04, 15.09s/it]

  8%|▊         | 1247/16104 [5:47:24<67:34:23, 16.37s/it]

  8%|▊         | 1248/16104 [5:47:43<70:53:58, 17.18s/it]

  8%|▊         | 1249/16104 [5:48:05<76:20:57, 18.50s/it]

  8%|▊         | 1250/16104 [5:48:23<76:07:13, 18.45s/it]


  8%|▊         | 1252/16104 [5:49:04<80:23:28, 19.49s/it]
{'loss': 0.5447, 'learning_rate': 1.9880939841256974e-06, 'rewards/chosen': -0.7187930345535278, 'rewards/rejected': -1.7153265476226807, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9965335130691528, 'policy_logps/rejected': -372.9776306152344, 'policy_logps/chosen': -363.59649658203125, 'referece_logps/rejected': -355.8243713378906, 'referece_logps/chosen': -356.4085693359375, 'logits/rejected': -0.6846882104873657, 'logits/chosen': -0.5744146108627319, 'epoch': 0.47}


  8%|▊         | 1254/16104 [5:49:32<69:53:59, 16.95s/it]

  8%|▊         | 1255/16104 [5:49:44<63:16:50, 15.34s/it]

  8%|▊         | 1256/16104 [5:49:57<61:05:32, 14.81s/it]
{'loss': 0.6274, 'learning_rate': 1.9879698900663994e-06, 'rewards/chosen': -0.49470213055610657, 'rewards/rejected': -0.7015809416770935, 'rewards/accuracies': 0.5, 'rewards/margins': 0.20687885582447052, 'policy_logps/rejected': -433.1845397949219, 'policy_logps/chosen': -508.71136474609375, 'referece_logps/rejected': -426.168701171875, 'referece_logps/chosen': -503.76434326171875, 'logits/rejected': -1.0909234285354614, 'logits/chosen': -1.2097833156585693, 'epoch': 0.47}
[2024-04-05 21:15:25,622] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1257/16104 [5:50:18<69:04:20, 16.75s/it]
[2024-04-05 21:15:37,471] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  8%|▊         | 1259/16104 [5:50:45<62:31:07, 15.16s/it]

  8%|▊         | 1260/16104 [5:51:04<66:36:15, 16.15s/it]

  8%|▊         | 1261/16104 [5:51:16<61:18:40, 14.87s/it]
{'loss': 0.6266, 'learning_rate': 1.9878138732860092e-06, 'rewards/chosen': -0.3579290509223938, 'rewards/rejected': -0.49076977372169495, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13284073770046234, 'policy_logps/rejected': -288.36773681640625, 'policy_logps/chosen': -264.682373046875, 'referece_logps/rejected': -283.46002197265625, 'referece_logps/chosen': -261.10308837890625, 'logits/rejected': -0.7768504023551941, 'logits/chosen': -0.6151748299598694, 'epoch': 0.47}

  8%|▊         | 1262/16104 [5:51:29<59:14:10, 14.37s/it]

  8%|▊         | 1263/16104 [5:51:40<55:55:33, 13.57s/it]

  8%|▊         | 1264/16104 [5:51:55<57:08:56, 13.86s/it]
[2024-04-05 21:17:18,148] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  8%|▊         | 1266/16104 [5:52:28<62:39:10, 15.20s/it]

  8%|▊         | 1267/16104 [5:52:40<58:41:07, 14.24s/it]

  8%|▊         | 1268/16104 [5:52:56<61:20:44, 14.89s/it]

  8%|▊         | 1269/16104 [5:53:12<61:54:42, 15.02s/it]

  8%|▊         | 1270/16104 [5:53:23<58:02:39, 14.09s/it]

  8%|▊         | 1271/16104 [5:53:42<62:58:37, 15.28s/it]

  8%|▊         | 1272/16104 [5:54:04<71:27:12, 17.34s/it]
[2024-04-05 21:19:10,839] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5458, 'learning_rate': 1.9874671202156976e-06, 'rewards/chosen': -0.7935863733291626, 'rewards/rejected': -1.3717557191848755, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5781692862510681, 'policy_logps/rejected': -482.45904541015625, 'policy_logps/chosen': -356.7055358886719, 'referece_logps/rejected': -468.74151611328125, 'referece_logps/chosen': -348.7696533203125, 'logits/rejected': -0.15099646151065826, 'logits/chosen': -0.041158027946949005, 'epoch': 0.47}

  8%|▊         | 1273/16104 [5:54:25<76:01:49, 18.46s/it]

  8%|▊         | 1274/16104 [5:54:39<70:42:12, 17.16s/it]

  8%|▊         | 1275/16104 [5:54:59<74:06:17, 17.99s/it]

  8%|▊         | 1276/16104 [5:55:16<72:55:58, 17.71s/it]

  8%|▊         | 1277/16104 [5:55:30<68:11:07, 16.56s/it]

  8%|▊         | 1278/16104 [5:55:43<63:55:42, 15.52s/it]

  8%|▊         | 1279/16104 [5:56:04<70:56:05, 17.23s/it]

  8%|▊         | 1280/16104 [5:56:19<67:44:50, 16.45s/it]

  8%|▊         | 1281/16104 [5:56:39<71:59:32, 17.48s/it]

  8%|▊         | 1282/16104 [5:56:57<73:38:00, 17.88s/it]
[2024-04-05 21:22:25,826] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1283/16104 [5:57:19<77:49:37, 18.90s/it]

  8%|▊         | 1284/16104 [5:57:38<78:04:58, 18.97s/it]

  8%|▊         | 1285/16104 [5:57:59<81:00:33, 19.68s/it]

  8%|▊         | 1286/16104 [5:58:18<79:37:16, 19.34s/it]

  8%|▊         | 1287/16104 [5:58:39<81:49:47, 19.88s/it]

  8%|▊         | 1288/16104 [5:58:59<82:44:37, 20.11s/it]

  8%|▊         | 1289/16104 [5:59:20<83:01:31, 20.17s/it]

  8%|▊         | 1290/16104 [5:59:32<72:56:41, 17.73s/it]

  8%|▊         | 1291/16104 [5:59:48<70:33:05, 17.15s/it]

  8%|▊         | 1292/16104 [6:00:01<65:58:22, 16.03s/it]

  8%|▊         | 1293/16104 [6:00:12<59:30:44, 14.47s/it]


  8%|▊         | 1295/16104 [6:00:44<63:39:02, 15.47s/it]
{'loss': 0.6137, 'learning_rate': 1.986726474678191e-06, 'rewards/chosen': -0.38752955198287964, 'rewards/rejected': -0.6017060279846191, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2141764611005783, 'policy_logps/rejected': -292.697998046875, 'policy_logps/chosen': -402.7651672363281, 'referece_logps/rejected': -286.6809387207031, 'referece_logps/chosen': -398.8899230957031, 'logits/rejected': -0.649077832698822, 'logits/chosen': -0.5714790225028992, 'epoch': 0.48}

  8%|▊         | 1296/16104 [6:00:55<57:45:34, 14.04s/it]

  8%|▊         | 1297/16104 [6:01:10<58:19:17, 14.18s/it]

  8%|▊         | 1298/16104 [6:01:28<63:58:23, 15.55s/it]
[2024-04-05 21:26:54,863] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1299/16104 [6:01:48<68:39:15, 16.69s/it]

  8%|▊         | 1300/16104 [6:01:59<62:31:27, 15.20s/it]


  8%|▊         | 1302/16104 [6:02:33<64:42:08, 15.74s/it]
{'loss': 0.6006, 'learning_rate': 1.9864968690260517e-06, 'rewards/chosen': -0.4511799216270447, 'rewards/rejected': -0.6832189559936523, 'rewards/accuracies': 0.5, 'rewards/margins': 0.23203907907009125, 'policy_logps/rejected': -468.9001159667969, 'policy_logps/chosen': -565.2364501953125, 'referece_logps/rejected': -462.0679016113281, 'referece_logps/chosen': -560.7246704101562, 'logits/rejected': 0.6385719776153564, 'logits/chosen': 0.6232969760894775, 'epoch': 0.49}

  8%|▊         | 1303/16104 [6:02:49<65:50:03, 16.01s/it]
[2024-04-05 21:28:17,486] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1304/16104 [6:03:10<72:08:59, 17.55s/it]

  8%|▊         | 1305/16104 [6:03:29<74:09:02, 18.04s/it]

  8%|▊         | 1306/16104 [6:03:52<79:04:15, 19.24s/it]
[2024-04-05 21:29:21,729] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1307/16104 [6:04:15<83:44:58, 20.38s/it]

  8%|▊         | 1308/16104 [6:04:35<84:16:06, 20.50s/it]

  8%|▊         | 1309/16104 [6:04:46<72:31:45, 17.65s/it]

  8%|▊         | 1310/16104 [6:04:58<65:35:40, 15.96s/it]


  8%|▊         | 1312/16104 [6:05:35<69:37:28, 16.94s/it]
{'loss': 0.6372, 'learning_rate': 1.9861654690932284e-06, 'rewards/chosen': -0.4165538251399994, 'rewards/rejected': -0.7801670432090759, 'rewards/accuracies': 0.75, 'rewards/margins': 0.36361315846443176, 'policy_logps/rejected': -384.7602844238281, 'policy_logps/chosen': -401.40863037109375, 'referece_logps/rejected': -376.9585876464844, 'referece_logps/chosen': -397.2430725097656, 'logits/rejected': -1.0861222743988037, 'logits/chosen': -0.9049341082572937, 'epoch': 0.49}


  8%|▊         | 1314/16104 [6:06:03<63:04:45, 15.35s/it]
{'loss': 0.5711, 'learning_rate': 1.9860987103578046e-06, 'rewards/chosen': -0.36906319856643677, 'rewards/rejected': -0.7337964773178101, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3647332787513733, 'policy_logps/rejected': -375.86358642578125, 'policy_logps/chosen': -478.7765197753906, 'referece_logps/rejected': -368.525634765625, 'referece_logps/chosen': -475.0859069824219, 'logits/rejected': -1.2927426099777222, 'logits/chosen': -1.4475739002227783, 'epoch': 0.49}


  8%|▊         | 1316/16104 [6:06:41<71:07:08, 17.31s/it]
[2024-04-05 21:31:47,951] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5933, 'learning_rate': 1.9860317920645725e-06, 'rewards/chosen': -0.45055118203163147, 'rewards/rejected': -0.8351465463638306, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3845953941345215, 'policy_logps/rejected': -338.0103759765625, 'policy_logps/chosen': -380.2234191894531, 'referece_logps/rejected': -329.65887451171875, 'referece_logps/chosen': -375.7178955078125, 'logits/rejected': -0.6116243004798889, 'logits/chosen': -0.6556215286254883, 'epoch': 0.49}

  8%|▊         | 1317/16104 [6:07:01<75:18:43, 18.34s/it]

  8%|▊         | 1318/16104 [6:07:22<77:25:33, 18.85s/it]

  8%|▊         | 1319/16104 [6:07:37<72:47:37, 17.72s/it]

  8%|▊         | 1320/16104 [6:07:47<63:58:26, 15.58s/it]

  8%|▊         | 1321/16104 [6:08:04<65:06:02, 15.85s/it]

  8%|▊         | 1322/16104 [6:08:14<58:42:02, 14.30s/it]

  8%|▊         | 1323/16104 [6:08:36<68:02:20, 16.57s/it]

  8%|▊         | 1324/16104 [6:08:50<64:30:48, 15.71s/it]

  8%|▊         | 1325/16104 [6:09:01<58:25:06, 14.23s/it]

  8%|▊         | 1326/16104 [6:09:12<55:16:21, 13.46s/it]

  8%|▊         | 1327/16104 [6:09:29<59:31:13, 14.50s/it]

  8%|▊         | 1328/16104 [6:09:40<55:22:43, 13.49s/it]

  8%|▊         | 1329/16104 [6:09:53<54:38:50, 13.32s/it]

  8%|▊         | 1330/16104 [6:10:13<62:58:11, 15.34s/it]

  8%|▊         | 1331/16104 [6:10:25<58:43:40, 14.31s/it]

  8%|▊         | 1332/16104 [6:10:38<57:08:44, 13.93s/it]


  8%|▊         | 1334/16104 [6:11:07<59:07:53, 14.41s/it]
{'loss': 0.5938, 'learning_rate': 1.9854223491192183e-06, 'rewards/chosen': -0.5758602023124695, 'rewards/rejected': -1.2602300643920898, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6843699216842651, 'policy_logps/rejected': -421.5859680175781, 'policy_logps/chosen': -294.4126281738281, 'referece_logps/rejected': -408.9836730957031, 'referece_logps/chosen': -288.654052734375, 'logits/rejected': -0.446219265460968, 'logits/chosen': -0.42909032106399536, 'epoch': 0.5}

  8%|▊         | 1335/16104 [6:11:27<65:19:51, 15.92s/it]

  8%|▊         | 1336/16104 [6:11:50<74:24:14, 18.14s/it]

  8%|▊         | 1337/16104 [6:12:06<71:36:03, 17.46s/it]


  8%|▊         | 1339/16104 [6:12:33<64:13:52, 15.66s/it]
{'loss': 0.6077, 'learning_rate': 1.9852507669989714e-06, 'rewards/chosen': -1.0394649505615234, 'rewards/rejected': -1.1508525609970093, 'rewards/accuracies': 0.625, 'rewards/margins': 0.11138764768838882, 'policy_logps/rejected': -667.8751831054688, 'policy_logps/chosen': -522.5744018554688, 'referece_logps/rejected': -656.3666381835938, 'referece_logps/chosen': -512.1797485351562, 'logits/rejected': -0.855406641960144, 'logits/chosen': -0.6228870749473572, 'epoch': 0.5}

  8%|▊         | 1340/16104 [6:12:49<64:03:28, 15.62s/it]

  8%|▊         | 1341/16104 [6:13:03<61:53:42, 15.09s/it]

  8%|▊         | 1342/16104 [6:13:16<59:09:14, 14.43s/it]

  8%|▊         | 1343/16104 [6:13:32<61:49:21, 15.08s/it]

  8%|▊         | 1344/16104 [6:13:48<62:47:25, 15.31s/it]

  8%|▊         | 1345/16104 [6:14:02<61:00:49, 14.88s/it]

  8%|▊         | 1346/16104 [6:14:13<55:53:33, 13.63s/it]

  8%|▊         | 1347/16104 [6:14:26<55:31:23, 13.55s/it]

  8%|▊         | 1348/16104 [6:14:38<54:13:30, 13.23s/it]

  8%|▊         | 1349/16104 [6:14:57<60:42:55, 14.81s/it]

  8%|▊         | 1350/16104 [6:15:13<61:59:16, 15.13s/it]
[2024-04-05 21:40:39,320] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  8%|▊         | 1351/16104 [6:15:32<67:06:02, 16.37s/it]

  8%|▊         | 1352/16104 [6:15:52<71:37:51, 17.48s/it]

  8%|▊         | 1353/16104 [6:16:13<75:45:15, 18.49s/it]


  8%|▊         | 1355/16104 [6:16:52<77:02:03, 18.80s/it]
{'loss': 0.546, 'learning_rate': 1.9846950094108006e-06, 'rewards/chosen': -0.5476238131523132, 'rewards/rejected': -0.9741893410682678, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4265655279159546, 'policy_logps/rejected': -470.39886474609375, 'policy_logps/chosen': -377.7428894042969, 'referece_logps/rejected': -460.656982421875, 'referece_logps/chosen': -372.2666320800781, 'logits/rejected': -0.10533501952886581, 'logits/chosen': -0.09870990365743637, 'epoch': 0.5}

  8%|▊         | 1356/16104 [6:17:11<77:21:29, 18.88s/it]


  8%|▊         | 1358/16104 [6:17:50<78:47:00, 19.23s/it]
{'loss': 0.6224, 'learning_rate': 1.984589669457621e-06, 'rewards/chosen': -0.5254177451133728, 'rewards/rejected': -0.99689781665802, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4714800715446472, 'policy_logps/rejected': -429.6408996582031, 'policy_logps/chosen': -401.72808837890625, 'referece_logps/rejected': -419.6719055175781, 'referece_logps/chosen': -396.4739074707031, 'logits/rejected': 0.48420584201812744, 'logits/chosen': 0.39656078815460205, 'epoch': 0.51}


  8%|▊         | 1360/16104 [6:18:25<76:03:21, 18.57s/it]

  8%|▊         | 1361/16104 [6:18:42<75:01:38, 18.32s/it]

  8%|▊         | 1362/16104 [6:19:01<75:15:00, 18.38s/it]

  8%|▊         | 1363/16104 [6:19:15<69:48:25, 17.05s/it]

  8%|▊         | 1364/16104 [6:19:34<72:27:42, 17.70s/it]

  8%|▊         | 1365/16104 [6:19:50<70:44:55, 17.28s/it]

  8%|▊         | 1366/16104 [6:20:07<70:09:05, 17.14s/it]

  8%|▊         | 1367/16104 [6:20:29<75:55:06, 18.55s/it]

  8%|▊         | 1368/16104 [6:20:41<68:03:48, 16.63s/it]

  9%|▊         | 1369/16104 [6:21:00<71:20:19, 17.43s/it]

  9%|▊         | 1370/16104 [6:21:18<71:59:33, 17.59s/it]

  9%|▊         | 1371/16104 [6:21:34<69:07:50, 16.89s/it]

  9%|▊         | 1372/16104 [6:21:45<62:12:42, 15.20s/it]

  9%|▊         | 1373/16104 [6:22:05<67:59:31, 16.62s/it]

  9%|▊         | 1374/16104 [6:22:27<74:24:53, 18.19s/it]

  9%|▊         | 1375/16104 [6:22:40<68:05:46, 16.64s/it]

  9%|▊         | 1376/16104 [6:22:53<63:30:05, 15.52s/it]

  9%|▊         | 1377/16104 [6:23:13<69:59:41, 17.11s/it]
[2024-04-05 21:48:20,573] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▊         | 1378/16104 [6:23:35<75:16:31, 18.40s/it]
[2024-04-05 21:48:41,990] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▊         | 1379/16104 [6:23:50<70:54:08, 17.33s/it]

  9%|▊         | 1380/16104 [6:24:02<65:13:31, 15.95s/it]

  9%|▊         | 1381/16104 [6:24:19<65:50:16, 16.10s/it]

  9%|▊         | 1382/16104 [6:24:41<73:11:02, 17.90s/it]

  9%|▊         | 1383/16104 [6:25:05<80:21:35, 19.65s/it]

  9%|▊         | 1384/16104 [6:25:19<73:43:52, 18.03s/it]

  9%|▊         | 1385/16104 [6:25:34<70:27:37, 17.23s/it]

  9%|▊         | 1386/16104 [6:25:57<77:30:37, 18.96s/it]

  9%|▊         | 1387/16104 [6:26:15<75:44:26, 18.53s/it]

  9%|▊         | 1388/16104 [6:26:25<66:03:42, 16.16s/it]

  9%|▊         | 1389/16104 [6:26:45<70:19:37, 17.21s/it]

  9%|▊         | 1390/16104 [6:27:03<71:34:27, 17.51s/it]

  9%|▊         | 1391/16104 [6:27:23<74:04:33, 18.13s/it]
[2024-04-05 21:52:30,026] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▊         | 1392/16104 [6:27:37<68:44:21, 16.82s/it]

  9%|▊         | 1393/16104 [6:27:53<68:13:14, 16.69s/it]

  9%|▊         | 1394/16104 [6:28:10<68:12:23, 16.69s/it]

  9%|▊         | 1395/16104 [6:28:29<71:30:20, 17.50s/it]

  9%|▊         | 1396/16104 [6:28:45<69:31:37, 17.02s/it]

  9%|▊         | 1397/16104 [6:29:01<68:38:13, 16.80s/it]
{'loss': 0.6374, 'learning_rate': 1.9831876447378428e-06, 'rewards/chosen': -0.505541980266571, 'rewards/rejected': -0.9949612021446228, 'rewards/accuracies': 0.625, 'rewards/margins': 0.489419162273407, 'policy_logps/rejected': -380.2301940917969, 'policy_logps/chosen': -502.44464111328125, 'referece_logps/rejected': -370.28057861328125, 'referece_logps/chosen': -497.38922119140625, 'logits/rejected': -0.5643791556358337, 'logits/chosen': -0.870051920413971, 'epoch': 0.52}


  9%|▊         | 1399/16104 [6:29:40<73:41:06, 18.04s/it]

  9%|▊         | 1400/16104 [6:29:59<74:59:25, 18.36s/it]

  9%|▊         | 1401/16104 [6:30:11<67:07:59, 16.44s/it]

  9%|▊         | 1402/16104 [6:30:24<62:38:26, 15.34s/it]

  9%|▊         | 1403/16104 [6:30:43<68:09:47, 16.69s/it]

  9%|▊         | 1404/16104 [6:31:06<75:07:04, 18.40s/it]

  9%|▊         | 1405/16104 [6:31:18<67:20:22, 16.49s/it]

  9%|▊         | 1406/16104 [6:31:30<62:10:14, 15.23s/it]

  9%|▊         | 1407/16104 [6:31:51<69:15:58, 16.97s/it]

  9%|▊         | 1408/16104 [6:32:12<74:11:35, 18.17s/it]

  9%|▊         | 1409/16104 [6:32:29<71:59:13, 17.64s/it]

  9%|▉         | 1410/16104 [6:32:39<63:20:48, 15.52s/it]

  9%|▉         | 1411/16104 [6:33:00<70:26:33, 17.26s/it]

  9%|▉         | 1412/16104 [6:33:12<63:59:15, 15.68s/it]

  9%|▉         | 1413/16104 [6:33:31<67:58:31, 16.66s/it]

  9%|▉         | 1414/16104 [6:33:48<68:28:44, 16.78s/it]

  9%|▉         | 1415/16104 [6:33:59<61:06:45, 14.98s/it]
{'loss': 0.6101, 'learning_rate': 1.9825201482700107e-06, 'rewards/chosen': -1.023235559463501, 'rewards/rejected': -0.9735581278800964, 'rewards/accuracies': 0.375, 'rewards/margins': -0.049677394330501556, 'policy_logps/rejected': -251.03594970703125, 'policy_logps/chosen': -310.8887939453125, 'referece_logps/rejected': -241.30038452148438, 'referece_logps/chosen': -300.65643310546875, 'logits/rejected': -0.91885906457901, 'logits/chosen': -0.8792118430137634, 'epoch': 0.53}
[2024-04-05 21:59:30,206] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1416/16104 [6:34:23<71:55:07, 17.63s/it]


  9%|▉         | 1418/16104 [6:35:02<74:31:21, 18.27s/it]
{'loss': 0.5796, 'learning_rate': 1.9824076466634985e-06, 'rewards/chosen': -0.8385505676269531, 'rewards/rejected': -1.153071403503418, 'rewards/accuracies': 0.75, 'rewards/margins': 0.31452083587646484, 'policy_logps/rejected': -256.2401428222656, 'policy_logps/chosen': -482.88116455078125, 'referece_logps/rejected': -244.70944213867188, 'referece_logps/chosen': -474.49566650390625, 'logits/rejected': -0.9495278596878052, 'logits/chosen': -1.0128302574157715, 'epoch': 0.53}
[2024-04-05 22:00:30,183] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  9%|▉         | 1420/16104 [6:35:40<75:01:05, 18.39s/it]
[2024-04-05 22:00:46,736] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6405, 'learning_rate': 1.9823324468892497e-06, 'rewards/chosen': -0.5168300867080688, 'rewards/rejected': -1.1097614765167236, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5929313898086548, 'policy_logps/rejected': -443.6638488769531, 'policy_logps/chosen': -419.13555908203125, 'referece_logps/rejected': -432.56622314453125, 'referece_logps/chosen': -413.96722412109375, 'logits/rejected': 0.4005762040615082, 'logits/chosen': 0.519238293170929, 'epoch': 0.53}


  9%|▉         | 1422/16104 [6:36:16<73:57:47, 18.14s/it]

  9%|▉         | 1423/16104 [6:36:31<70:49:45, 17.37s/it]

  9%|▉         | 1424/16104 [6:36:47<68:26:32, 16.78s/it]

  9%|▉         | 1425/16104 [6:37:08<73:50:21, 18.11s/it]

  9%|▉         | 1426/16104 [6:37:28<76:25:02, 18.74s/it]

  9%|▉         | 1427/16104 [6:37:45<73:31:47, 18.04s/it]

  9%|▉         | 1428/16104 [6:38:07<78:18:18, 19.21s/it]
[2024-04-05 22:03:13,737] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1429/16104 [6:38:27<79:44:13, 19.56s/it]
[2024-04-05 22:03:34,120] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1430/16104 [6:38:48<81:02:47, 19.88s/it]

  9%|▉         | 1431/16104 [6:39:05<78:31:02, 19.26s/it]

  9%|▉         | 1432/16104 [6:39:23<75:57:58, 18.64s/it]

  9%|▉         | 1433/16104 [6:39:39<73:49:57, 18.12s/it]

  9%|▉         | 1434/16104 [6:40:01<78:05:15, 19.16s/it]
[2024-04-05 22:05:08,258] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5044, 'learning_rate': 1.981801598598945e-06, 'rewards/chosen': -1.2282565832138062, 'rewards/rejected': -1.6966052055358887, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4683488607406616, 'policy_logps/rejected': -399.1631164550781, 'policy_logps/chosen': -409.2406005859375, 'referece_logps/rejected': -382.1971130371094, 'referece_logps/chosen': -396.9580383300781, 'logits/rejected': -0.19519788026809692, 'logits/chosen': -0.09869296848773956, 'epoch': 0.53}


  9%|▉         | 1436/16104 [6:40:37<75:07:21, 18.44s/it]

  9%|▉         | 1437/16104 [6:41:00<80:29:31, 19.76s/it]

  9%|▉         | 1438/16104 [6:41:18<79:03:19, 19.41s/it]

  9%|▉         | 1439/16104 [6:41:36<77:16:35, 18.97s/it]

  9%|▉         | 1440/16104 [6:41:52<73:11:21, 17.97s/it]

  9%|▉         | 1441/16104 [6:42:14<78:18:00, 19.22s/it]
[2024-04-05 22:07:21,072] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1442/16104 [6:42:30<74:56:56, 18.40s/it]
[2024-04-05 22:07:37,557] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5255, 'learning_rate': 1.98149476147342e-06, 'rewards/chosen': -0.9425939321517944, 'rewards/rejected': -1.9130847454071045, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9704907536506653, 'policy_logps/rejected': -399.24334716796875, 'policy_logps/chosen': -417.6970520019531, 'referece_logps/rejected': -380.112548828125, 'referece_logps/chosen': -408.2711181640625, 'logits/rejected': -0.5282122492790222, 'logits/chosen': -0.559579610824585, 'epoch': 0.54}


  9%|▉         | 1444/16104 [6:43:00<67:38:12, 16.61s/it]

  9%|▉         | 1445/16104 [6:43:22<74:20:13, 18.26s/it]

  9%|▉         | 1446/16104 [6:43:41<75:59:48, 18.66s/it]

  9%|▉         | 1447/16104 [6:43:54<68:55:49, 16.93s/it]

  9%|▉         | 1448/16104 [6:44:14<72:19:47, 17.77s/it]

  9%|▉         | 1449/16104 [6:44:29<68:56:05, 16.93s/it]

  9%|▉         | 1450/16104 [6:44:53<77:44:47, 19.10s/it]

  9%|▉         | 1451/16104 [6:45:07<71:01:17, 17.45s/it]

  9%|▉         | 1452/16104 [6:45:29<77:35:57, 19.07s/it]

  9%|▉         | 1453/16104 [6:45:50<79:36:53, 19.56s/it]
[2024-04-05 22:10:57,403] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1454/16104 [6:46:13<83:30:28, 20.52s/it]

  9%|▉         | 1455/16104 [6:46:25<73:04:34, 17.96s/it]

  9%|▉         | 1456/16104 [6:46:41<70:25:52, 17.31s/it]
{'loss': 0.5561, 'learning_rate': 1.9809516826915817e-06, 'rewards/chosen': -0.6481302976608276, 'rewards/rejected': -1.0940020084381104, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4458717405796051, 'policy_logps/rejected': -342.57940673828125, 'policy_logps/chosen': -468.4054260253906, 'referece_logps/rejected': -331.639404296875, 'referece_logps/chosen': -461.92413330078125, 'logits/rejected': 1.1255340576171875, 'logits/chosen': 1.0236661434173584, 'epoch': 0.54}


  9%|▉         | 1458/16104 [6:47:07<61:25:16, 15.10s/it]
[2024-04-05 22:12:14,499] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6464, 'learning_rate': 1.9808734650077437e-06, 'rewards/chosen': -0.5111428499221802, 'rewards/rejected': -0.8738389015197754, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3626960515975952, 'policy_logps/rejected': -340.0400085449219, 'policy_logps/chosen': -349.6250915527344, 'referece_logps/rejected': -331.3016052246094, 'referece_logps/chosen': -344.513671875, 'logits/rejected': -1.3089113235473633, 'logits/chosen': -1.1142266988754272, 'epoch': 0.54}


  9%|▉         | 1460/16104 [6:47:42<66:38:01, 16.38s/it]

  9%|▉         | 1461/16104 [6:47:58<65:32:58, 16.12s/it]

  9%|▉         | 1462/16104 [6:48:20<73:26:58, 18.06s/it]

  9%|▉         | 1463/16104 [6:48:37<71:52:20, 17.67s/it]
[2024-04-05 22:13:44,205] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6254, 'learning_rate': 1.9806772264594706e-06, 'rewards/chosen': -0.8855941891670227, 'rewards/rejected': -0.9802181720733643, 'rewards/accuracies': 0.375, 'rewards/margins': 0.09462395310401917, 'policy_logps/rejected': -494.858642578125, 'policy_logps/chosen': -482.8609619140625, 'referece_logps/rejected': -485.05645751953125, 'referece_logps/chosen': -474.0050354003906, 'logits/rejected': -0.8085188865661621, 'logits/chosen': -0.693536639213562, 'epoch': 0.55}


  9%|▉         | 1465/16104 [6:49:21<80:31:18, 19.80s/it]

  9%|▉         | 1466/16104 [6:49:39<78:51:18, 19.39s/it]

  9%|▉         | 1467/16104 [6:49:57<76:41:32, 18.86s/it]

  9%|▉         | 1468/16104 [6:50:09<68:29:26, 16.85s/it]

  9%|▉         | 1469/16104 [6:50:29<72:35:15, 17.86s/it]
[2024-04-05 22:15:36,635] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1470/16104 [6:50:50<76:21:22, 18.78s/it]

  9%|▉         | 1471/16104 [6:51:09<75:47:39, 18.65s/it]

  9%|▉         | 1472/16104 [6:51:27<74:51:57, 18.42s/it]

  9%|▉         | 1473/16104 [6:51:48<78:46:05, 19.38s/it]

  9%|▉         | 1474/16104 [6:52:11<82:54:43, 20.40s/it]
[2024-04-05 22:17:18,211] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1475/16104 [6:52:32<84:10:03, 20.71s/it]
[2024-04-05 22:17:39,647] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1476/16104 [6:52:54<85:06:10, 20.94s/it]

  9%|▉         | 1477/16104 [6:53:14<83:42:11, 20.60s/it]

  9%|▉         | 1478/16104 [6:53:29<77:05:58, 18.98s/it]
{'loss': 0.6052, 'learning_rate': 1.980082561092393e-06, 'rewards/chosen': -0.987840473651886, 'rewards/rejected': -0.6917222142219543, 'rewards/accuracies': 0.25, 'rewards/margins': -0.29611825942993164, 'policy_logps/rejected': -402.16461181640625, 'policy_logps/chosen': -417.2626037597656, 'referece_logps/rejected': -395.2474060058594, 'referece_logps/chosen': -407.3842468261719, 'logits/rejected': -0.8736910820007324, 'logits/chosen': -0.7489779591560364, 'epoch': 0.55}


  9%|▉         | 1480/16104 [6:54:02<72:39:22, 17.89s/it]

  9%|▉         | 1481/16104 [6:54:24<78:11:51, 19.25s/it]

  9%|▉         | 1482/16104 [6:54:37<70:45:29, 17.42s/it]
{'loss': 0.5743, 'learning_rate': 1.9799224768855993e-06, 'rewards/chosen': -0.008809681981801987, 'rewards/rejected': -1.2663750648498535, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2575654983520508, 'policy_logps/rejected': -379.40887451171875, 'policy_logps/chosen': -344.5998229980469, 'referece_logps/rejected': -366.7451171875, 'referece_logps/chosen': -344.5117492675781, 'logits/rejected': -1.1490412950515747, 'logits/chosen': -1.0921775102615356, 'epoch': 0.55}


  9%|▉         | 1484/16104 [6:55:08<66:17:37, 16.32s/it]

  9%|▉         | 1485/16104 [6:55:27<70:16:47, 17.31s/it]

  9%|▉         | 1486/16104 [6:55:39<63:41:54, 15.69s/it]

  9%|▉         | 1487/16104 [6:55:53<61:30:29, 15.15s/it]

  9%|▉         | 1488/16104 [6:56:13<66:57:24, 16.49s/it]
[2024-04-05 22:21:19,776] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1489/16104 [6:56:33<71:41:57, 17.66s/it]

  9%|▉         | 1490/16104 [6:56:52<73:13:14, 18.04s/it]

  9%|▉         | 1491/16104 [6:57:10<72:50:06, 17.94s/it]

  9%|▉         | 1492/16104 [6:57:27<72:29:59, 17.86s/it]

  9%|▉         | 1493/16104 [6:57:50<77:47:28, 19.17s/it]

  9%|▉         | 1494/16104 [6:58:10<79:41:28, 19.64s/it]

  9%|▉         | 1495/16104 [6:58:30<79:55:34, 19.70s/it]

  9%|▉         | 1496/16104 [6:58:44<72:48:30, 17.94s/it]
{'loss': 0.5672, 'learning_rate': 1.9793571882545048e-06, 'rewards/chosen': -0.9677460193634033, 'rewards/rejected': -1.407187581062317, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4394416809082031, 'policy_logps/rejected': -359.0837097167969, 'policy_logps/chosen': -437.32745361328125, 'referece_logps/rejected': -345.0118408203125, 'referece_logps/chosen': -427.6499938964844, 'logits/rejected': -0.8513795137405396, 'logits/chosen': -0.7749354839324951, 'epoch': 0.56}

  9%|▉         | 1497/16104 [6:58:59<69:20:09, 17.09s/it]


  9%|▉         | 1499/16104 [6:59:36<72:47:52, 17.94s/it]

  9%|▉         | 1500/16104 [6:59:48<65:40:40, 16.19s/it]

  9%|▉         | 1501/16104 [7:00:14<77:33:59, 19.12s/it]
{'loss': 0.5823, 'learning_rate': 1.9791534174288544e-06, 'rewards/chosen': -0.9220390319824219, 'rewards/rejected': -1.0685886144638062, 'rewards/accuracies': 0.375, 'rewards/margins': 0.1465495228767395, 'policy_logps/rejected': -460.06463623046875, 'policy_logps/chosen': -508.9670715332031, 'referece_logps/rejected': -449.37872314453125, 'referece_logps/chosen': -499.74664306640625, 'logits/rejected': 0.14310315251350403, 'logits/chosen': 0.03684571385383606, 'epoch': 0.56}


  9%|▉         | 1503/16104 [7:00:54<79:43:18, 19.66s/it]

  9%|▉         | 1504/16104 [7:01:11<76:41:21, 18.91s/it]
{'loss': 0.6425, 'learning_rate': 1.979030679618236e-06, 'rewards/chosen': -0.9406341910362244, 'rewards/rejected': -1.3003700971603394, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3597358465194702, 'policy_logps/rejected': -361.6398010253906, 'policy_logps/chosen': -342.1743469238281, 'referece_logps/rejected': -348.6361389160156, 'referece_logps/chosen': -332.76800537109375, 'logits/rejected': -0.6939425468444824, 'logits/chosen': -0.5495189428329468, 'epoch': 0.56}


  9%|▉         | 1506/16104 [7:01:42<70:43:42, 17.44s/it]
{'loss': 0.5067, 'learning_rate': 1.978948656390708e-06, 'rewards/chosen': -0.853095293045044, 'rewards/rejected': -1.4389177560806274, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5858224630355835, 'policy_logps/rejected': -425.43035888671875, 'policy_logps/chosen': -482.398193359375, 'referece_logps/rejected': -411.04119873046875, 'referece_logps/chosen': -473.86724853515625, 'logits/rejected': -1.1703978776931763, 'logits/chosen': -1.270411729812622, 'epoch': 0.56}


  9%|▉         | 1508/16104 [7:02:12<64:54:36, 16.01s/it]

  9%|▉         | 1509/16104 [7:02:36<74:02:41, 18.26s/it]
[2024-04-05 22:27:42,867] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

  9%|▉         | 1510/16104 [7:02:48<66:49:28, 16.48s/it]
[2024-04-05 22:27:55,198] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5363, 'learning_rate': 1.9787841347463142e-06, 'rewards/chosen': -0.761515200138092, 'rewards/rejected': -0.968901515007019, 'rewards/accuracies': 0.5, 'rewards/margins': 0.20738628506660461, 'policy_logps/rejected': -410.25482177734375, 'policy_logps/chosen': -280.0705871582031, 'referece_logps/rejected': -400.5657958984375, 'referece_logps/chosen': -272.4554443359375, 'logits/rejected': -0.8563517332077026, 'logits/chosen': -0.4673992991447449, 'epoch': 0.56}


  9%|▉         | 1512/16104 [7:03:22<68:12:58, 16.83s/it]
[2024-04-05 22:28:29,591] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5842, 'learning_rate': 1.978701636356069e-06, 'rewards/chosen': -1.0538716316223145, 'rewards/rejected': -1.492431402206421, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4385598301887512, 'policy_logps/rejected': -236.24063110351562, 'policy_logps/chosen': -370.7021789550781, 'referece_logps/rejected': -221.31631469726562, 'referece_logps/chosen': -360.1634521484375, 'logits/rejected': -0.30510905385017395, 'logits/chosen': -0.19805963337421417, 'epoch': 0.56}


  9%|▉         | 1514/16104 [7:03:58<70:18:30, 17.35s/it]

  9%|▉         | 1515/16104 [7:04:17<71:27:06, 17.63s/it]
{'loss': 0.5689, 'learning_rate': 1.978577591848175e-06, 'rewards/chosen': -0.49667567014694214, 'rewards/rejected': -0.7497028112411499, 'rewards/accuracies': 0.625, 'rewards/margins': 0.25302714109420776, 'policy_logps/rejected': -391.71197509765625, 'policy_logps/chosen': -275.25592041015625, 'referece_logps/rejected': -384.2149963378906, 'referece_logps/chosen': -270.2891540527344, 'logits/rejected': -0.5027714967727661, 'logits/chosen': -0.43307071924209595, 'epoch': 0.56}
[2024-04-05 22:29:44,704] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  9%|▉         | 1517/16104 [7:04:58<77:23:21, 19.10s/it]

  9%|▉         | 1518/16104 [7:05:11<69:49:37, 17.23s/it]
{'loss': 0.6228, 'learning_rate': 1.978453191073402e-06, 'rewards/chosen': -0.4743240177631378, 'rewards/rejected': -0.46850645542144775, 'rewards/accuracies': 0.625, 'rewards/margins': -0.005817577242851257, 'policy_logps/rejected': -451.18438720703125, 'policy_logps/chosen': -602.902587890625, 'referece_logps/rejected': -446.49932861328125, 'referece_logps/chosen': -598.159423828125, 'logits/rejected': 0.29003769159317017, 'logits/chosen': 0.21609243750572205, 'epoch': 0.57}

  9%|▉         | 1519/16104 [7:05:29<71:39:56, 17.69s/it]


  9%|▉         | 1521/16104 [7:06:05<71:31:22, 17.66s/it]

  9%|▉         | 1522/16104 [7:06:25<74:20:02, 18.35s/it]

  9%|▉         | 1523/16104 [7:06:45<76:17:06, 18.83s/it]

  9%|▉         | 1524/16104 [7:06:56<67:36:31, 16.69s/it]

  9%|▉         | 1525/16104 [7:07:12<66:55:41, 16.53s/it]

  9%|▉         | 1526/16104 [7:07:28<66:18:19, 16.37s/it]
{'loss': 0.5928, 'learning_rate': 1.9781197142696596e-06, 'rewards/chosen': -1.0280482769012451, 'rewards/rejected': -1.6889315843582153, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6608833074569702, 'policy_logps/rejected': -377.8652038574219, 'policy_logps/chosen': -455.3674011230469, 'referece_logps/rejected': -360.97589111328125, 'referece_logps/chosen': -445.0868835449219, 'logits/rejected': 0.21041050553321838, 'logits/chosen': 0.24661500751972198, 'epoch': 0.57}


  9%|▉         | 1528/16104 [7:08:08<73:27:41, 18.14s/it]
{'loss': 0.5844, 'learning_rate': 1.9780359493680606e-06, 'rewards/chosen': -0.5206797122955322, 'rewards/rejected': -1.0455278158187866, 'rewards/accuracies': 0.625, 'rewards/margins': 0.524848222732544, 'policy_logps/rejected': -311.7095642089844, 'policy_logps/chosen': -319.4365234375, 'referece_logps/rejected': -301.2542724609375, 'referece_logps/chosen': -314.229736328125, 'logits/rejected': -0.8447114825248718, 'logits/chosen': -0.8521336317062378, 'epoch': 0.57}


 10%|▉         | 1530/16104 [7:08:44<71:39:19, 17.70s/it]

 10%|▉         | 1531/16104 [7:09:04<74:29:39, 18.40s/it]

 10%|▉         | 1532/16104 [7:09:14<64:58:20, 16.05s/it]
{'loss': 0.6823, 'learning_rate': 1.977867944818854e-06, 'rewards/chosen': -0.579862654209137, 'rewards/rejected': -0.5374348759651184, 'rewards/accuracies': 0.375, 'rewards/margins': -0.04242774471640587, 'policy_logps/rejected': -333.9754333496094, 'policy_logps/chosen': -423.23968505859375, 'referece_logps/rejected': -328.6011047363281, 'referece_logps/chosen': -417.4410095214844, 'logits/rejected': -0.12148422002792358, 'logits/chosen': -0.18472842872142792, 'epoch': 0.57}


 10%|▉         | 1534/16104 [7:09:53<72:00:58, 17.79s/it]
{'loss': 0.5339, 'learning_rate': 1.97778370519843e-06, 'rewards/chosen': -0.8573102355003357, 'rewards/rejected': -1.7110660076141357, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8537557721138, 'policy_logps/rejected': -244.01260375976562, 'policy_logps/chosen': -332.9115905761719, 'referece_logps/rejected': -226.90194702148438, 'referece_logps/chosen': -324.3385009765625, 'logits/rejected': -0.35158851742744446, 'logits/chosen': -0.21250447630882263, 'epoch': 0.57}


 10%|▉         | 1536/16104 [7:10:28<72:44:22, 17.98s/it]

 10%|▉         | 1537/16104 [7:10:40<64:59:06, 16.06s/it]
{'loss': 0.5406, 'learning_rate': 1.9776570491238465e-06, 'rewards/chosen': -0.5735059380531311, 'rewards/rejected': -0.8305175304412842, 'rewards/accuracies': 0.75, 'rewards/margins': 0.25701165199279785, 'policy_logps/rejected': -239.11138916015625, 'policy_logps/chosen': -315.8917236328125, 'referece_logps/rejected': -230.80621337890625, 'referece_logps/chosen': -310.1567077636719, 'logits/rejected': -0.2608572840690613, 'logits/chosen': -0.15552878379821777, 'epoch': 0.57}

 10%|▉         | 1538/16104 [7:11:00<69:22:20, 17.15s/it]


 10%|▉         | 1540/16104 [7:11:39<74:36:03, 18.44s/it]
{'loss': 0.5903, 'learning_rate': 1.977530037117522e-06, 'rewards/chosen': -0.8235296010971069, 'rewards/rejected': -1.0452505350112915, 'rewards/accuracies': 0.5, 'rewards/margins': 0.22172099351882935, 'policy_logps/rejected': -361.67535400390625, 'policy_logps/chosen': -355.22686767578125, 'referece_logps/rejected': -351.22283935546875, 'referece_logps/chosen': -346.9915466308594, 'logits/rejected': -0.8423843383789062, 'logits/chosen': -0.8180152177810669, 'epoch': 0.57}


 10%|▉         | 1542/16104 [7:12:02<61:28:12, 15.20s/it]

 10%|▉         | 1543/16104 [7:12:23<68:08:11, 16.85s/it]
{'loss': 0.5115, 'learning_rate': 1.9774026692256976e-06, 'rewards/chosen': -0.6628586053848267, 'rewards/rejected': -1.255815863609314, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5929572582244873, 'policy_logps/rejected': -490.19085693359375, 'policy_logps/chosen': -504.15155029296875, 'referece_logps/rejected': -477.6327209472656, 'referece_logps/chosen': -497.5229797363281, 'logits/rejected': -0.39364543557167053, 'logits/chosen': -0.2983653247356415, 'epoch': 0.57}

 10%|▉         | 1544/16104 [7:12:42<70:13:48, 17.36s/it]


 10%|▉         | 1546/16104 [7:13:11<65:50:23, 16.28s/it]
{'loss': 0.6437, 'learning_rate': 1.9772749454947432e-06, 'rewards/chosen': -0.2647663354873657, 'rewards/rejected': -0.9918571710586548, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7270908951759338, 'policy_logps/rejected': -521.4963989257812, 'policy_logps/chosen': -526.0657958984375, 'referece_logps/rejected': -511.5777893066406, 'referece_logps/chosen': -523.4180908203125, 'logits/rejected': -0.31546589732170105, 'logits/chosen': -0.2723969519138336, 'epoch': 0.58}


 10%|▉         | 1548/16104 [7:13:53<75:08:12, 18.58s/it]

 10%|▉         | 1549/16104 [7:14:09<72:26:10, 17.92s/it]
{'loss': 0.7181, 'learning_rate': 1.9771468659711594e-06, 'rewards/chosen': -0.9517786502838135, 'rewards/rejected': -0.9398614168167114, 'rewards/accuracies': 0.375, 'rewards/margins': -0.01191723346710205, 'policy_logps/rejected': -419.1514587402344, 'policy_logps/chosen': -438.260009765625, 'referece_logps/rejected': -409.7528076171875, 'referece_logps/chosen': -428.7421875, 'logits/rejected': -0.4852740466594696, 'logits/chosen': -0.4864737093448639, 'epoch': 0.58}

 10%|▉         | 1550/16104 [7:14:20<64:15:13, 15.89s/it]


 10%|▉         | 1552/16104 [7:14:53<65:28:36, 16.20s/it]

 10%|▉         | 1553/16104 [7:15:13<70:04:25, 17.34s/it]

 10%|▉         | 1554/16104 [7:15:33<72:55:27, 18.04s/it]

 10%|▉         | 1555/16104 [7:15:45<66:20:56, 16.42s/it]

 10%|▉         | 1556/16104 [7:16:06<72:12:31, 17.87s/it]
{'loss': 0.5802, 'learning_rate': 1.9768466303736324e-06, 'rewards/chosen': -0.7746771574020386, 'rewards/rejected': -0.9570794105529785, 'rewards/accuracies': 0.75, 'rewards/margins': 0.18240228295326233, 'policy_logps/rejected': -276.4643859863281, 'policy_logps/chosen': -313.8057861328125, 'referece_logps/rejected': -266.8935852050781, 'referece_logps/chosen': -306.0589904785156, 'logits/rejected': -0.7645530700683594, 'logits/chosen': -0.686951220035553, 'epoch': 0.58}


 10%|▉         | 1558/16104 [7:16:33<63:59:01, 15.84s/it]

 10%|▉         | 1559/16104 [7:16:53<69:08:08, 17.11s/it]
{'loss': 0.6265, 'learning_rate': 1.9767173652121113e-06, 'rewards/chosen': -0.5476846694946289, 'rewards/rejected': -1.0788109302520752, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5311262011528015, 'policy_logps/rejected': -328.8969421386719, 'policy_logps/chosen': -340.3115539550781, 'referece_logps/rejected': -318.1088562011719, 'referece_logps/chosen': -334.834716796875, 'logits/rejected': -0.17417699098587036, 'logits/chosen': -0.19088660180568695, 'epoch': 0.58}
[2024-04-05 22:42:15,181] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 10%|▉         | 1560/16104 [7:17:08<66:03:26, 16.35s/it]


 10%|▉         | 1562/16104 [7:17:33<58:06:28, 14.39s/it]

 10%|▉         | 1563/16104 [7:17:51<62:20:59, 15.44s/it]

 10%|▉         | 1564/16104 [7:18:03<58:55:54, 14.59s/it]
{'loss': 0.626, 'learning_rate': 1.9765011331003554e-06, 'rewards/chosen': -0.5534731149673462, 'rewards/rejected': -0.7607492804527283, 'rewards/accuracies': 0.875, 'rewards/margins': 0.20727604627609253, 'policy_logps/rejected': -323.10443115234375, 'policy_logps/chosen': -471.3932800292969, 'referece_logps/rejected': -315.4969482421875, 'referece_logps/chosen': -465.8585510253906, 'logits/rejected': -0.3282754421234131, 'logits/chosen': -0.27472126483917236, 'epoch': 0.58}


 10%|▉         | 1566/16104 [7:18:27<53:43:19, 13.30s/it]
{'loss': 0.6233, 'learning_rate': 1.9764143637349027e-06, 'rewards/chosen': -0.6962041854858398, 'rewards/rejected': -0.5869701504707336, 'rewards/accuracies': 0.5, 'rewards/margins': -0.1092340350151062, 'policy_logps/rejected': -510.82476806640625, 'policy_logps/chosen': -492.7174072265625, 'referece_logps/rejected': -504.95501708984375, 'referece_logps/chosen': -485.75537109375, 'logits/rejected': -0.8120847940444946, 'logits/chosen': -0.8708542585372925, 'epoch': 0.58}


 10%|▉         | 1568/16104 [7:18:57<55:59:23, 13.87s/it]

 10%|▉         | 1569/16104 [7:19:15<60:17:58, 14.93s/it]

 10%|▉         | 1570/16104 [7:19:33<64:30:03, 15.98s/it]

 10%|▉         | 1571/16104 [7:19:45<59:48:12, 14.81s/it]
{'loss': 0.6753, 'learning_rate': 1.976196749142243e-06, 'rewards/chosen': -0.6537622213363647, 'rewards/rejected': -0.48278331756591797, 'rewards/accuracies': 0.25, 'rewards/margins': -0.17097893357276917, 'policy_logps/rejected': -419.14520263671875, 'policy_logps/chosen': -357.672119140625, 'referece_logps/rejected': -414.3173522949219, 'referece_logps/chosen': -351.1344909667969, 'logits/rejected': -0.16413572430610657, 'logits/chosen': -0.10418924689292908, 'epoch': 0.59}

 10%|▉         | 1572/16104 [7:20:04<64:26:03, 15.96s/it]


 10%|▉         | 1574/16104 [7:20:39<69:46:36, 17.29s/it]

 10%|▉         | 1575/16104 [7:20:57<70:52:05, 17.56s/it]
{'loss': 0.5272, 'learning_rate': 1.976021946657366e-06, 'rewards/chosen': -0.9159814715385437, 'rewards/rejected': -1.295035719871521, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3790542483329773, 'policy_logps/rejected': -325.2898254394531, 'policy_logps/chosen': -493.1012268066406, 'referece_logps/rejected': -312.3394470214844, 'referece_logps/chosen': -483.9414367675781, 'logits/rejected': 0.4823410212993622, 'logits/chosen': 0.12598377466201782, 'epoch': 0.59}


 10%|▉         | 1577/16104 [7:21:34<71:06:45, 17.62s/it]
{'loss': 0.601, 'learning_rate': 1.975934308516876e-06, 'rewards/chosen': -0.6715160608291626, 'rewards/rejected': -1.069419026374817, 'rewards/accuracies': 1.0, 'rewards/margins': 0.3979029953479767, 'policy_logps/rejected': -358.729248046875, 'policy_logps/chosen': -319.5123596191406, 'referece_logps/rejected': -348.03509521484375, 'referece_logps/chosen': -312.79718017578125, 'logits/rejected': -0.6805040240287781, 'logits/chosen': -0.536760687828064, 'epoch': 0.59}

 10%|▉         | 1578/16104 [7:21:46<64:56:02, 16.09s/it]


 10%|▉         | 1580/16104 [7:22:16<61:10:14, 15.16s/it]

 10%|▉         | 1581/16104 [7:22:29<59:15:14, 14.69s/it]

 10%|▉         | 1582/16104 [7:22:48<63:26:01, 15.73s/it]
{'loss': 0.5506, 'learning_rate': 1.9757145223267645e-06, 'rewards/chosen': -1.3077938556671143, 'rewards/rejected': -2.091064929962158, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7832711338996887, 'policy_logps/rejected': -432.48291015625, 'policy_logps/chosen': -584.34521484375, 'referece_logps/rejected': -411.572265625, 'referece_logps/chosen': -571.267333984375, 'logits/rejected': 0.1087382361292839, 'logits/chosen': 0.20200704038143158, 'epoch': 0.59}

 10%|▉         | 1583/16104 [7:22:59<57:48:50, 14.33s/it]


 10%|▉         | 1585/16104 [7:23:40<70:37:09, 17.51s/it]
{'loss': 0.4931, 'learning_rate': 1.9755821769657462e-06, 'rewards/chosen': -0.4359129071235657, 'rewards/rejected': -1.1047351360321045, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6688222289085388, 'policy_logps/rejected': -411.19573974609375, 'policy_logps/chosen': -463.7506408691406, 'referece_logps/rejected': -400.1484069824219, 'referece_logps/chosen': -459.3915100097656, 'logits/rejected': 0.2850537896156311, 'logits/chosen': 0.42104995250701904, 'epoch': 0.59}

 10%|▉         | 1586/16104 [7:23:55<67:35:22, 16.76s/it]


 10%|▉         | 1588/16104 [7:24:28<66:40:15, 16.53s/it]

 10%|▉         | 1589/16104 [7:24:44<65:59:50, 16.37s/it]
{'loss': 0.5686, 'learning_rate': 1.9754051639961907e-06, 'rewards/chosen': -0.7675085663795471, 'rewards/rejected': -1.412754774093628, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6452462077140808, 'policy_logps/rejected': -326.417724609375, 'policy_logps/chosen': -397.18145751953125, 'referece_logps/rejected': -312.2901611328125, 'referece_logps/chosen': -389.50640869140625, 'logits/rejected': -0.11654061079025269, 'logits/chosen': -0.01205889880657196, 'epoch': 0.59}

 10%|▉         | 1590/16104 [7:25:04<70:56:23, 17.60s/it]
[2024-04-05 22:50:31,218] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 10%|▉         | 1592/16104 [7:25:36<65:33:00, 16.26s/it]
{'loss': 0.59, 'learning_rate': 1.9752719899655294e-06, 'rewards/chosen': -0.890458881855011, 'rewards/rejected': -0.9659391045570374, 'rewards/accuracies': 0.5, 'rewards/margins': 0.07548025250434875, 'policy_logps/rejected': -374.8832702636719, 'policy_logps/chosen': -362.9739990234375, 'referece_logps/rejected': -365.223876953125, 'referece_logps/chosen': -354.06939697265625, 'logits/rejected': -0.626522421836853, 'logits/chosen': -0.6496880054473877, 'epoch': 0.59}


 10%|▉         | 1594/16104 [7:26:16<72:28:56, 17.98s/it]
{'loss': 0.6929, 'learning_rate': 1.975183010017967e-06, 'rewards/chosen': -0.8895073533058167, 'rewards/rejected': -0.9513291120529175, 'rewards/accuracies': 0.625, 'rewards/margins': 0.06182170659303665, 'policy_logps/rejected': -483.44818115234375, 'policy_logps/chosen': -270.560791015625, 'referece_logps/rejected': -473.93487548828125, 'referece_logps/chosen': -261.66571044921875, 'logits/rejected': 0.6785018444061279, 'logits/chosen': 0.661773681640625, 'epoch': 0.59}

 10%|▉         | 1595/16104 [7:26:37<76:14:05, 18.92s/it]

 10%|▉         | 1596/16104 [7:26:51<70:18:28, 17.45s/it]

 10%|▉         | 1597/16104 [7:27:03<63:39:07, 15.80s/it]


 10%|▉         | 1599/16104 [7:27:28<56:08:54, 13.94s/it]

 10%|▉         | 1600/16104 [7:27:48<63:29:45, 15.76s/it]
{'loss': 0.5846, 'learning_rate': 1.9749151234835773e-06, 'rewards/chosen': -0.3203333020210266, 'rewards/rejected': -0.7491841316223145, 'rewards/accuracies': 0.875, 'rewards/margins': 0.42885085940361023, 'policy_logps/rejected': -552.3885498046875, 'policy_logps/chosen': -416.10552978515625, 'referece_logps/rejected': -544.8966674804688, 'referece_logps/chosen': -412.9021301269531, 'logits/rejected': -0.6972200870513916, 'logits/chosen': -0.5838554501533508, 'epoch': 0.6}

 10%|▉         | 1601/16104 [7:28:06<66:49:04, 16.59s/it]


 10%|▉         | 1603/16104 [7:28:46<74:13:53, 18.43s/it]

 10%|▉         | 1604/16104 [7:28:59<68:06:51, 16.91s/it]

 10%|▉         | 1605/16104 [7:29:18<69:39:45, 17.30s/it]

 10%|▉         | 1606/16104 [7:29:38<73:25:55, 18.23s/it]

 10%|▉         | 1607/16104 [7:29:56<72:56:04, 18.11s/it]
{'loss': 0.5422, 'learning_rate': 1.974600794835105e-06, 'rewards/chosen': -0.8565099239349365, 'rewards/rejected': -1.1945390701293945, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3380289077758789, 'policy_logps/rejected': -403.3835144042969, 'policy_logps/chosen': -405.2414245605469, 'referece_logps/rejected': -391.4381103515625, 'referece_logps/chosen': -396.6763000488281, 'logits/rejected': 0.2696973383426666, 'logits/chosen': 0.27471500635147095, 'epoch': 0.6}


 10%|▉         | 1609/16104 [7:30:26<67:06:34, 16.67s/it]
{'loss': 0.5396, 'learning_rate': 1.9745106318034705e-06, 'rewards/chosen': -0.6471496820449829, 'rewards/rejected': -1.231264352798462, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5841146111488342, 'policy_logps/rejected': -324.989501953125, 'policy_logps/chosen': -288.28216552734375, 'referece_logps/rejected': -312.6768493652344, 'referece_logps/chosen': -281.81060791015625, 'logits/rejected': -0.5833352208137512, 'logits/chosen': -0.585567831993103, 'epoch': 0.6}

 10%|▉         | 1610/16104 [7:30:49<74:10:55, 18.43s/it]

 10%|█         | 1611/16104 [7:31:03<68:47:49, 17.09s/it]


 10%|█         | 1613/16104 [7:31:28<59:29:59, 14.78s/it]
{'loss': 0.6528, 'learning_rate': 1.9743298327064916e-06, 'rewards/chosen': -0.6947461366653442, 'rewards/rejected': -1.1948474645614624, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5001013875007629, 'policy_logps/rejected': -357.108154296875, 'policy_logps/chosen': -319.8578796386719, 'referece_logps/rejected': -345.15966796875, 'referece_logps/chosen': -312.9104309082031, 'logits/rejected': -0.7368792295455933, 'logits/chosen': -0.7427648305892944, 'epoch': 0.6}

 10%|█         | 1614/16104 [7:31:39<54:56:06, 13.65s/it]

 10%|█         | 1615/16104 [7:31:51<52:20:19, 13.00s/it]

 10%|█         | 1616/16104 [7:32:07<56:52:28, 14.13s/it]

 10%|█         | 1617/16104 [7:32:24<59:25:07, 14.77s/it]

 10%|█         | 1618/16104 [7:32:46<68:37:07, 17.05s/it]
{'loss': 0.6287, 'learning_rate': 1.9741029470480057e-06, 'rewards/chosen': -0.6936255097389221, 'rewards/rejected': -1.252376675605774, 'rewards/accuracies': 0.75, 'rewards/margins': 0.558751106262207, 'policy_logps/rejected': -368.2682800292969, 'policy_logps/chosen': -531.811279296875, 'referece_logps/rejected': -355.7445068359375, 'referece_logps/chosen': -524.875, 'logits/rejected': 0.07247571647167206, 'logits/chosen': 0.0559404231607914, 'epoch': 0.6}

 10%|█         | 1619/16104 [7:33:03<68:03:04, 16.91s/it]

 10%|█         | 1620/16104 [7:33:16<63:42:18, 15.83s/it]

 10%|█         | 1621/16104 [7:33:33<65:52:36, 16.37s/it]


 10%|█         | 1623/16104 [7:34:12<72:47:54, 18.10s/it]
{'loss': 0.5377, 'learning_rate': 1.973875076284537e-06, 'rewards/chosen': -0.8295350670814514, 'rewards/rejected': -1.028961420059204, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1994263231754303, 'policy_logps/rejected': -369.09405517578125, 'policy_logps/chosen': -328.40411376953125, 'referece_logps/rejected': -358.8044128417969, 'referece_logps/chosen': -320.1087646484375, 'logits/rejected': -0.3210678696632385, 'logits/chosen': -0.3080770969390869, 'epoch': 0.6}

 10%|█         | 1624/16104 [7:34:30<72:05:56, 17.93s/it]

 10%|█         | 1625/16104 [7:34:50<74:29:05, 18.52s/it]

 10%|█         | 1626/16104 [7:35:12<78:56:45, 19.63s/it]


 10%|█         | 1628/16104 [7:35:48<73:49:34, 18.36s/it]
{'loss': 0.5892, 'learning_rate': 1.973646220646531e-06, 'rewards/chosen': -0.19617149233818054, 'rewards/rejected': -1.0979242324829102, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9017527103424072, 'policy_logps/rejected': -254.05224609375, 'policy_logps/chosen': -270.16546630859375, 'referece_logps/rejected': -243.072998046875, 'referece_logps/chosen': -268.2037658691406, 'logits/rejected': -0.6561234593391418, 'logits/chosen': -0.689961314201355, 'epoch': 0.61}

 10%|█         | 1629/16104 [7:36:08<75:16:11, 18.72s/it]
[2024-04-05 23:01:36,309] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 10%|█         | 1630/16104 [7:36:29<78:26:33, 19.51s/it]
[2024-04-05 23:01:50,480] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 10%|█         | 1631/16104 [7:36:43<71:59:51, 17.91s/it]

 10%|█         | 1632/16104 [7:37:04<75:17:42, 18.73s/it]


 10%|█         | 1634/16104 [7:37:39<73:15:23, 18.23s/it]
{'loss': 0.6165, 'learning_rate': 1.973370294172471e-06, 'rewards/chosen': -0.45660075545310974, 'rewards/rejected': -1.2137864828109741, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7571858167648315, 'policy_logps/rejected': -325.75018310546875, 'policy_logps/chosen': -274.8219909667969, 'referece_logps/rejected': -313.6122741699219, 'referece_logps/chosen': -270.2559814453125, 'logits/rejected': -0.0780777633190155, 'logits/chosen': -0.03857758641242981, 'epoch': 0.61}

 10%|█         | 1635/16104 [7:37:54<69:45:02, 17.35s/it]


 10%|█         | 1637/16104 [7:38:33<72:43:31, 18.10s/it]
{'loss': 0.5625, 'learning_rate': 1.973231799353677e-06, 'rewards/chosen': -0.27587947249412537, 'rewards/rejected': -0.9724699854850769, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6965904235839844, 'policy_logps/rejected': -454.03436279296875, 'policy_logps/chosen': -436.271484375, 'referece_logps/rejected': -444.30963134765625, 'referece_logps/chosen': -433.5126953125, 'logits/rejected': -0.4467589557170868, 'logits/chosen': -0.3884876072406769, 'epoch': 0.61}

 10%|█         | 1638/16104 [7:38:47<68:10:42, 16.97s/it]

 10%|█         | 1639/16104 [7:39:07<71:52:03, 17.89s/it]

 10%|█         | 1640/16104 [7:39:23<70:02:41, 17.43s/it]

 10%|█         | 1641/16104 [7:39:42<71:13:23, 17.73s/it]

 10%|█         | 1642/16104 [7:39:59<70:51:00, 17.64s/it]

 10%|█         | 1643/16104 [7:40:15<68:56:05, 17.16s/it]

 10%|█         | 1644/16104 [7:40:30<65:54:58, 16.41s/it]

 10%|█         | 1645/16104 [7:40:42<60:08:34, 14.97s/it]

 10%|█         | 1646/16104 [7:41:02<67:15:27, 16.75s/it]

 10%|█         | 1647/16104 [7:41:23<72:05:50, 17.95s/it]


 10%|█         | 1649/16104 [7:41:57<69:59:53, 17.43s/it]

 10%|█         | 1650/16104 [7:42:17<73:00:49, 18.19s/it]
{'loss': 0.5519, 'learning_rate': 1.9726275614168667e-06, 'rewards/chosen': -0.7242954969406128, 'rewards/rejected': -1.3334529399871826, 'rewards/accuracies': 0.875, 'rewards/margins': 0.609157383441925, 'policy_logps/rejected': -427.3134460449219, 'policy_logps/chosen': -408.8087158203125, 'referece_logps/rejected': -413.97894287109375, 'referece_logps/chosen': -401.5657043457031, 'logits/rejected': -0.7251136302947998, 'logits/chosen': -0.7384064793586731, 'epoch': 0.61}

 10%|█         | 1651/16104 [7:42:37<76:03:01, 18.94s/it]

 10%|█         | 1652/16104 [7:42:54<72:44:24, 18.12s/it]

 10%|█         | 1653/16104 [7:43:10<71:05:29, 17.71s/it]
[2024-04-05 23:08:38,566] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 10%|█         | 1654/16104 [7:43:31<74:59:43, 18.68s/it]

 10%|█         | 1655/16104 [7:43:53<78:57:43, 19.67s/it]
[2024-04-05 23:09:22,896] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 10%|█         | 1656/16104 [7:44:16<82:10:34, 20.48s/it]

 10%|█         | 1657/16104 [7:44:30<74:34:12, 18.58s/it]

 10%|█         | 1658/16104 [7:44:52<78:37:53, 19.60s/it]

 10%|█         | 1659/16104 [7:45:10<76:19:52, 19.02s/it]

 10%|█         | 1660/16104 [7:45:26<73:25:05, 18.30s/it]
[2024-04-05 23:10:51,334] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 10%|█         | 1662/16104 [7:45:57<66:34:02, 16.59s/it]
{'loss': 0.5752, 'learning_rate': 1.972063901551851e-06, 'rewards/chosen': -0.9730464220046997, 'rewards/rejected': -1.5012288093566895, 'rewards/accuracies': 0.625, 'rewards/margins': 0.528182327747345, 'policy_logps/rejected': -329.52337646484375, 'policy_logps/chosen': -357.22393798828125, 'referece_logps/rejected': -314.5110778808594, 'referece_logps/chosen': -347.49346923828125, 'logits/rejected': -0.8954513072967529, 'logits/chosen': -0.9342821836471558, 'epoch': 0.62}


 10%|█         | 1664/16104 [7:46:39<75:19:34, 18.78s/it]
{'loss': 0.559, 'learning_rate': 1.9719694076480543e-06, 'rewards/chosen': -0.3143541216850281, 'rewards/rejected': -1.5327495336532593, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2183952331542969, 'policy_logps/rejected': -300.88458251953125, 'policy_logps/chosen': -397.57916259765625, 'referece_logps/rejected': -285.55706787109375, 'referece_logps/chosen': -394.4356384277344, 'logits/rejected': -0.34962064027786255, 'logits/chosen': -0.2777499854564667, 'epoch': 0.62}

 10%|█         | 1665/16104 [7:46:53<69:16:01, 17.27s/it]


 10%|█         | 1667/16104 [7:47:17<59:06:42, 14.74s/it]
{'loss': 0.5975, 'learning_rate': 1.9718273719129205e-06, 'rewards/chosen': -0.5114253759384155, 'rewards/rejected': -0.611710786819458, 'rewards/accuracies': 0.5, 'rewards/margins': 0.1002853512763977, 'policy_logps/rejected': -350.5347900390625, 'policy_logps/chosen': -412.46514892578125, 'referece_logps/rejected': -344.4176940917969, 'referece_logps/chosen': -407.3508605957031, 'logits/rejected': 0.815097451210022, 'logits/chosen': 0.6708911061286926, 'epoch': 0.62}

 10%|█         | 1668/16104 [7:47:29<55:46:42, 13.91s/it]

 10%|█         | 1669/16104 [7:47:42<55:11:51, 13.77s/it]

 10%|█         | 1670/16104 [7:47:55<53:18:16, 13.29s/it]


 10%|█         | 1672/16104 [7:48:27<58:13:17, 14.52s/it]

 10%|█         | 1673/16104 [7:48:43<60:17:40, 15.04s/it]
{'loss': 0.674, 'learning_rate': 1.971542239066432e-06, 'rewards/chosen': -0.9742761254310608, 'rewards/rejected': -1.2511311769485474, 'rewards/accuracies': 0.5, 'rewards/margins': 0.27685511112213135, 'policy_logps/rejected': -419.6290283203125, 'policy_logps/chosen': -405.64300537109375, 'referece_logps/rejected': -407.1177673339844, 'referece_logps/chosen': -395.9002380371094, 'logits/rejected': -0.9089146852493286, 'logits/chosen': -0.8754466772079468, 'epoch': 0.62}


 10%|█         | 1675/16104 [7:49:27<73:59:52, 18.46s/it]
{'loss': 0.6353, 'learning_rate': 1.9714468803588037e-06, 'rewards/chosen': -0.843035876750946, 'rewards/rejected': -1.4843120574951172, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6412762403488159, 'policy_logps/rejected': -564.9934692382812, 'policy_logps/chosen': -524.943359375, 'referece_logps/rejected': -550.1503295898438, 'referece_logps/chosen': -516.5130615234375, 'logits/rejected': -0.0586073100566864, 'logits/chosen': -0.09461268782615662, 'epoch': 0.62}

 10%|█         | 1676/16104 [7:49:38<64:34:26, 16.11s/it]

 10%|█         | 1677/16104 [7:49:56<67:16:43, 16.79s/it]

 10%|█         | 1678/16104 [7:50:15<69:19:29, 17.30s/it]

 10%|█         | 1679/16104 [7:50:28<64:34:24, 16.12s/it]

 10%|█         | 1680/16104 [7:50:46<66:45:25, 16.66s/it]

 10%|█         | 1681/16104 [7:50:58<61:32:56, 15.36s/it]


 10%|█         | 1683/16104 [7:51:27<60:47:35, 15.18s/it]

 10%|█         | 1684/16104 [7:51:41<59:22:32, 14.82s/it]
{'loss': 0.5907, 'learning_rate': 1.971015821208246e-06, 'rewards/chosen': -0.7353530526161194, 'rewards/rejected': -1.0171250104904175, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2817719578742981, 'policy_logps/rejected': -373.8218688964844, 'policy_logps/chosen': -289.20391845703125, 'referece_logps/rejected': -363.650634765625, 'referece_logps/chosen': -281.8503723144531, 'logits/rejected': -0.8136839270591736, 'logits/chosen': -0.4210284352302551, 'epoch': 0.63}

 10%|█         | 1685/16104 [7:52:00<64:14:45, 16.04s/it]


 10%|█         | 1687/16104 [7:52:34<65:59:49, 16.48s/it]

 10%|█         | 1688/16104 [7:52:45<60:11:50, 15.03s/it]

 10%|█         | 1689/16104 [7:53:08<69:09:23, 17.27s/it]
{'loss': 0.5578, 'learning_rate': 1.970774969035615e-06, 'rewards/chosen': -0.6836080551147461, 'rewards/rejected': -0.9339457750320435, 'rewards/accuracies': 0.375, 'rewards/margins': 0.250337690114975, 'policy_logps/rejected': -509.17010498046875, 'policy_logps/chosen': -526.3670043945312, 'referece_logps/rejected': -499.8305969238281, 'referece_logps/chosen': -519.5309448242188, 'logits/rejected': -0.20552495121955872, 'logits/chosen': -0.25260090827941895, 'epoch': 0.63}

 10%|█         | 1690/16104 [7:53:23<66:09:23, 16.52s/it]

 11%|█         | 1691/16104 [7:53:37<63:39:30, 15.90s/it]

 11%|█         | 1692/16104 [7:53:48<58:05:33, 14.51s/it]


 11%|█         | 1694/16104 [7:54:26<66:53:24, 16.71s/it]
[2024-04-05 23:19:32,740] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5674, 'learning_rate': 1.9705331351235673e-06, 'rewards/chosen': -1.033289909362793, 'rewards/rejected': -1.4625763893127441, 'rewards/accuracies': 0.625, 'rewards/margins': 0.42928653955459595, 'policy_logps/rejected': -423.9283447265625, 'policy_logps/chosen': -477.8114929199219, 'referece_logps/rejected': -409.3026123046875, 'referece_logps/chosen': -467.4786376953125, 'logits/rejected': -0.20624934136867523, 'logits/chosen': -0.3081541955471039, 'epoch': 0.63}

 11%|█         | 1695/16104 [7:54:43<67:56:59, 16.98s/it]

 11%|█         | 1696/16104 [7:55:05<73:23:33, 18.34s/it]

 11%|█         | 1697/16104 [7:55:20<70:05:29, 17.51s/it]

 11%|█         | 1698/16104 [7:55:37<69:31:09, 17.37s/it]

 11%|█         | 1699/16104 [7:55:53<67:44:48, 16.93s/it]


 11%|█         | 1701/16104 [7:56:33<74:40:25, 18.66s/it]

 11%|█         | 1702/16104 [7:56:56<78:55:04, 19.73s/it]

 11%|█         | 1703/16104 [7:57:16<79:29:52, 19.87s/it]

 11%|█         | 1704/16104 [7:57:34<77:15:06, 19.31s/it]
{'loss': 0.5733, 'learning_rate': 1.970046523060476e-06, 'rewards/chosen': -0.8600578308105469, 'rewards/rejected': -1.413371205329895, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5533135533332825, 'policy_logps/rejected': -340.2516174316406, 'policy_logps/chosen': -313.0414733886719, 'referece_logps/rejected': -326.1178894042969, 'referece_logps/chosen': -304.44091796875, 'logits/rejected': -1.035441517829895, 'logits/chosen': -1.155070424079895, 'epoch': 0.63}


 11%|█         | 1706/16104 [7:58:10<75:05:45, 18.78s/it]

 11%|█         | 1707/16104 [7:58:30<76:29:56, 19.13s/it]
{'loss': 0.5216, 'learning_rate': 1.9698997741696236e-06, 'rewards/chosen': -0.7573497891426086, 'rewards/rejected': -1.906640648841858, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1492910385131836, 'policy_logps/rejected': -375.0004577636719, 'policy_logps/chosen': -419.5904846191406, 'referece_logps/rejected': -355.93402099609375, 'referece_logps/chosen': -412.0169982910156, 'logits/rejected': -1.0137336254119873, 'logits/chosen': -1.04426908493042, 'epoch': 0.64}

 11%|█         | 1708/16104 [7:58:47<74:24:11, 18.61s/it]


 11%|█         | 1710/16104 [7:59:20<70:26:39, 17.62s/it]

 11%|█         | 1711/16104 [7:59:38<71:24:08, 17.86s/it]

 11%|█         | 1712/16104 [7:59:58<73:59:49, 18.51s/it]
{'loss': 0.5184, 'learning_rate': 1.9696544080277994e-06, 'rewards/chosen': -0.6015364527702332, 'rewards/rejected': -2.1654136180877686, 'rewards/accuracies': 0.625, 'rewards/margins': 1.5638773441314697, 'policy_logps/rejected': -392.5088195800781, 'policy_logps/chosen': -336.8543395996094, 'referece_logps/rejected': -370.85467529296875, 'referece_logps/chosen': -330.8389587402344, 'logits/rejected': -0.7137155532836914, 'logits/chosen': -0.6509133577346802, 'epoch': 0.64}

 11%|█         | 1713/16104 [8:00:16<72:34:06, 18.15s/it]

 11%|█         | 1714/16104 [8:00:37<76:27:04, 19.13s/it]

 11%|█         | 1715/16104 [8:00:53<73:16:09, 18.33s/it]

 11%|█         | 1716/16104 [8:01:10<70:53:08, 17.74s/it]

 11%|█         | 1717/16104 [8:01:25<68:04:56, 17.04s/it]

 11%|█         | 1718/16104 [8:01:45<71:26:38, 17.88s/it]

 11%|█         | 1719/16104 [8:02:05<74:26:22, 18.63s/it]

 11%|█         | 1720/16104 [8:02:25<76:04:23, 19.04s/it]

 11%|█         | 1721/16104 [8:02:36<65:56:02, 16.50s/it]

 11%|█         | 1722/16104 [8:02:49<62:14:28, 15.58s/it]

 11%|█         | 1723/16104 [8:03:03<60:00:17, 15.02s/it]

 11%|█         | 1724/16104 [8:03:18<60:09:48, 15.06s/it]

 11%|█         | 1725/16104 [8:03:37<64:59:54, 16.27s/it]


 11%|█         | 1727/16104 [8:04:16<71:50:55, 17.99s/it]
[2024-04-05 23:29:23,368] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1728/16104 [8:04:30<67:12:45, 16.83s/it]

 11%|█         | 1729/16104 [8:04:53<74:43:51, 18.72s/it]

 11%|█         | 1730/16104 [8:05:09<70:33:48, 17.67s/it]

 11%|█         | 1731/16104 [8:05:27<71:25:30, 17.89s/it]

 11%|█         | 1732/16104 [8:05:48<74:57:17, 18.78s/it]

 11%|█         | 1733/16104 [8:06:11<80:01:10, 20.05s/it]

 11%|█         | 1734/16104 [8:06:27<74:51:16, 18.75s/it]

 11%|█         | 1735/16104 [8:06:40<68:58:05, 17.28s/it]
[2024-04-05 23:31:47,669] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1736/16104 [8:07:02<73:32:15, 18.43s/it]

 11%|█         | 1737/16104 [8:07:20<73:23:46, 18.39s/it]

 11%|█         | 1738/16104 [8:07:35<69:57:08, 17.53s/it]

 11%|█         | 1739/16104 [8:07:59<77:02:11, 19.31s/it]

 11%|█         | 1740/16104 [8:08:13<70:38:34, 17.70s/it]

 11%|█         | 1741/16104 [8:08:29<68:55:07, 17.27s/it]

 11%|█         | 1742/16104 [8:08:46<68:15:19, 17.11s/it]

 11%|█         | 1743/16104 [8:08:59<62:56:28, 15.78s/it]

 11%|█         | 1744/16104 [8:09:09<56:57:42, 14.28s/it]

 11%|█         | 1745/16104 [8:09:27<61:09:35, 15.33s/it]

 11%|█         | 1746/16104 [8:09:48<67:46:09, 16.99s/it]

 11%|█         | 1747/16104 [8:10:05<67:31:42, 16.93s/it]

 11%|█         | 1748/16104 [8:10:23<68:54:39, 17.28s/it]

 11%|█         | 1749/16104 [8:10:39<67:37:12, 16.96s/it]

 11%|█         | 1750/16104 [8:10:54<65:12:47, 16.36s/it]

 11%|█         | 1751/16104 [8:11:11<65:32:57, 16.44s/it]

 11%|█         | 1752/16104 [8:11:29<67:56:16, 17.04s/it]

 11%|█         | 1753/16104 [8:11:41<61:36:24, 15.45s/it]

 11%|█         | 1754/16104 [8:11:57<62:19:37, 15.64s/it]

 11%|█         | 1755/16104 [8:12:09<58:03:05, 14.56s/it]

 11%|█         | 1756/16104 [8:12:25<60:21:26, 15.14s/it]

 11%|█         | 1757/16104 [8:12:36<54:52:27, 13.77s/it]

 11%|█         | 1758/16104 [8:12:56<61:53:29, 15.53s/it]

 11%|█         | 1759/16104 [8:13:16<68:11:23, 17.11s/it]

 11%|█         | 1760/16104 [8:13:34<69:01:50, 17.33s/it]

 11%|█         | 1761/16104 [8:13:49<65:51:40, 16.53s/it]

 11%|█         | 1762/16104 [8:14:04<63:47:32, 16.01s/it]

 11%|█         | 1763/16104 [8:14:27<71:55:42, 18.06s/it]

 11%|█         | 1764/16104 [8:14:44<70:37:18, 17.73s/it]

 11%|█         | 1765/16104 [8:15:04<73:27:56, 18.44s/it]
[2024-04-05 23:40:10,830] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1766/16104 [8:15:14<64:06:21, 16.10s/it]

 11%|█         | 1767/16104 [8:15:35<69:21:40, 17.42s/it]

 11%|█         | 1768/16104 [8:15:47<63:41:11, 15.99s/it]

 11%|█         | 1769/16104 [8:16:04<64:05:10, 16.09s/it]

 11%|█         | 1770/16104 [8:16:16<59:25:23, 14.92s/it]

 11%|█         | 1771/16104 [8:16:30<58:39:45, 14.73s/it]

 11%|█         | 1772/16104 [8:16:44<57:46:39, 14.51s/it]

 11%|█         | 1773/16104 [8:17:05<64:59:54, 16.33s/it]

 11%|█         | 1774/16104 [8:17:20<63:54:52, 16.06s/it]

 11%|█         | 1775/16104 [8:17:42<70:44:19, 17.77s/it]

 11%|█         | 1776/16104 [8:18:02<73:48:35, 18.55s/it]

 11%|█         | 1777/16104 [8:18:18<70:25:39, 17.70s/it]

 11%|█         | 1778/16104 [8:18:39<73:56:48, 18.58s/it]

 11%|█         | 1779/16104 [8:18:55<70:51:54, 17.81s/it]

 11%|█         | 1780/16104 [8:19:13<71:09:11, 17.88s/it]

 11%|█         | 1781/16104 [8:19:32<72:32:09, 18.23s/it]

 11%|█         | 1782/16104 [8:19:51<74:02:49, 18.61s/it]

 11%|█         | 1783/16104 [8:20:08<71:41:07, 18.02s/it]

 11%|█         | 1784/16104 [8:20:25<70:55:44, 17.83s/it]

 11%|█         | 1785/16104 [8:20:46<74:43:31, 18.79s/it]

 11%|█         | 1786/16104 [8:21:04<73:37:02, 18.51s/it]

 11%|█         | 1787/16104 [8:21:25<76:37:12, 19.27s/it]
[2024-04-05 23:46:32,449] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1788/16104 [8:21:41<72:09:31, 18.15s/it]
[2024-04-05 23:46:47,980] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1789/16104 [8:21:55<67:35:51, 17.00s/it]

 11%|█         | 1790/16104 [8:22:16<72:29:28, 18.23s/it]

 11%|█         | 1791/16104 [8:22:35<72:42:34, 18.29s/it]

 11%|█         | 1792/16104 [8:22:56<76:05:40, 19.14s/it]

 11%|█         | 1793/16104 [8:23:15<75:52:30, 19.09s/it]

 11%|█         | 1794/16104 [8:23:34<76:18:33, 19.20s/it]

 11%|█         | 1795/16104 [8:23:52<74:43:43, 18.80s/it]

 11%|█         | 1796/16104 [8:24:10<73:26:43, 18.48s/it]

 11%|█         | 1797/16104 [8:24:26<70:48:42, 17.82s/it]

 11%|█         | 1798/16104 [8:24:40<66:19:06, 16.69s/it]

 11%|█         | 1799/16104 [8:25:00<69:39:15, 17.53s/it]

 11%|█         | 1800/16104 [8:25:13<64:39:39, 16.27s/it]

 11%|█         | 1801/16104 [8:25:28<63:23:18, 15.95s/it]

 11%|█         | 1802/16104 [8:25:46<66:02:06, 16.62s/it]

 11%|█         | 1803/16104 [8:25:58<60:08:13, 15.14s/it]

 11%|█         | 1804/16104 [8:26:10<55:47:04, 14.04s/it]

 11%|█         | 1805/16104 [8:26:23<54:33:48, 13.74s/it]

 11%|█         | 1806/16104 [8:26:38<56:48:41, 14.30s/it]

 11%|█         | 1807/16104 [8:26:50<54:07:55, 13.63s/it]

 11%|█         | 1808/16104 [8:27:11<62:48:24, 15.82s/it]

 11%|█         | 1809/16104 [8:27:28<63:27:20, 15.98s/it]
[2024-04-05 23:52:34,689] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█         | 1810/16104 [8:27:46<66:07:19, 16.65s/it]

 11%|█         | 1811/16104 [8:27:58<61:00:43, 15.37s/it]

 11%|█▏        | 1812/16104 [8:28:11<57:31:45, 14.49s/it]

 11%|█▏        | 1813/16104 [8:28:33<66:46:25, 16.82s/it]

 11%|█▏        | 1814/16104 [8:28:52<69:09:20, 17.42s/it]
[2024-04-05 23:53:58,807] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 11%|█▏        | 1815/16104 [8:29:04<63:07:40, 15.90s/it]

 11%|█▏        | 1816/16104 [8:29:23<67:20:08, 16.97s/it]

 11%|█▏        | 1817/16104 [8:29:44<71:59:23, 18.14s/it]

 11%|█▏        | 1818/16104 [8:29:56<64:14:24, 16.19s/it]

 11%|█▏        | 1819/16104 [8:30:08<59:05:18, 14.89s/it]

 11%|█▏        | 1820/16104 [8:30:24<61:08:12, 15.41s/it]

 11%|█▏        | 1821/16104 [8:30:44<65:46:23, 16.58s/it]

 11%|█▏        | 1822/16104 [8:30:59<64:35:22, 16.28s/it]

 11%|█▏        | 1823/16104 [8:31:15<64:01:51, 16.14s/it]

 11%|█▏        | 1824/16104 [8:31:31<63:49:17, 16.09s/it]

 11%|█▏        | 1825/16104 [8:31:42<57:26:13, 14.48s/it]
{'loss': 0.6311, 'learning_rate': 1.963848113307001e-06, 'rewards/chosen': -0.8658971786499023, 'rewards/rejected': -0.9599432349205017, 'rewards/accuracies': 0.5, 'rewards/margins': 0.09404610097408295, 'policy_logps/rejected': -387.1227111816406, 'policy_logps/chosen': -419.1217041015625, 'referece_logps/rejected': -377.5232849121094, 'referece_logps/chosen': -410.4627380371094, 'logits/rejected': -0.20514324307441711, 'logits/chosen': -0.2197461724281311, 'epoch': 0.68}

 11%|█▏        | 1826/16104 [8:31:57<57:39:46, 14.54s/it]


 11%|█▏        | 1828/16104 [8:32:34<67:10:12, 16.94s/it]

 11%|█▏        | 1829/16104 [8:32:54<70:43:13, 17.83s/it]
[2024-04-05 23:58:01,052] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6414, 'learning_rate': 1.9636334391853117e-06, 'rewards/chosen': -0.4315805435180664, 'rewards/rejected': -1.19613516330719, 'rewards/accuracies': 1.0, 'rewards/margins': 0.764554500579834, 'policy_logps/rejected': -332.89959716796875, 'policy_logps/chosen': -295.504638671875, 'referece_logps/rejected': -320.9382629394531, 'referece_logps/chosen': -291.1888427734375, 'logits/rejected': -0.553837239742279, 'logits/chosen': -0.5123518705368042, 'epoch': 0.68}

 11%|█▏        | 1830/16104 [8:33:05<62:11:57, 15.69s/it]

 11%|█▏        | 1831/16104 [8:33:27<69:54:06, 17.63s/it]

 11%|█▏        | 1832/16104 [8:33:44<69:57:17, 17.65s/it]


 11%|█▏        | 1834/16104 [8:34:16<65:41:38, 16.57s/it]

 11%|█▏        | 1835/16104 [8:34:40<73:52:48, 18.64s/it]
[2024-04-05 23:59:46,941] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5759, 'learning_rate': 1.9633102586256012e-06, 'rewards/chosen': -1.1892945766448975, 'rewards/rejected': -2.0337135791778564, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8444189429283142, 'policy_logps/rejected': -470.6977844238281, 'policy_logps/chosen': -553.405517578125, 'referece_logps/rejected': -450.3606872558594, 'referece_logps/chosen': -541.5125732421875, 'logits/rejected': 0.4358963966369629, 'logits/chosen': 0.4478425681591034, 'epoch': 0.68}

 11%|█▏        | 1836/16104 [8:34:51<64:31:14, 16.28s/it]


 11%|█▏        | 1838/16104 [8:35:21<62:05:01, 15.67s/it]
{'loss': 0.5105, 'learning_rate': 1.963148142253457e-06, 'rewards/chosen': -0.6223182082176208, 'rewards/rejected': -1.168496012687683, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5461777448654175, 'policy_logps/rejected': -295.5383605957031, 'policy_logps/chosen': -292.5904846191406, 'referece_logps/rejected': -283.8534240722656, 'referece_logps/chosen': -286.3673095703125, 'logits/rejected': -0.08404184877872467, 'logits/chosen': -0.12909367680549622, 'epoch': 0.68}


 11%|█▏        | 1840/16104 [8:35:47<57:13:12, 14.44s/it]

 11%|█▏        | 1841/16104 [8:36:06<62:47:07, 15.85s/it]

 11%|█▏        | 1842/16104 [8:36:25<66:41:47, 16.84s/it]

 11%|█▏        | 1843/16104 [8:36:43<68:02:48, 17.18s/it]
{'loss': 0.6643, 'learning_rate': 1.9628771691078874e-06, 'rewards/chosen': -1.064149260520935, 'rewards/rejected': -0.9000486731529236, 'rewards/accuracies': 0.625, 'rewards/margins': -0.16410063207149506, 'policy_logps/rejected': -394.9840087890625, 'policy_logps/chosen': -439.7419738769531, 'referece_logps/rejected': -385.9834899902344, 'referece_logps/chosen': -429.1004943847656, 'logits/rejected': -0.962575376033783, 'logits/chosen': -1.0123919248580933, 'epoch': 0.69}

 11%|█▏        | 1844/16104 [8:37:05<73:30:09, 18.56s/it]

 11%|█▏        | 1845/16104 [8:37:21<70:28:48, 17.79s/it]

 11%|█▏        | 1846/16104 [8:37:43<75:12:01, 18.99s/it]

 11%|█▏        | 1847/16104 [8:38:01<74:17:18, 18.76s/it]

 11%|█▏        | 1848/16104 [8:38:19<73:09:03, 18.47s/it]


 11%|█▏        | 1850/16104 [8:38:57<74:07:24, 18.72s/it]
{'loss': 0.6454, 'learning_rate': 1.962496170861604e-06, 'rewards/chosen': -0.6773784756660461, 'rewards/rejected': -1.2309694290161133, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5535908341407776, 'policy_logps/rejected': -385.55987548828125, 'policy_logps/chosen': -360.1434631347656, 'referece_logps/rejected': -373.25018310546875, 'referece_logps/chosen': -353.3696594238281, 'logits/rejected': -0.614190936088562, 'logits/chosen': -0.5041179656982422, 'epoch': 0.69}


 12%|█▏        | 1852/16104 [8:39:34<74:32:34, 18.83s/it]

 12%|█▏        | 1853/16104 [8:39:54<75:38:10, 19.11s/it]

 12%|█▏        | 1854/16104 [8:40:06<66:42:30, 16.85s/it]

 12%|█▏        | 1855/16104 [8:40:18<61:19:31, 15.49s/it]

 12%|█▏        | 1856/16104 [8:40:32<59:48:12, 15.11s/it]
{'loss': 0.5264, 'learning_rate': 1.96216808245492e-06, 'rewards/chosen': -0.5276890993118286, 'rewards/rejected': -0.9984508752822876, 'rewards/accuracies': 0.75, 'rewards/margins': 0.47076180577278137, 'policy_logps/rejected': -220.35787963867188, 'policy_logps/chosen': -305.57415771484375, 'referece_logps/rejected': -210.37339782714844, 'referece_logps/chosen': -300.2972717285156, 'logits/rejected': 0.0038369959220290184, 'logits/chosen': 0.1701146811246872, 'epoch': 0.69}


 12%|█▏        | 1858/16104 [8:41:15<72:19:28, 18.28s/it]

 12%|█▏        | 1859/16104 [8:41:34<74:05:32, 18.72s/it]

 12%|█▏        | 1860/16104 [8:41:56<76:56:21, 19.45s/it]

 12%|█▏        | 1861/16104 [8:42:17<78:57:13, 19.96s/it]

 12%|█▏        | 1862/16104 [8:42:35<76:45:53, 19.40s/it]

 12%|█▏        | 1863/16104 [8:42:55<77:19:19, 19.55s/it]

 12%|█▏        | 1864/16104 [8:43:12<74:21:36, 18.80s/it]

 12%|█▏        | 1865/16104 [8:43:28<71:43:57, 18.14s/it]

 12%|█▏        | 1866/16104 [8:43:50<75:43:06, 19.14s/it]

 12%|█▏        | 1867/16104 [8:44:07<73:13:30, 18.52s/it]

 12%|█▏        | 1868/16104 [8:44:22<69:38:11, 17.61s/it]

 12%|█▏        | 1869/16104 [8:44:34<62:58:40, 15.93s/it]

 12%|█▏        | 1870/16104 [8:44:54<66:55:43, 16.93s/it]
{'loss': 0.6619, 'learning_rate': 1.9613970946713573e-06, 'rewards/chosen': -0.9394330978393555, 'rewards/rejected': -1.0739245414733887, 'rewards/accuracies': 0.75, 'rewards/margins': 0.13449135422706604, 'policy_logps/rejected': -392.3382568359375, 'policy_logps/chosen': -395.8211975097656, 'referece_logps/rejected': -381.5989990234375, 'referece_logps/chosen': -386.4268798828125, 'logits/rejected': -0.09554894268512726, 'logits/chosen': -0.1489831805229187, 'epoch': 0.7}

 12%|█▏        | 1871/16104 [8:45:15<72:12:24, 18.26s/it]

 12%|█▏        | 1872/16104 [8:45:28<65:16:56, 16.51s/it]

 12%|█▏        | 1873/16104 [8:45:39<59:35:13, 15.07s/it]

 12%|█▏        | 1874/16104 [8:45:57<63:01:16, 15.94s/it]


 12%|█▏        | 1876/16104 [8:46:20<53:22:19, 13.50s/it]

 12%|█▏        | 1877/16104 [8:46:31<50:11:04, 12.70s/it]
{'loss': 0.5991, 'learning_rate': 1.961008741965279e-06, 'rewards/chosen': -0.7209216356277466, 'rewards/rejected': -0.7077221870422363, 'rewards/accuracies': 0.375, 'rewards/margins': -0.013199403882026672, 'policy_logps/rejected': -276.7428894042969, 'policy_logps/chosen': -336.00360107421875, 'referece_logps/rejected': -269.6656494140625, 'referece_logps/chosen': -328.79437255859375, 'logits/rejected': 0.10622522234916687, 'logits/chosen': 0.029731780290603638, 'epoch': 0.7}


 12%|█▏        | 1879/16104 [8:47:02<55:07:48, 13.95s/it]

 12%|█▏        | 1880/16104 [8:47:13<51:12:44, 12.96s/it]

 12%|█▏        | 1881/16104 [8:47:29<55:11:42, 13.97s/it]

 12%|█▏        | 1882/16104 [8:47:47<59:23:31, 15.03s/it]

 12%|█▏        | 1883/16104 [8:48:04<62:13:22, 15.75s/it]

 12%|█▏        | 1884/16104 [8:48:17<59:03:08, 14.95s/it]

 12%|█▏        | 1885/16104 [8:48:35<62:25:36, 15.81s/it]

 12%|█▏        | 1886/16104 [8:48:50<61:49:45, 15.66s/it]

 12%|█▏        | 1887/16104 [8:49:07<63:03:53, 15.97s/it]

 12%|█▏        | 1888/16104 [8:49:29<70:03:58, 17.74s/it]

 12%|█▏        | 1889/16104 [8:49:47<70:08:58, 17.77s/it]

 12%|█▏        | 1890/16104 [8:50:00<65:04:46, 16.48s/it]

 12%|█▏        | 1891/16104 [8:50:17<65:54:39, 16.69s/it]

 12%|█▏        | 1892/16104 [8:50:37<69:51:37, 17.70s/it]

 12%|█▏        | 1893/16104 [8:50:53<67:52:22, 17.19s/it]

 12%|█▏        | 1894/16104 [8:51:13<70:32:50, 17.87s/it]

 12%|█▏        | 1895/16104 [8:51:32<72:35:53, 18.39s/it]
{'loss': 0.5499, 'learning_rate': 1.9600013758176865e-06, 'rewards/chosen': -0.9544965624809265, 'rewards/rejected': -1.6704893112182617, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7159926891326904, 'policy_logps/rejected': -395.8736267089844, 'policy_logps/chosen': -540.3067626953125, 'referece_logps/rejected': -379.1687316894531, 'referece_logps/chosen': -530.7618408203125, 'logits/rejected': 0.12454792112112045, 'logits/chosen': -0.002437591552734375, 'epoch': 0.71}


 12%|█▏        | 1897/16104 [8:52:07<70:45:24, 17.93s/it]

 12%|█▏        | 1898/16104 [8:52:28<75:18:52, 19.09s/it]
{'loss': 0.4896, 'learning_rate': 1.959832257838397e-06, 'rewards/chosen': -0.5771963596343994, 'rewards/rejected': -1.5627403259277344, 'rewards/accuracies': 0.875, 'rewards/margins': 0.985543966293335, 'policy_logps/rejected': -304.4688720703125, 'policy_logps/chosen': -312.6792297363281, 'referece_logps/rejected': -288.84149169921875, 'referece_logps/chosen': -306.9072570800781, 'logits/rejected': 0.04905220866203308, 'logits/chosen': 0.07491765916347504, 'epoch': 0.71}


 12%|█▏        | 1900/16104 [8:52:57<66:18:52, 16.81s/it]
{'loss': 0.5378, 'learning_rate': 1.9597193183804318e-06, 'rewards/chosen': -0.6073673367500305, 'rewards/rejected': -1.5878933668136597, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9805260300636292, 'policy_logps/rejected': -460.6719970703125, 'policy_logps/chosen': -487.4925842285156, 'referece_logps/rejected': -444.7930908203125, 'referece_logps/chosen': -481.41888427734375, 'logits/rejected': -0.4161381125450134, 'logits/chosen': -0.3696083426475525, 'epoch': 0.71}


 12%|█▏        | 1902/16104 [8:53:37<72:09:12, 18.29s/it]

 12%|█▏        | 1903/16104 [8:53:57<73:49:11, 18.71s/it]

 12%|█▏        | 1904/16104 [8:54:15<72:59:59, 18.51s/it]

 12%|█▏        | 1905/16104 [8:54:31<70:45:00, 17.94s/it]
{'loss': 0.5361, 'learning_rate': 1.9594362903842798e-06, 'rewards/chosen': -0.4445219337940216, 'rewards/rejected': -1.0958219766616821, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6513000130653381, 'policy_logps/rejected': -244.31289672851562, 'policy_logps/chosen': -265.8301696777344, 'referece_logps/rejected': -233.35464477539062, 'referece_logps/chosen': -261.38494873046875, 'logits/rejected': -0.2929903268814087, 'logits/chosen': -0.2983141541481018, 'epoch': 0.71}

 12%|█▏        | 1906/16104 [8:54:52<74:21:45, 18.86s/it]


 12%|█▏        | 1908/16104 [8:55:19<62:56:47, 15.96s/it]

 12%|█▏        | 1909/16104 [8:55:31<58:01:02, 14.71s/it]

 12%|█▏        | 1910/16104 [8:55:50<63:20:10, 16.06s/it]

 12%|█▏        | 1911/16104 [8:56:04<60:49:07, 15.43s/it]
{'loss': 0.5732, 'learning_rate': 1.959095376054226e-06, 'rewards/chosen': -0.8360374569892883, 'rewards/rejected': -1.472280502319336, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6362431049346924, 'policy_logps/rejected': -545.6608276367188, 'policy_logps/chosen': -437.021728515625, 'referece_logps/rejected': -530.9380493164062, 'referece_logps/chosen': -428.6613464355469, 'logits/rejected': -0.5886011719703674, 'logits/chosen': -0.4545780420303345, 'epoch': 0.71}


 12%|█▏        | 1913/16104 [8:56:42<67:35:33, 17.15s/it]

 12%|█▏        | 1914/16104 [8:56:59<67:52:41, 17.22s/it]

 12%|█▏        | 1915/16104 [8:57:15<66:22:36, 16.84s/it]
{'loss': 0.6198, 'learning_rate': 1.9588673238611633e-06, 'rewards/chosen': -0.4713329076766968, 'rewards/rejected': -0.8437585830688477, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3724256753921509, 'policy_logps/rejected': -591.463623046875, 'policy_logps/chosen': -388.685791015625, 'referece_logps/rejected': -583.0260009765625, 'referece_logps/chosen': -383.9724426269531, 'logits/rejected': -0.9304272532463074, 'logits/chosen': -0.6798937320709229, 'epoch': 0.71}

 12%|█▏        | 1916/16104 [8:57:28<62:24:37, 15.84s/it]

 12%|█▏        | 1917/16104 [8:57:50<69:15:00, 17.57s/it]

 12%|█▏        | 1918/16104 [8:58:04<65:14:20, 16.56s/it]

 12%|█▏        | 1919/16104 [8:58:22<66:39:33, 16.92s/it]


 12%|█▏        | 1921/16104 [8:58:59<69:09:50, 17.56s/it]

 12%|█▏        | 1922/16104 [8:59:19<72:06:05, 18.30s/it]
{'loss': 0.6209, 'learning_rate': 1.958466739278465e-06, 'rewards/chosen': -1.0302937030792236, 'rewards/rejected': -1.4885529279708862, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4582594335079193, 'policy_logps/rejected': -460.8910827636719, 'policy_logps/chosen': -401.98626708984375, 'referece_logps/rejected': -446.00555419921875, 'referece_logps/chosen': -391.68328857421875, 'logits/rejected': -0.1967916190624237, 'logits/chosen': -0.07087558507919312, 'epoch': 0.72}


 12%|█▏        | 1924/16104 [8:59:45<61:22:52, 15.58s/it]
{'loss': 0.5372, 'learning_rate': 1.95835193756058e-06, 'rewards/chosen': -0.7753397822380066, 'rewards/rejected': -1.164089322090149, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3887496888637543, 'policy_logps/rejected': -360.18072509765625, 'policy_logps/chosen': -387.1115417480469, 'referece_logps/rejected': -348.53985595703125, 'referece_logps/chosen': -379.3581237792969, 'logits/rejected': 0.045059934258461, 'logits/chosen': 0.06661923229694366, 'epoch': 0.72}

 12%|█▏        | 1925/16104 [9:00:06<67:55:16, 17.24s/it]

 12%|█▏        | 1926/16104 [9:00:18<61:53:47, 15.72s/it]


 12%|█▏        | 1928/16104 [9:00:48<60:01:42, 15.24s/it]

 12%|█▏        | 1929/16104 [9:01:09<67:27:51, 17.13s/it]

 12%|█▏        | 1930/16104 [9:01:23<63:52:20, 16.22s/it]
{'loss': 0.5287, 'learning_rate': 1.958006602072258e-06, 'rewards/chosen': -0.7864488363265991, 'rewards/rejected': -0.8300184011459351, 'rewards/accuracies': 0.5, 'rewards/margins': 0.04356955736875534, 'policy_logps/rejected': -407.9263610839844, 'policy_logps/chosen': -366.2243957519531, 'referece_logps/rejected': -399.6261901855469, 'referece_logps/chosen': -358.3598937988281, 'logits/rejected': -1.1164668798446655, 'logits/chosen': -0.9881739020347595, 'epoch': 0.72}

 12%|█▏        | 1931/16104 [9:01:41<64:52:04, 16.48s/it]

 12%|█▏        | 1932/16104 [9:01:59<67:06:24, 17.05s/it]


 12%|█▏        | 1934/16104 [9:02:38<72:00:35, 18.29s/it]

 12%|█▏        | 1935/16104 [9:02:58<73:38:35, 18.71s/it]

 12%|█▏        | 1936/16104 [9:03:16<73:10:36, 18.59s/it]

 12%|█▏        | 1937/16104 [9:03:31<69:22:45, 17.63s/it]
{'loss': 0.6522, 'learning_rate': 1.957601947439863e-06, 'rewards/chosen': -0.7556431293487549, 'rewards/rejected': -0.9052187204360962, 'rewards/accuracies': 0.375, 'rewards/margins': 0.1495756208896637, 'policy_logps/rejected': -371.8301086425781, 'policy_logps/chosen': -345.31884765625, 'referece_logps/rejected': -362.7779541015625, 'referece_logps/chosen': -337.76239013671875, 'logits/rejected': -0.2858304977416992, 'logits/chosen': -0.35622864961624146, 'epoch': 0.72}

 12%|█▏        | 1938/16104 [9:03:49<69:33:52, 17.68s/it]

 12%|█▏        | 1939/16104 [9:04:09<71:52:19, 18.27s/it]

 12%|█▏        | 1940/16104 [9:04:29<73:48:04, 18.76s/it]


 12%|█▏        | 1942/16104 [9:05:08<75:41:38, 19.24s/it]
{'loss': 0.5276, 'learning_rate': 1.957311746268766e-06, 'rewards/chosen': -0.5152494311332703, 'rewards/rejected': -1.2848410606384277, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7695915102958679, 'policy_logps/rejected': -397.218505859375, 'policy_logps/chosen': -559.12548828125, 'referece_logps/rejected': -384.3700866699219, 'referece_logps/chosen': -553.9729614257812, 'logits/rejected': -0.4376654326915741, 'logits/chosen': -0.5211108326911926, 'epoch': 0.72}

 12%|█▏        | 1943/16104 [9:05:25<73:05:18, 18.58s/it]

 12%|█▏        | 1944/16104 [9:05:39<68:29:54, 17.41s/it]

 12%|█▏        | 1945/16104 [9:06:00<72:55:17, 18.54s/it]


 12%|█▏        | 1947/16104 [9:06:32<69:08:40, 17.58s/it]

 12%|█▏        | 1948/16104 [9:06:52<71:45:19, 18.25s/it]

 12%|█▏        | 1949/16104 [9:07:12<73:47:10, 18.77s/it]

 12%|█▏        | 1950/16104 [9:07:32<75:17:18, 19.15s/it]

 12%|█▏        | 1951/16104 [9:07:46<69:08:15, 17.59s/it]
{'loss': 0.6165, 'learning_rate': 1.956786944685819e-06, 'rewards/chosen': -1.057194471359253, 'rewards/rejected': -1.4901522397994995, 'rewards/accuracies': 0.75, 'rewards/margins': 0.43295761942863464, 'policy_logps/rejected': -414.22412109375, 'policy_logps/chosen': -388.7894287109375, 'referece_logps/rejected': -399.3226013183594, 'referece_logps/chosen': -378.21746826171875, 'logits/rejected': -0.4373924732208252, 'logits/chosen': -0.41117602586746216, 'epoch': 0.73}

 12%|█▏        | 1952/16104 [9:08:07<73:58:26, 18.82s/it]


 12%|█▏        | 1954/16104 [9:08:50<78:36:55, 20.00s/it]
{'loss': 0.5927, 'learning_rate': 1.956611314072505e-06, 'rewards/chosen': -1.0662118196487427, 'rewards/rejected': -1.4830812215805054, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4168693721294403, 'policy_logps/rejected': -505.7234191894531, 'policy_logps/chosen': -435.74993896484375, 'referece_logps/rejected': -490.892578125, 'referece_logps/chosen': -425.087890625, 'logits/rejected': 0.10427622497081757, 'logits/chosen': 0.12437595427036285, 'epoch': 0.73}


 12%|█▏        | 1956/16104 [9:09:21<69:54:42, 17.79s/it]
{'loss': 0.5417, 'learning_rate': 1.9564940335098415e-06, 'rewards/chosen': -0.8852184414863586, 'rewards/rejected': -1.3131921291351318, 'rewards/accuracies': 0.75, 'rewards/margins': 0.42797374725341797, 'policy_logps/rejected': -485.34124755859375, 'policy_logps/chosen': -446.0389404296875, 'referece_logps/rejected': -472.20928955078125, 'referece_logps/chosen': -437.186767578125, 'logits/rejected': -0.47009938955307007, 'logits/chosen': -0.4122025966644287, 'epoch': 0.73}


 12%|█▏        | 1958/16104 [9:09:48<62:01:22, 15.78s/it]
{'loss': 0.598, 'learning_rate': 1.9563765981796176e-06, 'rewards/chosen': -0.5369934439659119, 'rewards/rejected': -1.3145538568496704, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7775603532791138, 'policy_logps/rejected': -355.88323974609375, 'policy_logps/chosen': -418.7352600097656, 'referece_logps/rejected': -342.7376708984375, 'referece_logps/chosen': -413.3653259277344, 'logits/rejected': -0.8305587768554688, 'logits/chosen': -0.7858514785766602, 'epoch': 0.73}


 12%|█▏        | 1960/16104 [9:10:24<65:50:15, 16.76s/it]
{'loss': 0.5298, 'learning_rate': 1.9562590081008352e-06, 'rewards/chosen': -0.5620911717414856, 'rewards/rejected': -1.1048778295516968, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5427865982055664, 'policy_logps/rejected': -341.3734130859375, 'policy_logps/chosen': -464.1126708984375, 'referece_logps/rejected': -330.3246765136719, 'referece_logps/chosen': -458.4917297363281, 'logits/rejected': -0.6097154021263123, 'logits/chosen': -0.7926796078681946, 'epoch': 0.73}

 12%|█▏        | 1961/16104 [9:10:36<60:01:23, 15.28s/it]

 12%|█▏        | 1962/16104 [9:10:53<62:38:04, 15.94s/it]


 12%|█▏        | 1964/16104 [9:11:26<65:04:44, 16.57s/it]
{'loss': 0.5922, 'learning_rate': 1.956023363773727e-06, 'rewards/chosen': -0.8756061792373657, 'rewards/rejected': -1.4997087717056274, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6241026520729065, 'policy_logps/rejected': -231.5556182861328, 'policy_logps/chosen': -302.4228515625, 'referece_logps/rejected': -216.55853271484375, 'referece_logps/chosen': -293.66680908203125, 'logits/rejected': -0.11667376756668091, 'logits/chosen': 0.05848485231399536, 'epoch': 0.73}

 12%|█▏        | 1965/16104 [9:11:44<66:27:55, 16.92s/it]


 12%|█▏        | 1967/16104 [9:12:10<58:40:17, 14.94s/it]
{'loss': 0.6364, 'learning_rate': 1.9558462244551247e-06, 'rewards/chosen': -0.7391992807388306, 'rewards/rejected': -0.693294107913971, 'rewards/accuracies': 0.375, 'rewards/margins': -0.045905113220214844, 'policy_logps/rejected': -421.9420166015625, 'policy_logps/chosen': -398.0848388671875, 'referece_logps/rejected': -415.00909423828125, 'referece_logps/chosen': -390.69281005859375, 'logits/rejected': -1.2159278392791748, 'logits/chosen': -1.2434149980545044, 'epoch': 0.73}
[2024-04-06 00:37:38,782] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 12%|█▏        | 1968/16104 [9:12:32<65:55:38, 16.79s/it]
[2024-04-06 00:37:54,804] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 12%|█▏        | 1969/16104 [9:12:48<65:01:09, 16.56s/it]

 12%|█▏        | 1970/16104 [9:13:01<61:24:22, 15.64s/it]

 12%|█▏        | 1971/16104 [9:13:15<59:10:07, 15.07s/it]


 12%|█▏        | 1973/16104 [9:13:40<54:24:23, 13.86s/it]
{'loss': 0.5189, 'learning_rate': 1.955490901909057e-06, 'rewards/chosen': -0.587699294090271, 'rewards/rejected': -1.2756747007369995, 'rewards/accuracies': 1.0, 'rewards/margins': 0.6879754066467285, 'policy_logps/rejected': -294.9219055175781, 'policy_logps/chosen': -469.27642822265625, 'referece_logps/rejected': -282.1651611328125, 'referece_logps/chosen': -463.39947509765625, 'logits/rejected': -1.2498912811279297, 'logits/chosen': -1.2846152782440186, 'epoch': 0.74}


 12%|█▏        | 1975/16104 [9:14:19<64:05:01, 16.33s/it]
[2024-04-06 00:39:25,744] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5968, 'learning_rate': 1.9553721518242967e-06, 'rewards/chosen': -0.28423115611076355, 'rewards/rejected': -1.301824688911438, 'rewards/accuracies': 0.875, 'rewards/margins': 1.017593502998352, 'policy_logps/rejected': -436.3638000488281, 'policy_logps/chosen': -338.3713073730469, 'referece_logps/rejected': -423.3455505371094, 'referece_logps/chosen': -335.5289306640625, 'logits/rejected': 0.23879358172416687, 'logits/chosen': 0.18197722733020782, 'epoch': 0.74}


 12%|█▏        | 1977/16104 [9:14:53<66:21:39, 16.91s/it]
[2024-04-06 00:39:59,841] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5664, 'learning_rate': 1.955253247153504e-06, 'rewards/chosen': -0.4385083019733429, 'rewards/rejected': -1.3511128425598145, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9126044511795044, 'policy_logps/rejected': -225.0177764892578, 'policy_logps/chosen': -440.3414001464844, 'referece_logps/rejected': -211.5066375732422, 'referece_logps/chosen': -435.956298828125, 'logits/rejected': -0.5922242999076843, 'logits/chosen': -0.6019694209098816, 'epoch': 0.74}

 12%|█▏        | 1978/16104 [9:15:10<66:20:10, 16.91s/it]

 12%|█▏        | 1979/16104 [9:15:24<63:09:25, 16.10s/it]

 12%|█▏        | 1980/16104 [9:15:42<65:41:35, 16.74s/it]
[2024-04-06 00:41:10,974] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 12%|█▏        | 1981/16104 [9:16:04<71:36:31, 18.25s/it]

 12%|█▏        | 1982/16104 [9:16:20<68:58:02, 17.58s/it]

 12%|█▏        | 1983/16104 [9:16:40<72:07:55, 18.39s/it]


 12%|█▏        | 1985/16104 [9:17:13<66:49:00, 17.04s/it]

 12%|█▏        | 1986/16104 [9:17:31<68:19:36, 17.42s/it]
{'loss': 0.7101, 'learning_rate': 1.954716263649242e-06, 'rewards/chosen': -1.195114254951477, 'rewards/rejected': -0.8932076096534729, 'rewards/accuracies': 0.375, 'rewards/margins': -0.3019067049026489, 'policy_logps/rejected': -384.51104736328125, 'policy_logps/chosen': -474.7261047363281, 'referece_logps/rejected': -375.5789489746094, 'referece_logps/chosen': -462.77490234375, 'logits/rejected': -0.48637527227401733, 'logits/chosen': -0.6596464514732361, 'epoch': 0.74}


 12%|█▏        | 1988/16104 [9:18:06<69:01:21, 17.60s/it]

 12%|█▏        | 1989/16104 [9:18:17<60:49:04, 15.51s/it]

 12%|█▏        | 1990/16104 [9:18:37<66:10:40, 16.88s/it]

 12%|█▏        | 1991/16104 [9:18:49<60:12:09, 15.36s/it]

 12%|█▏        | 1992/16104 [9:19:03<58:39:05, 14.96s/it]
{'loss': 0.6316, 'learning_rate': 1.954356536638893e-06, 'rewards/chosen': -0.35708847641944885, 'rewards/rejected': -0.9980079531669617, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6409194469451904, 'policy_logps/rejected': -376.8177490234375, 'policy_logps/chosen': -398.9158020019531, 'referece_logps/rejected': -366.83770751953125, 'referece_logps/chosen': -395.34490966796875, 'logits/rejected': -0.5356975793838501, 'logits/chosen': -0.4678903818130493, 'epoch': 0.74}

 12%|█▏        | 1993/16104 [9:19:24<65:59:12, 16.83s/it]

 12%|█▏        | 1994/16104 [9:19:45<71:01:45, 18.12s/it]


 12%|█▏        | 1996/16104 [9:20:27<77:18:09, 19.73s/it]
{'loss': 0.6506, 'learning_rate': 1.9541159464911657e-06, 'rewards/chosen': -0.7679917812347412, 'rewards/rejected': -0.6368662714958191, 'rewards/accuracies': 0.5, 'rewards/margins': -0.13112545013427734, 'policy_logps/rejected': -240.47906494140625, 'policy_logps/chosen': -406.8036804199219, 'referece_logps/rejected': -234.1104278564453, 'referece_logps/chosen': -399.1237487792969, 'logits/rejected': -0.8411195278167725, 'logits/chosen': -0.9160337448120117, 'epoch': 0.74}


 12%|█▏        | 1998/16104 [9:21:05<75:11:20, 19.19s/it]
{'loss': 0.6833, 'learning_rate': 1.95399541983341e-06, 'rewards/chosen': -0.5470913648605347, 'rewards/rejected': -0.9699152112007141, 'rewards/accuracies': 0.875, 'rewards/margins': 0.422823965549469, 'policy_logps/rejected': -461.8005065917969, 'policy_logps/chosen': -442.02728271484375, 'referece_logps/rejected': -452.101318359375, 'referece_logps/chosen': -436.5563659667969, 'logits/rejected': 0.4991608262062073, 'logits/chosen': 0.7597723603248596, 'epoch': 0.74}

 12%|█▏        | 1999/16104 [9:21:20<70:20:17, 17.95s/it]

 12%|█▏        | 2000/16104 [9:21:40<72:38:00, 18.54s/it]


 12%|█▏        | 2001/16104 [9:22:06<81:26:40, 20.79s/it]
{'loss': 0.5874, 'learning_rate': 1.9537539034476243e-06, 'rewards/chosen': -0.6400123238563538, 'rewards/rejected': -1.1168184280395508, 'rewards/accuracies': 0.625, 'rewards/margins': 0.47680607438087463, 'policy_logps/rejected': -366.22271728515625, 'policy_logps/chosen': -333.64617919921875, 'referece_logps/rejected': -355.0545349121094, 'referece_logps/chosen': -327.2460632324219, 'logits/rejected': -0.10665848851203918, 'logits/chosen': -0.08753766864538193, 'epoch': 0.75}

 12%|█▏        | 2003/16104 [9:22:35<69:27:56, 17.73s/it]

 12%|█▏        | 2004/16104 [9:22:49<65:02:53, 16.61s/it]
{'loss': 0.6014, 'learning_rate': 1.953632913758674e-06, 'rewards/chosen': -0.49070271849632263, 'rewards/rejected': -0.8731732964515686, 'rewards/accuracies': 0.75, 'rewards/margins': 0.38247057795524597, 'policy_logps/rejected': -397.95709228515625, 'policy_logps/chosen': -325.9688415527344, 'referece_logps/rejected': -389.225341796875, 'referece_logps/chosen': -321.06182861328125, 'logits/rejected': -0.25082898139953613, 'logits/chosen': -0.33461064100265503, 'epoch': 0.75}

 12%|█▏        | 2005/16104 [9:23:02<60:47:31, 15.52s/it]

 12%|█▏        | 2006/16104 [9:23:16<59:02:22, 15.08s/it]

 12%|█▏        | 2007/16104 [9:23:36<64:39:12, 16.51s/it]

 12%|█▏        | 2008/16104 [9:23:54<66:38:05, 17.02s/it]


 12%|█▏        | 2010/16104 [9:24:29<67:33:00, 17.25s/it]
{'loss': 0.5255, 'learning_rate': 1.95326901894259e-06, 'rewards/chosen': -0.57706618309021, 'rewards/rejected': -0.8424145579338074, 'rewards/accuracies': 0.625, 'rewards/margins': 0.26534831523895264, 'policy_logps/rejected': -560.2426147460938, 'policy_logps/chosen': -415.5404357910156, 'referece_logps/rejected': -551.8184814453125, 'referece_logps/chosen': -409.7698059082031, 'logits/rejected': -0.11213789135217667, 'logits/chosen': -0.09023717790842056, 'epoch': 0.75}


 12%|█▏        | 2012/16104 [9:25:01<65:59:10, 16.86s/it]
{'loss': 0.5668, 'learning_rate': 1.9531474121529077e-06, 'rewards/chosen': -0.5179566144943237, 'rewards/rejected': -0.552031934261322, 'rewards/accuracies': 0.375, 'rewards/margins': 0.03407531976699829, 'policy_logps/rejected': -309.0243835449219, 'policy_logps/chosen': -349.3731689453125, 'referece_logps/rejected': -303.5040588378906, 'referece_logps/chosen': -344.193603515625, 'logits/rejected': -0.18809345364570618, 'logits/chosen': -0.1137537881731987, 'epoch': 0.75}

 12%|█▎        | 2013/16104 [9:25:21<68:45:54, 17.57s/it]


 13%|█▎        | 2015/16104 [9:25:50<62:58:25, 16.09s/it]
{'loss': 0.6052, 'learning_rate': 1.95296471280069e-06, 'rewards/chosen': -0.49219590425491333, 'rewards/rejected': -0.7892286777496338, 'rewards/accuracies': 0.625, 'rewards/margins': 0.29703277349472046, 'policy_logps/rejected': -279.2768249511719, 'policy_logps/chosen': -509.62725830078125, 'referece_logps/rejected': -271.384521484375, 'referece_logps/chosen': -504.705322265625, 'logits/rejected': -0.33638569712638855, 'logits/chosen': -0.14713820815086365, 'epoch': 0.75}

 13%|█▎        | 2016/16104 [9:26:08<66:18:04, 16.94s/it]

 13%|█▎        | 2017/16104 [9:26:25<65:29:19, 16.74s/it]

 13%|█▎        | 2018/16104 [9:26:46<70:37:55, 18.05s/it]

 13%|█▎        | 2019/16104 [9:27:00<66:25:04, 16.98s/it]


 13%|█▎        | 2021/16104 [9:27:31<62:02:41, 15.86s/it]

 13%|█▎        | 2022/16104 [9:27:49<65:05:58, 16.64s/it]

 13%|█▎        | 2023/16104 [9:28:03<61:41:16, 15.77s/it]
{'loss': 0.6619, 'learning_rate': 1.9524758185477924e-06, 'rewards/chosen': -0.6610003113746643, 'rewards/rejected': -1.3502099514007568, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6892096400260925, 'policy_logps/rejected': -385.8665771484375, 'policy_logps/chosen': -310.3335266113281, 'referece_logps/rejected': -372.364501953125, 'referece_logps/chosen': -303.7235412597656, 'logits/rejected': -0.8358936905860901, 'logits/chosen': -0.8411629796028137, 'epoch': 0.75}


 13%|█▎        | 2025/16104 [9:28:32<59:12:55, 15.14s/it]

 13%|█▎        | 2026/16104 [9:28:48<60:04:12, 15.36s/it]
{'loss': 0.6058, 'learning_rate': 1.952291847400687e-06, 'rewards/chosen': -0.5535669326782227, 'rewards/rejected': -0.5709923505783081, 'rewards/accuracies': 0.5, 'rewards/margins': 0.01742543652653694, 'policy_logps/rejected': -465.3818664550781, 'policy_logps/chosen': -361.45806884765625, 'referece_logps/rejected': -459.6719055175781, 'referece_logps/chosen': -355.9223937988281, 'logits/rejected': -0.7250105738639832, 'logits/chosen': -0.6241306662559509, 'epoch': 0.75}


 13%|█▎        | 2028/16104 [9:29:28<69:18:19, 17.73s/it]
{'loss': 0.5781, 'learning_rate': 1.9521690073556264e-06, 'rewards/chosen': -0.4397850036621094, 'rewards/rejected': -1.0132158994674683, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5734309554100037, 'policy_logps/rejected': -273.7392272949219, 'policy_logps/chosen': -357.7804260253906, 'referece_logps/rejected': -263.6070556640625, 'referece_logps/chosen': -353.3825378417969, 'logits/rejected': -0.9898024201393127, 'logits/chosen': -0.9261918067932129, 'epoch': 0.76}

 13%|█▎        | 2029/16104 [9:29:43<65:52:21, 16.85s/it]

 13%|█▎        | 2030/16104 [9:29:57<62:48:59, 16.07s/it]


 13%|█▎        | 2032/16104 [9:30:29<64:07:23, 16.40s/it]
{'loss': 0.5892, 'learning_rate': 1.951922865082185e-06, 'rewards/chosen': -0.6079930067062378, 'rewards/rejected': -1.0315682888031006, 'rewards/accuracies': 0.875, 'rewards/margins': 0.42357540130615234, 'policy_logps/rejected': -435.6064453125, 'policy_logps/chosen': -392.637451171875, 'referece_logps/rejected': -425.2908020019531, 'referece_logps/chosen': -386.5574951171875, 'logits/rejected': 0.5601476430892944, 'logits/chosen': 0.39384526014328003, 'epoch': 0.76}


 13%|█▎        | 2034/16104 [9:31:03<63:36:32, 16.28s/it]
{'loss': 0.5142, 'learning_rate': 1.9517995628936316e-06, 'rewards/chosen': -0.31709805130958557, 'rewards/rejected': -1.0698776245117188, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7527795433998108, 'policy_logps/rejected': -382.22430419921875, 'policy_logps/chosen': -378.8114013671875, 'referece_logps/rejected': -371.5255126953125, 'referece_logps/chosen': -375.6404113769531, 'logits/rejected': -1.1110080480575562, 'logits/chosen': -1.0978460311889648, 'epoch': 0.76}

 13%|█▎        | 2035/16104 [9:31:23<67:44:19, 17.33s/it]

 13%|█▎        | 2036/16104 [9:31:35<61:51:57, 15.83s/it]

 13%|█▎        | 2037/16104 [9:31:58<69:51:49, 17.88s/it]

 13%|█▎        | 2038/16104 [9:32:11<63:35:26, 16.28s/it]

 13%|█▎        | 2039/16104 [9:32:25<60:49:26, 15.57s/it]


 13%|█▎        | 2041/16104 [9:32:54<59:17:00, 15.18s/it]
{'loss': 0.5095, 'learning_rate': 1.951366792552152e-06, 'rewards/chosen': 0.15531902015209198, 'rewards/rejected': -1.2993348836898804, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4546539783477783, 'policy_logps/rejected': -264.1771240234375, 'policy_logps/chosen': -252.3958740234375, 'referece_logps/rejected': -251.18377685546875, 'referece_logps/chosen': -253.9490509033203, 'logits/rejected': -0.6770083904266357, 'logits/chosen': -0.8058619499206543, 'epoch': 0.76}

 13%|█▎        | 2042/16104 [9:33:11<61:21:13, 15.71s/it]

 13%|█▎        | 2043/16104 [9:33:27<61:31:46, 15.75s/it]

 13%|█▎        | 2044/16104 [9:33:47<66:51:02, 17.12s/it]


 13%|█▎        | 2046/16104 [9:34:18<63:12:47, 16.19s/it]
{'loss': 0.641, 'learning_rate': 1.9510565162951534e-06, 'rewards/chosen': -0.7056871056556702, 'rewards/rejected': -0.7622191309928894, 'rewards/accuracies': 0.375, 'rewards/margins': 0.056531913578510284, 'policy_logps/rejected': -420.32965087890625, 'policy_logps/chosen': -491.18695068359375, 'referece_logps/rejected': -412.7074279785156, 'referece_logps/chosen': -484.1300964355469, 'logits/rejected': -1.1418262720108032, 'logits/chosen': -1.195388674736023, 'epoch': 0.76}

 13%|█▎        | 2047/16104 [9:34:35<64:36:06, 16.54s/it]

 13%|█▎        | 2048/16104 [9:34:49<61:14:04, 15.68s/it]

 13%|█▎        | 2049/16104 [9:35:05<61:06:47, 15.65s/it]


 13%|█▎        | 2051/16104 [9:35:46<71:41:22, 18.36s/it]
{'loss': 0.5322, 'learning_rate': 1.950745278239902e-06, 'rewards/chosen': -0.9383327960968018, 'rewards/rejected': -1.4114845991134644, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4731520116329193, 'policy_logps/rejected': -368.5201416015625, 'policy_logps/chosen': -300.34686279296875, 'referece_logps/rejected': -354.4052734375, 'referece_logps/chosen': -290.9635314941406, 'logits/rejected': -0.39687296748161316, 'logits/chosen': -0.3238108158111572, 'epoch': 0.76}

 13%|█▎        | 2052/16104 [9:36:00<66:03:45, 16.92s/it]


 13%|█▎        | 2054/16104 [9:36:24<57:06:25, 14.63s/it]
{'loss': 0.6043, 'learning_rate': 1.9505580738744864e-06, 'rewards/chosen': -0.9241700768470764, 'rewards/rejected': -1.5988825559616089, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6747124791145325, 'policy_logps/rejected': -278.646728515625, 'policy_logps/chosen': -592.3898315429688, 'referece_logps/rejected': -262.6579284667969, 'referece_logps/chosen': -583.1481323242188, 'logits/rejected': -0.6807767152786255, 'logits/chosen': -0.6830910444259644, 'epoch': 0.77}

 13%|█▎        | 2055/16104 [9:36:39<57:10:43, 14.65s/it]

 13%|█▎        | 2056/16104 [9:36:50<53:35:40, 13.73s/it]

 13%|█▎        | 2057/16104 [9:37:01<50:26:07, 12.93s/it]

 13%|█▎        | 2058/16104 [9:37:14<50:36:10, 12.97s/it]

 13%|█▎        | 2059/16104 [9:37:31<54:32:22, 13.98s/it]

 13%|█▎        | 2060/16104 [9:37:44<53:14:32, 13.65s/it]

 13%|█▎        | 2061/16104 [9:37:55<50:07:08, 12.85s/it]

 13%|█▎        | 2062/16104 [9:38:13<56:25:11, 14.46s/it]

 13%|█▎        | 2063/16104 [9:38:29<58:28:00, 14.99s/it]

 13%|█▎        | 2064/16104 [9:38:51<66:01:54, 16.93s/it]

 13%|█▎        | 2065/16104 [9:39:14<73:38:26, 18.88s/it]

 13%|█▎        | 2066/16104 [9:39:30<70:06:36, 17.98s/it]


 13%|█▎        | 2068/16104 [9:40:02<68:34:58, 17.59s/it]
{'loss': 0.4355, 'learning_rate': 1.9496798788468074e-06, 'rewards/chosen': -0.7088848352432251, 'rewards/rejected': -1.5750772953033447, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8661923408508301, 'policy_logps/rejected': -286.5410461425781, 'policy_logps/chosen': -310.1277770996094, 'referece_logps/rejected': -270.7902526855469, 'referece_logps/chosen': -303.0389099121094, 'logits/rejected': -0.14377349615097046, 'logits/chosen': -0.28675246238708496, 'epoch': 0.77}

 13%|█▎        | 2069/16104 [9:40:23<72:28:34, 18.59s/it]

 13%|█▎        | 2070/16104 [9:40:37<67:11:28, 17.24s/it]

 13%|█▎        | 2071/16104 [9:40:50<61:13:46, 15.71s/it]

 13%|█▎        | 2072/16104 [9:41:07<63:47:57, 16.37s/it]

 13%|█▎        | 2073/16104 [9:41:26<65:57:48, 16.92s/it]

 13%|█▎        | 2074/16104 [9:41:41<64:40:42, 16.60s/it]

 13%|█▎        | 2075/16104 [9:41:58<64:40:19, 16.60s/it]

 13%|█▎        | 2076/16104 [9:42:14<64:02:14, 16.43s/it]

 13%|█▎        | 2077/16104 [9:42:36<70:44:28, 18.16s/it]

 13%|█▎        | 2078/16104 [9:42:47<62:18:41, 15.99s/it]

 13%|█▎        | 2079/16104 [9:43:03<61:54:37, 15.89s/it]

 13%|█▎        | 2080/16104 [9:43:18<60:39:26, 15.57s/it]

 13%|█▎        | 2081/16104 [9:43:36<63:49:37, 16.39s/it]

 13%|█▎        | 2082/16104 [9:43:47<57:50:19, 14.85s/it]

 13%|█▎        | 2083/16104 [9:43:59<53:58:59, 13.86s/it]

 13%|█▎        | 2084/16104 [9:44:19<61:05:29, 15.69s/it]

 13%|█▎        | 2085/16104 [9:44:38<64:57:47, 16.68s/it]

 13%|█▎        | 2086/16104 [9:44:55<65:33:46, 16.84s/it]

 13%|█▎        | 2087/16104 [9:45:09<62:11:23, 15.97s/it]

 13%|█▎        | 2088/16104 [9:45:30<68:18:35, 17.55s/it]

 13%|█▎        | 2089/16104 [9:45:43<62:17:43, 16.00s/it]

 13%|█▎        | 2090/16104 [9:46:00<64:05:16, 16.46s/it]

 13%|█▎        | 2091/16104 [9:46:11<58:04:16, 14.92s/it]

 13%|█▎        | 2092/16104 [9:46:23<54:29:10, 14.00s/it]


 13%|█▎        | 2094/16104 [9:46:57<62:05:13, 15.95s/it]
{'loss': 0.6218, 'learning_rate': 1.948028974110861e-06, 'rewards/chosen': -0.631198525428772, 'rewards/rejected': -1.144287109375, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5130885243415833, 'policy_logps/rejected': -357.8616027832031, 'policy_logps/chosen': -385.2608337402344, 'referece_logps/rejected': -346.418701171875, 'referece_logps/chosen': -378.9488525390625, 'logits/rejected': -0.9075434803962708, 'logits/chosen': -0.6965785026550293, 'epoch': 0.78}

 13%|█▎        | 2095/16104 [9:47:09<57:18:18, 14.73s/it]

 13%|█▎        | 2096/16104 [9:47:27<62:01:55, 15.94s/it]
[2024-04-06 01:12:55,021] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2097/16104 [9:47:48<67:13:30, 17.28s/it]

 13%|█▎        | 2098/16104 [9:48:00<61:43:13, 15.86s/it]

 13%|█▎        | 2099/16104 [9:48:20<66:00:05, 16.97s/it]


 13%|█▎        | 2101/16104 [9:48:52<65:34:32, 16.86s/it]

 13%|█▎        | 2102/16104 [9:49:08<64:33:57, 16.60s/it]

 13%|█▎        | 2103/16104 [9:49:23<62:21:46, 16.04s/it]

 13%|█▎        | 2104/16104 [9:49:43<67:42:39, 17.41s/it]
[2024-04-06 01:14:50,351] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2105/16104 [9:50:04<71:13:02, 18.31s/it]

 13%|█▎        | 2106/16104 [9:50:22<70:45:37, 18.20s/it]

 13%|█▎        | 2107/16104 [9:50:37<67:59:31, 17.49s/it]

 13%|█▎        | 2108/16104 [9:50:48<59:30:46, 15.31s/it]

 13%|█▎        | 2109/16104 [9:51:08<65:41:23, 16.90s/it]

 13%|█▎        | 2110/16104 [9:51:25<65:28:23, 16.84s/it]

 13%|█▎        | 2111/16104 [9:51:37<59:51:46, 15.40s/it]

 13%|█▎        | 2112/16104 [9:51:57<65:14:16, 16.79s/it]

 13%|█▎        | 2113/16104 [9:52:16<68:27:54, 17.62s/it]

 13%|█▎        | 2114/16104 [9:52:35<69:37:11, 17.92s/it]

 13%|█▎        | 2115/16104 [9:52:57<74:34:16, 19.19s/it]
[2024-04-06 01:18:04,459] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2116/16104 [9:53:13<70:22:54, 18.11s/it]
[2024-04-06 01:18:20,060] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2117/16104 [9:53:33<72:59:39, 18.79s/it]

 13%|█▎        | 2118/16104 [9:53:54<74:57:12, 19.29s/it]

 13%|█▎        | 2119/16104 [9:54:12<73:13:52, 18.85s/it]
[2024-04-06 01:19:18,712] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2120/16104 [9:54:26<68:35:09, 17.66s/it]

 13%|█▎        | 2121/16104 [9:54:38<61:36:38, 15.86s/it]

 13%|█▎        | 2122/16104 [9:54:55<62:34:30, 16.11s/it]

 13%|█▎        | 2123/16104 [9:55:07<58:37:46, 15.10s/it]

 13%|█▎        | 2124/16104 [9:55:24<60:36:57, 15.61s/it]

 13%|█▎        | 2125/16104 [9:55:45<66:34:36, 17.15s/it]

 13%|█▎        | 2126/16104 [9:56:06<70:44:05, 18.22s/it]

 13%|█▎        | 2127/16104 [9:56:28<75:44:31, 19.51s/it]
[2024-04-06 01:21:35,455] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2128/16104 [9:56:44<71:47:08, 18.49s/it]

 13%|█▎        | 2129/16104 [9:57:01<69:34:55, 17.92s/it]

 13%|█▎        | 2130/16104 [9:57:21<72:17:34, 18.62s/it]

 13%|█▎        | 2131/16104 [9:57:44<77:40:02, 20.01s/it]

 13%|█▎        | 2132/16104 [9:58:02<74:58:22, 19.32s/it]

 13%|█▎        | 2133/16104 [9:58:20<72:34:26, 18.70s/it]

 13%|█▎        | 2134/16104 [9:58:38<72:48:28, 18.76s/it]

 13%|█▎        | 2135/16104 [9:58:59<75:07:18, 19.36s/it]

 13%|█▎        | 2136/16104 [9:59:12<66:59:58, 17.27s/it]

 13%|█▎        | 2137/16104 [9:59:32<70:21:54, 18.14s/it]

 13%|█▎        | 2138/16104 [9:59:46<65:47:46, 16.96s/it]

 13%|█▎        | 2139/16104 [10:00:06<68:53:15, 17.76s/it]

 13%|█▎        | 2140/16104 [10:00:27<72:39:14, 18.73s/it]

 13%|█▎        | 2141/16104 [10:00:44<70:56:59, 18.29s/it]

 13%|█▎        | 2142/16104 [10:01:03<72:32:49, 18.71s/it]

 13%|█▎        | 2143/16104 [10:01:25<75:39:50, 19.51s/it]

 13%|█▎        | 2144/16104 [10:01:46<78:02:40, 20.13s/it]
[2024-04-06 01:26:53,574] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2145/16104 [10:02:03<73:42:31, 19.01s/it]
[2024-04-06 01:27:09,978] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2146/16104 [10:02:24<75:42:57, 19.53s/it]

 13%|█▎        | 2147/16104 [10:02:35<66:03:27, 17.04s/it]

 13%|█▎        | 2148/16104 [10:02:51<65:06:23, 16.79s/it]
{'loss': 0.5394, 'learning_rate': 1.9445173899241456e-06, 'rewards/chosen': -0.564498245716095, 'rewards/rejected': -1.2710365056991577, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7065383195877075, 'policy_logps/rejected': -350.6763916015625, 'policy_logps/chosen': -268.99578857421875, 'referece_logps/rejected': -337.96600341796875, 'referece_logps/chosen': -263.3507995605469, 'logits/rejected': -0.0038631409406661987, 'logits/chosen': 0.05997149646282196, 'epoch': 0.8}


 13%|█▎        | 2150/16104 [10:03:25<63:43:55, 16.44s/it]

 13%|█▎        | 2151/16104 [10:03:35<57:06:39, 14.74s/it]

 13%|█▎        | 2152/16104 [10:03:56<64:21:07, 16.60s/it]

 13%|█▎        | 2153/16104 [10:04:12<62:48:30, 16.21s/it]

 13%|█▎        | 2154/16104 [10:04:25<58:48:44, 15.18s/it]

 13%|█▎        | 2155/16104 [10:04:47<67:43:44, 17.48s/it]

 13%|█▎        | 2156/16104 [10:05:06<69:37:42, 17.97s/it]

 13%|█▎        | 2157/16104 [10:05:29<75:22:41, 19.46s/it]
[2024-04-06 01:30:36,585] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2158/16104 [10:05:42<66:55:39, 17.28s/it]
{'loss': 0.6102, 'learning_rate': 1.9438548577437104e-06, 'rewards/chosen': -0.8551033139228821, 'rewards/rejected': -1.0972912311553955, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24218788743019104, 'policy_logps/rejected': -414.00018310546875, 'policy_logps/chosen': -340.37408447265625, 'referece_logps/rejected': -403.02728271484375, 'referece_logps/chosen': -331.82305908203125, 'logits/rejected': 0.25297874212265015, 'logits/chosen': 0.22542011737823486, 'epoch': 0.8}


 13%|█▎        | 2160/16104 [10:06:04<54:50:39, 14.16s/it]
{'loss': 0.5373, 'learning_rate': 1.9437218930543827e-06, 'rewards/chosen': -1.0164601802825928, 'rewards/rejected': -1.5867482423782349, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5702879428863525, 'policy_logps/rejected': -292.2367858886719, 'policy_logps/chosen': -428.364990234375, 'referece_logps/rejected': -276.3692932128906, 'referece_logps/chosen': -418.2003479003906, 'logits/rejected': 0.09061343967914581, 'logits/chosen': 0.10503311455249786, 'epoch': 0.8}


 13%|█▎        | 2162/16104 [10:06:27<50:44:43, 13.10s/it]

 13%|█▎        | 2163/16104 [10:06:42<52:10:04, 13.47s/it]
[2024-04-06 01:31:49,013] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2164/16104 [10:07:00<57:44:05, 14.91s/it]

 13%|█▎        | 2165/16104 [10:07:14<56:26:13, 14.58s/it]

 13%|█▎        | 2166/16104 [10:07:31<59:31:28, 15.37s/it]

 13%|█▎        | 2167/16104 [10:07:52<65:35:40, 16.94s/it]

 13%|█▎        | 2168/16104 [10:08:04<59:42:56, 15.43s/it]

 13%|█▎        | 2169/16104 [10:08:26<67:53:43, 17.54s/it]
[2024-04-06 01:33:33,277] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2170/16104 [10:08:48<72:55:34, 18.84s/it]

 13%|█▎        | 2171/16104 [10:09:03<68:59:11, 17.82s/it]

 13%|█▎        | 2172/16104 [10:09:22<69:22:50, 17.93s/it]
[2024-04-06 01:34:28,775] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 13%|█▎        | 2173/16104 [10:09:36<65:03:38, 16.81s/it]
{'loss': 0.5804, 'learning_rate': 1.9428539014521953e-06, 'rewards/chosen': -0.8617153167724609, 'rewards/rejected': -0.9224729537963867, 'rewards/accuracies': 0.375, 'rewards/margins': 0.06075764074921608, 'policy_logps/rejected': -356.0023498535156, 'policy_logps/chosen': -430.80670166015625, 'referece_logps/rejected': -346.77764892578125, 'referece_logps/chosen': -422.18951416015625, 'logits/rejected': 0.25492197275161743, 'logits/chosen': 0.3096921443939209, 'epoch': 0.81}


 14%|█▎        | 2175/16104 [10:10:14<69:55:26, 18.07s/it]

 14%|█▎        | 2176/16104 [10:10:35<74:22:18, 19.22s/it]

 14%|█▎        | 2177/16104 [10:10:49<68:16:40, 17.65s/it]

 14%|█▎        | 2178/16104 [10:11:02<62:06:26, 16.06s/it]

 14%|█▎        | 2179/16104 [10:11:20<64:42:06, 16.73s/it]

 14%|█▎        | 2180/16104 [10:11:32<58:46:09, 15.19s/it]

 14%|█▎        | 2181/16104 [10:11:46<57:58:10, 14.99s/it]
[2024-04-06 01:36:53,384] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▎        | 2182/16104 [10:11:57<53:06:29, 13.73s/it]

 14%|█▎        | 2183/16104 [10:12:15<58:01:22, 15.00s/it]

 14%|█▎        | 2184/16104 [10:12:27<54:29:45, 14.09s/it]
{'loss': 0.5664, 'learning_rate': 1.9421144122872778e-06, 'rewards/chosen': -0.5635437369346619, 'rewards/rejected': -1.2740734815597534, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7105296850204468, 'policy_logps/rejected': -362.5992736816406, 'policy_logps/chosen': -367.01953125, 'referece_logps/rejected': -349.8584899902344, 'referece_logps/chosen': -361.3841552734375, 'logits/rejected': -0.3926669955253601, 'logits/chosen': -0.530414342880249, 'epoch': 0.81}


 14%|█▎        | 2186/16104 [10:12:57<55:04:35, 14.25s/it]

 14%|█▎        | 2187/16104 [10:13:08<51:17:48, 13.27s/it]

 14%|█▎        | 2188/16104 [10:13:22<51:46:28, 13.39s/it]

 14%|█▎        | 2189/16104 [10:13:42<59:41:14, 15.44s/it]

 14%|█▎        | 2190/16104 [10:14:04<66:44:52, 17.27s/it]

 14%|█▎        | 2191/16104 [10:14:16<61:26:53, 15.90s/it]

 14%|█▎        | 2192/16104 [10:14:36<65:13:57, 16.88s/it]

 14%|█▎        | 2193/16104 [10:14:54<66:42:53, 17.27s/it]
{'loss': 0.6164, 'learning_rate': 1.941505945616479e-06, 'rewards/chosen': -0.8657111525535583, 'rewards/rejected': -1.214755892753601, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3490447700023651, 'policy_logps/rejected': -371.4449157714844, 'policy_logps/chosen': -355.7838134765625, 'referece_logps/rejected': -359.29736328125, 'referece_logps/chosen': -347.1266784667969, 'logits/rejected': -0.4586271643638611, 'logits/chosen': -0.4571493864059448, 'epoch': 0.82}


 14%|█▎        | 2195/16104 [10:15:31<70:17:11, 18.19s/it]
[2024-04-06 01:40:38,503] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▎        | 2196/16104 [10:15:52<73:32:21, 19.04s/it]

 14%|█▎        | 2197/16104 [10:16:06<67:28:51, 17.47s/it]

 14%|█▎        | 2198/16104 [10:16:25<69:19:47, 17.95s/it]
{'loss': 0.5777, 'learning_rate': 1.9411665754536206e-06, 'rewards/chosen': -0.9756839871406555, 'rewards/rejected': -1.4192113876342773, 'rewards/accuracies': 0.5, 'rewards/margins': 0.44352737069129944, 'policy_logps/rejected': -400.78466796875, 'policy_logps/chosen': -318.98193359375, 'referece_logps/rejected': -386.5925598144531, 'referece_logps/chosen': -309.22503662109375, 'logits/rejected': -0.36324048042297363, 'logits/chosen': -0.30129510164260864, 'epoch': 0.82}


 14%|█▎        | 2200/16104 [10:16:54<62:57:35, 16.30s/it]

 14%|█▎        | 2201/16104 [10:17:10<62:45:59, 16.25s/it]

 14%|█▎        | 2202/16104 [10:17:26<62:18:11, 16.13s/it]

 14%|█▎        | 2203/16104 [10:17:46<66:44:56, 17.29s/it]
{'loss': 0.6022, 'learning_rate': 1.9408262534941518e-06, 'rewards/chosen': -0.8910297751426697, 'rewards/rejected': -1.7599395513534546, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8689097762107849, 'policy_logps/rejected': -525.1439208984375, 'policy_logps/chosen': -382.58099365234375, 'referece_logps/rejected': -507.54449462890625, 'referece_logps/chosen': -373.6706848144531, 'logits/rejected': -1.0170118808746338, 'logits/chosen': -0.9653130769729614, 'epoch': 0.82}

 14%|█▎        | 2204/16104 [10:18:03<66:04:52, 17.11s/it]

 14%|█▎        | 2205/16104 [10:18:21<67:17:38, 17.43s/it]


 14%|█▎        | 2207/16104 [10:18:59<69:26:16, 17.99s/it]

 14%|█▎        | 2208/16104 [10:19:11<62:40:13, 16.24s/it]

 14%|█▎        | 2209/16104 [10:19:30<65:53:28, 17.07s/it]

 14%|█▎        | 2210/16104 [10:19:47<65:30:44, 16.97s/it]

 14%|█▎        | 2211/16104 [10:20:00<61:31:03, 15.94s/it]

 14%|█▎        | 2212/16104 [10:20:11<55:40:54, 14.43s/it]

 14%|█▎        | 2213/16104 [10:20:23<52:36:35, 13.63s/it]

 14%|█▎        | 2214/16104 [10:20:36<51:42:46, 13.40s/it]

 14%|█▍        | 2215/16104 [10:20:53<56:50:35, 14.73s/it]
{'loss': 0.6178, 'learning_rate': 1.9400055995227614e-06, 'rewards/chosen': -0.933442234992981, 'rewards/rejected': -1.1238011121749878, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1903589516878128, 'policy_logps/rejected': -313.1580810546875, 'policy_logps/chosen': -406.9335632324219, 'referece_logps/rejected': -301.9200744628906, 'referece_logps/chosen': -397.5990905761719, 'logits/rejected': -0.49502235651016235, 'logits/chosen': -0.5176194906234741, 'epoch': 0.83}


 14%|█▍        | 2217/16104 [10:21:38<72:08:37, 18.70s/it]

 14%|█▍        | 2218/16104 [10:21:54<68:25:04, 17.74s/it]

 14%|█▍        | 2219/16104 [10:22:09<65:13:05, 16.91s/it]

 14%|█▍        | 2220/16104 [10:22:30<70:20:45, 18.24s/it]

 14%|█▍        | 2221/16104 [10:22:43<64:04:52, 16.62s/it]

 14%|█▍        | 2222/16104 [10:23:03<67:41:45, 17.56s/it]

 14%|█▍        | 2223/16104 [10:23:22<69:33:40, 18.04s/it]

 14%|█▍        | 2224/16104 [10:23:34<63:11:52, 16.39s/it]

 14%|█▍        | 2225/16104 [10:23:47<58:31:30, 15.18s/it]

 14%|█▍        | 2226/16104 [10:24:04<60:47:43, 15.77s/it]

 14%|█▍        | 2227/16104 [10:24:25<66:42:09, 17.30s/it]
[2024-04-06 01:49:31,973] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2228/16104 [10:24:37<60:58:43, 15.82s/it]

 14%|█▍        | 2229/16104 [10:24:55<63:07:42, 16.38s/it]
[2024-04-06 01:50:02,015] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2230/16104 [10:25:11<62:24:44, 16.19s/it]

 14%|█▍        | 2231/16104 [10:25:25<60:37:35, 15.73s/it]

 14%|█▍        | 2232/16104 [10:25:41<60:13:05, 15.63s/it]

 14%|█▍        | 2233/16104 [10:25:58<62:29:19, 16.22s/it]

 14%|█▍        | 2234/16104 [10:26:19<68:11:18, 17.70s/it]

 14%|█▍        | 2235/16104 [10:26:33<63:04:52, 16.37s/it]
{'loss': 0.5756, 'learning_rate': 1.938625677315492e-06, 'rewards/chosen': -0.8790534734725952, 'rewards/rejected': -1.5743236541748047, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6952701210975647, 'policy_logps/rejected': -297.6339111328125, 'policy_logps/chosen': -285.6783447265625, 'referece_logps/rejected': -281.8906555175781, 'referece_logps/chosen': -276.8878173828125, 'logits/rejected': -1.0402610301971436, 'logits/chosen': -0.9086825847625732, 'epoch': 0.83}


 14%|█▍        | 2237/16104 [10:27:13<70:12:56, 18.23s/it]

 14%|█▍        | 2238/16104 [10:27:35<74:51:57, 19.44s/it]

 14%|█▍        | 2239/16104 [10:27:49<68:09:24, 17.70s/it]

 14%|█▍        | 2240/16104 [10:28:09<71:02:51, 18.45s/it]
{'loss': 0.548, 'learning_rate': 1.938278322821547e-06, 'rewards/chosen': -0.6391494870185852, 'rewards/rejected': -0.6819282174110413, 'rewards/accuracies': 0.375, 'rewards/margins': 0.042778775095939636, 'policy_logps/rejected': -307.5316162109375, 'policy_logps/chosen': -323.6337890625, 'referece_logps/rejected': -300.7123107910156, 'referece_logps/chosen': -317.2423095703125, 'logits/rejected': -0.26451095938682556, 'logits/chosen': -0.2545400857925415, 'epoch': 0.83}


 14%|█▍        | 2242/16104 [10:28:33<57:35:40, 14.96s/it]

 14%|█▍        | 2243/16104 [10:28:43<52:37:10, 13.67s/it]

 14%|█▍        | 2244/16104 [10:28:55<50:11:00, 13.03s/it]

 14%|█▍        | 2245/16104 [10:29:07<49:29:11, 12.85s/it]

 14%|█▍        | 2246/16104 [10:29:28<58:43:42, 15.26s/it]
[2024-04-06 01:54:35,344] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6524, 'learning_rate': 1.937860244943821e-06, 'rewards/chosen': -0.7851704955101013, 'rewards/rejected': -0.7356974482536316, 'rewards/accuracies': 0.5, 'rewards/margins': -0.04947299510240555, 'policy_logps/rejected': -334.4607238769531, 'policy_logps/chosen': -606.111328125, 'referece_logps/rejected': -327.103759765625, 'referece_logps/chosen': -598.2597045898438, 'logits/rejected': -0.08462145924568176, 'logits/chosen': -0.18769636750221252, 'epoch': 0.84}


 14%|█▍        | 2248/16104 [10:30:00<60:39:06, 15.76s/it]

 14%|█▍        | 2249/16104 [10:30:21<66:37:46, 17.31s/it]

 14%|█▍        | 2250/16104 [10:30:33<59:45:23, 15.53s/it]

 14%|█▍        | 2251/16104 [10:30:45<56:23:47, 14.66s/it]

 14%|█▍        | 2252/16104 [10:31:07<64:31:47, 16.77s/it]

 14%|█▍        | 2253/16104 [10:31:19<59:17:03, 15.41s/it]

 14%|█▍        | 2254/16104 [10:31:31<55:20:35, 14.39s/it]

 14%|█▍        | 2255/16104 [10:31:44<52:55:51, 13.76s/it]
{'loss': 0.5717, 'learning_rate': 1.9372305674952046e-06, 'rewards/chosen': -0.2829292416572571, 'rewards/rejected': -0.47314453125, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1902153044939041, 'policy_logps/rejected': -352.10308837890625, 'policy_logps/chosen': -299.83721923828125, 'referece_logps/rejected': -347.3716125488281, 'referece_logps/chosen': -297.0079345703125, 'logits/rejected': -0.11482863873243332, 'logits/chosen': -0.009480871260166168, 'epoch': 0.84}


 14%|█▍        | 2257/16104 [10:32:22<64:13:38, 16.70s/it]

 14%|█▍        | 2258/16104 [10:32:37<61:53:29, 16.09s/it]

 14%|█▍        | 2259/16104 [10:32:49<57:04:22, 14.84s/it]
{'loss': 0.6767, 'learning_rate': 1.936949724999762e-06, 'rewards/chosen': -0.42583391070365906, 'rewards/rejected': -1.302338719367981, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8765048980712891, 'policy_logps/rejected': -427.6341552734375, 'policy_logps/chosen': -427.82476806640625, 'referece_logps/rejected': -414.6107177734375, 'referece_logps/chosen': -423.56640625, 'logits/rejected': -0.7109443545341492, 'logits/chosen': -0.7453397512435913, 'epoch': 0.84}
[2024-04-06 01:58:17,141] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 14%|█▍        | 2261/16104 [10:33:25<62:11:44, 16.17s/it]
[2024-04-06 01:58:32,072] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2262/16104 [10:33:38<58:20:54, 15.18s/it]
{'loss': 0.4932, 'learning_rate': 1.936738695154717e-06, 'rewards/chosen': -0.5790022015571594, 'rewards/rejected': -0.7044379115104675, 'rewards/accuracies': 0.375, 'rewards/margins': 0.1254357397556305, 'policy_logps/rejected': -353.95220947265625, 'policy_logps/chosen': -390.2991943359375, 'referece_logps/rejected': -346.9078063964844, 'referece_logps/chosen': -384.5091857910156, 'logits/rejected': -0.43206024169921875, 'logits/chosen': -0.46414655447006226, 'epoch': 0.84}

 14%|█▍        | 2263/16104 [10:33:54<59:37:31, 15.51s/it]

 14%|█▍        | 2264/16104 [10:34:10<60:39:09, 15.78s/it]


 14%|█▍        | 2266/16104 [10:34:43<63:00:55, 16.39s/it]
[2024-04-06 01:59:50,208] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2267/16104 [10:35:01<65:06:27, 16.94s/it]
[2024-04-06 02:00:08,420] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5245, 'learning_rate': 1.9363862209292894e-06, 'rewards/chosen': -0.4645155072212219, 'rewards/rejected': -1.2169605493545532, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7524450421333313, 'policy_logps/rejected': -395.19403076171875, 'policy_logps/chosen': -364.7321472167969, 'referece_logps/rejected': -383.0244445800781, 'referece_logps/chosen': -360.0870361328125, 'logits/rejected': -0.23854665458202362, 'logits/chosen': -0.17358076572418213, 'epoch': 0.84}

 14%|█▍        | 2268/16104 [10:35:22<69:49:15, 18.17s/it]
[2024-04-06 02:00:47,685] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 14%|█▍        | 2270/16104 [10:36:02<73:16:32, 19.07s/it]

 14%|█▍        | 2271/16104 [10:36:21<74:01:36, 19.27s/it]

 14%|█▍        | 2272/16104 [10:36:34<66:09:37, 17.22s/it]

 14%|█▍        | 2273/16104 [10:36:53<68:28:00, 17.82s/it]

 14%|█▍        | 2274/16104 [10:37:06<62:58:15, 16.39s/it]
{'loss': 0.4939, 'learning_rate': 1.9358911661971155e-06, 'rewards/chosen': -0.6658129096031189, 'rewards/rejected': -1.619277000427246, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9534640312194824, 'policy_logps/rejected': -264.8519287109375, 'policy_logps/chosen': -414.1446838378906, 'referece_logps/rejected': -248.6591796875, 'referece_logps/chosen': -407.486572265625, 'logits/rejected': -0.42230868339538574, 'logits/chosen': -0.5575335025787354, 'epoch': 0.85}


 14%|█▍        | 2276/16104 [10:37:41<64:53:23, 16.89s/it]

 14%|█▍        | 2277/16104 [10:37:52<57:38:47, 15.01s/it]
{'loss': 0.6517, 'learning_rate': 1.9356784319490557e-06, 'rewards/chosen': -0.7181296348571777, 'rewards/rejected': -0.8698418140411377, 'rewards/accuracies': 0.5, 'rewards/margins': 0.15171226859092712, 'policy_logps/rejected': -342.40740966796875, 'policy_logps/chosen': -326.7717590332031, 'referece_logps/rejected': -333.708984375, 'referece_logps/chosen': -319.5904541015625, 'logits/rejected': -0.7253644466400146, 'logits/chosen': -0.7122859954833984, 'epoch': 0.85}

 14%|█▍        | 2278/16104 [10:38:02<52:31:34, 13.68s/it]

 14%|█▍        | 2279/16104 [10:38:15<51:02:45, 13.29s/it]


 14%|█▍        | 2281/16104 [10:38:37<47:01:10, 12.25s/it]

 14%|█▍        | 2282/16104 [10:38:48<45:11:36, 11.77s/it]
{'loss': 0.6574, 'learning_rate': 1.935323117910033e-06, 'rewards/chosen': -0.7716919183731079, 'rewards/rejected': -0.5529443621635437, 'rewards/accuracies': 0.375, 'rewards/margins': -0.21874749660491943, 'policy_logps/rejected': -473.6954650878906, 'policy_logps/chosen': -513.258544921875, 'referece_logps/rejected': -468.166015625, 'referece_logps/chosen': -505.5416259765625, 'logits/rejected': -0.0944046676158905, 'logits/chosen': -0.210071861743927, 'epoch': 0.85}

 14%|█▍        | 2283/16104 [10:38:59<43:50:31, 11.42s/it]

 14%|█▍        | 2284/16104 [10:39:15<49:33:55, 12.91s/it]

 14%|█▍        | 2285/16104 [10:39:35<57:16:14, 14.92s/it]

 14%|█▍        | 2286/16104 [10:39:49<56:09:47, 14.63s/it]

 14%|█▍        | 2287/16104 [10:39:59<51:40:00, 13.46s/it]


 14%|█▍        | 2289/16104 [10:40:30<55:09:12, 14.37s/it]
[2024-04-06 02:05:37,050] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2290/16104 [10:40:42<52:41:54, 13.73s/it]

 14%|█▍        | 2291/16104 [10:40:54<50:45:40, 13.23s/it]

 14%|█▍        | 2292/16104 [10:41:14<58:02:29, 15.13s/it]

 14%|█▍        | 2293/16104 [10:41:28<56:37:44, 14.76s/it]
{'loss': 0.5416, 'learning_rate': 1.9345380980087505e-06, 'rewards/chosen': -0.6730160117149353, 'rewards/rejected': -0.8673588037490845, 'rewards/accuracies': 0.5, 'rewards/margins': 0.19434280693531036, 'policy_logps/rejected': -446.15234375, 'policy_logps/chosen': -577.3233642578125, 'referece_logps/rejected': -437.478759765625, 'referece_logps/chosen': -570.5931396484375, 'logits/rejected': -1.3554165363311768, 'logits/chosen': -1.2947700023651123, 'epoch': 0.85}

 14%|█▍        | 2294/16104 [10:41:47<62:11:32, 16.21s/it]

 14%|█▍        | 2295/16104 [10:42:03<61:25:53, 16.02s/it]
[2024-04-06 02:07:32,553] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 14%|█▍        | 2297/16104 [10:42:44<69:44:15, 18.18s/it]

 14%|█▍        | 2298/16104 [10:43:04<71:30:57, 18.65s/it]
{'loss': 0.6714, 'learning_rate': 1.9341797584003824e-06, 'rewards/chosen': -0.5408979654312134, 'rewards/rejected': -0.6838999390602112, 'rewards/accuracies': 0.5, 'rewards/margins': 0.14300192892551422, 'policy_logps/rejected': -344.2848205566406, 'policy_logps/chosen': -311.3707275390625, 'referece_logps/rejected': -337.4458312988281, 'referece_logps/chosen': -305.96173095703125, 'logits/rejected': -1.3973422050476074, 'logits/chosen': -1.3492090702056885, 'epoch': 0.86}


 14%|█▍        | 2300/16104 [10:43:38<70:05:54, 18.28s/it]
{'loss': 0.5921, 'learning_rate': 1.9340361580120627e-06, 'rewards/chosen': -0.9017989635467529, 'rewards/rejected': -1.8856269121170044, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9838278889656067, 'policy_logps/rejected': -632.1747436523438, 'policy_logps/chosen': -432.3669738769531, 'referece_logps/rejected': -613.3184814453125, 'referece_logps/chosen': -423.3490295410156, 'logits/rejected': -0.3182772994041443, 'logits/chosen': -0.2941468358039856, 'epoch': 0.86}


 14%|█▍        | 2302/16104 [10:44:10<67:11:46, 17.53s/it]

 14%|█▍        | 2303/16104 [10:44:22<60:39:17, 15.82s/it]
{'loss': 0.5919, 'learning_rate': 1.9338204740611337e-06, 'rewards/chosen': -0.5258171558380127, 'rewards/rejected': -1.0325697660446167, 'rewards/accuracies': 0.5, 'rewards/margins': 0.506752610206604, 'policy_logps/rejected': -315.4367370605469, 'policy_logps/chosen': -392.165771484375, 'referece_logps/rejected': -305.11102294921875, 'referece_logps/chosen': -386.9076232910156, 'logits/rejected': -0.5418601036071777, 'logits/chosen': -0.612889289855957, 'epoch': 0.86}

 14%|█▍        | 2304/16104 [10:44:41<64:49:01, 16.91s/it]

 14%|█▍        | 2305/16104 [10:45:01<67:55:38, 17.72s/it]


 14%|█▍        | 2307/16104 [10:45:26<57:50:02, 15.09s/it]

 14%|█▍        | 2308/16104 [10:45:40<57:17:11, 14.95s/it]

 14%|█▍        | 2309/16104 [10:45:56<58:01:46, 15.14s/it]
{'loss': 0.5086, 'learning_rate': 1.9333880863209274e-06, 'rewards/chosen': -0.46285513043403625, 'rewards/rejected': -1.8417235612869263, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3788684606552124, 'policy_logps/rejected': -381.3273010253906, 'policy_logps/chosen': -308.3399658203125, 'referece_logps/rejected': -362.9100646972656, 'referece_logps/chosen': -303.7113952636719, 'logits/rejected': -1.0934245586395264, 'logits/chosen': -1.0057945251464844, 'epoch': 0.86}


 14%|█▍        | 2311/16104 [10:46:29<58:36:33, 15.30s/it]
{'loss': 0.5841, 'learning_rate': 1.933243654985366e-06, 'rewards/chosen': -0.602814793586731, 'rewards/rejected': -0.9016447067260742, 'rewards/accuracies': 0.625, 'rewards/margins': 0.29882991313934326, 'policy_logps/rejected': -353.20556640625, 'policy_logps/chosen': -319.58056640625, 'referece_logps/rejected': -344.1891174316406, 'referece_logps/chosen': -313.5523681640625, 'logits/rejected': -1.1141200065612793, 'logits/chosen': -0.9568430185317993, 'epoch': 0.86}


 14%|█▍        | 2313/16104 [10:46:54<53:38:39, 14.00s/it]

 14%|█▍        | 2314/16104 [10:47:08<53:57:11, 14.08s/it]

 14%|█▍        | 2315/16104 [10:47:23<54:20:31, 14.19s/it]

 14%|█▍        | 2316/16104 [10:47:42<60:25:00, 15.77s/it]

 14%|█▍        | 2317/16104 [10:48:02<65:12:21, 17.03s/it]

 14%|█▍        | 2318/16104 [10:48:14<59:29:59, 15.54s/it]
{'loss': 0.5305, 'learning_rate': 1.932736956296306e-06, 'rewards/chosen': -0.4466598629951477, 'rewards/rejected': -0.9182267189025879, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4715668261051178, 'policy_logps/rejected': -246.79701232910156, 'policy_logps/chosen': -375.4603576660156, 'referece_logps/rejected': -237.61476135253906, 'referece_logps/chosen': -370.9937744140625, 'logits/rejected': -0.7384532690048218, 'logits/chosen': -0.735891580581665, 'epoch': 0.86}


 14%|█▍        | 2320/16104 [10:48:52<65:28:24, 17.10s/it]

 14%|█▍        | 2321/16104 [10:49:04<59:35:52, 15.57s/it]

 14%|█▍        | 2322/16104 [10:49:17<56:00:06, 14.63s/it]

 14%|█▍        | 2323/16104 [10:49:34<59:31:43, 15.55s/it]
{'loss': 0.5916, 'learning_rate': 1.9323738966765084e-06, 'rewards/chosen': -1.0225034952163696, 'rewards/rejected': -1.2437514066696167, 'rewards/accuracies': 0.625, 'rewards/margins': 0.22124795615673065, 'policy_logps/rejected': -508.6923828125, 'policy_logps/chosen': -451.8890075683594, 'referece_logps/rejected': -496.2548828125, 'referece_logps/chosen': -441.6639709472656, 'logits/rejected': -0.4390760660171509, 'logits/chosen': -0.35390621423721313, 'epoch': 0.87}


 14%|█▍        | 2325/16104 [10:50:12<67:09:18, 17.55s/it]

 14%|█▍        | 2326/16104 [10:50:29<65:39:30, 17.16s/it]
{'loss': 0.6432, 'learning_rate': 1.9321556082868733e-06, 'rewards/chosen': -0.9040253162384033, 'rewards/rejected': -0.6337093114852905, 'rewards/accuracies': 0.375, 'rewards/margins': -0.270315945148468, 'policy_logps/rejected': -467.51629638671875, 'policy_logps/chosen': -653.0106811523438, 'referece_logps/rejected': -461.17919921875, 'referece_logps/chosen': -643.970458984375, 'logits/rejected': -0.14202165603637695, 'logits/chosen': -0.13161787390708923, 'epoch': 0.87}


 14%|█▍        | 2328/16104 [10:51:05<66:05:28, 17.27s/it]

 14%|█▍        | 2329/16104 [10:51:26<71:13:00, 18.61s/it]

 14%|█▍        | 2330/16104 [10:51:45<70:53:58, 18.53s/it]
{'loss': 0.5009, 'learning_rate': 1.9318640292114524e-06, 'rewards/chosen': -0.5756508111953735, 'rewards/rejected': -1.5309613943099976, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9553107619285583, 'policy_logps/rejected': -255.0936279296875, 'policy_logps/chosen': -346.5377197265625, 'referece_logps/rejected': -239.7840118408203, 'referece_logps/chosen': -340.78118896484375, 'logits/rejected': -0.9912912249565125, 'logits/chosen': -1.1157289743423462, 'epoch': 0.87}


 14%|█▍        | 2332/16104 [10:52:18<67:32:42, 17.66s/it]
{'loss': 0.6602, 'learning_rate': 1.9317180134885657e-06, 'rewards/chosen': -0.5355675220489502, 'rewards/rejected': -0.7624334692955017, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2268659472465515, 'policy_logps/rejected': -539.9446411132812, 'policy_logps/chosen': -543.4521484375, 'referece_logps/rejected': -532.3203125, 'referece_logps/chosen': -538.096435546875, 'logits/rejected': 0.09905648231506348, 'logits/chosen': 0.1330004334449768, 'epoch': 0.87}
[2024-04-06 02:17:46,962] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2333/16104 [10:52:40<72:02:02, 18.83s/it]
[2024-04-06 02:18:08,790] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 14%|█▍        | 2334/16104 [10:53:02<75:28:02, 19.73s/it]


 15%|█▍        | 2336/16104 [10:53:47<81:04:53, 21.20s/it]

 15%|█▍        | 2337/16104 [10:53:59<70:27:38, 18.43s/it]
{'loss': 0.5397, 'learning_rate': 1.931352314664114e-06, 'rewards/chosen': -0.405291885137558, 'rewards/rejected': -0.9785997867584229, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5733078718185425, 'policy_logps/rejected': -304.7362060546875, 'policy_logps/chosen': -429.5389404296875, 'referece_logps/rejected': -294.9501953125, 'referece_logps/chosen': -425.4860534667969, 'logits/rejected': -0.9930992126464844, 'logits/chosen': -1.0306756496429443, 'epoch': 0.87}

 15%|█▍        | 2338/16104 [10:54:14<66:51:53, 17.49s/it]


 15%|█▍        | 2340/16104 [10:54:49<67:18:07, 17.60s/it]
{'loss': 0.5702, 'learning_rate': 1.9311324432474133e-06, 'rewards/chosen': -0.8488361239433289, 'rewards/rejected': -2.0488526821136475, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2000166177749634, 'policy_logps/rejected': -458.89288330078125, 'policy_logps/chosen': -447.34332275390625, 'referece_logps/rejected': -438.4043884277344, 'referece_logps/chosen': -438.85498046875, 'logits/rejected': -0.6307838559150696, 'logits/chosen': -0.44805294275283813, 'epoch': 0.87}


 15%|█▍        | 2342/16104 [10:55:27<70:37:15, 18.47s/it]

 15%|█▍        | 2343/16104 [10:55:47<71:58:55, 18.83s/it]

 15%|█▍        | 2344/16104 [10:56:07<73:09:45, 19.14s/it]

 15%|█▍        | 2345/16104 [10:56:25<72:26:39, 18.95s/it]
[2024-04-06 02:21:32,454] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5996, 'learning_rate': 1.930765237606473e-06, 'rewards/chosen': -1.2470946311950684, 'rewards/rejected': -1.5919700860977173, 'rewards/accuracies': 0.375, 'rewards/margins': 0.3448755145072937, 'policy_logps/rejected': -610.786865234375, 'policy_logps/chosen': -489.0186462402344, 'referece_logps/rejected': -594.8671264648438, 'referece_logps/chosen': -476.54766845703125, 'logits/rejected': 0.7007268667221069, 'logits/chosen': 0.734145998954773, 'epoch': 0.87}


 15%|█▍        | 2347/16104 [10:56:49<58:16:45, 15.25s/it]

 15%|█▍        | 2348/16104 [10:57:01<54:31:45, 14.27s/it]

 15%|█▍        | 2349/16104 [10:57:21<60:44:06, 15.90s/it]

 15%|█▍        | 2350/16104 [10:57:43<67:43:17, 17.73s/it]

 15%|█▍        | 2351/16104 [10:57:55<61:05:49, 15.99s/it]

 15%|█▍        | 2352/16104 [10:58:07<57:11:12, 14.97s/it]
{'loss': 0.6396, 'learning_rate': 1.9302495684458265e-06, 'rewards/chosen': -1.1388094425201416, 'rewards/rejected': -1.1773790121078491, 'rewards/accuracies': 0.5, 'rewards/margins': 0.03856965899467468, 'policy_logps/rejected': -441.6558837890625, 'policy_logps/chosen': -442.0603942871094, 'referece_logps/rejected': -429.8821105957031, 'referece_logps/chosen': -430.67230224609375, 'logits/rejected': -0.8449910879135132, 'logits/chosen': -0.9618988037109375, 'epoch': 0.88}
[2024-04-06 02:23:37,030] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 15%|█▍        | 2354/16104 [10:58:45<63:07:39, 16.53s/it]

 15%|█▍        | 2355/16104 [10:59:05<67:39:52, 17.72s/it]
{'loss': 0.5839, 'learning_rate': 1.930028002863515e-06, 'rewards/chosen': -0.6644554138183594, 'rewards/rejected': -1.4479808807373047, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7835253477096558, 'policy_logps/rejected': -227.66317749023438, 'policy_logps/chosen': -432.2611083984375, 'referece_logps/rejected': -213.18336486816406, 'referece_logps/chosen': -425.6165466308594, 'logits/rejected': 0.15852795541286469, 'logits/chosen': 0.1640157401561737, 'epoch': 0.88}


 15%|█▍        | 2357/16104 [10:59:37<64:13:32, 16.82s/it]
{'loss': 0.6276, 'learning_rate': 1.929880104363866e-06, 'rewards/chosen': -0.5384655594825745, 'rewards/rejected': -0.825700044631958, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2872345447540283, 'policy_logps/rejected': -393.7062072753906, 'policy_logps/chosen': -323.0689392089844, 'referece_logps/rejected': -385.44921875, 'referece_logps/chosen': -317.68426513671875, 'logits/rejected': -0.4861370325088501, 'logits/chosen': -0.37472110986709595, 'epoch': 0.88}

 15%|█▍        | 2358/16104 [11:00:00<70:52:11, 18.56s/it]


 15%|█▍        | 2360/16104 [11:00:39<72:57:55, 19.11s/it]
{'loss': 0.6031, 'learning_rate': 1.929657974507059e-06, 'rewards/chosen': -0.9009851813316345, 'rewards/rejected': -1.5706466436386108, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6696613430976868, 'policy_logps/rejected': -345.3001708984375, 'policy_logps/chosen': -455.7599182128906, 'referece_logps/rejected': -329.5936584472656, 'referece_logps/chosen': -446.7501220703125, 'logits/rejected': -0.36978593468666077, 'logits/chosen': -0.3584271967411041, 'epoch': 0.88}


 15%|█▍        | 2362/16104 [11:01:15<70:10:28, 18.38s/it]
{'loss': 0.6039, 'learning_rate': 1.9295096998992424e-06, 'rewards/chosen': -0.80206698179245, 'rewards/rejected': -1.3311299085617065, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5290629267692566, 'policy_logps/rejected': -541.6221313476562, 'policy_logps/chosen': -541.9078369140625, 'referece_logps/rejected': -528.3109130859375, 'referece_logps/chosen': -533.88720703125, 'logits/rejected': 0.49500370025634766, 'logits/chosen': 0.5240552425384521, 'epoch': 0.88}


 15%|█▍        | 2364/16104 [11:01:47<64:12:27, 16.82s/it]
{'loss': 0.6721, 'learning_rate': 1.929361274890123e-06, 'rewards/chosen': -1.2308454513549805, 'rewards/rejected': -1.1334391832351685, 'rewards/accuracies': 0.375, 'rewards/margins': -0.09740620851516724, 'policy_logps/rejected': -486.7827453613281, 'policy_logps/chosen': -317.4637756347656, 'referece_logps/rejected': -475.4483642578125, 'referece_logps/chosen': -305.1553039550781, 'logits/rejected': -1.1323432922363281, 'logits/chosen': -1.1567739248275757, 'epoch': 0.88}


 15%|█▍        | 2366/16104 [11:02:25<69:00:21, 18.08s/it]
{'loss': 0.535, 'learning_rate': 1.9292126995037166e-06, 'rewards/chosen': -0.7644089460372925, 'rewards/rejected': -1.0568426847457886, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2924337089061737, 'policy_logps/rejected': -333.4801025390625, 'policy_logps/chosen': -283.2241516113281, 'referece_logps/rejected': -322.91168212890625, 'referece_logps/chosen': -275.580078125, 'logits/rejected': -0.6106457710266113, 'logits/chosen': -0.7382175922393799, 'epoch': 0.88}


 15%|█▍        | 2368/16104 [11:03:05<72:23:06, 18.97s/it]
{'loss': 0.6384, 'learning_rate': 1.9290639737640647e-06, 'rewards/chosen': -0.7323449850082397, 'rewards/rejected': -0.7452741861343384, 'rewards/accuracies': 0.5, 'rewards/margins': 0.012929130345582962, 'policy_logps/rejected': -276.2372131347656, 'policy_logps/chosen': -328.97705078125, 'referece_logps/rejected': -268.7844543457031, 'referece_logps/chosen': -321.65362548828125, 'logits/rejected': -1.2999495267868042, 'logits/chosen': -1.2493376731872559, 'epoch': 0.88}


 15%|█▍        | 2370/16104 [11:03:36<65:45:57, 17.24s/it]
{'loss': 0.5059, 'learning_rate': 1.928915097695232e-06, 'rewards/chosen': -1.0801150798797607, 'rewards/rejected': -1.477448582649231, 'rewards/accuracies': 0.875, 'rewards/margins': 0.39733365178108215, 'policy_logps/rejected': -386.85284423828125, 'policy_logps/chosen': -434.6578063964844, 'referece_logps/rejected': -372.078369140625, 'referece_logps/chosen': -423.8566589355469, 'logits/rejected': -1.1825454235076904, 'logits/chosen': -1.2592198848724365, 'epoch': 0.88}


 15%|█▍        | 2372/16104 [11:04:07<61:24:50, 16.10s/it]

 15%|█▍        | 2373/16104 [11:04:27<66:00:26, 17.31s/it]

 15%|█▍        | 2374/16104 [11:04:43<64:34:44, 16.93s/it]
{'loss': 0.5702, 'learning_rate': 1.9286168946664033e-06, 'rewards/chosen': -1.1905746459960938, 'rewards/rejected': -1.2449326515197754, 'rewards/accuracies': 0.75, 'rewards/margins': 0.05435808002948761, 'policy_logps/rejected': -431.26995849609375, 'policy_logps/chosen': -318.3533020019531, 'referece_logps/rejected': -418.82061767578125, 'referece_logps/chosen': -306.44757080078125, 'logits/rejected': -0.4549410045146942, 'logits/chosen': -0.44318321347236633, 'epoch': 0.88}
[2024-04-06 02:30:12,358] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2375/16104 [11:05:05<70:02:43, 18.37s/it]

 15%|█▍        | 2376/16104 [11:05:18<63:42:38, 16.71s/it]
[2024-04-06 02:30:41,877] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2377/16104 [11:05:35<63:40:57, 16.70s/it]

 15%|█▍        | 2378/16104 [11:05:55<67:46:18, 17.77s/it]

 15%|█▍        | 2379/16104 [11:06:11<65:58:45, 17.31s/it]

 15%|█▍        | 2380/16104 [11:06:27<63:59:59, 16.79s/it]

 15%|█▍        | 2381/16104 [11:06:43<63:38:28, 16.70s/it]

 15%|█▍        | 2382/16104 [11:06:59<62:56:11, 16.51s/it]

 15%|█▍        | 2383/16104 [11:07:20<67:52:58, 17.81s/it]

 15%|█▍        | 2384/16104 [11:07:33<62:01:01, 16.27s/it]


 15%|█▍        | 2386/16104 [11:08:06<63:49:58, 16.75s/it]
{'loss': 0.5661, 'learning_rate': 1.927718680189861e-06, 'rewards/chosen': -0.9581982493400574, 'rewards/rejected': -2.053636074066162, 'rewards/accuracies': 1.0, 'rewards/margins': 1.095438003540039, 'policy_logps/rejected': -363.02947998046875, 'policy_logps/chosen': -436.24163818359375, 'referece_logps/rejected': -342.4931640625, 'referece_logps/chosen': -426.65972900390625, 'logits/rejected': -0.11087608337402344, 'logits/chosen': -0.226888507604599, 'epoch': 0.89}

 15%|█▍        | 2387/16104 [11:08:28<69:43:58, 18.30s/it]


 15%|█▍        | 2389/16104 [11:09:00<64:51:39, 17.03s/it]

 15%|█▍        | 2390/16104 [11:09:12<58:44:05, 15.42s/it]
{'loss': 0.6069, 'learning_rate': 1.927418074213605e-06, 'rewards/chosen': -0.38602906465530396, 'rewards/rejected': -1.330053448677063, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9440245032310486, 'policy_logps/rejected': -468.84991455078125, 'policy_logps/chosen': -609.6754150390625, 'referece_logps/rejected': -455.54937744140625, 'referece_logps/chosen': -605.8151245117188, 'logits/rejected': -0.18106642365455627, 'logits/chosen': -0.2836887240409851, 'epoch': 0.89}


 15%|█▍        | 2392/16104 [11:09:42<57:19:25, 15.05s/it]
{'loss': 0.5181, 'learning_rate': 1.9272675461190166e-06, 'rewards/chosen': -0.7158771753311157, 'rewards/rejected': -1.4259542226791382, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7100771069526672, 'policy_logps/rejected': -386.45770263671875, 'policy_logps/chosen': -403.0905456542969, 'referece_logps/rejected': -372.19818115234375, 'referece_logps/chosen': -395.9317932128906, 'logits/rejected': -0.8047432899475098, 'logits/chosen': -0.6882745623588562, 'epoch': 0.89}

 15%|█▍        | 2393/16104 [11:09:55<54:46:12, 14.38s/it]


 15%|█▍        | 2395/16104 [11:10:20<50:40:14, 13.31s/it]
{'loss': 0.6079, 'learning_rate': 1.927041472662553e-06, 'rewards/chosen': -0.7484358549118042, 'rewards/rejected': -1.0726255178451538, 'rewards/accuracies': 0.625, 'rewards/margins': 0.324189692735672, 'policy_logps/rejected': -333.854248046875, 'policy_logps/chosen': -467.1020202636719, 'referece_logps/rejected': -323.12799072265625, 'referece_logps/chosen': -459.6177062988281, 'logits/rejected': 0.47774529457092285, 'logits/chosen': 0.40353086590766907, 'epoch': 0.89}


 15%|█▍        | 2397/16104 [11:10:52<57:22:36, 15.07s/it]
{'loss': 0.5249, 'learning_rate': 1.9268905695174208e-06, 'rewards/chosen': -1.163711667060852, 'rewards/rejected': -1.537545919418335, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3738342225551605, 'policy_logps/rejected': -320.87896728515625, 'policy_logps/chosen': -366.50921630859375, 'referece_logps/rejected': -305.50347900390625, 'referece_logps/chosen': -354.8721008300781, 'logits/rejected': -0.01244400069117546, 'logits/chosen': 0.06674999743700027, 'epoch': 0.89}

 15%|█▍        | 2398/16104 [11:11:12<62:29:22, 16.41s/it]

 15%|█▍        | 2399/16104 [11:11:25<58:36:49, 15.40s/it]
[2024-04-06 02:36:51,940] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▍        | 2400/16104 [11:11:45<63:54:11, 16.79s/it]

 15%|█▍        | 2401/16104 [11:11:59<60:35:33, 15.92s/it]

 15%|█▍        | 2402/16104 [11:12:17<63:09:02, 16.59s/it]

 15%|█▍        | 2403/16104 [11:12:37<67:01:50, 17.61s/it]


 15%|█▍        | 2405/16104 [11:13:10<63:42:05, 16.74s/it]
{'loss': 0.6194, 'learning_rate': 1.9262854574063405e-06, 'rewards/chosen': -0.8413820266723633, 'rewards/rejected': -0.9682042002677917, 'rewards/accuracies': 0.5, 'rewards/margins': 0.1268220990896225, 'policy_logps/rejected': -363.0155944824219, 'policy_logps/chosen': -491.6931457519531, 'referece_logps/rejected': -353.3335266113281, 'referece_logps/chosen': -483.2793273925781, 'logits/rejected': -1.004084587097168, 'logits/chosen': -1.0516383647918701, 'epoch': 0.9}

 15%|█▍        | 2406/16104 [11:13:23<59:37:30, 15.67s/it]

 15%|█▍        | 2407/16104 [11:13:37<57:12:27, 15.04s/it]

 15%|█▍        | 2408/16104 [11:13:55<61:19:20, 16.12s/it]


 15%|█▍        | 2410/16104 [11:14:30<65:13:41, 17.15s/it]
{'loss': 0.5696, 'learning_rate': 1.9259060444657334e-06, 'rewards/chosen': -0.5522319078445435, 'rewards/rejected': -0.6934711337089539, 'rewards/accuracies': 0.625, 'rewards/margins': 0.14123928546905518, 'policy_logps/rejected': -277.73236083984375, 'policy_logps/chosen': -401.2967529296875, 'referece_logps/rejected': -270.7976379394531, 'referece_logps/chosen': -395.7744445800781, 'logits/rejected': -0.2642480134963989, 'logits/chosen': -0.2393285036087036, 'epoch': 0.9}

 15%|█▍        | 2411/16104 [11:14:49<66:44:57, 17.55s/it]

 15%|█▍        | 2412/16104 [11:15:01<60:18:20, 15.86s/it]

 15%|█▍        | 2413/16104 [11:15:20<64:25:30, 16.94s/it]

 15%|█▍        | 2414/16104 [11:15:33<60:12:51, 15.83s/it]

 15%|█▍        | 2415/16104 [11:15:47<57:37:06, 15.15s/it]


 15%|█▌        | 2417/16104 [11:16:26<67:01:09, 17.63s/it]
{'loss': 0.5341, 'learning_rate': 1.9253732933439655e-06, 'rewards/chosen': -0.5137523412704468, 'rewards/rejected': -0.9728735089302063, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4591211676597595, 'policy_logps/rejected': -482.45635986328125, 'policy_logps/chosen': -444.9029235839844, 'referece_logps/rejected': -472.72760009765625, 'referece_logps/chosen': -439.7654113769531, 'logits/rejected': -1.2143912315368652, 'logits/chosen': -1.1800898313522339, 'epoch': 0.9}
[2024-04-06 02:41:56,299] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2418/16104 [11:16:49<72:42:21, 19.12s/it]
[2024-04-06 02:42:12,220] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 15%|█▌        | 2420/16104 [11:17:29<75:07:37, 19.76s/it]
[2024-04-06 02:42:35,719] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2421/16104 [11:17:45<70:52:28, 18.65s/it]
{'loss': 0.5231, 'learning_rate': 1.9250680405377563e-06, 'rewards/chosen': -0.4807452857494354, 'rewards/rejected': -1.3668134212493896, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8860681653022766, 'policy_logps/rejected': -310.0193176269531, 'policy_logps/chosen': -407.1219482421875, 'referece_logps/rejected': -296.3511962890625, 'referece_logps/chosen': -402.31451416015625, 'logits/rejected': -0.6541650891304016, 'logits/chosen': -0.737983763217926, 'epoch': 0.9}

 15%|█▌        | 2422/16104 [11:18:06<74:05:09, 19.49s/it]

 15%|█▌        | 2423/16104 [11:18:26<74:41:01, 19.65s/it]

 15%|█▌        | 2424/16104 [11:18:47<76:41:28, 20.18s/it]


 15%|█▌        | 2426/16104 [11:19:15<63:11:33, 16.63s/it]
{'loss': 0.5584, 'learning_rate': 1.9246856325885337e-06, 'rewards/chosen': -0.7811490297317505, 'rewards/rejected': -0.7883523106575012, 'rewards/accuracies': 0.375, 'rewards/margins': 0.007203251123428345, 'policy_logps/rejected': -217.05728149414062, 'policy_logps/chosen': -335.23626708984375, 'referece_logps/rejected': -209.17373657226562, 'referece_logps/chosen': -327.4247741699219, 'logits/rejected': -1.4118409156799316, 'logits/chosen': -1.2996371984481812, 'epoch': 0.9}

 15%|█▌        | 2427/16104 [11:19:32<63:35:26, 16.74s/it]

 15%|█▌        | 2428/16104 [11:19:49<63:58:49, 16.84s/it]

 15%|█▌        | 2429/16104 [11:20:09<67:39:56, 17.81s/it]

 15%|█▌        | 2430/16104 [11:20:31<72:32:13, 19.10s/it]

 15%|█▌        | 2431/16104 [11:20:42<63:02:03, 16.60s/it]

 15%|█▌        | 2432/16104 [11:20:55<59:27:09, 15.65s/it]

 15%|█▌        | 2433/16104 [11:21:14<62:45:30, 16.53s/it]


 15%|█▌        | 2435/16104 [11:21:51<65:42:36, 17.31s/it]
{'loss': 0.5295, 'learning_rate': 1.923994942014021e-06, 'rewards/chosen': -0.8794834017753601, 'rewards/rejected': -1.82142174243927, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9419383406639099, 'policy_logps/rejected': -282.48150634765625, 'policy_logps/chosen': -350.3485107421875, 'referece_logps/rejected': -264.267333984375, 'referece_logps/chosen': -341.5536804199219, 'logits/rejected': -0.22194184362888336, 'logits/chosen': -0.14470328390598297, 'epoch': 0.91}

 15%|█▌        | 2436/16104 [11:22:06<63:42:56, 16.78s/it]

 15%|█▌        | 2437/16104 [11:22:26<67:26:11, 17.76s/it]

 15%|█▌        | 2438/16104 [11:22:46<70:06:24, 18.47s/it]

 15%|█▌        | 2439/16104 [11:23:06<71:42:47, 18.89s/it]

 15%|█▌        | 2440/16104 [11:23:25<71:49:07, 18.92s/it]

 15%|█▌        | 2441/16104 [11:23:37<63:11:03, 16.65s/it]
[2024-04-06 02:49:05,325] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2442/16104 [11:23:58<68:48:52, 18.13s/it]
[2024-04-06 02:49:25,191] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2443/16104 [11:24:18<70:46:59, 18.65s/it]

 15%|█▌        | 2444/16104 [11:24:38<72:03:05, 18.99s/it]

 15%|█▌        | 2445/16104 [11:24:57<72:45:20, 19.18s/it]

 15%|█▌        | 2446/16104 [11:25:08<63:12:47, 16.66s/it]

 15%|█▌        | 2447/16104 [11:25:28<66:23:12, 17.50s/it]

 15%|█▌        | 2448/16104 [11:25:39<59:47:43, 15.76s/it]

 15%|█▌        | 2449/16104 [11:25:50<54:07:30, 14.27s/it]


 15%|█▌        | 2451/16104 [11:26:23<59:23:00, 15.66s/it]
{'loss': 0.5331, 'learning_rate': 1.9227595736672157e-06, 'rewards/chosen': -1.1649181842803955, 'rewards/rejected': -1.5472726821899414, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3823544979095459, 'policy_logps/rejected': -350.375244140625, 'policy_logps/chosen': -352.0050048828125, 'referece_logps/rejected': -334.90252685546875, 'referece_logps/chosen': -340.3558349609375, 'logits/rejected': 0.12329916656017303, 'logits/chosen': 0.21863716840744019, 'epoch': 0.91}

 15%|█▌        | 2452/16104 [11:26:42<63:01:51, 16.62s/it]

 15%|█▌        | 2453/16104 [11:27:04<69:47:31, 18.41s/it]

 15%|█▌        | 2454/16104 [11:27:22<68:52:30, 18.16s/it]

 15%|█▌        | 2455/16104 [11:27:37<64:43:12, 17.07s/it]


 15%|█▌        | 2457/16104 [11:28:13<66:29:33, 17.54s/it]
{'loss': 0.5312, 'learning_rate': 1.9222938462490846e-06, 'rewards/chosen': -0.6437172889709473, 'rewards/rejected': -1.837563395500183, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1938461065292358, 'policy_logps/rejected': -440.8328857421875, 'policy_logps/chosen': -473.2325439453125, 'referece_logps/rejected': -422.457275390625, 'referece_logps/chosen': -466.79534912109375, 'logits/rejected': -0.4120977818965912, 'logits/chosen': -0.4909988045692444, 'epoch': 0.92}


 15%|█▌        | 2459/16104 [11:28:43<62:31:20, 16.50s/it]
{'loss': 0.5939, 'learning_rate': 1.9221383052754057e-06, 'rewards/chosen': -0.7883296608924866, 'rewards/rejected': -1.6533918380737305, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8650621771812439, 'policy_logps/rejected': -441.3103942871094, 'policy_logps/chosen': -462.89208984375, 'referece_logps/rejected': -424.7764892578125, 'referece_logps/chosen': -455.0087890625, 'logits/rejected': -0.9948685169219971, 'logits/chosen': -0.7433158159255981, 'epoch': 0.92}

 15%|█▌        | 2460/16104 [11:28:54<56:15:44, 14.84s/it]


 15%|█▌        | 2462/16104 [11:29:25<58:45:57, 15.51s/it]
{'loss': 0.6629, 'learning_rate': 1.9219047140567115e-06, 'rewards/chosen': -1.240954875946045, 'rewards/rejected': -1.0819921493530273, 'rewards/accuracies': 0.25, 'rewards/margins': -0.15896278619766235, 'policy_logps/rejected': -509.445068359375, 'policy_logps/chosen': -492.1600646972656, 'referece_logps/rejected': -498.62518310546875, 'referece_logps/chosen': -479.7505187988281, 'logits/rejected': 0.2924884557723999, 'logits/chosen': 0.22863233089447021, 'epoch': 0.92}

 15%|█▌        | 2463/16104 [11:29:46<64:42:14, 17.08s/it]

 15%|█▌        | 2464/16104 [11:30:04<65:17:21, 17.23s/it]

 15%|█▌        | 2465/16104 [11:30:23<67:28:50, 17.81s/it]

 15%|█▌        | 2466/16104 [11:30:38<64:11:49, 16.95s/it]
[2024-04-06 02:56:03,028] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2467/16104 [11:30:56<65:31:25, 17.30s/it]

 15%|█▌        | 2468/16104 [11:31:16<68:58:34, 18.21s/it]

 15%|█▌        | 2469/16104 [11:31:32<66:30:38, 17.56s/it]

 15%|█▌        | 2470/16104 [11:31:48<64:09:19, 16.94s/it]

 15%|█▌        | 2471/16104 [11:32:08<67:30:45, 17.83s/it]

 15%|█▌        | 2472/16104 [11:32:24<66:05:09, 17.45s/it]

 15%|█▌        | 2473/16104 [11:32:37<60:21:45, 15.94s/it]

 15%|█▌        | 2474/16104 [11:32:54<62:20:24, 16.47s/it]

 15%|█▌        | 2475/16104 [11:33:11<62:23:29, 16.48s/it]

 15%|█▌        | 2476/16104 [11:33:32<67:33:35, 17.85s/it]


 15%|█▌        | 2478/16104 [11:34:04<64:54:24, 17.15s/it]

 15%|█▌        | 2479/16104 [11:34:15<58:54:29, 15.56s/it]
{'loss': 0.5415, 'learning_rate': 1.920574693232507e-06, 'rewards/chosen': -0.8784016966819763, 'rewards/rejected': -1.487267017364502, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6088653802871704, 'policy_logps/rejected': -266.2113037109375, 'policy_logps/chosen': -300.097900390625, 'referece_logps/rejected': -251.33863830566406, 'referece_logps/chosen': -291.3138732910156, 'logits/rejected': -0.4335036277770996, 'logits/chosen': -0.32987862825393677, 'epoch': 0.92}


 15%|█▌        | 2481/16104 [11:34:47<60:55:22, 16.10s/it]

 15%|█▌        | 2482/16104 [11:35:04<61:21:20, 16.21s/it]

 15%|█▌        | 2483/16104 [11:35:23<64:49:48, 17.13s/it]
[2024-04-06 03:00:30,423] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 15%|█▌        | 2484/16104 [11:35:40<64:00:04, 16.92s/it]

 15%|█▌        | 2485/16104 [11:35:52<59:11:29, 15.65s/it]

 15%|█▌        | 2486/16104 [11:36:08<58:45:54, 15.53s/it]

 15%|█▌        | 2487/16104 [11:36:30<66:12:08, 17.50s/it]

 15%|█▌        | 2488/16104 [11:36:42<60:51:07, 16.09s/it]

 15%|█▌        | 2489/16104 [11:37:01<63:10:42, 16.71s/it]

 15%|█▌        | 2490/16104 [11:37:14<59:37:20, 15.77s/it]

 15%|█▌        | 2491/16104 [11:37:27<56:21:41, 14.90s/it]

 15%|█▌        | 2492/16104 [11:37:45<60:06:37, 15.90s/it]
{'loss': 0.534, 'learning_rate': 1.9195503560808088e-06, 'rewards/chosen': -1.0695866346359253, 'rewards/rejected': -1.3185651302337646, 'rewards/accuracies': 0.75, 'rewards/margins': 0.24897855520248413, 'policy_logps/rejected': -385.13287353515625, 'policy_logps/chosen': -372.3092041015625, 'referece_logps/rejected': -371.94720458984375, 'referece_logps/chosen': -361.61334228515625, 'logits/rejected': 0.03502170741558075, 'logits/chosen': -0.004140473902225494, 'epoch': 0.93}


 15%|█▌        | 2494/16104 [11:38:18<60:40:57, 16.05s/it]

 15%|█▌        | 2495/16104 [11:38:30<55:56:55, 14.80s/it]

 15%|█▌        | 2496/16104 [11:38:42<52:55:12, 14.00s/it]
{'loss': 0.6312, 'learning_rate': 1.9192339103798013e-06, 'rewards/chosen': -0.8472412824630737, 'rewards/rejected': -0.998443067073822, 'rewards/accuracies': 0.625, 'rewards/margins': 0.15120181441307068, 'policy_logps/rejected': -387.474853515625, 'policy_logps/chosen': -379.1578674316406, 'referece_logps/rejected': -377.49041748046875, 'referece_logps/chosen': -370.6854553222656, 'logits/rejected': -0.13059654831886292, 'logits/chosen': -0.17430979013442993, 'epoch': 0.93}


 16%|█▌        | 2498/16104 [11:39:13<54:19:34, 14.37s/it]
{'loss': 0.5796, 'learning_rate': 1.9190754644085806e-06, 'rewards/chosen': -0.896702229976654, 'rewards/rejected': -1.3914296627044678, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4947274327278137, 'policy_logps/rejected': -390.487060546875, 'policy_logps/chosen': -372.5890197753906, 'referece_logps/rejected': -376.57281494140625, 'referece_logps/chosen': -363.6219787597656, 'logits/rejected': -0.4570696949958801, 'logits/chosen': -0.5410409569740295, 'epoch': 0.93}


 16%|█▌        | 2500/16104 [11:39:53<65:39:00, 17.37s/it]

 16%|█▌        | 2501/16104 [11:40:29<86:20:01, 22.85s/it]
[2024-04-06 03:05:35,791] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2502/16104 [11:40:41<74:08:35, 19.62s/it]
[2024-04-06 03:05:47,888] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2503/16104 [11:40:55<67:36:22, 17.89s/it]

 16%|█▌        | 2504/16104 [11:41:11<66:08:19, 17.51s/it]

 16%|█▌        | 2505/16104 [11:41:25<62:06:19, 16.44s/it]

 16%|█▌        | 2506/16104 [11:41:41<61:11:51, 16.20s/it]

 16%|█▌        | 2507/16104 [11:41:57<61:07:27, 16.18s/it]

 16%|█▌        | 2508/16104 [11:42:08<55:05:56, 14.59s/it]

 16%|█▌        | 2509/16104 [11:42:25<57:59:35, 15.36s/it]

 16%|█▌        | 2510/16104 [11:42:39<56:21:05, 14.92s/it]

 16%|█▌        | 2511/16104 [11:42:55<58:17:40, 15.44s/it]
{'loss': 0.6735, 'learning_rate': 1.918041941864997e-06, 'rewards/chosen': -0.6621454358100891, 'rewards/rejected': -1.2301056385040283, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5679601430892944, 'policy_logps/rejected': -209.32435607910156, 'policy_logps/chosen': -479.8260498046875, 'referece_logps/rejected': -197.0233154296875, 'referece_logps/chosen': -473.20458984375, 'logits/rejected': -0.8561362028121948, 'logits/chosen': -0.9025771617889404, 'epoch': 0.94}


 16%|█▌        | 2513/16104 [11:43:18<50:52:28, 13.48s/it]

 16%|█▌        | 2514/16104 [11:43:33<52:36:14, 13.93s/it]

 16%|█▌        | 2515/16104 [11:43:44<48:54:37, 12.96s/it]

 16%|█▌        | 2516/16104 [11:44:07<59:47:16, 15.84s/it]
[2024-04-06 03:09:13,858] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▌        | 2517/16104 [11:44:27<64:24:26, 17.07s/it]

 16%|█▌        | 2518/16104 [11:44:43<63:46:45, 16.90s/it]

 16%|█▌        | 2519/16104 [11:45:03<66:53:38, 17.73s/it]
{'loss': 0.4503, 'learning_rate': 1.917402808081241e-06, 'rewards/chosen': -0.5360362529754639, 'rewards/rejected': -1.5048097372055054, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9687735438346863, 'policy_logps/rejected': -292.0240173339844, 'policy_logps/chosen': -451.1596984863281, 'referece_logps/rejected': -276.97589111328125, 'referece_logps/chosen': -445.7993469238281, 'logits/rejected': -0.7520115375518799, 'logits/chosen': -0.8720413446426392, 'epoch': 0.94}


 16%|█▌        | 2521/16104 [11:45:32<60:20:04, 15.99s/it]

 16%|█▌        | 2522/16104 [11:45:51<64:19:52, 17.05s/it]

 16%|█▌        | 2523/16104 [11:46:13<69:48:07, 18.50s/it]

 16%|█▌        | 2524/16104 [11:46:30<67:49:31, 17.98s/it]

 16%|█▌        | 2525/16104 [11:46:46<65:28:23, 17.36s/it]

 16%|█▌        | 2526/16104 [11:47:05<67:18:49, 17.85s/it]

 16%|█▌        | 2527/16104 [11:47:26<70:53:41, 18.80s/it]

 16%|█▌        | 2528/16104 [11:47:42<67:37:40, 17.93s/it]

 16%|█▌        | 2529/16104 [11:47:59<66:48:16, 17.72s/it]
{'loss': 0.6293, 'learning_rate': 1.9166005510944852e-06, 'rewards/chosen': -0.7374427318572998, 'rewards/rejected': -1.3383914232254028, 'rewards/accuracies': 0.625, 'rewards/margins': 0.600948691368103, 'policy_logps/rejected': -601.4442138671875, 'policy_logps/chosen': -555.3878784179688, 'referece_logps/rejected': -588.060302734375, 'referece_logps/chosen': -548.0133666992188, 'logits/rejected': 0.5660476684570312, 'logits/chosen': 0.6052172183990479, 'epoch': 0.94}


 16%|█▌        | 2531/16104 [11:48:24<56:02:44, 14.87s/it]

 16%|█▌        | 2532/16104 [11:48:35<52:09:24, 13.83s/it]

 16%|█▌        | 2533/16104 [11:48:56<60:01:39, 15.92s/it]

 16%|█▌        | 2534/16104 [11:49:08<55:12:45, 14.65s/it]

 16%|█▌        | 2535/16104 [11:49:20<52:31:06, 13.93s/it]

 16%|█▌        | 2536/16104 [11:49:36<54:43:28, 14.52s/it]

 16%|█▌        | 2537/16104 [11:49:46<50:22:16, 13.37s/it]

 16%|█▌        | 2538/16104 [11:50:06<57:03:56, 15.14s/it]

 16%|█▌        | 2539/16104 [11:50:23<59:57:15, 15.91s/it]

 16%|█▌        | 2540/16104 [11:50:44<64:55:21, 17.23s/it]

 16%|█▌        | 2541/16104 [11:51:01<65:19:28, 17.34s/it]

 16%|█▌        | 2542/16104 [11:51:16<62:14:56, 16.52s/it]

 16%|█▌        | 2543/16104 [11:51:27<56:23:40, 14.97s/it]

 16%|█▌        | 2544/16104 [11:51:48<62:39:57, 16.64s/it]

 16%|█▌        | 2545/16104 [11:52:10<68:32:51, 18.20s/it]

 16%|█▌        | 2546/16104 [11:52:28<68:28:57, 18.18s/it]

 16%|█▌        | 2547/16104 [11:52:47<69:56:10, 18.57s/it]

 16%|█▌        | 2548/16104 [11:53:06<70:22:23, 18.69s/it]

 16%|█▌        | 2549/16104 [11:53:27<72:56:41, 19.37s/it]

 16%|█▌        | 2550/16104 [11:53:48<74:14:12, 19.72s/it]

 16%|█▌        | 2551/16104 [11:54:08<74:40:33, 19.84s/it]

 16%|█▌        | 2552/16104 [11:54:26<72:42:48, 19.32s/it]

 16%|█▌        | 2553/16104 [11:54:41<67:35:20, 17.96s/it]

 16%|█▌        | 2554/16104 [11:55:01<69:51:11, 18.56s/it]

 16%|█▌        | 2555/16104 [11:55:20<70:42:37, 18.79s/it]

 16%|█▌        | 2556/16104 [11:55:38<69:27:18, 18.46s/it]

 16%|█▌        | 2557/16104 [11:55:51<63:21:41, 16.84s/it]

 16%|█▌        | 2558/16104 [11:56:10<66:25:20, 17.65s/it]

 16%|█▌        | 2559/16104 [11:56:30<68:47:02, 18.28s/it]

 16%|█▌        | 2560/16104 [11:56:41<60:08:47, 15.99s/it]

 16%|█▌        | 2561/16104 [11:56:56<59:27:47, 15.81s/it]

 16%|█▌        | 2562/16104 [11:57:10<56:52:13, 15.12s/it]

 16%|█▌        | 2563/16104 [11:57:29<61:51:25, 16.45s/it]

 16%|█▌        | 2564/16104 [11:57:47<63:37:21, 16.92s/it]

 16%|█▌        | 2565/16104 [11:58:04<63:59:16, 17.01s/it]

 16%|█▌        | 2566/16104 [11:58:17<58:42:00, 15.61s/it]

 16%|█▌        | 2567/16104 [11:58:35<61:13:18, 16.28s/it]

 16%|█▌        | 2568/16104 [11:58:46<55:55:09, 14.87s/it]

 16%|█▌        | 2569/16104 [11:58:57<51:14:57, 13.63s/it]

 16%|█▌        | 2570/16104 [11:59:18<59:32:39, 15.84s/it]

 16%|█▌        | 2571/16104 [11:59:33<58:47:42, 15.64s/it]
{'loss': 0.5582, 'learning_rate': 1.9131906205195065e-06, 'rewards/chosen': -1.116505742073059, 'rewards/rejected': -2.0360398292541504, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9195343255996704, 'policy_logps/rejected': -292.75189208984375, 'policy_logps/chosen': -305.13409423828125, 'referece_logps/rejected': -272.3914794921875, 'referece_logps/chosen': -293.96905517578125, 'logits/rejected': -0.7276444435119629, 'logits/chosen': -0.84381103515625, 'epoch': 0.96}


 16%|█▌        | 2573/16104 [12:00:04<59:53:03, 15.93s/it]

 16%|█▌        | 2574/16104 [12:00:26<66:18:51, 17.64s/it]

 16%|█▌        | 2575/16104 [12:00:39<60:58:32, 16.23s/it]

 16%|█▌        | 2576/16104 [12:00:53<58:17:48, 15.51s/it]

 16%|█▌        | 2577/16104 [12:01:09<59:00:59, 15.71s/it]
{'loss': 0.502, 'learning_rate': 1.9126981624911514e-06, 'rewards/chosen': -0.3787939250469208, 'rewards/rejected': -1.1808401346206665, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8020462393760681, 'policy_logps/rejected': -274.7255554199219, 'policy_logps/chosen': -322.8715515136719, 'referece_logps/rejected': -262.9171447753906, 'referece_logps/chosen': -319.0836181640625, 'logits/rejected': -0.9199045300483704, 'logits/chosen': -0.9037039279937744, 'epoch': 0.96}

 16%|█▌        | 2578/16104 [12:01:30<64:32:12, 17.18s/it]


 16%|█▌        | 2580/16104 [12:02:01<60:16:22, 16.04s/it]

 16%|█▌        | 2581/16104 [12:02:15<58:09:17, 15.48s/it]
{'loss': 0.5964, 'learning_rate': 1.9123691186892664e-06, 'rewards/chosen': -1.585343837738037, 'rewards/rejected': -2.1689364910125732, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5835926532745361, 'policy_logps/rejected': -401.5496826171875, 'policy_logps/chosen': -462.5445251464844, 'referece_logps/rejected': -379.86029052734375, 'referece_logps/chosen': -446.6910400390625, 'logits/rejected': -1.2222745418548584, 'logits/chosen': -1.3086780309677124, 'epoch': 0.96}


 16%|█▌        | 2583/16104 [12:02:47<57:48:27, 15.39s/it]

 16%|█▌        | 2584/16104 [12:03:05<61:29:17, 16.37s/it]

 16%|█▌        | 2585/16104 [12:03:16<55:29:07, 14.78s/it]

 16%|█▌        | 2586/16104 [12:03:36<61:06:30, 16.27s/it]

 16%|█▌        | 2587/16104 [12:03:54<63:02:26, 16.79s/it]

 16%|█▌        | 2588/16104 [12:04:09<60:45:47, 16.18s/it]

 16%|█▌        | 2589/16104 [12:04:22<56:45:17, 15.12s/it]

 16%|█▌        | 2590/16104 [12:04:39<59:02:32, 15.73s/it]

 16%|█▌        | 2591/16104 [12:04:58<63:19:16, 16.87s/it]

 16%|█▌        | 2592/16104 [12:05:19<67:40:00, 18.03s/it]

 16%|█▌        | 2593/16104 [12:05:34<64:22:17, 17.15s/it]

 16%|█▌        | 2594/16104 [12:05:52<64:44:55, 17.25s/it]
{'loss': 0.5237, 'learning_rate': 1.911295649220079e-06, 'rewards/chosen': -1.0171698331832886, 'rewards/rejected': -2.1556546688079834, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1384847164154053, 'policy_logps/rejected': -684.753173828125, 'policy_logps/chosen': -531.1066284179688, 'referece_logps/rejected': -663.1966552734375, 'referece_logps/chosen': -520.9349365234375, 'logits/rejected': -0.5428309440612793, 'logits/chosen': -0.5264808535575867, 'epoch': 0.97}


 16%|█▌        | 2596/16104 [12:06:29<67:13:23, 17.92s/it]

 16%|█▌        | 2597/16104 [12:06:49<69:59:30, 18.65s/it]
{'loss': 0.5814, 'learning_rate': 1.911047040503988e-06, 'rewards/chosen': -1.0647001266479492, 'rewards/rejected': -1.618327260017395, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5536271333694458, 'policy_logps/rejected': -465.019775390625, 'policy_logps/chosen': -600.6202392578125, 'referece_logps/rejected': -448.8365173339844, 'referece_logps/chosen': -589.9732055664062, 'logits/rejected': -1.3230844736099243, 'logits/chosen': -1.4060192108154297, 'epoch': 0.97}

 16%|█▌        | 2598/16104 [12:07:10<72:42:02, 19.38s/it]


 16%|█▌        | 2600/16104 [12:07:41<65:11:38, 17.38s/it]
{'loss': 0.5333, 'learning_rate': 1.910798100106599e-06, 'rewards/chosen': -0.7728031873703003, 'rewards/rejected': -1.5703157186508179, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7975126504898071, 'policy_logps/rejected': -379.57916259765625, 'policy_logps/chosen': -321.3627014160156, 'referece_logps/rejected': -363.8760070800781, 'referece_logps/chosen': -313.6346740722656, 'logits/rejected': -0.8364773392677307, 'logits/chosen': -0.8868672847747803, 'epoch': 0.97}


 16%|█▌        | 2602/16104 [12:08:19<68:19:27, 18.22s/it]

 16%|█▌        | 2603/16104 [12:08:37<67:47:15, 18.08s/it]
{'loss': 0.5816, 'learning_rate': 1.9105488281185434e-06, 'rewards/chosen': -0.8606979846954346, 'rewards/rejected': -1.923761010169983, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0630630254745483, 'policy_logps/rejected': -315.7463684082031, 'policy_logps/chosen': -395.41943359375, 'referece_logps/rejected': -296.5087890625, 'referece_logps/chosen': -386.81243896484375, 'logits/rejected': -0.751772403717041, 'logits/chosen': -0.8428114056587219, 'epoch': 0.97}


 16%|█▌        | 2605/16104 [12:09:10<66:20:54, 17.69s/it]
[2024-04-06 03:34:16,993] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5905, 'learning_rate': 1.9103824626209455e-06, 'rewards/chosen': -0.67141193151474, 'rewards/rejected': -1.3556047677993774, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6841928958892822, 'policy_logps/rejected': -487.5175476074219, 'policy_logps/chosen': -568.4170532226562, 'referece_logps/rejected': -473.96148681640625, 'referece_logps/chosen': -561.7029418945312, 'logits/rejected': -0.07790551334619522, 'logits/chosen': -0.02494245022535324, 'epoch': 0.97}
[2024-04-06 03:34:31,811] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▌        | 2607/16104 [12:09:41<62:20:11, 16.63s/it]
{'loss': 0.5242, 'learning_rate': 1.910215949816969e-06, 'rewards/chosen': -0.4854757487773895, 'rewards/rejected': -1.0371041297912598, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5516284108161926, 'policy_logps/rejected': -379.2896728515625, 'policy_logps/chosen': -365.1136474609375, 'referece_logps/rejected': -368.91864013671875, 'referece_logps/chosen': -360.2589111328125, 'logits/rejected': -0.5246798992156982, 'logits/chosen': -0.29793888330459595, 'epoch': 0.97}

 16%|█▌        | 2608/16104 [12:10:02<67:38:06, 18.04s/it]


 16%|█▌        | 2610/16104 [12:10:34<63:15:34, 16.88s/it]

 16%|█▌        | 2611/16104 [12:10:51<63:22:49, 16.91s/it]

 16%|█▌        | 2612/16104 [12:11:09<64:59:55, 17.34s/it]

 16%|█▌        | 2613/16104 [12:11:31<70:13:12, 18.74s/it]
[2024-04-06 03:36:38,259] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.566, 'learning_rate': 1.9097155278363123e-06, 'rewards/chosen': -0.7130207419395447, 'rewards/rejected': -1.0467544794082642, 'rewards/accuracies': 0.75, 'rewards/margins': 0.33373379707336426, 'policy_logps/rejected': -619.6647338867188, 'policy_logps/chosen': -453.7199401855469, 'referece_logps/rejected': -609.1972045898438, 'referece_logps/chosen': -446.5897216796875, 'logits/rejected': 0.1160086989402771, 'logits/chosen': 0.1723533570766449, 'epoch': 0.97}


 16%|█▌        | 2615/16104 [12:12:01<64:00:24, 17.08s/it]

 16%|█▌        | 2616/16104 [12:12:12<56:50:04, 15.17s/it]
{'loss': 0.5945, 'learning_rate': 1.9094648200055984e-06, 'rewards/chosen': -0.9803377389907837, 'rewards/rejected': -1.9772839546203613, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9969460964202881, 'policy_logps/rejected': -263.65447998046875, 'policy_logps/chosen': -485.0403747558594, 'referece_logps/rejected': -243.8816375732422, 'referece_logps/chosen': -475.2370300292969, 'logits/rejected': -1.0803378820419312, 'logits/chosen': -1.2330896854400635, 'epoch': 0.97}


 16%|█▋        | 2618/16104 [12:12:54<68:24:33, 18.26s/it]
[2024-04-06 03:38:01,177] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2619/16104 [12:13:13<69:36:47, 18.58s/it]
[2024-04-06 03:38:20,514] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 16%|█▋        | 2620/16104 [12:13:31<68:51:15, 18.38s/it]
{'loss': 0.4918, 'learning_rate': 1.9091300278611376e-06, 'rewards/chosen': -0.5757634043693542, 'rewards/rejected': -1.0339126586914062, 'rewards/accuracies': 0.75, 'rewards/margins': 0.458149254322052, 'policy_logps/rejected': -320.40203857421875, 'policy_logps/chosen': -475.1337585449219, 'referece_logps/rejected': -310.0628967285156, 'referece_logps/chosen': -469.37615966796875, 'logits/rejected': -0.09673985093832016, 'logits/chosen': -0.18221856653690338, 'epoch': 0.98}
[2024-04-06 03:38:59,567] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▋        | 2622/16104 [12:14:09<69:07:19, 18.46s/it]
{'loss': 0.5669, 'learning_rate': 1.908962411119769e-06, 'rewards/chosen': -0.6637444496154785, 'rewards/rejected': -1.433722972869873, 'rewards/accuracies': 0.75, 'rewards/margins': 0.769978404045105, 'policy_logps/rejected': -209.29115295410156, 'policy_logps/chosen': -266.12750244140625, 'referece_logps/rejected': -194.95391845703125, 'referece_logps/chosen': -259.4900817871094, 'logits/rejected': -0.7967265844345093, 'logits/chosen': -0.859559178352356, 'epoch': 0.98}


 16%|█▋        | 2624/16104 [12:14:45<68:25:54, 18.28s/it]

 16%|█▋        | 2625/16104 [12:15:01<65:50:33, 17.59s/it]

 16%|█▋        | 2626/16104 [12:15:20<66:55:31, 17.88s/it]

 16%|█▋        | 2627/16104 [12:15:36<65:12:42, 17.42s/it]

 16%|█▋        | 2628/16104 [12:15:56<67:58:35, 18.16s/it]

 16%|█▋        | 2629/16104 [12:16:14<68:10:10, 18.21s/it]

 16%|█▋        | 2630/16104 [12:16:28<63:38:10, 17.00s/it]

 16%|█▋        | 2631/16104 [12:16:46<64:06:32, 17.13s/it]

 16%|█▋        | 2632/16104 [12:17:02<62:59:21, 16.83s/it]
{'loss': 0.526, 'learning_rate': 1.9081221218071187e-06, 'rewards/chosen': -0.48826050758361816, 'rewards/rejected': -1.5396208763122559, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0513603687286377, 'policy_logps/rejected': -264.84759521484375, 'policy_logps/chosen': -308.6683654785156, 'referece_logps/rejected': -249.4513702392578, 'referece_logps/chosen': -303.7857666015625, 'logits/rejected': -1.0447466373443604, 'logits/chosen': -1.0209254026412964, 'epoch': 0.98}


 16%|█▋        | 2634/16104 [12:17:44<71:27:40, 19.10s/it]

 16%|█▋        | 2635/16104 [12:18:05<73:23:47, 19.62s/it]

 16%|█▋        | 2636/16104 [12:18:22<70:18:35, 18.79s/it]
{'loss': 0.5136, 'learning_rate': 1.9077849773070615e-06, 'rewards/chosen': -0.9777610301971436, 'rewards/rejected': -1.7651374340057373, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7873762845993042, 'policy_logps/rejected': -334.51165771484375, 'policy_logps/chosen': -310.1919860839844, 'referece_logps/rejected': -316.86029052734375, 'referece_logps/chosen': -300.414306640625, 'logits/rejected': -0.7941917181015015, 'logits/chosen': -0.6964052319526672, 'epoch': 0.98}
[2024-04-06 03:43:51,803] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 16%|█▋        | 2638/16104 [12:19:00<68:54:04, 18.42s/it]

 16%|█▋        | 2639/16104 [12:19:16<66:29:46, 17.78s/it]

 16%|█▋        | 2640/16104 [12:19:34<67:26:44, 18.03s/it]
{'loss': 0.5121, 'learning_rate': 1.9074472452626775e-06, 'rewards/chosen': -0.46977585554122925, 'rewards/rejected': -1.1832047700881958, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7134289145469666, 'policy_logps/rejected': -357.0216979980469, 'policy_logps/chosen': -271.4560241699219, 'referece_logps/rejected': -345.1896667480469, 'referece_logps/chosen': -266.7582702636719, 'logits/rejected': 0.005187422037124634, 'logits/chosen': -0.03439978510141373, 'epoch': 0.98}


 16%|█▋        | 2642/16104 [12:20:10<67:16:44, 17.99s/it]

 16%|█▋        | 2643/16104 [12:20:22<60:49:48, 16.27s/it]
{'loss': 0.6045, 'learning_rate': 1.9071935607849068e-06, 'rewards/chosen': -0.5747799277305603, 'rewards/rejected': -0.8531280755996704, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2783481776714325, 'policy_logps/rejected': -387.0274353027344, 'policy_logps/chosen': -322.1966857910156, 'referece_logps/rejected': -378.49615478515625, 'referece_logps/chosen': -316.44891357421875, 'logits/rejected': 0.08701355755329132, 'logits/chosen': 0.12765038013458252, 'epoch': 0.98}


 16%|█▋        | 2645/16104 [12:21:00<66:10:18, 17.70s/it]

 16%|█▋        | 2646/16104 [12:21:16<64:44:20, 17.32s/it]

 16%|█▋        | 2647/16104 [12:21:36<67:44:08, 18.12s/it]
{'loss': 0.54, 'learning_rate': 1.9068548010641618e-06, 'rewards/chosen': -0.5586422085762024, 'rewards/rejected': -0.9225564002990723, 'rewards/accuracies': 0.75, 'rewards/margins': 0.36391422152519226, 'policy_logps/rejected': -323.3605041503906, 'policy_logps/chosen': -361.415283203125, 'referece_logps/rejected': -314.1349182128906, 'referece_logps/chosen': -355.828857421875, 'logits/rejected': -0.7062941789627075, 'logits/chosen': -0.7922544479370117, 'epoch': 0.99}

 16%|█▋        | 2648/16104 [12:21:47<59:19:17, 15.87s/it]

 16%|█▋        | 2649/16104 [12:22:01<57:21:34, 15.35s/it]


 16%|█▋        | 2651/16104 [12:22:28<53:17:31, 14.26s/it]

 16%|█▋        | 2652/16104 [12:22:44<56:03:52, 15.00s/it]

 16%|█▋        | 2653/16104 [12:23:02<58:37:24, 15.69s/it]

 16%|█▋        | 2654/16104 [12:23:12<53:04:23, 14.21s/it]
{'loss': 0.5159, 'learning_rate': 1.906260559355083e-06, 'rewards/chosen': -0.6440321207046509, 'rewards/rejected': -0.8039447069168091, 'rewards/accuracies': 0.375, 'rewards/margins': 0.1599125862121582, 'policy_logps/rejected': -373.4632568359375, 'policy_logps/chosen': -416.96563720703125, 'referece_logps/rejected': -365.4237976074219, 'referece_logps/chosen': -410.5252685546875, 'logits/rejected': -0.5591915845870972, 'logits/chosen': -0.6168923377990723, 'epoch': 0.99}


 16%|█▋        | 2656/16104 [12:23:50<61:16:36, 16.40s/it]
{'loss': 0.6268, 'learning_rate': 1.9060904460193745e-06, 'rewards/chosen': -0.40391483902931213, 'rewards/rejected': -0.9841257929801941, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5802108645439148, 'policy_logps/rejected': -578.5245971679688, 'policy_logps/chosen': -503.0702209472656, 'referece_logps/rejected': -568.6832885742188, 'referece_logps/chosen': -499.03106689453125, 'logits/rejected': -1.168102502822876, 'logits/chosen': -1.0799236297607422, 'epoch': 0.99}


 17%|█▋        | 2658/16104 [12:24:26<65:37:26, 17.57s/it]
[2024-04-06 03:49:33,510] [WARNING] [stage3.py:2069:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5519, 'learning_rate': 1.905920186071766e-06, 'rewards/chosen': -1.274248719215393, 'rewards/rejected': -2.045682668685913, 'rewards/accuracies': 0.375, 'rewards/margins': 0.7714340090751648, 'policy_logps/rejected': -468.509033203125, 'policy_logps/chosen': -500.09661865234375, 'referece_logps/rejected': -448.05224609375, 'referece_logps/chosen': -487.3541259765625, 'logits/rejected': 0.3140319585800171, 'logits/chosen': 0.3293358087539673, 'epoch': 0.99}

 17%|█▋        | 2659/16104 [12:24:42<63:09:05, 16.91s/it]

 17%|█▋        | 2660/16104 [12:24:56<59:54:46, 16.04s/it]

 17%|█▋        | 2661/16104 [12:25:13<61:01:06, 16.34s/it]
{'loss': 0.5346, 'learning_rate': 1.90566452131331e-06, 'rewards/chosen': -0.5546761751174927, 'rewards/rejected': -0.8475316762924194, 'rewards/accuracies': 0.5, 'rewards/margins': 0.29285550117492676, 'policy_logps/rejected': -355.89898681640625, 'policy_logps/chosen': -344.35736083984375, 'referece_logps/rejected': -347.42364501953125, 'referece_logps/chosen': -338.8106384277344, 'logits/rejected': -0.46407878398895264, 'logits/chosen': -0.4989689886569977, 'epoch': 0.99}


 17%|█▋        | 2663/16104 [12:25:48<65:09:24, 17.45s/it]
[2024-04-06 03:50:55,151] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2664/16104 [12:26:02<61:10:34, 16.39s/it]

 17%|█▋        | 2665/16104 [12:26:16<58:21:55, 15.63s/it]

 17%|█▋        | 2666/16104 [12:26:34<61:44:45, 16.54s/it]

 17%|█▋        | 2667/16104 [12:26:46<56:44:22, 15.20s/it]
{'loss': 0.6346, 'learning_rate': 1.9051522027244809e-06, 'rewards/chosen': -0.45825615525245667, 'rewards/rejected': -0.8515487909317017, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3932926654815674, 'policy_logps/rejected': -398.608154296875, 'policy_logps/chosen': -424.19580078125, 'referece_logps/rejected': -390.0926513671875, 'referece_logps/chosen': -419.61322021484375, 'logits/rejected': 0.5966390371322632, 'logits/chosen': 1.0190136432647705, 'epoch': 0.99}


 17%|█▋        | 2669/16104 [12:27:21<59:08:03, 15.85s/it]

 17%|█▋        | 2670/16104 [12:27:43<65:54:28, 17.66s/it]
[2024-04-06 03:52:49,910] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2671/16104 [12:28:03<68:31:22, 18.36s/it]
[2024-04-06 03:53:09,913] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2672/16104 [12:28:22<69:52:30, 18.73s/it]

 17%|█▋        | 2673/16104 [12:28:36<64:08:54, 17.19s/it]

 17%|█▋        | 2674/16104 [12:28:47<56:56:36, 15.26s/it]

 17%|█▋        | 2675/16104 [12:29:02<57:13:23, 15.34s/it]

 17%|█▋        | 2676/16104 [12:29:19<58:51:03, 15.78s/it]
[2024-04-06 03:54:26,183] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.583, 'learning_rate': 1.904381253561227e-06, 'rewards/chosen': -0.7533429861068726, 'rewards/rejected': -1.4423422813415527, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6889991164207458, 'policy_logps/rejected': -377.1947021484375, 'policy_logps/chosen': -434.8148498535156, 'referece_logps/rejected': -362.77130126953125, 'referece_logps/chosen': -427.2814025878906, 'logits/rejected': -0.3693753778934479, 'logits/chosen': -0.23105162382125854, 'epoch': 1.0}


 17%|█▋        | 2678/16104 [12:29:48<56:14:33, 15.08s/it]

 17%|█▋        | 2679/16104 [12:29:59<51:22:09, 13.78s/it]
{'loss': 0.6544, 'learning_rate': 1.9041236118729218e-06, 'rewards/chosen': -0.7232144474983215, 'rewards/rejected': -0.8551348447799683, 'rewards/accuracies': 0.625, 'rewards/margins': 0.13192033767700195, 'policy_logps/rejected': -395.75250244140625, 'policy_logps/chosen': -375.23504638671875, 'referece_logps/rejected': -387.2011413574219, 'referece_logps/chosen': -368.0029296875, 'logits/rejected': -0.3437606692314148, 'logits/chosen': -0.25830429792404175, 'epoch': 1.0}


 17%|█▋        | 2681/16104 [12:30:25<49:55:34, 13.39s/it]

 17%|█▋        | 2682/16104 [12:30:45<57:17:32, 15.37s/it]

 17%|█▋        | 2683/16104 [12:31:09<66:54:21, 17.95s/it]
[2024-04-06 03:56:16,250] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2684/16104 [12:31:30<70:40:26, 18.96s/it]
{'loss': 0.5593, 'learning_rate': 1.9036934776372039e-06, 'rewards/chosen': -0.8254949450492859, 'rewards/rejected': -1.2881662845611572, 'rewards/accuracies': 0.875, 'rewards/margins': 0.46267127990722656, 'policy_logps/rejected': -432.2886657714844, 'policy_logps/chosen': -436.1438293457031, 'referece_logps/rejected': -419.406982421875, 'referece_logps/chosen': -427.888916015625, 'logits/rejected': 0.7338880300521851, 'logits/chosen': 0.6437697410583496, 'epoch': 1.0}


 17%|█▋        | 2686/16104 [12:32:05<68:52:05, 18.48s/it]
[2024-04-06 03:57:12,134] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.6774, 'learning_rate': 1.90352116802645e-06, 'rewards/chosen': -0.48048022389411926, 'rewards/rejected': -0.7666975259780884, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2862173318862915, 'policy_logps/rejected': -416.5122985839844, 'policy_logps/chosen': -474.97894287109375, 'referece_logps/rejected': -408.8453063964844, 'referece_logps/chosen': -470.17413330078125, 'logits/rejected': 0.4553769528865814, 'logits/chosen': 0.47976839542388916, 'epoch': 1.0}

 17%|█▋        | 2687/16104 [12:32:16<60:12:05, 16.15s/it]


 17%|█▋        | 2689/16104 [12:32:55<66:45:34, 17.92s/it]

 17%|█▋        | 2690/16104 [12:33:15<69:00:20, 18.52s/it]
{'loss': 0.6621, 'learning_rate': 1.9031761102443288e-06, 'rewards/chosen': -1.2494258880615234, 'rewards/rejected': -1.6885823011398315, 'rewards/accuracies': 0.5, 'rewards/margins': 0.43915659189224243, 'policy_logps/rejected': -367.56683349609375, 'policy_logps/chosen': -357.0600280761719, 'referece_logps/rejected': -350.6809997558594, 'referece_logps/chosen': -344.5657958984375, 'logits/rejected': -0.5693142414093018, 'logits/chosen': -0.46984297037124634, 'epoch': 1.0}

 17%|█▋        | 2691/16104 [12:33:26<60:12:39, 16.16s/it]


 17%|█▋        | 2693/16104 [12:33:56<57:08:37, 15.34s/it]
{'loss': 0.6871, 'learning_rate': 1.902916933277133e-06, 'rewards/chosen': -0.36434298753738403, 'rewards/rejected': -0.9603633284568787, 'rewards/accuracies': 1.0, 'rewards/margins': 0.5960203409194946, 'policy_logps/rejected': -447.48333740234375, 'policy_logps/chosen': -433.55767822265625, 'referece_logps/rejected': -437.87969970703125, 'referece_logps/chosen': -429.9142761230469, 'logits/rejected': -0.39323312044143677, 'logits/chosen': -0.37021809816360474, 'epoch': 1.0}


 17%|█▋        | 2695/16104 [12:34:23<53:33:19, 14.38s/it]
{'loss': 0.7016, 'learning_rate': 1.9027439660035057e-06, 'rewards/chosen': -0.5464287400245667, 'rewards/rejected': -0.5672388076782227, 'rewards/accuracies': 0.5, 'rewards/margins': 0.02081010490655899, 'policy_logps/rejected': -343.97607421875, 'policy_logps/chosen': -375.32598876953125, 'referece_logps/rejected': -338.3036804199219, 'referece_logps/chosen': -369.8617248535156, 'logits/rejected': 0.09707711637020111, 'logits/chosen': -0.019424617290496826, 'epoch': 1.0}


 17%|█▋        | 2697/16104 [12:34:49<50:56:43, 13.68s/it]

 17%|█▋        | 2698/16104 [12:35:05<53:54:51, 14.48s/it]

 17%|█▋        | 2699/16104 [12:35:21<56:15:22, 15.11s/it]
{'loss': 0.6268, 'learning_rate': 1.9023975932730134e-06, 'rewards/chosen': -0.6353161931037903, 'rewards/rejected': -1.3493404388427734, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7140241861343384, 'policy_logps/rejected': -362.5257263183594, 'policy_logps/chosen': -410.3143310546875, 'referece_logps/rejected': -349.0323181152344, 'referece_logps/chosen': -403.9611511230469, 'logits/rejected': -1.00419020652771, 'logits/chosen': -0.9443798065185547, 'epoch': 1.01}


 17%|█▋        | 2701/16104 [12:35:44<49:06:32, 13.19s/it]

 17%|█▋        | 2702/16104 [12:35:55<46:31:06, 12.50s/it]
{'loss': 0.6679, 'learning_rate': 1.9021374304251631e-06, 'rewards/chosen': -0.5225265622138977, 'rewards/rejected': -0.8218880295753479, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2993614375591278, 'policy_logps/rejected': -431.7532958984375, 'policy_logps/chosen': -443.25750732421875, 'referece_logps/rejected': -423.534423828125, 'referece_logps/chosen': -438.0322570800781, 'logits/rejected': 0.027520421892404556, 'logits/chosen': 0.07080540060997009, 'epoch': 1.01}


 17%|█▋        | 2704/16104 [12:36:17<43:04:09, 11.57s/it]
{'loss': 0.5889, 'learning_rate': 1.9019638060554052e-06, 'rewards/chosen': -0.5368356704711914, 'rewards/rejected': -0.8082216382026672, 'rewards/accuracies': 0.75, 'rewards/margins': 0.27138596773147583, 'policy_logps/rejected': -426.45013427734375, 'policy_logps/chosen': -402.8924560546875, 'referece_logps/rejected': -418.367919921875, 'referece_logps/chosen': -397.52410888671875, 'logits/rejected': 0.06717079132795334, 'logits/chosen': 0.15112507343292236, 'epoch': 1.01}

 17%|█▋        | 2705/16104 [12:36:38<53:43:20, 14.43s/it]


 17%|█▋        | 2707/16104 [12:37:09<55:36:34, 14.94s/it]

 17%|█▋        | 2708/16104 [12:37:25<56:24:00, 15.16s/it]
{'loss': 0.5367, 'learning_rate': 1.9016161195114648e-06, 'rewards/chosen': -0.5570009350776672, 'rewards/rejected': -1.1713184118270874, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6143174767494202, 'policy_logps/rejected': -220.87228393554688, 'policy_logps/chosen': -402.016845703125, 'referece_logps/rejected': -209.1591033935547, 'referece_logps/chosen': -396.4468688964844, 'logits/rejected': -0.41519421339035034, 'logits/chosen': -0.47016245126724243, 'epoch': 1.01}

 17%|█▋        | 2709/16104 [12:37:46<63:21:14, 17.03s/it]


 17%|█▋        | 2711/16104 [12:38:11<54:04:15, 14.53s/it]
{'loss': 0.5573, 'learning_rate': 1.9013549716354083e-06, 'rewards/chosen': -0.7527706623077393, 'rewards/rejected': -1.3999370336532593, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6471664309501648, 'policy_logps/rejected': -202.33383178710938, 'policy_logps/chosen': -362.3529052734375, 'referece_logps/rejected': -188.33445739746094, 'referece_logps/chosen': -354.8251647949219, 'logits/rejected': -0.6417157649993896, 'logits/chosen': -0.46956920623779297, 'epoch': 1.01}


 17%|█▋        | 2713/16104 [12:38:33<47:08:10, 12.67s/it]

 17%|█▋        | 2714/16104 [12:38:53<56:00:42, 15.06s/it]
[2024-04-06 04:04:00,416] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5416, 'learning_rate': 1.901093495606607e-06, 'rewards/chosen': -0.36563044786453247, 'rewards/rejected': -1.9082355499267578, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5426051616668701, 'policy_logps/rejected': -488.9920654296875, 'policy_logps/chosen': -420.0159606933594, 'referece_logps/rejected': -469.9096984863281, 'referece_logps/chosen': -416.359619140625, 'logits/rejected': -0.4049791395664215, 'logits/chosen': -0.5414927005767822, 'epoch': 1.01}


 17%|█▋        | 2716/16104 [12:39:29<62:42:06, 16.86s/it]
{'loss': 0.5543, 'learning_rate': 1.900918995993997e-06, 'rewards/chosen': -1.5436687469482422, 'rewards/rejected': -2.2761037349700928, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7324350476264954, 'policy_logps/rejected': -453.0522766113281, 'policy_logps/chosen': -427.08734130859375, 'referece_logps/rejected': -430.291259765625, 'referece_logps/chosen': -411.65069580078125, 'logits/rejected': -0.37755677103996277, 'logits/chosen': -0.3214065730571747, 'epoch': 1.01}

 17%|█▋        | 2717/16104 [12:39:47<63:25:02, 17.05s/it]


 17%|█▋        | 2719/16104 [12:40:25<68:07:16, 18.32s/it]
[2024-04-06 04:05:32,595] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.5322, 'learning_rate': 1.900656973255557e-06, 'rewards/chosen': -1.0040329694747925, 'rewards/rejected': -1.2642077207565308, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2601747512817383, 'policy_logps/rejected': -439.4394226074219, 'policy_logps/chosen': -515.56103515625, 'referece_logps/rejected': -426.79736328125, 'referece_logps/chosen': -505.520751953125, 'logits/rejected': -0.7680903673171997, 'logits/chosen': -0.6621732711791992, 'epoch': 1.01}

 17%|█▋        | 2720/16104 [12:40:42<66:11:31, 17.80s/it]

 17%|█▋        | 2721/16104 [12:41:01<67:38:19, 18.19s/it]

 17%|█▋        | 2722/16104 [12:41:15<62:25:49, 16.79s/it]


 17%|█▋        | 2724/16104 [12:41:50<65:01:41, 17.50s/it]
{'loss': 0.5894, 'learning_rate': 1.900219540075036e-06, 'rewards/chosen': -0.44711190462112427, 'rewards/rejected': -1.1742514371871948, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7271396517753601, 'policy_logps/rejected': -275.31451416015625, 'policy_logps/chosen': -416.1529541015625, 'referece_logps/rejected': -263.572021484375, 'referece_logps/chosen': -411.68182373046875, 'logits/rejected': -0.7778432369232178, 'logits/chosen': -0.7047138810157776, 'epoch': 1.01}

 17%|█▋        | 2725/16104 [12:42:04<61:52:48, 16.65s/it]
[2024-04-06 04:07:27,969] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2726/16104 [12:42:21<61:37:08, 16.58s/it]


 17%|█▋        | 2728/16104 [12:43:04<70:29:36, 18.97s/it]
{'loss': 0.6432, 'learning_rate': 1.8998689380306448e-06, 'rewards/chosen': -0.5356096625328064, 'rewards/rejected': -0.8382713198661804, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3026617169380188, 'policy_logps/rejected': -518.0668334960938, 'policy_logps/chosen': -497.76385498046875, 'referece_logps/rejected': -509.68414306640625, 'referece_logps/chosen': -492.40771484375, 'logits/rejected': -0.4957379400730133, 'logits/chosen': -0.5728228688240051, 'epoch': 1.02}

 17%|█▋        | 2729/16104 [12:43:23<70:14:37, 18.91s/it]

 17%|█▋        | 2730/16104 [12:43:38<66:26:09, 17.88s/it]


 17%|█▋        | 2732/16104 [12:44:04<56:59:28, 15.34s/it]

 17%|█▋        | 2733/16104 [12:44:16<52:50:16, 14.23s/it]
{'loss': 0.5301, 'learning_rate': 1.8994298664724768e-06, 'rewards/chosen': -0.7624510526657104, 'rewards/rejected': -0.9639952182769775, 'rewards/accuracies': 0.625, 'rewards/margins': 0.20154422521591187, 'policy_logps/rejected': -246.37832641601562, 'policy_logps/chosen': -317.75299072265625, 'referece_logps/rejected': -236.73837280273438, 'referece_logps/chosen': -310.1285095214844, 'logits/rejected': -0.9753248691558838, 'logits/chosen': -1.0003894567489624, 'epoch': 1.02}

 17%|█▋        | 2734/16104 [12:44:35<58:55:54, 15.87s/it]

 17%|█▋        | 2735/16104 [12:44:50<57:49:39, 15.57s/it]

 17%|█▋        | 2736/16104 [12:45:11<63:35:59, 17.13s/it]

 17%|█▋        | 2737/16104 [12:45:31<66:43:00, 17.97s/it]


 17%|█▋        | 2739/16104 [12:46:08<68:17:28, 18.39s/it]
[2024-04-06 04:11:15,021] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2740/16104 [12:46:20<61:14:34, 16.50s/it]
{'loss': 0.4352, 'learning_rate': 1.8988136382819926e-06, 'rewards/chosen': -0.708850622177124, 'rewards/rejected': -1.375118374824524, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6662676334381104, 'policy_logps/rejected': -437.5977478027344, 'policy_logps/chosen': -322.2308349609375, 'referece_logps/rejected': -423.8465270996094, 'referece_logps/chosen': -315.1423034667969, 'logits/rejected': -0.301848828792572, 'logits/chosen': -0.22241491079330444, 'epoch': 1.02}

 17%|█▋        | 2741/16104 [12:46:41<66:47:23, 17.99s/it]

 17%|█▋        | 2742/16104 [12:47:03<70:37:33, 19.03s/it]

 17%|█▋        | 2743/16104 [12:47:21<69:50:41, 18.82s/it]


 17%|█▋        | 2745/16104 [12:47:54<65:11:52, 17.57s/it]
{'loss': 0.5788, 'learning_rate': 1.898372384459137e-06, 'rewards/chosen': -0.7631818652153015, 'rewards/rejected': -1.6269546747207642, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8637726902961731, 'policy_logps/rejected': -532.7952270507812, 'policy_logps/chosen': -321.2086181640625, 'referece_logps/rejected': -516.5256958007812, 'referece_logps/chosen': -313.5768127441406, 'logits/rejected': -0.9668795466423035, 'logits/chosen': -0.8209730386734009, 'epoch': 1.02}
[2024-04-06 04:13:22,907] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2746/16104 [12:48:16<69:39:17, 18.77s/it]

 17%|█▋        | 2747/16104 [12:48:27<61:03:11, 16.46s/it]
[2024-04-06 04:13:45,774] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2749/16104 [12:48:58<61:06:42, 16.47s/it]
{'loss': 0.5757, 'learning_rate': 1.8980187272456653e-06, 'rewards/chosen': -0.8011572360992432, 'rewards/rejected': -1.0448551177978516, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24369795620441437, 'policy_logps/rejected': -377.5294189453125, 'policy_logps/chosen': -353.422607421875, 'referece_logps/rejected': -367.08087158203125, 'referece_logps/chosen': -345.4110107421875, 'logits/rejected': -0.7288115620613098, 'logits/chosen': -0.4994966983795166, 'epoch': 1.02}

 17%|█▋        | 2750/16104 [12:49:18<64:57:26, 17.51s/it]

 17%|█▋        | 2751/16104 [12:49:32<60:20:29, 16.27s/it]

 17%|█▋        | 2752/16104 [12:49:48<60:07:35, 16.21s/it]
[2024-04-06 04:15:12,425] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2753/16104 [12:50:05<61:33:56, 16.60s/it]

 17%|█▋        | 2754/16104 [12:50:23<62:41:36, 16.91s/it]


 17%|█▋        | 2756/16104 [12:51:07<72:00:34, 19.42s/it]
{'loss': 0.4404, 'learning_rate': 1.8973984286913583e-06, 'rewards/chosen': -0.951316773891449, 'rewards/rejected': -1.2427979707717896, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2914811670780182, 'policy_logps/rejected': -224.80136108398438, 'policy_logps/chosen': -239.5917510986328, 'referece_logps/rejected': -212.37338256835938, 'referece_logps/chosen': -230.07859802246094, 'logits/rejected': 0.19815675914287567, 'logits/chosen': 0.19375115633010864, 'epoch': 1.03}

 17%|█▋        | 2757/16104 [12:51:23<68:40:21, 18.52s/it]


 17%|█▋        | 2759/16104 [12:51:50<60:17:23, 16.26s/it]
{'loss': 0.5147, 'learning_rate': 1.897132041861552e-06, 'rewards/chosen': -0.5720552206039429, 'rewards/rejected': -1.1652700901031494, 'rewards/accuracies': 0.625, 'rewards/margins': 0.593214750289917, 'policy_logps/rejected': -346.9230651855469, 'policy_logps/chosen': -482.3502502441406, 'referece_logps/rejected': -335.2703857421875, 'referece_logps/chosen': -476.62969970703125, 'logits/rejected': -0.6946264505386353, 'logits/chosen': -0.7533693313598633, 'epoch': 1.03}
[2024-04-06 04:17:20,868] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2761/16104 [12:52:24<59:32:57, 16.07s/it]
{'loss': 0.606, 'learning_rate': 1.8969542691827343e-06, 'rewards/chosen': -0.8945869207382202, 'rewards/rejected': -0.9813951849937439, 'rewards/accuracies': 0.375, 'rewards/margins': 0.08680817484855652, 'policy_logps/rejected': -284.51788330078125, 'policy_logps/chosen': -286.3603210449219, 'referece_logps/rejected': -274.7039794921875, 'referece_logps/chosen': -277.4144287109375, 'logits/rejected': -0.1431260108947754, 'logits/chosen': -0.021555691957473755, 'epoch': 1.03}

 17%|█▋        | 2762/16104 [12:52:43<62:34:17, 16.88s/it]

 17%|█▋        | 2763/16104 [12:52:57<59:04:34, 15.94s/it]

 17%|█▋        | 2764/16104 [12:53:13<58:53:22, 15.89s/it]


 17%|█▋        | 2766/16104 [12:53:51<63:45:22, 17.21s/it]
{'loss': 0.5366, 'learning_rate': 1.8965092025891636e-06, 'rewards/chosen': -0.8116743564605713, 'rewards/rejected': -1.5012855529785156, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6896111965179443, 'policy_logps/rejected': -247.66586303710938, 'policy_logps/chosen': -254.41250610351562, 'referece_logps/rejected': -232.6529998779297, 'referece_logps/chosen': -246.2957763671875, 'logits/rejected': -0.48956578969955444, 'logits/chosen': -0.39755135774612427, 'epoch': 1.03}

 17%|█▋        | 2767/16104 [12:54:04<59:29:19, 16.06s/it]

 17%|█▋        | 2768/16104 [12:54:28<68:29:35, 18.49s/it]

 17%|█▋        | 2769/16104 [12:54:50<72:11:11, 19.49s/it]


 17%|█▋        | 2771/16104 [12:55:28<71:02:22, 19.18s/it]
{'loss': 0.5326, 'learning_rate': 1.89606322936074e-06, 'rewards/chosen': -0.9832674264907837, 'rewards/rejected': -1.1727628707885742, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1894954890012741, 'policy_logps/rejected': -342.73016357421875, 'policy_logps/chosen': -336.4800109863281, 'referece_logps/rejected': -331.0025329589844, 'referece_logps/chosen': -326.6473388671875, 'logits/rejected': -0.5895705819129944, 'logits/chosen': -0.4748227298259735, 'epoch': 1.03}

 17%|█▋        | 2772/16104 [12:55:44<66:45:21, 18.03s/it]


 17%|█▋        | 2774/16104 [12:56:21<68:51:53, 18.60s/it]
{'loss': 0.5055, 'learning_rate': 1.8957952104265384e-06, 'rewards/chosen': -0.7125982046127319, 'rewards/rejected': -1.2013013362884521, 'rewards/accuracies': 1.0, 'rewards/margins': 0.4887031316757202, 'policy_logps/rejected': -329.2789306640625, 'policy_logps/chosen': -328.1700439453125, 'referece_logps/rejected': -317.2658996582031, 'referece_logps/chosen': -321.0440673828125, 'logits/rejected': -0.7088996767997742, 'logits/chosen': -0.9168785810470581, 'epoch': 1.03}


 17%|█▋        | 2776/16104 [12:56:55<67:21:18, 18.19s/it]

 17%|█▋        | 2777/16104 [12:57:14<68:54:51, 18.62s/it]
{'loss': 0.5202, 'learning_rate': 1.8955268653637124e-06, 'rewards/chosen': -0.9616115689277649, 'rewards/rejected': -1.4956647157669067, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5340532660484314, 'policy_logps/rejected': -454.4552917480469, 'policy_logps/chosen': -453.70654296875, 'referece_logps/rejected': -439.49859619140625, 'referece_logps/chosen': -444.0904541015625, 'logits/rejected': -0.7202969789505005, 'logits/chosen': -0.662778377532959, 'epoch': 1.03}

 17%|█▋        | 2778/16104 [12:57:36<72:14:02, 19.51s/it]
[2024-04-06 04:22:54,169] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2780/16104 [12:57:59<56:56:49, 15.39s/it]
{'loss': 0.5946, 'learning_rate': 1.8952581942699575e-06, 'rewards/chosen': -1.1718883514404297, 'rewards/rejected': -0.9259148240089417, 'rewards/accuracies': 0.5, 'rewards/margins': -0.24597357213497162, 'policy_logps/rejected': -318.61944580078125, 'policy_logps/chosen': -280.8454284667969, 'referece_logps/rejected': -309.36029052734375, 'referece_logps/chosen': -269.1265563964844, 'logits/rejected': -0.8006393313407898, 'logits/chosen': -0.6285509467124939, 'epoch': 1.04}


 17%|█▋        | 2782/16104 [12:58:35<61:57:40, 16.74s/it]
{'loss': 0.5248, 'learning_rate': 1.8950788991274584e-06, 'rewards/chosen': -0.9876658916473389, 'rewards/rejected': -1.4548667669296265, 'rewards/accuracies': 0.875, 'rewards/margins': 0.46720096468925476, 'policy_logps/rejected': -337.3084411621094, 'policy_logps/chosen': -329.0241394042969, 'referece_logps/rejected': -322.759765625, 'referece_logps/chosen': -319.1474609375, 'logits/rejected': -0.8715662956237793, 'logits/chosen': -0.7221747636795044, 'epoch': 1.04}


 17%|█▋        | 2784/16104 [12:59:02<57:07:25, 15.44s/it]
{'loss': 0.5603, 'learning_rate': 1.894899459154806e-06, 'rewards/chosen': -0.6298211812973022, 'rewards/rejected': -1.2870551347732544, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6572338342666626, 'policy_logps/rejected': -393.2720031738281, 'policy_logps/chosen': -370.01910400390625, 'referece_logps/rejected': -380.4014587402344, 'referece_logps/chosen': -363.7209167480469, 'logits/rejected': -0.5161679983139038, 'logits/chosen': -0.3081546127796173, 'epoch': 1.04}


 17%|█▋        | 2786/16104 [12:59:34<57:14:10, 15.47s/it]
{'loss': 0.5518, 'learning_rate': 1.894719874381035e-06, 'rewards/chosen': -0.6960270404815674, 'rewards/rejected': -1.2274694442749023, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5314423441886902, 'policy_logps/rejected': -249.70169067382812, 'policy_logps/chosen': -256.850341796875, 'referece_logps/rejected': -237.427001953125, 'referece_logps/chosen': -249.89007568359375, 'logits/rejected': -1.158290982246399, 'logits/chosen': -1.2639063596725464, 'epoch': 1.04}

 17%|█▋        | 2787/16104 [12:59:45<52:09:55, 14.10s/it]

 17%|█▋        | 2788/16104 [12:59:57<49:33:22, 13.40s/it]

 17%|█▋        | 2789/16104 [13:00:08<47:17:40, 12.79s/it]


 17%|█▋        | 2791/16104 [13:00:41<53:40:53, 14.52s/it]
{'loss': 0.5862, 'learning_rate': 1.8942702791324638e-06, 'rewards/chosen': -0.5568912625312805, 'rewards/rejected': -1.175392508506775, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6185013055801392, 'policy_logps/rejected': -334.083251953125, 'policy_logps/chosen': -407.0331115722656, 'referece_logps/rejected': -322.3293151855469, 'referece_logps/chosen': -401.4642028808594, 'logits/rejected': -0.5549322962760925, 'logits/chosen': -0.507526695728302, 'epoch': 1.04}

 17%|█▋        | 2792/16104 [13:00:58<56:13:50, 15.21s/it]
[2024-04-06 04:26:25,757] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2793/16104 [13:01:19<62:24:07, 16.88s/it]

 17%|█▋        | 2794/16104 [13:01:36<63:12:43, 17.10s/it]
[2024-04-06 04:26:59,623] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2796/16104 [13:02:13<66:32:42, 18.00s/it]

 17%|█▋        | 2797/16104 [13:02:31<66:19:54, 17.95s/it]
{'loss': 0.5067, 'learning_rate': 1.8937295711050062e-06, 'rewards/chosen': -0.7610906362533569, 'rewards/rejected': -1.4091399908065796, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6480492353439331, 'policy_logps/rejected': -520.08544921875, 'policy_logps/chosen': -451.1767578125, 'referece_logps/rejected': -505.9940490722656, 'referece_logps/chosen': -443.56585693359375, 'logits/rejected': -1.1560759544372559, 'logits/chosen': -1.2451951503753662, 'epoch': 1.04}
[2024-04-06 04:27:59,639] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


 17%|█▋        | 2799/16104 [13:03:13<71:54:53, 19.46s/it]
[2024-04-06 04:28:20,138] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time

 17%|█▋        | 2800/16104 [13:03:35<74:36:55, 20.19s/it]

 17%|█▋        | 2801/16104 [13:03:51<70:00:41, 18.95s/it]
{'loss': 0.4971, 'learning_rate': 1.8933683759789832e-06, 'rewards/chosen': -0.7205140590667725, 'rewards/rejected': -1.2369115352630615, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5163974165916443, 'policy_logps/rejected': -283.0622863769531, 'policy_logps/chosen': -260.4695129394531, 'referece_logps/rejected': -270.6931457519531, 'referece_logps/chosen': -253.26437377929688, 'logits/rejected': 0.1105002611875534, 'logits/chosen': 0.1790311336517334, 'epoch': 1.04}

 17%|█▋        | 2802/16104 [13:04:04<63:37:46, 17.22s/it]


 17%|█▋        | 2804/16104 [13:04:37<62:48:33, 17.00s/it]
{'loss': 0.5032, 'learning_rate': 1.8930971001690631e-06, 'rewards/chosen': -0.6999905109405518, 'rewards/rejected': -1.2123985290527344, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5124079585075378, 'policy_logps/rejected': -234.0453338623047, 'policy_logps/chosen': -300.0406494140625, 'referece_logps/rejected': -221.92137145996094, 'referece_logps/chosen': -293.04071044921875, 'logits/rejected': -0.8755845427513123, 'logits/chosen': -0.7627819776535034, 'epoch': 1.04}


 17%|█▋        | 2806/16104 [13:05:05<57:49:15, 15.65s/it]

 17%|█▋        | 2807/16104 [13:05:25<62:48:48, 17.01s/it]

 17%|█▋        | 2808/16104 [13:05:47<68:01:01, 18.42s/it]
{'loss': 0.4119, 'learning_rate': 1.8927348933230712e-06, 'rewards/chosen': -0.9695891737937927, 'rewards/rejected': -2.064069986343384, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0944808721542358, 'policy_logps/rejected': -266.6778564453125, 'policy_logps/chosen': -219.31503295898438, 'referece_logps/rejected': -246.03717041015625, 'referece_logps/chosen': -209.61912536621094, 'logits/rejected': -0.3147255778312683, 'logits/chosen': -0.21237924695014954, 'epoch': 1.05}

 17%|█▋        | 2809/16104 [13:06:06<68:32:39, 18.56s/it]

 17%|█▋        | 2810/16104 [13:06:18<61:20:28, 16.61s/it]


 17%|█▋        | 2812/16104 [13:06:55<66:47:28, 18.09s/it]
{'loss': 0.4849, 'learning_rate': 1.8923721086735959e-06, 'rewards/chosen': -0.7509827017784119, 'rewards/rejected': -1.8220312595367432, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0710484981536865, 'policy_logps/rejected': -406.82293701171875, 'policy_logps/chosen': -383.0500183105469, 'referece_logps/rejected': -388.6026306152344, 'referece_logps/chosen': -375.54022216796875, 'logits/rejected': -1.2225022315979004, 'logits/chosen': -1.181465744972229, 'epoch': 1.05}


 17%|█▋        | 2814/16104 [13:07:27<62:16:03, 16.87s/it]

 17%|█▋        | 2815/16104 [13:07:47<65:39:40, 17.79s/it]
{'loss': 0.6849, 'learning_rate': 1.8920996411441895e-06, 'rewards/chosen': -0.7010228633880615, 'rewards/rejected': -1.08568274974823, 'rewards/accuracies': 0.5, 'rewards/margins': 0.38465988636016846, 'policy_logps/rejected': -391.9788513183594, 'policy_logps/chosen': -414.8195495605469, 'referece_logps/rejected': -381.1220397949219, 'referece_logps/chosen': -407.809326171875, 'logits/rejected': -0.7006978392601013, 'logits/chosen': -0.7999149560928345, 'epoch': 1.05}


 17%|█▋        | 2817/16104 [13:08:26<68:11:13, 18.47s/it]
{'loss': 0.5601, 'learning_rate': 1.8919178156833497e-06, 'rewards/chosen': -0.4583318531513214, 'rewards/rejected': -1.633959412574768, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1756274700164795, 'policy_logps/rejected': -335.1265869140625, 'policy_logps/chosen': -280.111572265625, 'referece_logps/rejected': -318.7869873046875, 'referece_logps/chosen': -275.52825927734375, 'logits/rejected': -0.2483675181865692, 'logits/chosen': -0.3111785650253296, 'epoch': 1.05}


 18%|█▊        | 2819/16104 [13:08:57<63:20:53, 17.17s/it]
{'loss': 0.5735, 'learning_rate': 1.8917358459038425e-06, 'rewards/chosen': -1.0230088233947754, 'rewards/rejected': -1.5605943202972412, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5375853776931763, 'policy_logps/rejected': -272.2662353515625, 'policy_logps/chosen': -273.49420166015625, 'referece_logps/rejected': -256.6602783203125, 'referece_logps/chosen': -263.26409912109375, 'logits/rejected': -0.7341604828834534, 'logits/chosen': -0.7045043110847473, 'epoch': 1.05}

 18%|█▊        | 2820/16104 [13:09:12<60:36:46, 16.43s/it]

 18%|█▊        | 2821/16104 [13:09:24<55:57:36, 15.17s/it]

 18%|█▊        | 2822/16104 [13:09:47<64:16:58, 17.42s/it]

 18%|█▊        | 2823/16104 [13:10:00<59:40:56, 16.18s/it]

 18%|█▊        | 2824/16104 [13:10:18<61:41:29, 16.72s/it]

 18%|█▊        | 2825/16104 [13:10:33<60:02:51, 16.28s/it]

 18%|█▊        | 2826/16104 [13:10:53<63:56:47, 17.34s/it]

 18%|█▊        | 2827/16104 [13:11:13<66:17:27, 17.97s/it]

 18%|█▊        | 2828/16104 [13:11:30<65:43:28, 17.82s/it]

 18%|█▊        | 2829/16104 [13:11:53<71:26:05, 19.37s/it]

 18%|█▊        | 2830/16104 [13:12:10<68:51:50, 18.68s/it]

 18%|█▊        | 2831/16104 [13:12:28<68:26:06, 18.56s/it]

 18%|█▊        | 2832/16104 [13:12:45<66:21:24, 18.00s/it]

 18%|█▊        | 2833/16104 [13:13:04<67:52:52, 18.41s/it]

 18%|█▊        | 2834/16104 [13:13:24<69:23:15, 18.82s/it]

 18%|█▊        | 2835/16104 [13:13:36<61:34:59, 16.71s/it]

 18%|█▊        | 2836/16104 [13:13:50<58:52:12, 15.97s/it]

 18%|█▊        | 2837/16104 [13:14:02<53:50:52, 14.61s/it]

 18%|█▊        | 2838/16104 [13:14:13<50:00:09, 13.57s/it]

 18%|█▊        | 2839/16104 [13:14:32<56:29:28, 15.33s/it]

 18%|█▊        | 2840/16104 [13:14:47<55:55:04, 15.18s/it]

 18%|█▊        | 2841/16104 [13:15:04<57:41:35, 15.66s/it]

 18%|█▊        | 2842/16104 [13:15:16<54:10:59, 14.71s/it]

 18%|█▊        | 2843/16104 [13:15:37<60:40:31, 16.47s/it]

 18%|█▊        | 2844/16104 [13:15:48<55:07:59, 14.97s/it]

 18%|█▊        | 2845/16104 [13:16:05<56:55:16, 15.45s/it]

 18%|█▊        | 2846/16104 [13:16:25<61:52:07, 16.80s/it]

 18%|█▊        | 2847/16104 [13:16:39<58:25:20, 15.86s/it]

 18%|█▊        | 2848/16104 [13:16:57<60:57:09, 16.55s/it]

 18%|█▊        | 2849/16104 [13:17:18<65:46:12, 17.86s/it]

 18%|█▊        | 2850/16104 [13:17:28<57:59:15, 15.75s/it]

 18%|█▊        | 2851/16104 [13:17:39<52:33:40, 14.28s/it]

 18%|█▊        | 2852/16104 [13:17:52<50:30:01, 13.72s/it]

 18%|█▊        | 2853/16104 [13:18:13<58:52:09, 15.99s/it]

 18%|█▊        | 2854/16104 [13:18:33<63:31:25, 17.26s/it]


 18%|█▊        | 2856/16104 [13:19:02<59:10:20, 16.08s/it]
{'loss': 0.5361, 'learning_rate': 1.8883434099206848e-06, 'rewards/chosen': -0.985058605670929, 'rewards/rejected': -1.9201874732971191, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9351288080215454, 'policy_logps/rejected': -387.6833190917969, 'policy_logps/chosen': -486.3956298828125, 'referece_logps/rejected': -368.4814758300781, 'referece_logps/chosen': -476.5450439453125, 'logits/rejected': -0.22175781428813934, 'logits/chosen': -0.09108327329158783, 'epoch': 1.06}

 18%|█▊        | 2857/16104 [13:19:22<63:05:01, 17.14s/it]

 18%|█▊        | 2858/16104 [13:19:42<66:39:42, 18.12s/it]

 18%|█▊        | 2859/16104 [13:19:59<64:52:57, 17.64s/it]

 18%|█▊        | 2860/16104 [13:20:15<63:30:10, 17.26s/it]

 18%|█▊        | 2861/16104 [13:20:31<62:11:11, 16.90s/it]

 18%|█▊        | 2862/16104 [13:20:50<64:43:11, 17.59s/it]

 18%|█▊        | 2863/16104 [13:21:08<64:45:18, 17.61s/it]

 18%|█▊        | 2864/16104 [13:21:26<64:49:40, 17.63s/it]


 18%|█▊        | 2866/16104 [13:21:49<53:28:57, 14.54s/it]

 18%|█▊        | 2867/16104 [13:21:59<49:13:05, 13.39s/it]

 18%|█▊        | 2868/16104 [13:22:10<46:22:13, 12.61s/it]

 18%|█▊        | 2869/16104 [13:22:26<49:25:02, 13.44s/it]

 18%|█▊        | 2870/16104 [13:22:45<55:45:03, 15.17s/it]

 18%|█▊        | 2871/16104 [13:22:56<51:25:02, 13.99s/it]

 18%|█▊        | 2872/16104 [13:23:12<53:05:22, 14.44s/it]

 18%|█▊        | 2873/16104 [13:23:27<54:12:08, 14.75s/it]

 18%|█▊        | 2874/16104 [13:23:47<59:49:34, 16.28s/it]

 18%|█▊        | 2875/16104 [13:24:08<65:18:23, 17.77s/it]

 18%|█▊        | 2876/16104 [13:24:19<57:20:43, 15.61s/it]

 18%|█▊        | 2877/16104 [13:24:31<53:30:39, 14.56s/it]

 18%|█▊        | 2878/16104 [13:24:44<51:39:56, 14.06s/it]

 18%|█▊        | 2879/16104 [13:25:00<53:53:37, 14.67s/it]

 18%|█▊        | 2880/16104 [13:25:20<60:00:09, 16.33s/it]

 18%|█▊        | 2881/16104 [13:25:39<63:25:44, 17.27s/it]

 18%|█▊        | 2882/16104 [13:25:53<58:52:55, 16.03s/it]

 18%|█▊        | 2883/16104 [13:26:10<60:08:45, 16.38s/it]

 18%|█▊        | 2884/16104 [13:26:20<53:46:08, 14.64s/it]

 18%|█▊        | 2885/16104 [13:26:38<57:00:22, 15.52s/it]

 18%|█▊        | 2886/16104 [13:26:59<63:10:58, 17.21s/it]

 18%|█▊        | 2887/16104 [13:27:20<67:11:39, 18.30s/it]

 18%|█▊        | 2888/16104 [13:27:31<58:55:41, 16.05s/it]

 18%|█▊        | 2889/16104 [13:27:51<63:12:58, 17.22s/it]

 18%|█▊        | 2890/16104 [13:28:08<63:48:32, 17.38s/it]

 18%|█▊        | 2891/16104 [13:28:29<67:19:54, 18.35s/it]

 18%|█▊        | 2892/16104 [13:28:40<59:34:38, 16.23s/it]

 18%|█▊        | 2893/16104 [13:29:02<65:10:26, 17.76s/it]

 18%|█▊        | 2894/16104 [13:29:17<62:51:54, 17.13s/it]

 18%|█▊        | 2895/16104 [13:29:37<65:23:41, 17.82s/it]

 18%|█▊        | 2896/16104 [13:29:53<63:13:28, 17.23s/it]

 18%|█▊        | 2897/16104 [13:30:07<60:27:12, 16.48s/it]

 18%|█▊        | 2898/16104 [13:30:18<54:12:03, 14.78s/it]

 18%|█▊        | 2899/16104 [13:30:34<55:09:29, 15.04s/it]

 18%|█▊        | 2900/16104 [13:30:48<53:48:35, 14.67s/it]

 18%|█▊        | 2901/16104 [13:30:58<49:18:53, 13.45s/it]

 18%|█▊        | 2902/16104 [13:31:17<54:50:22, 14.95s/it]

 18%|█▊        | 2903/16104 [13:31:38<61:57:01, 16.89s/it]

 18%|█▊        | 2904/16104 [13:32:00<67:00:37, 18.28s/it]

 18%|█▊        | 2905/16104 [13:32:13<61:57:56, 16.90s/it]

 18%|█▊        | 2906/16104 [13:32:33<65:13:49, 17.79s/it]

 18%|█▊        | 2907/16104 [13:32:45<58:53:53, 16.07s/it]

 18%|█▊        | 2908/16104 [13:33:02<59:53:42, 16.34s/it]

 18%|█▊        | 2909/16104 [13:33:18<59:11:45, 16.15s/it]

 18%|█▊        | 2910/16104 [13:33:38<63:05:11, 17.21s/it]

 18%|█▊        | 2911/16104 [13:33:57<65:19:21, 17.82s/it]

 18%|█▊        | 2912/16104 [13:34:18<69:18:21, 18.91s/it]

 18%|█▊        | 2913/16104 [13:34:33<64:40:29, 17.65s/it]
{'loss': 0.4173, 'learning_rate': 1.8830210222239052e-06, 'rewards/chosen': -0.8190444111824036, 'rewards/rejected': -1.9563698768615723, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1373252868652344, 'policy_logps/rejected': -307.38995361328125, 'policy_logps/chosen': -394.6446838378906, 'referece_logps/rejected': -287.8262634277344, 'referece_logps/chosen': -386.45428466796875, 'logits/rejected': 0.01578788459300995, 'logits/chosen': 0.08090582489967346, 'epoch': 1.09}


 18%|█▊        | 2915/16104 [13:35:09<66:11:47, 18.07s/it]

 18%|█▊        | 2916/16104 [13:35:29<68:08:03, 18.60s/it]

 18%|█▊        | 2917/16104 [13:35:45<65:08:51, 17.79s/it]
{'loss': 0.6627, 'learning_rate': 1.8826431553348234e-06, 'rewards/chosen': -1.0504668951034546, 'rewards/rejected': -1.4411652088165283, 'rewards/accuracies': 0.625, 'rewards/margins': 0.39069825410842896, 'policy_logps/rejected': -441.86590576171875, 'policy_logps/chosen': -394.99261474609375, 'referece_logps/rejected': -427.4542236328125, 'referece_logps/chosen': -384.4879455566406, 'logits/rejected': -1.1124744415283203, 'logits/chosen': -1.1657841205596924, 'epoch': 1.09}


 18%|█▊        | 2919/16104 [13:36:10<55:22:48, 15.12s/it]
{'loss': 0.6023, 'learning_rate': 1.8824540076480493e-06, 'rewards/chosen': -0.9738747477531433, 'rewards/rejected': -1.0512155294418335, 'rewards/accuracies': 0.5, 'rewards/margins': 0.07734087109565735, 'policy_logps/rejected': -360.13958740234375, 'policy_logps/chosen': -248.75375366210938, 'referece_logps/rejected': -349.62738037109375, 'referece_logps/chosen': -239.01499938964844, 'logits/rejected': 0.3546244204044342, 'logits/chosen': 0.5497322678565979, 'epoch': 1.09}

 18%|█▊        | 2920/16104 [13:36:31<61:47:12, 16.87s/it]


 18%|█▊        | 2922/16104 [13:36:57<53:56:05, 14.73s/it]

 18%|█▊        | 2923/16104 [13:37:10<52:33:53, 14.36s/it]
{'loss': 0.6164, 'learning_rate': 1.8820752839430619e-06, 'rewards/chosen': -0.7969766855239868, 'rewards/rejected': -1.383601188659668, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5866245627403259, 'policy_logps/rejected': -483.62274169921875, 'policy_logps/chosen': -468.06634521484375, 'referece_logps/rejected': -469.7867126464844, 'referece_logps/chosen': -460.0965576171875, 'logits/rejected': -0.47386544942855835, 'logits/chosen': -0.6443009972572327, 'epoch': 1.09}


 18%|█▊        | 2925/16104 [13:37:51<63:47:10, 17.42s/it]

 18%|█▊        | 2926/16104 [13:38:03<57:47:59, 15.79s/it]

 18%|█▊        | 2927/16104 [13:38:22<61:37:02, 16.83s/it]

 18%|█▊        | 2928/16104 [13:38:38<60:18:33, 16.48s/it]

 18%|█▊        | 2929/16104 [13:38:49<54:39:10, 14.93s/it]

 18%|█▊        | 2930/16104 [13:39:05<55:47:07, 15.24s/it]

 18%|█▊        | 2931/16104 [13:39:16<50:50:27, 13.89s/it]
{'loss': 0.6445, 'learning_rate': 1.8813161240657375e-06, 'rewards/chosen': -1.0374467372894287, 'rewards/rejected': -1.0138976573944092, 'rewards/accuracies': 0.375, 'rewards/margins': -0.023549072444438934, 'policy_logps/rejected': -300.9544372558594, 'policy_logps/chosen': -399.1994323730469, 'referece_logps/rejected': -290.81549072265625, 'referece_logps/chosen': -388.8249206542969, 'logits/rejected': 0.15115827322006226, 'logits/chosen': 0.22392278909683228, 'epoch': 1.09}

 18%|█▊        | 2932/16104 [13:39:38<59:14:35, 16.19s/it]


 18%|█▊        | 2934/16104 [13:40:13<61:53:37, 16.92s/it]

 18%|█▊        | 2935/16104 [13:40:27<58:48:29, 16.08s/it]
{'loss': 0.4983, 'learning_rate': 1.880935688384751e-06, 'rewards/chosen': -0.5566723942756653, 'rewards/rejected': -1.100594401359558, 'rewards/accuracies': 0.875, 'rewards/margins': 0.543921947479248, 'policy_logps/rejected': -334.0505676269531, 'policy_logps/chosen': -469.099853515625, 'referece_logps/rejected': -323.0446472167969, 'referece_logps/chosen': -463.5331115722656, 'logits/rejected': 0.02822100929915905, 'logits/chosen': -0.09466859698295593, 'epoch': 1.09}


 18%|█▊        | 2937/16104 [13:40:59<60:08:11, 16.44s/it]

 18%|█▊        | 2938/16104 [13:41:21<66:20:46, 18.14s/it]

 18%|█▊        | 2939/16104 [13:41:41<68:01:21, 18.60s/it]

 18%|█▊        | 2940/16104 [13:41:56<63:55:58, 17.48s/it]

 18%|█▊        | 2941/16104 [13:42:17<68:10:38, 18.65s/it]
{'loss': 0.553, 'learning_rate': 1.880363965877754e-06, 'rewards/chosen': -1.2181692123413086, 'rewards/rejected': -1.7133699655532837, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4952007532119751, 'policy_logps/rejected': -345.5177001953125, 'policy_logps/chosen': -389.0043640136719, 'referece_logps/rejected': -328.38397216796875, 'referece_logps/chosen': -376.82269287109375, 'logits/rejected': -0.4496156573295593, 'logits/chosen': -0.45587441325187683, 'epoch': 1.1}

 18%|█▊        | 2942/16104 [13:42:36<68:36:38, 18.77s/it]


 18%|█▊        | 2944/16104 [13:43:10<66:57:48, 18.32s/it]

 18%|█▊        | 2945/16104 [13:43:22<59:04:58, 16.16s/it]

 18%|█▊        | 2946/16104 [13:43:38<59:46:15, 16.35s/it]

 18%|█▊        | 2947/16104 [13:43:56<60:49:38, 16.64s/it]

 18%|█▊        | 2948/16104 [13:44:13<60:59:59, 16.69s/it]

 18%|█▊        | 2949/16104 [13:44:33<65:22:54, 17.89s/it]
{'loss': 0.4937, 'learning_rate': 1.8795996750577335e-06, 'rewards/chosen': -1.1775517463684082, 'rewards/rejected': -1.7441002130508423, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5665484070777893, 'policy_logps/rejected': -404.8404846191406, 'policy_logps/chosen': -354.7845458984375, 'referece_logps/rejected': -387.3995056152344, 'referece_logps/chosen': -343.009033203125, 'logits/rejected': -0.24612362682819366, 'logits/chosen': -0.27790817618370056, 'epoch': 1.1}

 18%|█▊        | 2950/16104 [13:44:52<66:38:56, 18.24s/it]

 18%|█▊        | 2951/16104 [13:45:08<63:59:28, 17.51s/it]

 18%|█▊        | 2952/16104 [13:45:28<66:57:38, 18.33s/it]

 18%|█▊        | 2953/16104 [13:45:44<64:10:42, 17.57s/it]


 18%|█▊        | 2955/16104 [13:46:21<64:59:45, 17.79s/it]
{'loss': 0.5527, 'learning_rate': 1.8790249624167917e-06, 'rewards/chosen': -0.9399994015693665, 'rewards/rejected': -1.5996274948120117, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6596282124519348, 'policy_logps/rejected': -399.33355712890625, 'policy_logps/chosen': -377.87762451171875, 'referece_logps/rejected': -383.3372497558594, 'referece_logps/chosen': -368.4776306152344, 'logits/rejected': -0.1622432917356491, 'logits/chosen': -0.14952173829078674, 'epoch': 1.1}


 18%|█▊        | 2957/16104 [13:46:57<64:21:18, 17.62s/it]
{'loss': 0.3869, 'learning_rate': 1.8788331070301008e-06, 'rewards/chosen': -0.6937631964683533, 'rewards/rejected': -2.498277425765991, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8045142889022827, 'policy_logps/rejected': -429.7817687988281, 'policy_logps/chosen': -446.93438720703125, 'referece_logps/rejected': -404.7989501953125, 'referece_logps/chosen': -439.99676513671875, 'logits/rejected': -1.1141284704208374, 'logits/chosen': -1.118388056755066, 'epoch': 1.1}


 18%|█▊        | 2959/16104 [13:47:39<70:46:07, 19.38s/it]
{'loss': 0.4113, 'learning_rate': 1.8786411094419416e-06, 'rewards/chosen': -0.5312741994857788, 'rewards/rejected': -1.8583271503448486, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3270528316497803, 'policy_logps/rejected': -486.1558532714844, 'policy_logps/chosen': -360.2553405761719, 'referece_logps/rejected': -467.57257080078125, 'referece_logps/chosen': -354.9425964355469, 'logits/rejected': -0.0867689698934555, 'logits/chosen': 0.0546853244304657, 'epoch': 1.1}


 18%|█▊        | 2961/16104 [13:48:18<69:51:50, 19.14s/it]
{'loss': 0.5212, 'learning_rate': 1.8784489696833806e-06, 'rewards/chosen': -0.8879892826080322, 'rewards/rejected': -1.4499061107635498, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5619169473648071, 'policy_logps/rejected': -420.38818359375, 'policy_logps/chosen': -404.3170471191406, 'referece_logps/rejected': -405.88916015625, 'referece_logps/chosen': -395.4371337890625, 'logits/rejected': -0.7725889682769775, 'logits/chosen': -0.7638411521911621, 'epoch': 1.1}


 18%|█▊        | 2963/16104 [13:48:51<65:01:20, 17.81s/it]
{'loss': 0.5873, 'learning_rate': 1.8782566877855074e-06, 'rewards/chosen': -0.8610841631889343, 'rewards/rejected': -1.5388092994689941, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6777251958847046, 'policy_logps/rejected': -389.065673828125, 'policy_logps/chosen': -401.81036376953125, 'referece_logps/rejected': -373.6775817871094, 'referece_logps/chosen': -393.19952392578125, 'logits/rejected': -0.9032121896743774, 'logits/chosen': -0.9850553870201111, 'epoch': 1.1}


 18%|█▊        | 2965/16104 [13:49:13<52:00:33, 14.25s/it]

 18%|█▊        | 2966/16104 [13:49:29<54:08:41, 14.84s/it]

 18%|█▊        | 2967/16104 [13:49:40<49:38:23, 13.60s/it]

 18%|█▊        | 2968/16104 [13:49:52<47:54:31, 13.13s/it]
{'loss': 0.7316, 'learning_rate': 1.8777753613855666e-06, 'rewards/chosen': -0.8053005933761597, 'rewards/rejected': -0.7585085034370422, 'rewards/accuracies': 0.375, 'rewards/margins': -0.04679204523563385, 'policy_logps/rejected': -399.910888671875, 'policy_logps/chosen': -439.6071472167969, 'referece_logps/rejected': -392.3258056640625, 'referece_logps/chosen': -431.5541687011719, 'logits/rejected': -0.27932727336883545, 'logits/chosen': -0.20403984189033508, 'epoch': 1.11}


 18%|█▊        | 2970/16104 [13:50:31<59:30:19, 16.31s/it]

 18%|█▊        | 2971/16104 [13:50:47<59:19:30, 16.26s/it]

 18%|█▊        | 2972/16104 [13:51:07<63:02:54, 17.28s/it]
{'loss': 0.5794, 'learning_rate': 1.8773896611058354e-06, 'rewards/chosen': -0.5837985873222351, 'rewards/rejected': -1.5631842613220215, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9793856143951416, 'policy_logps/rejected': -295.2982482910156, 'policy_logps/chosen': -356.0560607910156, 'referece_logps/rejected': -279.66644287109375, 'referece_logps/chosen': -350.2181091308594, 'logits/rejected': -0.4909587502479553, 'logits/chosen': -0.41390854120254517, 'epoch': 1.11}


 18%|█▊        | 2974/16104 [13:51:40<60:06:36, 16.48s/it]

 18%|█▊        | 2975/16104 [13:52:02<66:14:53, 18.17s/it]

 18%|█▊        | 2976/16104 [13:52:15<60:42:26, 16.65s/it]
{'loss': 0.5597, 'learning_rate': 1.877003392954493e-06, 'rewards/chosen': -1.2077453136444092, 'rewards/rejected': -1.3407365083694458, 'rewards/accuracies': 0.75, 'rewards/margins': 0.132991224527359, 'policy_logps/rejected': -386.42291259765625, 'policy_logps/chosen': -312.15325927734375, 'referece_logps/rejected': -373.0155334472656, 'referece_logps/chosen': -300.0758056640625, 'logits/rejected': -1.2995444536209106, 'logits/chosen': -1.0400898456573486, 'epoch': 1.11}


 18%|█▊        | 2978/16104 [13:52:49<61:35:36, 16.89s/it]

 18%|█▊        | 2979/16104 [13:53:09<65:08:11, 17.87s/it]
{'loss': 0.5564, 'learning_rate': 1.8767133193256205e-06, 'rewards/chosen': -0.8740065097808838, 'rewards/rejected': -1.597062110900879, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7230556011199951, 'policy_logps/rejected': -371.75128173828125, 'policy_logps/chosen': -380.65069580078125, 'referece_logps/rejected': -355.7806396484375, 'referece_logps/chosen': -371.91064453125, 'logits/rejected': -0.3351685404777527, 'logits/chosen': -0.2603244185447693, 'epoch': 1.11}


 19%|█▊        | 2981/16104 [13:53:33<53:53:26, 14.78s/it]

 19%|█▊        | 2982/16104 [13:53:45<51:09:04, 14.03s/it]

 19%|█▊        | 2983/16104 [13:53:58<49:08:42, 13.48s/it]

 19%|█▊        | 2984/16104 [13:54:17<55:38:42, 15.27s/it]

 19%|█▊        | 2985/16104 [13:54:28<50:44:15, 13.92s/it]

 19%|█▊        | 2986/16104 [13:54:42<50:53:39, 13.97s/it]

 19%|█▊        | 2987/16104 [13:54:57<52:09:01, 14.31s/it]
{'loss': 0.5757, 'learning_rate': 1.8759382294926655e-06, 'rewards/chosen': -0.35267797112464905, 'rewards/rejected': -1.172208547592163, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8195304870605469, 'policy_logps/rejected': -403.8653259277344, 'policy_logps/chosen': -361.9840087890625, 'referece_logps/rejected': -392.14324951171875, 'referece_logps/chosen': -358.4572448730469, 'logits/rejected': 0.39651888608932495, 'logits/chosen': 0.2913888990879059, 'epoch': 1.11}


 19%|█▊        | 2989/16104 [13:55:30<57:30:09, 15.78s/it]
{'loss': 0.6433, 'learning_rate': 1.8757441026233438e-06, 'rewards/chosen': -0.7791004180908203, 'rewards/rejected': -1.206013560295105, 'rewards/accuracies': 0.625, 'rewards/margins': 0.42691314220428467, 'policy_logps/rejected': -565.7952880859375, 'policy_logps/chosen': -479.1983642578125, 'referece_logps/rejected': -553.7351684570312, 'referece_logps/chosen': -471.40740966796875, 'logits/rejected': 0.6578336358070374, 'logits/chosen': 0.616206705570221, 'epoch': 1.11}


 19%|█▊        | 2991/16104 [13:56:01<58:05:01, 15.95s/it]

 19%|█▊        | 2992/16104 [13:56:22<63:26:47, 17.42s/it]

 19%|█▊        | 2993/16104 [13:56:38<61:18:37, 16.83s/it]

 19%|█▊        | 2994/16104 [13:56:54<60:30:35, 16.62s/it]
{'loss': 0.6016, 'learning_rate': 1.875258165574109e-06, 'rewards/chosen': -0.8602666854858398, 'rewards/rejected': -0.9024055600166321, 'rewards/accuracies': 0.625, 'rewards/margins': 0.042138855904340744, 'policy_logps/rejected': -319.0381164550781, 'policy_logps/chosen': -460.9473571777344, 'referece_logps/rejected': -310.0140380859375, 'referece_logps/chosen': -452.3447265625, 'logits/rejected': -0.9585394859313965, 'logits/chosen': -0.8136305809020996, 'epoch': 1.12}

 19%|█▊        | 2995/16104 [13:57:05<54:26:08, 14.95s/it]


 19%|█▊        | 2997/16104 [13:57:28<47:26:32, 13.03s/it]

 19%|█▊        | 2998/16104 [13:57:46<53:50:16, 14.79s/it]
{'loss': 0.6692, 'learning_rate': 1.8748687786075696e-06, 'rewards/chosen': -0.7241390347480774, 'rewards/rejected': -0.40219393372535706, 'rewards/accuracies': 0.125, 'rewards/margins': -0.32194510102272034, 'policy_logps/rejected': -331.6785888671875, 'policy_logps/chosen': -328.0955505371094, 'referece_logps/rejected': -327.65667724609375, 'referece_logps/chosen': -320.8541564941406, 'logits/rejected': -0.3127015233039856, 'logits/chosen': -0.3724796175956726, 'epoch': 1.12}

 19%|█▊        | 2999/16104 [13:58:03<55:51:44, 15.35s/it]

 19%|█▊        | 3000/16104 [13:58:19<56:36:44, 15.55s/it]

 19%|█▊        | 3001/16104 [13:58:55<78:39:58, 21.61s/it]

 19%|█▊        | 3002/16104 [13:59:09<70:18:40, 19.32s/it]


 19%|█▊        | 3004/16104 [13:59:45<68:54:39, 18.94s/it]
{'loss': 0.5111, 'learning_rate': 1.874283636536573e-06, 'rewards/chosen': -0.21550539135932922, 'rewards/rejected': -1.2906399965286255, 'rewards/accuracies': 0.75, 'rewards/margins': 1.075134515762329, 'policy_logps/rejected': -321.4446105957031, 'policy_logps/chosen': -301.26141357421875, 'referece_logps/rejected': -308.5382080078125, 'referece_logps/chosen': -299.1063232421875, 'logits/rejected': -0.300322026014328, 'logits/chosen': -0.29158809781074524, 'epoch': 1.12}

 19%|█▊        | 3005/16104 [14:00:07<71:56:24, 19.77s/it]

 19%|█▊        | 3006/16104 [14:00:19<63:40:56, 17.50s/it]


 19%|█▊        | 3008/16104 [14:00:54<62:55:19, 17.30s/it]

 19%|█▊        | 3009/16104 [14:01:04<55:40:46, 15.31s/it]

 19%|█▊        | 3010/16104 [14:01:24<60:25:56, 16.61s/it]

 19%|█▊        | 3011/16104 [14:01:42<61:52:34, 17.01s/it]

 19%|█▊        | 3012/16104 [14:01:54<56:14:18, 15.46s/it]

 19%|█▊        | 3013/16104 [14:02:06<52:45:11, 14.51s/it]

 19%|█▊        | 3014/16104 [14:02:25<57:09:49, 15.72s/it]

 19%|█▊        | 3015/16104 [14:02:36<51:58:16, 14.29s/it]

 19%|█▊        | 3016/16104 [14:02:48<50:16:02, 13.83s/it]
{'loss': 0.5795, 'learning_rate': 1.873109533685015e-06, 'rewards/chosen': -0.7388171553611755, 'rewards/rejected': -1.4815096855163574, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7426924705505371, 'policy_logps/rejected': -372.936767578125, 'policy_logps/chosen': -288.10552978515625, 'referece_logps/rejected': -358.1217041015625, 'referece_logps/chosen': -280.71734619140625, 'logits/rejected': -1.1630574464797974, 'logits/chosen': -1.13137948513031, 'epoch': 1.12}


 19%|█▊        | 3018/16104 [14:03:25<57:41:53, 15.87s/it]

 19%|█▊        | 3019/16104 [14:03:47<64:15:17, 17.68s/it]
{'loss': 0.4883, 'learning_rate': 1.8728152130308302e-06, 'rewards/chosen': -0.7567057013511658, 'rewards/rejected': -1.6764342784881592, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9197285771369934, 'policy_logps/rejected': -482.8778381347656, 'policy_logps/chosen': -427.7046203613281, 'referece_logps/rejected': -466.113525390625, 'referece_logps/chosen': -420.1376037597656, 'logits/rejected': -0.5587797164916992, 'logits/chosen': -0.49002277851104736, 'epoch': 1.12}

 19%|█▉        | 3020/16104 [14:03:58<56:38:59, 15.59s/it]


 19%|█▉        | 3022/16104 [14:04:26<54:32:43, 15.01s/it]

 19%|█▉        | 3023/16104 [14:04:42<56:02:34, 15.42s/it]

 19%|█▉        | 3024/16104 [14:05:03<61:30:04, 16.93s/it]
{'loss': 0.5451, 'learning_rate': 1.8723239725215165e-06, 'rewards/chosen': -0.6373317837715149, 'rewards/rejected': -0.8704020977020264, 'rewards/accuracies': 0.625, 'rewards/margins': 0.23307037353515625, 'policy_logps/rejected': -454.9975280761719, 'policy_logps/chosen': -390.64385986328125, 'referece_logps/rejected': -446.2934875488281, 'referece_logps/chosen': -384.27056884765625, 'logits/rejected': 0.030274096876382828, 'logits/chosen': 0.13429595530033112, 'epoch': 1.13}


 19%|█▉        | 3026/16104 [14:05:36<62:34:52, 17.23s/it]

 19%|█▉        | 3027/16104 [14:05:56<65:48:42, 18.12s/it]
{'loss': 0.5469, 'learning_rate': 1.8720288047393949e-06, 'rewards/chosen': -0.9649912714958191, 'rewards/rejected': -1.6703907251358032, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7053993940353394, 'policy_logps/rejected': -436.42327880859375, 'policy_logps/chosen': -423.6523742675781, 'referece_logps/rejected': -419.7193908691406, 'referece_logps/chosen': -414.0024719238281, 'logits/rejected': -0.8160387277603149, 'logits/chosen': -0.7273375988006592, 'epoch': 1.13}


 19%|█▉        | 3029/16104 [14:06:27<58:50:10, 16.20s/it]
{'loss': 0.6297, 'learning_rate': 1.8718318498357406e-06, 'rewards/chosen': -1.8235015869140625, 'rewards/rejected': -1.7529680728912354, 'rewards/accuracies': 0.5, 'rewards/margins': -0.07053351402282715, 'policy_logps/rejected': -288.84039306640625, 'policy_logps/chosen': -304.6251220703125, 'referece_logps/rejected': -271.3106994628906, 'referece_logps/chosen': -286.39007568359375, 'logits/rejected': -0.8311767578125, 'logits/chosen': -0.7376317381858826, 'epoch': 1.13}

 19%|█▉        | 3030/16104 [14:06:37<52:54:14, 14.57s/it]


 19%|█▉        | 3032/16104 [14:07:19<64:18:26, 17.71s/it]
{'loss': 0.5664, 'learning_rate': 1.8715361529865717e-06, 'rewards/chosen': -0.8662563562393188, 'rewards/rejected': -1.5881102085113525, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7218538522720337, 'policy_logps/rejected': -335.2157287597656, 'policy_logps/chosen': -303.4029235839844, 'referece_logps/rejected': -319.33465576171875, 'referece_logps/chosen': -294.7403564453125, 'logits/rejected': -0.50934237241745, 'logits/chosen': -0.46761393547058105, 'epoch': 1.13}


 19%|█▉        | 3034/16104 [14:07:53<61:58:15, 17.07s/it]
{'loss': 0.5994, 'learning_rate': 1.8713388454711839e-06, 'rewards/chosen': -0.48011475801467896, 'rewards/rejected': -1.5984694957733154, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1183547973632812, 'policy_logps/rejected': -356.4046630859375, 'policy_logps/chosen': -400.67486572265625, 'referece_logps/rejected': -340.41998291015625, 'referece_logps/chosen': -395.8737487792969, 'logits/rejected': 0.15992826223373413, 'logits/chosen': 0.11794288456439972, 'epoch': 1.13}

 19%|█▉        | 3035/16104 [14:08:06<57:22:20, 15.80s/it]


 19%|█▉        | 3037/16104 [14:08:35<54:16:53, 14.95s/it]

 19%|█▉        | 3038/16104 [14:08:55<60:30:22, 16.67s/it]
{'loss': 0.6076, 'learning_rate': 1.8709438075058266e-06, 'rewards/chosen': -0.8349161148071289, 'rewards/rejected': -1.2693372964859009, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4344211220741272, 'policy_logps/rejected': -269.4131164550781, 'policy_logps/chosen': -436.41888427734375, 'referece_logps/rejected': -256.7197265625, 'referece_logps/chosen': -428.06976318359375, 'logits/rejected': -1.500672459602356, 'logits/chosen': -1.810106635093689, 'epoch': 1.13}


 19%|█▉        | 3040/16104 [14:09:34<66:13:12, 18.25s/it]

 19%|█▉        | 3041/16104 [14:09:51<64:00:04, 17.64s/it]

 19%|█▉        | 3042/16104 [14:10:11<66:32:21, 18.34s/it]

 19%|█▉        | 3043/16104 [14:10:27<64:37:49, 17.81s/it]
{'loss': 0.5568, 'learning_rate': 1.8704492173764649e-06, 'rewards/chosen': -0.6728382706642151, 'rewards/rejected': -1.1587903499603271, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4859521985054016, 'policy_logps/rejected': -409.5690002441406, 'policy_logps/chosen': -501.2334289550781, 'referece_logps/rejected': -397.9810791015625, 'referece_logps/chosen': -494.5050048828125, 'logits/rejected': -0.2839670777320862, 'logits/chosen': -0.3635856509208679, 'epoch': 1.13}


 19%|█▉        | 3045/16104 [14:11:01<61:26:35, 16.94s/it]
{'loss': 0.5789, 'learning_rate': 1.8702511348181319e-06, 'rewards/chosen': -0.4612676501274109, 'rewards/rejected': -1.145727276802063, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6844596266746521, 'policy_logps/rejected': -269.52239990234375, 'policy_logps/chosen': -256.52587890625, 'referece_logps/rejected': -258.06512451171875, 'referece_logps/chosen': -251.91322326660156, 'logits/rejected': -0.7926896810531616, 'logits/chosen': -0.6501261591911316, 'epoch': 1.13}


 19%|█▉        | 3047/16104 [14:11:33<61:04:13, 16.84s/it]
{'loss': 0.5893, 'learning_rate': 1.8700529114469544e-06, 'rewards/chosen': -1.08116614818573, 'rewards/rejected': -1.53079092502594, 'rewards/accuracies': 0.75, 'rewards/margins': 0.44962483644485474, 'policy_logps/rejected': -438.3546447753906, 'policy_logps/chosen': -371.93646240234375, 'referece_logps/rejected': -423.04669189453125, 'referece_logps/chosen': -361.1247863769531, 'logits/rejected': -0.13140350580215454, 'logits/chosen': -0.18201495707035065, 'epoch': 1.14}


 19%|█▉        | 3049/16104 [14:12:13<66:40:32, 18.39s/it]
{'loss': 0.5319, 'learning_rate': 1.8698545472950066e-06, 'rewards/chosen': -0.9036993384361267, 'rewards/rejected': -1.2898107767105103, 'rewards/accuracies': 0.625, 'rewards/margins': 0.38611143827438354, 'policy_logps/rejected': -424.8052062988281, 'policy_logps/chosen': -328.2505798339844, 'referece_logps/rejected': -411.9071044921875, 'referece_logps/chosen': -319.213623046875, 'logits/rejected': -0.31676363945007324, 'logits/chosen': -0.3067561089992523, 'epoch': 1.14}


 19%|█▉        | 3051/16104 [14:12:51<67:03:27, 18.49s/it]
{'loss': 0.5437, 'learning_rate': 1.869656042394386e-06, 'rewards/chosen': -0.28340739011764526, 'rewards/rejected': -1.3337537050247192, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0503464937210083, 'policy_logps/rejected': -345.94464111328125, 'policy_logps/chosen': -311.27630615234375, 'referece_logps/rejected': -332.6070861816406, 'referece_logps/chosen': -308.4422302246094, 'logits/rejected': 1.118187665939331, 'logits/chosen': 1.0911527872085571, 'epoch': 1.14}

 19%|█▉        | 3052/16104 [14:13:10<67:40:38, 18.67s/it]


 19%|█▉        | 3054/16104 [14:13:41<63:07:39, 17.41s/it]
{'loss': 0.5518, 'learning_rate': 1.86935802120996e-06, 'rewards/chosen': -0.8680721521377563, 'rewards/rejected': -0.9560608863830566, 'rewards/accuracies': 0.625, 'rewards/margins': 0.08798867464065552, 'policy_logps/rejected': -260.6851501464844, 'policy_logps/chosen': -410.157958984375, 'referece_logps/rejected': -251.12454223632812, 'referece_logps/chosen': -401.4771728515625, 'logits/rejected': -0.4771977663040161, 'logits/chosen': -0.2734735608100891, 'epoch': 1.14}

 19%|█▉        | 3055/16104 [14:13:57<61:14:44, 16.90s/it]

 19%|█▉        | 3056/16104 [14:14:14<62:08:24, 17.14s/it]

 19%|█▉        | 3057/16104 [14:14:27<56:53:21, 15.70s/it]

 19%|█▉        | 3058/16104 [14:14:43<57:10:45, 15.78s/it]


 19%|█▉        | 3060/16104 [14:15:15<57:25:21, 15.85s/it]
{'loss': 0.5679, 'learning_rate': 1.8687610294384986e-06, 'rewards/chosen': -0.5071409344673157, 'rewards/rejected': -0.8651009202003479, 'rewards/accuracies': 0.75, 'rewards/margins': 0.357960045337677, 'policy_logps/rejected': -348.18646240234375, 'policy_logps/chosen': -322.54229736328125, 'referece_logps/rejected': -339.53546142578125, 'referece_logps/chosen': -317.47088623046875, 'logits/rejected': -0.8218870162963867, 'logits/chosen': -0.916003406047821, 'epoch': 1.14}


 19%|█▉        | 3062/16104 [14:15:54<63:39:50, 17.57s/it]
{'loss': 0.5496, 'learning_rate': 1.868561750994921e-06, 'rewards/chosen': -0.9964309930801392, 'rewards/rejected': -1.700080156326294, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7036492824554443, 'policy_logps/rejected': -440.71148681640625, 'policy_logps/chosen': -493.36053466796875, 'referece_logps/rejected': -423.7106628417969, 'referece_logps/chosen': -483.39617919921875, 'logits/rejected': -0.37248915433883667, 'logits/chosen': -0.35861021280288696, 'epoch': 1.14}

 19%|█▉        | 3063/16104 [14:16:12<64:54:49, 17.92s/it]

 19%|█▉        | 3064/16104 [14:16:29<63:10:51, 17.44s/it]


 19%|█▉        | 3066/16104 [14:17:01<61:03:35, 16.86s/it]
{'loss': 0.4891, 'learning_rate': 1.8681627725215648e-06, 'rewards/chosen': -0.8814293146133423, 'rewards/rejected': -1.413167953491211, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5317386388778687, 'policy_logps/rejected': -401.98675537109375, 'policy_logps/chosen': -342.9037780761719, 'referece_logps/rejected': -387.8551025390625, 'referece_logps/chosen': -334.0894775390625, 'logits/rejected': -0.37448108196258545, 'logits/chosen': -0.10349918901920319, 'epoch': 1.14}


 19%|█▉        | 3068/16104 [14:17:33<58:13:13, 16.08s/it]
{'loss': 0.4761, 'learning_rate': 1.8679630725563431e-06, 'rewards/chosen': -0.6639922857284546, 'rewards/rejected': -1.5092734098434448, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8452810049057007, 'policy_logps/rejected': -385.3788146972656, 'policy_logps/chosen': -321.5384216308594, 'referece_logps/rejected': -370.2861022949219, 'referece_logps/chosen': -314.8985290527344, 'logits/rejected': -1.167772650718689, 'logits/chosen': -1.183588981628418, 'epoch': 1.14}

 19%|█▉        | 3069/16104 [14:17:53<62:07:23, 17.16s/it]


 19%|█▉        | 3071/16104 [14:18:27<62:38:35, 17.30s/it]
{'loss': 0.5809, 'learning_rate': 1.8676632592887041e-06, 'rewards/chosen': -0.5352121591567993, 'rewards/rejected': -1.2616276741027832, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7264155149459839, 'policy_logps/rejected': -278.71856689453125, 'policy_logps/chosen': -499.28314208984375, 'referece_logps/rejected': -266.102294921875, 'referece_logps/chosen': -493.9309997558594, 'logits/rejected': 0.2994805574417114, 'logits/chosen': 0.2839597463607788, 'epoch': 1.14}

 19%|█▉        | 3072/16104 [14:18:49<67:13:58, 18.57s/it]


 19%|█▉        | 3074/16104 [14:19:13<55:44:56, 15.40s/it]
{'loss': 0.5019, 'learning_rate': 1.8673631301343288e-06, 'rewards/chosen': -0.3934175670146942, 'rewards/rejected': -1.3138266801834106, 'rewards/accuracies': 1.0, 'rewards/margins': 0.920409083366394, 'policy_logps/rejected': -313.6848449707031, 'policy_logps/chosen': -419.9526062011719, 'referece_logps/rejected': -300.54656982421875, 'referece_logps/chosen': -416.0184326171875, 'logits/rejected': -1.425291895866394, 'logits/chosen': -1.487287998199463, 'epoch': 1.15}

 19%|█▉        | 3075/16104 [14:19:29<56:09:38, 15.52s/it]


 19%|█▉        | 3077/16104 [14:19:58<54:58:16, 15.19s/it]

 19%|█▉        | 3078/16104 [14:20:17<59:26:03, 16.43s/it]
{'loss': 0.5612, 'learning_rate': 1.8669624667380008e-06, 'rewards/chosen': -0.4456796944141388, 'rewards/rejected': -1.0665751695632935, 'rewards/accuracies': 0.5, 'rewards/margins': 0.620895504951477, 'policy_logps/rejected': -319.27716064453125, 'policy_logps/chosen': -310.525390625, 'referece_logps/rejected': -308.6114196777344, 'referece_logps/chosen': -306.068603515625, 'logits/rejected': -1.2657452821731567, 'logits/chosen': -1.4555494785308838, 'epoch': 1.15}

 19%|█▉        | 3079/16104 [14:20:38<64:37:35, 17.86s/it]


 19%|█▉        | 3081/16104 [14:21:14<63:35:12, 17.58s/it]

 19%|█▉        | 3082/16104 [14:21:31<63:32:35, 17.57s/it]
{'loss': 0.5364, 'learning_rate': 1.8665612422188395e-06, 'rewards/chosen': -0.583573579788208, 'rewards/rejected': -1.2719664573669434, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6883928775787354, 'policy_logps/rejected': -509.8280029296875, 'policy_logps/chosen': -407.2743835449219, 'referece_logps/rejected': -497.10833740234375, 'referece_logps/chosen': -401.43865966796875, 'logits/rejected': 0.20034156739711761, 'logits/chosen': 0.2680257558822632, 'epoch': 1.15}

 19%|█▉        | 3083/16104 [14:21:43<56:59:13, 15.76s/it]

 19%|█▉        | 3084/16104 [14:21:58<56:38:46, 15.66s/it]


 19%|█▉        | 3086/16104 [14:22:35<61:20:49, 16.96s/it]
{'loss': 0.4707, 'learning_rate': 1.8661594568365284e-06, 'rewards/chosen': -0.7275175452232361, 'rewards/rejected': -1.875996708869934, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1484792232513428, 'policy_logps/rejected': -266.38128662109375, 'policy_logps/chosen': -311.0321044921875, 'referece_logps/rejected': -247.621337890625, 'referece_logps/chosen': -303.7569274902344, 'logits/rejected': -0.7953140735626221, 'logits/chosen': -0.7013226747512817, 'epoch': 1.15}

 19%|█▉        | 3087/16104 [14:22:49<57:46:48, 15.98s/it]


 19%|█▉        | 3089/16104 [14:23:22<56:57:12, 15.75s/it]
{'loss': 0.5488, 'learning_rate': 1.8658577498897744e-06, 'rewards/chosen': -0.7906737923622131, 'rewards/rejected': -1.748130440711975, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9574565887451172, 'policy_logps/rejected': -458.91796875, 'policy_logps/chosen': -378.1253662109375, 'referece_logps/rejected': -441.4366760253906, 'referece_logps/chosen': -370.2186584472656, 'logits/rejected': -0.995496392250061, 'logits/chosen': -0.9816702008247375, 'epoch': 1.15}


 19%|█▉        | 3091/16104 [14:23:44<48:23:29, 13.39s/it]

 19%|█▉        | 3092/16104 [14:23:56<46:43:21, 12.93s/it]
{'loss': 0.5708, 'learning_rate': 1.8655557277136085e-06, 'rewards/chosen': -0.5757149457931519, 'rewards/rejected': -1.0309371948242188, 'rewards/accuracies': 0.625, 'rewards/margins': 0.45522239804267883, 'policy_logps/rejected': -400.6476745605469, 'policy_logps/chosen': -630.6637573242188, 'referece_logps/rejected': -390.3382568359375, 'referece_logps/chosen': -624.9066162109375, 'logits/rejected': -0.20000964403152466, 'logits/chosen': -0.20608805119991302, 'epoch': 1.15}

 19%|█▉        | 3093/16104 [14:24:17<55:59:35, 15.49s/it]


 19%|█▉        | 3095/16104 [14:24:48<56:01:25, 15.50s/it]
{'loss': 0.6122, 'learning_rate': 1.8652533904179875e-06, 'rewards/chosen': -1.592000126838684, 'rewards/rejected': -2.119218587875366, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5272184610366821, 'policy_logps/rejected': -352.33203125, 'policy_logps/chosen': -360.908203125, 'referece_logps/rejected': -331.1398620605469, 'referece_logps/chosen': -344.98822021484375, 'logits/rejected': -0.6625243425369263, 'logits/chosen': -0.6750084757804871, 'epoch': 1.15}

 19%|█▉        | 3096/16104 [14:24:59<51:19:03, 14.20s/it]

 19%|█▉        | 3097/16104 [14:25:11<48:22:25, 13.39s/it]


 19%|█▉        | 3099/16104 [14:25:46<57:40:37, 15.97s/it]

 19%|█▉        | 3100/16104 [14:25:56<52:09:02, 14.44s/it]
{'loss': 0.6475, 'learning_rate': 1.864748794958839e-06, 'rewards/chosen': -0.773491621017456, 'rewards/rejected': -1.009181261062622, 'rewards/accuracies': 0.75, 'rewards/margins': 0.23568955063819885, 'policy_logps/rejected': -534.83154296875, 'policy_logps/chosen': -487.82464599609375, 'referece_logps/rejected': -524.73974609375, 'referece_logps/chosen': -480.0897216796875, 'logits/rejected': -1.1447713375091553, 'logits/chosen': -1.1479827165603638, 'epoch': 1.15}

 19%|█▉        | 3101/16104 [14:26:07<48:09:31, 13.33s/it]


 19%|█▉        | 3103/16104 [14:26:32<45:50:53, 12.70s/it]
{'loss': 0.6372, 'learning_rate': 1.8644456178831054e-06, 'rewards/chosen': -0.6451911926269531, 'rewards/rejected': -1.1960639953613281, 'rewards/accuracies': 0.875, 'rewards/margins': 0.550872802734375, 'policy_logps/rejected': -414.11309814453125, 'policy_logps/chosen': -364.0004577636719, 'referece_logps/rejected': -402.15240478515625, 'referece_logps/chosen': -357.54852294921875, 'logits/rejected': -1.1830953359603882, 'logits/chosen': -1.1492478847503662, 'epoch': 1.16}

 19%|█▉        | 3104/16104 [14:26:43<44:17:49, 12.27s/it]

 19%|█▉        | 3105/16104 [14:26:55<44:02:34, 12.20s/it]

 19%|█▉        | 3106/16104 [14:27:15<51:53:01, 14.37s/it]

 19%|█▉        | 3107/16104 [14:27:35<58:06:28, 16.10s/it]


 19%|█▉        | 3109/16104 [14:28:04<54:21:20, 15.06s/it]
{'loss': 0.6193, 'learning_rate': 1.8638383196962232e-06, 'rewards/chosen': -0.9862658977508545, 'rewards/rejected': -1.6965034008026123, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7102375030517578, 'policy_logps/rejected': -246.41461181640625, 'policy_logps/chosen': -397.947998046875, 'referece_logps/rejected': -229.44956970214844, 'referece_logps/chosen': -388.08538818359375, 'logits/rejected': -0.8275226354598999, 'logits/chosen': -0.980224609375, 'epoch': 1.16}

 19%|█▉        | 3110/16104 [14:28:22<57:21:31, 15.89s/it]

 19%|█▉        | 3111/16104 [14:28:38<57:22:24, 15.90s/it]


 19%|█▉        | 3113/16104 [14:29:13<60:15:02, 16.70s/it]

 19%|█▉        | 3114/16104 [14:29:32<63:25:40, 17.58s/it]

 19%|█▉        | 3115/16104 [14:29:52<66:02:55, 18.31s/it]

 19%|█▉        | 3116/16104 [14:30:08<63:36:59, 17.63s/it]

 19%|█▉        | 3117/16104 [14:30:20<57:35:22, 15.96s/it]
{'loss': 0.4534, 'learning_rate': 1.8630266320808457e-06, 'rewards/chosen': -1.1458029747009277, 'rewards/rejected': -1.7410690784454346, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5952661633491516, 'policy_logps/rejected': -377.49249267578125, 'policy_logps/chosen': -433.91680908203125, 'referece_logps/rejected': -360.08184814453125, 'referece_logps/chosen': -422.4587707519531, 'logits/rejected': -0.3337441384792328, 'logits/chosen': -0.31122833490371704, 'epoch': 1.16}

 19%|█▉        | 3118/16104 [14:30:37<58:24:50, 16.19s/it]


 19%|█▉        | 3120/16104 [14:31:14<62:37:31, 17.36s/it]
{'loss': 0.484, 'learning_rate': 1.8627216730811882e-06, 'rewards/chosen': -1.1517177820205688, 'rewards/rejected': -2.2872438430786133, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1355259418487549, 'policy_logps/rejected': -404.8699951171875, 'policy_logps/chosen': -361.56024169921875, 'referece_logps/rejected': -381.9975280761719, 'referece_logps/chosen': -350.0430603027344, 'logits/rejected': -1.4588043689727783, 'logits/chosen': -1.5317699909210205, 'epoch': 1.16}


 19%|█▉        | 3122/16104 [14:31:53<66:36:07, 18.47s/it]
{'loss': 0.5959, 'learning_rate': 1.8625181925814073e-06, 'rewards/chosen': -0.8805384635925293, 'rewards/rejected': -1.6508194208145142, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7702808380126953, 'policy_logps/rejected': -666.1259765625, 'policy_logps/chosen': -365.55364990234375, 'referece_logps/rejected': -649.6177368164062, 'referece_logps/chosen': -356.7482604980469, 'logits/rejected': -1.7663954496383667, 'logits/chosen': -1.5192232131958008, 'epoch': 1.16}

 19%|█▉        | 3123/16104 [14:32:13<69:00:23, 19.14s/it]


 19%|█▉        | 3125/16104 [14:32:49<67:00:26, 18.59s/it]
{'loss': 0.5256, 'learning_rate': 1.8622127101640333e-06, 'rewards/chosen': -0.9414236545562744, 'rewards/rejected': -1.4103413820266724, 'rewards/accuracies': 0.75, 'rewards/margins': 0.46891769766807556, 'policy_logps/rejected': -540.8289794921875, 'policy_logps/chosen': -436.1093444824219, 'referece_logps/rejected': -526.7255249023438, 'referece_logps/chosen': -426.695068359375, 'logits/rejected': -0.8144820928573608, 'logits/chosen': -0.860319197177887, 'epoch': 1.16}

 19%|█▉        | 3126/16104 [14:33:05<64:29:01, 17.89s/it]


 19%|█▉        | 3128/16104 [14:33:45<67:05:07, 18.61s/it]

 19%|█▉        | 3129/16104 [14:33:56<59:35:52, 16.54s/it]
{'loss': 0.508, 'learning_rate': 1.8618049120008552e-06, 'rewards/chosen': -0.8953243494033813, 'rewards/rejected': -1.5820462703704834, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6867221593856812, 'policy_logps/rejected': -364.9139404296875, 'policy_logps/chosen': -378.9310607910156, 'referece_logps/rejected': -349.09344482421875, 'referece_logps/chosen': -369.977783203125, 'logits/rejected': -0.7705293297767639, 'logits/chosen': -0.6489216089248657, 'epoch': 1.17}

 19%|█▉        | 3130/16104 [14:34:14<60:28:15, 16.78s/it]


 19%|█▉        | 3132/16104 [14:34:53<65:38:43, 18.22s/it]
{'loss': 0.5842, 'learning_rate': 1.8614986973178035e-06, 'rewards/chosen': -1.2779191732406616, 'rewards/rejected': -1.9808669090270996, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7029477953910828, 'policy_logps/rejected': -410.3069152832031, 'policy_logps/chosen': -427.0254211425781, 'referece_logps/rejected': -390.49822998046875, 'referece_logps/chosen': -414.2462158203125, 'logits/rejected': -0.4102688431739807, 'logits/chosen': -0.38683560490608215, 'epoch': 1.17}

 19%|█▉        | 3133/16104 [14:35:04<57:54:58, 16.07s/it]

 19%|█▉        | 3134/16104 [14:35:26<64:36:49, 17.93s/it]

 19%|█▉        | 3135/16104 [14:35:39<59:37:26, 16.55s/it]

 19%|█▉        | 3136/16104 [14:35:57<61:14:24, 17.00s/it]

 19%|█▉        | 3137/16104 [14:36:16<62:37:02, 17.38s/it]

 19%|█▉        | 3138/16104 [14:36:34<63:47:09, 17.71s/it]


 19%|█▉        | 3140/16104 [14:37:05<58:50:14, 16.34s/it]
{'loss': 0.6318, 'learning_rate': 1.8606805917698357e-06, 'rewards/chosen': -0.7519758939743042, 'rewards/rejected': -1.238380789756775, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4864048957824707, 'policy_logps/rejected': -257.7265930175781, 'policy_logps/chosen': -299.2036437988281, 'referece_logps/rejected': -245.34280395507812, 'referece_logps/chosen': -291.68389892578125, 'logits/rejected': -0.6295382380485535, 'logits/chosen': -0.7710957527160645, 'epoch': 1.17}

 20%|█▉        | 3141/16104 [14:37:25<62:33:10, 17.37s/it]

 20%|█▉        | 3142/16104 [14:37:43<63:09:23, 17.54s/it]

 20%|█▉        | 3143/16104 [14:38:01<64:12:51, 17.84s/it]


 20%|█▉        | 3145/16104 [14:38:35<61:07:49, 16.98s/it]

 20%|█▉        | 3146/16104 [14:38:49<57:51:37, 16.07s/it]
{'loss': 0.5257, 'learning_rate': 1.8600655502183608e-06, 'rewards/chosen': -1.2858327627182007, 'rewards/rejected': -1.9745557308197021, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6887228488922119, 'policy_logps/rejected': -252.5940399169922, 'policy_logps/chosen': -405.84014892578125, 'referece_logps/rejected': -232.8485107421875, 'referece_logps/chosen': -392.9818115234375, 'logits/rejected': -1.0387216806411743, 'logits/chosen': -1.3066388368606567, 'epoch': 1.17}

 20%|█▉        | 3147/16104 [14:39:10<63:33:18, 17.66s/it]

 20%|█▉        | 3148/16104 [14:39:30<65:44:28, 18.27s/it]

 20%|█▉        | 3149/16104 [14:39:48<65:14:35, 18.13s/it]

 20%|█▉        | 3150/16104 [14:40:02<61:21:42, 17.05s/it]

 20%|█▉        | 3151/16104 [14:40:14<55:12:32, 15.34s/it]

 20%|█▉        | 3152/16104 [14:40:30<56:34:32, 15.73s/it]


 20%|█▉        | 3154/16104 [14:41:11<65:21:53, 18.17s/it]
{'loss': 0.5849, 'learning_rate': 1.8592435466652613e-06, 'rewards/chosen': -0.6401209831237793, 'rewards/rejected': -0.8673430681228638, 'rewards/accuracies': 0.625, 'rewards/margins': 0.22722208499908447, 'policy_logps/rejected': -252.54086303710938, 'policy_logps/chosen': -276.6564025878906, 'referece_logps/rejected': -243.86746215820312, 'referece_logps/chosen': -270.25518798828125, 'logits/rejected': -0.398803174495697, 'logits/chosen': -0.3325502276420593, 'epoch': 1.18}

 20%|█▉        | 3155/16104 [14:41:34<70:07:36, 19.50s/it]

 20%|█▉        | 3156/16104 [14:41:48<64:35:47, 17.96s/it]

 20%|█▉        | 3157/16104 [14:42:08<66:53:10, 18.60s/it]


 20%|█▉        | 3159/16104 [14:42:39<60:32:22, 16.84s/it]
{'loss': 0.4614, 'learning_rate': 1.8587286646766094e-06, 'rewards/chosen': -0.7094627022743225, 'rewards/rejected': -1.4846110343933105, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7751482725143433, 'policy_logps/rejected': -329.2098388671875, 'policy_logps/chosen': -391.75482177734375, 'referece_logps/rejected': -314.36376953125, 'referece_logps/chosen': -384.6601257324219, 'logits/rejected': -0.6787394881248474, 'logits/chosen': -0.4855934977531433, 'epoch': 1.18}


 20%|█▉        | 3161/16104 [14:43:11<59:31:38, 16.56s/it]
{'loss': 0.5085, 'learning_rate': 1.8585224686922314e-06, 'rewards/chosen': -0.5545223355293274, 'rewards/rejected': -1.497259497642517, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9427371025085449, 'policy_logps/rejected': -389.4130554199219, 'policy_logps/chosen': -418.73211669921875, 'referece_logps/rejected': -374.4404296875, 'referece_logps/chosen': -413.1868896484375, 'logits/rejected': 0.08834439516067505, 'logits/chosen': -0.09270866215229034, 'epoch': 1.18}

 20%|█▉        | 3162/16104 [14:43:25<56:11:49, 15.63s/it]

 20%|█▉        | 3163/16104 [14:43:46<62:14:44, 17.32s/it]

 20%|█▉        | 3164/16104 [14:44:01<59:29:07, 16.55s/it]

 20%|█▉        | 3165/16104 [14:44:20<62:08:00, 17.29s/it]

 20%|█▉        | 3166/16104 [14:44:42<67:35:00, 18.81s/it]

 20%|█▉        | 3167/16104 [14:44:55<61:06:48, 17.01s/it]


 20%|█▉        | 3169/16104 [14:45:21<53:15:04, 14.82s/it]

 20%|█▉        | 3170/16104 [14:45:36<52:34:32, 14.63s/it]
{'loss': 0.5313, 'learning_rate': 1.8575928681708573e-06, 'rewards/chosen': -0.3291434347629547, 'rewards/rejected': -1.489587426185608, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1604440212249756, 'policy_logps/rejected': -389.5582275390625, 'policy_logps/chosen': -369.426025390625, 'referece_logps/rejected': -374.662353515625, 'referece_logps/chosen': -366.13458251953125, 'logits/rejected': -0.3087503910064697, 'logits/chosen': -0.42926299571990967, 'epoch': 1.18}

 20%|█▉        | 3171/16104 [14:45:48<50:29:44, 14.06s/it]


 20%|█▉        | 3173/16104 [14:46:18<52:37:02, 14.65s/it]
{'loss': 0.6439, 'learning_rate': 1.8572823767389725e-06, 'rewards/chosen': -0.7671623229980469, 'rewards/rejected': -0.8592087030410767, 'rewards/accuracies': 0.5, 'rewards/margins': 0.09204638004302979, 'policy_logps/rejected': -339.0899963378906, 'policy_logps/chosen': -392.2950134277344, 'referece_logps/rejected': -330.4978942871094, 'referece_logps/chosen': -384.6233825683594, 'logits/rejected': -0.31646865606307983, 'logits/chosen': -0.24657964706420898, 'epoch': 1.18}

 20%|█▉        | 3174/16104 [14:46:38<58:49:34, 16.38s/it]

 20%|█▉        | 3175/16104 [14:46:54<58:04:55, 16.17s/it]


 20%|█▉        | 3177/16104 [14:47:34<63:50:33, 17.78s/it]
{'loss': 0.5909, 'learning_rate': 1.856867902682266e-06, 'rewards/chosen': -0.7954380512237549, 'rewards/rejected': -1.6677110195159912, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8722731471061707, 'policy_logps/rejected': -357.378173828125, 'policy_logps/chosen': -357.132080078125, 'referece_logps/rejected': -340.7010803222656, 'referece_logps/chosen': -349.1777038574219, 'logits/rejected': -0.28003185987472534, 'logits/chosen': -0.18615944683551788, 'epoch': 1.18}

 20%|█▉        | 3178/16104 [14:47:54<66:33:40, 18.54s/it]

 20%|█▉        | 3179/16104 [14:48:05<58:07:02, 16.19s/it]

 20%|█▉        | 3180/16104 [14:48:25<62:49:22, 17.50s/it]

 20%|█▉        | 3181/16104 [14:48:38<58:04:45, 16.18s/it]

 20%|█▉        | 3182/16104 [14:48:54<57:38:53, 16.06s/it]

 20%|█▉        | 3183/16104 [14:49:07<54:28:29, 15.18s/it]


 20%|█▉        | 3185/16104 [14:49:50<65:43:23, 18.31s/it]
{'loss': 0.5147, 'learning_rate': 1.85603729106944e-06, 'rewards/chosen': -0.8878549337387085, 'rewards/rejected': -1.2497053146362305, 'rewards/accuracies': 0.5, 'rewards/margins': 0.361850380897522, 'policy_logps/rejected': -293.0103759765625, 'policy_logps/chosen': -476.51214599609375, 'referece_logps/rejected': -280.5133361816406, 'referece_logps/chosen': -467.6335754394531, 'logits/rejected': -0.6509388089179993, 'logits/chosen': -0.6078066229820251, 'epoch': 1.19}

 20%|█▉        | 3186/16104 [14:50:03<60:33:48, 16.88s/it]

 20%|█▉        | 3187/16104 [14:50:23<63:27:10, 17.68s/it]


 20%|█▉        | 3189/16104 [14:50:56<60:18:57, 16.81s/it]
{'loss': 0.5712, 'learning_rate': 1.8556211540509161e-06, 'rewards/chosen': -0.8004633188247681, 'rewards/rejected': -1.7816283702850342, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9811651110649109, 'policy_logps/rejected': -260.0771179199219, 'policy_logps/chosen': -254.11871337890625, 'referece_logps/rejected': -242.26083374023438, 'referece_logps/chosen': -246.1140594482422, 'logits/rejected': -0.8500244617462158, 'logits/chosen': -0.7368418574333191, 'epoch': 1.19}

 20%|█▉        | 3190/16104 [14:51:07<54:14:04, 15.12s/it]

 20%|█▉        | 3191/16104 [14:51:19<51:25:49, 14.34s/it]

 20%|█▉        | 3192/16104 [14:51:41<59:32:14, 16.60s/it]

 20%|█▉        | 3193/16104 [14:52:01<63:06:46, 17.60s/it]

 20%|█▉        | 3194/16104 [14:52:15<59:10:46, 16.50s/it]

 20%|█▉        | 3195/16104 [14:52:31<58:49:06, 16.40s/it]

 20%|█▉        | 3196/16104 [14:52:52<63:04:07, 17.59s/it]

 20%|█▉        | 3197/16104 [14:53:07<60:14:57, 16.80s/it]

 20%|█▉        | 3198/16104 [14:53:29<65:47:04, 18.35s/it]

 20%|█▉        | 3199/16104 [14:53:45<63:29:01, 17.71s/it]

 20%|█▉        | 3200/16104 [14:54:07<67:39:21, 18.87s/it]


 20%|█▉        | 3202/16104 [14:54:40<64:33:48, 18.01s/it]
{'loss': 0.5197, 'learning_rate': 1.8542648855784386e-06, 'rewards/chosen': -0.5318688154220581, 'rewards/rejected': -2.0101704597473145, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4783016443252563, 'policy_logps/rejected': -400.70721435546875, 'policy_logps/chosen': -376.5736083984375, 'referece_logps/rejected': -380.60552978515625, 'referece_logps/chosen': -371.25494384765625, 'logits/rejected': -0.3259485363960266, 'logits/chosen': -0.2168988734483719, 'epoch': 1.19}

 20%|█▉        | 3203/16104 [14:54:57<62:50:06, 17.53s/it]

 20%|█▉        | 3204/16104 [14:55:17<65:31:27, 18.29s/it]

 20%|█▉        | 3205/16104 [14:55:27<57:31:44, 16.06s/it]

 20%|█▉        | 3206/16104 [14:55:44<57:52:16, 16.15s/it]

 20%|█▉        | 3207/16104 [14:56:05<63:10:55, 17.64s/it]

 20%|█▉        | 3208/16104 [14:56:21<61:59:52, 17.31s/it]


 20%|█▉        | 3210/16104 [14:56:44<51:02:34, 14.25s/it]
{'loss': 0.5995, 'learning_rate': 1.853427355486007e-06, 'rewards/chosen': -0.5878764986991882, 'rewards/rejected': -1.1228570938110352, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5349805951118469, 'policy_logps/rejected': -368.54541015625, 'policy_logps/chosen': -541.860595703125, 'referece_logps/rejected': -357.31683349609375, 'referece_logps/chosen': -535.9818725585938, 'logits/rejected': -0.389640748500824, 'logits/chosen': -0.47914251685142517, 'epoch': 1.2}

 20%|█▉        | 3211/16104 [14:56:56<47:59:51, 13.40s/it]

 20%|█▉        | 3212/16104 [14:57:16<55:18:24, 15.44s/it]

 20%|█▉        | 3213/16104 [14:57:34<57:58:18, 16.19s/it]

 20%|█▉        | 3214/16104 [14:57:54<62:26:30, 17.44s/it]

 20%|█▉        | 3215/16104 [14:58:10<60:20:31, 16.85s/it]

 20%|█▉        | 3216/16104 [14:58:21<54:13:24, 15.15s/it]


 20%|█▉        | 3218/16104 [14:58:56<60:56:53, 17.03s/it]
{'loss': 0.5462, 'learning_rate': 1.8525876159438396e-06, 'rewards/chosen': -1.1228692531585693, 'rewards/rejected': -1.7028272151947021, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5799578428268433, 'policy_logps/rejected': -322.3518981933594, 'policy_logps/chosen': -307.0265197753906, 'referece_logps/rejected': -305.3236389160156, 'referece_logps/chosen': -295.7978210449219, 'logits/rejected': 0.1669474095106125, 'logits/chosen': 0.05609874427318573, 'epoch': 1.2}

 20%|█▉        | 3219/16104 [14:59:17<65:10:50, 18.21s/it]

 20%|█▉        | 3220/16104 [14:59:32<60:45:16, 16.98s/it]


 20%|██        | 3222/16104 [15:00:04<59:40:56, 16.68s/it]
{'loss': 0.5378, 'learning_rate': 1.8521669183082604e-06, 'rewards/chosen': -0.9251686334609985, 'rewards/rejected': -2.1638476848602295, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2386789321899414, 'policy_logps/rejected': -485.9671630859375, 'policy_logps/chosen': -402.17242431640625, 'referece_logps/rejected': -464.32867431640625, 'referece_logps/chosen': -392.9206848144531, 'logits/rejected': -0.8967443108558655, 'logits/chosen': -1.0071626901626587, 'epoch': 1.2}

 20%|██        | 3223/16104 [15:00:27<65:47:39, 18.39s/it]

 20%|██        | 3224/16104 [15:00:42<62:39:33, 17.51s/it]


 20%|██        | 3226/16104 [15:01:18<64:12:42, 17.95s/it]
{'loss': 0.4707, 'learning_rate': 1.8517456691259485e-06, 'rewards/chosen': -0.8149519562721252, 'rewards/rejected': -1.4574860334396362, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6425340175628662, 'policy_logps/rejected': -368.74273681640625, 'policy_logps/chosen': -213.59934997558594, 'referece_logps/rejected': -354.1678771972656, 'referece_logps/chosen': -205.44984436035156, 'logits/rejected': -0.42063894867897034, 'logits/chosen': -0.4595896303653717, 'epoch': 1.2}

 20%|██        | 3227/16104 [15:01:31<58:15:14, 16.29s/it]

 20%|██        | 3228/16104 [15:01:46<56:41:08, 15.85s/it]

 20%|██        | 3229/16104 [15:02:01<56:27:30, 15.79s/it]

 20%|██        | 3230/16104 [15:02:22<61:22:45, 17.16s/it]

 20%|██        | 3231/16104 [15:02:39<62:00:18, 17.34s/it]

 20%|██        | 3232/16104 [15:02:57<62:03:37, 17.36s/it]


 20%|██        | 3234/16104 [15:03:25<55:02:34, 15.40s/it]

 20%|██        | 3235/16104 [15:03:45<59:52:37, 16.75s/it]
{'loss': 0.6796, 'learning_rate': 1.850795843285797e-06, 'rewards/chosen': -1.1436721086502075, 'rewards/rejected': -1.516953945159912, 'rewards/accuracies': 0.5, 'rewards/margins': 0.37328195571899414, 'policy_logps/rejected': -456.07965087890625, 'policy_logps/chosen': -506.03521728515625, 'referece_logps/rejected': -440.9101257324219, 'referece_logps/chosen': -494.59844970703125, 'logits/rejected': -0.04484667629003525, 'logits/chosen': -0.18229712545871735, 'epoch': 1.21}

 20%|██        | 3236/16104 [15:03:58<56:22:15, 15.77s/it]

 20%|██        | 3237/16104 [15:04:12<54:27:19, 15.24s/it]

 20%|██        | 3238/16104 [15:04:28<55:26:00, 15.51s/it]

 20%|██        | 3239/16104 [15:04:42<53:48:28, 15.06s/it]

 20%|██        | 3240/16104 [15:04:55<50:44:37, 14.20s/it]

 20%|██        | 3241/16104 [15:05:14<56:25:06, 15.79s/it]

 20%|██        | 3242/16104 [15:05:30<57:07:01, 15.99s/it]

 20%|██        | 3243/16104 [15:05:48<58:17:40, 16.32s/it]

 20%|██        | 3244/16104 [15:06:08<63:11:11, 17.69s/it]

 20%|██        | 3245/16104 [15:06:26<62:52:00, 17.60s/it]

 20%|██        | 3246/16104 [15:06:43<62:47:48, 17.58s/it]

 20%|██        | 3247/16104 [15:07:07<69:10:12, 19.37s/it]

 20%|██        | 3248/16104 [15:07:27<69:26:42, 19.45s/it]

 20%|██        | 3249/16104 [15:07:43<66:29:42, 18.62s/it]

 20%|██        | 3250/16104 [15:08:03<67:34:26, 18.93s/it]

 20%|██        | 3251/16104 [15:08:18<63:51:29, 17.89s/it]

 20%|██        | 3252/16104 [15:08:38<65:46:42, 18.43s/it]

 20%|██        | 3253/16104 [15:08:51<60:18:45, 16.90s/it]


 20%|██        | 3255/16104 [15:09:34<69:04:26, 19.35s/it]

 20%|██        | 3256/16104 [15:09:52<67:46:26, 18.99s/it]

 20%|██        | 3257/16104 [15:10:04<60:10:34, 16.86s/it]

 20%|██        | 3258/16104 [15:10:21<59:49:29, 16.77s/it]

 20%|██        | 3259/16104 [15:10:40<62:45:27, 17.59s/it]

 20%|██        | 3260/16104 [15:10:52<56:40:35, 15.89s/it]
{'loss': 0.5006, 'learning_rate': 1.8481428209995218e-06, 'rewards/chosen': -1.0381872653961182, 'rewards/rejected': -1.6254889965057373, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5873016715049744, 'policy_logps/rejected': -356.132080078125, 'policy_logps/chosen': -261.75714111328125, 'referece_logps/rejected': -339.87713623046875, 'referece_logps/chosen': -251.37527465820312, 'logits/rejected': -0.8873624801635742, 'logits/chosen': -0.7489114999771118, 'epoch': 1.21}

 20%|██        | 3261/16104 [15:11:03<51:38:25, 14.48s/it]


 20%|██        | 3263/16104 [15:11:36<56:11:29, 15.75s/it]

 20%|██        | 3264/16104 [15:11:57<61:39:27, 17.29s/it]

 20%|██        | 3265/16104 [15:12:17<64:55:28, 18.20s/it]

 20%|██        | 3266/16104 [15:12:37<66:40:45, 18.70s/it]
{'loss': 0.556, 'learning_rate': 1.8475029023908018e-06, 'rewards/chosen': -1.0379035472869873, 'rewards/rejected': -2.0255889892578125, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9876852631568909, 'policy_logps/rejected': -469.8565673828125, 'policy_logps/chosen': -398.4718933105469, 'referece_logps/rejected': -449.6007385253906, 'referece_logps/chosen': -388.09283447265625, 'logits/rejected': -0.7830041646957397, 'logits/chosen': -0.7215433120727539, 'epoch': 1.22}

 20%|██        | 3267/16104 [15:12:51<62:13:41, 17.45s/it]


 20%|██        | 3269/16104 [15:13:22<58:42:26, 16.47s/it]

 20%|██        | 3270/16104 [15:13:35<55:17:23, 15.51s/it]

 20%|██        | 3271/16104 [15:13:47<51:23:39, 14.42s/it]

 20%|██        | 3272/16104 [15:13:59<48:18:17, 13.55s/it]

 20%|██        | 3273/16104 [15:14:14<49:55:03, 14.01s/it]

 20%|██        | 3274/16104 [15:14:35<57:20:15, 16.09s/it]

 20%|██        | 3275/16104 [15:14:52<58:59:09, 16.55s/it]

 20%|██        | 3276/16104 [15:15:12<62:09:33, 17.44s/it]

 20%|██        | 3277/16104 [15:15:29<61:48:21, 17.35s/it]

 20%|██        | 3278/16104 [15:15:44<59:12:35, 16.62s/it]
{'loss': 0.5788, 'learning_rate': 1.846219363542972e-06, 'rewards/chosen': -0.7686726450920105, 'rewards/rejected': -1.5542986392974854, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7856258749961853, 'policy_logps/rejected': -483.05780029296875, 'policy_logps/chosen': -372.1669006347656, 'referece_logps/rejected': -467.5147705078125, 'referece_logps/chosen': -364.4801940917969, 'logits/rejected': -0.7114337682723999, 'logits/chosen': -0.5325640439987183, 'epoch': 1.22}


 20%|██        | 3280/16104 [15:16:21<63:10:27, 17.73s/it]

 20%|██        | 3281/16104 [15:16:41<65:41:23, 18.44s/it]
{'loss': 0.4623, 'learning_rate': 1.8458977083393222e-06, 'rewards/chosen': -0.7280105352401733, 'rewards/rejected': -1.4826561212539673, 'rewards/accuracies': 0.75, 'rewards/margins': 0.754645586013794, 'policy_logps/rejected': -403.30035400390625, 'policy_logps/chosen': -347.6132507324219, 'referece_logps/rejected': -388.47381591796875, 'referece_logps/chosen': -340.3331604003906, 'logits/rejected': 0.0025252997875213623, 'logits/chosen': 0.10842093080282211, 'epoch': 1.22}


 20%|██        | 3283/16104 [15:17:07<56:32:11, 15.87s/it]

 20%|██        | 3284/16104 [15:17:24<57:37:02, 16.18s/it]

 20%|██        | 3285/16104 [15:17:41<58:35:04, 16.45s/it]

 20%|██        | 3286/16104 [15:17:59<59:20:02, 16.66s/it]

 20%|██        | 3287/16104 [15:18:17<61:34:11, 17.29s/it]

 20%|██        | 3288/16104 [15:18:37<63:50:14, 17.93s/it]

 20%|██        | 3289/16104 [15:18:56<65:36:11, 18.43s/it]
{'loss': 0.5532, 'learning_rate': 1.8450384558528844e-06, 'rewards/chosen': -0.6802474856376648, 'rewards/rejected': -1.6998647451400757, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0196171998977661, 'policy_logps/rejected': -463.35321044921875, 'policy_logps/chosen': -439.7833557128906, 'referece_logps/rejected': -446.3545837402344, 'referece_logps/chosen': -432.98089599609375, 'logits/rejected': 0.2507372200489044, 'logits/chosen': 0.3225440979003906, 'epoch': 1.23}


 20%|██        | 3291/16104 [15:19:32<64:55:24, 18.24s/it]

 20%|██        | 3292/16104 [15:19:48<61:41:25, 17.33s/it]

 20%|██        | 3293/16104 [15:20:01<57:18:13, 16.10s/it]

 20%|██        | 3294/16104 [15:20:22<63:00:41, 17.71s/it]
{'loss': 0.5771, 'learning_rate': 1.8445003119499668e-06, 'rewards/chosen': -0.7842128872871399, 'rewards/rejected': -1.6488242149353027, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8646112680435181, 'policy_logps/rejected': -311.641357421875, 'policy_logps/chosen': -261.3055419921875, 'referece_logps/rejected': -295.1531677246094, 'referece_logps/chosen': -253.46339416503906, 'logits/rejected': -0.02633838728070259, 'logits/chosen': -0.02680489420890808, 'epoch': 1.23}


 20%|██        | 3296/16104 [15:20:59<63:50:48, 17.95s/it]

 20%|██        | 3297/16104 [15:21:14<60:26:39, 16.99s/it]
{'loss': 0.676, 'learning_rate': 1.8441770156348476e-06, 'rewards/chosen': -0.9597698450088501, 'rewards/rejected': -1.1941719055175781, 'rewards/accuracies': 0.625, 'rewards/margins': 0.23440207540988922, 'policy_logps/rejected': -572.9611206054688, 'policy_logps/chosen': -500.0144958496094, 'referece_logps/rejected': -561.0194091796875, 'referece_logps/chosen': -490.4168395996094, 'logits/rejected': 0.24082382023334503, 'logits/chosen': 0.25147247314453125, 'epoch': 1.23}


 20%|██        | 3299/16104 [15:21:45<58:24:35, 16.42s/it]

 20%|██        | 3300/16104 [15:21:56<52:21:25, 14.72s/it]

 20%|██        | 3301/16104 [15:22:12<54:17:31, 15.27s/it]

 21%|██        | 3302/16104 [15:22:32<59:22:49, 16.70s/it]

 21%|██        | 3303/16104 [15:22:48<58:33:39, 16.47s/it]
{'loss': 0.4768, 'learning_rate': 1.843529501113846e-06, 'rewards/chosen': -0.8956893086433411, 'rewards/rejected': -1.6498421430587769, 'rewards/accuracies': 0.875, 'rewards/margins': 0.754152774810791, 'policy_logps/rejected': -315.2908020019531, 'policy_logps/chosen': -261.5422668457031, 'referece_logps/rejected': -298.7923889160156, 'referece_logps/chosen': -252.5854034423828, 'logits/rejected': -0.7367687821388245, 'logits/chosen': -0.6731778979301453, 'epoch': 1.23}


 21%|██        | 3305/16104 [15:23:31<67:49:08, 19.08s/it]

 21%|██        | 3306/16104 [15:23:46<63:01:18, 17.73s/it]
{'loss': 0.5012, 'learning_rate': 1.8432052831437019e-06, 'rewards/chosen': -0.6622600555419922, 'rewards/rejected': -1.5283739566802979, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8661137819290161, 'policy_logps/rejected': -305.2546081542969, 'policy_logps/chosen': -348.38482666015625, 'referece_logps/rejected': -289.9708557128906, 'referece_logps/chosen': -341.7622375488281, 'logits/rejected': -0.44536107778549194, 'logits/chosen': -0.4370821714401245, 'epoch': 1.23}

 21%|██        | 3307/16104 [15:24:00<59:44:57, 16.81s/it]


 21%|██        | 3309/16104 [15:24:39<63:38:47, 17.91s/it]
{'loss': 0.5052, 'learning_rate': 1.8428807581911404e-06, 'rewards/chosen': -0.857326328754425, 'rewards/rejected': -1.7680175304412842, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9106911420822144, 'policy_logps/rejected': -369.15057373046875, 'policy_logps/chosen': -344.8575744628906, 'referece_logps/rejected': -351.47039794921875, 'referece_logps/chosen': -336.2843322753906, 'logits/rejected': -1.046112298965454, 'logits/chosen': -1.2155169248580933, 'epoch': 1.23}

 21%|██        | 3310/16104 [15:24:56<62:54:27, 17.70s/it]


 21%|██        | 3312/16104 [15:25:21<53:49:50, 15.15s/it]

 21%|██        | 3313/16104 [15:25:33<50:15:07, 14.14s/it]

 21%|██        | 3314/16104 [15:25:50<52:34:56, 14.80s/it]

 21%|██        | 3315/16104 [15:26:03<51:31:39, 14.50s/it]

 21%|██        | 3316/16104 [15:26:25<58:39:36, 16.51s/it]

 21%|██        | 3317/16104 [15:26:39<56:50:04, 16.00s/it]

 21%|██        | 3318/16104 [15:26:59<60:42:12, 17.09s/it]

 21%|██        | 3319/16104 [15:27:17<61:20:26, 17.27s/it]

 21%|██        | 3320/16104 [15:27:33<60:02:16, 16.91s/it]

 21%|██        | 3321/16104 [15:27:53<63:38:06, 17.92s/it]

 21%|██        | 3322/16104 [15:28:10<62:36:02, 17.63s/it]

 21%|██        | 3323/16104 [15:28:26<60:28:05, 17.03s/it]

 21%|██        | 3324/16104 [15:28:43<60:27:46, 17.03s/it]

 21%|██        | 3325/16104 [15:28:57<57:29:10, 16.19s/it]

 21%|██        | 3326/16104 [15:29:15<59:34:57, 16.79s/it]

 21%|██        | 3327/16104 [15:29:28<55:14:06, 15.56s/it]
{'loss': 0.606, 'learning_rate': 1.8409271684691437e-06, 'rewards/chosen': -0.41103917360305786, 'rewards/rejected': -0.8008831143379211, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3898439407348633, 'policy_logps/rejected': -397.04376220703125, 'policy_logps/chosen': -432.2826843261719, 'referece_logps/rejected': -389.0349426269531, 'referece_logps/chosen': -428.17230224609375, 'logits/rejected': -0.15054437518119812, 'logits/chosen': -0.200544536113739, 'epoch': 1.24}


 21%|██        | 3329/16104 [15:30:02<59:24:18, 16.74s/it]

 21%|██        | 3330/16104 [15:30:22<62:30:25, 17.62s/it]

 21%|██        | 3331/16104 [15:30:40<63:13:54, 17.82s/it]
{'loss': 0.486, 'learning_rate': 1.8404915397689277e-06, 'rewards/chosen': -0.7953945994377136, 'rewards/rejected': -1.47203528881073, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6766408681869507, 'policy_logps/rejected': -273.0362548828125, 'policy_logps/chosen': -258.44073486328125, 'referece_logps/rejected': -258.3158874511719, 'referece_logps/chosen': -250.48678588867188, 'logits/rejected': -0.5189955234527588, 'logits/chosen': -0.5068828463554382, 'epoch': 1.24}


 21%|██        | 3333/16104 [15:31:24<70:30:09, 19.87s/it]
{'loss': 0.454, 'learning_rate': 1.8402735214048987e-06, 'rewards/chosen': -0.9499120116233826, 'rewards/rejected': -1.6573593616485596, 'rewards/accuracies': 0.75, 'rewards/margins': 0.707447350025177, 'policy_logps/rejected': -333.1622314453125, 'policy_logps/chosen': -322.6261291503906, 'referece_logps/rejected': -316.588623046875, 'referece_logps/chosen': -313.12701416015625, 'logits/rejected': -0.20623879134655, 'logits/chosen': -0.1531987339258194, 'epoch': 1.24}

 21%|██        | 3334/16104 [15:31:47<73:44:17, 20.79s/it]


 21%|██        | 3336/16104 [15:32:26<71:13:44, 20.08s/it]

 21%|██        | 3337/16104 [15:32:38<62:57:33, 17.75s/it]

 21%|██        | 3338/16104 [15:32:51<58:16:49, 16.44s/it]

 21%|██        | 3339/16104 [15:33:07<57:30:55, 16.22s/it]

 21%|██        | 3340/16104 [15:33:28<62:13:50, 17.55s/it]

 21%|██        | 3341/16104 [15:33:48<65:17:04, 18.41s/it]

 21%|██        | 3342/16104 [15:34:07<65:42:48, 18.54s/it]

 21%|██        | 3343/16104 [15:34:24<63:31:05, 17.92s/it]

 21%|██        | 3344/16104 [15:34:35<56:49:03, 16.03s/it]

 21%|██        | 3345/16104 [15:34:52<57:41:38, 16.28s/it]

 21%|██        | 3346/16104 [15:35:12<61:14:21, 17.28s/it]

 21%|██        | 3347/16104 [15:35:27<59:24:17, 16.76s/it]
{'loss': 0.4577, 'learning_rate': 1.838743587891912e-06, 'rewards/chosen': -0.6188483834266663, 'rewards/rejected': -1.1750935316085815, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5562450885772705, 'policy_logps/rejected': -260.5384521484375, 'policy_logps/chosen': -468.3838806152344, 'referece_logps/rejected': -248.7875213623047, 'referece_logps/chosen': -462.1954040527344, 'logits/rejected': -0.5083650350570679, 'logits/chosen': -0.33411216735839844, 'epoch': 1.25}


 21%|██        | 3349/16104 [15:35:56<55:15:37, 15.60s/it]

 21%|██        | 3350/16104 [15:36:16<59:30:26, 16.80s/it]

 21%|██        | 3351/16104 [15:36:34<61:23:26, 17.33s/it]

 21%|██        | 3352/16104 [15:36:54<64:35:16, 18.23s/it]

 21%|██        | 3353/16104 [15:37:06<57:59:47, 16.37s/it]

 21%|██        | 3354/16104 [15:37:22<57:35:38, 16.26s/it]
{'loss': 0.565, 'learning_rate': 1.8379761266192607e-06, 'rewards/chosen': -0.4460170865058899, 'rewards/rejected': -2.0371687412261963, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5911517143249512, 'policy_logps/rejected': -344.881591796875, 'policy_logps/chosen': -557.8358154296875, 'referece_logps/rejected': -324.5098876953125, 'referece_logps/chosen': -553.3756103515625, 'logits/rejected': -0.8637272119522095, 'logits/chosen': -1.0808470249176025, 'epoch': 1.25}


 21%|██        | 3356/16104 [15:37:50<53:30:13, 15.11s/it]

 21%|██        | 3357/16104 [15:38:05<53:44:00, 15.18s/it]

 21%|██        | 3358/16104 [15:38:22<54:45:40, 15.47s/it]

 21%|██        | 3359/16104 [15:38:40<58:02:18, 16.39s/it]

 21%|██        | 3360/16104 [15:38:51<51:59:42, 14.69s/it]

 21%|██        | 3361/16104 [15:39:11<57:41:24, 16.30s/it]
{'loss': 0.6615, 'learning_rate': 1.8372070043630239e-06, 'rewards/chosen': -1.384793996810913, 'rewards/rejected': -1.4599140882492065, 'rewards/accuracies': 0.625, 'rewards/margins': 0.07511994242668152, 'policy_logps/rejected': -347.6266174316406, 'policy_logps/chosen': -418.0354309082031, 'referece_logps/rejected': -333.0274658203125, 'referece_logps/chosen': -404.1875, 'logits/rejected': -0.006435208022594452, 'logits/chosen': -0.08126914501190186, 'epoch': 1.25}


 21%|██        | 3363/16104 [15:39:49<63:19:00, 17.89s/it]
{'loss': 0.5533, 'learning_rate': 1.8369869502815983e-06, 'rewards/chosen': -1.2727550268173218, 'rewards/rejected': -1.3413065671920776, 'rewards/accuracies': 0.375, 'rewards/margins': 0.06855139136314392, 'policy_logps/rejected': -433.5089111328125, 'policy_logps/chosen': -400.6479187011719, 'referece_logps/rejected': -420.0958557128906, 'referece_logps/chosen': -387.92034912109375, 'logits/rejected': -0.43156880140304565, 'logits/chosen': -0.3506371080875397, 'epoch': 1.25}


 21%|██        | 3365/16104 [15:40:17<55:37:50, 15.72s/it]

 21%|██        | 3366/16104 [15:40:34<57:35:18, 16.28s/it]
{'loss': 0.4891, 'learning_rate': 1.836656615238477e-06, 'rewards/chosen': -1.710831880569458, 'rewards/rejected': -2.8457326889038086, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1349010467529297, 'policy_logps/rejected': -405.79949951171875, 'policy_logps/chosen': -411.8143005371094, 'referece_logps/rejected': -377.3421936035156, 'referece_logps/chosen': -394.7059631347656, 'logits/rejected': -0.8029722571372986, 'logits/chosen': -0.6949446797370911, 'epoch': 1.25}

 21%|██        | 3367/16104 [15:40:54<61:13:23, 17.30s/it]

 21%|██        | 3368/16104 [15:41:06<55:16:29, 15.62s/it]

 21%|██        | 3369/16104 [15:41:28<62:29:42, 17.67s/it]

 21%|██        | 3370/16104 [15:41:46<62:24:07, 17.64s/it]


 21%|██        | 3372/16104 [15:42:23<64:57:32, 18.37s/it]

 21%|██        | 3373/16104 [15:42:42<66:07:42, 18.70s/it]

 21%|██        | 3374/16104 [15:42:57<61:36:01, 17.42s/it]

 21%|██        | 3375/16104 [15:43:17<64:44:06, 18.31s/it]
{'loss': 0.4771, 'learning_rate': 1.8356637830011057e-06, 'rewards/chosen': -0.8459103107452393, 'rewards/rejected': -1.9183982610702515, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0724878311157227, 'policy_logps/rejected': -224.44410705566406, 'policy_logps/chosen': -255.5545196533203, 'referece_logps/rejected': -205.26011657714844, 'referece_logps/chosen': -247.0953826904297, 'logits/rejected': -0.5946397185325623, 'logits/chosen': -0.6629404425621033, 'epoch': 1.26}


 21%|██        | 3377/16104 [15:43:47<60:23:39, 17.08s/it]

 21%|██        | 3378/16104 [15:44:07<63:05:08, 17.85s/it]
{'loss': 0.6296, 'learning_rate': 1.8353322302875976e-06, 'rewards/chosen': -1.0917186737060547, 'rewards/rejected': -1.518391489982605, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4266729950904846, 'policy_logps/rejected': -371.7542419433594, 'policy_logps/chosen': -402.56646728515625, 'referece_logps/rejected': -356.5703125, 'referece_logps/chosen': -391.6492614746094, 'logits/rejected': -0.6971168518066406, 'logits/chosen': -0.6611955165863037, 'epoch': 1.26}


 21%|██        | 3380/16104 [15:44:47<66:50:40, 18.91s/it]
{'loss': 0.5627, 'learning_rate': 1.835111026184411e-06, 'rewards/chosen': -1.5714889764785767, 'rewards/rejected': -2.051129102706909, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4796401858329773, 'policy_logps/rejected': -410.5682373046875, 'policy_logps/chosen': -444.62335205078125, 'referece_logps/rejected': -390.0569763183594, 'referece_logps/chosen': -428.908447265625, 'logits/rejected': -0.31664517521858215, 'logits/chosen': -0.25524699687957764, 'epoch': 1.26}

 21%|██        | 3381/16104 [15:45:08<69:29:02, 19.66s/it]


 21%|██        | 3383/16104 [15:45:49<70:41:21, 20.00s/it]
{'loss': 0.5948, 'learning_rate': 1.8347789666778402e-06, 'rewards/chosen': -1.313215732574463, 'rewards/rejected': -1.3229146003723145, 'rewards/accuracies': 0.25, 'rewards/margins': 0.009698823094367981, 'policy_logps/rejected': -432.982177734375, 'policy_logps/chosen': -447.2935791015625, 'referece_logps/rejected': -419.7530517578125, 'referece_logps/chosen': -434.161376953125, 'logits/rejected': -0.6487345099449158, 'logits/chosen': -0.7014671564102173, 'epoch': 1.26}

 21%|██        | 3384/16104 [15:46:00<61:16:34, 17.34s/it]

 21%|██        | 3385/16104 [15:46:20<64:04:35, 18.14s/it]

 21%|██        | 3386/16104 [15:46:36<61:50:20, 17.50s/it]


 21%|██        | 3388/16104 [15:47:15<65:40:09, 18.59s/it]

 21%|██        | 3389/16104 [15:47:35<66:38:08, 18.87s/it]
{'loss': 0.4764, 'learning_rate': 1.8341139360416563e-06, 'rewards/chosen': -0.7582221031188965, 'rewards/rejected': -1.2865333557128906, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5283112525939941, 'policy_logps/rejected': -383.89508056640625, 'policy_logps/chosen': -404.63433837890625, 'referece_logps/rejected': -371.0296936035156, 'referece_logps/chosen': -397.05218505859375, 'logits/rejected': 0.028040356934070587, 'logits/chosen': 0.09091246128082275, 'epoch': 1.26}

 21%|██        | 3390/16104 [15:47:50<62:47:43, 17.78s/it]


 21%|██        | 3392/16104 [15:48:29<65:41:03, 18.60s/it]

 21%|██        | 3393/16104 [15:48:41<58:37:32, 16.60s/it]

 21%|██        | 3394/16104 [15:48:57<57:52:50, 16.39s/it]
{'loss': 0.5564, 'learning_rate': 1.8335588159153708e-06, 'rewards/chosen': -1.565894603729248, 'rewards/rejected': -2.018312454223633, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4524177312850952, 'policy_logps/rejected': -401.4855651855469, 'policy_logps/chosen': -311.6810302734375, 'referece_logps/rejected': -381.3023986816406, 'referece_logps/chosen': -296.0220642089844, 'logits/rejected': -0.7695841789245605, 'logits/chosen': -0.7377859950065613, 'epoch': 1.26}

 21%|██        | 3395/16104 [15:49:14<58:11:31, 16.48s/it]

 21%|██        | 3396/16104 [15:49:34<61:55:07, 17.54s/it]


 21%|██        | 3398/16104 [15:50:04<56:06:12, 15.90s/it]
{'loss': 0.5067, 'learning_rate': 1.8331141128464674e-06, 'rewards/chosen': -0.2860499620437622, 'rewards/rejected': -1.4705644845962524, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1845145225524902, 'policy_logps/rejected': -386.72552490234375, 'policy_logps/chosen': -353.0628662109375, 'referece_logps/rejected': -372.0198974609375, 'referece_logps/chosen': -350.2023620605469, 'logits/rejected': -0.8183181285858154, 'logits/chosen': -0.7072756290435791, 'epoch': 1.27}

 21%|██        | 3399/16104 [15:50:16<52:13:30, 14.80s/it]


 21%|██        | 3401/16104 [15:50:49<54:51:08, 15.55s/it]
{'loss': 0.5806, 'learning_rate': 1.8327802316690525e-06, 'rewards/chosen': -1.0775622129440308, 'rewards/rejected': -0.9142849445343018, 'rewards/accuracies': 0.5, 'rewards/margins': -0.16327717900276184, 'policy_logps/rejected': -313.33709716796875, 'policy_logps/chosen': -397.05303955078125, 'referece_logps/rejected': -304.1942443847656, 'referece_logps/chosen': -386.27740478515625, 'logits/rejected': -0.25214025378227234, 'logits/chosen': -0.21483583748340607, 'epoch': 1.27}


 21%|██        | 3403/16104 [15:51:15<50:19:22, 14.26s/it]

 21%|██        | 3404/16104 [15:51:33<54:15:03, 15.38s/it]

 21%|██        | 3405/16104 [15:51:45<50:05:24, 14.20s/it]
{'loss': 0.4542, 'learning_rate': 1.8323345851626204e-06, 'rewards/chosen': -0.862973153591156, 'rewards/rejected': -2.004289150238037, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1413158178329468, 'policy_logps/rejected': -361.1234436035156, 'policy_logps/chosen': -291.9635314941406, 'referece_logps/rejected': -341.0805969238281, 'referece_logps/chosen': -283.33380126953125, 'logits/rejected': -1.1984723806381226, 'logits/chosen': -1.0819334983825684, 'epoch': 1.27}


 21%|██        | 3407/16104 [15:52:17<55:15:25, 15.67s/it]
{'loss': 0.4379, 'learning_rate': 1.8321115598748583e-06, 'rewards/chosen': -0.9538062810897827, 'rewards/rejected': -1.5886666774749756, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6348603963851929, 'policy_logps/rejected': -470.0456237792969, 'policy_logps/chosen': -622.8546142578125, 'referece_logps/rejected': -454.15899658203125, 'referece_logps/chosen': -613.3165283203125, 'logits/rejected': -0.37305164337158203, 'logits/chosen': -0.5909299850463867, 'epoch': 1.27}

 21%|██        | 3408/16104 [15:52:40<62:32:57, 17.74s/it]


 21%|██        | 3410/16104 [15:53:11<59:15:42, 16.81s/it]

 21%|██        | 3411/16104 [15:53:25<56:09:44, 15.93s/it]
{'loss': 0.6129, 'learning_rate': 1.8316651054106766e-06, 'rewards/chosen': -1.3057595491409302, 'rewards/rejected': -1.4019200801849365, 'rewards/accuracies': 0.625, 'rewards/margins': 0.09616052359342575, 'policy_logps/rejected': -352.1833801269531, 'policy_logps/chosen': -294.0893859863281, 'referece_logps/rejected': -338.1641845703125, 'referece_logps/chosen': -281.0317687988281, 'logits/rejected': -0.3843703269958496, 'logits/chosen': -0.25482040643692017, 'epoch': 1.27}

 21%|██        | 3412/16104 [15:53:44<59:21:19, 16.84s/it]

 21%|██        | 3413/16104 [15:53:59<56:52:48, 16.13s/it]

 21%|██        | 3414/16104 [15:54:21<63:25:15, 17.99s/it]


 21%|██        | 3416/16104 [15:54:57<63:46:30, 18.10s/it]
{'loss': 0.6482, 'learning_rate': 1.8311062804117872e-06, 'rewards/chosen': -1.2198867797851562, 'rewards/rejected': -1.413879632949829, 'rewards/accuracies': 0.5, 'rewards/margins': 0.19399279356002808, 'policy_logps/rejected': -574.4949340820312, 'policy_logps/chosen': -338.83319091796875, 'referece_logps/rejected': -560.3560791015625, 'referece_logps/chosen': -326.63433837890625, 'logits/rejected': 0.3120670020580292, 'logits/chosen': 0.5007143616676331, 'epoch': 1.27}

 21%|██        | 3417/16104 [15:55:12<60:46:35, 17.25s/it]

 21%|██        | 3418/16104 [15:55:28<59:27:57, 16.88s/it]

 21%|██        | 3419/16104 [15:55:47<61:10:07, 17.36s/it]

 21%|██        | 3420/16104 [15:56:03<59:33:53, 16.91s/it]

 21%|██        | 3421/16104 [15:56:18<58:03:32, 16.48s/it]

 21%|██        | 3422/16104 [15:56:30<53:31:20, 15.19s/it]


 21%|██▏       | 3424/16104 [15:57:02<52:56:01, 15.03s/it]

 21%|██▏       | 3425/16104 [15:57:22<58:30:36, 16.61s/it]

 21%|██▏       | 3426/16104 [15:57:35<55:00:56, 15.62s/it]

 21%|██▏       | 3427/16104 [15:57:53<57:35:59, 16.36s/it]

 21%|██▏       | 3428/16104 [15:58:09<57:05:20, 16.21s/it]

 21%|██▏       | 3429/16104 [15:58:28<59:28:18, 16.89s/it]
{'loss': 0.5025, 'learning_rate': 1.8296494033193528e-06, 'rewards/chosen': -0.9659818410873413, 'rewards/rejected': -1.5230838060379028, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5571019053459167, 'policy_logps/rejected': -258.0582580566406, 'policy_logps/chosen': -448.52569580078125, 'referece_logps/rejected': -242.82742309570312, 'referece_logps/chosen': -438.86590576171875, 'logits/rejected': -0.23468947410583496, 'logits/chosen': -0.07697947323322296, 'epoch': 1.28}


 21%|██▏       | 3431/16104 [15:58:58<55:54:39, 15.88s/it]

 21%|██▏       | 3432/16104 [15:59:18<59:39:15, 16.95s/it]

 21%|██▏       | 3433/16104 [15:59:36<61:01:02, 17.34s/it]
{'loss': 0.5553, 'learning_rate': 1.829199991914804e-06, 'rewards/chosen': -1.0166362524032593, 'rewards/rejected': -1.9068645238876343, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8902282118797302, 'policy_logps/rejected': -433.3983154296875, 'policy_logps/chosen': -487.53802490234375, 'referece_logps/rejected': -414.3296813964844, 'referece_logps/chosen': -477.37164306640625, 'logits/rejected': -0.060537561774253845, 'logits/chosen': 0.15499421954154968, 'epoch': 1.28}

 21%|██▏       | 3434/16104 [15:59:53<61:07:37, 17.37s/it]


 21%|██▏       | 3436/16104 [16:00:27<59:14:52, 16.84s/it]
{'loss': 0.6134, 'learning_rate': 1.8288625811479865e-06, 'rewards/chosen': -1.2410341501235962, 'rewards/rejected': -1.109948754310608, 'rewards/accuracies': 0.5, 'rewards/margins': -0.13108539581298828, 'policy_logps/rejected': -429.76611328125, 'policy_logps/chosen': -301.6955261230469, 'referece_logps/rejected': -418.66656494140625, 'referece_logps/chosen': -289.28515625, 'logits/rejected': -1.1473904848098755, 'logits/chosen': -1.0087299346923828, 'epoch': 1.28}

 21%|██▏       | 3437/16104 [16:00:44<59:22:56, 16.88s/it]

 21%|██▏       | 3438/16104 [16:00:57<54:33:13, 15.51s/it]

 21%|██▏       | 3439/16104 [16:01:17<59:42:26, 16.97s/it]

 21%|██▏       | 3440/16104 [16:01:29<54:23:32, 15.46s/it]

 21%|██▏       | 3441/16104 [16:01:41<50:10:45, 14.27s/it]

 21%|██▏       | 3442/16104 [16:01:57<52:32:23, 14.94s/it]


 21%|██▏       | 3444/16104 [16:02:26<52:22:18, 14.89s/it]
{'loss': 0.5699, 'learning_rate': 1.8279613441624648e-06, 'rewards/chosen': -1.0809460878372192, 'rewards/rejected': -1.0604362487792969, 'rewards/accuracies': 0.5, 'rewards/margins': -0.020509913563728333, 'policy_logps/rejected': -369.51611328125, 'policy_logps/chosen': -279.4769592285156, 'referece_logps/rejected': -358.9117431640625, 'referece_logps/chosen': -268.6675109863281, 'logits/rejected': -0.812836766242981, 'logits/chosen': -0.7308133244514465, 'epoch': 1.28}


 21%|██▏       | 3446/16104 [16:02:58<53:50:48, 15.31s/it]

 21%|██▏       | 3447/16104 [16:03:14<55:16:05, 15.72s/it]

 21%|██▏       | 3448/16104 [16:03:28<52:55:55, 15.06s/it]
{'loss': 0.5553, 'learning_rate': 1.8275099217034985e-06, 'rewards/chosen': -0.9823914170265198, 'rewards/rejected': -0.9119168519973755, 'rewards/accuracies': 0.5, 'rewards/margins': -0.07047461718320847, 'policy_logps/rejected': -312.3765563964844, 'policy_logps/chosen': -335.9249267578125, 'referece_logps/rejected': -303.25738525390625, 'referece_logps/chosen': -326.1009826660156, 'logits/rejected': -0.6175612211227417, 'logits/chosen': -0.6584283113479614, 'epoch': 1.28}


 21%|██▏       | 3450/16104 [16:03:56<52:23:35, 14.91s/it]

 21%|██▏       | 3451/16104 [16:04:08<48:44:39, 13.87s/it]
{'loss': 0.5918, 'learning_rate': 1.8271710033636437e-06, 'rewards/chosen': -0.6063383221626282, 'rewards/rejected': -1.016212821006775, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4098745286464691, 'policy_logps/rejected': -364.8479919433594, 'policy_logps/chosen': -509.5332336425781, 'referece_logps/rejected': -354.68585205078125, 'referece_logps/chosen': -503.4698791503906, 'logits/rejected': -0.7054544687271118, 'logits/chosen': -0.7224322557449341, 'epoch': 1.29}


 21%|██▏       | 3453/16104 [16:04:46<58:40:46, 16.70s/it]
{'loss': 0.5202, 'learning_rate': 1.8269448904934082e-06, 'rewards/chosen': -0.5374603867530823, 'rewards/rejected': -1.2542352676391602, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7167749404907227, 'policy_logps/rejected': -303.8582763671875, 'policy_logps/chosen': -346.8454284667969, 'referece_logps/rejected': -291.31591796875, 'referece_logps/chosen': -341.4707946777344, 'logits/rejected': 0.23051953315734863, 'logits/chosen': 0.2506835460662842, 'epoch': 1.29}


 21%|██▏       | 3455/16104 [16:05:08<48:10:35, 13.71s/it]
{'loss': 0.528, 'learning_rate': 1.826718643817588e-06, 'rewards/chosen': -0.5367885231971741, 'rewards/rejected': -0.8280576467514038, 'rewards/accuracies': 0.5, 'rewards/margins': 0.29126912355422974, 'policy_logps/rejected': -346.06732177734375, 'policy_logps/chosen': -288.4165344238281, 'referece_logps/rejected': -337.7867431640625, 'referece_logps/chosen': -283.04864501953125, 'logits/rejected': -0.6977049708366394, 'logits/chosen': -0.6688019037246704, 'epoch': 1.29}

 21%|██▏       | 3456/16104 [16:05:25<52:17:36, 14.88s/it]

 21%|██▏       | 3457/16104 [16:05:45<57:41:34, 16.42s/it]


 21%|██▏       | 3459/16104 [16:06:18<58:43:50, 16.72s/it]

 21%|██▏       | 3460/16104 [16:06:40<64:33:29, 18.38s/it]

 21%|██▏       | 3461/16104 [16:07:02<68:30:36, 19.51s/it]

 21%|██▏       | 3462/16104 [16:07:18<64:20:10, 18.32s/it]
{'loss': 0.5771, 'learning_rate': 1.8259257272619661e-06, 'rewards/chosen': -0.7544042468070984, 'rewards/rejected': -1.2892589569091797, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5348547101020813, 'policy_logps/rejected': -399.83465576171875, 'policy_logps/chosen': -421.76904296875, 'referece_logps/rejected': -386.9420471191406, 'referece_logps/chosen': -414.2249755859375, 'logits/rejected': -0.2671310305595398, 'logits/chosen': -0.48148471117019653, 'epoch': 1.29}

 22%|██▏       | 3463/16104 [16:07:29<56:55:13, 16.21s/it]


 22%|██▏       | 3465/16104 [16:08:09<63:43:01, 18.15s/it]

 22%|██▏       | 3466/16104 [16:08:26<63:14:20, 18.01s/it]

 22%|██▏       | 3467/16104 [16:08:46<65:04:37, 18.54s/it]
{'loss': 0.5814, 'learning_rate': 1.8253583558969706e-06, 'rewards/chosen': -0.8363368511199951, 'rewards/rejected': -1.1028708219528198, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2665339410305023, 'policy_logps/rejected': -271.70355224609375, 'policy_logps/chosen': -321.5726318359375, 'referece_logps/rejected': -260.6748352050781, 'referece_logps/chosen': -313.209228515625, 'logits/rejected': -0.6901496052742004, 'logits/chosen': -0.6526206731796265, 'epoch': 1.29}

 22%|██▏       | 3468/16104 [16:09:02<62:02:48, 17.68s/it]

 22%|██▏       | 3469/16104 [16:09:21<64:10:32, 18.29s/it]

 22%|██▏       | 3470/16104 [16:09:34<57:49:43, 16.48s/it]


 22%|██▏       | 3472/16104 [16:10:09<58:43:01, 16.73s/it]
{'loss': 0.4667, 'learning_rate': 1.8247901498515837e-06, 'rewards/chosen': -0.7488042712211609, 'rewards/rejected': -1.6140258312225342, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8652217388153076, 'policy_logps/rejected': -422.5801086425781, 'policy_logps/chosen': -382.6043701171875, 'referece_logps/rejected': -406.4398498535156, 'referece_logps/chosen': -375.1163330078125, 'logits/rejected': -0.8055328130722046, 'logits/chosen': -0.4629523754119873, 'epoch': 1.29}

 22%|██▏       | 3473/16104 [16:10:29<62:59:03, 17.95s/it]

 22%|██▏       | 3474/16104 [16:10:42<56:59:08, 16.24s/it]


 22%|██▏       | 3476/16104 [16:11:17<58:52:31, 16.78s/it]
{'loss': 0.5327, 'learning_rate': 1.8243349844315115e-06, 'rewards/chosen': -0.8118917346000671, 'rewards/rejected': -1.3500360250473022, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5381442904472351, 'policy_logps/rejected': -418.788818359375, 'policy_logps/chosen': -408.659912109375, 'referece_logps/rejected': -405.2884521484375, 'referece_logps/chosen': -400.5409851074219, 'logits/rejected': -0.28107649087905884, 'logits/chosen': -0.24225090444087982, 'epoch': 1.3}


 22%|██▏       | 3478/16104 [16:11:57<64:17:24, 18.33s/it]
{'loss': 0.4996, 'learning_rate': 1.824107201628133e-06, 'rewards/chosen': -0.9342066049575806, 'rewards/rejected': -1.7428637742996216, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8086572885513306, 'policy_logps/rejected': -442.30987548828125, 'policy_logps/chosen': -454.1716003417969, 'referece_logps/rejected': -424.8812561035156, 'referece_logps/chosen': -444.82952880859375, 'logits/rejected': -0.665679931640625, 'logits/chosen': -0.8084896206855774, 'epoch': 1.3}


 22%|██▏       | 3480/16104 [16:12:33<64:31:16, 18.40s/it]
{'loss': 0.5071, 'learning_rate': 1.8238792854783281e-06, 'rewards/chosen': -0.7038881182670593, 'rewards/rejected': -2.029508590698242, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3256202936172485, 'policy_logps/rejected': -564.5516357421875, 'policy_logps/chosen': -585.5477294921875, 'referece_logps/rejected': -544.256591796875, 'referece_logps/chosen': -578.5088500976562, 'logits/rejected': -0.5060552954673767, 'logits/chosen': -0.40455520153045654, 'epoch': 1.3}


 22%|██▏       | 3482/16104 [16:13:05<59:21:25, 16.93s/it]

 22%|██▏       | 3483/16104 [16:13:23<60:40:36, 17.31s/it]
{'loss': 0.5967, 'learning_rate': 1.823537161309749e-06, 'rewards/chosen': -1.0077277421951294, 'rewards/rejected': -1.4036794900894165, 'rewards/accuracies': 0.625, 'rewards/margins': 0.39595165848731995, 'policy_logps/rejected': -399.0552978515625, 'policy_logps/chosen': -348.97039794921875, 'referece_logps/rejected': -385.0184631347656, 'referece_logps/chosen': -338.89312744140625, 'logits/rejected': -0.3781314194202423, 'logits/chosen': -0.3073092997074127, 'epoch': 1.3}


 22%|██▏       | 3485/16104 [16:14:03<65:32:01, 18.70s/it]
{'loss': 0.5578, 'learning_rate': 1.8233089119552687e-06, 'rewards/chosen': -1.18375825881958, 'rewards/rejected': -1.8665730953216553, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6828146576881409, 'policy_logps/rejected': -487.79412841796875, 'policy_logps/chosen': -482.3949279785156, 'referece_logps/rejected': -469.12841796875, 'referece_logps/chosen': -470.55731201171875, 'logits/rejected': 0.0210503488779068, 'logits/chosen': 0.08426034450531006, 'epoch': 1.3}

 22%|██▏       | 3486/16104 [16:14:25<69:05:26, 19.71s/it]

 22%|██▏       | 3487/16104 [16:14:41<64:32:57, 18.42s/it]

 22%|██▏       | 3488/16104 [16:14:55<59:52:28, 17.09s/it]

 22%|██▏       | 3489/16104 [16:15:08<55:37:32, 15.87s/it]

 22%|██▏       | 3490/16104 [16:15:28<60:18:39, 17.21s/it]


 22%|██▏       | 3492/16104 [16:16:01<58:06:18, 16.59s/it]

 22%|██▏       | 3493/16104 [16:16:21<61:35:14, 17.58s/it]

 22%|██▏       | 3494/16104 [16:16:43<66:24:12, 18.96s/it]
{'loss': 0.5307, 'learning_rate': 1.8222801418302648e-06, 'rewards/chosen': -0.7827039957046509, 'rewards/rejected': -1.0771762132644653, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2944721281528473, 'policy_logps/rejected': -481.92620849609375, 'policy_logps/chosen': -310.27978515625, 'referece_logps/rejected': -471.1544189453125, 'referece_logps/chosen': -302.4527587890625, 'logits/rejected': 0.7142853736877441, 'logits/chosen': 0.789567232131958, 'epoch': 1.3}

 22%|██▏       | 3495/16104 [16:17:00<64:01:50, 18.28s/it]


 22%|██▏       | 3497/16104 [16:17:39<66:31:05, 18.99s/it]
{'loss': 0.4779, 'learning_rate': 1.8219366195601247e-06, 'rewards/chosen': -1.4301369190216064, 'rewards/rejected': -1.8352348804473877, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4050980508327484, 'policy_logps/rejected': -231.6107177734375, 'policy_logps/chosen': -277.0156555175781, 'referece_logps/rejected': -213.25839233398438, 'referece_logps/chosen': -262.71429443359375, 'logits/rejected': -0.6188753843307495, 'logits/chosen': -0.7561741471290588, 'epoch': 1.3}

 22%|██▏       | 3498/16104 [16:17:53<60:43:13, 17.34s/it]


 22%|██▏       | 3500/16104 [16:18:33<65:58:57, 18.85s/it]
{'loss': 0.4483, 'learning_rate': 1.8215927980507656e-06, 'rewards/chosen': -0.8636850714683533, 'rewards/rejected': -1.4114576578140259, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5477725267410278, 'policy_logps/rejected': -238.2935028076172, 'policy_logps/chosen': -326.3490905761719, 'referece_logps/rejected': -224.17892456054688, 'referece_logps/chosen': -317.7122497558594, 'logits/rejected': -0.9038968682289124, 'logits/chosen': -1.0227769613265991, 'epoch': 1.3}


 22%|██▏       | 3502/16104 [16:19:27<77:11:10, 22.05s/it]
{'loss': 0.5286, 'learning_rate': 1.821363417528992e-06, 'rewards/chosen': -0.8969646692276001, 'rewards/rejected': -1.6681394577026367, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7711747884750366, 'policy_logps/rejected': -357.7924499511719, 'policy_logps/chosen': -317.43212890625, 'referece_logps/rejected': -341.111083984375, 'referece_logps/chosen': -308.4624938964844, 'logits/rejected': -1.6771316528320312, 'logits/chosen': -1.6057384014129639, 'epoch': 1.3}


 22%|██▏       | 3504/16104 [16:19:54<61:02:01, 17.44s/it]
{'loss': 0.4791, 'learning_rate': 1.821133904104756e-06, 'rewards/chosen': -0.6069042086601257, 'rewards/rejected': -1.3868136405944824, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7799094915390015, 'policy_logps/rejected': -454.43359375, 'policy_logps/chosen': -411.2991027832031, 'referece_logps/rejected': -440.56549072265625, 'referece_logps/chosen': -405.23004150390625, 'logits/rejected': -0.5498064160346985, 'logits/chosen': -0.4310257136821747, 'epoch': 1.31}


 22%|██▏       | 3506/16104 [16:20:23<56:03:03, 16.02s/it]
{'loss': 0.6277, 'learning_rate': 1.8209042578151946e-06, 'rewards/chosen': -0.6781562566757202, 'rewards/rejected': -0.780046820640564, 'rewards/accuracies': 0.5, 'rewards/margins': 0.10189057141542435, 'policy_logps/rejected': -351.54254150390625, 'policy_logps/chosen': -398.4394836425781, 'referece_logps/rejected': -343.7420959472656, 'referece_logps/chosen': -391.65789794921875, 'logits/rejected': -0.08649624139070511, 'logits/chosen': -0.13318943977355957, 'epoch': 1.31}

 22%|██▏       | 3507/16104 [16:20:34<50:23:53, 14.40s/it]


 22%|██▏       | 3509/16104 [16:21:00<47:42:39, 13.64s/it]
{'loss': 0.644, 'learning_rate': 1.8205595393396567e-06, 'rewards/chosen': -0.3523516058921814, 'rewards/rejected': -1.224613904953003, 'rewards/accuracies': 1.0, 'rewards/margins': 0.872262179851532, 'policy_logps/rejected': -382.4844970703125, 'policy_logps/chosen': -388.4053955078125, 'referece_logps/rejected': -370.23834228515625, 'referece_logps/chosen': -384.88189697265625, 'logits/rejected': -0.015921417623758316, 'logits/chosen': -0.06321234256029129, 'epoch': 1.31}

 22%|██▏       | 3510/16104 [16:21:17<51:24:01, 14.69s/it]

 22%|██▏       | 3511/16104 [16:21:32<52:28:30, 15.00s/it]

 22%|██▏       | 3512/16104 [16:21:55<60:02:31, 17.17s/it]

 22%|██▏       | 3513/16104 [16:22:14<62:48:14, 17.96s/it]


 22%|██▏       | 3515/16104 [16:22:56<67:16:36, 19.24s/it]
{'loss': 0.5837, 'learning_rate': 1.8198692063005775e-06, 'rewards/chosen': -0.6815261840820312, 'rewards/rejected': -1.2667789459228516, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5852528810501099, 'policy_logps/rejected': -322.2462158203125, 'policy_logps/chosen': -472.6776123046875, 'referece_logps/rejected': -309.57843017578125, 'referece_logps/chosen': -465.86236572265625, 'logits/rejected': -0.26036524772644043, 'logits/chosen': -0.35429447889328003, 'epoch': 1.31}

 22%|██▏       | 3516/16104 [16:23:17<69:26:56, 19.86s/it]

 22%|██▏       | 3517/16104 [16:23:33<65:37:52, 18.77s/it]

 22%|██▏       | 3518/16104 [16:23:48<61:23:58, 17.56s/it]

 22%|██▏       | 3519/16104 [16:24:03<58:18:44, 16.68s/it]

 22%|██▏       | 3520/16104 [16:24:22<61:23:47, 17.56s/it]

 22%|██▏       | 3521/16104 [16:24:35<55:58:47, 16.02s/it]


 22%|██▏       | 3523/16104 [16:25:10<59:52:35, 17.13s/it]
{'loss': 0.5323, 'learning_rate': 1.818946905173042e-06, 'rewards/chosen': -1.489084005355835, 'rewards/rejected': -2.8253087997436523, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3362245559692383, 'policy_logps/rejected': -364.4552001953125, 'policy_logps/chosen': -444.03411865234375, 'referece_logps/rejected': -336.2021179199219, 'referece_logps/chosen': -429.14324951171875, 'logits/rejected': -0.7025530338287354, 'logits/chosen': -0.6709737181663513, 'epoch': 1.31}

 22%|██▏       | 3524/16104 [16:25:23<55:58:52, 16.02s/it]

 22%|██▏       | 3525/16104 [16:25:36<53:06:52, 15.20s/it]

 22%|██▏       | 3526/16104 [16:25:53<54:25:31, 15.58s/it]

 22%|██▏       | 3527/16104 [16:26:10<56:26:16, 16.15s/it]

 22%|██▏       | 3528/16104 [16:26:27<56:34:35, 16.20s/it]

 22%|██▏       | 3529/16104 [16:26:46<60:03:33, 17.19s/it]

 22%|██▏       | 3530/16104 [16:26:59<55:54:08, 16.01s/it]

 22%|██▏       | 3531/16104 [16:27:17<57:12:44, 16.38s/it]

 22%|██▏       | 3532/16104 [16:27:36<60:35:16, 17.35s/it]

 22%|██▏       | 3533/16104 [16:27:49<56:08:47, 16.08s/it]

 22%|██▏       | 3534/16104 [16:28:11<61:53:49, 17.73s/it]

 22%|██▏       | 3535/16104 [16:28:25<57:36:56, 16.50s/it]

 22%|██▏       | 3536/16104 [16:28:41<57:34:30, 16.49s/it]

 22%|██▏       | 3537/16104 [16:29:03<63:01:31, 18.05s/it]

 22%|██▏       | 3538/16104 [16:29:17<59:07:43, 16.94s/it]

 22%|██▏       | 3539/16104 [16:29:33<58:04:08, 16.64s/it]


 22%|██▏       | 3541/16104 [16:30:14<65:19:38, 18.72s/it]
{'loss': 0.4227, 'learning_rate': 1.816863979364107e-06, 'rewards/chosen': -1.1332099437713623, 'rewards/rejected': -2.466017723083496, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3328077793121338, 'policy_logps/rejected': -389.66790771484375, 'policy_logps/chosen': -343.41522216796875, 'referece_logps/rejected': -365.0076904296875, 'referece_logps/chosen': -332.0831298828125, 'logits/rejected': -0.5842947959899902, 'logits/chosen': -0.6107701063156128, 'epoch': 1.32}

 22%|██▏       | 3542/16104 [16:30:31<63:37:18, 18.23s/it]

 22%|██▏       | 3543/16104 [16:30:49<63:47:43, 18.28s/it]


 22%|██▏       | 3545/16104 [16:31:20<58:09:43, 16.67s/it]

 22%|██▏       | 3546/16104 [16:31:34<54:59:36, 15.77s/it]

{'loss': 0.5494, 'learning_rate': 1.8162834876866039e-06, 'rewards/chosen': -0.7740826606750488, 'rewards/rejected': -1.1814768314361572, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4073941111564636, 'policy_logps/rejected': -322.2936706542969, 'policy_logps/chosen': -249.531005859375, 'referece_logps/rejected': -310.4788818359375, 'referece_logps/chosen': -241.79019165039062, 'logits/rejected': -0.9942310452461243, 'logits/chosen': -1.0656498670578003, 'epoch': 1.32}
{'loss': 0.4914, 'learning_rate': 1.8161672902719395e-06, 'rewards/chosen': -0.3786800801753998, 'rewards/rejected': -1.762150764465332, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3834706544876099, 'policy_logps/rejected': -265.5317687988281, 'policy_logps/chosen': -274.13446044921875, 'referece_logps/rejected': -247.91026306152344, 'referece_logps/chosen': -270.34765625, 'logits/rejected': -0.7626038193702698, 'logits/chosen': -0.8005680441856384, 'epoch': 1.32}

 22%|██▏       | 3548/16104 [16:31:58<48:21:05, 13.86s/it]
{'loss': 0.4801, 'learning_rate': 1.8160510598418522e-06, 'rewards/chosen': -1.1805909872055054, 'rewards/rejected': -1.8366268873214722, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6560357213020325, 'policy_logps/rejected': -519.0023193359375, 'policy_logps/chosen': -485.9281311035156, 'referece_logps/rejected': -500.6360778808594, 'referece_logps/chosen': -474.1221923828125, 'logits/rejected': -1.311165452003479, 'logits/chosen': -1.1445642709732056, 'epoch': 1.32}


 22%|██▏       | 3550/16104 [16:32:34<56:28:23, 16.19s/it]

 22%|██▏       | 3551/16104 [16:32:52<58:25:30, 16.76s/it]
{'loss': 0.4441, 'learning_rate': 1.8157021705060737e-06, 'rewards/chosen': -0.7688072919845581, 'rewards/rejected': -1.4128844738006592, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6440771222114563, 'policy_logps/rejected': -402.3977355957031, 'policy_logps/chosen': -298.23516845703125, 'referece_logps/rejected': -388.2688903808594, 'referece_logps/chosen': -290.54705810546875, 'logits/rejected': -0.8858528137207031, 'logits/chosen': -0.9797433614730835, 'epoch': 1.32}


 22%|██▏       | 3553/16104 [16:33:30<61:17:34, 17.58s/it]
{'loss': 0.6071, 'learning_rate': 1.8154694126246722e-06, 'rewards/chosen': -0.700282096862793, 'rewards/rejected': -0.746636152267456, 'rewards/accuracies': 0.625, 'rewards/margins': 0.04635409265756607, 'policy_logps/rejected': -362.1897277832031, 'policy_logps/chosen': -287.4866638183594, 'referece_logps/rejected': -354.7234191894531, 'referece_logps/chosen': -280.4838562011719, 'logits/rejected': -0.2590370178222656, 'logits/chosen': -0.3060095012187958, 'epoch': 1.32}

 22%|██▏       | 3554/16104 [16:33:48<61:12:56, 17.56s/it]

 22%|██▏       | 3555/16104 [16:34:06<61:59:27, 17.78s/it]


 22%|██▏       | 3557/16104 [16:34:42<62:06:48, 17.82s/it]
{'loss': 0.454, 'learning_rate': 1.8150035010532406e-06, 'rewards/chosen': -0.8583562970161438, 'rewards/rejected': -1.5211589336395264, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6628026962280273, 'policy_logps/rejected': -299.43951416015625, 'policy_logps/chosen': -406.71234130859375, 'referece_logps/rejected': -284.2279357910156, 'referece_logps/chosen': -398.12872314453125, 'logits/rejected': -1.0439209938049316, 'logits/chosen': -0.9387763738632202, 'epoch': 1.33}

 22%|██▏       | 3558/16104 [16:34:59<60:42:23, 17.42s/it]

 22%|██▏       | 3559/16104 [16:35:13<57:51:12, 16.60s/it]

 22%|██▏       | 3560/16104 [16:35:34<61:38:19, 17.69s/it]

 22%|██▏       | 3561/16104 [16:35:47<56:59:23, 16.36s/it]

 22%|██▏       | 3562/16104 [16:36:06<59:31:56, 17.09s/it]

 22%|██▏       | 3563/16104 [16:36:18<54:19:42, 15.60s/it]


 22%|██▏       | 3565/16104 [16:36:55<59:01:54, 16.95s/it]

 22%|██▏       | 3566/16104 [16:37:15<62:14:14, 17.87s/it]

 22%|██▏       | 3567/16104 [16:37:36<66:21:31, 19.05s/it]
{'loss': 0.577, 'learning_rate': 1.8138364150010437e-06, 'rewards/chosen': -0.8619666695594788, 'rewards/rejected': -0.980318009853363, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1183512806892395, 'policy_logps/rejected': -372.5320129394531, 'policy_logps/chosen': -362.63238525390625, 'referece_logps/rejected': -362.72882080078125, 'referece_logps/chosen': -354.0127258300781, 'logits/rejected': -0.8401621580123901, 'logits/chosen': -1.1321852207183838, 'epoch': 1.33}

 22%|██▏       | 3568/16104 [16:37:49<59:39:58, 17.13s/it]


 22%|██▏       | 3570/16104 [16:38:15<52:16:30, 15.01s/it]
{'loss': 0.5881, 'learning_rate': 1.8134856470083037e-06, 'rewards/chosen': -1.0462881326675415, 'rewards/rejected': -1.3467977046966553, 'rewards/accuracies': 0.75, 'rewards/margins': 0.30050957202911377, 'policy_logps/rejected': -332.04522705078125, 'policy_logps/chosen': -395.71337890625, 'referece_logps/rejected': -318.5772705078125, 'referece_logps/chosen': -385.25048828125, 'logits/rejected': -0.7633347511291504, 'logits/chosen': -0.7770890593528748, 'epoch': 1.33}

 22%|██▏       | 3571/16104 [16:38:35<57:48:35, 16.61s/it]

 22%|██▏       | 3572/16104 [16:38:50<55:42:54, 16.00s/it]

 22%|██▏       | 3573/16104 [16:39:04<54:14:25, 15.58s/it]

 22%|██▏       | 3574/16104 [16:39:24<58:12:46, 16.73s/it]


 22%|██▏       | 3576/16104 [16:39:51<53:02:26, 15.24s/it]
{'loss': 0.5734, 'learning_rate': 1.8127832226631145e-06, 'rewards/chosen': -0.6387640833854675, 'rewards/rejected': -0.7899574637413025, 'rewards/accuracies': 0.75, 'rewards/margins': 0.15119333565235138, 'policy_logps/rejected': -476.2691345214844, 'policy_logps/chosen': -351.4068298339844, 'referece_logps/rejected': -468.3695373535156, 'referece_logps/chosen': -345.0191955566406, 'logits/rejected': -0.5509604215621948, 'logits/chosen': -0.38090693950653076, 'epoch': 1.33}


 22%|██▏       | 3578/16104 [16:40:31<61:20:40, 17.63s/it]
{'loss': 0.5342, 'learning_rate': 1.812548818135931e-06, 'rewards/chosen': -0.3555848002433777, 'rewards/rejected': -1.848315715789795, 'rewards/accuracies': 0.875, 'rewards/margins': 1.492730736732483, 'policy_logps/rejected': -361.58111572265625, 'policy_logps/chosen': -336.79949951171875, 'referece_logps/rejected': -343.097900390625, 'referece_logps/chosen': -333.24359130859375, 'logits/rejected': -0.8930743932723999, 'logits/chosen': -1.0293747186660767, 'epoch': 1.33}

 22%|██▏       | 3579/16104 [16:40:43<56:02:08, 16.11s/it]

 22%|██▏       | 3580/16104 [16:41:00<56:59:39, 16.38s/it]

 22%|██▏       | 3581/16104 [16:41:19<59:06:33, 16.99s/it]

 22%|██▏       | 3582/16104 [16:41:34<57:37:10, 16.57s/it]

 22%|██▏       | 3583/16104 [16:41:57<63:46:33, 18.34s/it]

 22%|██▏       | 3584/16104 [16:42:15<63:34:54, 18.28s/it]

 22%|██▏       | 3585/16104 [16:42:35<65:34:53, 18.86s/it]

 22%|██▏       | 3586/16104 [16:42:47<58:47:08, 16.91s/it]

 22%|██▏       | 3587/16104 [16:42:58<52:23:25, 15.07s/it]

 22%|██▏       | 3588/16104 [16:43:19<58:41:03, 16.88s/it]

 22%|██▏       | 3589/16104 [16:43:30<52:02:15, 14.97s/it]

 22%|██▏       | 3590/16104 [16:43:40<47:10:16, 13.57s/it]

 22%|██▏       | 3591/16104 [16:43:57<50:59:59, 14.67s/it]

 22%|██▏       | 3592/16104 [16:44:12<51:06:08, 14.70s/it]

 22%|██▏       | 3593/16104 [16:44:33<57:18:46, 16.49s/it]

 22%|██▏       | 3594/16104 [16:44:47<55:02:47, 15.84s/it]

 22%|██▏       | 3595/16104 [16:44:58<49:34:09, 14.27s/it]

 22%|██▏       | 3596/16104 [16:45:08<45:52:06, 13.20s/it]

 22%|██▏       | 3597/16104 [16:45:22<46:33:38, 13.40s/it]

 22%|██▏       | 3598/16104 [16:45:34<44:28:29, 12.80s/it]

 22%|██▏       | 3599/16104 [16:45:54<52:04:18, 14.99s/it]

 22%|██▏       | 3600/16104 [16:46:04<47:30:10, 13.68s/it]

 22%|██▏       | 3601/16104 [16:46:23<52:06:52, 15.01s/it]

 22%|██▏       | 3602/16104 [16:46:35<49:55:19, 14.38s/it]

 22%|██▏       | 3603/16104 [16:46:55<55:45:18, 16.06s/it]

 22%|██▏       | 3604/16104 [16:47:06<50:03:03, 14.41s/it]

 22%|██▏       | 3605/16104 [16:47:27<56:35:49, 16.30s/it]

 22%|██▏       | 3606/16104 [16:47:39<52:26:02, 15.10s/it]

 22%|██▏       | 3607/16104 [16:47:53<50:55:35, 14.67s/it]

 22%|██▏       | 3608/16104 [16:48:12<56:01:12, 16.14s/it]

 22%|██▏       | 3609/16104 [16:48:33<60:28:38, 17.42s/it]

 22%|██▏       | 3610/16104 [16:48:45<54:47:05, 15.79s/it]

 22%|██▏       | 3611/16104 [16:49:01<55:28:27, 15.99s/it]

 22%|██▏       | 3612/16104 [16:49:13<50:58:25, 14.69s/it]

 22%|██▏       | 3613/16104 [16:49:28<51:29:08, 14.84s/it]

 22%|██▏       | 3614/16104 [16:49:41<49:46:51, 14.35s/it]

 22%|██▏       | 3615/16104 [16:50:01<55:04:29, 15.88s/it]

 22%|██▏       | 3616/16104 [16:50:22<60:23:08, 17.41s/it]

 22%|██▏       | 3617/16104 [16:50:40<61:10:47, 17.64s/it]

 22%|██▏       | 3618/16104 [16:50:51<54:04:57, 15.59s/it]

 22%|██▏       | 3619/16104 [16:51:07<54:34:22, 15.74s/it]

 22%|██▏       | 3620/16104 [16:51:23<55:20:11, 15.96s/it]

 22%|██▏       | 3621/16104 [16:51:41<56:47:48, 16.38s/it]

 22%|██▏       | 3622/16104 [16:52:01<60:55:15, 17.57s/it]

 22%|██▏       | 3623/16104 [16:52:17<59:26:25, 17.14s/it]

 23%|██▎       | 3624/16104 [16:52:32<57:33:47, 16.60s/it]

 23%|██▎       | 3625/16104 [16:52:44<52:37:44, 15.18s/it]

 23%|██▎       | 3626/16104 [16:53:00<53:02:10, 15.30s/it]

 23%|██▎       | 3627/16104 [16:53:15<53:15:39, 15.37s/it]

 23%|██▎       | 3628/16104 [16:53:29<51:33:03, 14.88s/it]

 23%|██▎       | 3629/16104 [16:53:43<50:32:16, 14.58s/it]

 23%|██▎       | 3630/16104 [16:53:59<52:20:44, 15.11s/it]

 23%|██▎       | 3631/16104 [16:54:19<57:20:50, 16.55s/it]

 23%|██▎       | 3632/16104 [16:54:31<52:03:22, 15.03s/it]

 23%|██▎       | 3633/16104 [16:54:54<60:12:24, 17.38s/it]

 23%|██▎       | 3634/16104 [16:55:08<57:20:19, 16.55s/it]

 23%|██▎       | 3635/16104 [16:55:27<59:27:15, 17.17s/it]

 23%|██▎       | 3636/16104 [16:55:42<57:26:50, 16.59s/it]

 23%|██▎       | 3637/16104 [16:55:54<52:48:34, 15.25s/it]

 23%|██▎       | 3638/16104 [16:56:12<55:47:27, 16.11s/it]

 23%|██▎       | 3639/16104 [16:56:32<59:58:31, 17.32s/it]

 23%|██▎       | 3640/16104 [16:56:45<55:10:05, 15.93s/it]

 23%|██▎       | 3641/16104 [16:56:58<51:45:41, 14.95s/it]

 23%|██▎       | 3642/16104 [16:57:16<55:05:03, 15.91s/it]

 23%|██▎       | 3643/16104 [16:57:38<61:30:19, 17.77s/it]

 23%|██▎       | 3644/16104 [16:57:58<64:14:02, 18.56s/it]

 23%|██▎       | 3645/16104 [16:58:18<65:46:25, 19.01s/it]

 23%|██▎       | 3646/16104 [16:58:35<63:39:54, 18.40s/it]

 23%|██▎       | 3647/16104 [16:58:55<64:59:33, 18.78s/it]


 23%|██▎       | 3649/16104 [16:59:30<62:30:02, 18.07s/it]

 23%|██▎       | 3650/16104 [16:59:49<63:47:22, 18.44s/it]

 23%|██▎       | 3651/16104 [17:00:10<65:54:40, 19.05s/it]

 23%|██▎       | 3652/16104 [17:00:25<61:51:55, 17.89s/it]

 23%|██▎       | 3653/16104 [17:00:43<62:01:09, 17.93s/it]

 23%|██▎       | 3654/16104 [17:01:00<60:57:44, 17.63s/it]

 23%|██▎       | 3655/16104 [17:01:13<55:48:00, 16.14s/it]

 23%|██▎       | 3656/16104 [17:01:34<61:36:56, 17.82s/it]
{'loss': 0.4816, 'learning_rate': 1.8033048670234447e-06, 'rewards/chosen': -0.8691341876983643, 'rewards/rejected': -1.469556450843811, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6004223227500916, 'policy_logps/rejected': -414.1415100097656, 'policy_logps/chosen': -377.78765869140625, 'referece_logps/rejected': -399.44598388671875, 'referece_logps/chosen': -369.0963134765625, 'logits/rejected': -0.08726611733436584, 'logits/chosen': 0.14313647150993347, 'epoch': 1.36}


 23%|██▎       | 3658/16104 [17:02:12<62:58:50, 18.22s/it]

 23%|██▎       | 3659/16104 [17:02:34<66:41:19, 19.29s/it]

 23%|██▎       | 3660/16104 [17:02:54<67:55:38, 19.65s/it]

 23%|██▎       | 3661/16104 [17:03:08<62:10:33, 17.99s/it]

 23%|██▎       | 3662/16104 [17:03:24<59:59:36, 17.36s/it]

 23%|██▎       | 3663/16104 [17:03:35<53:28:05, 15.47s/it]

 23%|██▎       | 3664/16104 [17:03:47<49:39:10, 14.37s/it]

 23%|██▎       | 3665/16104 [17:04:03<51:05:05, 14.78s/it]

 23%|██▎       | 3666/16104 [17:04:19<52:42:57, 15.26s/it]

 23%|██▎       | 3667/16104 [17:04:39<57:19:52, 16.60s/it]

 23%|██▎       | 3668/16104 [17:04:54<55:22:38, 16.03s/it]

 23%|██▎       | 3669/16104 [17:05:15<61:08:38, 17.70s/it]

 23%|██▎       | 3670/16104 [17:05:29<57:31:16, 16.65s/it]

 23%|██▎       | 3671/16104 [17:05:51<62:52:42, 18.21s/it]

 23%|██▎       | 3672/16104 [17:06:04<56:53:01, 16.47s/it]

 23%|██▎       | 3673/16104 [17:06:20<56:56:10, 16.49s/it]

 23%|██▎       | 3674/16104 [17:06:42<62:32:46, 18.11s/it]

 23%|██▎       | 3675/16104 [17:07:02<64:10:09, 18.59s/it]

 23%|██▎       | 3676/16104 [17:07:19<62:25:33, 18.08s/it]

 23%|██▎       | 3677/16104 [17:07:38<64:00:50, 18.54s/it]

 23%|██▎       | 3678/16104 [17:07:57<63:41:46, 18.45s/it]

 23%|██▎       | 3679/16104 [17:08:10<58:36:25, 16.98s/it]

 23%|██▎       | 3680/16104 [17:08:29<60:07:20, 17.42s/it]

 23%|██▎       | 3681/16104 [17:08:49<63:38:59, 18.44s/it]

 23%|██▎       | 3682/16104 [17:09:11<66:35:04, 19.30s/it]

 23%|██▎       | 3683/16104 [17:09:32<68:55:41, 19.98s/it]

 23%|██▎       | 3684/16104 [17:09:47<63:56:27, 18.53s/it]

 23%|██▎       | 3685/16104 [17:10:09<67:36:24, 19.60s/it]

 23%|██▎       | 3686/16104 [17:10:24<61:50:47, 17.93s/it]

 23%|██▎       | 3687/16104 [17:10:34<54:21:40, 15.76s/it]

 23%|██▎       | 3688/16104 [17:10:49<53:31:42, 15.52s/it]

 23%|██▎       | 3689/16104 [17:11:05<53:52:48, 15.62s/it]

 23%|██▎       | 3690/16104 [17:11:23<55:58:40, 16.23s/it]

 23%|██▎       | 3691/16104 [17:11:43<60:16:50, 17.48s/it]

 23%|██▎       | 3692/16104 [17:11:56<55:03:20, 15.97s/it]

 23%|██▎       | 3693/16104 [17:12:14<57:58:18, 16.82s/it]

 23%|██▎       | 3694/16104 [17:12:35<61:33:27, 17.86s/it]

 23%|██▎       | 3695/16104 [17:12:55<63:38:38, 18.46s/it]

 23%|██▎       | 3696/16104 [17:13:12<62:52:22, 18.24s/it]

 23%|██▎       | 3697/16104 [17:13:28<60:45:27, 17.63s/it]

 23%|██▎       | 3698/16104 [17:13:48<63:04:23, 18.30s/it]

 23%|██▎       | 3699/16104 [17:14:02<58:20:10, 16.93s/it]

 23%|██▎       | 3700/16104 [17:14:17<56:36:16, 16.43s/it]

 23%|██▎       | 3701/16104 [17:14:34<57:19:32, 16.64s/it]

 23%|██▎       | 3702/16104 [17:14:48<54:29:01, 15.82s/it]

 23%|██▎       | 3703/16104 [17:15:08<58:21:28, 16.94s/it]
{'loss': 0.4814, 'learning_rate': 1.7976391939259353e-06, 'rewards/chosen': -0.9552314877510071, 'rewards/rejected': -1.3611209392547607, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4058893322944641, 'policy_logps/rejected': -341.2157287597656, 'policy_logps/chosen': -436.0270690917969, 'referece_logps/rejected': -327.6045227050781, 'referece_logps/chosen': -426.4747314453125, 'logits/rejected': -0.9911245107650757, 'logits/chosen': -1.122236728668213, 'epoch': 1.38}

 23%|██▎       | 3704/16104 [17:15:25<58:58:18, 17.12s/it]

 23%|██▎       | 3705/16104 [17:15:41<57:38:51, 16.74s/it]


 23%|██▎       | 3707/16104 [17:16:17<59:41:08, 17.33s/it]
{'loss': 0.5569, 'learning_rate': 1.7971537107052362e-06, 'rewards/chosen': -1.0373766422271729, 'rewards/rejected': -1.6841301918029785, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6467535495758057, 'policy_logps/rejected': -413.4076232910156, 'policy_logps/chosen': -350.18133544921875, 'referece_logps/rejected': -396.56634521484375, 'referece_logps/chosen': -339.80755615234375, 'logits/rejected': -1.1529297828674316, 'logits/chosen': -1.0683059692382812, 'epoch': 1.38}


 23%|██▎       | 3709/16104 [17:16:47<55:11:34, 16.03s/it]
{'loss': 0.6017, 'learning_rate': 1.796910775597504e-06, 'rewards/chosen': -0.977156400680542, 'rewards/rejected': -1.1646229028701782, 'rewards/accuracies': 0.625, 'rewards/margins': 0.18746641278266907, 'policy_logps/rejected': -341.7889099121094, 'policy_logps/chosen': -356.49652099609375, 'referece_logps/rejected': -330.1426696777344, 'referece_logps/chosen': -346.7249450683594, 'logits/rejected': -1.1701668500900269, 'logits/chosen': -1.2069129943847656, 'epoch': 1.38}

 23%|██▎       | 3710/16104 [17:17:07<60:04:14, 17.45s/it]


 23%|██▎       | 3712/16104 [17:17:47<63:13:25, 18.37s/it]

 23%|██▎       | 3713/16104 [17:18:05<63:07:18, 18.34s/it]
{'loss': 0.5901, 'learning_rate': 1.7964245185838175e-06, 'rewards/chosen': -0.9886084794998169, 'rewards/rejected': -1.7689238786697388, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7803153991699219, 'policy_logps/rejected': -636.8812255859375, 'policy_logps/chosen': -474.1074523925781, 'referece_logps/rejected': -619.1920166015625, 'referece_logps/chosen': -464.2213134765625, 'logits/rejected': 0.6319811940193176, 'logits/chosen': 0.6842293739318848, 'epoch': 1.38}


 23%|██▎       | 3715/16104 [17:18:35<57:59:59, 16.85s/it]

 23%|██▎       | 3716/16104 [17:18:53<59:19:11, 17.24s/it]

 23%|██▎       | 3717/16104 [17:19:05<53:19:19, 15.50s/it]
{'loss': 0.4978, 'learning_rate': 1.7959377461014698e-06, 'rewards/chosen': -0.9970899820327759, 'rewards/rejected': -1.6046017408370972, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6075118184089661, 'policy_logps/rejected': -350.17352294921875, 'policy_logps/chosen': -332.6064453125, 'referece_logps/rejected': -334.12750244140625, 'referece_logps/chosen': -322.63555908203125, 'logits/rejected': -0.6156806945800781, 'logits/chosen': -0.49051523208618164, 'epoch': 1.38}


 23%|██▎       | 3719/16104 [17:19:45<61:55:15, 18.00s/it]
{'loss': 0.4733, 'learning_rate': 1.7956941666579886e-06, 'rewards/chosen': -0.9845159649848938, 'rewards/rejected': -1.4839314222335815, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4994155168533325, 'policy_logps/rejected': -359.76373291015625, 'policy_logps/chosen': -423.35821533203125, 'referece_logps/rejected': -344.9244079589844, 'referece_logps/chosen': -413.51300048828125, 'logits/rejected': -0.45543748140335083, 'logits/chosen': -0.704267144203186, 'epoch': 1.39}


 23%|██▎       | 3721/16104 [17:20:19<59:12:55, 17.22s/it]

 23%|██▎       | 3722/16104 [17:20:33<55:49:50, 16.23s/it]
{'loss': 0.6323, 'learning_rate': 1.7953285561007243e-06, 'rewards/chosen': -0.870613694190979, 'rewards/rejected': -1.557024598121643, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6864110231399536, 'policy_logps/rejected': -388.00494384765625, 'policy_logps/chosen': -205.71412658691406, 'referece_logps/rejected': -372.4346923828125, 'referece_logps/chosen': -197.00799560546875, 'logits/rejected': -0.3968794345855713, 'logits/chosen': -0.24272653460502625, 'epoch': 1.39}


 23%|██▎       | 3724/16104 [17:20:59<50:11:40, 14.60s/it]

 23%|██▎       | 3725/16104 [17:21:17<53:43:35, 15.62s/it]

 23%|██▎       | 3726/16104 [17:21:27<48:33:35, 14.12s/it]

 23%|██▎       | 3727/16104 [17:21:38<45:16:44, 13.17s/it]

 23%|██▎       | 3728/16104 [17:21:49<42:46:09, 12.44s/it]
{'loss': 0.6208, 'learning_rate': 1.794596466463029e-06, 'rewards/chosen': -0.8355886340141296, 'rewards/rejected': -0.8970521688461304, 'rewards/accuracies': 0.375, 'rewards/margins': 0.061463527381420135, 'policy_logps/rejected': -495.98956298828125, 'policy_logps/chosen': -385.5824279785156, 'referece_logps/rejected': -487.0190734863281, 'referece_logps/chosen': -377.2265625, 'logits/rejected': -0.6182719469070435, 'logits/chosen': -0.4482018053531647, 'epoch': 1.39}


 23%|██▎       | 3730/16104 [17:22:19<48:08:59, 14.01s/it]

 23%|██▎       | 3731/16104 [17:22:39<54:14:04, 15.78s/it]

 23%|██▎       | 3732/16104 [17:22:51<49:42:53, 14.47s/it]

 23%|██▎       | 3733/16104 [17:23:07<51:57:46, 15.12s/it]
{'loss': 0.5226, 'learning_rate': 1.7939855077915205e-06, 'rewards/chosen': -0.473100483417511, 'rewards/rejected': -1.6445502042770386, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1714495420455933, 'policy_logps/rejected': -341.5769958496094, 'policy_logps/chosen': -409.2635192871094, 'referece_logps/rejected': -325.1315002441406, 'referece_logps/chosen': -404.5325012207031, 'logits/rejected': -0.549422025680542, 'logits/chosen': -0.49841710925102234, 'epoch': 1.39}

 23%|██▎       | 3734/16104 [17:23:20<49:05:26, 14.29s/it]

 23%|██▎       | 3735/16104 [17:23:40<55:28:20, 16.15s/it]


 23%|██▎       | 3737/16104 [17:24:19<60:55:07, 17.73s/it]

 23%|██▎       | 3738/16104 [17:24:29<53:38:07, 15.61s/it]
{'loss': 0.534, 'learning_rate': 1.7933737461668112e-06, 'rewards/chosen': -0.6952918767929077, 'rewards/rejected': -0.5722446441650391, 'rewards/accuracies': 0.5, 'rewards/margins': -0.12304726243019104, 'policy_logps/rejected': -368.86639404296875, 'policy_logps/chosen': -376.31182861328125, 'referece_logps/rejected': -363.1439208984375, 'referece_logps/chosen': -369.35888671875, 'logits/rejected': -0.7917706370353699, 'logits/chosen': -0.8096141219139099, 'epoch': 1.39}

 23%|██▎       | 3739/16104 [17:24:46<54:40:27, 15.92s/it]


 23%|██▎       | 3741/16104 [17:25:21<57:58:11, 16.88s/it]
{'loss': 0.5025, 'learning_rate': 1.7930063040317824e-06, 'rewards/chosen': -0.7864896655082703, 'rewards/rejected': -1.992676854133606, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2061870098114014, 'policy_logps/rejected': -477.54718017578125, 'policy_logps/chosen': -410.4280700683594, 'referece_logps/rejected': -457.6204528808594, 'referece_logps/chosen': -402.5632019042969, 'logits/rejected': -0.7680560350418091, 'logits/chosen': -0.6336056590080261, 'epoch': 1.39}

 23%|██▎       | 3742/16104 [17:25:38<57:49:12, 16.84s/it]

 23%|██▎       | 3743/16104 [17:26:00<63:25:06, 18.47s/it]


 23%|██▎       | 3745/16104 [17:26:35<61:05:20, 17.79s/it]

 23%|██▎       | 3746/16104 [17:26:55<63:01:12, 18.36s/it]

 23%|██▎       | 3747/16104 [17:27:09<59:00:40, 17.19s/it]

 23%|██▎       | 3748/16104 [17:27:29<61:31:08, 17.92s/it]

 23%|██▎       | 3749/16104 [17:27:47<61:14:37, 17.85s/it]
{'loss': 0.4761, 'learning_rate': 1.792025047247193e-06, 'rewards/chosen': -0.5386781096458435, 'rewards/rejected': -1.6104774475097656, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0717992782592773, 'policy_logps/rejected': -326.629638671875, 'policy_logps/chosen': -341.3091125488281, 'referece_logps/rejected': -310.52490234375, 'referece_logps/chosen': -335.92236328125, 'logits/rejected': -0.8621987104415894, 'logits/chosen': -0.9004508256912231, 'epoch': 1.4}

 23%|██▎       | 3750/16104 [17:28:06<63:04:18, 18.38s/it]


 23%|██▎       | 3752/16104 [17:28:42<62:33:18, 18.23s/it]
{'loss': 0.5905, 'learning_rate': 1.7916565471758307e-06, 'rewards/chosen': -0.686777651309967, 'rewards/rejected': -1.5598554611206055, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8730777502059937, 'policy_logps/rejected': -336.9791259765625, 'policy_logps/chosen': -383.859619140625, 'referece_logps/rejected': -321.38055419921875, 'referece_logps/chosen': -376.9918212890625, 'logits/rejected': -1.1891486644744873, 'logits/chosen': -1.1813831329345703, 'epoch': 1.4}


 23%|██▎       | 3754/16104 [17:29:12<56:27:39, 16.46s/it]

 23%|██▎       | 3755/16104 [17:29:27<54:46:01, 15.97s/it]
{'loss': 0.6048, 'learning_rate': 1.7912877588891959e-06, 'rewards/chosen': -0.9059858322143555, 'rewards/rejected': -1.2210884094238281, 'rewards/accuracies': 0.5, 'rewards/margins': 0.31510257720947266, 'policy_logps/rejected': -205.07510375976562, 'policy_logps/chosen': -425.6482238769531, 'referece_logps/rejected': -192.86422729492188, 'referece_logps/chosen': -416.58837890625, 'logits/rejected': -1.1373361349105835, 'logits/chosen': -1.3775259256362915, 'epoch': 1.4}


 23%|██▎       | 3757/16104 [17:30:02<56:49:05, 16.57s/it]
{'loss': 0.5738, 'learning_rate': 1.791041739978142e-06, 'rewards/chosen': -0.9830535650253296, 'rewards/rejected': -1.2473504543304443, 'rewards/accuracies': 0.625, 'rewards/margins': 0.26429682970046997, 'policy_logps/rejected': -524.3165893554688, 'policy_logps/chosen': -382.62091064453125, 'referece_logps/rejected': -511.8431701660156, 'referece_logps/chosen': -372.7904052734375, 'logits/rejected': -1.057699203491211, 'logits/chosen': -0.8694223165512085, 'epoch': 1.4}


 23%|██▎       | 3759/16104 [17:30:32<53:52:33, 15.71s/it]
{'loss': 0.5854, 'learning_rate': 1.7907955930708893e-06, 'rewards/chosen': -1.0643538236618042, 'rewards/rejected': -1.3376927375793457, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2733389735221863, 'policy_logps/rejected': -240.1013641357422, 'policy_logps/chosen': -210.32046508789062, 'referece_logps/rejected': -226.7244110107422, 'referece_logps/chosen': -199.6769256591797, 'logits/rejected': -0.5505520701408386, 'logits/chosen': -0.47409260272979736, 'epoch': 1.4}

 23%|██▎       | 3760/16104 [17:30:45<50:43:19, 14.79s/it]


 23%|██▎       | 3762/16104 [17:31:16<51:50:56, 15.12s/it]

 23%|██▎       | 3763/16104 [17:31:36<57:00:17, 16.63s/it]

 23%|██▎       | 3764/16104 [17:31:56<60:25:50, 17.63s/it]

 23%|██▎       | 3765/16104 [17:32:08<54:27:19, 15.89s/it]

 23%|██▎       | 3766/16104 [17:32:27<58:19:18, 17.02s/it]

 23%|██▎       | 3767/16104 [17:32:38<51:53:48, 15.14s/it]

 23%|██▎       | 3768/16104 [17:32:54<52:23:42, 15.29s/it]

 23%|██▎       | 3769/16104 [17:33:05<48:40:34, 14.21s/it]

 23%|██▎       | 3770/16104 [17:33:22<51:01:26, 14.89s/it]

 23%|██▎       | 3771/16104 [17:33:35<49:29:43, 14.45s/it]

 23%|██▎       | 3772/16104 [17:33:50<49:48:16, 14.54s/it]
{'loss': 0.453, 'learning_rate': 1.7891925210190144e-06, 'rewards/chosen': -0.782721996307373, 'rewards/rejected': -1.582721471786499, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7999993562698364, 'policy_logps/rejected': -318.8163757324219, 'policy_logps/chosen': -304.274658203125, 'referece_logps/rejected': -302.9891662597656, 'referece_logps/chosen': -296.44744873046875, 'logits/rejected': -0.11817288398742676, 'logits/chosen': -0.009443312883377075, 'epoch': 1.41}

 23%|██▎       | 3773/16104 [17:34:10<55:43:51, 16.27s/it]

 23%|██▎       | 3774/16104 [17:34:22<51:30:02, 15.04s/it]


 23%|██▎       | 3776/16104 [17:34:59<58:03:38, 16.95s/it]

 23%|██▎       | 3777/16104 [17:35:11<52:56:46, 15.46s/it]
{'loss': 0.6287, 'learning_rate': 1.7885745176551797e-06, 'rewards/chosen': -1.3966867923736572, 'rewards/rejected': -2.1347906589508057, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7381038665771484, 'policy_logps/rejected': -443.2846984863281, 'policy_logps/chosen': -445.9516296386719, 'referece_logps/rejected': -421.9367980957031, 'referece_logps/chosen': -431.9847412109375, 'logits/rejected': 0.3582971394062042, 'logits/chosen': 0.13939641416072845, 'epoch': 1.41}


 23%|██▎       | 3779/16104 [17:35:38<48:29:05, 14.16s/it]
{'loss': 0.6222, 'learning_rate': 1.7883270929799124e-06, 'rewards/chosen': -1.292997121810913, 'rewards/rejected': -1.826461672782898, 'rewards/accuracies': 0.375, 'rewards/margins': 0.5334644317626953, 'policy_logps/rejected': -281.8415222167969, 'policy_logps/chosen': -473.6120910644531, 'referece_logps/rejected': -263.576904296875, 'referece_logps/chosen': -460.68206787109375, 'logits/rejected': -0.026778846979141235, 'logits/chosen': 0.0029219835996627808, 'epoch': 1.41}


 23%|██▎       | 3781/16104 [17:36:09<52:54:20, 15.46s/it]

 23%|██▎       | 3782/16104 [17:36:24<52:04:38, 15.21s/it]

 23%|██▎       | 3783/16104 [17:36:46<58:48:01, 17.18s/it]

 23%|██▎       | 3784/16104 [17:36:58<53:50:42, 15.73s/it]

 24%|██▎       | 3785/16104 [17:37:10<49:40:36, 14.52s/it]

 24%|██▎       | 3786/16104 [17:37:28<53:36:11, 15.67s/it]

 24%|██▎       | 3787/16104 [17:37:48<57:29:51, 16.81s/it]

 24%|██▎       | 3788/16104 [17:38:04<56:43:31, 16.58s/it]

 24%|██▎       | 3789/16104 [17:38:16<52:26:18, 15.33s/it]

 24%|██▎       | 3790/16104 [17:38:35<56:24:13, 16.49s/it]
{'loss': 0.537, 'learning_rate': 1.7869639782599502e-06, 'rewards/chosen': -1.2316548824310303, 'rewards/rejected': -2.0219054222106934, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7902505397796631, 'policy_logps/rejected': -358.1991271972656, 'policy_logps/chosen': -391.4786071777344, 'referece_logps/rejected': -337.9800720214844, 'referece_logps/chosen': -379.1620788574219, 'logits/rejected': -0.27674078941345215, 'logits/chosen': -0.20480084419250488, 'epoch': 1.41}

 24%|██▎       | 3791/16104 [17:38:55<59:40:03, 17.45s/it]


 24%|██▎       | 3793/16104 [17:39:34<63:34:58, 18.59s/it]

 24%|██▎       | 3794/16104 [17:39:45<55:54:31, 16.35s/it]

 24%|██▎       | 3795/16104 [17:40:04<57:38:37, 16.86s/it]

 24%|██▎       | 3796/16104 [17:40:25<61:59:05, 18.13s/it]

 24%|██▎       | 3797/16104 [17:40:38<57:22:02, 16.78s/it]

 24%|██▎       | 3798/16104 [17:40:55<56:57:04, 16.66s/it]

 24%|██▎       | 3799/16104 [17:41:15<60:24:40, 17.67s/it]
{'loss': 0.402, 'learning_rate': 1.7858458372110229e-06, 'rewards/chosen': -0.6296595335006714, 'rewards/rejected': -1.855323314666748, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2256639003753662, 'policy_logps/rejected': -439.4289245605469, 'policy_logps/chosen': -501.78680419921875, 'referece_logps/rejected': -420.87567138671875, 'referece_logps/chosen': -495.490234375, 'logits/rejected': -0.4902602732181549, 'logits/chosen': -0.3638007640838623, 'epoch': 1.42}

 24%|██▎       | 3800/16104 [17:41:33<61:27:16, 17.98s/it]


 24%|██▎       | 3802/16104 [17:42:14<66:01:57, 19.32s/it]

 24%|██▎       | 3803/16104 [17:42:34<66:38:29, 19.50s/it]

 24%|██▎       | 3804/16104 [17:42:52<64:33:37, 18.90s/it]

 24%|██▎       | 3805/16104 [17:43:08<61:44:00, 18.07s/it]

 24%|██▎       | 3806/16104 [17:43:28<63:22:58, 18.55s/it]

 24%|██▎       | 3807/16104 [17:43:49<65:52:42, 19.29s/it]
{'loss': 0.4826, 'learning_rate': 1.7848497722999807e-06, 'rewards/chosen': -0.7451602816581726, 'rewards/rejected': -1.6908199787139893, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9456596970558167, 'policy_logps/rejected': -469.12493896484375, 'policy_logps/chosen': -306.0147705078125, 'referece_logps/rejected': -452.21673583984375, 'referece_logps/chosen': -298.56317138671875, 'logits/rejected': -0.3406466245651245, 'logits/chosen': -0.24216628074645996, 'epoch': 1.42}

 24%|██▎       | 3808/16104 [17:44:09<67:17:32, 19.70s/it]


 24%|██▎       | 3810/16104 [17:44:42<60:09:19, 17.62s/it]

 24%|██▎       | 3811/16104 [17:44:56<56:25:17, 16.52s/it]
{'loss': 0.5483, 'learning_rate': 1.7843509777174735e-06, 'rewards/chosen': -0.5420603156089783, 'rewards/rejected': -1.4788485765457153, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9367883801460266, 'policy_logps/rejected': -287.90740966796875, 'policy_logps/chosen': -353.501220703125, 'referece_logps/rejected': -273.11895751953125, 'referece_logps/chosen': -348.08062744140625, 'logits/rejected': -0.1300065815448761, 'logits/chosen': -0.14386579394340515, 'epoch': 1.42}


 24%|██▎       | 3813/16104 [17:45:28<57:03:26, 16.71s/it]
{'loss': 0.5267, 'learning_rate': 1.7841013900356592e-06, 'rewards/chosen': -1.135685920715332, 'rewards/rejected': -2.6379177570343018, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5022318363189697, 'policy_logps/rejected': -305.70831298828125, 'policy_logps/chosen': -393.8638916015625, 'referece_logps/rejected': -279.3291320800781, 'referece_logps/chosen': -382.50701904296875, 'logits/rejected': -0.8180583715438843, 'logits/chosen': -0.8344561457633972, 'epoch': 1.42}

 24%|██▎       | 3814/16104 [17:45:44<56:14:32, 16.47s/it]


 24%|██▎       | 3816/16104 [17:46:15<55:33:30, 16.28s/it]

 24%|██▎       | 3817/16104 [17:46:27<50:52:51, 14.91s/it]
{'loss': 0.6302, 'learning_rate': 1.7836018340928346e-06, 'rewards/chosen': -0.7870495319366455, 'rewards/rejected': -1.3343706130981445, 'rewards/accuracies': 0.625, 'rewards/margins': 0.547321081161499, 'policy_logps/rejected': -418.4034423828125, 'policy_logps/chosen': -465.32440185546875, 'referece_logps/rejected': -405.05975341796875, 'referece_logps/chosen': -457.4538879394531, 'logits/rejected': 0.14581719040870667, 'logits/chosen': 0.39869073033332825, 'epoch': 1.42}

 24%|██▎       | 3818/16104 [17:46:41<50:43:39, 14.86s/it]


 24%|██▎       | 3820/16104 [17:47:03<43:36:30, 12.78s/it]
{'loss': 0.5512, 'learning_rate': 1.7832268342880673e-06, 'rewards/chosen': -0.754433274269104, 'rewards/rejected': -1.144748568534851, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3903152644634247, 'policy_logps/rejected': -444.1412353515625, 'policy_logps/chosen': -428.97088623046875, 'referece_logps/rejected': -432.6937255859375, 'referece_logps/chosen': -421.426513671875, 'logits/rejected': -0.28456780314445496, 'logits/chosen': -0.15681833028793335, 'epoch': 1.42}


 24%|██▎       | 3822/16104 [17:47:34<48:56:39, 14.35s/it]

 24%|██▎       | 3823/16104 [17:47:45<45:15:07, 13.27s/it]
{'loss': 0.5854, 'learning_rate': 1.7828515493369995e-06, 'rewards/chosen': -0.7273739576339722, 'rewards/rejected': -1.227232813835144, 'rewards/accuracies': 0.75, 'rewards/margins': 0.49985891580581665, 'policy_logps/rejected': -295.92919921875, 'policy_logps/chosen': -375.55755615234375, 'referece_logps/rejected': -283.6568603515625, 'referece_logps/chosen': -368.2838134765625, 'logits/rejected': -0.4991340637207031, 'logits/chosen': -0.5558962225914001, 'epoch': 1.42}

 24%|██▎       | 3824/16104 [17:48:08<54:40:30, 16.03s/it]

 24%|██▍       | 3825/16104 [17:48:23<54:26:20, 15.96s/it]


 24%|██▍       | 3826/16104 [17:48:40<55:12:49, 16.19s/it]
{'loss': 0.5546, 'learning_rate': 1.782350726077494e-06, 'rewards/chosen': -0.6129406094551086, 'rewards/rejected': -1.0515658855438232, 'rewards/accuracies': 0.625, 'rewards/margins': 0.43862539529800415, 'policy_logps/rejected': -344.6131591796875, 'policy_logps/chosen': -404.493896484375, 'referece_logps/rejected': -334.09747314453125, 'referece_logps/chosen': -398.3644714355469, 'logits/rejected': 0.13667984306812286, 'logits/chosen': 0.32676559686660767, 'epoch': 1.43}
 24%|██▍       | 3827/16104 [17:48:53<52:03:37, 15.27s/it]

 24%|██▍       | 3828/16104 [17:49:05<48:59:57, 14.37s/it]

 24%|██▍       | 3829/16104 [17:49:26<55:24:55, 16.25s/it]


 24%|██▍       | 3831/16104 [17:49:55<51:45:14, 15.18s/it]

 24%|██▍       | 3832/16104 [17:50:15<56:18:38, 16.52s/it]
{'loss': 0.448, 'learning_rate': 1.781723984972799e-06, 'rewards/chosen': -0.7368181347846985, 'rewards/rejected': -1.764840841293335, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0280227661132812, 'policy_logps/rejected': -353.21502685546875, 'policy_logps/chosen': -382.3021240234375, 'referece_logps/rejected': -335.5666198730469, 'referece_logps/chosen': -374.9339294433594, 'logits/rejected': -1.1952834129333496, 'logits/chosen': -1.4233449697494507, 'epoch': 1.43}


 24%|██▍       | 3834/16104 [17:50:49<56:18:37, 16.52s/it]
{'loss': 0.5755, 'learning_rate': 1.7814730671405067e-06, 'rewards/chosen': -1.242922067642212, 'rewards/rejected': -1.4129621982574463, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17004022002220154, 'policy_logps/rejected': -352.73443603515625, 'policy_logps/chosen': -411.6475524902344, 'referece_logps/rejected': -338.60479736328125, 'referece_logps/chosen': -399.2183837890625, 'logits/rejected': -0.029630929231643677, 'logits/chosen': 0.018615394830703735, 'epoch': 1.43}

 24%|██▍       | 3835/16104 [17:51:04<54:48:33, 16.08s/it]

 24%|██▍       | 3836/16104 [17:51:18<53:16:01, 15.63s/it]

 24%|██▍       | 3837/16104 [17:51:34<53:21:11, 15.66s/it]


 24%|██▍       | 3839/16104 [17:52:03<52:05:56, 15.29s/it]

 24%|██▍       | 3840/16104 [17:52:23<57:10:42, 16.78s/it]
{'loss': 0.5255, 'learning_rate': 1.780719555118619e-06, 'rewards/chosen': -0.09086035937070847, 'rewards/rejected': -1.3943736553192139, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3035134077072144, 'policy_logps/rejected': -485.90789794921875, 'policy_logps/chosen': -518.9319458007812, 'referece_logps/rejected': -471.964111328125, 'referece_logps/chosen': -518.0233764648438, 'logits/rejected': 0.2518027722835541, 'logits/chosen': 0.28535035252571106, 'epoch': 1.43}

 24%|██▍       | 3841/16104 [17:52:34<51:26:52, 15.10s/it]


 24%|██▍       | 3843/16104 [17:53:09<54:17:58, 15.94s/it]
{'loss': 0.5445, 'learning_rate': 1.78034237268884e-06, 'rewards/chosen': -0.7372244596481323, 'rewards/rejected': -0.9218944311141968, 'rewards/accuracies': 0.5, 'rewards/margins': 0.18466991186141968, 'policy_logps/rejected': -270.8836975097656, 'policy_logps/chosen': -269.8102722167969, 'referece_logps/rejected': -261.6647644042969, 'referece_logps/chosen': -262.4380187988281, 'logits/rejected': 0.4064105153083801, 'logits/chosen': 0.5203613638877869, 'epoch': 1.43}

 24%|██▍       | 3844/16104 [17:53:24<52:46:29, 15.50s/it]

 24%|██▍       | 3845/16104 [17:53:42<55:19:58, 16.25s/it]

 24%|██▍       | 3846/16104 [17:53:58<54:53:42, 16.12s/it]

 24%|██▍       | 3847/16104 [17:54:12<53:30:01, 15.71s/it]


 24%|██▍       | 3849/16104 [17:54:48<56:03:27, 16.47s/it]

 24%|██▍       | 3850/16104 [17:55:07<59:00:33, 17.34s/it]

 24%|██▍       | 3851/16104 [17:55:20<54:11:02, 15.92s/it]

 24%|██▍       | 3852/16104 [17:55:37<56:16:25, 16.53s/it]

 24%|██▍       | 3853/16104 [17:55:57<59:23:33, 17.45s/it]
{'loss': 0.601, 'learning_rate': 1.7790830468894032e-06, 'rewards/chosen': -0.8305729031562805, 'rewards/rejected': -1.6056588888168335, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7750858068466187, 'policy_logps/rejected': -551.9259643554688, 'policy_logps/chosen': -465.84356689453125, 'referece_logps/rejected': -535.869384765625, 'referece_logps/chosen': -457.537841796875, 'logits/rejected': -0.45581746101379395, 'logits/chosen': -0.3235507607460022, 'epoch': 1.44}


 24%|██▍       | 3855/16104 [17:56:29<56:39:15, 16.65s/it]

 24%|██▍       | 3856/16104 [17:56:41<52:04:31, 15.31s/it]
{'loss': 0.5764, 'learning_rate': 1.778704634369317e-06, 'rewards/chosen': -0.7722553014755249, 'rewards/rejected': -1.470670223236084, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6984147429466248, 'policy_logps/rejected': -450.90155029296875, 'policy_logps/chosen': -550.5057373046875, 'referece_logps/rejected': -436.1948547363281, 'referece_logps/chosen': -542.783203125, 'logits/rejected': -1.5057013034820557, 'logits/chosen': -1.5206061601638794, 'epoch': 1.44}

 24%|██▍       | 3857/16104 [17:56:57<52:21:14, 15.39s/it]

 24%|██▍       | 3858/16104 [17:57:14<54:03:23, 15.89s/it]

 24%|██▍       | 3859/16104 [17:57:32<56:36:51, 16.64s/it]


 24%|██▍       | 3861/16104 [17:58:04<53:49:52, 15.83s/it]
{'loss': 0.6067, 'learning_rate': 1.7780733169040962e-06, 'rewards/chosen': -0.9961049556732178, 'rewards/rejected': -1.1468979120254517, 'rewards/accuracies': 0.5, 'rewards/margins': 0.1507928967475891, 'policy_logps/rejected': -398.9148254394531, 'policy_logps/chosen': -356.71337890625, 'referece_logps/rejected': -387.4458923339844, 'referece_logps/chosen': -346.7523193359375, 'logits/rejected': -0.6505447030067444, 'logits/chosen': -0.6578750014305115, 'epoch': 1.44}


 24%|██▍       | 3863/16104 [17:58:36<54:17:11, 15.97s/it]

 24%|██▍       | 3864/16104 [17:58:51<53:50:36, 15.84s/it]
{'loss': 0.6451, 'learning_rate': 1.777694148690651e-06, 'rewards/chosen': -0.6249980926513672, 'rewards/rejected': -0.6637868881225586, 'rewards/accuracies': 0.5, 'rewards/margins': 0.038788795471191406, 'policy_logps/rejected': -355.1957702636719, 'policy_logps/chosen': -415.48211669921875, 'referece_logps/rejected': -348.55792236328125, 'referece_logps/chosen': -409.2321472167969, 'logits/rejected': -0.01818113774061203, 'logits/chosen': -0.05378671735525131, 'epoch': 1.44}

 24%|██▍       | 3865/16104 [17:59:11<57:29:55, 16.91s/it]


 24%|██▍       | 3867/16104 [17:59:43<57:43:06, 16.98s/it]
{'loss': 0.4605, 'learning_rate': 1.7773146973451684e-06, 'rewards/chosen': -0.8770861029624939, 'rewards/rejected': -2.4016802310943604, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5245940685272217, 'policy_logps/rejected': -402.75238037109375, 'policy_logps/chosen': -432.88116455078125, 'referece_logps/rejected': -378.7355651855469, 'referece_logps/chosen': -424.11029052734375, 'logits/rejected': -0.4421232044696808, 'logits/chosen': -0.33644890785217285, 'epoch': 1.44}

 24%|██▍       | 3868/16104 [17:59:59<56:17:22, 16.56s/it]


 24%|██▍       | 3870/16104 [18:00:33<58:42:35, 17.28s/it]

 24%|██▍       | 3871/16104 [18:00:49<57:31:23, 16.93s/it]
{'loss': 0.5162, 'learning_rate': 1.7768083220290295e-06, 'rewards/chosen': -0.508924663066864, 'rewards/rejected': -0.7465349435806274, 'rewards/accuracies': 0.75, 'rewards/margins': 0.23761023581027985, 'policy_logps/rejected': -316.5458068847656, 'policy_logps/chosen': -289.5754089355469, 'referece_logps/rejected': -309.0804748535156, 'referece_logps/chosen': -284.48614501953125, 'logits/rejected': -0.3660232126712799, 'logits/chosen': -0.17181310057640076, 'epoch': 1.44}

 24%|██▍       | 3872/16104 [18:01:11<61:49:16, 18.19s/it]

 24%|██▍       | 3873/16104 [18:01:30<63:17:04, 18.63s/it]


 24%|██▍       | 3875/16104 [18:02:03<59:50:49, 17.62s/it]
{'loss': 0.5161, 'learning_rate': 1.7763014439403903e-06, 'rewards/chosen': -0.47293663024902344, 'rewards/rejected': -1.4636051654815674, 'rewards/accuracies': 1.0, 'rewards/margins': 0.990668535232544, 'policy_logps/rejected': -342.89080810546875, 'policy_logps/chosen': -396.3512878417969, 'referece_logps/rejected': -328.2547302246094, 'referece_logps/chosen': -391.6219177246094, 'logits/rejected': -0.08991971611976624, 'logits/chosen': -0.12862873077392578, 'epoch': 1.44}


 24%|██▍       | 3877/16104 [18:02:36<55:57:09, 16.47s/it]
{'loss': 0.5666, 'learning_rate': 1.7760478164588912e-06, 'rewards/chosen': -1.0196220874786377, 'rewards/rejected': -1.4952623844146729, 'rewards/accuracies': 0.875, 'rewards/margins': 0.47564029693603516, 'policy_logps/rejected': -322.9281921386719, 'policy_logps/chosen': -415.33843994140625, 'referece_logps/rejected': -307.9755554199219, 'referece_logps/chosen': -405.1422424316406, 'logits/rejected': -0.6027892827987671, 'logits/chosen': -0.6655279397964478, 'epoch': 1.44}

 24%|██▍       | 3878/16104 [18:02:55<58:11:26, 17.13s/it]


 24%|██▍       | 3880/16104 [18:03:18<48:41:10, 14.34s/it]

 24%|██▍       | 3881/16104 [18:03:38<54:24:15, 16.02s/it]
{'loss': 0.5124, 'learning_rate': 1.775540184826728e-06, 'rewards/chosen': -0.6737315654754639, 'rewards/rejected': -1.7604694366455078, 'rewards/accuracies': 1.0, 'rewards/margins': 1.086737871170044, 'policy_logps/rejected': -410.123291015625, 'policy_logps/chosen': -409.3240051269531, 'referece_logps/rejected': -392.51861572265625, 'referece_logps/chosen': -402.5867004394531, 'logits/rejected': -0.5253316760063171, 'logits/chosen': -0.5116806626319885, 'epoch': 1.45}


 24%|██▍       | 3883/16104 [18:04:15<58:45:09, 17.31s/it]
{'loss': 0.5788, 'learning_rate': 1.7752861807582019e-06, 'rewards/chosen': -0.951786994934082, 'rewards/rejected': -1.2323113679885864, 'rewards/accuracies': 0.375, 'rewards/margins': 0.2805243730545044, 'policy_logps/rejected': -399.896484375, 'policy_logps/chosen': -341.164306640625, 'referece_logps/rejected': -387.5733642578125, 'referece_logps/chosen': -331.64642333984375, 'logits/rejected': -0.39322686195373535, 'logits/chosen': -0.5590376853942871, 'epoch': 1.45}


 24%|██▍       | 3885/16104 [18:04:44<52:14:43, 15.39s/it]

 24%|██▍       | 3886/16104 [18:04:56<49:08:23, 14.48s/it]

 24%|██▍       | 3887/16104 [18:05:16<54:28:10, 16.05s/it]

 24%|██▍       | 3888/16104 [18:05:30<52:15:18, 15.40s/it]
{'loss': 0.5997, 'learning_rate': 1.7746506218469316e-06, 'rewards/chosen': -0.7388736009597778, 'rewards/rejected': -1.4012787342071533, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6624050140380859, 'policy_logps/rejected': -408.7124328613281, 'policy_logps/chosen': -456.76177978515625, 'referece_logps/rejected': -394.69964599609375, 'referece_logps/chosen': -449.373046875, 'logits/rejected': -1.1533708572387695, 'logits/chosen': -1.1402171850204468, 'epoch': 1.45}


 24%|██▍       | 3890/16104 [18:06:04<55:59:06, 16.50s/it]
{'loss': 0.5947, 'learning_rate': 1.7743961788944209e-06, 'rewards/chosen': -1.740136981010437, 'rewards/rejected': -1.9676333665847778, 'rewards/accuracies': 0.375, 'rewards/margins': 0.22749632596969604, 'policy_logps/rejected': -371.32427978515625, 'policy_logps/chosen': -367.94268798828125, 'referece_logps/rejected': -351.6479797363281, 'referece_logps/chosen': -350.5413513183594, 'logits/rejected': -0.35842716693878174, 'logits/chosen': -0.2964920401573181, 'epoch': 1.45}

 24%|██▍       | 3891/16104 [18:06:25<60:22:41, 17.80s/it]

 24%|██▍       | 3892/16104 [18:06:47<64:21:48, 18.97s/it]


 24%|██▍       | 3894/16104 [18:07:20<59:13:37, 17.46s/it]

 24%|██▍       | 3895/16104 [18:07:32<53:48:10, 15.86s/it]

 24%|██▍       | 3896/16104 [18:07:48<54:02:02, 15.93s/it]
{'loss': 0.5659, 'learning_rate': 1.7736320983847052e-06, 'rewards/chosen': -0.4603014886379242, 'rewards/rejected': -1.3141915798187256, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8538900017738342, 'policy_logps/rejected': -360.017333984375, 'policy_logps/chosen': -404.1922302246094, 'referece_logps/rejected': -346.8754577636719, 'referece_logps/chosen': -399.58917236328125, 'logits/rejected': -0.01790778338909149, 'logits/chosen': 0.0077999308705329895, 'epoch': 1.45}

 24%|██▍       | 3897/16104 [18:08:00<50:20:42, 14.85s/it]

 24%|██▍       | 3898/16104 [18:08:13<48:32:29, 14.32s/it]


 24%|██▍       | 3900/16104 [18:08:52<57:27:32, 16.95s/it]
{'loss': 0.5464, 'learning_rate': 1.7731220854135706e-06, 'rewards/chosen': -0.9809566736221313, 'rewards/rejected': -1.4698326587677002, 'rewards/accuracies': 0.625, 'rewards/margins': 0.48887601494789124, 'policy_logps/rejected': -527.6116943359375, 'policy_logps/chosen': -510.616455078125, 'referece_logps/rejected': -512.913330078125, 'referece_logps/chosen': -500.806884765625, 'logits/rejected': 0.3099675178527832, 'logits/chosen': 0.20133638381958008, 'epoch': 1.45}

 24%|██▍       | 3901/16104 [18:09:09<58:11:14, 17.17s/it]


 24%|██▍       | 3903/16104 [18:09:44<57:33:54, 16.99s/it]

 24%|██▍       | 3904/16104 [18:10:02<58:20:02, 17.21s/it]
{'loss': 0.5326, 'learning_rate': 1.7726115720557738e-06, 'rewards/chosen': -0.37512046098709106, 'rewards/rejected': -1.1360585689544678, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7609381079673767, 'policy_logps/rejected': -278.3953552246094, 'policy_logps/chosen': -310.4823913574219, 'referece_logps/rejected': -267.0347595214844, 'referece_logps/chosen': -306.7311706542969, 'logits/rejected': -0.3192189335823059, 'logits/chosen': -0.3832084834575653, 'epoch': 1.45}

 24%|██▍       | 3905/16104 [18:10:15<53:46:20, 15.87s/it]


 24%|██▍       | 3907/16104 [18:10:42<51:20:16, 15.15s/it]
{'loss': 0.5598, 'learning_rate': 1.772228358857434e-06, 'rewards/chosen': -0.976861298084259, 'rewards/rejected': -1.0960392951965332, 'rewards/accuracies': 0.5, 'rewards/margins': 0.1191779300570488, 'policy_logps/rejected': -345.42352294921875, 'policy_logps/chosen': -308.0934143066406, 'referece_logps/rejected': -334.463134765625, 'referece_logps/chosen': -298.32476806640625, 'logits/rejected': -0.6051717400550842, 'logits/chosen': -0.42491310834884644, 'epoch': 1.46}

 24%|██▍       | 3908/16104 [18:10:55<49:07:19, 14.50s/it]

 24%|██▍       | 3909/16104 [18:11:18<56:50:33, 16.78s/it]

 24%|██▍       | 3910/16104 [18:11:31<53:40:31, 15.85s/it]


 24%|██▍       | 3912/16104 [18:12:04<54:05:22, 15.97s/it]
{'loss': 0.574, 'learning_rate': 1.7715890455021913e-06, 'rewards/chosen': -1.1011070013046265, 'rewards/rejected': -1.2233062982559204, 'rewards/accuracies': 0.625, 'rewards/margins': 0.12219921499490738, 'policy_logps/rejected': -394.8366394042969, 'policy_logps/chosen': -428.1882019042969, 'referece_logps/rejected': -382.60357666015625, 'referece_logps/chosen': -417.1770935058594, 'logits/rejected': -0.7860355973243713, 'logits/chosen': -0.6976974010467529, 'epoch': 1.46}

 24%|██▍       | 3913/16104 [18:12:25<58:52:46, 17.39s/it]

 24%|██▍       | 3914/16104 [18:12:38<54:06:06, 15.98s/it]

 24%|██▍       | 3915/16104 [18:12:59<59:21:13, 17.53s/it]

 24%|██▍       | 3916/16104 [18:13:21<63:47:45, 18.84s/it]

 24%|██▍       | 3917/16104 [18:13:37<61:18:20, 18.11s/it]

 24%|██▍       | 3918/16104 [18:13:55<61:19:07, 18.11s/it]

 24%|██▍       | 3919/16104 [18:14:09<56:43:47, 16.76s/it]


 24%|██▍       | 3921/16104 [18:14:44<58:39:09, 17.33s/it]
{'loss': 0.6048, 'learning_rate': 1.7704363155321994e-06, 'rewards/chosen': -1.1285934448242188, 'rewards/rejected': -1.1087977886199951, 'rewards/accuracies': 0.5, 'rewards/margins': -0.019795559346675873, 'policy_logps/rejected': -354.2320251464844, 'policy_logps/chosen': -258.45831298828125, 'referece_logps/rejected': -343.14404296875, 'referece_logps/chosen': -247.17237854003906, 'logits/rejected': -0.0735897496342659, 'logits/chosen': -0.07825291901826859, 'epoch': 1.46}

 24%|██▍       | 3922/16104 [18:15:00<56:45:59, 16.78s/it]


 24%|██▍       | 3924/16104 [18:15:30<55:28:06, 16.39s/it]

 24%|██▍       | 3925/16104 [18:15:43<51:09:55, 15.12s/it]
{'loss': 0.5403, 'learning_rate': 1.7699231805728765e-06, 'rewards/chosen': -0.6701461672782898, 'rewards/rejected': -1.7431317567825317, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0729856491088867, 'policy_logps/rejected': -336.1302490234375, 'policy_logps/chosen': -314.4798583984375, 'referece_logps/rejected': -318.6989440917969, 'referece_logps/chosen': -307.77838134765625, 'logits/rejected': -0.4768840968608856, 'logits/chosen': -0.4594493508338928, 'epoch': 1.46}

 24%|██▍       | 3926/16104 [18:16:02<55:33:41, 16.42s/it]

 24%|██▍       | 3927/16104 [18:16:13<49:45:41, 14.71s/it]

 24%|██▍       | 3928/16104 [18:16:28<50:09:06, 14.83s/it]

 24%|██▍       | 3929/16104 [18:16:48<55:08:59, 16.31s/it]

 24%|██▍       | 3930/16104 [18:17:03<54:35:31, 16.14s/it]

 24%|██▍       | 3931/16104 [18:17:20<55:29:49, 16.41s/it]


 24%|██▍       | 3933/16104 [18:17:57<58:12:34, 17.22s/it]
{'loss': 0.4746, 'learning_rate': 1.7688954160379486e-06, 'rewards/chosen': -0.7965974807739258, 'rewards/rejected': -1.2609341144561768, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4643366038799286, 'policy_logps/rejected': -403.38702392578125, 'policy_logps/chosen': -305.30133056640625, 'referece_logps/rejected': -390.77764892578125, 'referece_logps/chosen': -297.3353271484375, 'logits/rejected': -0.33510100841522217, 'logits/chosen': -0.2062523066997528, 'epoch': 1.47}

 24%|██▍       | 3934/16104 [18:18:14<58:10:07, 17.21s/it]

 24%|██▍       | 3935/16104 [18:18:26<52:46:21, 15.61s/it]


 24%|██▍       | 3937/16104 [18:19:03<57:25:04, 16.99s/it]
{'loss': 0.535, 'learning_rate': 1.7683807871275422e-06, 'rewards/chosen': -1.1012940406799316, 'rewards/rejected': -2.5307047367095947, 'rewards/accuracies': 0.75, 'rewards/margins': 1.429410696029663, 'policy_logps/rejected': -369.54766845703125, 'policy_logps/chosen': -578.2188110351562, 'referece_logps/rejected': -344.24066162109375, 'referece_logps/chosen': -567.2058715820312, 'logits/rejected': -0.1467479169368744, 'logits/chosen': -0.13748782873153687, 'epoch': 1.47}

 24%|██▍       | 3938/16104 [18:19:24<61:50:56, 18.30s/it]

 24%|██▍       | 3939/16104 [18:19:36<55:28:57, 16.42s/it]

 24%|██▍       | 3940/16104 [18:19:50<52:52:02, 15.65s/it]

 24%|██▍       | 3941/16104 [18:20:03<49:46:57, 14.73s/it]

 24%|██▍       | 3942/16104 [18:20:18<49:42:28, 14.71s/it]

 24%|██▍       | 3943/16104 [18:20:29<46:14:40, 13.69s/it]

 24%|██▍       | 3944/16104 [18:20:44<47:59:44, 14.21s/it]

 24%|██▍       | 3945/16104 [18:21:02<51:06:34, 15.13s/it]

 25%|██▍       | 3946/16104 [18:21:14<48:46:48, 14.44s/it]


 25%|██▍       | 3948/16104 [18:21:45<49:45:57, 14.74s/it]
{'loss': 0.4761, 'learning_rate': 1.7669629943311983e-06, 'rewards/chosen': -0.6131715774536133, 'rewards/rejected': -1.283806562423706, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6706351041793823, 'policy_logps/rejected': -322.4493713378906, 'policy_logps/chosen': -385.0120544433594, 'referece_logps/rejected': -309.6112976074219, 'referece_logps/chosen': -378.8803405761719, 'logits/rejected': -1.0225483179092407, 'logits/chosen': -1.060308814048767, 'epoch': 1.47}

 25%|██▍       | 3949/16104 [18:22:03<52:38:32, 15.59s/it]

 25%|██▍       | 3950/16104 [18:22:15<49:40:47, 14.72s/it]

 25%|██▍       | 3951/16104 [18:22:30<49:07:16, 14.55s/it]

 25%|██▍       | 3952/16104 [18:22:48<52:47:10, 15.64s/it]

 25%|██▍       | 3953/16104 [18:23:08<57:19:16, 16.98s/it]


 25%|██▍       | 3955/16104 [18:23:41<55:48:28, 16.54s/it]
{'loss': 0.4775, 'learning_rate': 1.7660588075373993e-06, 'rewards/chosen': -0.8299577832221985, 'rewards/rejected': -1.2412078380584717, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4112500846385956, 'policy_logps/rejected': -315.4345397949219, 'policy_logps/chosen': -311.998046875, 'referece_logps/rejected': -303.0224304199219, 'referece_logps/chosen': -303.698486328125, 'logits/rejected': -0.7500606179237366, 'logits/chosen': -0.730133056640625, 'epoch': 1.47}

 25%|██▍       | 3956/16104 [18:24:03<61:02:13, 18.09s/it]


 25%|██▍       | 3958/16104 [18:24:27<51:01:26, 15.12s/it]
{'loss': 0.515, 'learning_rate': 1.7656708339802643e-06, 'rewards/chosen': -0.8016301393508911, 'rewards/rejected': -1.7291233539581299, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9274934530258179, 'policy_logps/rejected': -312.91119384765625, 'policy_logps/chosen': -301.3324279785156, 'referece_logps/rejected': -295.6199951171875, 'referece_logps/chosen': -293.31610107421875, 'logits/rejected': -0.5370299220085144, 'logits/chosen': -0.6286640167236328, 'epoch': 1.47}


 25%|██▍       | 3960/16104 [18:25:03<56:28:53, 16.74s/it]
{'loss': 0.5609, 'learning_rate': 1.7654120300696978e-06, 'rewards/chosen': -1.0472122430801392, 'rewards/rejected': -1.1663591861724854, 'rewards/accuracies': 0.375, 'rewards/margins': 0.1191469132900238, 'policy_logps/rejected': -304.7988586425781, 'policy_logps/chosen': -329.8194580078125, 'referece_logps/rejected': -293.1352844238281, 'referece_logps/chosen': -319.3472900390625, 'logits/rejected': -0.5123246908187866, 'logits/chosen': -0.6177793145179749, 'epoch': 1.48}

 25%|██▍       | 3961/16104 [18:25:23<58:50:38, 17.45s/it]

 25%|██▍       | 3962/16104 [18:25:42<61:04:33, 18.11s/it]

 25%|██▍       | 3963/16104 [18:26:04<64:34:31, 19.15s/it]


 25%|██▍       | 3965/16104 [18:26:31<56:12:49, 16.67s/it]
{'loss': 0.5444, 'learning_rate': 1.7647644785449966e-06, 'rewards/chosen': -0.5126113891601562, 'rewards/rejected': -1.2151920795440674, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7025806307792664, 'policy_logps/rejected': -281.1116943359375, 'policy_logps/chosen': -339.5601806640625, 'referece_logps/rejected': -268.95977783203125, 'referece_logps/chosen': -334.4340515136719, 'logits/rejected': 0.02713078260421753, 'logits/chosen': 0.17579731345176697, 'epoch': 1.48}

 25%|██▍       | 3966/16104 [18:26:55<63:01:39, 18.69s/it]

 25%|██▍       | 3967/16104 [18:27:12<61:03:51, 18.11s/it]


 25%|██▍       | 3969/16104 [18:27:52<64:35:39, 19.16s/it]
{'loss': 0.6088, 'learning_rate': 1.764245880444239e-06, 'rewards/chosen': -1.3462681770324707, 'rewards/rejected': -1.8621078729629517, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5158397555351257, 'policy_logps/rejected': -323.6546325683594, 'policy_logps/chosen': -395.4241027832031, 'referece_logps/rejected': -305.0335388183594, 'referece_logps/chosen': -381.96142578125, 'logits/rejected': -0.22460773587226868, 'logits/chosen': -0.2108227014541626, 'epoch': 1.48}

 25%|██▍       | 3970/16104 [18:28:13<67:14:26, 19.95s/it]

 25%|██▍       | 3971/16104 [18:28:25<59:07:41, 17.54s/it]

 25%|██▍       | 3972/16104 [18:28:48<64:18:46, 19.08s/it]

 25%|██▍       | 3973/16104 [18:29:04<61:15:58, 18.18s/it]

 25%|██▍       | 3974/16104 [18:29:25<63:55:15, 18.97s/it]

 25%|██▍       | 3975/16104 [18:29:37<56:33:54, 16.79s/it]

 25%|██▍       | 3976/16104 [18:29:56<59:02:05, 17.52s/it]

 25%|██▍       | 3977/16104 [18:30:15<61:08:35, 18.15s/it]

 25%|██▍       | 3978/16104 [18:30:26<53:56:45, 16.02s/it]

 25%|██▍       | 3979/16104 [18:30:40<51:35:41, 15.32s/it]


 25%|██▍       | 3981/16104 [18:31:10<51:53:41, 15.41s/it]
{'loss': 0.5422, 'learning_rate': 1.762687119635797e-06, 'rewards/chosen': -0.8855255246162415, 'rewards/rejected': -1.1925840377807617, 'rewards/accuracies': 0.625, 'rewards/margins': 0.30705854296684265, 'policy_logps/rejected': -731.1307373046875, 'policy_logps/chosen': -403.1856994628906, 'referece_logps/rejected': -719.2048950195312, 'referece_logps/chosen': -394.3304748535156, 'logits/rejected': -1.1322513818740845, 'logits/chosen': -0.9279079437255859, 'epoch': 1.48}


 25%|██▍       | 3983/16104 [18:31:44<54:02:54, 16.05s/it]
{'loss': 0.5039, 'learning_rate': 1.7624268939935702e-06, 'rewards/chosen': -0.6788078546524048, 'rewards/rejected': -1.3238626718521118, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6450548768043518, 'policy_logps/rejected': -266.71893310546875, 'policy_logps/chosen': -298.7890319824219, 'referece_logps/rejected': -253.48028564453125, 'referece_logps/chosen': -292.0009460449219, 'logits/rejected': -1.2482483386993408, 'logits/chosen': -1.3412729501724243, 'epoch': 1.48}

 25%|██▍       | 3984/16104 [18:32:02<56:14:44, 16.71s/it]

 25%|██▍       | 3985/16104 [18:32:22<59:19:16, 17.62s/it]

 25%|██▍       | 3986/16104 [18:32:38<57:38:34, 17.12s/it]

 25%|██▍       | 3987/16104 [18:32:50<53:06:39, 15.78s/it]

 25%|██▍       | 3988/16104 [18:33:09<56:20:30, 16.74s/it]

 25%|██▍       | 3989/16104 [18:33:28<58:34:05, 17.40s/it]

 25%|██▍       | 3990/16104 [18:33:45<58:15:43, 17.31s/it]

 25%|██▍       | 3991/16104 [18:34:05<60:32:53, 18.00s/it]

 25%|██▍       | 3992/16104 [18:34:26<64:06:31, 19.05s/it]

 25%|██▍       | 3993/16104 [18:34:45<63:42:48, 18.94s/it]

 25%|██▍       | 3994/16104 [18:35:00<60:00:22, 17.84s/it]

 25%|██▍       | 3995/16104 [18:35:14<55:37:36, 16.54s/it]

 25%|██▍       | 3996/16104 [18:35:37<62:03:58, 18.45s/it]

 25%|██▍       | 3997/16104 [18:35:52<58:24:25, 17.37s/it]

 25%|██▍       | 3998/16104 [18:36:07<56:03:37, 16.67s/it]

 25%|██▍       | 3999/16104 [18:36:25<57:15:11, 17.03s/it]


 25%|██▍       | 4001/16104 [18:37:16<73:55:30, 21.99s/it]
{'loss': 0.4867, 'learning_rate': 1.7600793167978208e-06, 'rewards/chosen': -1.1806074380874634, 'rewards/rejected': -1.9023443460464478, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7217368483543396, 'policy_logps/rejected': -314.4549560546875, 'policy_logps/chosen': -422.7689514160156, 'referece_logps/rejected': -295.4315490722656, 'referece_logps/chosen': -410.9629211425781, 'logits/rejected': -0.09355368465185165, 'logits/chosen': -0.12764042615890503, 'epoch': 1.49}

 25%|██▍       | 4002/16104 [18:37:36<71:35:05, 21.29s/it]

 25%|██▍       | 4003/16104 [18:37:52<66:17:06, 19.72s/it]

 25%|██▍       | 4004/16104 [18:38:09<63:45:19, 18.97s/it]

 25%|██▍       | 4005/16104 [18:38:20<55:30:34, 16.52s/it]

 25%|██▍       | 4006/16104 [18:38:32<51:26:29, 15.31s/it]

 25%|██▍       | 4007/16104 [18:38:49<52:37:23, 15.66s/it]

 25%|██▍       | 4008/16104 [18:39:10<58:03:38, 17.28s/it]

 25%|██▍       | 4009/16104 [18:39:29<59:34:43, 17.73s/it]

 25%|██▍       | 4010/16104 [18:39:41<53:55:00, 16.05s/it]

 25%|██▍       | 4011/16104 [18:40:01<57:31:50, 17.13s/it]

 25%|██▍       | 4012/16104 [18:40:12<51:45:28, 15.41s/it]

 25%|██▍       | 4013/16104 [18:40:33<57:23:22, 17.09s/it]

 25%|██▍       | 4014/16104 [18:40:49<56:34:26, 16.85s/it]

 25%|██▍       | 4015/16104 [18:41:08<58:46:39, 17.50s/it]


 25%|██▍       | 4017/16104 [18:41:40<56:59:37, 16.98s/it]
{'loss': 0.5332, 'learning_rate': 1.7579842174966084e-06, 'rewards/chosen': -1.3622803688049316, 'rewards/rejected': -1.8024356365203857, 'rewards/accuracies': 0.375, 'rewards/margins': 0.4401552677154541, 'policy_logps/rejected': -319.171142578125, 'policy_logps/chosen': -219.17018127441406, 'referece_logps/rejected': -301.14678955078125, 'referece_logps/chosen': -205.54737854003906, 'logits/rejected': -0.8531538248062134, 'logits/chosen': -0.8133411407470703, 'epoch': 1.5}

 25%|██▍       | 4018/16104 [18:42:00<59:40:51, 17.78s/it]

 25%|██▍       | 4019/16104 [18:42:20<62:02:51, 18.48s/it]

 25%|██▍       | 4020/16104 [18:42:40<63:43:59, 18.99s/it]

 25%|██▍       | 4021/16104 [18:42:55<59:05:47, 17.61s/it]

 25%|██▍       | 4022/16104 [18:43:11<57:51:29, 17.24s/it]

 25%|██▍       | 4023/16104 [18:43:30<59:02:12, 17.59s/it]

 25%|██▍       | 4024/16104 [18:43:48<59:28:04, 17.72s/it]

 25%|██▍       | 4025/16104 [18:44:05<59:13:45, 17.65s/it]

 25%|██▌       | 4026/16104 [18:44:18<54:32:49, 16.26s/it]

 25%|██▌       | 4027/16104 [18:44:31<51:02:33, 15.22s/it]

 25%|██▌       | 4028/16104 [18:44:43<48:00:12, 14.31s/it]

 25%|██▌       | 4029/16104 [18:45:03<53:27:38, 15.94s/it]

 25%|██▌       | 4030/16104 [18:45:22<57:04:42, 17.02s/it]

 25%|██▌       | 4031/16104 [18:45:42<59:36:49, 17.78s/it]

 25%|██▌       | 4032/16104 [18:46:00<59:59:16, 17.89s/it]

 25%|██▌       | 4033/16104 [18:46:13<55:10:00, 16.45s/it]


 25%|██▌       | 4035/16104 [18:46:53<60:53:04, 18.16s/it]
{'loss': 0.4815, 'learning_rate': 1.7556178493593927e-06, 'rewards/chosen': -0.8042280077934265, 'rewards/rejected': -2.7739105224609375, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9696826934814453, 'policy_logps/rejected': -581.2797241210938, 'policy_logps/chosen': -579.5573120117188, 'referece_logps/rejected': -553.5406494140625, 'referece_logps/chosen': -571.5150146484375, 'logits/rejected': 0.2867755889892578, 'logits/chosen': 0.2266373485326767, 'epoch': 1.5}

 25%|██▌       | 4036/16104 [18:47:14<64:12:58, 19.16s/it]

 25%|██▌       | 4037/16104 [18:47:33<64:10:45, 19.15s/it]

 25%|██▌       | 4038/16104 [18:47:46<57:37:26, 17.19s/it]

 25%|██▌       | 4039/16104 [18:48:06<60:40:31, 18.10s/it]

 25%|██▌       | 4040/16104 [18:48:27<63:44:49, 19.02s/it]

 25%|██▌       | 4041/16104 [18:48:43<60:11:38, 17.96s/it]


 25%|██▌       | 4043/16104 [18:49:10<52:12:30, 15.58s/it]

 25%|██▌       | 4044/16104 [18:49:25<51:21:29, 15.33s/it]

 25%|██▌       | 4045/16104 [18:49:41<52:05:24, 15.55s/it]

 25%|██▌       | 4046/16104 [18:50:00<55:52:26, 16.68s/it]

 25%|██▌       | 4047/16104 [18:50:18<57:29:52, 17.17s/it]

 25%|██▌       | 4048/16104 [18:50:38<60:25:43, 18.04s/it]

 25%|██▌       | 4049/16104 [18:51:00<64:24:56, 19.24s/it]
{'loss': 0.557, 'learning_rate': 1.7537704924185066e-06, 'rewards/chosen': -0.5086374282836914, 'rewards/rejected': -1.1062085628509521, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5975710153579712, 'policy_logps/rejected': -379.5390930175781, 'policy_logps/chosen': -287.5414733886719, 'referece_logps/rejected': -368.4769592285156, 'referece_logps/chosen': -282.4551086425781, 'logits/rejected': -1.0856094360351562, 'logits/chosen': -1.06559157371521, 'epoch': 1.51}


 25%|██▌       | 4051/16104 [18:51:38<64:01:19, 19.12s/it]

 25%|██▌       | 4052/16104 [18:51:53<59:54:27, 17.89s/it]

 25%|██▌       | 4053/16104 [18:52:12<61:42:43, 18.44s/it]

 25%|██▌       | 4054/16104 [18:52:30<60:59:08, 18.22s/it]
{'loss': 0.5406, 'learning_rate': 1.7531092729816718e-06, 'rewards/chosen': -1.0186848640441895, 'rewards/rejected': -1.1074774265289307, 'rewards/accuracies': 0.375, 'rewards/margins': 0.08879242092370987, 'policy_logps/rejected': -367.3046875, 'policy_logps/chosen': -432.6813659667969, 'referece_logps/rejected': -356.22998046875, 'referece_logps/chosen': -422.4945068359375, 'logits/rejected': 0.16492408514022827, 'logits/chosen': 0.0856831818819046, 'epoch': 1.51}


 25%|██▌       | 4056/16104 [18:53:00<55:35:09, 16.61s/it]

 25%|██▌       | 4057/16104 [18:53:17<56:08:12, 16.78s/it]

 25%|██▌       | 4058/16104 [18:53:35<57:18:13, 17.13s/it]
{'loss': 0.5416, 'learning_rate': 1.7525797490370732e-06, 'rewards/chosen': -0.4439886212348938, 'rewards/rejected': -1.1914145946502686, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7474260926246643, 'policy_logps/rejected': -331.9743957519531, 'policy_logps/chosen': -267.3529968261719, 'referece_logps/rejected': -320.06024169921875, 'referece_logps/chosen': -262.9130859375, 'logits/rejected': -0.942007839679718, 'logits/chosen': -0.9715640544891357, 'epoch': 1.51}


 25%|██▌       | 4060/16104 [18:54:07<55:28:49, 16.58s/it]

 25%|██▌       | 4061/16104 [18:54:26<57:36:36, 17.22s/it]
{'loss': 0.5885, 'learning_rate': 1.752182286406351e-06, 'rewards/chosen': -0.9313545823097229, 'rewards/rejected': -1.6496431827545166, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7182885408401489, 'policy_logps/rejected': -500.3893737792969, 'policy_logps/chosen': -331.3429260253906, 'referece_logps/rejected': -483.8929443359375, 'referece_logps/chosen': -322.02935791015625, 'logits/rejected': 0.1125897616147995, 'logits/chosen': 0.07002106308937073, 'epoch': 1.51}

 25%|██▌       | 4062/16104 [18:54:42<56:10:58, 16.80s/it]

 25%|██▌       | 4063/16104 [18:55:02<59:20:18, 17.74s/it]

 25%|██▌       | 4064/16104 [18:55:18<57:38:01, 17.23s/it]


 25%|██▌       | 4066/16104 [18:55:56<61:11:27, 18.30s/it]

 25%|██▌       | 4067/16104 [18:56:07<53:35:14, 16.03s/it]
{'loss': 0.5982, 'learning_rate': 1.7513865397576058e-06, 'rewards/chosen': -0.766692578792572, 'rewards/rejected': -1.4640847444534302, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6973922848701477, 'policy_logps/rejected': -465.2047424316406, 'policy_logps/chosen': -479.50677490234375, 'referece_logps/rejected': -450.56390380859375, 'referece_logps/chosen': -471.8398132324219, 'logits/rejected': -0.36820554733276367, 'logits/chosen': -0.3218439817428589, 'epoch': 1.52}


 25%|██▌       | 4069/16104 [18:56:39<51:45:47, 15.48s/it]

 25%|██▌       | 4070/16104 [18:56:55<52:21:54, 15.67s/it]

 25%|██▌       | 4071/16104 [18:57:15<56:55:30, 17.03s/it]

 25%|██▌       | 4072/16104 [18:57:27<51:29:02, 15.40s/it]

 25%|██▌       | 4073/16104 [18:57:41<50:24:24, 15.08s/it]

 25%|██▌       | 4074/16104 [18:57:53<47:38:07, 14.25s/it]

 25%|██▌       | 4075/16104 [18:58:05<45:29:10, 13.61s/it]

 25%|██▌       | 4076/16104 [18:58:20<46:42:28, 13.98s/it]

 25%|██▌       | 4077/16104 [18:58:34<46:36:14, 13.95s/it]
{'loss': 0.497, 'learning_rate': 1.750057864322184e-06, 'rewards/chosen': -1.2911276817321777, 'rewards/rejected': -1.7863588333129883, 'rewards/accuracies': 0.625, 'rewards/margins': 0.49523115158081055, 'policy_logps/rejected': -312.724853515625, 'policy_logps/chosen': -307.2066955566406, 'referece_logps/rejected': -294.8612365722656, 'referece_logps/chosen': -294.29541015625, 'logits/rejected': -1.366426944732666, 'logits/chosen': -1.4560072422027588, 'epoch': 1.52}


 25%|██▌       | 4079/16104 [18:59:14<56:23:24, 16.88s/it]

 25%|██▌       | 4080/16104 [18:59:29<54:33:14, 16.33s/it]

 25%|██▌       | 4081/16104 [18:59:49<57:41:53, 17.28s/it]

 25%|██▌       | 4082/16104 [19:00:03<55:08:40, 16.51s/it]

 25%|██▌       | 4083/16104 [19:00:19<53:55:39, 16.15s/it]

 25%|██▌       | 4084/16104 [19:00:31<50:17:57, 15.06s/it]

 25%|██▌       | 4085/16104 [19:00:47<51:00:52, 15.28s/it]

 25%|██▌       | 4086/16104 [19:01:07<55:30:36, 16.63s/it]
{'loss': 0.4888, 'learning_rate': 1.748859462106925e-06, 'rewards/chosen': -0.7156619429588318, 'rewards/rejected': -1.269619107246399, 'rewards/accuracies': 0.625, 'rewards/margins': 0.553956925868988, 'policy_logps/rejected': -439.5390625, 'policy_logps/chosen': -543.3907470703125, 'referece_logps/rejected': -426.8428649902344, 'referece_logps/chosen': -536.234130859375, 'logits/rejected': -0.3837290406227112, 'logits/chosen': -0.38568028807640076, 'epoch': 1.52}


 25%|██▌       | 4088/16104 [19:01:32<49:29:37, 14.83s/it]
{'loss': 0.5682, 'learning_rate': 1.7485928171454986e-06, 'rewards/chosen': -1.1226383447647095, 'rewards/rejected': -1.167904019355774, 'rewards/accuracies': 0.5, 'rewards/margins': 0.04526577517390251, 'policy_logps/rejected': -520.4642333984375, 'policy_logps/chosen': -405.09210205078125, 'referece_logps/rejected': -508.7852783203125, 'referece_logps/chosen': -393.86572265625, 'logits/rejected': -0.9924163818359375, 'logits/chosen': -0.9557774662971497, 'epoch': 1.52}


 25%|██▌       | 4090/16104 [19:02:05<51:27:00, 15.42s/it]

 25%|██▌       | 4091/16104 [19:02:26<56:57:56, 17.07s/it]

 25%|██▌       | 4092/16104 [19:02:45<58:42:44, 17.60s/it]

 25%|██▌       | 4093/16104 [19:02:57<52:42:51, 15.80s/it]

 25%|██▌       | 4094/16104 [19:03:17<56:47:19, 17.02s/it]

 25%|██▌       | 4095/16104 [19:03:33<55:42:35, 16.70s/it]

 25%|██▌       | 4096/16104 [19:03:53<59:08:27, 17.73s/it]

 25%|██▌       | 4097/16104 [19:04:10<58:21:14, 17.50s/it]
{'loss': 0.5237, 'learning_rate': 1.7473914164876542e-06, 'rewards/chosen': -0.5436651110649109, 'rewards/rejected': -1.188677191734314, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6450120210647583, 'policy_logps/rejected': -314.46942138671875, 'policy_logps/chosen': -277.25714111328125, 'referece_logps/rejected': -302.5826416015625, 'referece_logps/chosen': -271.82049560546875, 'logits/rejected': -0.3162389099597931, 'logits/chosen': -0.2991020977497101, 'epoch': 1.53}


 25%|██▌       | 4099/16104 [19:04:51<63:53:20, 19.16s/it]

 25%|██▌       | 4100/16104 [19:05:09<62:14:19, 18.67s/it]

 25%|██▌       | 4101/16104 [19:05:22<56:23:46, 16.91s/it]

 25%|██▌       | 4102/16104 [19:05:35<52:28:47, 15.74s/it]
{'loss': 0.5088, 'learning_rate': 1.7467229132596261e-06, 'rewards/chosen': -1.2365175485610962, 'rewards/rejected': -2.0566952228546143, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8201777935028076, 'policy_logps/rejected': -372.157470703125, 'policy_logps/chosen': -564.385498046875, 'referece_logps/rejected': -351.59051513671875, 'referece_logps/chosen': -552.0203857421875, 'logits/rejected': -0.03286054730415344, 'logits/chosen': 0.012779466807842255, 'epoch': 1.53}


 25%|██▌       | 4104/16104 [19:06:13<57:51:53, 17.36s/it]

 25%|██▌       | 4105/16104 [19:06:31<58:56:14, 17.68s/it]

 25%|██▌       | 4106/16104 [19:06:51<60:49:15, 18.25s/it]

 26%|██▌       | 4107/16104 [19:07:07<59:04:44, 17.73s/it]
{'loss': 0.5499, 'learning_rate': 1.7460536548747999e-06, 'rewards/chosen': -0.8663563132286072, 'rewards/rejected': -1.3502051830291748, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4838488698005676, 'policy_logps/rejected': -300.90869140625, 'policy_logps/chosen': -309.9539794921875, 'referece_logps/rejected': -287.4066162109375, 'referece_logps/chosen': -301.2904357910156, 'logits/rejected': -0.8163180947303772, 'logits/chosen': -0.6933369636535645, 'epoch': 1.53}

 26%|██▌       | 4108/16104 [19:07:21<54:43:47, 16.42s/it]


 26%|██▌       | 4110/16104 [19:07:52<53:23:20, 16.02s/it]

 26%|██▌       | 4111/16104 [19:08:12<57:03:12, 17.13s/it]

 26%|██▌       | 4112/16104 [19:08:34<62:23:50, 18.73s/it]
{'loss': 0.4556, 'learning_rate': 1.7453836420099935e-06, 'rewards/chosen': -0.6220808625221252, 'rewards/rejected': -1.054539680480957, 'rewards/accuracies': 0.625, 'rewards/margins': 0.43245893716812134, 'policy_logps/rejected': -303.4365539550781, 'policy_logps/chosen': -382.633056640625, 'referece_logps/rejected': -292.89117431640625, 'referece_logps/chosen': -376.4122619628906, 'logits/rejected': -0.003789164125919342, 'logits/chosen': 0.04384975507855415, 'epoch': 1.53}


 26%|██▌       | 4114/16104 [19:09:09<61:45:25, 18.54s/it]

 26%|██▌       | 4115/16104 [19:09:27<61:29:00, 18.46s/it]

 26%|██▌       | 4116/16104 [19:09:48<63:45:05, 19.14s/it]

 26%|██▌       | 4117/16104 [19:10:09<65:24:43, 19.64s/it]
{'loss': 0.501, 'learning_rate': 1.7447128753427864e-06, 'rewards/chosen': -0.7750437259674072, 'rewards/rejected': -1.6539466381072998, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8789030313491821, 'policy_logps/rejected': -363.92010498046875, 'policy_logps/chosen': -414.91436767578125, 'referece_logps/rejected': -347.380615234375, 'referece_logps/chosen': -407.1639404296875, 'logits/rejected': 0.16741353273391724, 'logits/chosen': 0.19116386771202087, 'epoch': 1.53}


 26%|██▌       | 4119/16104 [19:10:39<56:46:49, 17.06s/it]

 26%|██▌       | 4120/16104 [19:10:59<60:06:19, 18.06s/it]
{'loss': 0.4382, 'learning_rate': 1.744310053799469e-06, 'rewards/chosen': -1.455956220626831, 'rewards/rejected': -2.5882785320281982, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1323221921920776, 'policy_logps/rejected': -426.9907531738281, 'policy_logps/chosen': -408.47955322265625, 'referece_logps/rejected': -401.10797119140625, 'referece_logps/chosen': -393.9200134277344, 'logits/rejected': -0.31121087074279785, 'logits/chosen': -0.17243528366088867, 'epoch': 1.54}


 26%|██▌       | 4122/16104 [19:11:37<61:29:29, 18.48s/it]

 26%|██▌       | 4123/16104 [19:11:49<54:51:51, 16.49s/it]

 26%|██▌       | 4124/16104 [19:12:07<56:32:09, 16.99s/it]

 26%|██▌       | 4125/16104 [19:12:24<56:01:11, 16.84s/it]

 26%|██▌       | 4126/16104 [19:12:38<53:30:36, 16.08s/it]

 26%|██▌       | 4127/16104 [19:12:58<57:13:05, 17.20s/it]

 26%|██▌       | 4128/16104 [19:13:20<62:13:07, 18.70s/it]

 26%|██▌       | 4129/16104 [19:13:38<61:54:12, 18.61s/it]

 26%|██▌       | 4130/16104 [19:13:58<63:08:52, 18.99s/it]

 26%|██▌       | 4131/16104 [19:14:19<65:19:59, 19.64s/it]

 26%|██▌       | 4132/16104 [19:14:38<64:23:13, 19.36s/it]

 26%|██▌       | 4133/16104 [19:14:53<60:07:02, 18.08s/it]

 26%|██▌       | 4134/16104 [19:15:05<53:56:52, 16.22s/it]

 26%|██▌       | 4135/16104 [19:15:26<58:21:39, 17.55s/it]

 26%|██▌       | 4136/16104 [19:15:38<52:59:27, 15.94s/it]

 26%|██▌       | 4137/16104 [19:15:58<56:57:02, 17.13s/it]
{'loss': 0.4531, 'learning_rate': 1.7420222842282298e-06, 'rewards/chosen': -0.42349207401275635, 'rewards/rejected': -1.5638706684112549, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1403785943984985, 'policy_logps/rejected': -269.2919006347656, 'policy_logps/chosen': -363.1120300292969, 'referece_logps/rejected': -253.65316772460938, 'referece_logps/chosen': -358.87713623046875, 'logits/rejected': -1.0905593633651733, 'logits/chosen': -0.9649561643600464, 'epoch': 1.54}


 26%|██▌       | 4139/16104 [19:16:33<58:04:31, 17.47s/it]

 26%|██▌       | 4140/16104 [19:16:54<61:20:12, 18.46s/it]

 26%|██▌       | 4141/16104 [19:17:12<60:48:37, 18.30s/it]
{'loss': 0.5476, 'learning_rate': 1.7414827238366673e-06, 'rewards/chosen': -0.41286611557006836, 'rewards/rejected': -1.2166471481323242, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8037810325622559, 'policy_logps/rejected': -330.0890808105469, 'policy_logps/chosen': -444.8147277832031, 'referece_logps/rejected': -317.9226379394531, 'referece_logps/chosen': -440.6860656738281, 'logits/rejected': 0.04307714104652405, 'logits/chosen': 0.06390886008739471, 'epoch': 1.54}


 26%|██▌       | 4143/16104 [19:17:37<50:33:21, 15.22s/it]

 26%|██▌       | 4144/16104 [19:17:47<46:05:02, 13.87s/it]

 26%|██▌       | 4145/16104 [19:17:59<44:06:16, 13.28s/it]

 26%|██▌       | 4146/16104 [19:18:20<51:35:51, 15.53s/it]

 26%|██▌       | 4147/16104 [19:18:35<50:46:27, 15.29s/it]
{'loss': 0.6794, 'learning_rate': 1.7406724835296043e-06, 'rewards/chosen': -0.90374755859375, 'rewards/rejected': -0.9639164209365845, 'rewards/accuracies': 0.5, 'rewards/margins': 0.06016884744167328, 'policy_logps/rejected': -445.7596435546875, 'policy_logps/chosen': -464.4705810546875, 'referece_logps/rejected': -436.1204833984375, 'referece_logps/chosen': -455.4331359863281, 'logits/rejected': -0.30046236515045166, 'logits/chosen': -0.2516326904296875, 'epoch': 1.55}

 26%|██▌       | 4148/16104 [19:18:56<56:25:04, 16.99s/it]

 26%|██▌       | 4149/16104 [19:19:16<59:19:02, 17.86s/it]


 26%|██▌       | 4151/16104 [19:19:56<62:53:28, 18.94s/it]

 26%|██▌       | 4152/16104 [19:20:16<64:14:28, 19.35s/it]

 26%|██▌       | 4153/16104 [19:20:38<66:45:47, 20.11s/it]

 26%|██▌       | 4154/16104 [19:20:49<57:25:52, 17.30s/it]
{'loss': 0.5654, 'learning_rate': 1.7397258400051347e-06, 'rewards/chosen': -0.9293368458747864, 'rewards/rejected': -1.196837306022644, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2675005793571472, 'policy_logps/rejected': -267.17132568359375, 'policy_logps/chosen': -379.2188415527344, 'referece_logps/rejected': -255.20294189453125, 'referece_logps/chosen': -369.92547607421875, 'logits/rejected': -0.4377105236053467, 'logits/chosen': -0.4185697138309479, 'epoch': 1.55}

 26%|██▌       | 4155/16104 [19:21:09<60:17:53, 18.17s/it]

 26%|██▌       | 4156/16104 [19:21:29<62:20:34, 18.78s/it]

 26%|██▌       | 4157/16104 [19:21:45<59:26:44, 17.91s/it]


 26%|██▌       | 4159/16104 [19:22:21<58:34:41, 17.65s/it]
{'loss': 0.54, 'learning_rate': 1.7390487682527973e-06, 'rewards/chosen': -1.1652864217758179, 'rewards/rejected': -2.2612452507019043, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0959585905075073, 'policy_logps/rejected': -563.3641357421875, 'policy_logps/chosen': -395.365966796875, 'referece_logps/rejected': -540.7516479492188, 'referece_logps/chosen': -383.7131042480469, 'logits/rejected': -0.9789482951164246, 'logits/chosen': -0.6887102723121643, 'epoch': 1.55}


 26%|██▌       | 4161/16104 [19:23:00<62:15:09, 18.76s/it]
{'loss': 0.5003, 'learning_rate': 1.7387777302426191e-06, 'rewards/chosen': -0.44554203748703003, 'rewards/rejected': -1.7121317386627197, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2665897607803345, 'policy_logps/rejected': -320.8769226074219, 'policy_logps/chosen': -377.75689697265625, 'referece_logps/rejected': -303.7555847167969, 'referece_logps/chosen': -373.30145263671875, 'logits/rejected': 0.16247396171092987, 'logits/chosen': 0.19099752604961395, 'epoch': 1.55}

 26%|██▌       | 4162/16104 [19:23:19<62:31:32, 18.85s/it]

 26%|██▌       | 4163/16104 [19:23:39<63:38:50, 19.19s/it]


 26%|██▌       | 4165/16104 [19:24:13<59:00:54, 17.79s/it]

 26%|██▌       | 4166/16104 [19:24:29<56:58:57, 17.18s/it]

 26%|██▌       | 4167/16104 [19:24:40<51:27:56, 15.52s/it]
{'loss': 0.6314, 'learning_rate': 1.7379638991505514e-06, 'rewards/chosen': -0.6563526391983032, 'rewards/rejected': -1.0490669012069702, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3927142322063446, 'policy_logps/rejected': -296.3000183105469, 'policy_logps/chosen': -236.94032287597656, 'referece_logps/rejected': -285.8093566894531, 'referece_logps/chosen': -230.37680053710938, 'logits/rejected': -0.5845973491668701, 'logits/chosen': -0.7241004705429077, 'epoch': 1.55}

 26%|██▌       | 4168/16104 [19:24:52<47:56:01, 14.46s/it]


 26%|██▌       | 4170/16104 [19:25:27<53:42:35, 16.20s/it]
{'loss': 0.5572, 'learning_rate': 1.7375565805290177e-06, 'rewards/chosen': -0.6555652022361755, 'rewards/rejected': -1.3231834173202515, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6676181554794312, 'policy_logps/rejected': -377.0505676269531, 'policy_logps/chosen': -389.2198791503906, 'referece_logps/rejected': -363.8187561035156, 'referece_logps/chosen': -382.66424560546875, 'logits/rejected': -0.789993166923523, 'logits/chosen': -0.7663307785987854, 'epoch': 1.55}

 26%|██▌       | 4171/16104 [19:25:44<54:15:56, 16.37s/it]


 26%|██▌       | 4173/16104 [19:26:19<55:43:03, 16.81s/it]
{'loss': 0.566, 'learning_rate': 1.7371489933881728e-06, 'rewards/chosen': -1.0377389192581177, 'rewards/rejected': -1.8520755767822266, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8143367171287537, 'policy_logps/rejected': -422.2834777832031, 'policy_logps/chosen': -445.4497375488281, 'referece_logps/rejected': -403.7627258300781, 'referece_logps/chosen': -435.0723876953125, 'logits/rejected': -0.48645561933517456, 'logits/chosen': -0.3741084337234497, 'epoch': 1.55}

 26%|██▌       | 4174/16104 [19:26:40<60:06:42, 18.14s/it]


 26%|██▌       | 4176/16104 [19:27:15<57:46:30, 17.44s/it]
{'loss': 0.517, 'learning_rate': 1.7367411378764047e-06, 'rewards/chosen': -0.8549970984458923, 'rewards/rejected': -1.2456066608428955, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3906095623970032, 'policy_logps/rejected': -385.2328796386719, 'policy_logps/chosen': -428.8604736328125, 'referece_logps/rejected': -372.7768249511719, 'referece_logps/chosen': -420.31048583984375, 'logits/rejected': -0.0187300443649292, 'logits/chosen': -0.15666446089744568, 'epoch': 1.56}

 26%|██▌       | 4177/16104 [19:27:28<53:47:18, 16.24s/it]

 26%|██▌       | 4178/16104 [19:27:42<50:54:19, 15.37s/it]


 26%|██▌       | 4180/16104 [19:28:17<54:54:02, 16.58s/it]
{'loss': 0.5231, 'learning_rate': 1.7361969133181584e-06, 'rewards/chosen': -1.2174257040023804, 'rewards/rejected': -2.471207857131958, 'rewards/accuracies': 0.875, 'rewards/margins': 1.253782033920288, 'policy_logps/rejected': -490.42669677734375, 'policy_logps/chosen': -492.65875244140625, 'referece_logps/rejected': -465.71453857421875, 'referece_logps/chosen': -480.4844665527344, 'logits/rejected': -0.8088290691375732, 'logits/chosen': -0.835235595703125, 'epoch': 1.56}


 26%|██▌       | 4182/16104 [19:28:49<53:05:03, 16.03s/it]
{'loss': 0.5831, 'learning_rate': 1.7359246223341438e-06, 'rewards/chosen': -0.9969339370727539, 'rewards/rejected': -1.1879006624221802, 'rewards/accuracies': 0.5, 'rewards/margins': 0.19096669554710388, 'policy_logps/rejected': -561.6161499023438, 'policy_logps/chosen': -355.8824462890625, 'referece_logps/rejected': -549.7371826171875, 'referece_logps/chosen': -345.9131164550781, 'logits/rejected': -0.15748700499534607, 'logits/chosen': -0.2385290414094925, 'epoch': 1.56}

 26%|██▌       | 4183/16104 [19:29:06<54:28:13, 16.45s/it]


 26%|██▌       | 4185/16104 [19:29:43<58:52:20, 17.78s/it]

 26%|██▌       | 4186/16104 [19:30:01<59:00:26, 17.82s/it]

 26%|██▌       | 4187/16104 [19:30:21<60:54:33, 18.40s/it]

 26%|██▌       | 4188/16104 [19:30:39<60:18:33, 18.22s/it]

 26%|██▌       | 4189/16104 [19:30:59<61:55:43, 18.71s/it]
{'loss': 0.4054, 'learning_rate': 1.734970666441289e-06, 'rewards/chosen': -0.7608538269996643, 'rewards/rejected': -1.5877485275268555, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8268948197364807, 'policy_logps/rejected': -345.97210693359375, 'policy_logps/chosen': -380.10980224609375, 'referece_logps/rejected': -330.0946044921875, 'referece_logps/chosen': -372.5012512207031, 'logits/rejected': -1.1556349992752075, 'logits/chosen': -1.1033892631530762, 'epoch': 1.56}


 26%|██▌       | 4191/16104 [19:31:33<60:17:11, 18.22s/it]

 26%|██▌       | 4192/16104 [19:31:53<61:49:22, 18.68s/it]
{'loss': 0.4502, 'learning_rate': 1.7345613821280836e-06, 'rewards/chosen': -0.6034351587295532, 'rewards/rejected': -1.5296361446380615, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9262008666992188, 'policy_logps/rejected': -294.3379211425781, 'policy_logps/chosen': -287.35028076171875, 'referece_logps/rejected': -279.04156494140625, 'referece_logps/chosen': -281.31597900390625, 'logits/rejected': -1.1348820924758911, 'logits/chosen': -1.1401516199111938, 'epoch': 1.56}

 26%|██▌       | 4193/16104 [19:32:14<64:16:02, 19.42s/it]

 26%|██▌       | 4194/16104 [19:32:33<63:02:31, 19.06s/it]

 26%|██▌       | 4195/16104 [19:32:53<64:05:08, 19.37s/it]

 26%|██▌       | 4196/16104 [19:33:12<64:29:09, 19.50s/it]


 26%|██▌       | 4198/16104 [19:33:50<63:15:53, 19.13s/it]
{'loss': 0.5023, 'learning_rate': 1.733742011364193e-06, 'rewards/chosen': -0.6589257717132568, 'rewards/rejected': -1.8524715900421143, 'rewards/accuracies': 0.875, 'rewards/margins': 1.193545937538147, 'policy_logps/rejected': -221.73269653320312, 'policy_logps/chosen': -379.99114990234375, 'referece_logps/rejected': -203.20797729492188, 'referece_logps/chosen': -373.4018859863281, 'logits/rejected': 0.031928449869155884, 'logits/chosen': -0.04477277398109436, 'epoch': 1.56}


 26%|██▌       | 4200/16104 [19:34:24<59:46:47, 18.08s/it]

 26%|██▌       | 4201/16104 [19:34:35<53:04:06, 16.05s/it]
{'loss': 0.5825, 'learning_rate': 1.733331925211813e-06, 'rewards/chosen': -0.08335857093334198, 'rewards/rejected': -0.7262611389160156, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6429026126861572, 'policy_logps/rejected': -453.878173828125, 'policy_logps/chosen': -504.55987548828125, 'referece_logps/rejected': -446.61553955078125, 'referece_logps/chosen': -503.7262878417969, 'logits/rejected': -0.09320180863142014, 'logits/chosen': -0.12254782021045685, 'epoch': 1.57}

 26%|██▌       | 4202/16104 [19:34:46<48:05:05, 14.54s/it]


 26%|██▌       | 4204/16104 [19:35:14<47:24:52, 14.34s/it]
{'loss': 0.5996, 'learning_rate': 1.732921572078175e-06, 'rewards/chosen': -1.043125867843628, 'rewards/rejected': -1.1106516122817993, 'rewards/accuracies': 0.625, 'rewards/margins': 0.0675256997346878, 'policy_logps/rejected': -451.2898864746094, 'policy_logps/chosen': -423.4139404296875, 'referece_logps/rejected': -440.18341064453125, 'referece_logps/chosen': -412.9826354980469, 'logits/rejected': -1.6191110610961914, 'logits/chosen': -1.4745824337005615, 'epoch': 1.57}

 26%|██▌       | 4205/16104 [19:35:36<55:08:36, 16.68s/it]


 26%|██▌       | 4207/16104 [19:36:08<55:00:24, 16.64s/it]

 26%|██▌       | 4208/16104 [19:36:23<53:54:48, 16.32s/it]

 26%|██▌       | 4209/16104 [19:36:43<57:27:47, 17.39s/it]

 26%|██▌       | 4210/16104 [19:37:02<58:18:24, 17.65s/it]

 26%|██▌       | 4211/16104 [19:37:15<54:20:35, 16.45s/it]
{'loss': 0.5419, 'learning_rate': 1.7319630440119526e-06, 'rewards/chosen': -0.4742833971977234, 'rewards/rejected': -1.5021966695785522, 'rewards/accuracies': 1.0, 'rewards/margins': 1.027913212776184, 'policy_logps/rejected': -278.79742431640625, 'policy_logps/chosen': -313.4791259765625, 'referece_logps/rejected': -263.7754821777344, 'referece_logps/chosen': -308.73626708984375, 'logits/rejected': -0.3671976625919342, 'logits/chosen': -0.3498590886592865, 'epoch': 1.57}

 26%|██▌       | 4212/16104 [19:37:33<55:30:07, 16.80s/it]


 26%|██▌       | 4214/16104 [19:38:08<56:07:32, 16.99s/it]
{'loss': 0.4646, 'learning_rate': 1.7315518020203029e-06, 'rewards/chosen': -0.7663912177085876, 'rewards/rejected': -1.339463710784912, 'rewards/accuracies': 1.0, 'rewards/margins': 0.573072612285614, 'policy_logps/rejected': -377.36578369140625, 'policy_logps/chosen': -397.06982421875, 'referece_logps/rejected': -363.97113037109375, 'referece_logps/chosen': -389.4058532714844, 'logits/rejected': -0.09987262636423111, 'logits/chosen': -0.17595532536506653, 'epoch': 1.57}

 26%|██▌       | 4215/16104 [19:38:27<57:51:12, 17.52s/it]

 26%|██▌       | 4216/16104 [19:38:43<56:29:27, 17.11s/it]


 26%|██▌       | 4218/16104 [19:39:18<56:38:54, 17.16s/it]
{'loss': 0.4933, 'learning_rate': 1.7310030650946106e-06, 'rewards/chosen': -0.6579370498657227, 'rewards/rejected': -1.527488112449646, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8695511221885681, 'policy_logps/rejected': -420.6124267578125, 'policy_logps/chosen': -411.91058349609375, 'referece_logps/rejected': -405.3375244140625, 'referece_logps/chosen': -405.3312072753906, 'logits/rejected': -0.18690240383148193, 'logits/chosen': -0.21682807803153992, 'epoch': 1.57}

 26%|██▌       | 4219/16104 [19:39:39<60:29:50, 18.32s/it]

 26%|██▌       | 4220/16104 [19:39:55<57:39:51, 17.47s/it]

 26%|██▌       | 4221/16104 [19:40:13<58:23:27, 17.69s/it]

 26%|██▌       | 4222/16104 [19:40:33<60:28:25, 18.32s/it]


 26%|██▌       | 4224/16104 [19:41:10<60:53:47, 18.45s/it]
{'loss': 0.5058, 'learning_rate': 1.7301790727058343e-06, 'rewards/chosen': -0.9032543897628784, 'rewards/rejected': -1.757889986038208, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8546355366706848, 'policy_logps/rejected': -263.8273010253906, 'policy_logps/chosen': -449.8804016113281, 'referece_logps/rejected': -246.24839782714844, 'referece_logps/chosen': -440.84783935546875, 'logits/rejected': -0.2587507367134094, 'logits/chosen': -0.2634395956993103, 'epoch': 1.57}


 26%|██▌       | 4226/16104 [19:41:42<56:49:29, 17.22s/it]

 26%|██▌       | 4227/16104 [19:42:00<57:33:18, 17.45s/it]
{'loss': 0.5498, 'learning_rate': 1.729766677686308e-06, 'rewards/chosen': -0.801949679851532, 'rewards/rejected': -1.361487865447998, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5595383048057556, 'policy_logps/rejected': -307.72265625, 'policy_logps/chosen': -318.0616455078125, 'referece_logps/rejected': -294.1077880859375, 'referece_logps/chosen': -310.04217529296875, 'logits/rejected': -0.040888845920562744, 'logits/chosen': -0.08060497045516968, 'epoch': 1.57}


 26%|██▋       | 4229/16104 [19:42:26<49:46:36, 15.09s/it]
{'loss': 0.632, 'learning_rate': 1.7294916000622012e-06, 'rewards/chosen': -0.8185937404632568, 'rewards/rejected': -0.8605713248252869, 'rewards/accuracies': 0.625, 'rewards/margins': 0.04197748005390167, 'policy_logps/rejected': -478.83795166015625, 'policy_logps/chosen': -298.07794189453125, 'referece_logps/rejected': -470.2322082519531, 'referece_logps/chosen': -289.89202880859375, 'logits/rejected': -0.571157693862915, 'logits/chosen': -0.5320331454277039, 'epoch': 1.58}


 26%|██▋       | 4231/16104 [19:42:54<48:38:48, 14.75s/it]

 26%|██▋       | 4232/16104 [19:43:08<47:29:22, 14.40s/it]
{'loss': 0.653, 'learning_rate': 1.7290787623206792e-06, 'rewards/chosen': -0.3979642987251282, 'rewards/rejected': -1.5608676671981812, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1629034280776978, 'policy_logps/rejected': -371.1518859863281, 'policy_logps/chosen': -304.1996154785156, 'referece_logps/rejected': -355.5431823730469, 'referece_logps/chosen': -300.219970703125, 'logits/rejected': -0.8391667604446411, 'logits/chosen': -0.900990903377533, 'epoch': 1.58}


 26%|██▋       | 4234/16104 [19:43:46<55:08:13, 16.72s/it]
{'loss': 0.6655, 'learning_rate': 1.7288033896877026e-06, 'rewards/chosen': -1.074864149093628, 'rewards/rejected': -1.406069278717041, 'rewards/accuracies': 0.625, 'rewards/margins': 0.33120501041412354, 'policy_logps/rejected': -418.1259765625, 'policy_logps/chosen': -363.5182800292969, 'referece_logps/rejected': -404.0652770996094, 'referece_logps/chosen': -352.7696228027344, 'logits/rejected': -0.46360015869140625, 'logits/chosen': -0.40959566831588745, 'epoch': 1.58}

 26%|██▋       | 4235/16104 [19:43:57<49:58:04, 15.16s/it]

 26%|██▋       | 4236/16104 [19:44:13<50:22:52, 15.28s/it]

 26%|██▋       | 4237/16104 [19:44:33<54:55:14, 16.66s/it]


 26%|██▋       | 4239/16104 [19:44:54<45:02:28, 13.67s/it]
{'loss': 0.5134, 'learning_rate': 1.7281144422783222e-06, 'rewards/chosen': -0.45889559388160706, 'rewards/rejected': -1.5964372158050537, 'rewards/accuracies': 0.875, 'rewards/margins': 1.137541651725769, 'policy_logps/rejected': -368.9122314453125, 'policy_logps/chosen': -331.52447509765625, 'referece_logps/rejected': -352.9478454589844, 'referece_logps/chosen': -326.93548583984375, 'logits/rejected': -0.5846120715141296, 'logits/chosen': -0.2010265290737152, 'epoch': 1.58}


 26%|██▋       | 4241/16104 [19:45:20<44:55:50, 13.63s/it]
{'loss': 0.5539, 'learning_rate': 1.7278386571008454e-06, 'rewards/chosen': -1.1681015491485596, 'rewards/rejected': -1.610183835029602, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4420822560787201, 'policy_logps/rejected': -633.7471313476562, 'policy_logps/chosen': -557.4437255859375, 'referece_logps/rejected': -617.6453247070312, 'referece_logps/chosen': -545.7627563476562, 'logits/rejected': -0.18164868652820587, 'logits/chosen': 0.020942479372024536, 'epoch': 1.58}

 26%|██▋       | 4242/16104 [19:45:31<42:01:38, 12.75s/it]


 26%|██▋       | 4244/16104 [19:45:56<41:15:53, 12.53s/it]

 26%|██▋       | 4245/16104 [19:46:08<40:47:37, 12.38s/it]
{'loss': 0.5745, 'learning_rate': 1.7272867334820687e-06, 'rewards/chosen': -0.48261183500289917, 'rewards/rejected': -1.3284770250320435, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8458651900291443, 'policy_logps/rejected': -320.33734130859375, 'policy_logps/chosen': -537.8821411132812, 'referece_logps/rejected': -307.0525817871094, 'referece_logps/chosen': -533.0560302734375, 'logits/rejected': -0.41071972250938416, 'logits/chosen': -0.573307991027832, 'epoch': 1.58}


 26%|██▋       | 4247/16104 [19:46:45<51:17:26, 15.57s/it]
{'loss': 0.6443, 'learning_rate': 1.7270105951300737e-06, 'rewards/chosen': -0.8304475545883179, 'rewards/rejected': -0.9785299301147461, 'rewards/accuracies': 0.5, 'rewards/margins': 0.14808236062526703, 'policy_logps/rejected': -377.245361328125, 'policy_logps/chosen': -348.03692626953125, 'referece_logps/rejected': -367.4600524902344, 'referece_logps/chosen': -339.7324523925781, 'logits/rejected': -0.40374040603637695, 'logits/chosen': -0.6072469353675842, 'epoch': 1.58}


 26%|██▋       | 4249/16104 [19:47:17<53:04:06, 16.12s/it]
{'loss': 0.6403, 'learning_rate': 1.7267343391425763e-06, 'rewards/chosen': -0.7053675651550293, 'rewards/rejected': -0.8371559381484985, 'rewards/accuracies': 0.375, 'rewards/margins': 0.13178838789463043, 'policy_logps/rejected': -325.7400817871094, 'policy_logps/chosen': -489.8467102050781, 'referece_logps/rejected': -317.3684997558594, 'referece_logps/chosen': -482.79302978515625, 'logits/rejected': -0.3326966166496277, 'logits/chosen': 0.004200935363769531, 'epoch': 1.58}

 26%|██▋       | 4250/16104 [19:47:32<52:03:50, 15.81s/it]


 26%|██▋       | 4252/16104 [19:47:57<46:19:05, 14.07s/it]
{'loss': 0.5833, 'learning_rate': 1.7263197346925497e-06, 'rewards/chosen': -1.2940651178359985, 'rewards/rejected': -1.469799518585205, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17573431134223938, 'policy_logps/rejected': -385.19818115234375, 'policy_logps/chosen': -702.1203002929688, 'referece_logps/rejected': -370.5002136230469, 'referece_logps/chosen': -689.1796875, 'logits/rejected': -0.523730993270874, 'logits/chosen': -0.3990385830402374, 'epoch': 1.58}

 26%|██▋       | 4253/16104 [19:48:07<42:51:32, 13.02s/it]


 26%|██▋       | 4255/16104 [19:48:31<40:55:43, 12.44s/it]
{'loss': 0.6618, 'learning_rate': 1.7259048658141662e-06, 'rewards/chosen': -1.0722049474716187, 'rewards/rejected': -1.7188717126846313, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6466667056083679, 'policy_logps/rejected': -317.4580383300781, 'policy_logps/chosen': -264.56964111328125, 'referece_logps/rejected': -300.2693176269531, 'referece_logps/chosen': -253.84756469726562, 'logits/rejected': -1.3688640594482422, 'logits/chosen': -1.3076177835464478, 'epoch': 1.59}

 26%|██▋       | 4256/16104 [19:48:41<39:19:53, 11.95s/it]


 26%|██▋       | 4258/16104 [19:49:16<48:38:37, 14.78s/it]
{'loss': 0.5191, 'learning_rate': 1.725489732658465e-06, 'rewards/chosen': -0.5262260437011719, 'rewards/rejected': -1.6714601516723633, 'rewards/accuracies': 0.75, 'rewards/margins': 1.145234227180481, 'policy_logps/rejected': -528.45751953125, 'policy_logps/chosen': -542.9738159179688, 'referece_logps/rejected': -511.7428894042969, 'referece_logps/chosen': -537.7115478515625, 'logits/rejected': 0.7281513214111328, 'logits/chosen': 0.7659645080566406, 'epoch': 1.59}

 26%|██▋       | 4259/16104 [19:49:27<44:45:11, 13.60s/it]

 26%|██▋       | 4260/16104 [19:49:48<51:19:55, 15.60s/it]

 26%|██▋       | 4261/16104 [19:50:01<49:35:32, 15.07s/it]

 26%|██▋       | 4262/16104 [19:50:13<46:23:40, 14.10s/it]

 26%|██▋       | 4263/16104 [19:50:26<45:18:57, 13.78s/it]

 26%|██▋       | 4264/16104 [19:50:41<46:36:22, 14.17s/it]


 26%|██▋       | 4266/16104 [19:51:13<47:45:54, 14.53s/it]
{'loss': 0.5644, 'learning_rate': 1.7243814200371702e-06, 'rewards/chosen': -0.17839431762695312, 'rewards/rejected': -1.3354638814926147, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1570695638656616, 'policy_logps/rejected': -314.36199951171875, 'policy_logps/chosen': -344.3726806640625, 'referece_logps/rejected': -301.00738525390625, 'referece_logps/chosen': -342.5887145996094, 'logits/rejected': -0.002456553280353546, 'logits/chosen': -0.140655979514122, 'epoch': 1.59}


 27%|██▋       | 4268/16104 [19:51:53<57:12:46, 17.40s/it]
{'loss': 0.6036, 'learning_rate': 1.724104048744508e-06, 'rewards/chosen': -1.033843755722046, 'rewards/rejected': -1.8623713254928589, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8285275101661682, 'policy_logps/rejected': -391.271728515625, 'policy_logps/chosen': -461.9154357910156, 'referece_logps/rejected': -372.6480407714844, 'referece_logps/chosen': -451.5770568847656, 'logits/rejected': -0.8544562458992004, 'logits/chosen': -0.8686680793762207, 'epoch': 1.59}

 27%|██▋       | 4269/16104 [19:52:14<60:51:06, 18.51s/it]

 27%|██▋       | 4270/16104 [19:52:34<62:23:07, 18.98s/it]


 27%|██▋       | 4272/16104 [19:53:09<59:58:23, 18.25s/it]
{'loss': 0.5543, 'learning_rate': 1.7235489547084757e-06, 'rewards/chosen': -0.7139384746551514, 'rewards/rejected': -1.2839871644973755, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5700485110282898, 'policy_logps/rejected': -621.49560546875, 'policy_logps/chosen': -482.8843994140625, 'referece_logps/rejected': -608.65576171875, 'referece_logps/chosen': -475.7449951171875, 'logits/rejected': -0.1513751745223999, 'logits/chosen': -0.1720729023218155, 'epoch': 1.59}

 27%|██▋       | 4273/16104 [19:53:22<54:36:35, 16.62s/it]

 27%|██▋       | 4274/16104 [19:53:36<52:08:43, 15.87s/it]

 27%|██▋       | 4275/16104 [19:53:50<50:50:40, 15.47s/it]

 27%|██▋       | 4276/16104 [19:54:02<46:46:57, 14.24s/it]


 27%|██▋       | 4278/16104 [19:54:27<44:22:29, 13.51s/it]
{'loss': 0.5752, 'learning_rate': 1.7227154357014363e-06, 'rewards/chosen': -0.32528096437454224, 'rewards/rejected': -1.0617883205413818, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7365073561668396, 'policy_logps/rejected': -429.30230712890625, 'policy_logps/chosen': -426.4361572265625, 'referece_logps/rejected': -418.6844482421875, 'referece_logps/chosen': -423.18328857421875, 'logits/rejected': -1.4452697038650513, 'logits/chosen': -1.5849682092666626, 'epoch': 1.59}

 27%|██▋       | 4279/16104 [19:54:40<44:00:19, 13.40s/it]

 27%|██▋       | 4280/16104 [19:55:00<50:40:31, 15.43s/it]

 27%|██▋       | 4281/16104 [19:55:20<55:12:38, 16.81s/it]

 27%|██▋       | 4282/16104 [19:55:43<60:54:26, 18.55s/it]


 27%|██▋       | 4284/16104 [19:56:13<56:32:29, 17.22s/it]
{'loss': 0.5547, 'learning_rate': 1.7218808642298744e-06, 'rewards/chosen': -0.7371142506599426, 'rewards/rejected': -1.1311391592025757, 'rewards/accuracies': 0.5, 'rewards/margins': 0.39402493834495544, 'policy_logps/rejected': -400.04168701171875, 'policy_logps/chosen': -569.7989501953125, 'referece_logps/rejected': -388.7303161621094, 'referece_logps/chosen': -562.4278564453125, 'logits/rejected': -0.5340713262557983, 'logits/chosen': -0.6611935496330261, 'epoch': 1.6}

 27%|██▋       | 4285/16104 [19:56:26<51:59:50, 15.84s/it]

 27%|██▋       | 4286/16104 [19:56:39<49:51:55, 15.19s/it]


 27%|██▋       | 4288/16104 [19:57:11<51:02:12, 15.55s/it]
{'loss': 0.5056, 'learning_rate': 1.7213238991464345e-06, 'rewards/chosen': -1.0205044746398926, 'rewards/rejected': -2.1222524642944336, 'rewards/accuracies': 0.875, 'rewards/margins': 1.101747989654541, 'policy_logps/rejected': -326.2252197265625, 'policy_logps/chosen': -333.1604309082031, 'referece_logps/rejected': -305.0026550292969, 'referece_logps/chosen': -322.9554138183594, 'logits/rejected': -0.4789961278438568, 'logits/chosen': -0.45741361379623413, 'epoch': 1.6}

 27%|██▋       | 4289/16104 [19:57:31<54:58:40, 16.75s/it]

 27%|██▋       | 4290/16104 [19:57:44<51:38:57, 15.74s/it]

 27%|██▋       | 4291/16104 [19:58:04<56:15:19, 17.14s/it]


 27%|██▋       | 4293/16104 [19:58:39<57:28:48, 17.52s/it]
{'loss': 0.5336, 'learning_rate': 1.7206270363105645e-06, 'rewards/chosen': -0.8170168399810791, 'rewards/rejected': -1.3752723932266235, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5582555532455444, 'policy_logps/rejected': -392.09991455078125, 'policy_logps/chosen': -352.0268859863281, 'referece_logps/rejected': -378.34716796875, 'referece_logps/chosen': -343.8567199707031, 'logits/rejected': -0.27407440543174744, 'logits/chosen': -0.18467092514038086, 'epoch': 1.6}

 27%|██▋       | 4294/16104 [19:58:56<56:34:48, 17.25s/it]


 27%|██▋       | 4296/16104 [19:59:33<58:10:36, 17.74s/it]
{'loss': 0.5523, 'learning_rate': 1.7202085687561427e-06, 'rewards/chosen': -0.9963164925575256, 'rewards/rejected': -1.388372540473938, 'rewards/accuracies': 0.625, 'rewards/margins': 0.39205604791641235, 'policy_logps/rejected': -346.8544921875, 'policy_logps/chosen': -347.4715270996094, 'referece_logps/rejected': -332.9707336425781, 'referece_logps/chosen': -337.5083312988281, 'logits/rejected': -0.5724509358406067, 'logits/chosen': -0.5852190852165222, 'epoch': 1.6}

 27%|██▋       | 4297/16104 [19:59:50<57:50:14, 17.63s/it]

 27%|██▋       | 4298/16104 [20:00:10<59:25:27, 18.12s/it]

 27%|██▋       | 4299/16104 [20:00:28<59:46:30, 18.23s/it]

 27%|██▋       | 4300/16104 [20:00:48<61:25:15, 18.73s/it]

 27%|██▋       | 4301/16104 [20:00:58<53:10:18, 16.22s/it]


 27%|██▋       | 4303/16104 [20:01:33<56:24:17, 17.21s/it]
{'loss': 0.4953, 'learning_rate': 1.7192311250457552e-06, 'rewards/chosen': -0.4989449679851532, 'rewards/rejected': -1.1659021377563477, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6669572591781616, 'policy_logps/rejected': -348.3722229003906, 'policy_logps/chosen': -316.0624694824219, 'referece_logps/rejected': -336.71319580078125, 'referece_logps/chosen': -311.072998046875, 'logits/rejected': -0.8894193768501282, 'logits/chosen': -0.9609537720680237, 'epoch': 1.6}


 27%|██▋       | 4305/16104 [20:02:09<57:07:37, 17.43s/it]
{'loss': 0.4651, 'learning_rate': 1.7189515934818182e-06, 'rewards/chosen': -1.2964109182357788, 'rewards/rejected': -2.623549222946167, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3271383047103882, 'policy_logps/rejected': -314.89569091796875, 'policy_logps/chosen': -511.5200500488281, 'referece_logps/rejected': -288.6601867675781, 'referece_logps/chosen': -498.5559997558594, 'logits/rejected': -0.8199554681777954, 'logits/chosen': -0.8558011054992676, 'epoch': 1.6}


 27%|██▋       | 4307/16104 [20:02:51<62:55:12, 19.20s/it]
{'loss': 0.4741, 'learning_rate': 1.7186719455863824e-06, 'rewards/chosen': -1.7740567922592163, 'rewards/rejected': -2.5797717571258545, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8057149052619934, 'policy_logps/rejected': -399.096435546875, 'policy_logps/chosen': -348.3484191894531, 'referece_logps/rejected': -373.2986755371094, 'referece_logps/chosen': -330.60784912109375, 'logits/rejected': -0.25661611557006836, 'logits/chosen': -0.30447953939437866, 'epoch': 1.6}

 27%|██▋       | 4308/16104 [20:03:11<63:09:59, 19.28s/it]

 27%|██▋       | 4309/16104 [20:03:26<59:20:49, 18.11s/it]

 27%|██▋       | 4310/16104 [20:03:38<53:34:17, 16.35s/it]

 27%|██▋       | 4311/16104 [20:03:49<48:03:03, 14.67s/it]

 27%|██▋       | 4312/16104 [20:04:04<48:39:35, 14.86s/it]

 27%|██▋       | 4313/16104 [20:04:17<46:11:22, 14.10s/it]

 27%|██▋       | 4314/16104 [20:04:31<46:31:38, 14.21s/it]

 27%|██▋       | 4315/16104 [20:04:53<53:49:27, 16.44s/it]

 27%|██▋       | 4316/16104 [20:05:11<55:25:02, 16.92s/it]

 27%|██▋       | 4317/16104 [20:05:23<50:36:44, 15.46s/it]

 27%|██▋       | 4318/16104 [20:05:35<47:15:48, 14.44s/it]

 27%|██▋       | 4319/16104 [20:05:55<52:23:45, 16.01s/it]

 27%|██▋       | 4320/16104 [20:06:11<52:46:38, 16.12s/it]


 27%|██▋       | 4322/16104 [20:06:40<48:44:11, 14.89s/it]

 27%|██▋       | 4323/16104 [20:07:00<53:42:08, 16.41s/it]
{'loss': 0.5611, 'learning_rate': 1.7164305799227857e-06, 'rewards/chosen': -0.8522286415100098, 'rewards/rejected': -0.8356585502624512, 'rewards/accuracies': 0.375, 'rewards/margins': -0.0165700763463974, 'policy_logps/rejected': -236.18199157714844, 'policy_logps/chosen': -339.5384216308594, 'referece_logps/rejected': -227.8253936767578, 'referece_logps/chosen': -331.01611328125, 'logits/rejected': -0.4375441372394562, 'logits/chosen': -0.35212624073028564, 'epoch': 1.61}

 27%|██▋       | 4324/16104 [20:07:13<50:31:06, 15.44s/it]


 27%|██▋       | 4326/16104 [20:07:40<47:37:16, 14.56s/it]
{'loss': 0.5124, 'learning_rate': 1.7160094972049462e-06, 'rewards/chosen': -1.1277424097061157, 'rewards/rejected': -1.666075587272644, 'rewards/accuracies': 0.75, 'rewards/margins': 0.538332998752594, 'policy_logps/rejected': -189.9620361328125, 'policy_logps/chosen': -288.34246826171875, 'referece_logps/rejected': -173.30128479003906, 'referece_logps/chosen': -277.0650634765625, 'logits/rejected': -0.8865261673927307, 'logits/chosen': -0.8537011742591858, 'epoch': 1.61}

 27%|██▋       | 4327/16104 [20:08:01<53:51:56, 16.47s/it]

 27%|██▋       | 4328/16104 [20:08:17<53:19:51, 16.30s/it]

 27%|██▋       | 4329/16104 [20:08:29<49:48:08, 15.23s/it]

 27%|██▋       | 4330/16104 [20:08:52<57:28:44, 17.57s/it]


 27%|██▋       | 4332/16104 [20:09:30<59:49:44, 18.30s/it]

 27%|██▋       | 4333/16104 [20:09:50<61:26:39, 18.79s/it]
{'loss': 0.4953, 'learning_rate': 1.7150259573933267e-06, 'rewards/chosen': -0.7112695574760437, 'rewards/rejected': -1.6227450370788574, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9114755392074585, 'policy_logps/rejected': -351.55511474609375, 'policy_logps/chosen': -418.54498291015625, 'referece_logps/rejected': -335.3276672363281, 'referece_logps/chosen': -411.43231201171875, 'logits/rejected': 0.006774425506591797, 'logits/chosen': -0.13547460734844208, 'epoch': 1.61}

 27%|██▋       | 4334/16104 [20:10:07<59:32:38, 18.21s/it]


 27%|██▋       | 4336/16104 [20:10:42<57:36:22, 17.62s/it]
{'loss': 0.5953, 'learning_rate': 1.7146040063563614e-06, 'rewards/chosen': -1.0718272924423218, 'rewards/rejected': -1.1701219081878662, 'rewards/accuracies': 0.375, 'rewards/margins': 0.09829455614089966, 'policy_logps/rejected': -382.2455749511719, 'policy_logps/chosen': -380.1543884277344, 'referece_logps/rejected': -370.54437255859375, 'referece_logps/chosen': -369.4361267089844, 'logits/rejected': -0.22762998938560486, 'logits/chosen': -0.13180209696292877, 'epoch': 1.62}

 27%|██▋       | 4337/16104 [20:10:59<56:49:10, 17.38s/it]

 27%|██▋       | 4338/16104 [20:11:17<57:18:13, 17.53s/it]

 27%|██▋       | 4339/16104 [20:11:35<57:56:28, 17.73s/it]

 27%|██▋       | 4340/16104 [20:11:52<57:44:16, 17.67s/it]

 27%|██▋       | 4341/16104 [20:12:13<60:24:14, 18.49s/it]

 27%|██▋       | 4342/16104 [20:12:31<59:50:27, 18.32s/it]

 27%|██▋       | 4343/16104 [20:12:48<59:25:10, 18.19s/it]

 27%|██▋       | 4344/16104 [20:13:06<58:22:19, 17.87s/it]


 27%|██▋       | 4346/16104 [20:13:40<57:33:29, 17.62s/it]
{'loss': 0.6024, 'learning_rate': 1.7131956248080152e-06, 'rewards/chosen': -0.9026031494140625, 'rewards/rejected': -1.5282373428344727, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6256341934204102, 'policy_logps/rejected': -394.9543151855469, 'policy_logps/chosen': -440.5937805175781, 'referece_logps/rejected': -379.6719055175781, 'referece_logps/chosen': -431.5677490234375, 'logits/rejected': -0.1267208456993103, 'logits/chosen': -0.07271337509155273, 'epoch': 1.62}

 27%|██▋       | 4347/16104 [20:14:01<60:55:38, 18.66s/it]

 27%|██▋       | 4348/16104 [20:14:17<58:39:26, 17.96s/it]

 27%|██▋       | 4349/16104 [20:14:34<57:49:54, 17.71s/it]

 27%|██▋       | 4350/16104 [20:14:54<59:51:31, 18.33s/it]

 27%|██▋       | 4351/16104 [20:15:11<58:19:26, 17.86s/it]

 27%|██▋       | 4352/16104 [20:15:23<52:05:03, 15.96s/it]

 27%|██▋       | 4353/16104 [20:15:36<49:43:53, 15.24s/it]

 27%|██▋       | 4354/16104 [20:15:47<45:30:16, 13.94s/it]

 27%|██▋       | 4355/16104 [20:16:08<52:21:31, 16.04s/it]

 27%|██▋       | 4356/16104 [20:16:24<52:00:56, 15.94s/it]

 27%|██▋       | 4357/16104 [20:16:35<47:23:39, 14.52s/it]

 27%|██▋       | 4358/16104 [20:16:50<47:32:57, 14.57s/it]

 27%|██▋       | 4359/16104 [20:17:01<44:49:20, 13.74s/it]

 27%|██▋       | 4360/16104 [20:17:23<52:16:51, 16.03s/it]

 27%|██▋       | 4361/16104 [20:17:43<56:11:37, 17.23s/it]

 27%|██▋       | 4362/16104 [20:18:01<57:14:15, 17.55s/it]

 27%|██▋       | 4363/16104 [20:18:18<56:50:27, 17.43s/it]

 27%|██▋       | 4364/16104 [20:18:38<59:08:33, 18.14s/it]

 27%|██▋       | 4365/16104 [20:18:57<60:08:51, 18.45s/it]

 27%|██▋       | 4366/16104 [20:19:14<58:07:56, 17.83s/it]

 27%|██▋       | 4367/16104 [20:19:30<56:50:58, 17.44s/it]

 27%|██▋       | 4368/16104 [20:19:52<61:35:13, 18.89s/it]

 27%|██▋       | 4369/16104 [20:20:10<60:14:45, 18.48s/it]

 27%|██▋       | 4370/16104 [20:20:20<52:31:35, 16.12s/it]

 27%|██▋       | 4371/16104 [20:20:31<47:10:22, 14.47s/it]

 27%|██▋       | 4372/16104 [20:20:45<46:44:40, 14.34s/it]

 27%|██▋       | 4373/16104 [20:21:05<52:17:07, 16.05s/it]

 27%|██▋       | 4374/16104 [20:21:24<54:33:11, 16.74s/it]

 27%|██▋       | 4375/16104 [20:21:37<51:14:51, 15.73s/it]

 27%|██▋       | 4376/16104 [20:21:53<51:10:55, 15.71s/it]

 27%|██▋       | 4377/16104 [20:22:12<55:12:14, 16.95s/it]

 27%|██▋       | 4378/16104 [20:22:33<58:58:45, 18.11s/it]

 27%|██▋       | 4379/16104 [20:22:46<54:01:24, 16.59s/it]

 27%|██▋       | 4380/16104 [20:23:06<56:42:13, 17.41s/it]

 27%|██▋       | 4381/16104 [20:23:19<52:59:47, 16.27s/it]

 27%|██▋       | 4382/16104 [20:23:31<48:38:30, 14.94s/it]

 27%|██▋       | 4383/16104 [20:23:53<55:35:53, 17.08s/it]

 27%|██▋       | 4384/16104 [20:24:14<58:51:00, 18.08s/it]

 27%|██▋       | 4385/16104 [20:24:33<60:09:03, 18.48s/it]

 27%|██▋       | 4386/16104 [20:24:48<56:30:43, 17.36s/it]

 27%|██▋       | 4387/16104 [20:25:08<59:06:12, 18.16s/it]

 27%|██▋       | 4388/16104 [20:25:27<60:29:52, 18.59s/it]

 27%|██▋       | 4389/16104 [20:25:43<58:05:56, 17.85s/it]

 27%|██▋       | 4390/16104 [20:25:58<54:53:57, 16.87s/it]

 27%|██▋       | 4391/16104 [20:26:17<57:04:13, 17.54s/it]

 27%|██▋       | 4392/16104 [20:26:38<60:23:51, 18.56s/it]

 27%|██▋       | 4393/16104 [20:26:55<58:42:55, 18.05s/it]

 27%|██▋       | 4394/16104 [20:27:18<64:05:17, 19.70s/it]

 27%|██▋       | 4395/16104 [20:27:37<63:11:08, 19.43s/it]

 27%|██▋       | 4396/16104 [20:27:48<54:41:22, 16.82s/it]

 27%|██▋       | 4397/16104 [20:28:03<53:01:39, 16.31s/it]

 27%|██▋       | 4398/16104 [20:28:14<47:37:44, 14.65s/it]

 27%|██▋       | 4399/16104 [20:28:28<47:12:00, 14.52s/it]

 27%|██▋       | 4400/16104 [20:28:45<49:39:01, 15.27s/it]

 27%|██▋       | 4401/16104 [20:28:56<45:15:04, 13.92s/it]

 27%|██▋       | 4402/16104 [20:29:16<51:40:38, 15.90s/it]

 27%|██▋       | 4403/16104 [20:29:35<54:27:05, 16.75s/it]

 27%|██▋       | 4404/16104 [20:29:52<54:12:42, 16.68s/it]

 27%|██▋       | 4405/16104 [20:30:10<55:48:34, 17.17s/it]

 27%|██▋       | 4406/16104 [20:30:33<61:12:34, 18.84s/it]

 27%|██▋       | 4407/16104 [20:30:47<56:50:57, 17.50s/it]

 27%|██▋       | 4408/16104 [20:30:59<51:51:42, 15.96s/it]

 27%|██▋       | 4409/16104 [20:31:19<55:15:33, 17.01s/it]

 27%|██▋       | 4410/16104 [20:31:34<53:42:26, 16.53s/it]

 27%|██▋       | 4411/16104 [20:31:54<56:17:47, 17.33s/it]

 27%|██▋       | 4412/16104 [20:32:11<56:53:29, 17.52s/it]

 27%|██▋       | 4413/16104 [20:32:29<56:53:49, 17.52s/it]

 27%|██▋       | 4414/16104 [20:32:46<56:47:59, 17.49s/it]

 27%|██▋       | 4415/16104 [20:33:03<56:14:37, 17.32s/it]

 27%|██▋       | 4416/16104 [20:33:16<51:29:07, 15.86s/it]

 27%|██▋       | 4417/16104 [20:33:29<49:13:03, 15.16s/it]

 27%|██▋       | 4418/16104 [20:33:49<53:36:05, 16.51s/it]


 27%|██▋       | 4420/16104 [20:34:18<50:40:50, 15.62s/it]

 27%|██▋       | 4421/16104 [20:34:34<51:19:55, 15.82s/it]

 27%|██▋       | 4422/16104 [20:34:47<49:09:11, 15.15s/it]

 27%|██▋       | 4423/16104 [20:35:07<53:22:21, 16.45s/it]

 27%|██▋       | 4424/16104 [20:35:27<57:13:47, 17.64s/it]

 27%|██▋       | 4425/16104 [20:35:43<55:30:12, 17.11s/it]

 27%|██▋       | 4426/16104 [20:36:00<54:53:23, 16.92s/it]

 27%|██▋       | 4427/16104 [20:36:18<56:02:13, 17.28s/it]

 27%|██▋       | 4428/16104 [20:36:32<53:29:19, 16.49s/it]

 28%|██▊       | 4429/16104 [20:36:55<59:11:58, 18.25s/it]

 28%|██▊       | 4430/16104 [20:37:14<59:42:02, 18.41s/it]

 28%|██▊       | 4431/16104 [20:37:30<57:18:54, 17.68s/it]

 28%|██▊       | 4432/16104 [20:37:43<53:06:43, 16.38s/it]

 28%|██▊       | 4433/16104 [20:38:02<55:51:58, 17.23s/it]

 28%|██▊       | 4434/16104 [20:38:23<59:38:49, 18.40s/it]

 28%|██▊       | 4435/16104 [20:38:43<61:10:28, 18.87s/it]

 28%|██▊       | 4436/16104 [20:38:59<57:49:45, 17.84s/it]

 28%|██▊       | 4437/16104 [20:39:15<56:13:20, 17.35s/it]

 28%|██▊       | 4438/16104 [20:39:34<57:36:29, 17.78s/it]

 28%|██▊       | 4439/16104 [20:39:44<50:44:55, 15.66s/it]

 28%|██▊       | 4440/16104 [20:40:02<52:57:23, 16.34s/it]

 28%|██▊       | 4441/16104 [20:40:22<56:13:29, 17.35s/it]

 28%|██▊       | 4442/16104 [20:40:38<54:29:15, 16.82s/it]

 28%|██▊       | 4443/16104 [20:40:51<51:27:14, 15.88s/it]

 28%|██▊       | 4444/16104 [20:41:10<54:00:18, 16.67s/it]

 28%|██▊       | 4445/16104 [20:41:31<58:07:58, 17.95s/it]

 28%|██▊       | 4446/16104 [20:41:49<58:32:51, 18.08s/it]

 28%|██▊       | 4447/16104 [20:42:03<54:41:34, 16.89s/it]

 28%|██▊       | 4448/16104 [20:42:15<49:43:57, 15.36s/it]

 28%|██▊       | 4449/16104 [20:42:31<50:04:11, 15.47s/it]

 28%|██▊       | 4450/16104 [20:42:52<55:39:47, 17.19s/it]

 28%|██▊       | 4451/16104 [20:43:11<57:17:44, 17.70s/it]

 28%|██▊       | 4452/16104 [20:43:30<59:10:54, 18.28s/it]

 28%|██▊       | 4453/16104 [20:43:50<60:28:48, 18.69s/it]

 28%|██▊       | 4454/16104 [20:44:05<57:02:45, 17.63s/it]

 28%|██▊       | 4455/16104 [20:44:20<54:21:39, 16.80s/it]

 28%|██▊       | 4456/16104 [20:44:39<56:43:28, 17.53s/it]

 28%|██▊       | 4457/16104 [20:44:57<57:14:10, 17.69s/it]

 28%|██▊       | 4458/16104 [20:45:17<58:48:08, 18.18s/it]
{'loss': 0.5189, 'learning_rate': 1.6972259803817904e-06, 'rewards/chosen': -0.6052460670471191, 'rewards/rejected': -1.5093801021575928, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9041340947151184, 'policy_logps/rejected': -331.1847229003906, 'policy_logps/chosen': -352.51708984375, 'referece_logps/rejected': -316.0909423828125, 'referece_logps/chosen': -346.4646301269531, 'logits/rejected': -0.7790622115135193, 'logits/chosen': -0.668476939201355, 'epoch': 1.66}


 28%|██▊       | 4460/16104 [20:45:55<61:04:10, 18.88s/it]

 28%|██▊       | 4461/16104 [20:46:16<62:57:34, 19.47s/it]
{'loss': 0.522, 'learning_rate': 1.6967933205005754e-06, 'rewards/chosen': -0.5916422009468079, 'rewards/rejected': -2.157883644104004, 'rewards/accuracies': 0.5, 'rewards/margins': 1.5662412643432617, 'policy_logps/rejected': -485.05548095703125, 'policy_logps/chosen': -470.3323669433594, 'referece_logps/rejected': -463.4766845703125, 'referece_logps/chosen': -464.4158935546875, 'logits/rejected': 0.02959612011909485, 'logits/chosen': -0.10825136303901672, 'epoch': 1.66}


 28%|██▊       | 4463/16104 [20:46:48<57:21:39, 17.74s/it]

 28%|██▊       | 4464/16104 [20:47:08<59:15:12, 18.33s/it]

 28%|██▊       | 4465/16104 [20:47:26<58:59:18, 18.25s/it]

 28%|██▊       | 4466/16104 [20:47:46<60:22:59, 18.68s/it]
{'loss': 0.4834, 'learning_rate': 1.6960716570457291e-06, 'rewards/chosen': -0.5695812106132507, 'rewards/rejected': -1.6713978052139282, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1018167734146118, 'policy_logps/rejected': -287.45147705078125, 'policy_logps/chosen': -265.62347412109375, 'referece_logps/rejected': -270.7375183105469, 'referece_logps/chosen': -259.92767333984375, 'logits/rejected': -0.1930781602859497, 'logits/chosen': -0.07914897054433823, 'epoch': 1.66}

 28%|██▊       | 4467/16104 [20:48:03<58:34:10, 18.12s/it]


 28%|██▊       | 4469/16104 [20:48:46<64:11:14, 19.86s/it]

 28%|██▊       | 4470/16104 [20:49:06<64:07:49, 19.84s/it]

 28%|██▊       | 4471/16104 [20:49:26<65:04:11, 20.14s/it]

 28%|██▊       | 4472/16104 [20:49:45<63:46:34, 19.74s/it]
{'loss': 0.5167, 'learning_rate': 1.6952047317720206e-06, 'rewards/chosen': -0.8214583396911621, 'rewards/rejected': -1.4573208093643188, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6358624696731567, 'policy_logps/rejected': -288.94451904296875, 'policy_logps/chosen': -299.09576416015625, 'referece_logps/rejected': -274.3713073730469, 'referece_logps/chosen': -290.88116455078125, 'logits/rejected': -0.9051276445388794, 'logits/chosen': -0.836948573589325, 'epoch': 1.67}


 28%|██▊       | 4474/16104 [20:50:26<64:41:13, 20.02s/it]
{'loss': 0.5082, 'learning_rate': 1.6949155316402487e-06, 'rewards/chosen': -1.0325493812561035, 'rewards/rejected': -1.3869215250015259, 'rewards/accuracies': 0.625, 'rewards/margins': 0.35437220335006714, 'policy_logps/rejected': -235.54859924316406, 'policy_logps/chosen': -560.9403686523438, 'referece_logps/rejected': -221.67938232421875, 'referece_logps/chosen': -550.6148681640625, 'logits/rejected': 0.01958591118454933, 'logits/chosen': -0.19447150826454163, 'epoch': 1.67}


 28%|██▊       | 4476/16104 [20:50:58<58:38:18, 18.15s/it]
{'loss': 0.5343, 'learning_rate': 1.6946262190661842e-06, 'rewards/chosen': -0.7381118535995483, 'rewards/rejected': -1.602508783340454, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8643970489501953, 'policy_logps/rejected': -423.4233703613281, 'policy_logps/chosen': -517.1286010742188, 'referece_logps/rejected': -407.39825439453125, 'referece_logps/chosen': -509.74749755859375, 'logits/rejected': -0.14515262842178345, 'logits/chosen': -0.10078270733356476, 'epoch': 1.67}


 28%|██▊       | 4478/16104 [20:51:35<60:04:18, 18.60s/it]

 28%|██▊       | 4479/16104 [20:51:55<61:21:39, 19.00s/it]
{'loss': 0.6359, 'learning_rate': 1.6941920394781976e-06, 'rewards/chosen': -1.2070035934448242, 'rewards/rejected': -1.0254464149475098, 'rewards/accuracies': 0.375, 'rewards/margins': -0.18155710399150848, 'policy_logps/rejected': -280.2283020019531, 'policy_logps/chosen': -312.9386291503906, 'referece_logps/rejected': -269.9738464355469, 'referece_logps/chosen': -300.86859130859375, 'logits/rejected': 0.4509425163269043, 'logits/chosen': 0.630607008934021, 'epoch': 1.67}


 28%|██▊       | 4481/16104 [20:52:26<54:11:08, 16.78s/it]

 28%|██▊       | 4482/16104 [20:52:38<49:42:04, 15.40s/it]

 28%|██▊       | 4483/16104 [20:52:49<45:13:38, 14.01s/it]
{'loss': 0.656, 'learning_rate': 1.6936127402499323e-06, 'rewards/chosen': -0.750052809715271, 'rewards/rejected': -1.6690007448196411, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9189478158950806, 'policy_logps/rejected': -305.71917724609375, 'policy_logps/chosen': -285.1604919433594, 'referece_logps/rejected': -289.0291748046875, 'referece_logps/chosen': -277.6599426269531, 'logits/rejected': -0.6114588379859924, 'logits/chosen': -0.4570031762123108, 'epoch': 1.67}


 28%|██▊       | 4485/16104 [20:53:31<56:32:18, 17.52s/it]
{'loss': 0.5467, 'learning_rate': 1.6933229222651246e-06, 'rewards/chosen': -0.6299121975898743, 'rewards/rejected': -1.326085090637207, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6961728930473328, 'policy_logps/rejected': -284.3960876464844, 'policy_logps/chosen': -515.2242431640625, 'referece_logps/rejected': -271.1352233886719, 'referece_logps/chosen': -508.9251708984375, 'logits/rejected': -0.45812636613845825, 'logits/chosen': -0.5449544191360474, 'epoch': 1.67}

 28%|██▊       | 4486/16104 [20:53:45<53:48:47, 16.67s/it]

 28%|██▊       | 4487/16104 [20:54:03<54:56:57, 17.03s/it]

 28%|██▊       | 4488/16104 [20:54:21<55:42:52, 17.27s/it]


 28%|██▊       | 4490/16104 [20:54:52<53:30:53, 16.59s/it]

 28%|██▊       | 4491/16104 [20:55:03<47:52:25, 14.84s/it]
{'loss': 0.5825, 'learning_rate': 1.6924527953907908e-06, 'rewards/chosen': -0.6583455801010132, 'rewards/rejected': -1.3745568990707397, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7162112593650818, 'policy_logps/rejected': -309.74017333984375, 'policy_logps/chosen': -248.37246704101562, 'referece_logps/rejected': -295.9945983886719, 'referece_logps/chosen': -241.78903198242188, 'logits/rejected': -1.193930983543396, 'logits/chosen': -1.1480358839035034, 'epoch': 1.67}


 28%|██▊       | 4493/16104 [20:55:34<48:39:33, 15.09s/it]

 28%|██▊       | 4494/16104 [20:55:49<48:03:59, 14.90s/it]

 28%|██▊       | 4495/16104 [20:56:10<54:16:13, 16.83s/it]

 28%|██▊       | 4496/16104 [20:56:25<51:59:14, 16.12s/it]

 28%|██▊       | 4497/16104 [20:56:39<49:53:37, 15.47s/it]

 28%|██▊       | 4498/16104 [20:56:54<50:18:11, 15.60s/it]

 28%|██▊       | 4499/16104 [20:57:07<46:52:37, 14.54s/it]

 28%|██▊       | 4500/16104 [20:57:24<49:34:33, 15.38s/it]
{'loss': 0.5478, 'learning_rate': 1.6911457147366851e-06, 'rewards/chosen': -0.797372579574585, 'rewards/rejected': -1.3920366764068604, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5946640968322754, 'policy_logps/rejected': -349.08294677734375, 'policy_logps/chosen': -360.4300231933594, 'referece_logps/rejected': -335.1625671386719, 'referece_logps/chosen': -352.456298828125, 'logits/rejected': -0.5142689943313599, 'logits/chosen': -0.46211594343185425, 'epoch': 1.68}

 28%|██▊       | 4501/16104 [20:57:50<59:39:03, 18.51s/it]


 28%|██▊       | 4503/16104 [20:58:12<47:29:22, 14.74s/it]
{'loss': 0.5851, 'learning_rate': 1.6907095177283487e-06, 'rewards/chosen': -0.8796907663345337, 'rewards/rejected': -1.6481297016143799, 'rewards/accuracies': 0.75, 'rewards/margins': 0.768438994884491, 'policy_logps/rejected': -396.9316711425781, 'policy_logps/chosen': -481.21343994140625, 'referece_logps/rejected': -380.4504089355469, 'referece_logps/chosen': -472.41650390625, 'logits/rejected': -0.5004360675811768, 'logits/chosen': -0.3771648108959198, 'epoch': 1.68}

 28%|██▊       | 4504/16104 [20:58:30<50:14:41, 15.59s/it]


 28%|██▊       | 4506/16104 [20:58:52<42:45:33, 13.27s/it]
{'loss': 0.6168, 'learning_rate': 1.6902730692561256e-06, 'rewards/chosen': -0.8390912413597107, 'rewards/rejected': -1.2399579286575317, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4008665680885315, 'policy_logps/rejected': -337.7889709472656, 'policy_logps/chosen': -443.48651123046875, 'referece_logps/rejected': -325.3894348144531, 'referece_logps/chosen': -435.0956115722656, 'logits/rejected': -0.7459433674812317, 'logits/chosen': -0.7593811750411987, 'epoch': 1.68}


 28%|██▊       | 4508/16104 [20:59:20<44:02:02, 13.67s/it]

 28%|██▊       | 4509/16104 [20:59:40<50:09:04, 15.57s/it]

 28%|██▊       | 4510/16104 [20:59:54<49:03:53, 15.23s/it]

 28%|██▊       | 4511/16104 [21:00:10<49:21:21, 15.33s/it]

 28%|██▊       | 4512/16104 [21:00:21<45:17:47, 14.07s/it]

 28%|██▊       | 4513/16104 [21:00:32<42:33:04, 13.22s/it]
{'loss': 0.4944, 'learning_rate': 1.6892537124652276e-06, 'rewards/chosen': -0.675484836101532, 'rewards/rejected': -1.2113145589828491, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5358297228813171, 'policy_logps/rejected': -520.2059326171875, 'policy_logps/chosen': -530.4422607421875, 'referece_logps/rejected': -508.0928039550781, 'referece_logps/chosen': -523.6874389648438, 'logits/rejected': -0.8968486785888672, 'logits/chosen': -1.0004338026046753, 'epoch': 1.68}

 28%|██▊       | 4514/16104 [21:00:44<40:43:32, 12.65s/it]


 28%|██▊       | 4516/16104 [21:01:12<43:46:16, 13.60s/it]

 28%|██▊       | 4517/16104 [21:01:25<43:00:26, 13.36s/it]

 28%|██▊       | 4518/16104 [21:01:39<42:59:31, 13.36s/it]

 28%|██▊       | 4519/16104 [21:02:00<51:05:59, 15.88s/it]

 28%|██▊       | 4520/16104 [21:02:17<51:35:11, 16.03s/it]

 28%|██▊       | 4521/16104 [21:02:35<53:52:53, 16.75s/it]

 28%|██▊       | 4522/16104 [21:02:53<55:14:45, 17.17s/it]
{'loss': 0.5451, 'learning_rate': 1.68794110368925e-06, 'rewards/chosen': -0.42987701296806335, 'rewards/rejected': -1.2857139110565186, 'rewards/accuracies': 0.875, 'rewards/margins': 0.855836808681488, 'policy_logps/rejected': -271.36614990234375, 'policy_logps/chosen': -265.87994384765625, 'referece_logps/rejected': -258.5090026855469, 'referece_logps/chosen': -261.5811767578125, 'logits/rejected': 0.15495391190052032, 'logits/chosen': 0.14601466059684753, 'epoch': 1.68}


 28%|██▊       | 4523/16104 [21:03:10<54:42:27, 17.01s/it]
{'loss': 0.523, 'learning_rate': 1.6876491065857584e-06, 'rewards/chosen': -0.6538217663764954, 'rewards/rejected': -2.1222424507141113, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4684205055236816, 'policy_logps/rejected': -514.0541381835938, 'policy_logps/chosen': -400.2029724121094, 'referece_logps/rejected': -492.83172607421875, 'referece_logps/chosen': -393.66473388671875, 'logits/rejected': 0.16903547942638397, 'logits/chosen': 0.1401328146457672, 'epoch': 1.69}

 28%|██▊       | 4525/16104 [21:03:49<58:29:02, 18.18s/it]
{'loss': 0.563, 'learning_rate': 1.6875030663061089e-06, 'rewards/chosen': -1.1354565620422363, 'rewards/rejected': -1.3387068510055542, 'rewards/accuracies': 0.5, 'rewards/margins': 0.20325040817260742, 'policy_logps/rejected': -614.0026245117188, 'policy_logps/chosen': -671.1058959960938, 'referece_logps/rejected': -600.6156005859375, 'referece_logps/chosen': -659.7513427734375, 'logits/rejected': -0.12004359811544418, 'logits/chosen': -0.21390268206596375, 'epoch': 1.69}

 28%|██▊       | 4526/16104 [21:04:10<61:27:24, 19.11s/it]


 28%|██▊       | 4528/16104 [21:04:45<59:59:44, 18.66s/it]

 28%|██▊       | 4529/16104 [21:04:59<55:24:07, 17.23s/it]

 28%|██▊       | 4530/16104 [21:05:19<57:46:37, 17.97s/it]

 28%|██▊       | 4531/16104 [21:05:39<59:39:07, 18.56s/it]
{'loss': 0.5367, 'learning_rate': 1.6866262408098132e-06, 'rewards/chosen': -1.0774726867675781, 'rewards/rejected': -1.671431064605713, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5939582586288452, 'policy_logps/rejected': -389.7944641113281, 'policy_logps/chosen': -447.35748291015625, 'referece_logps/rejected': -373.0801086425781, 'referece_logps/chosen': -436.582763671875, 'logits/rejected': 0.19956691563129425, 'logits/chosen': 0.19903220236301422, 'epoch': 1.69}


 28%|██▊       | 4533/16104 [21:06:09<54:24:10, 16.93s/it]
{'loss': 0.4556, 'learning_rate': 1.6863337433792562e-06, 'rewards/chosen': -0.6478961110115051, 'rewards/rejected': -1.9512518644332886, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3033556938171387, 'policy_logps/rejected': -502.1201171875, 'policy_logps/chosen': -485.538330078125, 'referece_logps/rejected': -482.60760498046875, 'referece_logps/chosen': -479.05938720703125, 'logits/rejected': 0.1424393653869629, 'logits/chosen': 0.17327187955379486, 'epoch': 1.69}

 28%|██▊       | 4534/16104 [21:06:28<56:11:19, 17.48s/it]


 28%|██▊       | 4536/16104 [21:07:05<59:04:44, 18.39s/it]

 28%|██▊       | 4537/16104 [21:07:25<60:18:15, 18.77s/it]

 28%|██▊       | 4538/16104 [21:07:45<62:15:26, 19.38s/it]

 28%|██▊       | 4539/16104 [21:08:05<62:28:45, 19.45s/it]

 28%|██▊       | 4540/16104 [21:08:23<60:55:14, 18.97s/it]

 28%|██▊       | 4541/16104 [21:08:43<62:01:37, 19.31s/it]

 28%|██▊       | 4542/16104 [21:09:01<61:14:33, 19.07s/it]
{'loss': 0.4572, 'learning_rate': 1.6850161313359614e-06, 'rewards/chosen': -0.5873358845710754, 'rewards/rejected': -1.8697251081466675, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2823891639709473, 'policy_logps/rejected': -346.99273681640625, 'policy_logps/chosen': -305.61773681640625, 'referece_logps/rejected': -328.2955017089844, 'referece_logps/chosen': -299.7443542480469, 'logits/rejected': -1.0639086961746216, 'logits/chosen': -1.0799106359481812, 'epoch': 1.69}


 28%|██▊       | 4544/16104 [21:09:29<51:54:56, 16.17s/it]
{'loss': 0.5829, 'learning_rate': 1.684723023696235e-06, 'rewards/chosen': -0.856868326663971, 'rewards/rejected': -0.6856861114501953, 'rewards/accuracies': 0.25, 'rewards/margins': -0.17118225991725922, 'policy_logps/rejected': -398.957275390625, 'policy_logps/chosen': -400.3326721191406, 'referece_logps/rejected': -392.100341796875, 'referece_logps/chosen': -391.7640075683594, 'logits/rejected': -0.7202208042144775, 'logits/chosen': -0.9578324556350708, 'epoch': 1.69}


 28%|██▊       | 4546/16104 [21:10:03<52:20:39, 16.30s/it]

 28%|██▊       | 4547/16104 [21:10:15<48:09:25, 15.00s/it]

 28%|██▊       | 4548/16104 [21:10:28<46:02:37, 14.34s/it]

 28%|██▊       | 4549/16104 [21:10:47<50:59:50, 15.89s/it]

 28%|██▊       | 4550/16104 [21:11:03<50:43:53, 15.81s/it]

 28%|██▊       | 4551/16104 [21:11:20<52:01:50, 16.21s/it]

 28%|██▊       | 4552/16104 [21:11:39<55:06:52, 17.18s/it]

 28%|██▊       | 4553/16104 [21:12:00<58:16:44, 18.16s/it]
{'loss': 0.5975, 'learning_rate': 1.6834026689383507e-06, 'rewards/chosen': -0.6175050735473633, 'rewards/rejected': -1.4231092929840088, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8056042194366455, 'policy_logps/rejected': -364.2811584472656, 'policy_logps/chosen': -343.3533020019531, 'referece_logps/rejected': -350.050048828125, 'referece_logps/chosen': -337.1782531738281, 'logits/rejected': 0.24890771508216858, 'logits/chosen': 0.2551994323730469, 'epoch': 1.7}


 28%|██▊       | 4555/16104 [21:12:25<48:32:15, 15.13s/it]
{'loss': 0.6719, 'learning_rate': 1.6831089525241187e-06, 'rewards/chosen': -0.6376391649246216, 'rewards/rejected': -0.6744818091392517, 'rewards/accuracies': 0.625, 'rewards/margins': 0.03684253990650177, 'policy_logps/rejected': -298.4164123535156, 'policy_logps/chosen': -340.33697509765625, 'referece_logps/rejected': -291.671630859375, 'referece_logps/chosen': -333.9605407714844, 'logits/rejected': -0.30357781052589417, 'logits/chosen': -0.23353788256645203, 'epoch': 1.7}


 28%|██▊       | 4557/16104 [21:12:58<49:27:52, 15.42s/it]

 28%|██▊       | 4558/16104 [21:13:10<45:53:39, 14.31s/it]

 28%|██▊       | 4559/16104 [21:13:26<47:39:52, 14.86s/it]
{'loss': 0.6038, 'learning_rate': 1.6825211881474877e-06, 'rewards/chosen': -0.6811352968215942, 'rewards/rejected': -0.7021716833114624, 'rewards/accuracies': 0.25, 'rewards/margins': 0.02103642001748085, 'policy_logps/rejected': -333.98968505859375, 'policy_logps/chosen': -427.27313232421875, 'referece_logps/rejected': -326.9679870605469, 'referece_logps/chosen': -420.4617614746094, 'logits/rejected': -0.7758771777153015, 'logits/chosen': -0.8229029178619385, 'epoch': 1.7}

 28%|██▊       | 4560/16104 [21:13:44<51:02:26, 15.92s/it]


 28%|██▊       | 4562/16104 [21:14:13<49:01:43, 15.29s/it]
{'loss': 0.4908, 'learning_rate': 1.6820800749476142e-06, 'rewards/chosen': -0.8848885297775269, 'rewards/rejected': -1.110709547996521, 'rewards/accuracies': 0.375, 'rewards/margins': 0.2258211076259613, 'policy_logps/rejected': -380.59686279296875, 'policy_logps/chosen': -345.51348876953125, 'referece_logps/rejected': -369.4897766113281, 'referece_logps/chosen': -336.6645812988281, 'logits/rejected': -0.4304569959640503, 'logits/chosen': -0.6342165470123291, 'epoch': 1.7}

 28%|██▊       | 4563/16104 [21:14:24<44:52:26, 14.00s/it]

 28%|██▊       | 4564/16104 [21:14:41<47:17:56, 14.76s/it]

 28%|██▊       | 4565/16104 [21:15:00<51:57:24, 16.21s/it]


 28%|██▊       | 4567/16104 [21:15:24<44:30:32, 13.89s/it]
{'loss': 0.525, 'learning_rate': 1.681344334533396e-06, 'rewards/chosen': -1.159131646156311, 'rewards/rejected': -1.2951654195785522, 'rewards/accuracies': 0.625, 'rewards/margins': 0.13603369891643524, 'policy_logps/rejected': -377.6403503417969, 'policy_logps/chosen': -406.1008605957031, 'referece_logps/rejected': -364.68865966796875, 'referece_logps/chosen': -394.509521484375, 'logits/rejected': -0.8487278819084167, 'logits/chosen': -0.7857619524002075, 'epoch': 1.7}


 28%|██▊       | 4569/16104 [21:16:02<51:54:14, 16.20s/it]
{'loss': 0.5715, 'learning_rate': 1.6810498453948746e-06, 'rewards/chosen': -0.4298434257507324, 'rewards/rejected': -0.9739872813224792, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5441438555717468, 'policy_logps/rejected': -485.77301025390625, 'policy_logps/chosen': -481.5942687988281, 'referece_logps/rejected': -476.03314208984375, 'referece_logps/chosen': -477.29583740234375, 'logits/rejected': -0.32886815071105957, 'logits/chosen': -0.2767826020717621, 'epoch': 1.7}


 28%|██▊       | 4571/16104 [21:16:32<50:03:54, 15.63s/it]
{'loss': 0.5714, 'learning_rate': 1.6807552460576285e-06, 'rewards/chosen': -1.1595954895019531, 'rewards/rejected': -1.485734224319458, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3261386752128601, 'policy_logps/rejected': -328.23944091796875, 'policy_logps/chosen': -273.7401428222656, 'referece_logps/rejected': -313.382080078125, 'referece_logps/chosen': -262.1441650390625, 'logits/rejected': -0.19767440855503082, 'logits/chosen': -0.269234299659729, 'epoch': 1.7}

 28%|██▊       | 4572/16104 [21:16:48<51:01:31, 15.93s/it]


 28%|██▊       | 4574/16104 [21:17:30<58:50:50, 18.37s/it]

 28%|██▊       | 4575/16104 [21:17:50<60:25:28, 18.87s/it]

 28%|██▊       | 4576/16104 [21:18:10<61:07:33, 19.09s/it]

 28%|██▊       | 4577/16104 [21:18:24<56:29:21, 17.64s/it]
{'loss': 0.5011, 'learning_rate': 1.67987078733031e-06, 'rewards/chosen': -1.3056929111480713, 'rewards/rejected': -2.0598111152648926, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7541182041168213, 'policy_logps/rejected': -307.42529296875, 'policy_logps/chosen': -318.5916748046875, 'referece_logps/rejected': -286.8271484375, 'referece_logps/chosen': -305.5347595214844, 'logits/rejected': -0.6164785027503967, 'logits/chosen': -0.5451141595840454, 'epoch': 1.71}

 28%|██▊       | 4578/16104 [21:18:43<57:13:42, 17.87s/it]


 28%|██▊       | 4580/16104 [21:19:24<61:52:00, 19.33s/it]
{'loss': 0.5062, 'learning_rate': 1.6794281866093194e-06, 'rewards/chosen': -1.0267082452774048, 'rewards/rejected': -2.0918121337890625, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0651038885116577, 'policy_logps/rejected': -359.3393859863281, 'policy_logps/chosen': -493.8907470703125, 'referece_logps/rejected': -338.42132568359375, 'referece_logps/chosen': -483.6236572265625, 'logits/rejected': -1.3802443742752075, 'logits/chosen': -1.3554614782333374, 'epoch': 1.71}


 28%|██▊       | 4582/16104 [21:20:04<62:57:48, 19.67s/it]
{'loss': 0.4921, 'learning_rate': 1.6791329820316324e-06, 'rewards/chosen': -1.316672444343567, 'rewards/rejected': -1.533921718597412, 'rewards/accuracies': 0.625, 'rewards/margins': 0.21724911034107208, 'policy_logps/rejected': -247.61729431152344, 'policy_logps/chosen': -282.6629943847656, 'referece_logps/rejected': -232.27806091308594, 'referece_logps/chosen': -269.4963073730469, 'logits/rejected': -0.8877515196800232, 'logits/chosen': -0.8369573354721069, 'epoch': 1.71}


 28%|██▊       | 4584/16104 [21:20:46<65:24:32, 20.44s/it]

 28%|██▊       | 4585/16104 [21:21:06<64:44:56, 20.24s/it]
{'loss': 0.4683, 'learning_rate': 1.6786899691389787e-06, 'rewards/chosen': -0.768356442451477, 'rewards/rejected': -1.607269048690796, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8389124870300293, 'policy_logps/rejected': -405.6390380859375, 'policy_logps/chosen': -675.3383178710938, 'referece_logps/rejected': -389.56634521484375, 'referece_logps/chosen': -667.6547241210938, 'logits/rejected': -0.0509539470076561, 'logits/chosen': -0.10802412778139114, 'epoch': 1.71}

 28%|██▊       | 4586/16104 [21:21:27<65:43:32, 20.54s/it]


 28%|██▊       | 4588/16104 [21:22:01<59:17:31, 18.54s/it]

 28%|██▊       | 4589/16104 [21:22:12<52:42:19, 16.48s/it]
{'loss': 0.5682, 'learning_rate': 1.6780989009509214e-06, 'rewards/chosen': -1.2496284246444702, 'rewards/rejected': -1.1428955793380737, 'rewards/accuracies': 0.375, 'rewards/margins': -0.10673293471336365, 'policy_logps/rejected': -337.2083740234375, 'policy_logps/chosen': -302.3863525390625, 'referece_logps/rejected': -325.7793884277344, 'referece_logps/chosen': -289.89007568359375, 'logits/rejected': 0.002758413553237915, 'logits/chosen': 0.09130725264549255, 'epoch': 1.71}

 29%|██▊       | 4590/16104 [21:22:26<50:00:46, 15.64s/it]

 29%|██▊       | 4591/16104 [21:22:47<54:58:20, 17.19s/it]

 29%|██▊       | 4592/16104 [21:23:03<54:09:16, 16.94s/it]


 29%|██▊       | 4594/16104 [21:23:44<60:12:28, 18.83s/it]

 29%|██▊       | 4595/16104 [21:24:03<60:00:27, 18.77s/it]
{'loss': 0.5628, 'learning_rate': 1.6772114758791857e-06, 'rewards/chosen': -0.9919870495796204, 'rewards/rejected': -1.259627103805542, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2676401138305664, 'policy_logps/rejected': -321.97930908203125, 'policy_logps/chosen': -299.3908386230469, 'referece_logps/rejected': -309.383056640625, 'referece_logps/chosen': -289.470947265625, 'logits/rejected': -0.8432165384292603, 'logits/chosen': -0.846451997756958, 'epoch': 1.71}

 29%|██▊       | 4596/16104 [21:24:25<63:24:22, 19.84s/it]

 29%|██▊       | 4597/16104 [21:24:36<54:48:12, 17.15s/it]


 29%|██▊       | 4599/16104 [21:25:02<48:34:56, 15.20s/it]

 29%|██▊       | 4600/16104 [21:25:19<49:46:09, 15.57s/it]
{'loss': 0.5313, 'learning_rate': 1.6764712015849254e-06, 'rewards/chosen': -0.09750118851661682, 'rewards/rejected': -1.403871774673462, 'rewards/accuracies': 1.0, 'rewards/margins': 1.306370496749878, 'policy_logps/rejected': -290.90570068359375, 'policy_logps/chosen': -504.2908630371094, 'referece_logps/rejected': -276.8669738769531, 'referece_logps/chosen': -503.3158264160156, 'logits/rejected': 0.02188238501548767, 'logits/chosen': 0.20751795172691345, 'epoch': 1.71}

 29%|██▊       | 4601/16104 [21:25:36<51:33:50, 16.14s/it]


 29%|██▊       | 4603/16104 [21:26:08<51:33:15, 16.14s/it]
{'loss': 0.5565, 'learning_rate': 1.6760267085868475e-06, 'rewards/chosen': -1.2327278852462769, 'rewards/rejected': -2.5890581607818604, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3563305139541626, 'policy_logps/rejected': -330.1496276855469, 'policy_logps/chosen': -400.49700927734375, 'referece_logps/rejected': -304.2590637207031, 'referece_logps/chosen': -388.16973876953125, 'logits/rejected': -0.4651849865913391, 'logits/chosen': -0.7962428331375122, 'epoch': 1.71}


 29%|██▊       | 4605/16104 [21:26:47<57:29:19, 18.00s/it]

 29%|██▊       | 4606/16104 [21:27:01<53:53:32, 16.87s/it]
{'loss': 0.5895, 'learning_rate': 1.6755819694703957e-06, 'rewards/chosen': -0.6218277215957642, 'rewards/rejected': -1.5675995349884033, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9457718133926392, 'policy_logps/rejected': -354.39013671875, 'policy_logps/chosen': -563.0909423828125, 'referece_logps/rejected': -338.71417236328125, 'referece_logps/chosen': -556.8726806640625, 'logits/rejected': -0.4204917550086975, 'logits/chosen': -0.4399260878562927, 'epoch': 1.72}

 29%|██▊       | 4607/16104 [21:27:12<47:56:07, 15.01s/it]

 29%|██▊       | 4608/16104 [21:27:30<51:23:50, 16.10s/it]


 29%|██▊       | 4610/16104 [21:27:57<46:04:11, 14.43s/it]
{'loss': 0.653, 'learning_rate': 1.6749886014108539e-06, 'rewards/chosen': -0.8425396680831909, 'rewards/rejected': -1.3571373224258423, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5145977139472961, 'policy_logps/rejected': -390.0977783203125, 'policy_logps/chosen': -331.5628967285156, 'referece_logps/rejected': -376.5263671875, 'referece_logps/chosen': -323.13751220703125, 'logits/rejected': -0.7245331406593323, 'logits/chosen': -0.6969875693321228, 'epoch': 1.72}

 29%|██▊       | 4611/16104 [21:28:16<50:20:35, 15.77s/it]

 29%|██▊       | 4612/16104 [21:28:34<52:36:54, 16.48s/it]

 29%|██▊       | 4613/16104 [21:28:53<55:16:19, 17.32s/it]


 29%|██▊       | 4615/16104 [21:29:33<59:28:34, 18.64s/it]
{'loss': 0.516, 'learning_rate': 1.674246277030388e-06, 'rewards/chosen': -0.8299987316131592, 'rewards/rejected': -2.1701934337615967, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3401947021484375, 'policy_logps/rejected': -354.921142578125, 'policy_logps/chosen': -479.6949462890625, 'referece_logps/rejected': -333.21923828125, 'referece_logps/chosen': -471.39495849609375, 'logits/rejected': -0.17593306303024292, 'logits/chosen': -0.22874855995178223, 'epoch': 1.72}

 29%|██▊       | 4616/16104 [21:29:52<60:23:55, 18.93s/it]

 29%|██▊       | 4617/16104 [21:30:12<60:51:15, 19.07s/it]

 29%|██▊       | 4618/16104 [21:30:28<57:48:17, 18.12s/it]

 29%|██▊       | 4619/16104 [21:30:48<59:59:24, 18.80s/it]

 29%|██▊       | 4620/16104 [21:31:05<58:36:26, 18.37s/it]

 29%|██▊       | 4621/16104 [21:31:18<53:33:29, 16.79s/it]

 29%|██▊       | 4622/16104 [21:31:36<54:21:34, 17.04s/it]

 29%|██▊       | 4623/16104 [21:31:53<54:33:08, 17.11s/it]


 29%|██▊       | 4625/16104 [21:32:33<59:05:18, 18.53s/it]
{'loss': 0.5181, 'learning_rate': 1.6727595834361378e-06, 'rewards/chosen': -0.6940162777900696, 'rewards/rejected': -2.3446853160858154, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6506688594818115, 'policy_logps/rejected': -421.2049865722656, 'policy_logps/chosen': -357.4283142089844, 'referece_logps/rejected': -397.7581481933594, 'referece_logps/chosen': -350.48809814453125, 'logits/rejected': -0.2752760052680969, 'logits/chosen': 0.005945935845375061, 'epoch': 1.72}


 29%|██▊       | 4627/16104 [21:32:55<46:48:50, 14.68s/it]
{'loss': 0.5816, 'learning_rate': 1.6724619179528486e-06, 'rewards/chosen': -0.7135498523712158, 'rewards/rejected': -1.9392938613891602, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2257437705993652, 'policy_logps/rejected': -272.7991638183594, 'policy_logps/chosen': -506.1156311035156, 'referece_logps/rejected': -253.4062042236328, 'referece_logps/chosen': -498.9801940917969, 'logits/rejected': -1.7250961065292358, 'logits/chosen': -1.8511958122253418, 'epoch': 1.72}

 29%|██▊       | 4628/16104 [21:33:10<46:57:59, 14.73s/it]

 29%|██▊       | 4629/16104 [21:33:24<46:45:16, 14.67s/it]

 29%|██▉       | 4630/16104 [21:33:46<53:59:55, 16.94s/it]

 29%|██▉       | 4631/16104 [21:34:04<54:55:54, 17.24s/it]

 29%|██▉       | 4632/16104 [21:34:18<51:10:30, 16.06s/it]


 29%|██▉       | 4634/16104 [21:34:47<49:08:10, 15.42s/it]
{'loss': 0.5481, 'learning_rate': 1.6714192322056186e-06, 'rewards/chosen': -0.6230670213699341, 'rewards/rejected': -0.9700155258178711, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3469485640525818, 'policy_logps/rejected': -374.8695068359375, 'policy_logps/chosen': -306.5857849121094, 'referece_logps/rejected': -365.1693420410156, 'referece_logps/chosen': -300.3551025390625, 'logits/rejected': -1.799316167831421, 'logits/chosen': -1.7577288150787354, 'epoch': 1.73}

 29%|██▉       | 4635/16104 [21:35:02<48:32:57, 15.24s/it]


 29%|██▉       | 4637/16104 [21:35:31<46:40:56, 14.66s/it]
{'loss': 0.512, 'learning_rate': 1.6709719593632484e-06, 'rewards/chosen': -0.7408438920974731, 'rewards/rejected': -1.611985683441162, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8711416721343994, 'policy_logps/rejected': -553.3702392578125, 'policy_logps/chosen': -353.7223205566406, 'referece_logps/rejected': -537.2503662109375, 'referece_logps/chosen': -346.3138732910156, 'logits/rejected': -0.40797609090805054, 'logits/chosen': -0.38914167881011963, 'epoch': 1.73}

 29%|██▉       | 4638/16104 [21:35:50<50:51:49, 15.97s/it]

 29%|██▉       | 4639/16104 [21:36:06<50:35:04, 15.88s/it]

 29%|██▉       | 4640/16104 [21:36:21<49:28:08, 15.53s/it]

 29%|██▉       | 4641/16104 [21:36:38<50:46:29, 15.95s/it]

 29%|██▉       | 4642/16104 [21:36:54<51:23:01, 16.14s/it]


 29%|██▉       | 4644/16104 [21:37:23<49:58:45, 15.70s/it]
{'loss': 0.472, 'learning_rate': 1.6699273730422311e-06, 'rewards/chosen': -0.7502948045730591, 'rewards/rejected': -1.6890565156936646, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9387616515159607, 'policy_logps/rejected': -371.0700988769531, 'policy_logps/chosen': -334.1116638183594, 'referece_logps/rejected': -354.17950439453125, 'referece_logps/chosen': -326.6087341308594, 'logits/rejected': -1.2396246194839478, 'logits/chosen': -1.229047179222107, 'epoch': 1.73}

 29%|██▉       | 4645/16104 [21:37:40<51:20:56, 16.13s/it]

 29%|██▉       | 4646/16104 [21:37:59<53:09:31, 16.70s/it]

 29%|██▉       | 4647/16104 [21:38:19<56:42:26, 17.82s/it]


 29%|██▉       | 4649/16104 [21:38:51<54:20:44, 17.08s/it]

 29%|██▉       | 4650/16104 [21:39:07<53:01:54, 16.67s/it]
{'loss': 0.5987, 'learning_rate': 1.6690309563695767e-06, 'rewards/chosen': -0.8163026571273804, 'rewards/rejected': -2.117405414581299, 'rewards/accuracies': 0.625, 'rewards/margins': 1.301102638244629, 'policy_logps/rejected': -360.8045654296875, 'policy_logps/chosen': -368.37725830078125, 'referece_logps/rejected': -339.6304626464844, 'referece_logps/chosen': -360.2142639160156, 'logits/rejected': -0.16970570385456085, 'logits/chosen': -0.08954031765460968, 'epoch': 1.73}

 29%|██▉       | 4651/16104 [21:39:25<54:13:51, 17.05s/it]


 29%|██▉       | 4653/16104 [21:39:56<50:41:27, 15.94s/it]

 29%|██▉       | 4654/16104 [21:40:14<52:47:54, 16.60s/it]

 29%|██▉       | 4655/16104 [21:40:29<51:42:33, 16.26s/it]
{'loss': 0.4765, 'learning_rate': 1.6682831981742014e-06, 'rewards/chosen': -0.7726622819900513, 'rewards/rejected': -2.038362741470337, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2657005786895752, 'policy_logps/rejected': -324.9711608886719, 'policy_logps/chosen': -338.434326171875, 'referece_logps/rejected': -304.5875244140625, 'referece_logps/chosen': -330.7076721191406, 'logits/rejected': -0.6916529536247253, 'logits/chosen': -0.6450895071029663, 'epoch': 1.73}


 29%|██▉       | 4657/16104 [21:41:07<56:11:36, 17.67s/it]
{'loss': 0.5442, 'learning_rate': 1.6679839056209608e-06, 'rewards/chosen': -1.0234098434448242, 'rewards/rejected': -1.290215253829956, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2668052911758423, 'policy_logps/rejected': -193.99090576171875, 'policy_logps/chosen': -370.20526123046875, 'referece_logps/rejected': -181.0887451171875, 'referece_logps/chosen': -359.97119140625, 'logits/rejected': -0.3940035402774811, 'logits/chosen': -0.4679783284664154, 'epoch': 1.74}

 29%|██▉       | 4658/16104 [21:41:27<57:29:02, 18.08s/it]

 29%|██▉       | 4659/16104 [21:41:45<57:58:25, 18.24s/it]


 29%|██▉       | 4661/16104 [21:42:15<52:07:45, 16.40s/it]

 29%|██▉       | 4662/16104 [21:42:35<55:40:00, 17.51s/it]
{'loss': 0.5061, 'learning_rate': 1.6672352014738755e-06, 'rewards/chosen': -0.7217578291893005, 'rewards/rejected': -2.044133424758911, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3223755359649658, 'policy_logps/rejected': -298.3492126464844, 'policy_logps/chosen': -306.3294677734375, 'referece_logps/rejected': -277.9078674316406, 'referece_logps/chosen': -299.1119079589844, 'logits/rejected': 0.06633014976978302, 'logits/chosen': -0.10488785803318024, 'epoch': 1.74}


 29%|██▉       | 4664/16104 [21:43:07<53:33:43, 16.86s/it]
{'loss': 0.5887, 'learning_rate': 1.6669355308366507e-06, 'rewards/chosen': -1.0476995706558228, 'rewards/rejected': -1.0137073993682861, 'rewards/accuracies': 0.25, 'rewards/margins': -0.03399220108985901, 'policy_logps/rejected': -362.98736572265625, 'policy_logps/chosen': -388.7254638671875, 'referece_logps/rejected': -352.8502502441406, 'referece_logps/chosen': -378.2485046386719, 'logits/rejected': -0.9337413907051086, 'logits/chosen': -0.9410300254821777, 'epoch': 1.74}


 29%|██▉       | 4666/16104 [21:43:45<57:33:36, 18.12s/it]
{'loss': 0.576, 'learning_rate': 1.6666357522844976e-06, 'rewards/chosen': -0.8286892175674438, 'rewards/rejected': -1.351679801940918, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5229905843734741, 'policy_logps/rejected': -235.62705993652344, 'policy_logps/chosen': -358.7160339355469, 'referece_logps/rejected': -222.1102752685547, 'referece_logps/chosen': -350.42913818359375, 'logits/rejected': -0.7263264656066895, 'logits/chosen': -0.5380966067314148, 'epoch': 1.74}

 29%|██▉       | 4667/16104 [21:43:59<52:57:48, 16.67s/it]

 29%|██▉       | 4668/16104 [21:44:15<52:31:54, 16.54s/it]

 29%|██▉       | 4669/16104 [21:44:30<51:38:05, 16.26s/it]


 29%|██▉       | 4671/16104 [21:44:54<44:06:34, 13.89s/it]

 29%|██▉       | 4672/16104 [21:45:12<47:38:07, 15.00s/it]
{'loss': 0.6376, 'learning_rate': 1.6657357696236183e-06, 'rewards/chosen': -0.7182590365409851, 'rewards/rejected': -0.5327608585357666, 'rewards/accuracies': 0.375, 'rewards/margins': -0.18549823760986328, 'policy_logps/rejected': -527.4573364257812, 'policy_logps/chosen': -612.4163208007812, 'referece_logps/rejected': -522.1296997070312, 'referece_logps/chosen': -605.2337036132812, 'logits/rejected': 0.5895817875862122, 'logits/chosen': 0.589087724685669, 'epoch': 1.74}

 29%|██▉       | 4673/16104 [21:45:31<52:06:28, 16.41s/it]


 29%|██▉       | 4675/16104 [21:46:00<47:34:09, 14.98s/it]

 29%|██▉       | 4676/16104 [21:46:20<52:30:18, 16.54s/it]

 29%|██▉       | 4677/16104 [21:46:34<49:47:40, 15.69s/it]
{'loss': 0.6243, 'learning_rate': 1.6649850434368138e-06, 'rewards/chosen': -1.187483549118042, 'rewards/rejected': -1.3694056272506714, 'rewards/accuracies': 0.5, 'rewards/margins': 0.18192197382450104, 'policy_logps/rejected': -434.4658508300781, 'policy_logps/chosen': -529.6132202148438, 'referece_logps/rejected': -420.77178955078125, 'referece_logps/chosen': -517.7384033203125, 'logits/rejected': -0.6324706077575684, 'logits/chosen': -0.6404605507850647, 'epoch': 1.74}

 29%|██▉       | 4678/16104 [21:46:55<54:57:19, 17.31s/it]

 29%|██▉       | 4679/16104 [21:47:13<56:02:59, 17.66s/it]


 29%|██▉       | 4681/16104 [21:47:48<55:08:47, 17.38s/it]
{'loss': 0.5745, 'learning_rate': 1.6643839782539746e-06, 'rewards/chosen': -1.1991605758666992, 'rewards/rejected': -1.6053893566131592, 'rewards/accuracies': 0.375, 'rewards/margins': 0.4062288701534271, 'policy_logps/rejected': -401.12945556640625, 'policy_logps/chosen': -359.27093505859375, 'referece_logps/rejected': -385.0755615234375, 'referece_logps/chosen': -347.27935791015625, 'logits/rejected': -1.3616546392440796, 'logits/chosen': -1.6423044204711914, 'epoch': 1.74}

 29%|██▉       | 4682/16104 [21:48:01<51:36:05, 16.26s/it]

 29%|██▉       | 4683/16104 [21:48:17<50:41:37, 15.98s/it]

 29%|██▉       | 4684/16104 [21:48:35<53:14:38, 16.78s/it]

 29%|██▉       | 4685/16104 [21:48:49<50:01:01, 15.77s/it]

 29%|██▉       | 4686/16104 [21:49:07<52:37:20, 16.59s/it]

 29%|██▉       | 4687/16104 [21:49:25<53:17:22, 16.80s/it]

 29%|██▉       | 4688/16104 [21:49:44<55:54:12, 17.63s/it]

 29%|██▉       | 4689/16104 [21:49:59<53:23:37, 16.84s/it]


 29%|██▉       | 4691/16104 [21:50:34<55:16:23, 17.43s/it]
{'loss': 0.5933, 'learning_rate': 1.6628794348624262e-06, 'rewards/chosen': -0.8089985251426697, 'rewards/rejected': -0.9701521396636963, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1611536145210266, 'policy_logps/rejected': -365.03033447265625, 'policy_logps/chosen': -425.64727783203125, 'referece_logps/rejected': -355.3288269042969, 'referece_logps/chosen': -417.55731201171875, 'logits/rejected': -0.49582624435424805, 'logits/chosen': -0.41702717542648315, 'epoch': 1.75}

 29%|██▉       | 4692/16104 [21:50:50<53:21:12, 16.83s/it]


 29%|██▉       | 4694/16104 [21:51:18<48:12:05, 15.21s/it]
{'loss': 0.5519, 'learning_rate': 1.66242754868214e-06, 'rewards/chosen': -0.7496604919433594, 'rewards/rejected': -0.6972069144248962, 'rewards/accuracies': 0.5, 'rewards/margins': -0.05245360732078552, 'policy_logps/rejected': -350.56768798828125, 'policy_logps/chosen': -462.1024169921875, 'referece_logps/rejected': -343.59564208984375, 'referece_logps/chosen': -454.6058044433594, 'logits/rejected': 0.18507306277751923, 'logits/chosen': 0.21115857362747192, 'epoch': 1.75}

 29%|██▉       | 4695/16104 [21:51:31<46:00:23, 14.52s/it]

 29%|██▉       | 4696/16104 [21:51:43<43:09:31, 13.62s/it]

 29%|██▉       | 4697/16104 [21:51:59<45:59:19, 14.51s/it]

 29%|██▉       | 4698/16104 [21:52:10<42:25:42, 13.39s/it]

 29%|██▉       | 4699/16104 [21:52:24<42:51:29, 13.53s/it]

 29%|██▉       | 4700/16104 [21:52:39<43:57:04, 13.87s/it]

 29%|██▉       | 4701/16104 [21:53:00<50:37:00, 15.98s/it]

 29%|██▉       | 4702/16104 [21:53:15<49:50:24, 15.74s/it]

 29%|██▉       | 4703/16104 [21:53:27<46:29:04, 14.68s/it]

 29%|██▉       | 4704/16104 [21:53:40<45:14:21, 14.29s/it]


 29%|██▉       | 4706/16104 [21:54:19<53:03:39, 16.76s/it]
{'loss': 0.5583, 'learning_rate': 1.6606175939336611e-06, 'rewards/chosen': -0.839921236038208, 'rewards/rejected': -1.1769534349441528, 'rewards/accuracies': 0.75, 'rewards/margins': 0.33703237771987915, 'policy_logps/rejected': -428.0065002441406, 'policy_logps/chosen': -455.56878662109375, 'referece_logps/rejected': -416.23699951171875, 'referece_logps/chosen': -447.1696472167969, 'logits/rejected': -0.5839052796363831, 'logits/chosen': -0.5233882665634155, 'epoch': 1.75}


 29%|██▉       | 4708/16104 [21:54:53<52:05:35, 16.46s/it]
{'loss': 0.5946, 'learning_rate': 1.6603155603997908e-06, 'rewards/chosen': -0.18657109141349792, 'rewards/rejected': -0.4548364281654358, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2682653069496155, 'policy_logps/rejected': -317.5628662109375, 'policy_logps/chosen': -508.872802734375, 'referece_logps/rejected': -313.0144958496094, 'referece_logps/chosen': -507.007080078125, 'logits/rejected': 0.0662098228931427, 'logits/chosen': 0.04230383038520813, 'epoch': 1.75}

 29%|██▉       | 4709/16104 [21:55:05<48:03:06, 15.18s/it]

 29%|██▉       | 4710/16104 [21:55:25<52:22:04, 16.55s/it]


 29%|██▉       | 4712/16104 [21:55:59<52:22:39, 16.55s/it]
{'loss': 0.569, 'learning_rate': 1.659711172849629e-06, 'rewards/chosen': -1.1050848960876465, 'rewards/rejected': -1.4681437015533447, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3630587160587311, 'policy_logps/rejected': -540.611083984375, 'policy_logps/chosen': -496.1016845703125, 'referece_logps/rejected': -525.9296875, 'referece_logps/chosen': -485.0508728027344, 'logits/rejected': -0.7315489053726196, 'logits/chosen': -0.599789023399353, 'epoch': 1.76}

 29%|██▉       | 4713/16104 [21:56:14<51:23:37, 16.24s/it]


 29%|██▉       | 4715/16104 [21:56:51<54:14:17, 17.14s/it]
{'loss': 0.5473, 'learning_rate': 1.65925760195743e-06, 'rewards/chosen': -0.7592523694038391, 'rewards/rejected': -1.4852815866470337, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7260292172431946, 'policy_logps/rejected': -365.42425537109375, 'policy_logps/chosen': -275.0858459472656, 'referece_logps/rejected': -350.5714416503906, 'referece_logps/chosen': -267.4933166503906, 'logits/rejected': -1.0916390419006348, 'logits/chosen': -1.001558780670166, 'epoch': 1.76}

 29%|██▉       | 4716/16104 [21:57:10<56:41:24, 17.92s/it]


 29%|██▉       | 4718/16104 [21:57:43<54:14:49, 17.15s/it]
{'loss': 0.5418, 'learning_rate': 1.6588037910519193e-06, 'rewards/chosen': -0.6571617722511292, 'rewards/rejected': -0.9247657060623169, 'rewards/accuracies': 0.75, 'rewards/margins': 0.2676040232181549, 'policy_logps/rejected': -386.07232666015625, 'policy_logps/chosen': -533.67626953125, 'referece_logps/rejected': -376.8246765136719, 'referece_logps/chosen': -527.1046142578125, 'logits/rejected': -0.1957842856645584, 'logits/chosen': -0.32702478766441345, 'epoch': 1.76}

 29%|██▉       | 4719/16104 [21:57:55<49:14:15, 15.57s/it]

 29%|██▉       | 4720/16104 [21:58:14<53:10:52, 16.82s/it]

 29%|██▉       | 4721/16104 [21:58:33<55:07:24, 17.43s/it]

 29%|██▉       | 4722/16104 [21:58:50<53:57:07, 17.06s/it]

 29%|██▉       | 4723/16104 [21:59:01<48:12:55, 15.25s/it]


 29%|██▉       | 4725/16104 [21:59:37<53:11:37, 16.83s/it]
{'loss': 0.6303, 'learning_rate': 1.6577439664821964e-06, 'rewards/chosen': -0.9210659265518188, 'rewards/rejected': -1.1025266647338867, 'rewards/accuracies': 0.625, 'rewards/margins': 0.18146070837974548, 'policy_logps/rejected': -339.25775146484375, 'policy_logps/chosen': -355.67681884765625, 'referece_logps/rejected': -328.2324523925781, 'referece_logps/chosen': -346.4661560058594, 'logits/rejected': -0.42789584398269653, 'logits/chosen': -0.5014545917510986, 'epoch': 1.76}

 29%|██▉       | 4726/16104 [21:59:49<48:19:20, 15.29s/it]

 29%|██▉       | 4727/16104 [22:00:06<50:05:40, 15.85s/it]

 29%|██▉       | 4728/16104 [22:00:23<51:42:21, 16.36s/it]

 29%|██▉       | 4729/16104 [22:00:43<55:07:17, 17.45s/it]

 29%|██▉       | 4730/16104 [22:01:02<56:15:06, 17.80s/it]

 29%|██▉       | 4731/16104 [22:01:22<57:54:03, 18.33s/it]

 29%|██▉       | 4732/16104 [22:01:37<55:00:08, 17.41s/it]

 29%|██▉       | 4733/16104 [22:01:57<57:17:48, 18.14s/it]

 29%|██▉       | 4734/16104 [22:02:09<52:05:57, 16.50s/it]

 29%|██▉       | 4735/16104 [22:02:29<54:58:20, 17.41s/it]

 29%|██▉       | 4736/16104 [22:02:45<53:32:12, 16.95s/it]

 29%|██▉       | 4737/16104 [22:03:03<54:43:20, 17.33s/it]

 29%|██▉       | 4738/16104 [22:03:16<50:36:55, 16.03s/it]

 29%|██▉       | 4739/16104 [22:03:36<54:20:48, 17.22s/it]

 29%|██▉       | 4740/16104 [22:03:48<49:19:41, 15.63s/it]


 29%|██▉       | 4742/16104 [22:04:19<48:44:30, 15.44s/it]
{'loss': 0.6237, 'learning_rate': 1.6551646831730013e-06, 'rewards/chosen': -0.6436710357666016, 'rewards/rejected': -1.1645724773406982, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5209014415740967, 'policy_logps/rejected': -485.28900146484375, 'policy_logps/chosen': -438.5968017578125, 'referece_logps/rejected': -473.6432800292969, 'referece_logps/chosen': -432.1600646972656, 'logits/rejected': -0.29821673035621643, 'logits/chosen': -0.18921256065368652, 'epoch': 1.77}

 29%|██▉       | 4743/16104 [22:04:30<44:27:42, 14.09s/it]

 29%|██▉       | 4744/16104 [22:04:50<49:28:42, 15.68s/it]

 29%|██▉       | 4745/16104 [22:05:07<51:02:06, 16.17s/it]

 29%|██▉       | 4746/16104 [22:05:26<53:22:42, 16.92s/it]

 29%|██▉       | 4747/16104 [22:05:43<54:16:28, 17.20s/it]

 29%|██▉       | 4748/16104 [22:06:00<53:56:15, 17.10s/it]


 29%|██▉       | 4750/16104 [22:06:35<55:12:40, 17.51s/it]
{'loss': 0.4741, 'learning_rate': 1.653948250692106e-06, 'rewards/chosen': -1.127044439315796, 'rewards/rejected': -1.3860101699829102, 'rewards/accuracies': 0.625, 'rewards/margins': 0.25896570086479187, 'policy_logps/rejected': -393.4623107910156, 'policy_logps/chosen': -301.6676940917969, 'referece_logps/rejected': -379.60223388671875, 'referece_logps/chosen': -290.397216796875, 'logits/rejected': -0.7150654196739197, 'logits/chosen': -0.7569144368171692, 'epoch': 1.77}

 30%|██▉       | 4751/16104 [22:06:54<56:05:14, 17.79s/it]

 30%|██▉       | 4752/16104 [22:07:17<60:58:19, 19.34s/it]

 30%|██▉       | 4753/16104 [22:07:35<59:47:05, 18.96s/it]

 30%|██▉       | 4754/16104 [22:07:56<61:58:46, 19.66s/it]

 30%|██▉       | 4755/16104 [22:08:16<62:11:10, 19.73s/it]

 30%|██▉       | 4756/16104 [22:08:37<63:27:50, 20.13s/it]

 30%|██▉       | 4757/16104 [22:08:56<62:03:21, 19.69s/it]

 30%|██▉       | 4758/16104 [22:09:15<61:57:01, 19.66s/it]

 30%|██▉       | 4759/16104 [22:09:32<58:54:22, 18.69s/it]

 30%|██▉       | 4760/16104 [22:09:47<55:33:12, 17.63s/it]

 30%|██▉       | 4761/16104 [22:10:05<55:35:02, 17.64s/it]

 30%|██▉       | 4762/16104 [22:10:15<49:05:08, 15.58s/it]

 30%|██▉       | 4763/16104 [22:10:37<54:52:29, 17.42s/it]


 30%|██▉       | 4765/16104 [22:11:08<52:45:59, 16.75s/it]
{'loss': 0.5808, 'learning_rate': 1.6516628790634905e-06, 'rewards/chosen': -0.673810601234436, 'rewards/rejected': -1.5241899490356445, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8503793478012085, 'policy_logps/rejected': -434.8041076660156, 'policy_logps/chosen': -446.4374694824219, 'referece_logps/rejected': -419.5622253417969, 'referece_logps/chosen': -439.6993713378906, 'logits/rejected': -0.11234818398952484, 'logits/chosen': -0.23431342840194702, 'epoch': 1.78}

 30%|██▉       | 4766/16104 [22:11:19<47:13:34, 15.00s/it]

 30%|██▉       | 4767/16104 [22:11:32<46:02:02, 14.62s/it]

 30%|██▉       | 4768/16104 [22:11:50<49:05:16, 15.59s/it]

 30%|██▉       | 4769/16104 [22:12:11<53:39:34, 17.04s/it]

 30%|██▉       | 4770/16104 [22:12:27<53:02:12, 16.85s/it]

 30%|██▉       | 4771/16104 [22:12:41<50:23:02, 16.00s/it]

 30%|██▉       | 4772/16104 [22:12:53<46:22:12, 14.73s/it]

 30%|██▉       | 4773/16104 [22:13:09<47:35:15, 15.12s/it]

 30%|██▉       | 4774/16104 [22:13:22<45:41:22, 14.52s/it]

 30%|██▉       | 4775/16104 [22:13:36<45:22:00, 14.42s/it]

 30%|██▉       | 4776/16104 [22:13:50<44:26:22, 14.12s/it]

 30%|██▉       | 4777/16104 [22:14:08<48:04:55, 15.28s/it]

 30%|██▉       | 4778/16104 [22:14:27<52:02:31, 16.54s/it]

 30%|██▉       | 4779/16104 [22:14:42<50:51:42, 16.17s/it]

 30%|██▉       | 4780/16104 [22:14:59<51:36:01, 16.40s/it]

 30%|██▉       | 4781/16104 [22:15:12<48:19:26, 15.36s/it]

 30%|██▉       | 4782/16104 [22:15:32<52:35:18, 16.72s/it]

 30%|██▉       | 4783/16104 [22:15:45<49:22:15, 15.70s/it]

 30%|██▉       | 4784/16104 [22:16:02<50:20:52, 16.01s/it]

 30%|██▉       | 4785/16104 [22:16:22<53:45:41, 17.10s/it]

 30%|██▉       | 4786/16104 [22:16:35<50:15:02, 15.98s/it]

 30%|██▉       | 4787/16104 [22:16:47<46:04:28, 14.66s/it]

 30%|██▉       | 4788/16104 [22:16:57<42:25:24, 13.50s/it]

 30%|██▉       | 4789/16104 [22:17:10<41:14:42, 13.12s/it]

 30%|██▉       | 4790/16104 [22:17:23<41:25:06, 13.18s/it]

 30%|██▉       | 4791/16104 [22:17:42<46:47:17, 14.89s/it]

 30%|██▉       | 4792/16104 [22:18:02<51:20:50, 16.34s/it]

 30%|██▉       | 4793/16104 [22:18:16<49:26:46, 15.74s/it]

 30%|██▉       | 4794/16104 [22:18:29<46:39:37, 14.85s/it]

 30%|██▉       | 4795/16104 [22:18:41<44:33:33, 14.18s/it]

 30%|██▉       | 4796/16104 [22:19:01<49:36:23, 15.79s/it]

 30%|██▉       | 4797/16104 [22:19:19<51:20:58, 16.35s/it]

 30%|██▉       | 4798/16104 [22:19:40<55:45:06, 17.75s/it]

 30%|██▉       | 4799/16104 [22:20:00<58:18:46, 18.57s/it]

 30%|██▉       | 4800/16104 [22:20:18<58:06:19, 18.50s/it]

 30%|██▉       | 4801/16104 [22:20:35<56:12:22, 17.90s/it]

 30%|██▉       | 4802/16104 [22:20:52<55:14:00, 17.59s/it]

 30%|██▉       | 4803/16104 [22:21:06<51:54:23, 16.54s/it]

 30%|██▉       | 4804/16104 [22:21:25<53:55:10, 17.18s/it]


 30%|██▉       | 4806/16104 [22:21:58<53:13:59, 16.96s/it]

 30%|██▉       | 4807/16104 [22:22:12<50:25:19, 16.07s/it]

 30%|██▉       | 4808/16104 [22:22:23<45:38:01, 14.54s/it]

 30%|██▉       | 4809/16104 [22:22:39<47:15:11, 15.06s/it]

 30%|██▉       | 4810/16104 [22:22:59<51:20:59, 16.37s/it]

 30%|██▉       | 4811/16104 [22:23:15<51:06:30, 16.29s/it]

 30%|██▉       | 4812/16104 [22:23:35<54:35:21, 17.40s/it]

 30%|██▉       | 4813/16104 [22:23:53<55:30:08, 17.70s/it]

 30%|██▉       | 4814/16104 [22:24:10<54:46:49, 17.47s/it]

 30%|██▉       | 4815/16104 [22:24:26<53:08:36, 16.95s/it]

 30%|██▉       | 4816/16104 [22:24:39<49:48:36, 15.89s/it]

 30%|██▉       | 4817/16104 [22:24:59<53:47:39, 17.16s/it]

 30%|██▉       | 4818/16104 [22:25:19<56:03:45, 17.88s/it]

 30%|██▉       | 4819/16104 [22:25:36<55:23:01, 17.67s/it]

 30%|██▉       | 4820/16104 [22:25:56<57:40:18, 18.40s/it]

 30%|██▉       | 4821/16104 [22:26:11<54:22:03, 17.35s/it]

 30%|██▉       | 4822/16104 [22:26:27<52:53:32, 16.88s/it]

 30%|██▉       | 4823/16104 [22:26:47<55:36:52, 17.75s/it]

 30%|██▉       | 4824/16104 [22:26:58<49:58:55, 15.95s/it]

 30%|██▉       | 4825/16104 [22:27:21<56:07:32, 17.91s/it]

 30%|██▉       | 4826/16104 [22:27:41<57:50:36, 18.46s/it]

 30%|██▉       | 4827/16104 [22:27:58<57:09:50, 18.25s/it]

 30%|██▉       | 4828/16104 [22:28:18<58:29:48, 18.68s/it]

 30%|██▉       | 4829/16104 [22:28:36<57:43:06, 18.43s/it]

 30%|██▉       | 4830/16104 [22:28:54<57:23:24, 18.33s/it]

 30%|██▉       | 4831/16104 [22:29:14<58:40:00, 18.74s/it]

 30%|███       | 4832/16104 [22:29:27<53:28:02, 17.08s/it]

 30%|███       | 4833/16104 [22:29:39<49:02:11, 15.66s/it]

 30%|███       | 4834/16104 [22:29:59<52:33:40, 16.79s/it]

 30%|███       | 4835/16104 [22:30:19<55:36:49, 17.77s/it]

 30%|███       | 4836/16104 [22:30:38<57:31:41, 18.38s/it]

 30%|███       | 4837/16104 [22:30:50<51:19:56, 16.40s/it]

 30%|███       | 4838/16104 [22:31:10<54:45:57, 17.50s/it]

 30%|███       | 4839/16104 [22:31:30<57:13:26, 18.29s/it]

 30%|███       | 4840/16104 [22:31:45<54:00:05, 17.26s/it]

 30%|███       | 4841/16104 [22:32:09<59:46:36, 19.11s/it]

 30%|███       | 4842/16104 [22:32:28<59:40:46, 19.08s/it]

 30%|███       | 4843/16104 [22:32:43<55:51:11, 17.86s/it]

 30%|███       | 4844/16104 [22:33:02<57:19:52, 18.33s/it]

 30%|███       | 4845/16104 [22:33:14<51:12:56, 16.38s/it]

 30%|███       | 4846/16104 [22:33:26<47:22:04, 15.15s/it]

 30%|███       | 4847/16104 [22:33:40<45:46:09, 14.64s/it]

 30%|███       | 4848/16104 [22:33:52<43:35:01, 13.94s/it]

 30%|███       | 4849/16104 [22:34:06<43:27:24, 13.90s/it]

 30%|███       | 4850/16104 [22:34:22<45:57:00, 14.70s/it]

 30%|███       | 4851/16104 [22:34:39<47:50:45, 15.31s/it]

 30%|███       | 4852/16104 [22:34:54<47:34:41, 15.22s/it]

 30%|███       | 4853/16104 [22:35:06<44:39:23, 14.29s/it]

 30%|███       | 4854/16104 [22:35:27<50:31:52, 16.17s/it]

 30%|███       | 4855/16104 [22:35:41<49:04:30, 15.71s/it]

 30%|███       | 4856/16104 [22:35:55<46:47:35, 14.98s/it]

 30%|███       | 4857/16104 [22:36:06<43:39:44, 13.98s/it]

 30%|███       | 4858/16104 [22:36:26<49:12:15, 15.75s/it]

 30%|███       | 4859/16104 [22:36:40<47:34:49, 15.23s/it]

 30%|███       | 4860/16104 [22:37:01<52:53:49, 16.94s/it]

 30%|███       | 4861/16104 [22:37:17<51:37:22, 16.53s/it]

 30%|███       | 4862/16104 [22:37:37<54:50:34, 17.56s/it]

 30%|███       | 4863/16104 [22:37:53<53:42:55, 17.20s/it]

 30%|███       | 4864/16104 [22:38:06<49:16:36, 15.78s/it]

 30%|███       | 4865/16104 [22:38:22<49:28:31, 15.85s/it]

 30%|███       | 4866/16104 [22:38:41<52:57:22, 16.96s/it]

 30%|███       | 4867/16104 [22:39:02<56:27:42, 18.09s/it]

 30%|███       | 4868/16104 [22:39:14<50:29:42, 16.18s/it]

 30%|███       | 4869/16104 [22:39:24<45:24:23, 14.55s/it]

 30%|███       | 4870/16104 [22:39:35<41:45:54, 13.38s/it]

 30%|███       | 4871/16104 [22:39:47<40:21:15, 12.93s/it]

 30%|███       | 4872/16104 [22:40:03<43:13:41, 13.86s/it]

 30%|███       | 4873/16104 [22:40:22<48:37:40, 15.59s/it]

 30%|███       | 4874/16104 [22:40:44<53:46:42, 17.24s/it]

 30%|███       | 4875/16104 [22:41:03<56:04:19, 17.98s/it]

 30%|███       | 4876/16104 [22:41:24<58:14:40, 18.67s/it]

 30%|███       | 4877/16104 [22:41:45<60:40:06, 19.45s/it]

 30%|███       | 4878/16104 [22:41:56<53:18:30, 17.10s/it]

 30%|███       | 4879/16104 [22:42:16<56:02:47, 17.97s/it]

 30%|███       | 4880/16104 [22:42:37<58:05:42, 18.63s/it]

 30%|███       | 4881/16104 [22:42:50<53:00:37, 17.00s/it]

 30%|███       | 4882/16104 [22:43:10<55:32:06, 17.82s/it]

 30%|███       | 4883/16104 [22:43:29<57:21:22, 18.40s/it]

 30%|███       | 4884/16104 [22:43:52<60:53:31, 19.54s/it]

 30%|███       | 4885/16104 [22:44:04<54:15:54, 17.41s/it]

 30%|███       | 4886/16104 [22:44:25<57:38:40, 18.50s/it]

 30%|███       | 4887/16104 [22:44:42<56:15:27, 18.06s/it]

 30%|███       | 4888/16104 [22:44:56<52:20:11, 16.80s/it]

 30%|███       | 4889/16104 [22:45:09<48:56:31, 15.71s/it]

 30%|███       | 4890/16104 [22:45:23<47:44:03, 15.32s/it]

 30%|███       | 4891/16104 [22:45:35<43:46:18, 14.05s/it]

 30%|███       | 4892/16104 [22:45:50<45:16:37, 14.54s/it]

 30%|███       | 4893/16104 [22:46:06<46:13:37, 14.84s/it]

 30%|███       | 4894/16104 [22:46:22<47:09:12, 15.14s/it]

 30%|███       | 4895/16104 [22:46:32<43:04:14, 13.83s/it]

 30%|███       | 4896/16104 [22:46:45<41:47:27, 13.42s/it]

 30%|███       | 4897/16104 [22:46:59<42:20:02, 13.60s/it]

 30%|███       | 4898/16104 [22:47:19<48:24:06, 15.55s/it]

 30%|███       | 4899/16104 [22:47:32<45:33:08, 14.64s/it]

 30%|███       | 4900/16104 [22:47:50<48:46:41, 15.67s/it]

 30%|███       | 4901/16104 [22:48:06<49:29:37, 15.90s/it]

 30%|███       | 4902/16104 [22:48:21<48:44:16, 15.66s/it]

 30%|███       | 4903/16104 [22:48:40<51:47:25, 16.65s/it]

 30%|███       | 4904/16104 [22:49:00<54:51:33, 17.63s/it]

 30%|███       | 4905/16104 [22:49:23<60:06:33, 19.32s/it]
{'loss': 0.5137, 'learning_rate': 1.6300495346691583e-06, 'rewards/chosen': -0.7670285105705261, 'rewards/rejected': -1.5961095094680786, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8290808200836182, 'policy_logps/rejected': -328.0124206542969, 'policy_logps/chosen': -357.9066467285156, 'referece_logps/rejected': -312.05133056640625, 'referece_logps/chosen': -350.23638916015625, 'logits/rejected': -0.37990719079971313, 'logits/chosen': -0.12449951469898224, 'epoch': 1.83}


 30%|███       | 4907/16104 [22:50:01<58:52:29, 18.93s/it]

 30%|███       | 4908/16104 [22:50:12<51:40:13, 16.61s/it]

 30%|███       | 4909/16104 [22:50:23<46:07:44, 14.83s/it]
{'loss': 0.4824, 'learning_rate': 1.6294245883818546e-06, 'rewards/chosen': -0.9013814926147461, 'rewards/rejected': -1.6634832620620728, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7621017098426819, 'policy_logps/rejected': -132.85003662109375, 'policy_logps/chosen': -363.10699462890625, 'referece_logps/rejected': -116.2152099609375, 'referece_logps/chosen': -354.09320068359375, 'logits/rejected': -0.7139784097671509, 'logits/chosen': -0.7797543406486511, 'epoch': 1.83}


 30%|███       | 4911/16104 [22:51:01<53:42:26, 17.27s/it]

 31%|███       | 4912/16104 [22:51:22<56:30:39, 18.18s/it]

 31%|███       | 4913/16104 [22:51:37<53:23:22, 17.17s/it]

 31%|███       | 4914/16104 [22:51:54<53:30:14, 17.21s/it]

 31%|███       | 4915/16104 [22:52:15<56:38:45, 18.23s/it]

 31%|███       | 4916/16104 [22:52:32<55:48:04, 17.96s/it]
{'loss': 0.5453, 'learning_rate': 1.6283299523607026e-06, 'rewards/chosen': -0.6054672002792358, 'rewards/rejected': -0.7707467675209045, 'rewards/accuracies': 0.625, 'rewards/margins': 0.16527950763702393, 'policy_logps/rejected': -334.020263671875, 'policy_logps/chosen': -305.7637023925781, 'referece_logps/rejected': -326.3127746582031, 'referece_logps/chosen': -299.7090148925781, 'logits/rejected': -0.10407871752977371, 'logits/chosen': -0.21193768084049225, 'epoch': 1.83}


 31%|███       | 4918/16104 [22:52:57<46:35:10, 14.99s/it]
{'loss': 0.486, 'learning_rate': 1.6280169703632813e-06, 'rewards/chosen': -0.8280273675918579, 'rewards/rejected': -1.0262906551361084, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1982632577419281, 'policy_logps/rejected': -282.1843566894531, 'policy_logps/chosen': -310.1722106933594, 'referece_logps/rejected': -271.92144775390625, 'referece_logps/chosen': -301.8919677734375, 'logits/rejected': -0.3764860928058624, 'logits/chosen': -0.30592361092567444, 'epoch': 1.83}


 31%|███       | 4920/16104 [22:53:29<47:08:48, 15.18s/it]

 31%|███       | 4921/16104 [22:53:44<46:50:21, 15.08s/it]
{'loss': 0.5769, 'learning_rate': 1.627547306849928e-06, 'rewards/chosen': -0.6393117904663086, 'rewards/rejected': -1.479911208152771, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8405994176864624, 'policy_logps/rejected': -358.94903564453125, 'policy_logps/chosen': -440.9460754394531, 'referece_logps/rejected': -344.1499328613281, 'referece_logps/chosen': -434.5529479980469, 'logits/rejected': -0.17161113023757935, 'logits/chosen': -0.12487268447875977, 'epoch': 1.83}


 31%|███       | 4923/16104 [22:54:14<45:44:36, 14.73s/it]

 31%|███       | 4924/16104 [22:54:33<49:39:26, 15.99s/it]

 31%|███       | 4925/16104 [22:54:50<50:27:54, 16.25s/it]
{'loss': 0.5344, 'learning_rate': 1.6269207334659814e-06, 'rewards/chosen': -0.7423849105834961, 'rewards/rejected': -1.0713410377502441, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3289560377597809, 'policy_logps/rejected': -503.6134033203125, 'policy_logps/chosen': -508.16571044921875, 'referece_logps/rejected': -492.9000244140625, 'referece_logps/chosen': -500.74188232421875, 'logits/rejected': -0.17667196691036224, 'logits/chosen': -0.3578736186027527, 'epoch': 1.83}


 31%|███       | 4927/16104 [22:55:23<50:57:30, 16.41s/it]

 31%|███       | 4928/16104 [22:55:40<51:48:55, 16.69s/it]
{'loss': 0.5565, 'learning_rate': 1.6264505371251915e-06, 'rewards/chosen': -0.6985257267951965, 'rewards/rejected': -2.007788896560669, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3092631101608276, 'policy_logps/rejected': -392.4685363769531, 'policy_logps/chosen': -336.63385009765625, 'referece_logps/rejected': -372.3905944824219, 'referece_logps/chosen': -329.6485900878906, 'logits/rejected': -0.10116461664438248, 'logits/chosen': 0.10371221601963043, 'epoch': 1.84}

 31%|███       | 4929/16104 [22:55:51<46:51:21, 15.09s/it]


 31%|███       | 4931/16104 [22:56:22<46:43:04, 15.05s/it]

 31%|███       | 4932/16104 [22:56:41<49:54:01, 16.08s/it]

 31%|███       | 4933/16104 [22:56:59<51:54:27, 16.73s/it]

 31%|███       | 4934/16104 [22:57:11<47:20:21, 15.26s/it]

 31%|███       | 4935/16104 [22:57:31<51:59:24, 16.76s/it]

 31%|███       | 4936/16104 [22:57:45<49:12:40, 15.86s/it]

 31%|███       | 4937/16104 [22:58:04<52:43:56, 17.00s/it]

 31%|███       | 4938/16104 [22:58:17<48:37:30, 15.68s/it]
{'loss': 0.6284, 'learning_rate': 1.6248815697837355e-06, 'rewards/chosen': -1.2428843975067139, 'rewards/rejected': -1.5943859815597534, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3515015244483948, 'policy_logps/rejected': -512.1895751953125, 'policy_logps/chosen': -369.85089111328125, 'referece_logps/rejected': -496.2457580566406, 'referece_logps/chosen': -357.4219970703125, 'logits/rejected': -0.7742146253585815, 'logits/chosen': -0.734473705291748, 'epoch': 1.84}


 31%|███       | 4940/16104 [22:58:46<46:30:53, 15.00s/it]

 31%|███       | 4941/16104 [22:58:59<44:25:21, 14.33s/it]

 31%|███       | 4942/16104 [22:59:13<44:10:30, 14.25s/it]

 31%|███       | 4943/16104 [22:59:25<41:50:15, 13.49s/it]
{'loss': 0.5037, 'learning_rate': 1.624096137807205e-06, 'rewards/chosen': -1.060683250427246, 'rewards/rejected': -1.4719297885894775, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4112465977668762, 'policy_logps/rejected': -434.1116943359375, 'policy_logps/chosen': -499.60260009765625, 'referece_logps/rejected': -419.392333984375, 'referece_logps/chosen': -488.9957580566406, 'logits/rejected': -0.23840966820716858, 'logits/chosen': -0.10637854039669037, 'epoch': 1.84}

 31%|███       | 4944/16104 [22:59:36<39:12:01, 12.65s/it]

 31%|███       | 4945/16104 [22:59:55<45:45:22, 14.76s/it]


 31%|███       | 4947/16104 [23:00:20<41:42:25, 13.46s/it]

 31%|███       | 4948/16104 [23:00:42<49:32:16, 15.99s/it]
{'loss': 0.5335, 'learning_rate': 1.6233100746856635e-06, 'rewards/chosen': -0.9849819540977478, 'rewards/rejected': -1.97812020778656, 'rewards/accuracies': 0.75, 'rewards/margins': 0.993138313293457, 'policy_logps/rejected': -401.6579284667969, 'policy_logps/chosen': -420.139404296875, 'referece_logps/rejected': -381.8767395019531, 'referece_logps/chosen': -410.28961181640625, 'logits/rejected': -0.36671918630599976, 'logits/chosen': -0.3675369918346405, 'epoch': 1.84}

 31%|███       | 4949/16104 [23:00:53<45:00:08, 14.52s/it]


 31%|███       | 4951/16104 [23:01:31<52:32:15, 16.96s/it]

 31%|███       | 4952/16104 [23:01:51<56:07:16, 18.12s/it]

 31%|███       | 4953/16104 [23:02:10<57:04:46, 18.43s/it]

 31%|███       | 4954/16104 [23:02:24<52:50:02, 17.06s/it]

 31%|███       | 4955/16104 [23:02:43<53:55:40, 17.41s/it]

 31%|███       | 4956/16104 [23:03:03<56:15:18, 18.17s/it]

 31%|███       | 4957/16104 [23:03:20<56:04:26, 18.11s/it]

 31%|███       | 4958/16104 [23:03:42<59:24:23, 19.19s/it]

 31%|███       | 4959/16104 [23:03:58<55:50:45, 18.04s/it]
{'loss': 0.6024, 'learning_rate': 1.6215785181062487e-06, 'rewards/chosen': -1.242578148841858, 'rewards/rejected': -2.273854970932007, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0312769412994385, 'policy_logps/rejected': -462.28289794921875, 'policy_logps/chosen': -325.3355712890625, 'referece_logps/rejected': -439.5443420410156, 'referece_logps/chosen': -312.9097900390625, 'logits/rejected': -0.07729896903038025, 'logits/chosen': -0.0686277449131012, 'epoch': 1.85}


 31%|███       | 4961/16104 [23:04:38<58:55:25, 19.04s/it]

 31%|███       | 4962/16104 [23:04:56<58:40:55, 18.96s/it]

 31%|███       | 4963/16104 [23:05:08<52:06:25, 16.84s/it]

 31%|███       | 4964/16104 [23:05:23<50:05:00, 16.18s/it]

 31%|███       | 4965/16104 [23:05:37<48:25:21, 15.65s/it]
{'loss': 0.6229, 'learning_rate': 1.6206327498159817e-06, 'rewards/chosen': -0.7863829135894775, 'rewards/rejected': -1.1088775396347046, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3224947154521942, 'policy_logps/rejected': -363.272216796875, 'policy_logps/chosen': -356.1377868652344, 'referece_logps/rejected': -352.1834716796875, 'referece_logps/chosen': -348.27398681640625, 'logits/rejected': -0.8018666505813599, 'logits/chosen': -0.721272349357605, 'epoch': 1.85}

 31%|███       | 4966/16104 [23:05:48<43:52:42, 14.18s/it]


 31%|███       | 4968/16104 [23:06:21<46:19:18, 14.97s/it]

 31%|███       | 4969/16104 [23:06:31<42:13:01, 13.65s/it]

 31%|███       | 4970/16104 [23:06:53<49:50:25, 16.12s/it]

 31%|███       | 4971/16104 [23:07:11<51:25:56, 16.63s/it]

 31%|███       | 4972/16104 [23:07:33<56:03:46, 18.13s/it]

 31%|███       | 4973/16104 [23:07:51<56:19:52, 18.22s/it]

 31%|███       | 4974/16104 [23:08:07<53:54:56, 17.44s/it]

 31%|███       | 4975/16104 [23:08:23<52:27:05, 16.97s/it]

 31%|███       | 4976/16104 [23:08:34<47:46:55, 15.46s/it]

 31%|███       | 4977/16104 [23:08:49<47:21:48, 15.32s/it]

 31%|███       | 4978/16104 [23:09:05<47:54:37, 15.50s/it]

 31%|███       | 4979/16104 [23:09:20<46:50:44, 15.16s/it]

 31%|███       | 4980/16104 [23:09:40<51:15:05, 16.59s/it]

 31%|███       | 4981/16104 [23:09:59<54:02:01, 17.49s/it]

 31%|███       | 4982/16104 [23:10:19<55:55:40, 18.10s/it]

 31%|███       | 4983/16104 [23:10:35<54:00:03, 17.48s/it]

 31%|███       | 4984/16104 [23:10:49<51:23:52, 16.64s/it]
{'loss': 0.5474, 'learning_rate': 1.617631860863633e-06, 'rewards/chosen': -0.7405167818069458, 'rewards/rejected': -1.5633089542388916, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8227921724319458, 'policy_logps/rejected': -475.42572021484375, 'policy_logps/chosen': -496.5206298828125, 'referece_logps/rejected': -459.79266357421875, 'referece_logps/chosen': -489.11541748046875, 'logits/rejected': -1.0389453172683716, 'logits/chosen': -1.080743432044983, 'epoch': 1.86}


 31%|███       | 4986/16104 [23:11:19<47:11:17, 15.28s/it]
{'loss': 0.5633, 'learning_rate': 1.6173154523846276e-06, 'rewards/chosen': -0.4010936915874481, 'rewards/rejected': -0.5801683664321899, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17907467484474182, 'policy_logps/rejected': -264.4951477050781, 'policy_logps/chosen': -605.9159545898438, 'referece_logps/rejected': -258.6934509277344, 'referece_logps/chosen': -601.905029296875, 'logits/rejected': 0.111155204474926, 'logits/chosen': 0.04441642761230469, 'epoch': 1.86}


 31%|███       | 4988/16104 [23:11:49<45:53:36, 14.86s/it]

 31%|███       | 4989/16104 [23:12:01<43:08:40, 13.97s/it]
{'loss': 0.5628, 'learning_rate': 1.6168406523957874e-06, 'rewards/chosen': -0.6699270606040955, 'rewards/rejected': -1.1395313739776611, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4696042835712433, 'policy_logps/rejected': -292.71148681640625, 'policy_logps/chosen': -375.40960693359375, 'referece_logps/rejected': -281.316162109375, 'referece_logps/chosen': -368.7103576660156, 'logits/rejected': 0.27451372146606445, 'logits/chosen': 0.20736883580684662, 'epoch': 1.86}


 31%|███       | 4991/16104 [23:12:25<39:59:13, 12.95s/it]

 31%|███       | 4992/16104 [23:12:43<44:34:41, 14.44s/it]
{'loss': 0.5557, 'learning_rate': 1.6163656278362075e-06, 'rewards/chosen': -0.5267232060432434, 'rewards/rejected': -1.5682345628738403, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0415114164352417, 'policy_logps/rejected': -319.7635192871094, 'policy_logps/chosen': -167.85324096679688, 'referece_logps/rejected': -304.0811462402344, 'referece_logps/chosen': -162.5860137939453, 'logits/rejected': -0.37399688363075256, 'logits/chosen': -0.35844886302948, 'epoch': 1.86}


 31%|███       | 4994/16104 [23:13:17<49:14:38, 15.96s/it]
{'loss': 0.5052, 'learning_rate': 1.6160488201203642e-06, 'rewards/chosen': -1.0067898035049438, 'rewards/rejected': -1.0949136018753052, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08812371641397476, 'policy_logps/rejected': -347.655029296875, 'policy_logps/chosen': -400.1842041015625, 'referece_logps/rejected': -336.7059020996094, 'referece_logps/chosen': -390.1163024902344, 'logits/rejected': 0.05476602911949158, 'logits/chosen': 0.1519114375114441, 'epoch': 1.86}


 31%|███       | 4996/16104 [23:13:50<49:12:10, 15.95s/it]
{'loss': 0.5393, 'learning_rate': 1.6157319127234254e-06, 'rewards/chosen': -0.7518091201782227, 'rewards/rejected': -1.433645248413086, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6818361282348633, 'policy_logps/rejected': -320.9792785644531, 'policy_logps/chosen': -299.56829833984375, 'referece_logps/rejected': -306.6428527832031, 'referece_logps/chosen': -292.05023193359375, 'logits/rejected': -0.7081561088562012, 'logits/chosen': -0.860737681388855, 'epoch': 1.86}

 31%|███       | 4997/16104 [23:14:02<45:47:39, 14.84s/it]


 31%|███       | 4999/16104 [23:14:31<44:34:42, 14.45s/it]

 31%|███       | 5000/16104 [23:14:43<42:33:46, 13.80s/it]

 31%|███       | 5001/16104 [23:15:17<60:55:27, 19.75s/it]

 31%|███       | 5002/16104 [23:15:34<58:23:55, 18.94s/it]
{'loss': 0.5532, 'learning_rate': 1.6147805929588967e-06, 'rewards/chosen': -0.8557455539703369, 'rewards/rejected': -1.4406397342681885, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5848941802978516, 'policy_logps/rejected': -401.2142639160156, 'policy_logps/chosen': -419.5853271484375, 'referece_logps/rejected': -386.807861328125, 'referece_logps/chosen': -411.02789306640625, 'logits/rejected': -0.17727741599082947, 'logits/chosen': -0.13111859560012817, 'epoch': 1.86}


 31%|███       | 5004/16104 [23:16:03<51:02:19, 16.55s/it]
{'loss': 0.5151, 'learning_rate': 1.6144632873505165e-06, 'rewards/chosen': -0.4115898013114929, 'rewards/rejected': -1.3989304304122925, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9873406291007996, 'policy_logps/rejected': -525.8779296875, 'policy_logps/chosen': -451.6322021484375, 'referece_logps/rejected': -511.88861083984375, 'referece_logps/chosen': -447.51629638671875, 'logits/rejected': -0.49870172142982483, 'logits/chosen': -0.46344149112701416, 'epoch': 1.86}


 31%|███       | 5006/16104 [23:16:32<47:59:58, 15.57s/it]

 31%|███       | 5007/16104 [23:16:48<48:40:23, 15.79s/it]
{'loss': 0.6893, 'learning_rate': 1.613987142532973e-06, 'rewards/chosen': -0.832385241985321, 'rewards/rejected': -1.5442454814910889, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7118602395057678, 'policy_logps/rejected': -321.3541259765625, 'policy_logps/chosen': -403.2020568847656, 'referece_logps/rejected': -305.91168212890625, 'referece_logps/chosen': -394.8782043457031, 'logits/rejected': -0.30470338463783264, 'logits/chosen': -0.43707919120788574, 'epoch': 1.87}


 31%|███       | 5009/16104 [23:17:10<41:06:15, 13.34s/it]

 31%|███       | 5010/16104 [23:17:25<42:57:20, 13.94s/it]

 31%|███       | 5011/16104 [23:17:48<51:35:38, 16.74s/it]
{'loss': 0.555, 'learning_rate': 1.6133519350899732e-06, 'rewards/chosen': -0.5988420844078064, 'rewards/rejected': -1.0457228422164917, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4468807578086853, 'policy_logps/rejected': -330.5137939453125, 'policy_logps/chosen': -374.7026672363281, 'referece_logps/rejected': -320.0565490722656, 'referece_logps/chosen': -368.7142333984375, 'logits/rejected': -1.239493727684021, 'logits/chosen': -1.3214235305786133, 'epoch': 1.87}


 31%|███       | 5013/16104 [23:18:22<52:36:07, 17.07s/it]

 31%|███       | 5014/16104 [23:18:42<55:28:31, 18.01s/it]


 31%|███       | 5015/16104 [23:18:54<49:34:29, 16.09s/it]

 31%|███       | 5016/16104 [23:19:14<52:54:41, 17.18s/it]

 31%|███       | 5017/16104 [23:19:26<48:42:30, 15.82s/it]

 31%|███       | 5018/16104 [23:19:40<46:54:35, 15.23s/it]

 31%|███       | 5019/16104 [23:20:01<51:33:46, 16.75s/it]
{'loss': 0.4886, 'learning_rate': 1.6120803296787606e-06, 'rewards/chosen': -0.7533999681472778, 'rewards/rejected': -1.5766850709915161, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8232852816581726, 'policy_logps/rejected': -470.816650390625, 'policy_logps/chosen': -455.138671875, 'referece_logps/rejected': -455.0497741699219, 'referece_logps/chosen': -447.60467529296875, 'logits/rejected': -1.0777552127838135, 'logits/chosen': -1.109993577003479, 'epoch': 1.87}


 31%|███       | 5021/16104 [23:20:36<52:15:18, 16.97s/it]

 31%|███       | 5022/16104 [23:20:47<46:27:56, 15.09s/it]

 31%|███       | 5023/16104 [23:21:02<46:35:35, 15.14s/it]
{'loss': 0.5379, 'learning_rate': 1.6114439325335673e-06, 'rewards/chosen': -0.7641175389289856, 'rewards/rejected': -1.4131094217300415, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6489919424057007, 'policy_logps/rejected': -378.87841796875, 'policy_logps/chosen': -354.52880859375, 'referece_logps/rejected': -364.747314453125, 'referece_logps/chosen': -346.8876647949219, 'logits/rejected': 0.04506094381213188, 'logits/chosen': -0.1722540259361267, 'epoch': 1.87}

 31%|███       | 5024/16104 [23:21:13<42:40:36, 13.87s/it]

 31%|███       | 5025/16104 [23:21:26<41:56:21, 13.63s/it]

 31%|███       | 5026/16104 [23:21:45<47:26:06, 15.41s/it]


 31%|███       | 5028/16104 [23:22:24<54:09:20, 17.60s/it]

 31%|███       | 5029/16104 [23:22:44<56:12:33, 18.27s/it]
{'loss': 0.5773, 'learning_rate': 1.6104885949246565e-06, 'rewards/chosen': -1.0949381589889526, 'rewards/rejected': -1.4021401405334473, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3072020411491394, 'policy_logps/rejected': -331.8486328125, 'policy_logps/chosen': -350.0020751953125, 'referece_logps/rejected': -317.82720947265625, 'referece_logps/chosen': -339.05267333984375, 'logits/rejected': -0.7042509913444519, 'logits/chosen': -0.8025854229927063, 'epoch': 1.87}

 31%|███       | 5030/16104 [23:22:58<52:07:36, 16.95s/it]

 31%|███       | 5031/16104 [23:23:18<54:45:40, 17.80s/it]


 31%|███▏      | 5033/16104 [23:23:57<57:55:48, 18.84s/it]
{'loss': 0.5382, 'learning_rate': 1.6098512091924482e-06, 'rewards/chosen': -0.7308515906333923, 'rewards/rejected': -0.9794004559516907, 'rewards/accuracies': 0.625, 'rewards/margins': 0.24854891002178192, 'policy_logps/rejected': -445.9599914550781, 'policy_logps/chosen': -443.4029235839844, 'referece_logps/rejected': -436.1659851074219, 'referece_logps/chosen': -436.0944519042969, 'logits/rejected': -0.7043168544769287, 'logits/chosen': -0.7232155799865723, 'epoch': 1.88}

 31%|███▏      | 5034/16104 [23:24:15<57:34:28, 18.72s/it]

 31%|███▏      | 5035/16104 [23:24:36<59:06:26, 19.22s/it]

 31%|███▏      | 5036/16104 [23:24:56<59:58:45, 19.51s/it]

 31%|███▏      | 5037/16104 [23:25:18<62:13:14, 20.24s/it]

 31%|███▏      | 5038/16104 [23:25:38<61:53:33, 20.13s/it]


 31%|███▏      | 5040/16104 [23:26:02<49:35:20, 16.14s/it]

 31%|███▏      | 5041/16104 [23:26:13<44:34:03, 14.50s/it]
{'loss': 0.5956, 'learning_rate': 1.6085752540015358e-06, 'rewards/chosen': -1.39506196975708, 'rewards/rejected': -0.9799910187721252, 'rewards/accuracies': 0.25, 'rewards/margins': -0.4150710105895996, 'policy_logps/rejected': -367.05731201171875, 'policy_logps/chosen': -433.3187561035156, 'referece_logps/rejected': -357.2574157714844, 'referece_logps/chosen': -419.3681640625, 'logits/rejected': -0.5774742960929871, 'logits/chosen': -0.5198855996131897, 'epoch': 1.88}


 31%|███▏      | 5043/16104 [23:26:39<42:01:26, 13.68s/it]
{'loss': 0.6009, 'learning_rate': 1.6082560188951834e-06, 'rewards/chosen': -0.4217796325683594, 'rewards/rejected': -0.9804152250289917, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5586355328559875, 'policy_logps/rejected': -464.4600524902344, 'policy_logps/chosen': -391.42816162109375, 'referece_logps/rejected': -454.6558532714844, 'referece_logps/chosen': -387.21038818359375, 'logits/rejected': -0.7046680450439453, 'logits/chosen': -0.488897442817688, 'epoch': 1.88}


 31%|███▏      | 5045/16104 [23:27:03<39:29:13, 12.85s/it]

 31%|███▏      | 5046/16104 [23:27:23<46:25:36, 15.11s/it]
{'loss': 0.6159, 'learning_rate': 1.6077769817139928e-06, 'rewards/chosen': -1.0402556657791138, 'rewards/rejected': -1.4049831628799438, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3647274374961853, 'policy_logps/rejected': -241.5650634765625, 'policy_logps/chosen': -327.5635986328125, 'referece_logps/rejected': -227.5152130126953, 'referece_logps/chosen': -317.1610412597656, 'logits/rejected': -0.35764428973197937, 'logits/chosen': -0.445403516292572, 'epoch': 1.88}

 31%|███▏      | 5047/16104 [23:27:41<49:35:14, 16.14s/it]


 31%|███▏      | 5049/16104 [23:28:20<54:58:19, 17.90s/it]
{'loss': 0.5793, 'learning_rate': 1.6072977232618367e-06, 'rewards/chosen': -0.8163079023361206, 'rewards/rejected': -1.647768497467041, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8314605951309204, 'policy_logps/rejected': -378.4541931152344, 'policy_logps/chosen': -381.9783020019531, 'referece_logps/rejected': -361.9764709472656, 'referece_logps/chosen': -373.81524658203125, 'logits/rejected': -0.32158952951431274, 'logits/chosen': -0.38404905796051025, 'epoch': 1.88}

 31%|███▏      | 5050/16104 [23:28:36<52:45:34, 17.18s/it]


 31%|███▏      | 5052/16104 [23:29:07<50:34:39, 16.47s/it]

 31%|███▏      | 5053/16104 [23:29:24<51:33:58, 16.80s/it]

 31%|███▏      | 5054/16104 [23:29:37<47:29:13, 15.47s/it]
{'loss': 0.5101, 'learning_rate': 1.6064984679355911e-06, 'rewards/chosen': -0.9434868097305298, 'rewards/rejected': -1.4007227420806885, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4572359025478363, 'policy_logps/rejected': -473.2044372558594, 'policy_logps/chosen': -426.2686767578125, 'referece_logps/rejected': -459.197265625, 'referece_logps/chosen': -416.8338317871094, 'logits/rejected': -1.6557782888412476, 'logits/chosen': -1.4571377038955688, 'epoch': 1.88}


 31%|███▏      | 5056/16104 [23:30:14<53:24:12, 17.40s/it]
{'loss': 0.4964, 'learning_rate': 1.6061785940222046e-06, 'rewards/chosen': -1.0322184562683105, 'rewards/rejected': -1.3952778577804565, 'rewards/accuracies': 0.5, 'rewards/margins': 0.36305949091911316, 'policy_logps/rejected': -478.3505859375, 'policy_logps/chosen': -433.1237487792969, 'referece_logps/rejected': -464.39776611328125, 'referece_logps/chosen': -422.801513671875, 'logits/rejected': -1.0945767164230347, 'logits/chosen': -0.9604176878929138, 'epoch': 1.88}


 31%|███▏      | 5058/16104 [23:30:55<57:44:42, 18.82s/it]

 31%|███▏      | 5059/16104 [23:31:13<57:04:31, 18.60s/it]

 31%|███▏      | 5060/16104 [23:31:33<58:05:27, 18.94s/it]

 31%|███▏      | 5061/16104 [23:31:53<58:53:55, 19.20s/it]
{'loss': 0.4889, 'learning_rate': 1.6053784802344007e-06, 'rewards/chosen': -0.6822155117988586, 'rewards/rejected': -1.6782444715499878, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9960289001464844, 'policy_logps/rejected': -321.8748779296875, 'policy_logps/chosen': -231.23318481445312, 'referece_logps/rejected': -305.0924072265625, 'referece_logps/chosen': -224.41104125976562, 'logits/rejected': -0.7497634887695312, 'logits/chosen': -0.633051872253418, 'epoch': 1.89}


 31%|███▏      | 5063/16104 [23:32:27<56:01:07, 18.27s/it]
{'loss': 0.4429, 'learning_rate': 1.6050582632534805e-06, 'rewards/chosen': -0.9405320882797241, 'rewards/rejected': -2.3580565452575684, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4175244569778442, 'policy_logps/rejected': -515.724365234375, 'policy_logps/chosen': -373.9787292480469, 'referece_logps/rejected': -492.1437683105469, 'referece_logps/chosen': -364.57342529296875, 'logits/rejected': -0.8320077657699585, 'logits/chosen': -0.7863562107086182, 'epoch': 1.89}

 31%|███▏      | 5064/16104 [23:32:44<54:54:32, 17.91s/it]


 31%|███▏      | 5066/16104 [23:33:23<57:08:57, 18.64s/it]
{'loss': 0.5265, 'learning_rate': 1.6045777542306503e-06, 'rewards/chosen': -0.7833425402641296, 'rewards/rejected': -1.269932508468628, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4865899980068207, 'policy_logps/rejected': -380.5116882324219, 'policy_logps/chosen': -347.8406982421875, 'referece_logps/rejected': -367.8123779296875, 'referece_logps/chosen': -340.0072937011719, 'logits/rejected': -0.002793937921524048, 'logits/chosen': 0.050106942653656006, 'epoch': 1.89}


 31%|███▏      | 5068/16104 [23:33:57<56:12:31, 18.34s/it]

 31%|███▏      | 5069/16104 [23:34:13<53:32:13, 17.47s/it]
{'loss': 0.4873, 'learning_rate': 1.6040970251015846e-06, 'rewards/chosen': -0.975197434425354, 'rewards/rejected': -1.6106737852096558, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6354765295982361, 'policy_logps/rejected': -269.14044189453125, 'policy_logps/chosen': -351.8430480957031, 'referece_logps/rejected': -253.03369140625, 'referece_logps/chosen': -342.091064453125, 'logits/rejected': -0.409368634223938, 'logits/chosen': -0.4139404892921448, 'epoch': 1.89}

 31%|███▏      | 5070/16104 [23:34:30<52:52:12, 17.25s/it]


 31%|███▏      | 5072/16104 [23:35:01<49:54:16, 16.29s/it]
{'loss': 0.5964, 'learning_rate': 1.603616076041301e-06, 'rewards/chosen': -1.285430908203125, 'rewards/rejected': -1.2637890577316284, 'rewards/accuracies': 0.75, 'rewards/margins': -0.021641805768013, 'policy_logps/rejected': -369.27447509765625, 'policy_logps/chosen': -496.10186767578125, 'referece_logps/rejected': -356.63653564453125, 'referece_logps/chosen': -483.24755859375, 'logits/rejected': -0.30128899216651917, 'logits/chosen': 0.023274242877960205, 'epoch': 1.89}


 32%|███▏      | 5074/16104 [23:35:33<49:31:47, 16.17s/it]

 32%|███▏      | 5075/16104 [23:35:53<52:46:55, 17.23s/it]

 32%|███▏      | 5076/16104 [23:36:15<57:02:22, 18.62s/it]
{'loss': 0.6012, 'learning_rate': 1.6029744688150097e-06, 'rewards/chosen': -0.5344907641410828, 'rewards/rejected': -2.0822761058807373, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5477852821350098, 'policy_logps/rejected': -383.5306396484375, 'policy_logps/chosen': -411.7267761230469, 'referece_logps/rejected': -362.7078857421875, 'referece_logps/chosen': -406.3818664550781, 'logits/rejected': -0.01867186650633812, 'logits/chosen': -0.013110671192407608, 'epoch': 1.89}


 32%|███▏      | 5078/16104 [23:36:55<59:32:19, 19.44s/it]
{'loss': 0.5189, 'learning_rate': 1.602653518827548e-06, 'rewards/chosen': -0.43233853578567505, 'rewards/rejected': -1.3097589015960693, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8774203658103943, 'policy_logps/rejected': -358.0589904785156, 'policy_logps/chosen': -324.0096435546875, 'referece_logps/rejected': -344.96142578125, 'referece_logps/chosen': -319.686279296875, 'logits/rejected': -0.8756217360496521, 'logits/chosen': -0.7409977912902832, 'epoch': 1.89}

 32%|███▏      | 5079/16104 [23:37:15<59:50:24, 19.54s/it]

 32%|███▏      | 5080/16104 [23:37:36<61:28:54, 20.08s/it]

 32%|███▏      | 5081/16104 [23:37:53<58:15:16, 19.03s/it]


 32%|███▏      | 5083/16104 [23:38:30<57:35:17, 18.81s/it]
{'loss': 0.4897, 'learning_rate': 1.6018507173503584e-06, 'rewards/chosen': -1.1179295778274536, 'rewards/rejected': -2.339085578918457, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2211557626724243, 'policy_logps/rejected': -460.0058898925781, 'policy_logps/chosen': -351.27899169921875, 'referece_logps/rejected': -436.6150207519531, 'referece_logps/chosen': -340.0997009277344, 'logits/rejected': -0.47543495893478394, 'logits/chosen': -0.38653290271759033, 'epoch': 1.89}


 32%|███▏      | 5085/16104 [23:39:03<53:40:59, 17.54s/it]

 32%|███▏      | 5086/16104 [23:39:15<48:50:29, 15.96s/it]
{'loss': 0.4937, 'learning_rate': 1.6013687442608569e-06, 'rewards/chosen': -0.6512807011604309, 'rewards/rejected': -2.191897392272949, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5406169891357422, 'policy_logps/rejected': -366.7136535644531, 'policy_logps/chosen': -391.1671142578125, 'referece_logps/rejected': -344.7947082519531, 'referece_logps/chosen': -384.654296875, 'logits/rejected': -0.3262096643447876, 'logits/chosen': -0.46070969104766846, 'epoch': 1.89}


 32%|███▏      | 5088/16104 [23:39:57<56:58:01, 18.62s/it]
{'loss': 0.518, 'learning_rate': 1.6010473072248298e-06, 'rewards/chosen': -1.1399469375610352, 'rewards/rejected': -1.1445446014404297, 'rewards/accuracies': 0.375, 'rewards/margins': 0.004597663879394531, 'policy_logps/rejected': -420.94232177734375, 'policy_logps/chosen': -388.272216796875, 'referece_logps/rejected': -409.496826171875, 'referece_logps/chosen': -376.8727722167969, 'logits/rejected': -0.6534467935562134, 'logits/chosen': -0.5285772085189819, 'epoch': 1.9}

 32%|███▏      | 5089/16104 [23:40:08<49:41:56, 16.24s/it]

 32%|███▏      | 5090/16104 [23:40:26<51:32:27, 16.85s/it]


 32%|███▏      | 5092/16104 [23:40:55<49:05:27, 16.05s/it]

 32%|███▏      | 5093/16104 [23:41:09<47:25:42, 15.51s/it]
{'loss': 0.5955, 'learning_rate': 1.6002432892634471e-06, 'rewards/chosen': -0.8801714181900024, 'rewards/rejected': -1.4407535791397095, 'rewards/accuracies': 0.75, 'rewards/margins': 0.560582160949707, 'policy_logps/rejected': -317.3758850097656, 'policy_logps/chosen': -381.8562316894531, 'referece_logps/rejected': -302.9683837890625, 'referece_logps/chosen': -373.0545654296875, 'logits/rejected': -0.7879306674003601, 'logits/chosen': -0.8105736970901489, 'epoch': 1.9}


 32%|███▏      | 5095/16104 [23:41:49<54:28:06, 17.81s/it]

 32%|███▏      | 5096/16104 [23:42:02<49:40:33, 16.25s/it]

 32%|███▏      | 5097/16104 [23:42:14<45:33:23, 14.90s/it]

 32%|███▏      | 5098/16104 [23:42:33<49:55:50, 16.33s/it]
{'loss': 0.4641, 'learning_rate': 1.5994386642793095e-06, 'rewards/chosen': -0.5041468739509583, 'rewards/rejected': -1.1006914377212524, 'rewards/accuracies': 0.875, 'rewards/margins': 0.596544623374939, 'policy_logps/rejected': -353.3646240234375, 'policy_logps/chosen': -539.6447143554688, 'referece_logps/rejected': -342.35772705078125, 'referece_logps/chosen': -534.6032104492188, 'logits/rejected': -1.0702965259552002, 'logits/chosen': -1.185760259628296, 'epoch': 1.9}

 32%|███▏      | 5099/16104 [23:42:46<46:52:11, 15.33s/it]


 32%|███▏      | 5101/16104 [23:43:15<46:01:11, 15.06s/it]
{'loss': 0.4398, 'learning_rate': 1.5989555982563826e-06, 'rewards/chosen': -0.6177162528038025, 'rewards/rejected': -1.6211591958999634, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0034430027008057, 'policy_logps/rejected': -435.16107177734375, 'policy_logps/chosen': -393.32672119140625, 'referece_logps/rejected': -418.949462890625, 'referece_logps/chosen': -387.1495361328125, 'logits/rejected': 0.08437143266201019, 'logits/chosen': 0.016932684928178787, 'epoch': 1.9}

 32%|███▏      | 5102/16104 [23:43:33<48:23:09, 15.83s/it]


 32%|███▏      | 5104/16104 [23:44:15<56:42:57, 18.56s/it]
{'loss': 0.4999, 'learning_rate': 1.5984723141740574e-06, 'rewards/chosen': -1.192861557006836, 'rewards/rejected': -1.9850695133209229, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7922079563140869, 'policy_logps/rejected': -442.890380859375, 'policy_logps/chosen': -416.1128845214844, 'referece_logps/rejected': -423.0397033691406, 'referece_logps/chosen': -404.1842956542969, 'logits/rejected': -0.3712259829044342, 'logits/chosen': -0.31624898314476013, 'epoch': 1.9}

 32%|███▏      | 5105/16104 [23:44:35<57:46:07, 18.91s/it]

 32%|███▏      | 5106/16104 [23:44:51<54:49:41, 17.95s/it]

 32%|███▏      | 5107/16104 [23:45:10<56:20:09, 18.44s/it]

 32%|███▏      | 5108/16104 [23:45:25<52:49:09, 17.29s/it]


 32%|███▏      | 5110/16104 [23:46:06<57:12:51, 18.73s/it]

 32%|███▏      | 5111/16104 [23:46:24<56:21:12, 18.45s/it]

 32%|███▏      | 5112/16104 [23:46:43<57:38:51, 18.88s/it]
{'loss': 0.4863, 'learning_rate': 1.5971824918913358e-06, 'rewards/chosen': -0.6921215057373047, 'rewards/rejected': -1.5923222303390503, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9002007246017456, 'policy_logps/rejected': -397.5611267089844, 'policy_logps/chosen': -406.31121826171875, 'referece_logps/rejected': -381.63787841796875, 'referece_logps/chosen': -399.3900146484375, 'logits/rejected': -0.2813957631587982, 'logits/chosen': -0.2509702146053314, 'epoch': 1.9}


 32%|███▏      | 5114/16104 [23:47:12<49:31:43, 16.22s/it]
{'loss': 0.5074, 'learning_rate': 1.5968597946192048e-06, 'rewards/chosen': -1.2698684930801392, 'rewards/rejected': -1.4382009506225586, 'rewards/accuracies': 0.5, 'rewards/margins': 0.16833248734474182, 'policy_logps/rejected': -362.987548828125, 'policy_logps/chosen': -394.2471923828125, 'referece_logps/rejected': -348.6055908203125, 'referece_logps/chosen': -381.5484924316406, 'logits/rejected': -1.392429232597351, 'logits/chosen': -0.9186177253723145, 'epoch': 1.91}

 32%|███▏      | 5115/16104 [23:47:25<46:21:24, 15.19s/it]

 32%|███▏      | 5116/16104 [23:47:45<50:52:04, 16.67s/it]


 32%|███▏      | 5118/16104 [23:48:24<55:06:55, 18.06s/it]
{'loss': 0.4941, 'learning_rate': 1.5962141103986512e-06, 'rewards/chosen': -0.9678560495376587, 'rewards/rejected': -1.4013164043426514, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4334602952003479, 'policy_logps/rejected': -369.81805419921875, 'policy_logps/chosen': -453.0941467285156, 'referece_logps/rejected': -355.80487060546875, 'referece_logps/chosen': -443.41558837890625, 'logits/rejected': -0.667019248008728, 'logits/chosen': -0.6869626641273499, 'epoch': 1.91}

 32%|███▏      | 5119/16104 [23:48:45<57:17:42, 18.78s/it]

 32%|███▏      | 5120/16104 [23:49:03<56:45:23, 18.60s/it]

 32%|███▏      | 5121/16104 [23:49:18<53:17:29, 17.47s/it]

 32%|███▏      | 5122/16104 [23:49:31<49:18:07, 16.16s/it]

 32%|███▏      | 5123/16104 [23:49:43<45:33:38, 14.94s/it]

 32%|███▏      | 5124/16104 [23:50:02<48:57:13, 16.05s/it]


 32%|███▏      | 5126/16104 [23:50:36<51:32:10, 16.90s/it]
{'loss': 0.5857, 'learning_rate': 1.5949215847153715e-06, 'rewards/chosen': -1.469592809677124, 'rewards/rejected': -1.3571527004241943, 'rewards/accuracies': 0.5, 'rewards/margins': -0.1124400794506073, 'policy_logps/rejected': -370.3220520019531, 'policy_logps/chosen': -346.973876953125, 'referece_logps/rejected': -356.7505187988281, 'referece_logps/chosen': -332.2779235839844, 'logits/rejected': -0.2981604337692261, 'logits/chosen': -0.28632086515426636, 'epoch': 1.91}


 32%|███▏      | 5128/16104 [23:51:12<53:17:17, 17.48s/it]
{'loss': 0.582, 'learning_rate': 1.5945982125074054e-06, 'rewards/chosen': -1.1514536142349243, 'rewards/rejected': -1.0617989301681519, 'rewards/accuracies': 0.375, 'rewards/margins': -0.08965466171503067, 'policy_logps/rejected': -420.31512451171875, 'policy_logps/chosen': -373.6119689941406, 'referece_logps/rejected': -409.6971435546875, 'referece_logps/chosen': -362.0974426269531, 'logits/rejected': -1.7823920249938965, 'logits/chosen': -1.581000566482544, 'epoch': 1.91}

 32%|███▏      | 5129/16104 [23:51:27<50:37:27, 16.61s/it]

 32%|███▏      | 5130/16104 [23:51:47<53:31:01, 17.56s/it]

 32%|███▏      | 5131/16104 [23:52:00<49:26:02, 16.22s/it]

 32%|███▏      | 5132/16104 [23:52:19<52:35:39, 17.26s/it]


 32%|███▏      | 5134/16104 [23:52:57<54:57:52, 18.04s/it]

 32%|███▏      | 5135/16104 [23:53:13<53:08:31, 17.44s/it]
{'loss': 0.5419, 'learning_rate': 1.593465652467447e-06, 'rewards/chosen': -0.7755632400512695, 'rewards/rejected': -0.9003590941429138, 'rewards/accuracies': 0.625, 'rewards/margins': 0.12479591369628906, 'policy_logps/rejected': -381.1239013671875, 'policy_logps/chosen': -308.0960693359375, 'referece_logps/rejected': -372.12030029296875, 'referece_logps/chosen': -300.3404541015625, 'logits/rejected': -0.28385689854621887, 'logits/chosen': -0.10012534260749817, 'epoch': 1.91}

 32%|███▏      | 5136/16104 [23:53:33<55:39:47, 18.27s/it]

 32%|███▏      | 5137/16104 [23:53:50<54:41:50, 17.95s/it]

 32%|███▏      | 5138/16104 [23:54:09<55:52:51, 18.35s/it]

 32%|███▏      | 5139/16104 [23:54:27<55:05:00, 18.08s/it]

 32%|███▏      | 5140/16104 [23:54:46<55:46:11, 18.31s/it]


 32%|███▏      | 5142/16104 [23:55:21<54:18:53, 17.84s/it]
{'loss': 0.4848, 'learning_rate': 1.5923319160971898e-06, 'rewards/chosen': -0.19810494780540466, 'rewards/rejected': -2.0176873207092285, 'rewards/accuracies': 0.75, 'rewards/margins': 1.819582223892212, 'policy_logps/rejected': -335.2200927734375, 'policy_logps/chosen': -368.8226623535156, 'referece_logps/rejected': -315.0432434082031, 'referece_logps/chosen': -366.84161376953125, 'logits/rejected': -0.3120063543319702, 'logits/chosen': -0.3146546185016632, 'epoch': 1.92}

 32%|███▏      | 5143/16104 [23:55:36<52:07:37, 17.12s/it]

 32%|███▏      | 5144/16104 [23:55:50<49:28:10, 16.25s/it]

 32%|███▏      | 5145/16104 [23:56:07<50:14:58, 16.51s/it]


 32%|███▏      | 5147/16104 [23:56:33<44:28:22, 14.61s/it]
{'loss': 0.5761, 'learning_rate': 1.5915213854466495e-06, 'rewards/chosen': -0.7420104742050171, 'rewards/rejected': -0.9627214670181274, 'rewards/accuracies': 0.375, 'rewards/margins': 0.22071093320846558, 'policy_logps/rejected': -337.2388916015625, 'policy_logps/chosen': -366.3189392089844, 'referece_logps/rejected': -327.6116943359375, 'referece_logps/chosen': -358.8988037109375, 'logits/rejected': 0.42927974462509155, 'logits/chosen': 0.395929753780365, 'epoch': 1.92}


 32%|███▏      | 5149/16104 [23:57:09<49:24:56, 16.24s/it]
{'loss': 0.647, 'learning_rate': 1.5911970056438549e-06, 'rewards/chosen': -0.4795543849468231, 'rewards/rejected': -2.028827667236328, 'rewards/accuracies': 1.0, 'rewards/margins': 1.549273133277893, 'policy_logps/rejected': -482.15118408203125, 'policy_logps/chosen': -366.1635437011719, 'referece_logps/rejected': -461.8628845214844, 'referece_logps/chosen': -361.36798095703125, 'logits/rejected': 0.28076308965682983, 'logits/chosen': 0.2140636146068573, 'epoch': 1.92}

 32%|███▏      | 5150/16104 [23:57:23<47:35:45, 15.64s/it]

 32%|███▏      | 5151/16104 [23:57:35<44:14:07, 14.54s/it]

 32%|███▏      | 5152/16104 [23:57:54<48:13:11, 15.85s/it]

 32%|███▏      | 5153/16104 [23:58:06<44:55:42, 14.77s/it]

 32%|███▏      | 5154/16104 [23:58:22<45:46:25, 15.05s/it]

 32%|███▏      | 5155/16104 [23:58:43<51:31:14, 16.94s/it]


 32%|███▏      | 5157/16104 [23:59:19<53:22:41, 17.55s/it]
{'loss': 0.4778, 'learning_rate': 1.5898985303588334e-06, 'rewards/chosen': -0.6993638873100281, 'rewards/rejected': -1.7442655563354492, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0449016094207764, 'policy_logps/rejected': -493.3147888183594, 'policy_logps/chosen': -440.0910339355469, 'referece_logps/rejected': -475.8721008300781, 'referece_logps/chosen': -433.097412109375, 'logits/rejected': -0.6970187425613403, 'logits/chosen': -0.594529926776886, 'epoch': 1.92}

 32%|███▏      | 5158/16104 [23:59:30<47:27:24, 15.61s/it]

 32%|███▏      | 5159/16104 [23:59:46<47:51:30, 15.74s/it]

 32%|███▏      | 5160/16104 [24:00:06<51:20:45, 16.89s/it]

 32%|███▏      | 5161/16104 [24:00:23<52:07:58, 17.15s/it]

 32%|███▏      | 5162/16104 [24:00:42<53:20:41, 17.55s/it]

 32%|███▏      | 5163/16104 [24:00:58<52:16:24, 17.20s/it]

 32%|███▏      | 5164/16104 [24:01:12<49:03:50, 16.15s/it]

 32%|███▏      | 5165/16104 [24:01:33<53:46:42, 17.70s/it]

 32%|███▏      | 5166/16104 [24:01:50<52:46:23, 17.37s/it]


 32%|███▏      | 5168/16104 [24:02:17<46:19:31, 15.25s/it]
{'loss': 0.5062, 'learning_rate': 1.5881106339034166e-06, 'rewards/chosen': -0.51019686460495, 'rewards/rejected': -1.378975510597229, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8687787055969238, 'policy_logps/rejected': -406.5431213378906, 'policy_logps/chosen': -520.1546020507812, 'referece_logps/rejected': -392.7533874511719, 'referece_logps/chosen': -515.0526733398438, 'logits/rejected': -1.0438812971115112, 'logits/chosen': -1.0938433408737183, 'epoch': 1.93}

 32%|███▏      | 5169/16104 [24:02:39<52:40:03, 17.34s/it]

 32%|███▏      | 5170/16104 [24:02:55<50:50:09, 16.74s/it]

 32%|███▏      | 5171/16104 [24:03:12<51:29:19, 16.95s/it]

 32%|███▏      | 5172/16104 [24:03:27<49:38:02, 16.34s/it]

 32%|███▏      | 5173/16104 [24:03:42<48:04:05, 15.83s/it]


 32%|███▏      | 5175/16104 [24:04:19<53:25:40, 17.60s/it]

 32%|███▏      | 5176/16104 [24:04:37<53:36:57, 17.66s/it]

 32%|███▏      | 5177/16104 [24:04:57<55:32:24, 18.30s/it]

 32%|███▏      | 5178/16104 [24:05:16<56:37:51, 18.66s/it]

 32%|███▏      | 5179/16104 [24:05:36<57:34:42, 18.97s/it]

 32%|███▏      | 5180/16104 [24:05:54<56:22:58, 18.58s/it]

 32%|███▏      | 5181/16104 [24:06:13<57:21:16, 18.90s/it]

 32%|███▏      | 5182/16104 [24:06:24<50:09:37, 16.53s/it]

 32%|███▏      | 5183/16104 [24:06:41<49:57:47, 16.47s/it]


 32%|███▏      | 5184/16104 [24:07:02<53:55:22, 17.78s/it]

 32%|███▏      | 5185/16104 [24:07:14<48:54:19, 16.12s/it]

 32%|███▏      | 5186/16104 [24:07:27<45:55:23, 15.14s/it]

 32%|███▏      | 5187/16104 [24:07:37<41:48:48, 13.79s/it]

 32%|███▏      | 5188/16104 [24:07:56<46:44:28, 15.41s/it]

 32%|███▏      | 5189/16104 [24:08:12<46:41:46, 15.40s/it]

 32%|███▏      | 5190/16104 [24:08:32<50:35:58, 16.69s/it]

 32%|███▏      | 5191/16104 [24:08:42<45:15:45, 14.93s/it]

 32%|███▏      | 5192/16104 [24:08:54<42:32:37, 14.04s/it]

 32%|███▏      | 5193/16104 [24:09:11<44:45:16, 14.77s/it]

 32%|███▏      | 5194/16104 [24:09:21<40:59:22, 13.53s/it]

 32%|███▏      | 5195/16104 [24:09:32<38:22:53, 12.67s/it]

 32%|███▏      | 5196/16104 [24:09:44<38:04:47, 12.57s/it]

 32%|███▏      | 5197/16104 [24:10:00<41:08:00, 13.58s/it]

 32%|███▏      | 5198/16104 [24:10:12<39:32:36, 13.05s/it]

 32%|███▏      | 5199/16104 [24:10:30<44:02:28, 14.54s/it]

 32%|███▏      | 5200/16104 [24:10:44<43:39:15, 14.41s/it]

 32%|███▏      | 5201/16104 [24:11:04<48:17:10, 15.94s/it]

 32%|███▏      | 5202/16104 [24:11:23<51:31:05, 17.01s/it]

 32%|███▏      | 5203/16104 [24:11:41<51:52:06, 17.13s/it]

 32%|███▏      | 5204/16104 [24:12:00<53:42:32, 17.74s/it]

 32%|███▏      | 5205/16104 [24:12:19<55:14:47, 18.25s/it]

 32%|███▏      | 5206/16104 [24:12:33<51:01:33, 16.86s/it]

 32%|███▏      | 5207/16104 [24:12:44<45:23:04, 14.99s/it]

 32%|███▏      | 5208/16104 [24:13:03<49:35:13, 16.38s/it]

 32%|███▏      | 5209/16104 [24:13:14<44:27:16, 14.69s/it]

 32%|███▏      | 5210/16104 [24:13:31<46:56:36, 15.51s/it]

 32%|███▏      | 5211/16104 [24:13:50<49:42:19, 16.43s/it]

 32%|███▏      | 5212/16104 [24:14:08<50:47:23, 16.79s/it]

 32%|███▏      | 5213/16104 [24:14:19<46:19:01, 15.31s/it]

 32%|███▏      | 5214/16104 [24:14:38<49:42:09, 16.43s/it]

 32%|███▏      | 5215/16104 [24:14:50<45:20:03, 14.99s/it]

 32%|███▏      | 5216/16104 [24:15:03<43:47:06, 14.48s/it]

 32%|███▏      | 5217/16104 [24:15:21<46:16:38, 15.30s/it]

 32%|███▏      | 5218/16104 [24:15:35<45:40:21, 15.10s/it]

 32%|███▏      | 5219/16104 [24:15:50<45:11:10, 14.94s/it]

 32%|███▏      | 5220/16104 [24:16:02<42:31:00, 14.06s/it]

 32%|███▏      | 5221/16104 [24:16:16<43:02:40, 14.24s/it]

 32%|███▏      | 5222/16104 [24:16:35<47:20:08, 15.66s/it]

 32%|███▏      | 5223/16104 [24:16:57<52:28:36, 17.36s/it]

 32%|███▏      | 5224/16104 [24:17:15<52:55:52, 17.51s/it]

 32%|███▏      | 5225/16104 [24:17:34<54:51:57, 18.16s/it]

 32%|███▏      | 5226/16104 [24:17:46<49:25:41, 16.36s/it]

 32%|███▏      | 5227/16104 [24:18:01<47:56:55, 15.87s/it]

 32%|███▏      | 5228/16104 [24:18:12<43:21:21, 14.35s/it]

 32%|███▏      | 5229/16104 [24:18:23<40:30:13, 13.41s/it]

 32%|███▏      | 5230/16104 [24:18:41<44:21:18, 14.68s/it]

 32%|███▏      | 5231/16104 [24:19:02<49:47:34, 16.49s/it]

 32%|███▏      | 5232/16104 [24:19:18<49:26:35, 16.37s/it]

 32%|███▏      | 5233/16104 [24:19:39<54:21:19, 18.00s/it]

 33%|███▎      | 5234/16104 [24:19:56<53:04:59, 17.58s/it]

 33%|███▎      | 5235/16104 [24:20:09<48:27:01, 16.05s/it]

 33%|███▎      | 5236/16104 [24:20:19<43:40:42, 14.47s/it]

 33%|███▎      | 5237/16104 [24:20:32<42:04:48, 13.94s/it]

 33%|███▎      | 5238/16104 [24:20:44<40:34:38, 13.44s/it]

 33%|███▎      | 5239/16104 [24:21:03<45:27:04, 15.06s/it]

 33%|███▎      | 5240/16104 [24:21:17<44:01:45, 14.59s/it]

 33%|███▎      | 5241/16104 [24:21:33<45:30:24, 15.08s/it]
{'loss': 0.5615, 'learning_rate': 1.5761729804427529e-06, 'rewards/chosen': -2.0562260150909424, 'rewards/rejected': -2.746474027633667, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6902478933334351, 'policy_logps/rejected': -358.256591796875, 'policy_logps/chosen': -479.4646301269531, 'referece_logps/rejected': -330.7918395996094, 'referece_logps/chosen': -458.9023742675781, 'logits/rejected': -0.19669578969478607, 'logits/chosen': -0.2706732153892517, 'epoch': 1.95}

 33%|███▎      | 5242/16104 [24:21:53<49:53:45, 16.54s/it]


 33%|███▎      | 5244/16104 [24:22:24<49:49:06, 16.51s/it]

 33%|███▎      | 5245/16104 [24:22:44<52:39:54, 17.46s/it]

 33%|███▎      | 5246/16104 [24:23:02<53:29:31, 17.74s/it]

 33%|███▎      | 5247/16104 [24:23:20<53:16:54, 17.67s/it]

 33%|███▎      | 5248/16104 [24:23:33<49:03:04, 16.27s/it]
{'loss': 0.4453, 'learning_rate': 1.5750217070687302e-06, 'rewards/chosen': -1.4370458126068115, 'rewards/rejected': -2.0734786987304688, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6364327669143677, 'policy_logps/rejected': -492.01446533203125, 'policy_logps/chosen': -428.5093994140625, 'referece_logps/rejected': -471.2796325683594, 'referece_logps/chosen': -414.138916015625, 'logits/rejected': 0.37161409854888916, 'logits/chosen': 0.5407298803329468, 'epoch': 1.96}


 33%|███▎      | 5250/16104 [24:24:15<56:21:03, 18.69s/it]

 33%|███▎      | 5251/16104 [24:24:36<58:23:14, 19.37s/it]
{'loss': 0.5087, 'learning_rate': 1.574527955151253e-06, 'rewards/chosen': -1.3900879621505737, 'rewards/rejected': -2.1162564754486084, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7261682748794556, 'policy_logps/rejected': -420.37579345703125, 'policy_logps/chosen': -356.64031982421875, 'referece_logps/rejected': -399.21319580078125, 'referece_logps/chosen': -342.73944091796875, 'logits/rejected': 0.5440425276756287, 'logits/chosen': 0.4771711826324463, 'epoch': 1.96}


 33%|███▎      | 5253/16104 [24:25:06<51:33:38, 17.11s/it]

 33%|███▎      | 5254/16104 [24:25:28<56:11:44, 18.65s/it]

 33%|███▎      | 5255/16104 [24:25:46<55:16:12, 18.34s/it]

 33%|███▎      | 5256/16104 [24:26:09<59:00:40, 19.58s/it]

 33%|███▎      | 5257/16104 [24:26:29<59:32:07, 19.76s/it]

 33%|███▎      | 5258/16104 [24:26:48<58:55:50, 19.56s/it]

 33%|███▎      | 5259/16104 [24:27:04<55:48:22, 18.52s/it]

 33%|███▎      | 5260/16104 [24:27:22<55:25:20, 18.40s/it]

 33%|███▎      | 5261/16104 [24:27:34<49:33:35, 16.45s/it]

 33%|███▎      | 5262/16104 [24:27:51<49:40:25, 16.49s/it]

 33%|███▎      | 5263/16104 [24:28:12<53:55:18, 17.91s/it]

 33%|███▎      | 5264/16104 [24:28:32<55:45:00, 18.51s/it]

 33%|███▎      | 5265/16104 [24:28:53<58:43:52, 19.51s/it]

 33%|███▎      | 5266/16104 [24:29:08<54:29:33, 18.10s/it]

 33%|███▎      | 5267/16104 [24:29:20<48:37:01, 16.15s/it]
{'loss': 0.6676, 'learning_rate': 1.5718910833965718e-06, 'rewards/chosen': -0.7483436465263367, 'rewards/rejected': -1.5750004053115845, 'rewards/accuracies': 0.375, 'rewards/margins': 0.8266568183898926, 'policy_logps/rejected': -274.6866455078125, 'policy_logps/chosen': -418.2760009765625, 'referece_logps/rejected': -258.9366455078125, 'referece_logps/chosen': -410.7925720214844, 'logits/rejected': -0.39996346831321716, 'logits/chosen': -0.3902357220649719, 'epoch': 1.96}


 33%|███▎      | 5269/16104 [24:29:46<43:35:34, 14.48s/it]

 33%|███▎      | 5270/16104 [24:29:59<42:27:11, 14.11s/it]

 33%|███▎      | 5271/16104 [24:30:17<45:57:53, 15.27s/it]

 33%|███▎      | 5272/16104 [24:30:28<41:53:36, 13.92s/it]

 33%|███▎      | 5273/16104 [24:30:41<41:05:14, 13.66s/it]

 33%|███▎      | 5274/16104 [24:30:56<42:11:56, 14.03s/it]

 33%|███▎      | 5275/16104 [24:31:12<44:03:14, 14.65s/it]

 33%|███▎      | 5276/16104 [24:31:30<46:53:11, 15.59s/it]
{'loss': 0.5236, 'learning_rate': 1.5704052387076179e-06, 'rewards/chosen': -1.137215495109558, 'rewards/rejected': -2.699326992034912, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5621116161346436, 'policy_logps/rejected': -307.0496826171875, 'policy_logps/chosen': -373.7912902832031, 'referece_logps/rejected': -280.056396484375, 'referece_logps/chosen': -362.41912841796875, 'logits/rejected': -0.2790263295173645, 'logits/chosen': -0.22288230061531067, 'epoch': 1.97}


 33%|███▎      | 5278/16104 [24:32:11<54:06:56, 18.00s/it]

 33%|███▎      | 5279/16104 [24:32:27<52:47:24, 17.56s/it]

 33%|███▎      | 5280/16104 [24:32:48<55:24:24, 18.43s/it]

 33%|███▎      | 5281/16104 [24:33:01<50:50:07, 16.91s/it]

 33%|███▎      | 5282/16104 [24:33:17<49:55:39, 16.61s/it]

 33%|███▎      | 5283/16104 [24:33:29<45:40:46, 15.20s/it]

 33%|███▎      | 5284/16104 [24:33:45<46:31:29, 15.48s/it]

 33%|███▎      | 5285/16104 [24:34:02<48:18:31, 16.07s/it]

 33%|███▎      | 5286/16104 [24:34:21<50:29:32, 16.80s/it]

 33%|███▎      | 5287/16104 [24:34:41<53:09:45, 17.69s/it]

 33%|███▎      | 5288/16104 [24:34:58<52:59:22, 17.64s/it]

 33%|███▎      | 5289/16104 [24:35:18<54:41:01, 18.20s/it]
{'loss': 0.5696, 'learning_rate': 1.5682557203078573e-06, 'rewards/chosen': -1.1859968900680542, 'rewards/rejected': -1.5314923524856567, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3454955220222473, 'policy_logps/rejected': -505.6827087402344, 'policy_logps/chosen': -504.5452880859375, 'referece_logps/rejected': -490.3677978515625, 'referece_logps/chosen': -492.685302734375, 'logits/rejected': 0.05349378287792206, 'logits/chosen': 0.10335828363895416, 'epoch': 1.97}


 33%|███▎      | 5291/16104 [24:35:48<50:04:09, 16.67s/it]

 33%|███▎      | 5292/16104 [24:36:06<51:17:26, 17.08s/it]

 33%|███▎      | 5293/16104 [24:36:19<47:11:55, 15.72s/it]

 33%|███▎      | 5294/16104 [24:36:30<43:04:29, 14.34s/it]

 33%|███▎      | 5295/16104 [24:36:47<45:33:04, 15.17s/it]
{'loss': 0.565, 'learning_rate': 1.5672623237461488e-06, 'rewards/chosen': -0.63480544090271, 'rewards/rejected': -1.2478878498077393, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6130824089050293, 'policy_logps/rejected': -426.46258544921875, 'policy_logps/chosen': -572.29443359375, 'referece_logps/rejected': -413.98370361328125, 'referece_logps/chosen': -565.9463500976562, 'logits/rejected': -0.4714965522289276, 'logits/chosen': -0.5739021897315979, 'epoch': 1.97}


 33%|███▎      | 5297/16104 [24:37:23<50:02:01, 16.67s/it]

 33%|███▎      | 5298/16104 [24:37:36<47:08:48, 15.71s/it]

 33%|███▎      | 5299/16104 [24:37:53<47:42:23, 15.89s/it]

 33%|███▎      | 5300/16104 [24:38:04<43:59:18, 14.66s/it]

 33%|███▎      | 5301/16104 [24:38:19<43:40:16, 14.55s/it]

 33%|███▎      | 5302/16104 [24:38:41<50:22:47, 16.79s/it]

 33%|███▎      | 5303/16104 [24:38:59<51:52:02, 17.29s/it]

 33%|███▎      | 5304/16104 [24:39:19<53:55:30, 17.98s/it]
{'loss': 0.4916, 'learning_rate': 1.5657706804489792e-06, 'rewards/chosen': -1.5340481996536255, 'rewards/rejected': -2.2844161987304688, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7503678202629089, 'policy_logps/rejected': -389.3828430175781, 'policy_logps/chosen': -455.8215026855469, 'referece_logps/rejected': -366.53863525390625, 'referece_logps/chosen': -440.48101806640625, 'logits/rejected': -1.1229279041290283, 'logits/chosen': -1.2348850965499878, 'epoch': 1.98}


 33%|███▎      | 5306/16104 [24:39:49<50:23:33, 16.80s/it]

 33%|███▎      | 5307/16104 [24:40:01<45:26:26, 15.15s/it]

 33%|███▎      | 5308/16104 [24:40:19<48:14:32, 16.09s/it]

 33%|███▎      | 5309/16104 [24:40:35<48:44:17, 16.25s/it]

 33%|███▎      | 5310/16104 [24:40:51<47:57:12, 15.99s/it]

 33%|███▎      | 5311/16104 [24:41:04<45:47:13, 15.27s/it]

 33%|███▎      | 5312/16104 [24:41:21<47:07:30, 15.72s/it]

 33%|███▎      | 5313/16104 [24:41:39<48:56:45, 16.33s/it]

 33%|███▎      | 5314/16104 [24:41:59<51:54:09, 17.32s/it]
{'loss': 0.5288, 'learning_rate': 1.564111125009582e-06, 'rewards/chosen': -0.8482503294944763, 'rewards/rejected': -1.2986845970153809, 'rewards/accuracies': 0.75, 'rewards/margins': 0.45043423771858215, 'policy_logps/rejected': -324.058349609375, 'policy_logps/chosen': -304.6265869140625, 'referece_logps/rejected': -311.071533203125, 'referece_logps/chosen': -296.14410400390625, 'logits/rejected': -0.517533004283905, 'logits/chosen': -0.6134896278381348, 'epoch': 1.98}

 33%|███▎      | 5315/16104 [24:42:14<50:03:29, 16.70s/it]


 33%|███▎      | 5317/16104 [24:42:46<48:48:33, 16.29s/it]
{'loss': 0.4698, 'learning_rate': 1.5636128130958369e-06, 'rewards/chosen': -0.6302171349525452, 'rewards/rejected': -0.6794988512992859, 'rewards/accuracies': 0.875, 'rewards/margins': 0.04928167909383774, 'policy_logps/rejected': -339.8530578613281, 'policy_logps/chosen': -336.03631591796875, 'referece_logps/rejected': -333.05810546875, 'referece_logps/chosen': -329.734130859375, 'logits/rejected': -0.875026524066925, 'logits/chosen': -1.043441891670227, 'epoch': 1.98}


 33%|███▎      | 5319/16104 [24:43:23<51:08:14, 17.07s/it]
{'loss': 0.5539, 'learning_rate': 1.5632804911464213e-06, 'rewards/chosen': -0.43397924304008484, 'rewards/rejected': -1.722091794013977, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2881124019622803, 'policy_logps/rejected': -338.62811279296875, 'policy_logps/chosen': -389.39703369140625, 'referece_logps/rejected': -321.4071960449219, 'referece_logps/chosen': -385.0572814941406, 'logits/rejected': -0.5674967169761658, 'logits/chosen': -0.6213583946228027, 'epoch': 1.98}

 33%|███▎      | 5320/16104 [24:43:42<53:25:55, 17.84s/it]


 33%|███▎      | 5322/16104 [24:44:20<54:04:10, 18.05s/it]
{'loss': 0.4925, 'learning_rate': 1.5627818373463492e-06, 'rewards/chosen': -0.7839381098747253, 'rewards/rejected': -1.5722107887268066, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7882727384567261, 'policy_logps/rejected': -296.75494384765625, 'policy_logps/chosen': -311.03497314453125, 'referece_logps/rejected': -281.0328369140625, 'referece_logps/chosen': -303.1955871582031, 'logits/rejected': -0.7163539528846741, 'logits/chosen': -0.7211548686027527, 'epoch': 1.98}


 33%|███▎      | 5324/16104 [24:44:53<52:43:41, 17.61s/it]

 33%|███▎      | 5325/16104 [24:45:13<54:55:38, 18.34s/it]

 33%|███▎      | 5326/16104 [24:45:28<51:26:30, 17.18s/it]

 33%|███▎      | 5327/16104 [24:45:46<52:02:42, 17.39s/it]

 33%|███▎      | 5328/16104 [24:46:04<52:50:54, 17.66s/it]

 33%|███▎      | 5329/16104 [24:46:23<53:56:50, 18.02s/it]
{'loss': 0.5547, 'learning_rate': 1.5616175153332517e-06, 'rewards/chosen': -1.4045065641403198, 'rewards/rejected': -1.7191624641418457, 'rewards/accuracies': 0.5, 'rewards/margins': 0.31465578079223633, 'policy_logps/rejected': -356.2223205566406, 'policy_logps/chosen': -360.01031494140625, 'referece_logps/rejected': -339.03070068359375, 'referece_logps/chosen': -345.96527099609375, 'logits/rejected': -0.5008571147918701, 'logits/chosen': -0.5452202558517456, 'epoch': 1.99}


 33%|███▎      | 5331/16104 [24:47:05<58:09:36, 19.44s/it]

 33%|███▎      | 5332/16104 [24:47:23<57:30:53, 19.22s/it]
{'loss': 0.5199, 'learning_rate': 1.5611181792737297e-06, 'rewards/chosen': -1.021633267402649, 'rewards/rejected': -1.9018956422805786, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8802624940872192, 'policy_logps/rejected': -555.4058227539062, 'policy_logps/chosen': -380.0674133300781, 'referece_logps/rejected': -536.3869018554688, 'referece_logps/chosen': -369.8511047363281, 'logits/rejected': 0.12847188115119934, 'logits/chosen': 0.30613136291503906, 'epoch': 1.99}


 33%|███▎      | 5334/16104 [24:47:49<47:44:43, 15.96s/it]

 33%|███▎      | 5335/16104 [24:48:03<45:35:48, 15.24s/it]

 33%|███▎      | 5336/16104 [24:48:24<50:55:35, 17.03s/it]

 33%|███▎      | 5337/16104 [24:48:37<47:47:17, 15.98s/it]

 33%|███▎      | 5338/16104 [24:48:57<50:58:32, 17.05s/it]

 33%|███▎      | 5339/16104 [24:49:10<47:01:26, 15.73s/it]
{'loss': 0.508, 'learning_rate': 1.5599522676777708e-06, 'rewards/chosen': -0.9853119850158691, 'rewards/rejected': -2.0238757133483887, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0385637283325195, 'policy_logps/rejected': -459.0823669433594, 'policy_logps/chosen': -453.58306884765625, 'referece_logps/rejected': -438.8436279296875, 'referece_logps/chosen': -443.7299499511719, 'logits/rejected': -0.9631341695785522, 'logits/chosen': -0.9184401035308838, 'epoch': 1.99}


 33%|███▎      | 5341/16104 [24:49:41<46:08:48, 15.44s/it]

 33%|███▎      | 5342/16104 [24:50:02<50:51:08, 17.01s/it]

 33%|███▎      | 5343/16104 [24:50:16<48:15:39, 16.15s/it]

 33%|███▎      | 5344/16104 [24:50:27<44:12:19, 14.79s/it]
{'loss': 0.5757, 'learning_rate': 1.5591187940138746e-06, 'rewards/chosen': -1.181699275970459, 'rewards/rejected': -1.5339748859405518, 'rewards/accuracies': 0.625, 'rewards/margins': 0.35227566957473755, 'policy_logps/rejected': -411.9298095703125, 'policy_logps/chosen': -459.40447998046875, 'referece_logps/rejected': -396.59002685546875, 'referece_logps/chosen': -447.5875244140625, 'logits/rejected': -0.8510152101516724, 'logits/chosen': -0.9317821264266968, 'epoch': 1.99}

 33%|███▎      | 5345/16104 [24:50:49<49:59:31, 16.73s/it]


 33%|███▎      | 5347/16104 [24:51:23<51:24:22, 17.20s/it]

 33%|███▎      | 5348/16104 [24:51:42<52:27:11, 17.56s/it]

 33%|███▎      | 5349/16104 [24:51:56<49:30:16, 16.57s/it]
{'loss': 0.4708, 'learning_rate': 1.5582847549162001e-06, 'rewards/chosen': -1.3152339458465576, 'rewards/rejected': -1.9894896745681763, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6742558479309082, 'policy_logps/rejected': -267.293701171875, 'policy_logps/chosen': -242.09625244140625, 'referece_logps/rejected': -247.39878845214844, 'referece_logps/chosen': -228.94390869140625, 'logits/rejected': -0.5203313231468201, 'logits/chosen': -0.5351342558860779, 'epoch': 1.99}


 33%|███▎      | 5351/16104 [24:52:26<47:26:08, 15.88s/it]
{'loss': 0.5102, 'learning_rate': 1.5579509811445882e-06, 'rewards/chosen': -1.1720352172851562, 'rewards/rejected': -2.372343063354492, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2003077268600464, 'policy_logps/rejected': -427.53729248046875, 'policy_logps/chosen': -397.4689636230469, 'referece_logps/rejected': -403.8138427734375, 'referece_logps/chosen': -385.74859619140625, 'logits/rejected': -0.3295663595199585, 'logits/chosen': -0.2807307243347168, 'epoch': 1.99}

 33%|███▎      | 5352/16104 [24:52:37<43:06:16, 14.43s/it]


 33%|███▎      | 5354/16104 [24:53:02<40:30:15, 13.56s/it]

 33%|███▎      | 5355/16104 [24:53:22<46:17:30, 15.50s/it]

 33%|███▎      | 5356/16104 [24:53:36<44:40:53, 14.97s/it]
{'loss': 0.4696, 'learning_rate': 1.5571161518567638e-06, 'rewards/chosen': -0.6060894131660461, 'rewards/rejected': -1.699663758277893, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0935742855072021, 'policy_logps/rejected': -289.7252502441406, 'policy_logps/chosen': -356.9285583496094, 'referece_logps/rejected': -272.7286376953125, 'referece_logps/chosen': -350.86767578125, 'logits/rejected': -0.8799295425415039, 'logits/chosen': -1.1088075637817383, 'epoch': 2.0}

 33%|███▎      | 5357/16104 [24:53:55<48:10:31, 16.14s/it]


 33%|███▎      | 5359/16104 [24:54:24<46:08:26, 15.46s/it]
{'loss': 0.4868, 'learning_rate': 1.5566149837939243e-06, 'rewards/chosen': -1.062620997428894, 'rewards/rejected': -1.2279893159866333, 'rewards/accuracies': 0.5, 'rewards/margins': 0.16536845266819, 'policy_logps/rejected': -383.41748046875, 'policy_logps/chosen': -377.3868408203125, 'referece_logps/rejected': -371.1376037597656, 'referece_logps/chosen': -366.7606201171875, 'logits/rejected': -0.1502763032913208, 'logits/chosen': -0.18845660984516144, 'epoch': 2.0}

 33%|███▎      | 5360/16104 [24:54:39<45:21:10, 15.20s/it]

 33%|███▎      | 5361/16104 [24:54:59<49:36:24, 16.62s/it]


 33%|███▎      | 5363/16104 [24:55:22<42:00:53, 14.08s/it]

 33%|███▎      | 5364/16104 [24:55:38<43:13:38, 14.49s/it]
{'loss': 0.511, 'learning_rate': 1.555779253457953e-06, 'rewards/chosen': -0.8819629549980164, 'rewards/rejected': -2.0969338417053223, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2149709463119507, 'policy_logps/rejected': -368.6920166015625, 'policy_logps/chosen': -460.8992919921875, 'referece_logps/rejected': -347.7226867675781, 'referece_logps/chosen': -452.0796813964844, 'logits/rejected': -0.10176438093185425, 'logits/chosen': -0.08768093585968018, 'epoch': 2.0}

 33%|███▎      | 5365/16104 [24:55:55<46:11:20, 15.48s/it]

 33%|███▎      | 5366/16104 [24:56:17<51:20:57, 17.22s/it]


 33%|███▎      | 5368/16104 [24:56:50<51:11:10, 17.16s/it]
{'loss': 0.4988, 'learning_rate': 1.555110264467895e-06, 'rewards/chosen': -1.031054973602295, 'rewards/rejected': -2.4247593879699707, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3937044143676758, 'policy_logps/rejected': -546.1300048828125, 'policy_logps/chosen': -405.61700439453125, 'referece_logps/rejected': -521.8824462890625, 'referece_logps/chosen': -395.3064880371094, 'logits/rejected': -0.5498358011245728, 'logits/chosen': -0.42349496483802795, 'epoch': 2.0}


 33%|███▎      | 5370/16104 [24:57:15<43:33:34, 14.61s/it]

 33%|███▎      | 5371/16104 [24:57:27<41:10:11, 13.81s/it]

 33%|███▎      | 5372/16104 [24:57:38<38:44:50, 13.00s/it]
{'loss': 0.6613, 'learning_rate': 1.5544409161946427e-06, 'rewards/chosen': -0.6342083215713501, 'rewards/rejected': -0.961117684841156, 'rewards/accuracies': 0.75, 'rewards/margins': 0.32690930366516113, 'policy_logps/rejected': -403.7694091796875, 'policy_logps/chosen': -389.53399658203125, 'referece_logps/rejected': -394.158203125, 'referece_logps/chosen': -383.19189453125, 'logits/rejected': -0.39097079634666443, 'logits/chosen': -0.37279534339904785, 'epoch': 2.0}


 33%|███▎      | 5374/16104 [24:58:15<47:25:03, 15.91s/it]

 33%|███▎      | 5375/16104 [24:58:34<50:29:11, 16.94s/it]

 33%|███▎      | 5376/16104 [24:58:52<51:14:27, 17.19s/it]

 33%|███▎      | 5377/16104 [24:59:02<45:20:24, 15.22s/it]

 33%|███▎      | 5378/16104 [24:59:16<44:21:38, 14.89s/it]

 33%|███▎      | 5379/16104 [24:59:34<46:49:35, 15.72s/it]
{'loss': 0.7225, 'learning_rate': 1.5532686934944437e-06, 'rewards/chosen': -1.0335476398468018, 'rewards/rejected': -0.8349112272262573, 'rewards/accuracies': 0.5, 'rewards/margins': -0.19863641262054443, 'policy_logps/rejected': -556.9305419921875, 'policy_logps/chosen': -345.9764404296875, 'referece_logps/rejected': -548.5814208984375, 'referece_logps/chosen': -335.6409606933594, 'logits/rejected': -0.3098619878292084, 'logits/chosen': -0.2064891755580902, 'epoch': 2.0}


 33%|███▎      | 5381/16104 [24:59:57<40:11:29, 13.49s/it]
{'loss': 0.5348, 'learning_rate': 1.552933571194972e-06, 'rewards/chosen': -0.8162860870361328, 'rewards/rejected': -1.4666506052017212, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6503644585609436, 'policy_logps/rejected': -324.71563720703125, 'policy_logps/chosen': -282.9747009277344, 'referece_logps/rejected': -310.04913330078125, 'referece_logps/chosen': -274.8117980957031, 'logits/rejected': -0.8612073659896851, 'logits/chosen': -0.8233383893966675, 'epoch': 2.0}

 33%|███▎      | 5382/16104 [25:00:18<46:56:21, 15.76s/it]


 33%|███▎      | 5384/16104 [25:00:43<42:09:12, 14.16s/it]
{'loss': 0.5023, 'learning_rate': 1.552430720009093e-06, 'rewards/chosen': -0.6721760630607605, 'rewards/rejected': -1.7572507858276367, 'rewards/accuracies': 0.5, 'rewards/margins': 1.085074782371521, 'policy_logps/rejected': -422.41162109375, 'policy_logps/chosen': -461.66754150390625, 'referece_logps/rejected': -404.839111328125, 'referece_logps/chosen': -454.94573974609375, 'logits/rejected': -0.6739441156387329, 'logits/chosen': -0.6000498533248901, 'epoch': 2.01}


 33%|███▎      | 5386/16104 [25:01:04<36:58:27, 12.42s/it]

 33%|███▎      | 5387/16104 [25:01:15<35:30:19, 11.93s/it]
{'loss': 0.5612, 'learning_rate': 1.5519276677019434e-06, 'rewards/chosen': -0.7969915866851807, 'rewards/rejected': -1.3618603944778442, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5648688077926636, 'policy_logps/rejected': -358.80279541015625, 'policy_logps/chosen': -418.1759033203125, 'referece_logps/rejected': -345.1842041015625, 'referece_logps/chosen': -410.20599365234375, 'logits/rejected': -0.3922218382358551, 'logits/chosen': -0.1861167848110199, 'epoch': 2.01}

 33%|███▎      | 5388/16104 [25:01:26<34:21:24, 11.54s/it]


 33%|███▎      | 5390/16104 [25:01:58<40:44:45, 13.69s/it]

 33%|███▎      | 5391/16104 [25:02:21<48:25:32, 16.27s/it]

 33%|███▎      | 5392/16104 [25:02:41<51:46:51, 17.40s/it]
{'loss': 0.5282, 'learning_rate': 1.551088800751333e-06, 'rewards/chosen': -0.9253544211387634, 'rewards/rejected': -1.36545991897583, 'rewards/accuracies': 0.625, 'rewards/margins': 0.44010549783706665, 'policy_logps/rejected': -350.39276123046875, 'policy_logps/chosen': -413.51641845703125, 'referece_logps/rejected': -336.7381896972656, 'referece_logps/chosen': -404.26287841796875, 'logits/rejected': -0.3761747181415558, 'logits/chosen': -0.04775144159793854, 'epoch': 2.01}


 33%|███▎      | 5394/16104 [25:03:07<44:45:23, 15.04s/it]

 34%|███▎      | 5395/16104 [25:03:27<49:17:03, 16.57s/it]

 34%|███▎      | 5396/16104 [25:03:39<44:52:18, 15.09s/it]

 34%|███▎      | 5397/16104 [25:03:57<47:24:47, 15.94s/it]

 34%|███▎      | 5398/16104 [25:04:18<52:46:02, 17.74s/it]
{'loss': 0.4299, 'learning_rate': 1.5500814248320154e-06, 'rewards/chosen': -0.7298337817192078, 'rewards/rejected': -1.0469785928726196, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3171447515487671, 'policy_logps/rejected': -351.1362609863281, 'policy_logps/chosen': -339.4847412109375, 'referece_logps/rejected': -340.6664733886719, 'referece_logps/chosen': -332.1864013671875, 'logits/rejected': -0.09954649955034256, 'logits/chosen': 0.03816433250904083, 'epoch': 2.01}


 34%|███▎      | 5400/16104 [25:04:55<53:08:27, 17.87s/it]

 34%|███▎      | 5401/16104 [25:05:14<54:50:19, 18.45s/it]

 34%|███▎      | 5402/16104 [25:05:35<56:30:43, 19.01s/it]

 34%|███▎      | 5403/16104 [25:05:54<57:01:14, 19.18s/it]

 34%|███▎      | 5404/16104 [25:06:15<58:23:23, 19.65s/it]
{'loss': 0.5072, 'learning_rate': 1.549073247848883e-06, 'rewards/chosen': -0.9567345380783081, 'rewards/rejected': -1.8022816181182861, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8455471992492676, 'policy_logps/rejected': -383.06927490234375, 'policy_logps/chosen': -337.8328857421875, 'referece_logps/rejected': -365.0464782714844, 'referece_logps/chosen': -328.26556396484375, 'logits/rejected': -0.1727016270160675, 'logits/chosen': -0.20365655422210693, 'epoch': 2.01}


 34%|███▎      | 5406/16104 [25:06:39<46:13:16, 15.55s/it]
{'loss': 0.611, 'learning_rate': 1.5487370110940492e-06, 'rewards/chosen': -0.5344846844673157, 'rewards/rejected': -1.7470566034317017, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2125719785690308, 'policy_logps/rejected': -390.8561096191406, 'policy_logps/chosen': -299.2059326171875, 'referece_logps/rejected': -373.38555908203125, 'referece_logps/chosen': -293.8611145019531, 'logits/rejected': -0.7531459927558899, 'logits/chosen': -0.7428072094917297, 'epoch': 2.01}

 34%|███▎      | 5407/16104 [25:07:00<51:13:41, 17.24s/it]

 34%|███▎      | 5408/16104 [25:07:18<52:09:56, 17.56s/it]


 34%|███▎      | 5410/16104 [25:07:47<46:55:30, 15.80s/it]

 34%|███▎      | 5411/16104 [25:08:04<48:28:10, 16.32s/it]

 34%|███▎      | 5412/16104 [25:08:22<49:58:18, 16.83s/it]

 34%|███▎      | 5413/16104 [25:08:35<46:09:08, 15.54s/it]
{'loss': 0.4867, 'learning_rate': 1.547559483591477e-06, 'rewards/chosen': -0.5849935412406921, 'rewards/rejected': -1.3905733823776245, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8055799007415771, 'policy_logps/rejected': -490.0811767578125, 'policy_logps/chosen': -375.37823486328125, 'referece_logps/rejected': -476.17547607421875, 'referece_logps/chosen': -369.5282897949219, 'logits/rejected': -1.1619287729263306, 'logits/chosen': -0.8325675129890442, 'epoch': 2.02}


 34%|███▎      | 5415/16104 [25:08:59<40:23:34, 13.60s/it]
{'loss': 0.543, 'learning_rate': 1.5472228477122547e-06, 'rewards/chosen': -0.6643396019935608, 'rewards/rejected': -1.2430250644683838, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5786854028701782, 'policy_logps/rejected': -274.62689208984375, 'policy_logps/chosen': -429.77862548828125, 'referece_logps/rejected': -262.1966552734375, 'referece_logps/chosen': -423.1352233886719, 'logits/rejected': 0.6312134265899658, 'logits/chosen': 0.5857955813407898, 'epoch': 2.02}

 34%|███▎      | 5416/16104 [25:09:09<37:45:27, 12.72s/it]

 34%|███▎      | 5417/16104 [25:09:26<41:07:53, 13.86s/it]

 34%|███▎      | 5418/16104 [25:09:40<40:56:03, 13.79s/it]

 34%|███▎      | 5419/16104 [25:09:54<41:06:37, 13.85s/it]

 34%|███▎      | 5420/16104 [25:10:12<45:30:58, 15.34s/it]


 34%|███▎      | 5422/16104 [25:10:45<47:59:21, 16.17s/it]
{'loss': 0.4649, 'learning_rate': 1.546043925204139e-06, 'rewards/chosen': -0.7556777000427246, 'rewards/rejected': -1.6579766273498535, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9022988080978394, 'policy_logps/rejected': -312.4842224121094, 'policy_logps/chosen': -346.670166015625, 'referece_logps/rejected': -295.90447998046875, 'referece_logps/chosen': -339.1134033203125, 'logits/rejected': 0.4075278043746948, 'logits/chosen': 0.5216557383537292, 'epoch': 2.02}

 34%|███▎      | 5423/16104 [25:11:04<49:54:29, 16.82s/it]


 34%|███▎      | 5425/16104 [25:11:43<53:54:56, 18.18s/it]

 34%|███▎      | 5426/16104 [25:12:03<55:56:59, 18.86s/it]
{'loss': 0.4371, 'learning_rate': 1.5453697691036842e-06, 'rewards/chosen': -0.7376852035522461, 'rewards/rejected': -1.6828299760818481, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9451448917388916, 'policy_logps/rejected': -365.6787109375, 'policy_logps/chosen': -331.3163146972656, 'referece_logps/rejected': -348.8504333496094, 'referece_logps/chosen': -323.939453125, 'logits/rejected': -0.9251460433006287, 'logits/chosen': -1.0091149806976318, 'epoch': 2.02}


 34%|███▎      | 5428/16104 [25:12:43<57:14:29, 19.30s/it]
{'loss': 0.4844, 'learning_rate': 1.5450325586591015e-06, 'rewards/chosen': -0.7743564248085022, 'rewards/rejected': -2.2533674240112305, 'rewards/accuracies': 0.875, 'rewards/margins': 1.479011058807373, 'policy_logps/rejected': -529.9400024414062, 'policy_logps/chosen': -463.7638854980469, 'referece_logps/rejected': -507.4063720703125, 'referece_logps/chosen': -456.0203552246094, 'logits/rejected': -0.5430755019187927, 'logits/chosen': -0.497982919216156, 'epoch': 2.02}


 34%|███▎      | 5430/16104 [25:13:13<51:22:44, 17.33s/it]

 34%|███▎      | 5431/16104 [25:13:31<52:19:42, 17.65s/it]

 34%|███▎      | 5432/16104 [25:13:50<53:05:26, 17.91s/it]

 34%|███▎      | 5433/16104 [25:14:01<47:24:51, 16.00s/it]

 34%|███▎      | 5434/16104 [25:14:13<43:46:39, 14.77s/it]
{'loss': 0.5024, 'learning_rate': 1.5440203984027322e-06, 'rewards/chosen': -0.4616050720214844, 'rewards/rejected': -1.4942431449890137, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0326379537582397, 'policy_logps/rejected': -257.8529052734375, 'policy_logps/chosen': -256.2894287109375, 'referece_logps/rejected': -242.9104766845703, 'referece_logps/chosen': -251.6733856201172, 'logits/rejected': -0.38291847705841064, 'logits/chosen': -0.33536991477012634, 'epoch': 2.02}


 34%|███▍      | 5436/16104 [25:14:35<37:56:14, 12.80s/it]
{'loss': 0.5694, 'learning_rate': 1.5436828355250406e-06, 'rewards/chosen': -0.3937133550643921, 'rewards/rejected': -0.817181408405304, 'rewards/accuracies': 0.875, 'rewards/margins': 0.42346805334091187, 'policy_logps/rejected': -416.4446716308594, 'policy_logps/chosen': -434.0550231933594, 'referece_logps/rejected': -408.2729187011719, 'referece_logps/chosen': -430.117919921875, 'logits/rejected': -0.06843693554401398, 'logits/chosen': 0.012216344475746155, 'epoch': 2.03}

 34%|███▍      | 5437/16104 [25:14:54<43:26:14, 14.66s/it]

 34%|███▍      | 5438/16104 [25:15:14<48:22:46, 16.33s/it]

 34%|███▍      | 5439/16104 [25:15:31<48:35:43, 16.40s/it]


 34%|███▍      | 5441/16104 [25:16:12<54:50:24, 18.51s/it]
{'loss': 0.4713, 'learning_rate': 1.542838543573866e-06, 'rewards/chosen': -0.33466091752052307, 'rewards/rejected': -0.8822412490844727, 'rewards/accuracies': 0.75, 'rewards/margins': 0.547580361366272, 'policy_logps/rejected': -378.67877197265625, 'policy_logps/chosen': -497.26470947265625, 'referece_logps/rejected': -369.8563537597656, 'referece_logps/chosen': -493.9181213378906, 'logits/rejected': 1.16615629196167, 'logits/chosen': 1.0366827249526978, 'epoch': 2.03}

 34%|███▍      | 5442/16104 [25:16:27<51:52:58, 17.52s/it]

 34%|███▍      | 5443/16104 [25:16:39<46:45:09, 15.79s/it]

 34%|███▍      | 5444/16104 [25:16:54<46:30:14, 15.70s/it]


 34%|███▍      | 5446/16104 [25:17:25<46:53:04, 15.84s/it]
{'loss': 0.5318, 'learning_rate': 1.5419937026530415e-06, 'rewards/chosen': -0.8373657464981079, 'rewards/rejected': -1.1609798669815063, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3236141800880432, 'policy_logps/rejected': -236.2422332763672, 'policy_logps/chosen': -280.3061218261719, 'referece_logps/rejected': -224.63243103027344, 'referece_logps/chosen': -271.9324645996094, 'logits/rejected': 0.26825565099716187, 'logits/chosen': 0.21027350425720215, 'epoch': 2.03}

 34%|███▍      | 5447/16104 [25:17:40<46:07:15, 15.58s/it]


 34%|███▍      | 5449/16104 [25:18:14<49:00:09, 16.56s/it]
{'loss': 0.4542, 'learning_rate': 1.5414865349505148e-06, 'rewards/chosen': -0.6574155688285828, 'rewards/rejected': -1.2205400466918945, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5631243586540222, 'policy_logps/rejected': -308.2372741699219, 'policy_logps/chosen': -281.955810546875, 'referece_logps/rejected': -296.0318603515625, 'referece_logps/chosen': -275.38165283203125, 'logits/rejected': -1.2442187070846558, 'logits/chosen': -1.1377851963043213, 'epoch': 2.03}


 34%|███▍      | 5451/16104 [25:18:43<46:22:56, 15.67s/it]

 34%|███▍      | 5452/16104 [25:18:59<46:39:18, 15.77s/it]
{'loss': 0.4959, 'learning_rate': 1.5409791701111241e-06, 'rewards/chosen': -0.6781505346298218, 'rewards/rejected': -1.47798752784729, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7998368740081787, 'policy_logps/rejected': -315.92926025390625, 'policy_logps/chosen': -263.5006103515625, 'referece_logps/rejected': -301.1493835449219, 'referece_logps/chosen': -256.7191162109375, 'logits/rejected': -0.24813739955425262, 'logits/chosen': -0.14311456680297852, 'epoch': 2.03}

 34%|███▍      | 5453/16104 [25:19:17<48:08:17, 16.27s/it]


 34%|███▍      | 5455/16104 [25:19:51<50:21:28, 17.02s/it]
{'loss': 0.491, 'learning_rate': 1.5404716083195837e-06, 'rewards/chosen': -0.9843007922172546, 'rewards/rejected': -2.1438496112823486, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1595487594604492, 'policy_logps/rejected': -476.28125, 'policy_logps/chosen': -350.9889221191406, 'referece_logps/rejected': -454.8427734375, 'referece_logps/chosen': -341.14593505859375, 'logits/rejected': -0.18743281066417694, 'logits/chosen': -0.09910991787910461, 'epoch': 2.03}

 34%|███▍      | 5456/16104 [25:20:06<48:32:10, 16.41s/it]

 34%|███▍      | 5457/16104 [25:20:25<50:43:49, 17.15s/it]

 34%|███▍      | 5458/16104 [25:20:41<49:17:41, 16.67s/it]

 34%|███▍      | 5459/16104 [25:20:58<49:38:13, 16.79s/it]

 34%|███▍      | 5460/16104 [25:21:17<51:44:26, 17.50s/it]

 34%|███▍      | 5461/16104 [25:21:29<47:07:35, 15.94s/it]


 34%|███▍      | 5463/16104 [25:21:58<45:22:00, 15.35s/it]
{'loss': 0.5631, 'learning_rate': 1.5391171487371441e-06, 'rewards/chosen': -0.7586867809295654, 'rewards/rejected': -1.184213638305664, 'rewards/accuracies': 0.625, 'rewards/margins': 0.42552682757377625, 'policy_logps/rejected': -466.8275451660156, 'policy_logps/chosen': -480.0068054199219, 'referece_logps/rejected': -454.98541259765625, 'referece_logps/chosen': -472.419921875, 'logits/rejected': -0.8582851886749268, 'logits/chosen': -0.8529151082038879, 'epoch': 2.04}

 34%|███▍      | 5464/16104 [25:22:13<44:58:34, 15.22s/it]


 34%|███▍      | 5466/16104 [25:22:48<48:46:58, 16.51s/it]

 34%|███▍      | 5467/16104 [25:23:08<51:59:33, 17.60s/it]
{'loss': 0.3813, 'learning_rate': 1.5384393953287162e-06, 'rewards/chosen': -0.8274316191673279, 'rewards/rejected': -2.425703763961792, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5982723236083984, 'policy_logps/rejected': -422.2814025878906, 'policy_logps/chosen': -352.1040954589844, 'referece_logps/rejected': -398.0243835449219, 'referece_logps/chosen': -343.82977294921875, 'logits/rejected': -0.2362665832042694, 'logits/chosen': -0.25340700149536133, 'epoch': 2.04}

 34%|███▍      | 5468/16104 [25:23:30<55:20:48, 18.73s/it]


 34%|███▍      | 5470/16104 [25:24:06<55:00:00, 18.62s/it]
{'loss': 0.6479, 'learning_rate': 1.5379308515496479e-06, 'rewards/chosen': -1.5193595886230469, 'rewards/rejected': -1.808139681816101, 'rewards/accuracies': 0.375, 'rewards/margins': 0.2887800335884094, 'policy_logps/rejected': -364.046875, 'policy_logps/chosen': -339.00714111328125, 'referece_logps/rejected': -345.9654541015625, 'referece_logps/chosen': -323.8135681152344, 'logits/rejected': 0.09520117938518524, 'logits/chosen': 0.020250707864761353, 'epoch': 2.04}

 34%|███▍      | 5471/16104 [25:24:23<53:17:23, 18.04s/it]

 34%|███▍      | 5472/16104 [25:24:39<51:14:39, 17.35s/it]

 34%|███▍      | 5473/16104 [25:24:57<52:09:32, 17.66s/it]

 34%|███▍      | 5474/16104 [25:25:17<53:51:32, 18.24s/it]

 34%|███▍      | 5475/16104 [25:25:29<48:58:18, 16.59s/it]

 34%|███▍      | 5476/16104 [25:25:41<44:09:40, 14.96s/it]


 34%|███▍      | 5478/16104 [25:26:17<48:36:25, 16.47s/it]
{'loss': 0.4733, 'learning_rate': 1.53657377785701e-06, 'rewards/chosen': -1.3525370359420776, 'rewards/rejected': -2.4209535121917725, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0684164762496948, 'policy_logps/rejected': -475.4359130859375, 'policy_logps/chosen': -410.11029052734375, 'referece_logps/rejected': -451.22637939453125, 'referece_logps/chosen': -396.58489990234375, 'logits/rejected': 0.46331292390823364, 'logits/chosen': 0.29539644718170166, 'epoch': 2.04}

 34%|███▍      | 5479/16104 [25:26:37<51:46:35, 17.54s/it]

 34%|███▍      | 5480/16104 [25:26:57<53:59:15, 18.29s/it]

 34%|███▍      | 5481/16104 [25:27:18<56:29:17, 19.14s/it]


 34%|███▍      | 5483/16104 [25:27:54<54:44:45, 18.56s/it]
{'loss': 0.4722, 'learning_rate': 1.5357249011516741e-06, 'rewards/chosen': -2.0767509937286377, 'rewards/rejected': -2.824925661087036, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7481746673583984, 'policy_logps/rejected': -402.9519348144531, 'policy_logps/chosen': -392.58135986328125, 'referece_logps/rejected': -374.70269775390625, 'referece_logps/chosen': -371.8138732910156, 'logits/rejected': -0.7477214932441711, 'logits/chosen': -0.7622972726821899, 'epoch': 2.04}

 34%|███▍      | 5484/16104 [25:28:11<53:36:24, 18.17s/it]


 34%|███▍      | 5486/16104 [25:28:44<49:29:54, 16.78s/it]
{'loss': 0.4848, 'learning_rate': 1.5352153150211901e-06, 'rewards/chosen': -0.5062462091445923, 'rewards/rejected': -1.9379810094833374, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4317348003387451, 'policy_logps/rejected': -275.4251708984375, 'policy_logps/chosen': -341.0281066894531, 'referece_logps/rejected': -256.0453796386719, 'referece_logps/chosen': -335.9656677246094, 'logits/rejected': 0.19287759065628052, 'logits/chosen': 0.09451991319656372, 'epoch': 2.04}


 34%|███▍      | 5488/16104 [25:29:16<49:31:13, 16.79s/it]
{'loss': 0.4473, 'learning_rate': 1.5348754826706761e-06, 'rewards/chosen': -0.5108341574668884, 'rewards/rejected': -1.7707514762878418, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2599173784255981, 'policy_logps/rejected': -425.47796630859375, 'policy_logps/chosen': -708.192138671875, 'referece_logps/rejected': -407.77044677734375, 'referece_logps/chosen': -703.0838012695312, 'logits/rejected': 0.024872995913028717, 'logits/chosen': -0.1270117163658142, 'epoch': 2.04}

 34%|███▍      | 5489/16104 [25:29:36<51:35:19, 17.50s/it]

 34%|███▍      | 5490/16104 [25:29:57<55:27:10, 18.81s/it]

 34%|███▍      | 5491/16104 [25:30:15<54:20:52, 18.44s/it]


 34%|███▍      | 5493/16104 [25:30:41<45:24:01, 15.40s/it]
{'loss': 0.5212, 'learning_rate': 1.5340255232730277e-06, 'rewards/chosen': -0.6782252788543701, 'rewards/rejected': -1.3685181140899658, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6902927160263062, 'policy_logps/rejected': -245.02159118652344, 'policy_logps/chosen': -309.2576904296875, 'referece_logps/rejected': -231.33641052246094, 'referece_logps/chosen': -302.4754333496094, 'logits/rejected': -0.6888871192932129, 'logits/chosen': -0.6966755390167236, 'epoch': 2.05}

 34%|███▍      | 5494/16104 [25:30:59<48:12:28, 16.36s/it]

 34%|███▍      | 5495/16104 [25:31:18<50:22:37, 17.09s/it]

 34%|███▍      | 5496/16104 [25:31:36<50:49:32, 17.25s/it]

 34%|███▍      | 5497/16104 [25:31:57<54:33:51, 18.52s/it]

 34%|███▍      | 5498/16104 [25:32:19<57:28:50, 19.51s/it]

 34%|███▍      | 5499/16104 [25:32:35<54:32:24, 18.51s/it]

 34%|███▍      | 5500/16104 [25:32:50<51:08:19, 17.36s/it]

 34%|███▍      | 5501/16104 [25:33:21<63:37:24, 21.60s/it]

 34%|███▍      | 5502/16104 [25:33:38<59:17:59, 20.14s/it]

 34%|███▍      | 5503/16104 [25:33:58<58:55:30, 20.01s/it]

 34%|███▍      | 5504/16104 [25:34:14<55:48:02, 18.95s/it]


 34%|███▍      | 5506/16104 [25:34:47<51:40:46, 17.55s/it]
{'loss': 0.5042, 'learning_rate': 1.5318131035189848e-06, 'rewards/chosen': -0.7281026840209961, 'rewards/rejected': -1.9718589782714844, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2437565326690674, 'policy_logps/rejected': -272.23834228515625, 'policy_logps/chosen': -321.9277038574219, 'referece_logps/rejected': -252.51974487304688, 'referece_logps/chosen': -314.6466979980469, 'logits/rejected': -1.1622507572174072, 'logits/chosen': -1.1141681671142578, 'epoch': 2.05}


 34%|███▍      | 5508/16104 [25:35:27<55:30:34, 18.86s/it]
{'loss': 0.521, 'learning_rate': 1.5314724081785051e-06, 'rewards/chosen': -0.8914700746536255, 'rewards/rejected': -1.4632761478424072, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5718058943748474, 'policy_logps/rejected': -465.7889709472656, 'policy_logps/chosen': -432.8657531738281, 'referece_logps/rejected': -451.15618896484375, 'referece_logps/chosen': -423.9510498046875, 'logits/rejected': -0.33029964566230774, 'logits/chosen': -0.4091359078884125, 'epoch': 2.05}


 34%|███▍      | 5510/16104 [25:36:01<52:50:59, 17.96s/it]
{'loss': 0.6292, 'learning_rate': 1.5311316268419975e-06, 'rewards/chosen': -0.6725804805755615, 'rewards/rejected': -1.1119139194488525, 'rewards/accuracies': 0.75, 'rewards/margins': 0.43933340907096863, 'policy_logps/rejected': -247.09474182128906, 'policy_logps/chosen': -384.1856384277344, 'referece_logps/rejected': -235.97561645507812, 'referece_logps/chosen': -377.4598083496094, 'logits/rejected': -0.3580854833126068, 'logits/chosen': -0.3281465172767639, 'epoch': 2.05}

 34%|███▍      | 5511/16104 [25:36:18<52:02:34, 17.69s/it]

 34%|███▍      | 5512/16104 [25:36:36<52:38:04, 17.89s/it]

 34%|███▍      | 5513/16104 [25:36:57<54:30:48, 18.53s/it]

 34%|███▍      | 5514/16104 [25:37:17<56:27:46, 19.19s/it]

 34%|███▍      | 5515/16104 [25:37:40<59:12:24, 20.13s/it]

 34%|███▍      | 5516/16104 [25:37:59<58:51:59, 20.02s/it]

 34%|███▍      | 5517/16104 [25:38:16<56:03:09, 19.06s/it]

 34%|███▍      | 5518/16104 [25:38:32<53:30:53, 18.20s/it]

 34%|███▍      | 5519/16104 [25:38:48<50:53:58, 17.31s/it]

 34%|███▍      | 5520/16104 [25:39:07<53:03:49, 18.05s/it]

 34%|███▍      | 5521/16104 [25:39:26<53:55:07, 18.34s/it]

 34%|███▍      | 5522/16104 [25:39:46<55:17:27, 18.81s/it]


 34%|███▍      | 5524/16104 [25:40:13<46:35:05, 15.85s/it]
{'loss': 0.5616, 'learning_rate': 1.5287437542312296e-06, 'rewards/chosen': -0.8804187178611755, 'rewards/rejected': -1.6568018198013306, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7763830423355103, 'policy_logps/rejected': -375.11614990234375, 'policy_logps/chosen': -297.3192138671875, 'referece_logps/rejected': -358.548095703125, 'referece_logps/chosen': -288.5150146484375, 'logits/rejected': -1.3760591745376587, 'logits/chosen': -1.2976813316345215, 'epoch': 2.06}

 34%|███▍      | 5525/16104 [25:40:26<43:39:23, 14.86s/it]


 34%|███▍      | 5527/16104 [25:40:49<38:42:17, 13.17s/it]
{'loss': 0.6167, 'learning_rate': 1.528231521187807e-06, 'rewards/chosen': -0.9397926330566406, 'rewards/rejected': -1.0459505319595337, 'rewards/accuracies': 0.5, 'rewards/margins': 0.10615785419940948, 'policy_logps/rejected': -301.6497802734375, 'policy_logps/chosen': -432.62640380859375, 'referece_logps/rejected': -291.1902770996094, 'referece_logps/chosen': -423.2285461425781, 'logits/rejected': -0.2313951849937439, 'logits/chosen': -0.3525460958480835, 'epoch': 2.06}

 34%|███▍      | 5528/16104 [25:41:01<37:26:44, 12.75s/it]

 34%|███▍      | 5529/16104 [25:41:12<36:20:20, 12.37s/it]


 34%|███▍      | 5531/16104 [25:41:47<44:37:14, 15.19s/it]
{'loss': 0.5431, 'learning_rate': 1.5275482446781194e-06, 'rewards/chosen': -1.3016104698181152, 'rewards/rejected': -1.7101680040359497, 'rewards/accuracies': 0.625, 'rewards/margins': 0.40855738520622253, 'policy_logps/rejected': -408.3538513183594, 'policy_logps/chosen': -372.1748046875, 'referece_logps/rejected': -391.2521667480469, 'referece_logps/chosen': -359.15869140625, 'logits/rejected': -0.3948632776737213, 'logits/chosen': -0.3066081404685974, 'epoch': 2.06}

 34%|███▍      | 5532/16104 [25:42:06<47:38:08, 16.22s/it]


 34%|███▍      | 5534/16104 [25:42:37<47:58:30, 16.34s/it]
{'loss': 0.7012, 'learning_rate': 1.5270355631988597e-06, 'rewards/chosen': -0.6568354964256287, 'rewards/rejected': -1.8780659437179565, 'rewards/accuracies': 0.5, 'rewards/margins': 1.221230387687683, 'policy_logps/rejected': -396.2454833984375, 'policy_logps/chosen': -496.5258483886719, 'referece_logps/rejected': -377.46484375, 'referece_logps/chosen': -489.95745849609375, 'logits/rejected': -0.7954859137535095, 'logits/chosen': -0.6599670052528381, 'epoch': 2.06}

 34%|███▍      | 5535/16104 [25:42:52<46:15:24, 15.76s/it]

 34%|███▍      | 5536/16104 [25:43:02<41:52:46, 14.27s/it]

 34%|███▍      | 5537/16104 [25:43:17<41:54:25, 14.28s/it]

 34%|███▍      | 5538/16104 [25:43:30<41:20:08, 14.08s/it]

 34%|███▍      | 5539/16104 [25:43:49<45:14:19, 15.41s/it]


 34%|███▍      | 5541/16104 [25:44:19<43:51:53, 14.95s/it]
{'loss': 0.5277, 'learning_rate': 1.5258385605531593e-06, 'rewards/chosen': -1.0455325841903687, 'rewards/rejected': -1.7305140495300293, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6849814057350159, 'policy_logps/rejected': -338.9375915527344, 'policy_logps/chosen': -347.0155334472656, 'referece_logps/rejected': -321.6324157714844, 'referece_logps/chosen': -336.5602111816406, 'logits/rejected': -0.8269791007041931, 'logits/chosen': -0.8043534159660339, 'epoch': 2.06}

 34%|███▍      | 5542/16104 [25:44:39<47:32:10, 16.20s/it]

 34%|███▍      | 5543/16104 [25:44:54<47:08:36, 16.07s/it]

 34%|███▍      | 5544/16104 [25:45:14<50:11:22, 17.11s/it]


 34%|███▍      | 5546/16104 [25:45:37<41:58:51, 14.31s/it]
{'loss': 0.5244, 'learning_rate': 1.5249829203918054e-06, 'rewards/chosen': -0.94333815574646, 'rewards/rejected': -2.0043606758117676, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0610225200653076, 'policy_logps/rejected': -463.3129577636719, 'policy_logps/chosen': -426.6397705078125, 'referece_logps/rejected': -443.2693786621094, 'referece_logps/chosen': -417.2063903808594, 'logits/rejected': -0.4283856153488159, 'logits/chosen': -0.604629635810852, 'epoch': 2.07}

 34%|███▍      | 5547/16104 [25:45:54<43:52:07, 14.96s/it]

 34%|███▍      | 5548/16104 [25:46:05<40:32:58, 13.83s/it]


 34%|███▍      | 5550/16104 [25:46:30<37:52:15, 12.92s/it]
{'loss': 0.5866, 'learning_rate': 1.5242980259642736e-06, 'rewards/chosen': -0.5979615449905396, 'rewards/rejected': -1.053554892539978, 'rewards/accuracies': 0.75, 'rewards/margins': 0.45559340715408325, 'policy_logps/rejected': -429.9444274902344, 'policy_logps/chosen': -409.4916076660156, 'referece_logps/rejected': -419.4089050292969, 'referece_logps/chosen': -403.5119934082031, 'logits/rejected': -1.1228328943252563, 'logits/chosen': -1.0528876781463623, 'epoch': 2.07}

 34%|███▍      | 5551/16104 [25:46:41<36:43:13, 12.53s/it]

 34%|███▍      | 5552/16104 [25:46:52<35:04:24, 11.97s/it]

 34%|███▍      | 5553/16104 [25:47:15<44:47:02, 15.28s/it]

 34%|███▍      | 5554/16104 [25:47:33<46:59:45, 16.04s/it]


 35%|███▍      | 5556/16104 [25:48:07<48:35:23, 16.58s/it]

 35%|███▍      | 5557/16104 [25:48:18<43:46:35, 14.94s/it]

 35%|███▍      | 5558/16104 [25:48:37<47:25:59, 16.19s/it]

 35%|███▍      | 5559/16104 [25:48:57<50:33:01, 17.26s/it]

 35%|███▍      | 5560/16104 [25:49:16<52:29:06, 17.92s/it]

 35%|███▍      | 5561/16104 [25:49:34<52:34:31, 17.95s/it]
{'loss': 0.5137, 'learning_rate': 1.5224128178975094e-06, 'rewards/chosen': -0.8776501417160034, 'rewards/rejected': -1.2753056287765503, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3976556062698364, 'policy_logps/rejected': -428.34234619140625, 'policy_logps/chosen': -459.3172302246094, 'referece_logps/rejected': -415.58929443359375, 'referece_logps/chosen': -450.5407409667969, 'logits/rejected': 0.06049559265375137, 'logits/chosen': 0.11420556902885437, 'epoch': 2.07}


 35%|███▍      | 5563/16104 [25:50:07<48:45:02, 16.65s/it]

 35%|███▍      | 5564/16104 [25:50:26<50:26:42, 17.23s/it]

 35%|███▍      | 5565/16104 [25:50:45<52:37:28, 17.98s/it]

 35%|███▍      | 5566/16104 [25:50:56<46:28:01, 15.87s/it]

 35%|███▍      | 5567/16104 [25:51:07<42:10:55, 14.41s/it]

 35%|███▍      | 5568/16104 [25:51:23<43:22:46, 14.82s/it]

 35%|███▍      | 5569/16104 [25:51:43<48:02:42, 16.42s/it]

 35%|███▍      | 5570/16104 [25:51:56<45:08:19, 15.43s/it]

 35%|███▍      | 5571/16104 [25:52:14<47:09:55, 16.12s/it]
{'loss': 0.561, 'learning_rate': 1.5206967732245554e-06, 'rewards/chosen': -0.856838047504425, 'rewards/rejected': -1.1493521928787231, 'rewards/accuracies': 0.375, 'rewards/margins': 0.2925141453742981, 'policy_logps/rejected': -301.1610107421875, 'policy_logps/chosen': -403.8161926269531, 'referece_logps/rejected': -289.66754150390625, 'referece_logps/chosen': -395.24786376953125, 'logits/rejected': -0.9276858568191528, 'logits/chosen': -0.9940736889839172, 'epoch': 2.08}


 35%|███▍      | 5573/16104 [25:52:38<41:16:37, 14.11s/it]

 35%|███▍      | 5574/16104 [25:52:58<46:25:17, 15.87s/it]

 35%|███▍      | 5575/16104 [25:53:11<43:30:44, 14.88s/it]

 35%|███▍      | 5576/16104 [25:53:27<44:54:41, 15.36s/it]

 35%|███▍      | 5577/16104 [25:53:41<43:02:49, 14.72s/it]

 35%|███▍      | 5578/16104 [25:53:53<40:54:19, 13.99s/it]

 35%|███▍      | 5579/16104 [25:54:05<39:31:14, 13.52s/it]

 35%|███▍      | 5580/16104 [25:54:27<46:43:22, 15.98s/it]

 35%|███▍      | 5581/16104 [25:54:38<42:26:54, 14.52s/it]

 35%|███▍      | 5582/16104 [25:54:56<45:01:43, 15.41s/it]

 35%|███▍      | 5583/16104 [25:55:09<43:15:44, 14.80s/it]

 35%|███▍      | 5584/16104 [25:55:21<40:59:08, 14.03s/it]

 35%|███▍      | 5585/16104 [25:55:38<43:27:05, 14.87s/it]

 35%|███▍      | 5586/16104 [25:55:54<44:23:30, 15.19s/it]

 35%|███▍      | 5587/16104 [25:56:10<44:35:52, 15.27s/it]

 35%|███▍      | 5588/16104 [25:56:29<47:58:00, 16.42s/it]

 35%|███▍      | 5589/16104 [25:56:41<44:03:34, 15.08s/it]

 35%|███▍      | 5590/16104 [25:56:53<41:40:44, 14.27s/it]
{'loss': 0.5441, 'learning_rate': 1.5174304912042527e-06, 'rewards/chosen': -0.8682968616485596, 'rewards/rejected': -2.4406628608703613, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5723657608032227, 'policy_logps/rejected': -395.1806640625, 'policy_logps/chosen': -431.6824951171875, 'referece_logps/rejected': -370.7740478515625, 'referece_logps/chosen': -422.99951171875, 'logits/rejected': -0.9338716268539429, 'logits/chosen': -0.7013929486274719, 'epoch': 2.08}


 35%|███▍      | 5592/16104 [25:57:21<41:45:08, 14.30s/it]

 35%|███▍      | 5593/16104 [25:57:39<44:36:44, 15.28s/it]

 35%|███▍      | 5594/16104 [25:57:56<46:04:29, 15.78s/it]

 35%|███▍      | 5595/16104 [25:58:15<49:11:48, 16.85s/it]

 35%|███▍      | 5596/16104 [25:58:36<52:46:05, 18.08s/it]

 35%|███▍      | 5597/16104 [25:58:56<54:21:07, 18.62s/it]

 35%|███▍      | 5598/16104 [25:59:16<55:44:34, 19.10s/it]

 35%|███▍      | 5599/16104 [25:59:39<58:29:04, 20.04s/it]

 35%|███▍      | 5600/16104 [25:59:58<57:50:13, 19.82s/it]

 35%|███▍      | 5601/16104 [26:00:16<56:07:03, 19.23s/it]

 35%|███▍      | 5602/16104 [26:00:35<56:19:35, 19.31s/it]

 35%|███▍      | 5603/16104 [26:00:53<54:39:54, 18.74s/it]
{'loss': 0.6382, 'learning_rate': 1.5151913101267125e-06, 'rewards/chosen': -0.8152139782905579, 'rewards/rejected': -1.08357572555542, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2683617174625397, 'policy_logps/rejected': -411.1275329589844, 'policy_logps/chosen': -439.9234924316406, 'referece_logps/rejected': -400.291748046875, 'referece_logps/chosen': -431.7713928222656, 'logits/rejected': 0.4164726138114929, 'logits/chosen': 0.44905751943588257, 'epoch': 2.09}


 35%|███▍      | 5605/16104 [26:01:21<47:36:53, 16.33s/it]

 35%|███▍      | 5606/16104 [26:01:41<50:41:49, 17.39s/it]

 35%|███▍      | 5607/16104 [26:01:56<48:48:11, 16.74s/it]

 35%|███▍      | 5608/16104 [26:02:10<46:02:43, 15.79s/it]

 35%|███▍      | 5609/16104 [26:02:22<43:08:29, 14.80s/it]

 35%|███▍      | 5610/16104 [26:02:41<46:31:03, 15.96s/it]

 35%|███▍      | 5611/16104 [26:02:59<48:12:46, 16.54s/it]

 35%|███▍      | 5612/16104 [26:03:10<43:19:52, 14.87s/it]

 35%|███▍      | 5613/16104 [26:03:21<40:18:13, 13.83s/it]

 35%|███▍      | 5614/16104 [26:03:32<37:16:00, 12.79s/it]

 35%|███▍      | 5615/16104 [26:03:46<38:16:34, 13.14s/it]

 35%|███▍      | 5616/16104 [26:04:05<43:32:44, 14.95s/it]

 35%|███▍      | 5617/16104 [26:04:23<46:31:29, 15.97s/it]

 35%|███▍      | 5618/16104 [26:04:41<48:16:05, 16.57s/it]
{'loss': 0.4816, 'learning_rate': 1.5126032641461324e-06, 'rewards/chosen': -0.5893914103507996, 'rewards/rejected': -1.5855023860931396, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9961109161376953, 'policy_logps/rejected': -326.7342529296875, 'policy_logps/chosen': -392.5691833496094, 'referece_logps/rejected': -310.87921142578125, 'referece_logps/chosen': -386.6752624511719, 'logits/rejected': -1.0738142728805542, 'logits/chosen': -0.8928320407867432, 'epoch': 2.09}


 35%|███▍      | 5620/16104 [26:05:17<50:14:19, 17.25s/it]

 35%|███▍      | 5621/16104 [26:05:29<45:55:08, 15.77s/it]

 35%|███▍      | 5622/16104 [26:05:49<49:19:40, 16.94s/it]

 35%|███▍      | 5623/16104 [26:06:01<45:04:11, 15.48s/it]

 35%|███▍      | 5624/16104 [26:06:17<45:03:43, 15.48s/it]

 35%|███▍      | 5625/16104 [26:06:33<45:46:43, 15.73s/it]

 35%|███▍      | 5626/16104 [26:06:52<48:57:41, 16.82s/it]

 35%|███▍      | 5627/16104 [26:07:12<51:18:42, 17.63s/it]

 35%|███▍      | 5628/16104 [26:07:33<54:53:01, 18.86s/it]

 35%|███▍      | 5629/16104 [26:07:50<53:14:48, 18.30s/it]

 35%|███▍      | 5630/16104 [26:08:03<48:20:43, 16.62s/it]

 35%|███▍      | 5631/16104 [26:08:21<49:51:05, 17.14s/it]

 35%|███▍      | 5632/16104 [26:08:39<50:19:08, 17.30s/it]
{'loss': 0.4861, 'learning_rate': 1.5101835447440344e-06, 'rewards/chosen': -1.180065393447876, 'rewards/rejected': -1.1836220026016235, 'rewards/accuracies': 0.375, 'rewards/margins': 0.003556620329618454, 'policy_logps/rejected': -589.9114990234375, 'policy_logps/chosen': -579.7272338867188, 'referece_logps/rejected': -578.0752563476562, 'referece_logps/chosen': -567.9266357421875, 'logits/rejected': 0.014256864786148071, 'logits/chosen': 0.11667552590370178, 'epoch': 2.1}

 35%|███▍      | 5633/16104 [26:08:51<45:50:49, 15.76s/it]


 35%|███▍      | 5635/16104 [26:09:24<46:38:30, 16.04s/it]

 35%|███▍      | 5636/16104 [26:09:44<50:31:37, 17.38s/it]

 35%|███▌      | 5637/16104 [26:10:05<53:14:25, 18.31s/it]

 35%|███▌      | 5638/16104 [26:10:23<52:42:50, 18.13s/it]

 35%|███▌      | 5639/16104 [26:10:42<54:18:14, 18.68s/it]

 35%|███▌      | 5640/16104 [26:10:57<50:37:43, 17.42s/it]

 35%|███▌      | 5641/16104 [26:11:17<52:33:06, 18.08s/it]

 35%|███▌      | 5642/16104 [26:11:36<53:46:29, 18.50s/it]
{'loss': 0.3624, 'learning_rate': 1.5084526960840665e-06, 'rewards/chosen': -1.0337109565734863, 'rewards/rejected': -2.627716541290283, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5940055847167969, 'policy_logps/rejected': -419.0787353515625, 'policy_logps/chosen': -491.380859375, 'referece_logps/rejected': -392.8016052246094, 'referece_logps/chosen': -481.04376220703125, 'logits/rejected': -0.8681597709655762, 'logits/chosen': -0.9025486707687378, 'epoch': 2.1}


 35%|███▌      | 5644/16104 [26:12:10<51:38:35, 17.77s/it]
{'loss': 0.4566, 'learning_rate': 1.508106279314131e-06, 'rewards/chosen': -1.7059459686279297, 'rewards/rejected': -2.7418713569641113, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0359253883361816, 'policy_logps/rejected': -358.86285400390625, 'policy_logps/chosen': -300.32818603515625, 'referece_logps/rejected': -331.4441223144531, 'referece_logps/chosen': -283.26873779296875, 'logits/rejected': -0.8571951389312744, 'logits/chosen': -0.7712018489837646, 'epoch': 2.1}


 35%|███▌      | 5646/16104 [26:12:41<49:23:47, 17.00s/it]

 35%|███▌      | 5647/16104 [26:12:52<43:59:10, 15.14s/it]

 35%|███▌      | 5648/16104 [26:13:12<48:21:40, 16.65s/it]

 35%|███▌      | 5649/16104 [26:13:23<43:32:52, 14.99s/it]

 35%|███▌      | 5650/16104 [26:13:34<39:59:36, 13.77s/it]

 35%|███▌      | 5651/16104 [26:13:46<38:49:53, 13.37s/it]

 35%|███▌      | 5652/16104 [26:14:01<40:08:41, 13.83s/it]

 35%|███▌      | 5653/16104 [26:14:16<41:02:49, 14.14s/it]

 35%|███▌      | 5654/16104 [26:14:31<41:41:11, 14.36s/it]

 35%|███▌      | 5655/16104 [26:14:43<39:35:10, 13.64s/it]

 35%|███▌      | 5656/16104 [26:15:01<43:08:21, 14.86s/it]

 35%|███▌      | 5657/16104 [26:15:17<44:21:26, 15.29s/it]
{'loss': 0.3817, 'learning_rate': 1.5058525688196326e-06, 'rewards/chosen': -0.29231396317481995, 'rewards/rejected': -1.164085865020752, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8717719912528992, 'policy_logps/rejected': -321.9084777832031, 'policy_logps/chosen': -370.1871032714844, 'referece_logps/rejected': -310.267578125, 'referece_logps/chosen': -367.26397705078125, 'logits/rejected': 0.07552626729011536, 'logits/chosen': 0.23263642191886902, 'epoch': 2.11}


 35%|███▌      | 5659/16104 [26:15:52<47:40:50, 16.43s/it]

 35%|███▌      | 5660/16104 [26:16:10<48:51:01, 16.84s/it]

 35%|███▌      | 5661/16104 [26:16:21<43:36:36, 15.03s/it]

 35%|███▌      | 5662/16104 [26:16:36<43:15:33, 14.91s/it]

 35%|███▌      | 5663/16104 [26:16:46<39:39:19, 13.67s/it]

 35%|███▌      | 5664/16104 [26:16:59<38:22:59, 13.24s/it]

 35%|███▌      | 5665/16104 [26:17:12<38:14:15, 13.19s/it]

 35%|███▌      | 5666/16104 [26:17:22<36:02:23, 12.43s/it]

 35%|███▌      | 5667/16104 [26:17:34<35:02:06, 12.08s/it]

 35%|███▌      | 5668/16104 [26:17:51<39:43:13, 13.70s/it]

 35%|███▌      | 5669/16104 [26:18:05<39:46:00, 13.72s/it]

 35%|███▌      | 5670/16104 [26:18:20<41:21:28, 14.27s/it]

 35%|███▌      | 5671/16104 [26:18:40<45:32:28, 15.71s/it]

 35%|███▌      | 5672/16104 [26:18:55<45:37:52, 15.75s/it]

 35%|███▌      | 5673/16104 [26:19:13<47:26:19, 16.37s/it]

 35%|███▌      | 5674/16104 [26:19:29<47:03:30, 16.24s/it]

 35%|███▌      | 5675/16104 [26:19:44<46:05:11, 15.91s/it]

 35%|███▌      | 5676/16104 [26:19:58<43:46:50, 15.11s/it]

 35%|███▌      | 5677/16104 [26:20:13<43:59:01, 15.19s/it]

 35%|███▌      | 5678/16104 [26:20:25<41:34:11, 14.35s/it]

 35%|███▌      | 5679/16104 [26:20:45<46:22:11, 16.01s/it]
{'loss': 0.5591, 'learning_rate': 1.5020307272132418e-06, 'rewards/chosen': -0.5223743915557861, 'rewards/rejected': -1.48500657081604, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9626321792602539, 'policy_logps/rejected': -588.3331298828125, 'policy_logps/chosen': -379.5516052246094, 'referece_logps/rejected': -573.4830932617188, 'referece_logps/chosen': -374.3278503417969, 'logits/rejected': 0.28567275404930115, 'logits/chosen': 0.26518309116363525, 'epoch': 2.12}


 35%|███▌      | 5681/16104 [26:21:15<43:32:40, 15.04s/it]
{'loss': 0.6168, 'learning_rate': 1.501682798549189e-06, 'rewards/chosen': -0.9575036764144897, 'rewards/rejected': -1.3195505142211914, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3620469570159912, 'policy_logps/rejected': -448.0426940917969, 'policy_logps/chosen': -271.512939453125, 'referece_logps/rejected': -434.84722900390625, 'referece_logps/chosen': -261.93792724609375, 'logits/rejected': -0.4960716664791107, 'logits/chosen': -0.3763205409049988, 'epoch': 2.12}

 35%|███▌      | 5682/16104 [26:21:36<48:53:14, 16.89s/it]


 35%|███▌      | 5684/16104 [26:22:10<49:23:58, 17.07s/it]
{'loss': 0.6524, 'learning_rate': 1.5011607533659745e-06, 'rewards/chosen': -1.0500282049179077, 'rewards/rejected': -1.5658776760101318, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5158495306968689, 'policy_logps/rejected': -411.6787414550781, 'policy_logps/chosen': -446.20184326171875, 'referece_logps/rejected': -396.0199890136719, 'referece_logps/chosen': -435.7015380859375, 'logits/rejected': -0.8396526575088501, 'logits/chosen': -0.8552453517913818, 'epoch': 2.12}


 35%|███▌      | 5686/16104 [26:22:47<52:13:39, 18.05s/it]

 35%|███▌      | 5687/16104 [26:23:08<54:41:18, 18.90s/it]
{'loss': 0.4395, 'learning_rate': 1.5006385257271437e-06, 'rewards/chosen': -1.1693713665008545, 'rewards/rejected': -2.0340168476104736, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8646454811096191, 'policy_logps/rejected': -361.4950866699219, 'policy_logps/chosen': -375.6358642578125, 'referece_logps/rejected': -341.1549072265625, 'referece_logps/chosen': -363.942138671875, 'logits/rejected': -0.655504047870636, 'logits/chosen': -0.7619202136993408, 'epoch': 2.12}

 35%|███▌      | 5688/16104 [26:23:21<49:18:11, 17.04s/it]


 35%|███▌      | 5690/16104 [26:23:59<52:40:14, 18.21s/it]

 35%|███▌      | 5691/16104 [26:24:19<54:35:02, 18.87s/it]
{'loss': 0.4896, 'learning_rate': 1.4999419387174764e-06, 'rewards/chosen': -0.7710691690444946, 'rewards/rejected': -1.6990547180175781, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9279855489730835, 'policy_logps/rejected': -401.0611877441406, 'policy_logps/chosen': -399.8376770019531, 'referece_logps/rejected': -384.0706787109375, 'referece_logps/chosen': -392.126953125, 'logits/rejected': -0.4459623098373413, 'logits/chosen': -0.4481431543827057, 'epoch': 2.12}

 35%|███▌      | 5692/16104 [26:24:41<56:45:25, 19.62s/it]


 35%|███▌      | 5694/16104 [26:25:12<49:26:26, 17.10s/it]
{'loss': 0.5908, 'learning_rate': 1.4994192860883657e-06, 'rewards/chosen': -1.1173896789550781, 'rewards/rejected': -1.4043951034545898, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2870054244995117, 'policy_logps/rejected': -259.9686584472656, 'policy_logps/chosen': -381.0123291015625, 'referece_logps/rejected': -245.92469787597656, 'referece_logps/chosen': -369.8384094238281, 'logits/rejected': -0.30276668071746826, 'logits/chosen': -0.3752664625644684, 'epoch': 2.12}

 35%|███▌      | 5695/16104 [26:25:22<43:56:34, 15.20s/it]


 35%|███▌      | 5697/16104 [26:25:51<41:58:12, 14.52s/it]

 35%|███▌      | 5698/16104 [26:26:02<38:41:59, 13.39s/it]
{'loss': 0.5223, 'learning_rate': 1.4987221331155042e-06, 'rewards/chosen': -0.5961189866065979, 'rewards/rejected': -1.187784194946289, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5916651487350464, 'policy_logps/rejected': -254.75448608398438, 'policy_logps/chosen': -295.841064453125, 'referece_logps/rejected': -242.8766326904297, 'referece_logps/chosen': -289.8798828125, 'logits/rejected': -0.8434263467788696, 'logits/chosen': -0.7738064527511597, 'epoch': 2.12}


 35%|███▌      | 5700/16104 [26:26:42<48:37:55, 16.83s/it]

 35%|███▌      | 5701/16104 [26:27:02<51:07:28, 17.69s/it]

 35%|███▌      | 5702/16104 [26:27:15<47:30:56, 16.44s/it]

 35%|███▌      | 5703/16104 [26:27:26<42:29:37, 14.71s/it]
{'loss': 0.5245, 'learning_rate': 1.497850238032842e-06, 'rewards/chosen': -0.882010817527771, 'rewards/rejected': -1.291804313659668, 'rewards/accuracies': 0.75, 'rewards/margins': 0.40979352593421936, 'policy_logps/rejected': -500.71710205078125, 'policy_logps/chosen': -331.8538818359375, 'referece_logps/rejected': -487.79901123046875, 'referece_logps/chosen': -323.0337829589844, 'logits/rejected': -0.9306917190551758, 'logits/chosen': -0.8376938700675964, 'epoch': 2.12}

 35%|███▌      | 5704/16104 [26:27:47<47:39:51, 16.50s/it]


 35%|███▌      | 5706/16104 [26:28:22<49:34:52, 17.17s/it]

 35%|███▌      | 5707/16104 [26:28:41<51:48:10, 17.94s/it]
{'loss': 0.4346, 'learning_rate': 1.4971523594236509e-06, 'rewards/chosen': -1.0307503938674927, 'rewards/rejected': -1.8857457637786865, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8549952507019043, 'policy_logps/rejected': -441.3946533203125, 'policy_logps/chosen': -413.79180908203125, 'referece_logps/rejected': -422.53717041015625, 'referece_logps/chosen': -403.4842834472656, 'logits/rejected': -0.2848298251628876, 'logits/chosen': -0.3030235767364502, 'epoch': 2.13}

 35%|███▌      | 5708/16104 [26:29:01<53:16:01, 18.45s/it]


 35%|███▌      | 5710/16104 [26:29:37<51:39:03, 17.89s/it]

 35%|███▌      | 5711/16104 [26:29:56<52:56:20, 18.34s/it]
{'loss': 0.5318, 'learning_rate': 1.4964541590432745e-06, 'rewards/chosen': -1.3035329580307007, 'rewards/rejected': -1.6951221227645874, 'rewards/accuracies': 0.875, 'rewards/margins': 0.39158910512924194, 'policy_logps/rejected': -370.23486328125, 'policy_logps/chosen': -358.6634826660156, 'referece_logps/rejected': -353.28363037109375, 'referece_logps/chosen': -345.628173828125, 'logits/rejected': -0.7706153392791748, 'logits/chosen': -0.7858663201332092, 'epoch': 2.13}


 35%|███▌      | 5713/16104 [26:30:30<50:48:14, 17.60s/it]
{'loss': 0.6147, 'learning_rate': 1.4961049383301007e-06, 'rewards/chosen': -1.0487394332885742, 'rewards/rejected': -1.3931118249893188, 'rewards/accuracies': 0.75, 'rewards/margins': 0.34437239170074463, 'policy_logps/rejected': -479.57598876953125, 'policy_logps/chosen': -380.951416015625, 'referece_logps/rejected': -465.6448669433594, 'referece_logps/chosen': -370.46405029296875, 'logits/rejected': -0.3176575005054474, 'logits/chosen': -0.28156977891921997, 'epoch': 2.13}

 35%|███▌      | 5714/16104 [26:30:47<50:33:06, 17.52s/it]

 35%|███▌      | 5715/16104 [26:30:59<46:00:39, 15.94s/it]

 35%|███▌      | 5716/16104 [26:31:15<45:46:40, 15.86s/it]


 36%|███▌      | 5718/16104 [26:31:50<49:11:43, 17.05s/it]

 36%|███▌      | 5719/16104 [26:32:10<51:30:13, 17.85s/it]

 36%|███▌      | 5720/16104 [26:32:27<50:34:48, 17.54s/it]

 36%|███▌      | 5721/16104 [26:32:40<47:20:50, 16.42s/it]

 36%|███▌      | 5722/16104 [26:32:55<45:27:19, 15.76s/it]
{'loss': 0.6146, 'learning_rate': 1.494532452554608e-06, 'rewards/chosen': -0.8012723922729492, 'rewards/rejected': -1.15414297580719, 'rewards/accuracies': 0.75, 'rewards/margins': 0.35287052392959595, 'policy_logps/rejected': -419.5251770019531, 'policy_logps/chosen': -319.9840087890625, 'referece_logps/rejected': -407.9837341308594, 'referece_logps/chosen': -311.9712829589844, 'logits/rejected': -0.5254459381103516, 'logits/chosen': -0.41293829679489136, 'epoch': 2.13}


 36%|███▌      | 5724/16104 [26:33:16<37:57:31, 13.16s/it]

 36%|███▌      | 5725/16104 [26:33:38<45:24:07, 15.75s/it]

 36%|███▌      | 5726/16104 [26:33:50<42:23:55, 14.71s/it]

 36%|███▌      | 5727/16104 [26:34:10<46:45:54, 16.22s/it]

 36%|███▌      | 5728/16104 [26:34:30<50:42:57, 17.60s/it]

 36%|███▌      | 5729/16104 [26:34:48<50:33:49, 17.54s/it]

 36%|███▌      | 5730/16104 [26:35:10<54:21:41, 18.86s/it]
{'loss': 0.453, 'learning_rate': 1.4931333269399083e-06, 'rewards/chosen': -0.9638351798057556, 'rewards/rejected': -1.5715094804763794, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6076743006706238, 'policy_logps/rejected': -358.7666015625, 'policy_logps/chosen': -460.5484619140625, 'referece_logps/rejected': -343.051513671875, 'referece_logps/chosen': -450.9101257324219, 'logits/rejected': -0.6295015215873718, 'logits/chosen': -0.2942662835121155, 'epoch': 2.13}

 36%|███▌      | 5731/16104 [26:35:29<55:00:21, 19.09s/it]


 36%|███▌      | 5733/16104 [26:36:08<54:57:51, 19.08s/it]
{'loss': 0.5263, 'learning_rate': 1.4926083254957772e-06, 'rewards/chosen': -0.8692851066589355, 'rewards/rejected': -1.79308021068573, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9237948656082153, 'policy_logps/rejected': -522.431640625, 'policy_logps/chosen': -397.47552490234375, 'referece_logps/rejected': -504.5008544921875, 'referece_logps/chosen': -388.78265380859375, 'logits/rejected': -0.38082993030548096, 'logits/chosen': -0.21637757122516632, 'epoch': 2.14}


 36%|███▌      | 5735/16104 [26:36:40<51:04:36, 17.73s/it]

 36%|███▌      | 5736/16104 [26:37:01<53:18:25, 18.51s/it]

 36%|███▌      | 5737/16104 [26:37:16<50:37:02, 17.58s/it]

 36%|███▌      | 5738/16104 [26:37:36<52:39:23, 18.29s/it]
{'loss': 0.4889, 'learning_rate': 1.491732924645604e-06, 'rewards/chosen': -0.6375508904457092, 'rewards/rejected': -0.8969358205795288, 'rewards/accuracies': 0.5, 'rewards/margins': 0.25938504934310913, 'policy_logps/rejected': -336.38580322265625, 'policy_logps/chosen': -367.12994384765625, 'referece_logps/rejected': -327.41650390625, 'referece_logps/chosen': -360.75445556640625, 'logits/rejected': 0.24673092365264893, 'logits/chosen': 0.337653785943985, 'epoch': 2.14}

 36%|███▌      | 5739/16104 [26:37:58<55:26:12, 19.25s/it]


 36%|███▌      | 5741/16104 [26:38:26<47:26:46, 16.48s/it]

 36%|███▌      | 5742/16104 [26:38:44<48:41:43, 16.92s/it]
{'loss': 0.5485, 'learning_rate': 1.491032245876446e-06, 'rewards/chosen': -0.8172861933708191, 'rewards/rejected': -0.9531525373458862, 'rewards/accuracies': 0.625, 'rewards/margins': 0.13586635887622833, 'policy_logps/rejected': -317.6307067871094, 'policy_logps/chosen': -493.262451171875, 'referece_logps/rejected': -308.09918212890625, 'referece_logps/chosen': -485.0895690917969, 'logits/rejected': -0.21394221484661102, 'logits/chosen': -0.1824551373720169, 'epoch': 2.14}

 36%|███▌      | 5743/16104 [26:39:04<50:50:53, 17.67s/it]

 36%|███▌      | 5744/16104 [26:39:20<49:16:04, 17.12s/it]


 36%|███▌      | 5746/16104 [26:39:52<49:28:58, 17.20s/it]

 36%|███▌      | 5747/16104 [26:40:12<51:39:09, 17.95s/it]
{'loss': 0.5882, 'learning_rate': 1.4901559505477468e-06, 'rewards/chosen': -0.9916551113128662, 'rewards/rejected': -1.3224965333938599, 'rewards/accuracies': 0.75, 'rewards/margins': 0.33084142208099365, 'policy_logps/rejected': -400.16522216796875, 'policy_logps/chosen': -417.9400939941406, 'referece_logps/rejected': -386.9402770996094, 'referece_logps/chosen': -408.02349853515625, 'logits/rejected': -0.4008229374885559, 'logits/chosen': -0.48417189717292786, 'epoch': 2.14}


 36%|███▌      | 5749/16104 [26:40:45<50:18:25, 17.49s/it]

 36%|███▌      | 5750/16104 [26:41:00<48:40:15, 16.92s/it]

 36%|███▌      | 5751/16104 [26:41:20<51:17:22, 17.83s/it]

 36%|███▌      | 5752/16104 [26:41:36<49:52:37, 17.35s/it]

 36%|███▌      | 5753/16104 [26:41:49<45:59:12, 15.99s/it]
{'loss': 0.5577, 'learning_rate': 1.4891037419178464e-06, 'rewards/chosen': -0.45578593015670776, 'rewards/rejected': -1.7374719381332397, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2816858291625977, 'policy_logps/rejected': -327.5142517089844, 'policy_logps/chosen': -516.7495727539062, 'referece_logps/rejected': -310.1395568847656, 'referece_logps/chosen': -512.1917114257812, 'logits/rejected': -0.2323131114244461, 'logits/chosen': -0.360480397939682, 'epoch': 2.14}


 36%|███▌      | 5755/16104 [26:42:22<47:15:47, 16.44s/it]

 36%|███▌      | 5756/16104 [26:42:33<42:24:39, 14.75s/it]
{'loss': 0.5492, 'learning_rate': 1.4885773704080097e-06, 'rewards/chosen': -0.6502683162689209, 'rewards/rejected': -0.7290006279945374, 'rewards/accuracies': 0.375, 'rewards/margins': 0.07873238623142242, 'policy_logps/rejected': -349.1418762207031, 'policy_logps/chosen': -412.7305908203125, 'referece_logps/rejected': -341.85186767578125, 'referece_logps/chosen': -406.2279052734375, 'logits/rejected': -0.6516323089599609, 'logits/chosen': -0.6833747029304504, 'epoch': 2.14}

 36%|███▌      | 5757/16104 [26:42:56<49:27:57, 17.21s/it]


 36%|███▌      | 5759/16104 [26:43:20<42:20:15, 14.73s/it]

 36%|███▌      | 5760/16104 [26:43:33<40:30:34, 14.10s/it]

 36%|███▌      | 5761/16104 [26:43:54<46:34:58, 16.21s/it]
{'loss': 0.4016, 'learning_rate': 1.4876996893764267e-06, 'rewards/chosen': -0.8515275716781616, 'rewards/rejected': -1.7171622514724731, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8656347393989563, 'policy_logps/rejected': -375.1844482421875, 'policy_logps/chosen': -330.4452209472656, 'referece_logps/rejected': -358.0128173828125, 'referece_logps/chosen': -321.929931640625, 'logits/rejected': -0.9722490310668945, 'logits/chosen': -0.9742849469184875, 'epoch': 2.15}


 36%|███▌      | 5763/16104 [26:44:30<48:57:55, 17.05s/it]

 36%|███▌      | 5764/16104 [26:44:51<51:49:03, 18.04s/it]

 36%|███▌      | 5765/16104 [26:45:13<55:23:54, 19.29s/it]

 36%|███▌      | 5766/16104 [26:45:25<48:59:39, 17.06s/it]

 36%|███▌      | 5767/16104 [26:45:45<51:55:54, 18.09s/it]

 36%|███▌      | 5768/16104 [26:45:59<47:53:23, 16.68s/it]
{'loss': 0.629, 'learning_rate': 1.4864701075416388e-06, 'rewards/chosen': -0.9932270646095276, 'rewards/rejected': -1.679379940032959, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6861528754234314, 'policy_logps/rejected': -383.1850280761719, 'policy_logps/chosen': -383.3012390136719, 'referece_logps/rejected': -366.39117431640625, 'referece_logps/chosen': -373.36895751953125, 'logits/rejected': -0.33631598949432373, 'logits/chosen': -0.36784058809280396, 'epoch': 2.15}

 36%|███▌      | 5769/16104 [26:46:14<46:52:02, 16.33s/it]

 36%|███▌      | 5770/16104 [26:46:32<48:12:44, 16.80s/it]


 36%|███▌      | 5772/16104 [26:47:05<47:04:32, 16.40s/it]
{'loss': 0.539, 'learning_rate': 1.4857670562651539e-06, 'rewards/chosen': -1.4498958587646484, 'rewards/rejected': -2.6287410259246826, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1788450479507446, 'policy_logps/rejected': -393.5202331542969, 'policy_logps/chosen': -411.7947998046875, 'referece_logps/rejected': -367.2328186035156, 'referece_logps/chosen': -397.29583740234375, 'logits/rejected': -0.5678591132164001, 'logits/chosen': -0.5879026055335999, 'epoch': 2.15}


 36%|███▌      | 5774/16104 [26:47:40<47:55:15, 16.70s/it]

 36%|███▌      | 5775/16104 [26:47:57<47:57:17, 16.71s/it]

 36%|███▌      | 5776/16104 [26:48:17<50:18:02, 17.53s/it]

 36%|███▌      | 5777/16104 [26:48:36<51:33:43, 17.97s/it]

 36%|███▌      | 5778/16104 [26:48:53<51:15:45, 17.87s/it]

 36%|███▌      | 5779/16104 [26:49:05<46:24:55, 16.18s/it]
{'loss': 0.5232, 'learning_rate': 1.4845359602746355e-06, 'rewards/chosen': -0.8806564807891846, 'rewards/rejected': -1.63468337059021, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7540270090103149, 'policy_logps/rejected': -297.6253662109375, 'policy_logps/chosen': -300.63348388671875, 'referece_logps/rejected': -281.2785339355469, 'referece_logps/chosen': -291.826904296875, 'logits/rejected': -1.1666837930679321, 'logits/chosen': -1.1072165966033936, 'epoch': 2.15}


 36%|███▌      | 5781/16104 [26:49:31<41:00:12, 14.30s/it]
{'loss': 0.6519, 'learning_rate': 1.4841840420532272e-06, 'rewards/chosen': -0.9058508276939392, 'rewards/rejected': -1.3490196466445923, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4431688189506531, 'policy_logps/rejected': -389.0436706542969, 'policy_logps/chosen': -394.99090576171875, 'referece_logps/rejected': -375.553466796875, 'referece_logps/chosen': -385.93243408203125, 'logits/rejected': -1.1989821195602417, 'logits/chosen': -1.1978262662887573, 'epoch': 2.15}

 36%|███▌      | 5782/16104 [26:49:42<37:56:30, 13.23s/it]

 36%|███▌      | 5783/16104 [26:49:54<36:57:47, 12.89s/it]

 36%|███▌      | 5784/16104 [26:50:07<36:34:33, 12.76s/it]

 36%|███▌      | 5785/16104 [26:50:18<35:35:48, 12.42s/it]

 36%|███▌      | 5786/16104 [26:50:37<40:47:08, 14.23s/it]

 36%|███▌      | 5787/16104 [26:50:58<47:14:50, 16.49s/it]

 36%|███▌      | 5788/16104 [26:51:16<48:37:19, 16.97s/it]


 36%|███▌      | 5790/16104 [26:51:51<47:46:46, 16.68s/it]
{'loss': 0.497, 'learning_rate': 1.482599441366938e-06, 'rewards/chosen': -1.2797657251358032, 'rewards/rejected': -2.3198893070220947, 'rewards/accuracies': 0.75, 'rewards/margins': 1.040123462677002, 'policy_logps/rejected': -384.2405700683594, 'policy_logps/chosen': -478.3742980957031, 'referece_logps/rejected': -361.0416564941406, 'referece_logps/chosen': -465.5766906738281, 'logits/rejected': 0.08684854209423065, 'logits/chosen': 0.26575833559036255, 'epoch': 2.16}

 36%|███▌      | 5791/16104 [26:52:09<49:09:21, 17.16s/it]

 36%|███▌      | 5792/16104 [26:52:25<47:39:05, 16.64s/it]

 36%|███▌      | 5793/16104 [26:52:45<50:35:04, 17.66s/it]


 36%|███▌      | 5795/16104 [26:53:09<42:24:46, 14.81s/it]

 36%|███▌      | 5796/16104 [26:53:30<47:02:53, 16.43s/it]

 36%|███▌      | 5797/16104 [26:53:46<46:52:13, 16.37s/it]

 36%|███▌      | 5798/16104 [26:53:58<42:48:14, 14.95s/it]
{'loss': 0.6047, 'learning_rate': 1.4811895797657903e-06, 'rewards/chosen': -1.578213095664978, 'rewards/rejected': -1.3940705060958862, 'rewards/accuracies': 0.375, 'rewards/margins': -0.18414266407489777, 'policy_logps/rejected': -500.36572265625, 'policy_logps/chosen': -480.20880126953125, 'referece_logps/rejected': -486.42498779296875, 'referece_logps/chosen': -464.4266662597656, 'logits/rejected': -0.6781250834465027, 'logits/chosen': -0.4937651455402374, 'epoch': 2.16}

 36%|███▌      | 5799/16104 [26:54:17<46:57:46, 16.41s/it]

 36%|███▌      | 5800/16104 [26:54:31<44:42:54, 15.62s/it]


 36%|███▌      | 5802/16104 [26:55:00<43:37:21, 15.24s/it]
{'loss': 0.4386, 'learning_rate': 1.4804841815776114e-06, 'rewards/chosen': -1.0592477321624756, 'rewards/rejected': -2.6326279640197754, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5733802318572998, 'policy_logps/rejected': -347.9496765136719, 'policy_logps/chosen': -462.39678955078125, 'referece_logps/rejected': -321.6234130859375, 'referece_logps/chosen': -451.8043212890625, 'logits/rejected': -0.062418267130851746, 'logits/chosen': -0.12220614403486252, 'epoch': 2.16}

 36%|███▌      | 5803/16104 [26:55:18<46:19:07, 16.19s/it]


 36%|███▌      | 5805/16104 [26:55:51<46:16:12, 16.17s/it]
{'loss': 0.6461, 'learning_rate': 1.4799549288288656e-06, 'rewards/chosen': -0.6637136936187744, 'rewards/rejected': -0.9908416271209717, 'rewards/accuracies': 0.75, 'rewards/margins': 0.32712793350219727, 'policy_logps/rejected': -430.236083984375, 'policy_logps/chosen': -361.2029724121094, 'referece_logps/rejected': -420.3276672363281, 'referece_logps/chosen': -354.5658264160156, 'logits/rejected': -0.7595533132553101, 'logits/chosen': -0.40980949997901917, 'epoch': 2.16}

 36%|███▌      | 5806/16104 [26:56:03<42:10:54, 14.75s/it]

 36%|███▌      | 5807/16104 [26:56:17<41:50:04, 14.63s/it]

 36%|███▌      | 5808/16104 [26:56:37<46:24:17, 16.23s/it]


 36%|███▌      | 5810/16104 [26:57:06<42:37:11, 14.90s/it]
{'loss': 0.5671, 'learning_rate': 1.479072452708813e-06, 'rewards/chosen': -1.0903658866882324, 'rewards/rejected': -1.1116242408752441, 'rewards/accuracies': 0.375, 'rewards/margins': 0.021258331835269928, 'policy_logps/rejected': -257.8287658691406, 'policy_logps/chosen': -310.5693359375, 'referece_logps/rejected': -246.71249389648438, 'referece_logps/chosen': -299.6656799316406, 'logits/rejected': -0.6225829720497131, 'logits/chosen': -0.6231704354286194, 'epoch': 2.16}

 36%|███▌      | 5811/16104 [26:57:23<44:55:40, 15.71s/it]

 36%|███▌      | 5812/16104 [26:57:45<49:49:02, 17.43s/it]

 36%|███▌      | 5813/16104 [26:57:59<47:20:43, 16.56s/it]


 36%|███▌      | 5815/16104 [26:58:34<47:41:40, 16.69s/it]
{'loss': 0.4692, 'learning_rate': 1.4781894921054097e-06, 'rewards/chosen': -1.080655574798584, 'rewards/rejected': -1.8836369514465332, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8029813766479492, 'policy_logps/rejected': -271.94671630859375, 'policy_logps/chosen': -267.2951354980469, 'referece_logps/rejected': -253.1103515625, 'referece_logps/chosen': -256.48858642578125, 'logits/rejected': -0.5065224170684814, 'logits/chosen': -0.46815913915634155, 'epoch': 2.17}

 36%|███▌      | 5816/16104 [26:58:49<46:28:54, 16.26s/it]

 36%|███▌      | 5817/16104 [26:59:01<42:25:07, 14.84s/it]


 36%|███▌      | 5819/16104 [26:59:30<43:11:48, 15.12s/it]

 36%|███▌      | 5820/16104 [26:59:50<47:42:12, 16.70s/it]
{'loss': 0.4808, 'learning_rate': 1.4773060479115883e-06, 'rewards/chosen': -0.6296210289001465, 'rewards/rejected': -1.9187933206558228, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2891722917556763, 'policy_logps/rejected': -339.8924560546875, 'policy_logps/chosen': -361.42755126953125, 'referece_logps/rejected': -320.70452880859375, 'referece_logps/chosen': -355.13134765625, 'logits/rejected': -0.604477047920227, 'logits/chosen': -0.4722720682621002, 'epoch': 2.17}


 36%|███▌      | 5822/16104 [27:00:16<41:50:51, 14.65s/it]

 36%|███▌      | 5823/16104 [27:00:34<44:49:08, 15.69s/it]

 36%|███▌      | 5824/16104 [27:00:50<45:28:17, 15.92s/it]
{'loss': 0.4747, 'learning_rate': 1.4765989449717937e-06, 'rewards/chosen': -0.7890427112579346, 'rewards/rejected': -1.357130765914917, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5680880546569824, 'policy_logps/rejected': -357.8092041015625, 'policy_logps/chosen': -375.8125305175781, 'referece_logps/rejected': -344.2379150390625, 'referece_logps/chosen': -367.9220886230469, 'logits/rejected': 0.18485888838768005, 'logits/chosen': 0.17293381690979004, 'epoch': 2.17}

 36%|███▌      | 5825/16104 [27:01:05<44:08:30, 15.46s/it]

 36%|███▌      | 5826/16104 [27:01:23<46:07:46, 16.16s/it]


 36%|███▌      | 5828/16104 [27:02:02<51:02:01, 17.88s/it]

 36%|███▌      | 5829/16104 [27:02:20<51:28:31, 18.04s/it]
{'loss': 0.4467, 'learning_rate': 1.4757146325669723e-06, 'rewards/chosen': -1.0273164510726929, 'rewards/rejected': -1.7626081705093384, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7352916598320007, 'policy_logps/rejected': -351.9419250488281, 'policy_logps/chosen': -428.1453552246094, 'referece_logps/rejected': -334.31585693359375, 'referece_logps/chosen': -417.8721618652344, 'logits/rejected': -0.5027642250061035, 'logits/chosen': -0.7557684779167175, 'epoch': 2.17}

 36%|███▌      | 5830/16104 [27:02:40<52:45:48, 18.49s/it]

 36%|███▌      | 5831/16104 [27:03:00<53:48:45, 18.86s/it]


 36%|███▌      | 5833/16104 [27:03:23<43:10:39, 15.13s/it]
{'loss': 0.5659, 'learning_rate': 1.4750068362170961e-06, 'rewards/chosen': -0.748038113117218, 'rewards/rejected': -0.9346486330032349, 'rewards/accuracies': 0.375, 'rewards/margins': 0.18661057949066162, 'policy_logps/rejected': -381.4128723144531, 'policy_logps/chosen': -373.2216796875, 'referece_logps/rejected': -372.0663757324219, 'referece_logps/chosen': -365.74127197265625, 'logits/rejected': 1.0142216682434082, 'logits/chosen': 0.953685998916626, 'epoch': 2.17}

 36%|███▌      | 5834/16104 [27:03:39<44:06:49, 15.46s/it]

 36%|███▌      | 5835/16104 [27:03:53<43:14:14, 15.16s/it]

 36%|███▌      | 5836/16104 [27:04:07<41:57:04, 14.71s/it]

 36%|███▌      | 5837/16104 [27:04:20<40:25:22, 14.17s/it]

 36%|███▋      | 5838/16104 [27:04:39<44:29:22, 15.60s/it]

 36%|███▋      | 5839/16104 [27:04:49<40:13:58, 14.11s/it]

 36%|███▋      | 5840/16104 [27:05:10<45:43:42, 16.04s/it]


 36%|███▋      | 5842/16104 [27:05:38<42:40:20, 14.97s/it]
{'loss': 0.3847, 'learning_rate': 1.473413171058011e-06, 'rewards/chosen': -1.3301355838775635, 'rewards/rejected': -2.958993911743164, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6288585662841797, 'policy_logps/rejected': -354.18829345703125, 'policy_logps/chosen': -487.10626220703125, 'referece_logps/rejected': -324.5982971191406, 'referece_logps/chosen': -473.804931640625, 'logits/rejected': -0.5882600545883179, 'logits/chosen': -0.6129356622695923, 'epoch': 2.18}

 36%|███▋      | 5843/16104 [27:05:58<46:35:00, 16.34s/it]

 36%|███▋      | 5844/16104 [27:06:13<45:27:16, 15.95s/it]

 36%|███▋      | 5845/16104 [27:06:30<45:59:42, 16.14s/it]

 36%|███▋      | 5846/16104 [27:06:49<48:59:11, 17.19s/it]

 36%|███▋      | 5847/16104 [27:07:07<49:43:15, 17.45s/it]

 36%|███▋      | 5848/16104 [27:07:27<51:41:17, 18.14s/it]

 36%|███▋      | 5849/16104 [27:07:44<50:18:50, 17.66s/it]

 36%|███▋      | 5850/16104 [27:07:56<45:49:12, 16.09s/it]


 36%|███▋      | 5852/16104 [27:08:26<43:23:08, 15.23s/it]
{'loss': 0.4286, 'learning_rate': 1.4716406129311306e-06, 'rewards/chosen': -0.9257619976997375, 'rewards/rejected': -1.8764162063598633, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9506543278694153, 'policy_logps/rejected': -302.71649169921875, 'policy_logps/chosen': -269.7093811035156, 'referece_logps/rejected': -283.95233154296875, 'referece_logps/chosen': -260.4517517089844, 'logits/rejected': -0.9074476957321167, 'logits/chosen': -0.8594115972518921, 'epoch': 2.18}

 36%|███▋      | 5853/16104 [27:08:42<43:20:34, 15.22s/it]

 36%|███▋      | 5854/16104 [27:08:54<40:45:03, 14.31s/it]

 36%|███▋      | 5855/16104 [27:09:07<40:04:36, 14.08s/it]


 36%|███▋      | 5857/16104 [27:09:32<37:42:31, 13.25s/it]
{'loss': 0.5151, 'learning_rate': 1.4707536179680665e-06, 'rewards/chosen': -0.36922895908355713, 'rewards/rejected': -1.2286851406097412, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8594561219215393, 'policy_logps/rejected': -330.549072265625, 'policy_logps/chosen': -368.0932312011719, 'referece_logps/rejected': -318.26220703125, 'referece_logps/chosen': -364.40093994140625, 'logits/rejected': 0.22235266864299774, 'logits/chosen': 0.17961160838603973, 'epoch': 2.18}

 36%|███▋      | 5858/16104 [27:09:44<36:00:17, 12.65s/it]


 36%|███▋      | 5860/16104 [27:10:09<35:46:51, 12.57s/it]

 36%|███▋      | 5861/16104 [27:10:20<35:03:06, 12.32s/it]
{'loss': 0.68, 'learning_rate': 1.4700436791837401e-06, 'rewards/chosen': -1.1141096353530884, 'rewards/rejected': -1.2087891101837158, 'rewards/accuracies': 0.625, 'rewards/margins': 0.09467953443527222, 'policy_logps/rejected': -409.5017395019531, 'policy_logps/chosen': -265.9730529785156, 'referece_logps/rejected': -397.4138488769531, 'referece_logps/chosen': -254.8319854736328, 'logits/rejected': -0.8903436064720154, 'logits/chosen': -0.8078526258468628, 'epoch': 2.18}

 36%|███▋      | 5862/16104 [27:10:38<39:51:53, 14.01s/it]

 36%|███▋      | 5863/16104 [27:10:58<44:56:08, 15.80s/it]

 36%|███▋      | 5864/16104 [27:11:18<48:11:08, 16.94s/it]

 36%|███▋      | 5865/16104 [27:11:32<45:28:10, 15.99s/it]

 36%|███▋      | 5866/16104 [27:11:51<48:37:12, 17.10s/it]


 36%|███▋      | 5868/16104 [27:12:25<48:41:22, 17.12s/it]
{'loss': 0.5846, 'learning_rate': 1.4688005545446641e-06, 'rewards/chosen': -0.6202894449234009, 'rewards/rejected': -1.817594289779663, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1973049640655518, 'policy_logps/rejected': -356.21771240234375, 'policy_logps/chosen': -394.3089294433594, 'referece_logps/rejected': -338.0417785644531, 'referece_logps/chosen': -388.1060485839844, 'logits/rejected': -0.4847577214241028, 'logits/chosen': -0.5667253732681274, 'epoch': 2.19}

 36%|███▋      | 5869/16104 [27:12:39<45:35:00, 16.03s/it]

 36%|███▋      | 5870/16104 [27:12:58<48:42:09, 17.13s/it]


 36%|███▋      | 5872/16104 [27:13:33<48:46:17, 17.16s/it]
{'loss': 0.4788, 'learning_rate': 1.4680897802459796e-06, 'rewards/chosen': -0.8767625689506531, 'rewards/rejected': -1.5572879314422607, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6805252432823181, 'policy_logps/rejected': -542.051513671875, 'policy_logps/chosen': -481.2325744628906, 'referece_logps/rejected': -526.4786987304688, 'referece_logps/chosen': -472.4649353027344, 'logits/rejected': -0.6575204133987427, 'logits/chosen': -0.5821004509925842, 'epoch': 2.19}


 36%|███▋      | 5874/16104 [27:14:05<47:59:44, 16.89s/it]

 36%|███▋      | 5875/16104 [27:14:25<50:16:59, 17.70s/it]
{'loss': 0.5421, 'learning_rate': 1.467556500678608e-06, 'rewards/chosen': -1.0722520351409912, 'rewards/rejected': -2.212742805480957, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1404907703399658, 'policy_logps/rejected': -324.1600341796875, 'policy_logps/chosen': -339.3629150390625, 'referece_logps/rejected': -302.0325927734375, 'referece_logps/chosen': -328.640380859375, 'logits/rejected': -0.455722838640213, 'logits/chosen': -0.4916858673095703, 'epoch': 2.19}


 36%|███▋      | 5877/16104 [27:14:59<48:37:21, 17.12s/it]
{'loss': 0.5754, 'learning_rate': 1.4672008863875685e-06, 'rewards/chosen': -0.9090892672538757, 'rewards/rejected': -1.043166160583496, 'rewards/accuracies': 0.25, 'rewards/margins': 0.1340770423412323, 'policy_logps/rejected': -219.3878631591797, 'policy_logps/chosen': -278.2288818359375, 'referece_logps/rejected': -208.95619201660156, 'referece_logps/chosen': -269.1379699707031, 'logits/rejected': -0.9046175479888916, 'logits/chosen': -1.0292258262634277, 'epoch': 2.19}

 37%|███▋      | 5878/16104 [27:15:16<48:41:31, 17.14s/it]

 37%|███▋      | 5879/16104 [27:15:34<48:40:09, 17.14s/it]

 37%|███▋      | 5880/16104 [27:15:48<46:40:46, 16.44s/it]

 37%|███▋      | 5881/16104 [27:16:04<46:21:05, 16.32s/it]


 37%|███▋      | 5883/16104 [27:16:37<45:01:12, 15.86s/it]
{'loss': 0.4691, 'learning_rate': 1.4661335901660495e-06, 'rewards/chosen': -0.8597507476806641, 'rewards/rejected': -2.1158347129821777, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2560839653015137, 'policy_logps/rejected': -269.0705871582031, 'policy_logps/chosen': -307.57586669921875, 'referece_logps/rejected': -247.9122314453125, 'referece_logps/chosen': -298.9783935546875, 'logits/rejected': -1.0501495599746704, 'logits/chosen': -1.0130077600479126, 'epoch': 2.19}


 37%|███▋      | 5885/16104 [27:17:11<47:28:09, 16.72s/it]
{'loss': 0.4918, 'learning_rate': 1.4657776738346277e-06, 'rewards/chosen': -1.2073473930358887, 'rewards/rejected': -2.206064462661743, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9987168908119202, 'policy_logps/rejected': -380.27435302734375, 'policy_logps/chosen': -467.9957275390625, 'referece_logps/rejected': -358.2137145996094, 'referece_logps/chosen': -455.9222717285156, 'logits/rejected': -1.147277593612671, 'logits/chosen': -0.9954378604888916, 'epoch': 2.19}

 37%|███▋      | 5886/16104 [27:17:30<48:46:14, 17.18s/it]

 37%|███▋      | 5887/16104 [27:17:44<45:57:29, 16.19s/it]

 37%|███▋      | 5888/16104 [27:18:00<45:58:16, 16.20s/it]


 37%|███▋      | 5890/16104 [27:18:31<46:22:02, 16.34s/it]
{'loss': 0.5142, 'learning_rate': 1.4648875534051676e-06, 'rewards/chosen': -1.01984703540802, 'rewards/rejected': -2.2009785175323486, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1811316013336182, 'policy_logps/rejected': -306.4973449707031, 'policy_logps/chosen': -365.76568603515625, 'referece_logps/rejected': -284.487548828125, 'referece_logps/chosen': -355.5672302246094, 'logits/rejected': -1.1037755012512207, 'logits/chosen': -1.1856290102005005, 'epoch': 2.19}

 37%|███▋      | 5891/16104 [27:18:46<45:02:53, 15.88s/it]

 37%|███▋      | 5892/16104 [27:19:03<45:46:34, 16.14s/it]


 37%|███▋      | 5894/16104 [27:19:33<43:07:19, 15.20s/it]
{'loss': 0.5885, 'learning_rate': 1.4641751185188427e-06, 'rewards/chosen': -0.8812476992607117, 'rewards/rejected': -1.3762929439544678, 'rewards/accuracies': 0.5, 'rewards/margins': 0.49504533410072327, 'policy_logps/rejected': -274.5760803222656, 'policy_logps/chosen': -281.70526123046875, 'referece_logps/rejected': -260.81317138671875, 'referece_logps/chosen': -272.8927917480469, 'logits/rejected': -0.5273511409759521, 'logits/chosen': -0.5707895755767822, 'epoch': 2.2}

 37%|███▋      | 5895/16104 [27:19:44<39:41:17, 14.00s/it]


 37%|███▋      | 5897/16104 [27:20:19<45:41:07, 16.11s/it]
{'loss': 0.5077, 'learning_rate': 1.4636405951734103e-06, 'rewards/chosen': -1.257571816444397, 'rewards/rejected': -2.0170109272003174, 'rewards/accuracies': 0.625, 'rewards/margins': 0.75943922996521, 'policy_logps/rejected': -274.85662841796875, 'policy_logps/chosen': -511.6723327636719, 'referece_logps/rejected': -254.6864776611328, 'referece_logps/chosen': -499.09661865234375, 'logits/rejected': -0.7913084030151367, 'logits/chosen': -0.9899179935455322, 'epoch': 2.2}

 37%|███▋      | 5898/16104 [27:20:33<43:23:32, 15.31s/it]

 37%|███▋      | 5899/16104 [27:20:45<40:29:30, 14.28s/it]

 37%|███▋      | 5900/16104 [27:20:58<40:09:01, 14.17s/it]

 37%|███▋      | 5901/16104 [27:21:21<47:18:28, 16.69s/it]


 37%|███▋      | 5903/16104 [27:21:57<49:42:45, 17.54s/it]
{'loss': 0.4987, 'learning_rate': 1.4625710422898076e-06, 'rewards/chosen': -0.6648160219192505, 'rewards/rejected': -1.3265215158462524, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6617055535316467, 'policy_logps/rejected': -259.66351318359375, 'policy_logps/chosen': -375.49664306640625, 'referece_logps/rejected': -246.39828491210938, 'referece_logps/chosen': -368.8485107421875, 'logits/rejected': -0.6944112181663513, 'logits/chosen': -0.7255272269248962, 'epoch': 2.2}


 37%|███▋      | 5905/16104 [27:22:36<52:17:58, 18.46s/it]

 37%|███▋      | 5906/16104 [27:22:56<53:32:24, 18.90s/it]
{'loss': 0.5047, 'learning_rate': 1.462036013141025e-06, 'rewards/chosen': -0.9395712018013, 'rewards/rejected': -1.8183326721191406, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8787615299224854, 'policy_logps/rejected': -452.21954345703125, 'policy_logps/chosen': -430.3711242675781, 'referece_logps/rejected': -434.0362243652344, 'referece_logps/chosen': -420.97540283203125, 'logits/rejected': -0.3641105592250824, 'logits/chosen': -0.22498434782028198, 'epoch': 2.2}

 37%|███▋      | 5907/16104 [27:23:15<54:03:49, 19.09s/it]

 37%|███▋      | 5908/16104 [27:23:28<48:54:35, 17.27s/it]

 37%|███▋      | 5909/16104 [27:23:48<51:23:41, 18.15s/it]

 37%|███▋      | 5910/16104 [27:24:06<50:47:20, 17.94s/it]

 37%|███▋      | 5911/16104 [27:24:24<50:38:00, 17.88s/it]

 37%|███▋      | 5912/16104 [27:24:39<48:42:55, 17.21s/it]


 37%|███▋      | 5914/16104 [27:25:16<50:14:51, 17.75s/it]
{'loss': 0.5537, 'learning_rate': 1.460608446905562e-06, 'rewards/chosen': -1.5716464519500732, 'rewards/rejected': -2.119802951812744, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5481562614440918, 'policy_logps/rejected': -411.19537353515625, 'policy_logps/chosen': -328.42095947265625, 'referece_logps/rejected': -389.9973449707031, 'referece_logps/chosen': -312.7044677734375, 'logits/rejected': -0.7222270965576172, 'logits/chosen': -0.6147680282592773, 'epoch': 2.2}

 37%|███▋      | 5915/16104 [27:25:35<51:40:54, 18.26s/it]

 37%|███▋      | 5916/16104 [27:25:50<49:00:22, 17.32s/it]

 37%|███▋      | 5917/16104 [27:26:10<51:06:22, 18.06s/it]

 37%|███▋      | 5918/16104 [27:26:27<49:52:19, 17.63s/it]

 37%|███▋      | 5919/16104 [27:26:46<50:43:45, 17.93s/it]

 37%|███▋      | 5920/16104 [27:27:05<51:59:09, 18.38s/it]

 37%|███▋      | 5921/16104 [27:27:18<47:09:46, 16.67s/it]

 37%|███▋      | 5922/16104 [27:27:34<46:48:44, 16.55s/it]

 37%|███▋      | 5923/16104 [27:27:54<49:40:16, 17.56s/it]

 37%|███▋      | 5924/16104 [27:28:14<51:45:08, 18.30s/it]

 37%|███▋      | 5925/16104 [27:28:31<51:11:05, 18.10s/it]

 37%|███▋      | 5926/16104 [27:28:47<48:41:29, 17.22s/it]

 37%|███▋      | 5927/16104 [27:29:04<48:39:33, 17.21s/it]

 37%|███▋      | 5928/16104 [27:29:16<44:24:07, 15.71s/it]

 37%|███▋      | 5929/16104 [27:29:35<46:44:59, 16.54s/it]

 37%|███▋      | 5930/16104 [27:29:54<49:10:59, 17.40s/it]

 37%|███▋      | 5931/16104 [27:30:12<49:44:15, 17.60s/it]


 37%|███▋      | 5933/16104 [27:30:50<52:01:20, 18.41s/it]
{'loss': 0.5254, 'learning_rate': 1.4572132046732786e-06, 'rewards/chosen': -1.079895257949829, 'rewards/rejected': -2.1733644008636475, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0934690237045288, 'policy_logps/rejected': -412.94097900390625, 'policy_logps/chosen': -339.885009765625, 'referece_logps/rejected': -391.20733642578125, 'referece_logps/chosen': -329.0860900878906, 'logits/rejected': -0.8746172189712524, 'logits/chosen': -0.9792740345001221, 'epoch': 2.21}

 37%|███▋      | 5934/16104 [27:31:10<53:04:40, 18.79s/it]

 37%|███▋      | 5935/16104 [27:31:31<55:02:12, 19.48s/it]

 37%|███▋      | 5936/16104 [27:31:51<55:08:51, 19.53s/it]

 37%|███▋      | 5937/16104 [27:32:05<50:27:50, 17.87s/it]

 37%|███▋      | 5938/16104 [27:32:17<45:36:16, 16.15s/it]

 37%|███▋      | 5939/16104 [27:32:32<44:40:56, 15.82s/it]

 37%|███▋      | 5940/16104 [27:32:51<47:10:25, 16.71s/it]

 37%|███▋      | 5941/16104 [27:33:01<42:10:29, 14.94s/it]

 37%|███▋      | 5942/16104 [27:33:17<42:20:43, 15.00s/it]

 37%|███▋      | 5943/16104 [27:33:32<42:42:22, 15.13s/it]

 37%|███▋      | 5944/16104 [27:33:44<40:22:44, 14.31s/it]

 37%|███▋      | 5945/16104 [27:34:04<45:12:58, 16.02s/it]

 37%|███▋      | 5946/16104 [27:34:24<48:30:40, 17.19s/it]


 37%|███▋      | 5948/16104 [27:35:01<49:32:22, 17.56s/it]
{'loss': 0.5842, 'learning_rate': 1.4545280315760374e-06, 'rewards/chosen': -0.989068329334259, 'rewards/rejected': -1.2757799625396729, 'rewards/accuracies': 0.75, 'rewards/margins': 0.28671157360076904, 'policy_logps/rejected': -381.36822509765625, 'policy_logps/chosen': -484.24285888671875, 'referece_logps/rejected': -368.6103820800781, 'referece_logps/chosen': -474.3521728515625, 'logits/rejected': -0.6902076601982117, 'logits/chosen': -0.9031476974487305, 'epoch': 2.22}

 37%|███▋      | 5949/16104 [27:35:12<44:04:52, 15.63s/it]

 37%|███▋      | 5950/16104 [27:35:23<40:16:32, 14.28s/it]

 37%|███▋      | 5951/16104 [27:35:42<44:38:53, 15.83s/it]

 37%|███▋      | 5952/16104 [27:36:01<47:15:59, 16.76s/it]

 37%|███▋      | 5953/16104 [27:36:18<47:03:13, 16.69s/it]

 37%|███▋      | 5954/16104 [27:36:36<48:08:32, 17.08s/it]


 37%|███▋      | 5956/16104 [27:37:02<41:47:04, 14.82s/it]

 37%|███▋      | 5957/16104 [27:37:16<40:45:06, 14.46s/it]

 37%|███▋      | 5958/16104 [27:37:31<41:54:13, 14.87s/it]

 37%|███▋      | 5959/16104 [27:37:50<45:26:44, 16.13s/it]

 37%|███▋      | 5960/16104 [27:38:07<45:43:23, 16.23s/it]

 37%|███▋      | 5961/16104 [27:38:21<43:52:08, 15.57s/it]

 37%|███▋      | 5962/16104 [27:38:40<47:09:39, 16.74s/it]

 37%|███▋      | 5963/16104 [27:39:00<49:24:26, 17.54s/it]

 37%|███▋      | 5964/16104 [27:39:16<48:03:36, 17.06s/it]

 37%|███▋      | 5965/16104 [27:39:35<49:43:07, 17.65s/it]

 37%|███▋      | 5966/16104 [27:39:56<52:40:47, 18.71s/it]

 37%|███▋      | 5967/16104 [27:40:16<54:03:49, 19.20s/it]

 37%|███▋      | 5968/16104 [27:40:30<49:12:34, 17.48s/it]

 37%|███▋      | 5969/16104 [27:40:50<51:40:54, 18.36s/it]

 37%|███▋      | 5970/16104 [27:41:01<45:26:07, 16.14s/it]

 37%|███▋      | 5971/16104 [27:41:14<42:49:04, 15.21s/it]

 37%|███▋      | 5972/16104 [27:41:26<39:51:54, 14.16s/it]

 37%|███▋      | 5973/16104 [27:41:42<41:42:33, 14.82s/it]

 37%|███▋      | 5974/16104 [27:41:54<39:04:50, 13.89s/it]

 37%|███▋      | 5975/16104 [27:42:11<41:30:02, 14.75s/it]

 37%|███▋      | 5976/16104 [27:42:26<41:33:49, 14.77s/it]

 37%|███▋      | 5977/16104 [27:42:46<46:02:11, 16.37s/it]

 37%|███▋      | 5978/16104 [27:43:06<49:02:52, 17.44s/it]

 37%|███▋      | 5979/16104 [27:43:26<51:09:42, 18.19s/it]

 37%|███▋      | 5980/16104 [27:43:38<46:02:00, 16.37s/it]

 37%|███▋      | 5981/16104 [27:43:59<50:13:49, 17.86s/it]

 37%|███▋      | 5982/16104 [27:44:16<49:12:37, 17.50s/it]

 37%|███▋      | 5983/16104 [27:44:28<44:45:05, 15.92s/it]

 37%|███▋      | 5984/16104 [27:44:44<45:13:55, 16.09s/it]

 37%|███▋      | 5985/16104 [27:45:04<48:25:50, 17.23s/it]

 37%|███▋      | 5986/16104 [27:45:24<50:40:08, 18.03s/it]

 37%|███▋      | 5987/16104 [27:45:42<50:33:07, 17.99s/it]

 37%|███▋      | 5988/16104 [27:46:00<50:35:15, 18.00s/it]

 37%|███▋      | 5989/16104 [27:46:16<49:04:44, 17.47s/it]

 37%|███▋      | 5990/16104 [27:46:33<48:06:20, 17.12s/it]

 37%|███▋      | 5991/16104 [27:46:54<51:28:06, 18.32s/it]

 37%|███▋      | 5992/16104 [27:47:06<46:26:10, 16.53s/it]

 37%|███▋      | 5993/16104 [27:47:25<48:44:13, 17.35s/it]

 37%|███▋      | 5994/16104 [27:47:46<51:13:29, 18.24s/it]

 37%|███▋      | 5995/16104 [27:48:02<49:54:04, 17.77s/it]

 37%|███▋      | 5996/16104 [27:48:24<53:23:33, 19.02s/it]

 37%|███▋      | 5997/16104 [27:48:41<51:49:10, 18.46s/it]

 37%|███▋      | 5998/16104 [27:48:55<47:44:28, 17.01s/it]

 37%|███▋      | 5999/16104 [27:49:08<44:39:07, 15.91s/it]

 37%|███▋      | 6000/16104 [27:49:19<40:15:34, 14.34s/it]

 37%|███▋      | 6001/16104 [27:49:54<57:08:41, 20.36s/it]

 37%|███▋      | 6002/16104 [27:50:14<57:08:01, 20.36s/it]

 37%|███▋      | 6003/16104 [27:50:34<56:56:56, 20.30s/it]

 37%|███▋      | 6004/16104 [27:50:56<58:28:45, 20.84s/it]

 37%|███▋      | 6005/16104 [27:51:13<55:09:21, 19.66s/it]

 37%|███▋      | 6006/16104 [27:51:29<52:14:35, 18.63s/it]

 37%|███▋      | 6007/16104 [27:51:44<48:49:04, 17.41s/it]

 37%|███▋      | 6008/16104 [27:52:03<49:53:15, 17.79s/it]

 37%|███▋      | 6009/16104 [27:52:22<51:33:54, 18.39s/it]

 37%|███▋      | 6010/16104 [27:52:40<51:07:52, 18.24s/it]

 37%|███▋      | 6011/16104 [27:52:55<48:10:21, 17.18s/it]

 37%|███▋      | 6012/16104 [27:53:14<49:46:18, 17.75s/it]

 37%|███▋      | 6013/16104 [27:53:34<51:30:06, 18.37s/it]

 37%|███▋      | 6014/16104 [27:53:50<49:55:42, 17.81s/it]

 37%|███▋      | 6015/16104 [27:54:10<51:13:35, 18.28s/it]

 37%|███▋      | 6016/16104 [27:54:29<52:24:38, 18.70s/it]

 37%|███▋      | 6017/16104 [27:54:42<47:15:53, 16.87s/it]

 37%|███▋      | 6018/16104 [27:54:53<42:12:42, 15.07s/it]

 37%|███▋      | 6019/16104 [27:55:12<45:23:31, 16.20s/it]

 37%|███▋      | 6020/16104 [27:55:33<49:47:08, 17.77s/it]

 37%|███▋      | 6021/16104 [27:55:48<47:41:02, 17.02s/it]

 37%|███▋      | 6022/16104 [27:56:10<51:10:12, 18.27s/it]

 37%|███▋      | 6023/16104 [27:56:27<50:22:03, 17.99s/it]

 37%|███▋      | 6024/16104 [27:56:43<48:37:10, 17.36s/it]

 37%|███▋      | 6025/16104 [27:56:56<45:09:17, 16.13s/it]

 37%|███▋      | 6026/16104 [27:57:14<46:29:43, 16.61s/it]

 37%|███▋      | 6027/16104 [27:57:26<42:51:20, 15.31s/it]

 37%|███▋      | 6028/16104 [27:57:46<46:27:04, 16.60s/it]

 37%|███▋      | 6029/16104 [27:58:04<47:40:46, 17.04s/it]

 37%|███▋      | 6030/16104 [27:58:25<50:55:51, 18.20s/it]

 37%|███▋      | 6031/16104 [27:58:38<46:31:06, 16.63s/it]

 37%|███▋      | 6032/16104 [27:58:52<44:28:56, 15.90s/it]

 37%|███▋      | 6033/16104 [27:59:05<42:18:41, 15.12s/it]

 37%|███▋      | 6034/16104 [27:59:25<46:01:36, 16.45s/it]

 37%|███▋      | 6035/16104 [27:59:36<41:39:43, 14.90s/it]

 37%|███▋      | 6036/16104 [27:59:51<41:53:53, 14.98s/it]

 37%|███▋      | 6037/16104 [28:00:11<45:38:51, 16.32s/it]

 37%|███▋      | 6038/16104 [28:00:30<48:31:31, 17.35s/it]

 38%|███▊      | 6039/16104 [28:00:50<50:28:35, 18.05s/it]

 38%|███▊      | 6040/16104 [28:01:09<51:16:06, 18.34s/it]

 38%|███▊      | 6041/16104 [28:01:24<48:05:52, 17.21s/it]

 38%|███▊      | 6042/16104 [28:01:35<42:59:38, 15.38s/it]

 38%|███▊      | 6043/16104 [28:01:46<39:13:46, 14.04s/it]

 38%|███▊      | 6044/16104 [28:01:56<36:20:03, 13.00s/it]

 38%|███▊      | 6045/16104 [28:02:12<38:42:25, 13.85s/it]

 38%|███▊      | 6046/16104 [28:02:27<39:41:50, 14.21s/it]

 38%|███▊      | 6047/16104 [28:02:44<42:05:39, 15.07s/it]

 38%|███▊      | 6048/16104 [28:03:04<45:45:35, 16.38s/it]

 38%|███▊      | 6049/16104 [28:03:23<48:32:20, 17.38s/it]

 38%|███▊      | 6050/16104 [28:03:34<43:17:58, 15.50s/it]
{'loss': 0.4909, 'learning_rate': 1.4361603998159387e-06, 'rewards/chosen': -0.8232129812240601, 'rewards/rejected': -1.1130754947662354, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2898625433444977, 'policy_logps/rejected': -366.1734619140625, 'policy_logps/chosen': -324.02777099609375, 'referece_logps/rejected': -355.042724609375, 'referece_logps/chosen': -315.7956237792969, 'logits/rejected': -1.0439919233322144, 'logits/chosen': -1.1337642669677734, 'epoch': 2.25}


 38%|███▊      | 6052/16104 [28:04:11<46:59:52, 16.83s/it]

 38%|███▊      | 6053/16104 [28:04:30<48:40:17, 17.43s/it]

 38%|███▊      | 6054/16104 [28:04:46<47:19:31, 16.95s/it]

 38%|███▊      | 6055/16104 [28:05:06<49:32:12, 17.75s/it]
{'loss': 0.4892, 'learning_rate': 1.4352552429190982e-06, 'rewards/chosen': -1.5598008632659912, 'rewards/rejected': -1.9500095844268799, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3902086019515991, 'policy_logps/rejected': -417.00872802734375, 'policy_logps/chosen': -317.411376953125, 'referece_logps/rejected': -397.5086364746094, 'referece_logps/chosen': -301.8133544921875, 'logits/rejected': -0.8815711736679077, 'logits/chosen': -0.8583056330680847, 'epoch': 2.26}

 38%|███▊      | 6056/16104 [28:05:21<47:33:07, 17.04s/it]


 38%|███▊      | 6058/16104 [28:05:46<41:11:59, 14.76s/it]
{'loss': 0.5152, 'learning_rate': 1.4347119374401929e-06, 'rewards/chosen': -1.214748740196228, 'rewards/rejected': -2.1047375202178955, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8899887800216675, 'policy_logps/rejected': -461.75, 'policy_logps/chosen': -341.4178466796875, 'referece_logps/rejected': -440.70257568359375, 'referece_logps/chosen': -329.2703857421875, 'logits/rejected': -0.8740792274475098, 'logits/chosen': -0.7187314033508301, 'epoch': 2.26}


 38%|███▊      | 6060/16104 [28:06:24<47:48:11, 17.13s/it]

 38%|███▊      | 6061/16104 [28:06:40<46:34:01, 16.69s/it]

 38%|███▊      | 6062/16104 [28:06:57<46:49:57, 16.79s/it]

 38%|███▊      | 6063/16104 [28:07:13<46:05:27, 16.52s/it]

 38%|███▊      | 6064/16104 [28:07:28<45:21:07, 16.26s/it]
{'loss': 0.4889, 'learning_rate': 1.433624851888664e-06, 'rewards/chosen': -0.40155068039894104, 'rewards/rejected': -2.606766939163208, 'rewards/accuracies': 0.875, 'rewards/margins': 2.205216646194458, 'policy_logps/rejected': -405.8559875488281, 'policy_logps/chosen': -439.604248046875, 'referece_logps/rejected': -379.7882995605469, 'referece_logps/chosen': -435.5887451171875, 'logits/rejected': -0.0026478655636310577, 'logits/chosen': -0.054417435079813004, 'epoch': 2.26}


 38%|███▊      | 6066/16104 [28:07:57<42:13:06, 15.14s/it]

 38%|███▊      | 6067/16104 [28:08:12<42:03:00, 15.08s/it]

 38%|███▊      | 6068/16104 [28:08:26<41:54:08, 15.03s/it]

 38%|███▊      | 6069/16104 [28:08:42<42:36:11, 15.28s/it]

 38%|███▊      | 6070/16104 [28:09:02<46:09:10, 16.56s/it]

 38%|███▊      | 6071/16104 [28:09:24<50:59:38, 18.30s/it]

 38%|███▊      | 6072/16104 [28:09:37<46:45:56, 16.78s/it]

 38%|███▊      | 6073/16104 [28:09:58<50:17:01, 18.05s/it]
{'loss': 0.5028, 'learning_rate': 1.4319930400457887e-06, 'rewards/chosen': -1.042426586151123, 'rewards/rejected': -1.9832855463027954, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9408589601516724, 'policy_logps/rejected': -296.47528076171875, 'policy_logps/chosen': -338.9521484375, 'referece_logps/rejected': -276.64239501953125, 'referece_logps/chosen': -328.52789306640625, 'logits/rejected': -0.7226852178573608, 'logits/chosen': -0.9236529469490051, 'epoch': 2.26}

 38%|███▊      | 6074/16104 [28:10:15<48:57:30, 17.57s/it]

 38%|███▊      | 6075/16104 [28:10:33<49:29:12, 17.76s/it]


 38%|███▊      | 6077/16104 [28:11:03<45:31:04, 16.34s/it]
{'loss': 0.5516, 'learning_rate': 1.4312673356728507e-06, 'rewards/chosen': -1.0792155265808105, 'rewards/rejected': -1.6461799144744873, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5669643878936768, 'policy_logps/rejected': -300.32049560546875, 'policy_logps/chosen': -297.561767578125, 'referece_logps/rejected': -283.85870361328125, 'referece_logps/chosen': -286.7696533203125, 'logits/rejected': -0.10081026703119278, 'logits/chosen': -0.17774800956249237, 'epoch': 2.26}

 38%|███▊      | 6078/16104 [28:11:23<48:11:09, 17.30s/it]


 38%|███▊      | 6080/16104 [28:12:01<50:46:43, 18.24s/it]

 38%|███▊      | 6081/16104 [28:12:20<51:45:08, 18.59s/it]

 38%|███▊      | 6082/16104 [28:12:42<54:15:49, 19.49s/it]
{'loss': 0.4788, 'learning_rate': 1.430359812737258e-06, 'rewards/chosen': -0.9692701697349548, 'rewards/rejected': -1.666094422340393, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6968242526054382, 'policy_logps/rejected': -299.93853759765625, 'policy_logps/chosen': -367.9106140136719, 'referece_logps/rejected': -283.27764892578125, 'referece_logps/chosen': -358.2178955078125, 'logits/rejected': -0.8923103213310242, 'logits/chosen': -0.8311242461204529, 'epoch': 2.27}


 38%|███▊      | 6084/16104 [28:13:17<51:51:34, 18.63s/it]
{'loss': 0.5568, 'learning_rate': 1.4299966816498634e-06, 'rewards/chosen': -1.363398551940918, 'rewards/rejected': -1.4784464836120605, 'rewards/accuracies': 0.5, 'rewards/margins': 0.11504803597927094, 'policy_logps/rejected': -229.37774658203125, 'policy_logps/chosen': -256.4066467285156, 'referece_logps/rejected': -214.59326171875, 'referece_logps/chosen': -242.77267456054688, 'logits/rejected': -1.3120522499084473, 'logits/chosen': -1.3657450675964355, 'epoch': 2.27}

 38%|███▊      | 6085/16104 [28:13:35<51:31:50, 18.52s/it]


 38%|███▊      | 6087/16104 [28:14:07<46:42:56, 16.79s/it]

 38%|███▊      | 6088/16104 [28:14:24<46:59:53, 16.89s/it]

 38%|███▊      | 6089/16104 [28:14:44<49:37:33, 17.84s/it]
{'loss': 0.4853, 'learning_rate': 1.429088549662611e-06, 'rewards/chosen': -0.8321115970611572, 'rewards/rejected': -1.917103886604309, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0849924087524414, 'policy_logps/rejected': -391.533203125, 'policy_logps/chosen': -328.3563232421875, 'referece_logps/rejected': -372.3621826171875, 'referece_logps/chosen': -320.03521728515625, 'logits/rejected': -1.2178953886032104, 'logits/chosen': -1.02460777759552, 'epoch': 2.27}

 38%|███▊      | 6090/16104 [28:15:04<51:04:04, 18.36s/it]


 38%|███▊      | 6092/16104 [28:15:37<47:31:53, 17.09s/it]
{'loss': 0.5213, 'learning_rate': 1.4285434621227108e-06, 'rewards/chosen': -0.8694323897361755, 'rewards/rejected': -1.150170922279358, 'rewards/accuracies': 0.75, 'rewards/margins': 0.28073859214782715, 'policy_logps/rejected': -433.7127685546875, 'policy_logps/chosen': -376.8604736328125, 'referece_logps/rejected': -422.2110595703125, 'referece_logps/chosen': -368.1661376953125, 'logits/rejected': -0.7433964014053345, 'logits/chosen': -0.802844226360321, 'epoch': 2.27}


 38%|███▊      | 6094/16104 [28:16:13<49:34:33, 17.83s/it]
{'loss': 0.4333, 'learning_rate': 1.428179983740455e-06, 'rewards/chosen': -1.0361347198486328, 'rewards/rejected': -2.033406972885132, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9972723126411438, 'policy_logps/rejected': -405.34893798828125, 'policy_logps/chosen': -453.9537353515625, 'referece_logps/rejected': -385.014892578125, 'referece_logps/chosen': -443.5923767089844, 'logits/rejected': -0.8173106908798218, 'logits/chosen': -0.8568657636642456, 'epoch': 2.27}


 38%|███▊      | 6096/16104 [28:16:50<50:19:19, 18.10s/it]
{'loss': 0.577, 'learning_rate': 1.4278164360756227e-06, 'rewards/chosen': -0.5931206345558167, 'rewards/rejected': -1.7577605247497559, 'rewards/accuracies': 0.75, 'rewards/margins': 1.164639949798584, 'policy_logps/rejected': -517.103271484375, 'policy_logps/chosen': -513.7681884765625, 'referece_logps/rejected': -499.5256042480469, 'referece_logps/chosen': -507.8370056152344, 'logits/rejected': -1.2338470220565796, 'logits/chosen': -1.2062699794769287, 'epoch': 2.27}


 38%|███▊      | 6098/16104 [28:17:26<50:09:04, 18.04s/it]

 38%|███▊      | 6099/16104 [28:17:45<50:59:12, 18.35s/it]

 38%|███▊      | 6100/16104 [28:17:59<47:03:35, 16.93s/it]

 38%|███▊      | 6101/16104 [28:18:13<44:20:06, 15.96s/it]
{'loss': 0.6505, 'learning_rate': 1.426907264188331e-06, 'rewards/chosen': -1.0450732707977295, 'rewards/rejected': -1.2157846689224243, 'rewards/accuracies': 0.625, 'rewards/margins': 0.17071160674095154, 'policy_logps/rejected': -476.776123046875, 'policy_logps/chosen': -556.5810546875, 'referece_logps/rejected': -464.6182556152344, 'referece_logps/chosen': -546.1303100585938, 'logits/rejected': 0.6359602212905884, 'logits/chosen': 0.8089576959609985, 'epoch': 2.27}


 38%|███▊      | 6103/16104 [28:18:54<51:07:11, 18.40s/it]

 38%|███▊      | 6104/16104 [28:19:14<52:20:02, 18.84s/it]

 38%|███▊      | 6105/16104 [28:19:27<47:39:57, 17.16s/it]

 38%|███▊      | 6106/16104 [28:19:46<48:56:02, 17.62s/it]

 38%|███▊      | 6107/16104 [28:20:05<49:57:36, 17.99s/it]

 38%|███▊      | 6108/16104 [28:20:24<50:53:35, 18.33s/it]

 38%|███▊      | 6109/16104 [28:20:43<51:04:26, 18.40s/it]

 38%|███▊      | 6110/16104 [28:20:58<48:52:00, 17.60s/it]

 38%|███▊      | 6111/16104 [28:21:17<49:22:14, 17.79s/it]

 38%|███▊      | 6112/16104 [28:21:28<44:15:45, 15.95s/it]

 38%|███▊      | 6113/16104 [28:21:41<41:47:12, 15.06s/it]

 38%|███▊      | 6114/16104 [28:21:55<40:20:38, 14.54s/it]

 38%|███▊      | 6115/16104 [28:22:13<43:13:19, 15.58s/it]

 38%|███▊      | 6116/16104 [28:22:32<46:34:28, 16.79s/it]

 38%|███▊      | 6117/16104 [28:22:45<43:31:31, 15.69s/it]
{'loss': 0.5541, 'learning_rate': 1.4239950174640414e-06, 'rewards/chosen': -1.0614839792251587, 'rewards/rejected': -1.590381383895874, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5288972854614258, 'policy_logps/rejected': -347.7618408203125, 'policy_logps/chosen': -388.98846435546875, 'referece_logps/rejected': -331.8580322265625, 'referece_logps/chosen': -378.3736267089844, 'logits/rejected': -0.7300270795822144, 'logits/chosen': -0.8913661241531372, 'epoch': 2.28}


 38%|███▊      | 6119/16104 [28:23:19<46:14:50, 16.67s/it]

 38%|███▊      | 6120/16104 [28:23:31<42:17:05, 15.25s/it]
{'loss': 0.5356, 'learning_rate': 1.4234484814799755e-06, 'rewards/chosen': -0.7182834148406982, 'rewards/rejected': -1.845445156097412, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1271617412567139, 'policy_logps/rejected': -373.243408203125, 'policy_logps/chosen': -444.5894470214844, 'referece_logps/rejected': -354.78900146484375, 'referece_logps/chosen': -437.4066467285156, 'logits/rejected': 0.163772851228714, 'logits/chosen': 0.1648322194814682, 'epoch': 2.28}


 38%|███▊      | 6122/16104 [28:23:53<36:34:53, 13.19s/it]

 38%|███▊      | 6123/16104 [28:24:09<38:47:40, 13.99s/it]

 38%|███▊      | 6124/16104 [28:24:28<42:29:27, 15.33s/it]

 38%|███▊      | 6125/16104 [28:24:39<39:11:39, 14.14s/it]
{'loss': 0.5356, 'learning_rate': 1.4225372456865582e-06, 'rewards/chosen': -0.9565462470054626, 'rewards/rejected': -0.8347102999687195, 'rewards/accuracies': 0.5, 'rewards/margins': -0.12183590233325958, 'policy_logps/rejected': -355.94976806640625, 'policy_logps/chosen': -419.9306640625, 'referece_logps/rejected': -347.6026916503906, 'referece_logps/chosen': -410.365234375, 'logits/rejected': -0.5034539103507996, 'logits/chosen': -0.6605510711669922, 'epoch': 2.28}


 38%|███▊      | 6127/16104 [28:25:03<36:43:41, 13.25s/it]

 38%|███▊      | 6128/16104 [28:25:23<41:58:05, 15.14s/it]

 38%|███▊      | 6129/16104 [28:25:40<43:08:53, 15.57s/it]

 38%|███▊      | 6130/16104 [28:25:50<39:19:15, 14.19s/it]

 38%|███▊      | 6131/16104 [28:26:09<42:40:10, 15.40s/it]

 38%|███▊      | 6132/16104 [28:26:27<44:44:18, 16.15s/it]

 38%|███▊      | 6133/16104 [28:26:37<40:05:57, 14.48s/it]

 38%|███▊      | 6134/16104 [28:26:55<43:14:28, 15.61s/it]

 38%|███▊      | 6135/16104 [28:27:11<42:58:01, 15.52s/it]

 38%|███▊      | 6136/16104 [28:27:31<47:05:25, 17.01s/it]

 38%|███▊      | 6137/16104 [28:27:51<49:17:33, 17.80s/it]

 38%|███▊      | 6138/16104 [28:28:07<48:12:50, 17.42s/it]

 38%|███▊      | 6139/16104 [28:28:24<47:11:49, 17.05s/it]
{'loss': 0.5465, 'learning_rate': 1.4199835151210598e-06, 'rewards/chosen': -0.6518663763999939, 'rewards/rejected': -0.7159482836723328, 'rewards/accuracies': 0.625, 'rewards/margins': 0.06408196687698364, 'policy_logps/rejected': -361.1923828125, 'policy_logps/chosen': -391.3992004394531, 'referece_logps/rejected': -354.03289794921875, 'referece_logps/chosen': -384.8805236816406, 'logits/rejected': -0.24154959619045258, 'logits/chosen': -0.10203496366739273, 'epoch': 2.29}


 38%|███▊      | 6141/16104 [28:28:56<45:53:23, 16.58s/it]
{'loss': 0.5202, 'learning_rate': 1.4196184241711295e-06, 'rewards/chosen': -0.5785974860191345, 'rewards/rejected': -2.076399326324463, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4978017807006836, 'policy_logps/rejected': -443.732421875, 'policy_logps/chosen': -480.1510009765625, 'referece_logps/rejected': -422.9684143066406, 'referece_logps/chosen': -474.3650207519531, 'logits/rejected': -0.803537905216217, 'logits/chosen': -0.751421332359314, 'epoch': 2.29}


 38%|███▊      | 6143/16104 [28:29:27<44:32:23, 16.10s/it]

 38%|███▊      | 6144/16104 [28:29:47<47:23:05, 17.13s/it]

 38%|███▊      | 6145/16104 [28:29:59<43:13:28, 15.62s/it]

 38%|███▊      | 6146/16104 [28:30:10<39:18:42, 14.21s/it]
{'loss': 0.5353, 'learning_rate': 1.4187053998750635e-06, 'rewards/chosen': -0.6641006469726562, 'rewards/rejected': -1.4213416576385498, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7572410106658936, 'policy_logps/rejected': -523.8805541992188, 'policy_logps/chosen': -475.6468811035156, 'referece_logps/rejected': -509.6671142578125, 'referece_logps/chosen': -469.005859375, 'logits/rejected': -1.0363320112228394, 'logits/chosen': -1.0027353763580322, 'epoch': 2.29}


 38%|███▊      | 6148/16104 [28:30:42<42:36:01, 15.40s/it]
{'loss': 0.5959, 'learning_rate': 1.4183400715432613e-06, 'rewards/chosen': -1.2545695304870605, 'rewards/rejected': -2.2847023010253906, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0301328897476196, 'policy_logps/rejected': -340.0162353515625, 'policy_logps/chosen': -407.81744384765625, 'referece_logps/rejected': -317.16925048828125, 'referece_logps/chosen': -395.2717590332031, 'logits/rejected': -1.3193848133087158, 'logits/chosen': -1.3700441122055054, 'epoch': 2.29}


 38%|███▊      | 6150/16104 [28:31:13<42:11:30, 15.26s/it]

 38%|███▊      | 6151/16104 [28:31:32<45:13:14, 16.36s/it]

 38%|███▊      | 6152/16104 [28:31:49<45:38:26, 16.51s/it]
{'loss': 0.557, 'learning_rate': 1.4176092118675534e-06, 'rewards/chosen': -0.24794751405715942, 'rewards/rejected': -2.168926477432251, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9209790229797363, 'policy_logps/rejected': -461.028076171875, 'policy_logps/chosen': -409.2105712890625, 'referece_logps/rejected': -439.33880615234375, 'referece_logps/chosen': -406.7310791015625, 'logits/rejected': 0.2692475914955139, 'logits/chosen': 0.11353453993797302, 'epoch': 2.29}

 38%|███▊      | 6153/16104 [28:32:03<43:20:06, 15.68s/it]


 38%|███▊      | 6155/16104 [28:32:42<49:17:45, 17.84s/it]
{'loss': 0.527, 'learning_rate': 1.4170608897080084e-06, 'rewards/chosen': -1.3499681949615479, 'rewards/rejected': -2.047410011291504, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6974417567253113, 'policy_logps/rejected': -490.3475341796875, 'policy_logps/chosen': -453.80255126953125, 'referece_logps/rejected': -469.8734130859375, 'referece_logps/chosen': -440.3028869628906, 'logits/rejected': -0.5511820912361145, 'logits/chosen': -0.648786187171936, 'epoch': 2.29}


 38%|███▊      | 6157/16104 [28:33:16<47:27:51, 17.18s/it]

 38%|███▊      | 6158/16104 [28:33:27<42:58:02, 15.55s/it]
{'loss': 0.5347, 'learning_rate': 1.416512415710753e-06, 'rewards/chosen': -0.8221698999404907, 'rewards/rejected': -1.0747511386871338, 'rewards/accuracies': 0.75, 'rewards/margins': 0.25258123874664307, 'policy_logps/rejected': -398.3094177246094, 'policy_logps/chosen': -407.8667907714844, 'referece_logps/rejected': -387.5618591308594, 'referece_logps/chosen': -399.64508056640625, 'logits/rejected': -0.41042017936706543, 'logits/chosen': -0.5251603126525879, 'epoch': 2.29}

 38%|███▊      | 6159/16104 [28:33:43<43:08:36, 15.62s/it]

 38%|███▊      | 6160/16104 [28:34:01<44:50:41, 16.24s/it]


 38%|███▊      | 6162/16104 [28:34:36<46:40:15, 16.90s/it]

 38%|███▊      | 6163/16104 [28:34:54<47:19:00, 17.14s/it]

 38%|███▊      | 6164/16104 [28:35:16<51:24:59, 18.62s/it]
{'loss': 0.5051, 'learning_rate': 1.4154150130018865e-06, 'rewards/chosen': -0.23814336955547333, 'rewards/rejected': -0.8212295770645142, 'rewards/accuracies': 1.0, 'rewards/margins': 0.5830861926078796, 'policy_logps/rejected': -366.8380126953125, 'policy_logps/chosen': -435.58551025390625, 'referece_logps/rejected': -358.6257019042969, 'referece_logps/chosen': -433.20404052734375, 'logits/rejected': -0.3615729808807373, 'logits/chosen': -0.4637688398361206, 'epoch': 2.3}

 38%|███▊      | 6165/16104 [28:35:31<48:40:27, 17.63s/it]

 38%|███▊      | 6166/16104 [28:35:47<47:06:56, 17.07s/it]


 38%|███▊      | 6168/16104 [28:36:22<46:49:32, 16.97s/it]
{'loss': 0.5258, 'learning_rate': 1.4146830750117586e-06, 'rewards/chosen': -0.8465206027030945, 'rewards/rejected': -0.8313930630683899, 'rewards/accuracies': 0.375, 'rewards/margins': -0.015127554535865784, 'policy_logps/rejected': -303.370849609375, 'policy_logps/chosen': -215.48916625976562, 'referece_logps/rejected': -295.056884765625, 'referece_logps/chosen': -207.0239715576172, 'logits/rejected': -0.8522875308990479, 'logits/chosen': -0.680645763874054, 'epoch': 2.3}

 38%|███▊      | 6169/16104 [28:36:33<42:23:38, 15.36s/it]


 38%|███▊      | 6171/16104 [28:37:06<42:37:18, 15.45s/it]

 38%|███▊      | 6172/16104 [28:37:18<40:24:26, 14.65s/it]
{'loss': 0.5104, 'learning_rate': 1.4139508686269183e-06, 'rewards/chosen': -0.47291335463523865, 'rewards/rejected': -1.6194336414337158, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1465201377868652, 'policy_logps/rejected': -356.4729919433594, 'policy_logps/chosen': -370.78558349609375, 'referece_logps/rejected': -340.2786560058594, 'referece_logps/chosen': -366.0564270019531, 'logits/rejected': -1.2469664812088013, 'logits/chosen': -1.1921192407608032, 'epoch': 2.3}


 38%|███▊      | 6174/16104 [28:37:40<34:58:11, 12.68s/it]

 38%|███▊      | 6175/16104 [28:37:58<39:14:15, 14.23s/it]

 38%|███▊      | 6176/16104 [28:38:14<41:05:18, 14.90s/it]

 38%|███▊      | 6177/16104 [28:38:34<45:01:59, 16.33s/it]

 38%|███▊      | 6178/16104 [28:38:52<46:45:15, 16.96s/it]
{'loss': 0.5009, 'learning_rate': 1.4128520568462863e-06, 'rewards/chosen': -0.4395034909248352, 'rewards/rejected': -1.1148898601531982, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6753864288330078, 'policy_logps/rejected': -231.64645385742188, 'policy_logps/chosen': -344.8494873046875, 'referece_logps/rejected': -220.49755859375, 'referece_logps/chosen': -340.4544372558594, 'logits/rejected': -0.8851174116134644, 'logits/chosen': -0.827379584312439, 'epoch': 2.3}


 38%|███▊      | 6180/16104 [28:39:24<45:50:34, 16.63s/it]
{'loss': 0.5213, 'learning_rate': 1.412485652568893e-06, 'rewards/chosen': -0.8604897260665894, 'rewards/rejected': -0.7222632169723511, 'rewards/accuracies': 0.375, 'rewards/margins': -0.13822653889656067, 'policy_logps/rejected': -427.45794677734375, 'policy_logps/chosen': -550.8164672851562, 'referece_logps/rejected': -420.2353210449219, 'referece_logps/chosen': -542.2116088867188, 'logits/rejected': -0.97765052318573, 'logits/chosen': -1.1764963865280151, 'epoch': 2.3}


 38%|███▊      | 6182/16104 [28:40:02<49:31:21, 17.97s/it]
{'loss': 0.3946, 'learning_rate': 1.4121191815483774e-06, 'rewards/chosen': -0.30243098735809326, 'rewards/rejected': -2.0838005542755127, 'rewards/accuracies': 0.875, 'rewards/margins': 1.781369686126709, 'policy_logps/rejected': -352.7775573730469, 'policy_logps/chosen': -339.5646667480469, 'referece_logps/rejected': -331.9395751953125, 'referece_logps/chosen': -336.5403747558594, 'logits/rejected': 0.1298622339963913, 'logits/chosen': 0.1399175524711609, 'epoch': 2.3}


 38%|███▊      | 6184/16104 [28:40:44<53:22:17, 19.37s/it]

 38%|███▊      | 6185/16104 [28:41:04<53:52:07, 19.55s/it]
{'loss': 0.5108, 'learning_rate': 1.4115693500039666e-06, 'rewards/chosen': -0.7553978562355042, 'rewards/rejected': -2.011147975921631, 'rewards/accuracies': 0.75, 'rewards/margins': 1.255750298500061, 'policy_logps/rejected': -410.0249938964844, 'policy_logps/chosen': -511.90655517578125, 'referece_logps/rejected': -389.91351318359375, 'referece_logps/chosen': -504.3525390625, 'logits/rejected': -1.5322484970092773, 'logits/chosen': -1.3595149517059326, 'epoch': 2.3}

 38%|███▊      | 6186/16104 [28:41:19<50:02:05, 18.16s/it]


 38%|███▊      | 6188/16104 [28:41:48<45:37:55, 16.57s/it]

 38%|███▊      | 6189/16104 [28:42:09<48:50:56, 17.74s/it]
{'loss': 0.5868, 'learning_rate': 1.4108360082306927e-06, 'rewards/chosen': -0.47324639558792114, 'rewards/rejected': -0.8975511789321899, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4243047833442688, 'policy_logps/rejected': -357.121826171875, 'policy_logps/chosen': -358.91693115234375, 'referece_logps/rejected': -348.14630126953125, 'referece_logps/chosen': -354.1844482421875, 'logits/rejected': -0.4425255358219147, 'logits/chosen': -0.3509822189807892, 'epoch': 2.31}

 38%|███▊      | 6190/16104 [28:42:26<48:13:01, 17.51s/it]

 38%|███▊      | 6191/16104 [28:42:42<47:16:26, 17.17s/it]

 38%|███▊      | 6192/16104 [28:42:57<45:40:08, 16.59s/it]

 38%|███▊      | 6193/16104 [28:43:17<48:31:55, 17.63s/it]

 38%|███▊      | 6194/16104 [28:43:29<44:02:08, 16.00s/it]

 38%|███▊      | 6195/16104 [28:43:42<40:59:18, 14.89s/it]

 38%|███▊      | 6196/16104 [28:43:58<42:04:45, 15.29s/it]

 38%|███▊      | 6197/16104 [28:44:18<45:41:10, 16.60s/it]


 38%|███▊      | 6199/16104 [28:44:49<43:10:27, 15.69s/it]

 38%|███▊      | 6200/16104 [28:45:11<48:14:03, 17.53s/it]
{'loss': 0.4858, 'learning_rate': 1.4088179487109032e-06, 'rewards/chosen': -1.252214789390564, 'rewards/rejected': -1.618180751800537, 'rewards/accuracies': 0.625, 'rewards/margins': 0.36596590280532837, 'policy_logps/rejected': -404.691650390625, 'policy_logps/chosen': -335.1336975097656, 'referece_logps/rejected': -388.5098571777344, 'referece_logps/chosen': -322.6115417480469, 'logits/rejected': -1.2509992122650146, 'logits/chosen': -1.213569164276123, 'epoch': 2.31}


 39%|███▊      | 6202/16104 [28:45:41<46:02:38, 16.74s/it]
{'loss': 0.5988, 'learning_rate': 1.4084508135223124e-06, 'rewards/chosen': -0.6672244071960449, 'rewards/rejected': -1.2650997638702393, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5978752970695496, 'policy_logps/rejected': -532.6267700195312, 'policy_logps/chosen': -324.9591979980469, 'referece_logps/rejected': -519.975830078125, 'referece_logps/chosen': -318.2869873046875, 'logits/rejected': -0.3701125979423523, 'logits/chosen': -0.12897008657455444, 'epoch': 2.31}

 39%|███▊      | 6203/16104 [28:45:52<41:03:29, 14.93s/it]

 39%|███▊      | 6204/16104 [28:46:10<43:49:17, 15.94s/it]

 39%|███▊      | 6205/16104 [28:46:30<47:07:09, 17.14s/it]


 39%|███▊      | 6207/16104 [28:46:59<44:01:52, 16.02s/it]
{'loss': 0.6215, 'learning_rate': 1.407532686535938e-06, 'rewards/chosen': -1.0196621417999268, 'rewards/rejected': -1.0868183374404907, 'rewards/accuracies': 0.5, 'rewards/margins': 0.06715621799230576, 'policy_logps/rejected': -474.3271789550781, 'policy_logps/chosen': -414.1841125488281, 'referece_logps/rejected': -463.4589538574219, 'referece_logps/chosen': -403.98748779296875, 'logits/rejected': -0.8422572612762451, 'logits/chosen': -0.897711455821991, 'epoch': 2.31}


 39%|███▊      | 6209/16104 [28:47:33<45:06:43, 16.41s/it]
{'loss': 0.514, 'learning_rate': 1.4071653202914166e-06, 'rewards/chosen': -1.4982507228851318, 'rewards/rejected': -2.689605236053467, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1913543939590454, 'policy_logps/rejected': -373.04241943359375, 'policy_logps/chosen': -417.30999755859375, 'referece_logps/rejected': -346.1463928222656, 'referece_logps/chosen': -402.32745361328125, 'logits/rejected': -0.5238240957260132, 'logits/chosen': -0.493547260761261, 'epoch': 2.31}

 39%|███▊      | 6210/16104 [28:47:50<45:08:36, 16.43s/it]

 39%|███▊      | 6211/16104 [28:48:07<46:22:21, 16.87s/it]

 39%|███▊      | 6212/16104 [28:48:23<45:40:56, 16.63s/it]


 39%|███▊      | 6214/16104 [28:48:57<45:41:15, 16.63s/it]
{'loss': 0.4742, 'learning_rate': 1.4062466165753068e-06, 'rewards/chosen': -0.6781124472618103, 'rewards/rejected': -1.8054391145706177, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1273267269134521, 'policy_logps/rejected': -375.7366638183594, 'policy_logps/chosen': -473.49163818359375, 'referece_logps/rejected': -357.68231201171875, 'referece_logps/chosen': -466.7104797363281, 'logits/rejected': 0.20246727764606476, 'logits/chosen': 0.1268908679485321, 'epoch': 2.32}


 39%|███▊      | 6216/16104 [28:49:27<43:08:38, 15.71s/it]
{'loss': 0.5304, 'learning_rate': 1.4058790200030257e-06, 'rewards/chosen': -1.3126922845840454, 'rewards/rejected': -1.6878643035888672, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3751720190048218, 'policy_logps/rejected': -587.1646728515625, 'policy_logps/chosen': -495.0001525878906, 'referece_logps/rejected': -570.2860107421875, 'referece_logps/chosen': -481.87322998046875, 'logits/rejected': -0.38610631227493286, 'logits/chosen': -0.2737157940864563, 'epoch': 2.32}


 39%|███▊      | 6218/16104 [28:50:05<47:51:44, 17.43s/it]

 39%|███▊      | 6219/16104 [28:50:23<48:33:06, 17.68s/it]

 39%|███▊      | 6220/16104 [28:50:37<45:09:19, 16.45s/it]

 39%|███▊      | 6221/16104 [28:50:53<45:18:06, 16.50s/it]
{'loss': 0.5016, 'learning_rate': 1.4049597413781778e-06, 'rewards/chosen': -0.8083937168121338, 'rewards/rejected': -2.1603128910064697, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3519192934036255, 'policy_logps/rejected': -374.4681091308594, 'policy_logps/chosen': -385.3017578125, 'referece_logps/rejected': -352.864990234375, 'referece_logps/chosen': -377.2178039550781, 'logits/rejected': -0.2707379460334778, 'logits/chosen': -0.3132975101470947, 'epoch': 2.32}

 39%|███▊      | 6222/16104 [28:51:12<46:42:34, 17.02s/it]


 39%|███▊      | 6224/16104 [28:51:53<51:14:33, 18.67s/it]
{'loss': 0.4485, 'learning_rate': 1.4044079775676392e-06, 'rewards/chosen': -0.6947785019874573, 'rewards/rejected': -2.611392021179199, 'rewards/accuracies': 0.625, 'rewards/margins': 1.9166135787963867, 'policy_logps/rejected': -446.70257568359375, 'policy_logps/chosen': -444.095458984375, 'referece_logps/rejected': -420.5887145996094, 'referece_logps/chosen': -437.1476745605469, 'logits/rejected': -0.039816368371248245, 'logits/chosen': -0.03835758566856384, 'epoch': 2.32}

 39%|███▊      | 6225/16104 [28:52:09<48:53:20, 17.82s/it]

 39%|███▊      | 6226/16104 [28:52:29<50:44:35, 18.49s/it]

 39%|███▊      | 6227/16104 [28:52:46<49:46:14, 18.14s/it]

 39%|███▊      | 6228/16104 [28:53:04<49:25:37, 18.02s/it]

 39%|███▊      | 6229/16104 [28:53:23<50:06:53, 18.27s/it]

 39%|███▊      | 6230/16104 [28:53:36<46:15:07, 16.86s/it]


 39%|███▊      | 6232/16104 [28:54:13<48:23:29, 17.65s/it]
{'loss': 0.4909, 'learning_rate': 1.4029358881549159e-06, 'rewards/chosen': -0.5453705191612244, 'rewards/rejected': -2.4728333950042725, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9274629354476929, 'policy_logps/rejected': -298.48687744140625, 'policy_logps/chosen': -263.86138916015625, 'referece_logps/rejected': -273.758544921875, 'referece_logps/chosen': -258.4076843261719, 'logits/rejected': 1.090975284576416, 'logits/chosen': 1.062482476234436, 'epoch': 2.32}


 39%|███▊      | 6234/16104 [28:54:49<48:33:32, 17.71s/it]
{'loss': 0.449, 'learning_rate': 1.4025677026580816e-06, 'rewards/chosen': -1.0770304203033447, 'rewards/rejected': -2.6526107788085938, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5755805969238281, 'policy_logps/rejected': -389.9913024902344, 'policy_logps/chosen': -390.25213623046875, 'referece_logps/rejected': -363.4651794433594, 'referece_logps/chosen': -379.48187255859375, 'logits/rejected': -0.5356917381286621, 'logits/chosen': -0.08468171954154968, 'epoch': 2.32}


 39%|███▊      | 6236/16104 [28:55:29<51:30:42, 18.79s/it]
{'loss': 0.533, 'learning_rate': 1.4021994520229199e-06, 'rewards/chosen': -0.7566348314285278, 'rewards/rejected': -0.9074150323867798, 'rewards/accuracies': 0.5, 'rewards/margins': 0.15078029036521912, 'policy_logps/rejected': -463.9239196777344, 'policy_logps/chosen': -467.17742919921875, 'referece_logps/rejected': -454.84979248046875, 'referece_logps/chosen': -459.6111145019531, 'logits/rejected': -0.4772956967353821, 'logits/chosen': -0.5152812600135803, 'epoch': 2.32}


 39%|███▊      | 6238/16104 [28:56:01<47:11:21, 17.22s/it]
{'loss': 0.5413, 'learning_rate': 1.401831136309017e-06, 'rewards/chosen': -1.1259205341339111, 'rewards/rejected': -1.6492732763290405, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5233527421951294, 'policy_logps/rejected': -343.2752685546875, 'policy_logps/chosen': -354.7839050292969, 'referece_logps/rejected': -326.78253173828125, 'referece_logps/chosen': -343.52471923828125, 'logits/rejected': 0.387151837348938, 'logits/chosen': 0.5024723410606384, 'epoch': 2.32}

 39%|███▊      | 6239/16104 [28:56:17<45:49:53, 16.73s/it]

 39%|███▊      | 6240/16104 [28:56:35<46:55:50, 17.13s/it]

 39%|███▉      | 6241/16104 [28:56:53<47:39:21, 17.39s/it]


 39%|███▉      | 6243/16104 [28:57:29<48:11:51, 17.60s/it]

 39%|███▉      | 6244/16104 [28:57:47<48:29:16, 17.70s/it]
{'loss': 0.4918, 'learning_rate': 1.4007257992908723e-06, 'rewards/chosen': -1.2780003547668457, 'rewards/rejected': -1.2280340194702148, 'rewards/accuracies': 0.375, 'rewards/margins': -0.04996626079082489, 'policy_logps/rejected': -282.5994567871094, 'policy_logps/chosen': -397.3102722167969, 'referece_logps/rejected': -270.3191223144531, 'referece_logps/chosen': -384.5302734375, 'logits/rejected': -1.3477369546890259, 'logits/chosen': -1.4793707132339478, 'epoch': 2.33}


 39%|███▉      | 6246/16104 [28:58:27<51:22:57, 18.76s/it]

 39%|███▉      | 6247/16104 [28:58:48<52:41:18, 19.24s/it]
{'loss': 0.477, 'learning_rate': 1.400172911845194e-06, 'rewards/chosen': -1.8243213891983032, 'rewards/rejected': -3.3182942867279053, 'rewards/accuracies': 0.875, 'rewards/margins': 1.493972897529602, 'policy_logps/rejected': -364.20166015625, 'policy_logps/chosen': -606.8302612304688, 'referece_logps/rejected': -331.01873779296875, 'referece_logps/chosen': -588.5870971679688, 'logits/rejected': -0.7894982695579529, 'logits/chosen': -0.858691930770874, 'epoch': 2.33}


 39%|███▉      | 6249/16104 [28:59:12<43:02:30, 15.72s/it]

 39%|███▉      | 6250/16104 [28:59:30<44:46:40, 16.36s/it]

 39%|███▉      | 6251/16104 [28:59:43<42:27:56, 15.52s/it]
{'loss': 0.5887, 'learning_rate': 1.3994355019911766e-06, 'rewards/chosen': -0.7596079707145691, 'rewards/rejected': -0.8305141925811768, 'rewards/accuracies': 0.75, 'rewards/margins': 0.07090625166893005, 'policy_logps/rejected': -465.1739501953125, 'policy_logps/chosen': -555.9935913085938, 'referece_logps/rejected': -456.8687744140625, 'referece_logps/chosen': -548.3975830078125, 'logits/rejected': -1.0392911434173584, 'logits/chosen': -1.0469627380371094, 'epoch': 2.33}


 39%|███▉      | 6253/16104 [29:00:09<38:21:08, 14.02s/it]
{'loss': 0.5761, 'learning_rate': 1.3990667000870638e-06, 'rewards/chosen': -0.9278122782707214, 'rewards/rejected': -1.7163500785827637, 'rewards/accuracies': 0.875, 'rewards/margins': 0.788537859916687, 'policy_logps/rejected': -396.46044921875, 'policy_logps/chosen': -380.55572509765625, 'referece_logps/rejected': -379.2969665527344, 'referece_logps/chosen': -371.277587890625, 'logits/rejected': -0.4533825218677521, 'logits/chosen': -0.5106676816940308, 'epoch': 2.33}


 39%|███▉      | 6255/16104 [29:00:43<43:25:45, 15.87s/it]
{'loss': 0.5106, 'learning_rate': 1.3986978336111107e-06, 'rewards/chosen': -0.7196208238601685, 'rewards/rejected': -1.8104243278503418, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0908035039901733, 'policy_logps/rejected': -440.142822265625, 'policy_logps/chosen': -428.4864196777344, 'referece_logps/rejected': -422.0386047363281, 'referece_logps/chosen': -421.29022216796875, 'logits/rejected': 0.5442541241645813, 'logits/chosen': 0.44846171140670776, 'epoch': 2.33}

 39%|███▉      | 6256/16104 [29:01:01<44:42:15, 16.34s/it]

 39%|███▉      | 6257/16104 [29:01:16<44:03:05, 16.10s/it]

 39%|███▉      | 6258/16104 [29:01:39<49:12:45, 17.99s/it]

 39%|███▉      | 6259/16104 [29:01:55<47:55:20, 17.52s/it]

 39%|███▉      | 6260/16104 [29:02:13<48:27:42, 17.72s/it]


 39%|███▉      | 6262/16104 [29:02:55<53:34:52, 19.60s/it]

 39%|███▉      | 6263/16104 [29:03:10<49:02:11, 17.94s/it]
{'loss': 0.5707, 'learning_rate': 1.3972217231827603e-06, 'rewards/chosen': -1.055407166481018, 'rewards/rejected': -1.328598976135254, 'rewards/accuracies': 0.375, 'rewards/margins': 0.27319180965423584, 'policy_logps/rejected': -379.5770263671875, 'policy_logps/chosen': -366.57476806640625, 'referece_logps/rejected': -366.2910461425781, 'referece_logps/chosen': -356.0207214355469, 'logits/rejected': -0.09052953124046326, 'logits/chosen': -0.10415774583816528, 'epoch': 2.33}

 39%|███▉      | 6264/16104 [29:03:29<49:59:14, 18.29s/it]

 39%|███▉      | 6265/16104 [29:03:50<52:47:53, 19.32s/it]

 39%|███▉      | 6266/16104 [29:04:04<47:58:11, 17.55s/it]

 39%|███▉      | 6267/16104 [29:04:23<49:42:28, 18.19s/it]

 39%|███▉      | 6268/16104 [29:04:36<44:58:04, 16.46s/it]

 39%|███▉      | 6269/16104 [29:04:50<43:24:52, 15.89s/it]

 39%|███▉      | 6270/16104 [29:05:02<40:10:31, 14.71s/it]

 39%|███▉      | 6271/16104 [29:05:13<36:52:42, 13.50s/it]

 39%|███▉      | 6272/16104 [29:05:33<41:58:16, 15.37s/it]

 39%|███▉      | 6273/16104 [29:05:44<38:19:00, 14.03s/it]

 39%|███▉      | 6274/16104 [29:05:57<37:24:02, 13.70s/it]


 39%|███▉      | 6276/16104 [29:06:24<36:55:34, 13.53s/it]
{'loss': 0.5555, 'learning_rate': 1.3948208521095597e-06, 'rewards/chosen': -0.35334643721580505, 'rewards/rejected': -0.865936815738678, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5125904083251953, 'policy_logps/rejected': -344.1399230957031, 'policy_logps/chosen': -381.8856201171875, 'referece_logps/rejected': -335.4805603027344, 'referece_logps/chosen': -378.3521728515625, 'logits/rejected': 0.0335981547832489, 'logits/chosen': -0.05990716814994812, 'epoch': 2.34}


 39%|███▉      | 6278/16104 [29:06:52<36:43:38, 13.46s/it]
{'loss': 0.6022, 'learning_rate': 1.3944512473499436e-06, 'rewards/chosen': -0.7479800581932068, 'rewards/rejected': -0.7913409471511841, 'rewards/accuracies': 0.625, 'rewards/margins': 0.04336080700159073, 'policy_logps/rejected': -369.487060546875, 'policy_logps/chosen': -460.73919677734375, 'referece_logps/rejected': -361.57366943359375, 'referece_logps/chosen': -453.2593994140625, 'logits/rejected': -0.6671492457389832, 'logits/chosen': -0.6224979758262634, 'epoch': 2.34}

 39%|███▉      | 6279/16104 [29:07:03<34:39:58, 12.70s/it]

 39%|███▉      | 6280/16104 [29:07:19<37:10:49, 13.62s/it]

 39%|███▉      | 6281/16104 [29:07:37<40:21:15, 14.79s/it]

 39%|███▉      | 6282/16104 [29:07:47<37:03:25, 13.58s/it]


 39%|███▉      | 6284/16104 [29:08:20<40:28:25, 14.84s/it]

 39%|███▉      | 6285/16104 [29:08:41<44:46:45, 16.42s/it]
{'loss': 0.5569, 'learning_rate': 1.393157128461762e-06, 'rewards/chosen': -0.5068562030792236, 'rewards/rejected': -1.5069527626037598, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0000966787338257, 'policy_logps/rejected': -298.31634521484375, 'policy_logps/chosen': -457.42138671875, 'referece_logps/rejected': -283.246826171875, 'referece_logps/chosen': -452.3528137207031, 'logits/rejected': 0.11572200059890747, 'logits/chosen': 0.002319931983947754, 'epoch': 2.34}

 39%|███▉      | 6286/16104 [29:09:03<49:41:48, 18.22s/it]

 39%|███▉      | 6287/16104 [29:09:16<45:12:37, 16.58s/it]

 39%|███▉      | 6288/16104 [29:09:36<48:23:45, 17.75s/it]


 39%|███▉      | 6290/16104 [29:10:10<48:07:46, 17.66s/it]
{'loss': 0.503, 'learning_rate': 1.39223228056057e-06, 'rewards/chosen': -1.150957465171814, 'rewards/rejected': -1.5800741910934448, 'rewards/accuracies': 0.375, 'rewards/margins': 0.4291166663169861, 'policy_logps/rejected': -287.4181823730469, 'policy_logps/chosen': -442.430908203125, 'referece_logps/rejected': -271.617431640625, 'referece_logps/chosen': -430.92132568359375, 'logits/rejected': -0.8044448494911194, 'logits/chosen': -0.8399448990821838, 'epoch': 2.34}

 39%|███▉      | 6291/16104 [29:10:27<47:12:48, 17.32s/it]


 39%|███▉      | 6293/16104 [29:10:59<44:56:01, 16.49s/it]
{'loss': 0.6126, 'learning_rate': 1.3916771813620463e-06, 'rewards/chosen': -0.6831247806549072, 'rewards/rejected': -1.4256763458251953, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7425516247749329, 'policy_logps/rejected': -327.15643310546875, 'policy_logps/chosen': -352.64593505859375, 'referece_logps/rejected': -312.899658203125, 'referece_logps/chosen': -345.8146667480469, 'logits/rejected': -0.4745689034461975, 'logits/chosen': -0.5114716291427612, 'epoch': 2.34}

 39%|███▉      | 6294/16104 [29:11:16<45:30:02, 16.70s/it]

 39%|███▉      | 6295/16104 [29:11:33<46:07:40, 16.93s/it]

 39%|███▉      | 6296/16104 [29:11:46<42:26:26, 15.58s/it]

 39%|███▉      | 6297/16104 [29:12:03<44:00:35, 16.16s/it]


 39%|███▉      | 6299/16104 [29:12:39<45:36:10, 16.74s/it]
{'loss': 0.5404, 'learning_rate': 1.3905665553780503e-06, 'rewards/chosen': -0.6257858276367188, 'rewards/rejected': -0.9301561117172241, 'rewards/accuracies': 0.625, 'rewards/margins': 0.30437031388282776, 'policy_logps/rejected': -257.3887939453125, 'policy_logps/chosen': -443.7676696777344, 'referece_logps/rejected': -248.0872039794922, 'referece_logps/chosen': -437.509765625, 'logits/rejected': -0.3361799120903015, 'logits/chosen': -0.3248324990272522, 'epoch': 2.35}


 39%|███▉      | 6301/16104 [29:13:04<40:39:01, 14.93s/it]
{'loss': 0.5455, 'learning_rate': 1.3901962202439265e-06, 'rewards/chosen': -0.8143470883369446, 'rewards/rejected': -1.2719405889511108, 'rewards/accuracies': 0.5, 'rewards/margins': 0.45759356021881104, 'policy_logps/rejected': -296.0660095214844, 'policy_logps/chosen': -372.78253173828125, 'referece_logps/rejected': -283.34661865234375, 'referece_logps/chosen': -364.6390686035156, 'logits/rejected': -0.6211864948272705, 'logits/chosen': -0.7796381115913391, 'epoch': 2.35}

 39%|███▉      | 6302/16104 [29:13:20<41:05:58, 15.09s/it]

 39%|███▉      | 6303/16104 [29:13:32<38:33:49, 14.16s/it]


 39%|███▉      | 6305/16104 [29:14:01<39:42:00, 14.59s/it]
{'loss': 0.4473, 'learning_rate': 1.3894553606260129e-06, 'rewards/chosen': -0.5838919878005981, 'rewards/rejected': -1.0168968439102173, 'rewards/accuracies': 0.875, 'rewards/margins': 0.43300488591194153, 'policy_logps/rejected': -527.5056762695312, 'policy_logps/chosen': -448.48590087890625, 'referece_logps/rejected': -517.336669921875, 'referece_logps/chosen': -442.64697265625, 'logits/rejected': -0.09130549430847168, 'logits/chosen': -0.11383548378944397, 'epoch': 2.35}

 39%|███▉      | 6306/16104 [29:14:20<43:26:39, 15.96s/it]

 39%|███▉      | 6307/16104 [29:14:40<46:46:08, 17.19s/it]


 39%|███▉      | 6309/16104 [29:15:17<47:59:59, 17.64s/it]
{'loss': 0.6338, 'learning_rate': 1.388714248941483e-06, 'rewards/chosen': -1.3551108837127686, 'rewards/rejected': -1.4695184230804443, 'rewards/accuracies': 0.5, 'rewards/margins': 0.11440760642290115, 'policy_logps/rejected': -434.9876708984375, 'policy_logps/chosen': -472.0088195800781, 'referece_logps/rejected': -420.29248046875, 'referece_logps/chosen': -458.4576721191406, 'logits/rejected': 0.23085379600524902, 'logits/chosen': 0.16107182204723358, 'epoch': 2.35}

 39%|███▉      | 6310/16104 [29:15:32<45:55:59, 16.88s/it]

 39%|███▉      | 6311/16104 [29:15:50<46:53:02, 17.24s/it]

 39%|███▉      | 6312/16104 [29:16:11<50:16:27, 18.48s/it]

 39%|███▉      | 6313/16104 [29:16:26<47:10:03, 17.34s/it]

 39%|███▉      | 6314/16104 [29:16:38<42:49:28, 15.75s/it]

 39%|███▉      | 6315/16104 [29:16:57<45:44:59, 16.82s/it]

 39%|███▉      | 6316/16104 [29:17:08<41:00:30, 15.08s/it]


 39%|███▉      | 6318/16104 [29:17:35<38:51:37, 14.30s/it]

 39%|███▉      | 6319/16104 [29:17:53<41:51:48, 15.40s/it]
{'loss': 0.5521, 'learning_rate': 1.3868603700869378e-06, 'rewards/chosen': -0.7810359597206116, 'rewards/rejected': -0.9531111121177673, 'rewards/accuracies': 0.625, 'rewards/margins': 0.172075092792511, 'policy_logps/rejected': -329.473388671875, 'policy_logps/chosen': -354.40289306640625, 'referece_logps/rejected': -319.9422912597656, 'referece_logps/chosen': -346.5924987792969, 'logits/rejected': -0.5153650045394897, 'logits/chosen': -0.49631989002227783, 'epoch': 2.35}

 39%|███▉      | 6320/16104 [29:18:13<45:36:41, 16.78s/it]


 39%|███▉      | 6322/16104 [29:18:47<46:29:53, 17.11s/it]
{'loss': 0.5044, 'learning_rate': 1.3863039009300432e-06, 'rewards/chosen': -1.3108322620391846, 'rewards/rejected': -1.9901384115219116, 'rewards/accuracies': 0.75, 'rewards/margins': 0.679306149482727, 'policy_logps/rejected': -293.2602844238281, 'policy_logps/chosen': -462.3674011230469, 'referece_logps/rejected': -273.3589172363281, 'referece_logps/chosen': -449.2590637207031, 'logits/rejected': -0.5563066005706787, 'logits/chosen': -0.6958054304122925, 'epoch': 2.36}

 39%|███▉      | 6323/16104 [29:19:00<42:45:40, 15.74s/it]

 39%|███▉      | 6324/16104 [29:19:11<38:58:38, 14.35s/it]

 39%|███▉      | 6325/16104 [29:19:32<44:18:13, 16.31s/it]

 39%|███▉      | 6326/16104 [29:19:53<48:47:28, 17.96s/it]

 39%|███▉      | 6327/16104 [29:20:11<48:10:20, 17.74s/it]

 39%|███▉      | 6328/16104 [29:20:30<49:21:43, 18.18s/it]

 39%|███▉      | 6329/16104 [29:20:51<51:42:14, 19.04s/it]

 39%|███▉      | 6330/16104 [29:21:10<51:46:33, 19.07s/it]

 39%|███▉      | 6331/16104 [29:21:29<51:42:58, 19.05s/it]

 39%|███▉      | 6332/16104 [29:21:49<52:27:43, 19.33s/it]

 39%|███▉      | 6333/16104 [29:22:06<50:32:25, 18.62s/it]

 39%|███▉      | 6334/16104 [29:22:23<49:13:11, 18.14s/it]

 39%|███▉      | 6335/16104 [29:22:39<47:29:51, 17.50s/it]

 39%|███▉      | 6336/16104 [29:22:57<47:37:44, 17.55s/it]

 39%|███▉      | 6337/16104 [29:23:12<46:04:10, 16.98s/it]

 39%|███▉      | 6338/16104 [29:23:31<47:36:12, 17.55s/it]

 39%|███▉      | 6339/16104 [29:23:51<49:38:07, 18.30s/it]


 39%|███▉      | 6341/16104 [29:24:17<42:33:45, 15.69s/it]
{'loss': 0.335, 'learning_rate': 1.3827763386614072e-06, 'rewards/chosen': -0.7310796976089478, 'rewards/rejected': -1.6918883323669434, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9608086347579956, 'policy_logps/rejected': -318.19537353515625, 'policy_logps/chosen': -255.82725524902344, 'referece_logps/rejected': -301.2764892578125, 'referece_logps/chosen': -248.5164794921875, 'logits/rejected': -0.580007791519165, 'logits/chosen': -0.5619771480560303, 'epoch': 2.36}

 39%|███▉      | 6342/16104 [29:24:32<42:02:09, 15.50s/it]

 39%|███▉      | 6343/16104 [29:24:52<45:26:01, 16.76s/it]

 39%|███▉      | 6344/16104 [29:25:12<47:50:48, 17.65s/it]

 39%|███▉      | 6345/16104 [29:25:24<43:43:27, 16.13s/it]

 39%|███▉      | 6346/16104 [29:25:39<42:31:10, 15.69s/it]

 39%|███▉      | 6347/16104 [29:26:01<47:14:09, 17.43s/it]

 39%|███▉      | 6348/16104 [29:26:20<49:01:12, 18.09s/it]

 39%|███▉      | 6349/16104 [29:26:40<50:39:49, 18.70s/it]

 39%|███▉      | 6350/16104 [29:26:53<45:41:32, 16.86s/it]

 39%|███▉      | 6351/16104 [29:27:06<42:36:39, 15.73s/it]

 39%|███▉      | 6352/16104 [29:27:19<40:00:56, 14.77s/it]

 39%|███▉      | 6353/16104 [29:27:33<39:25:12, 14.55s/it]


 39%|███▉      | 6355/16104 [29:28:11<45:56:34, 16.97s/it]

 39%|███▉      | 6356/16104 [29:28:31<48:08:02, 17.78s/it]

 39%|███▉      | 6357/16104 [29:28:51<49:58:50, 18.46s/it]

 39%|███▉      | 6358/16104 [29:29:10<50:48:00, 18.76s/it]

 39%|███▉      | 6359/16104 [29:29:30<51:49:10, 19.14s/it]

 39%|███▉      | 6360/16104 [29:29:48<50:40:35, 18.72s/it]

 39%|███▉      | 6361/16104 [29:30:07<50:44:27, 18.75s/it]

 40%|███▉      | 6362/16104 [29:30:25<50:27:51, 18.65s/it]

 40%|███▉      | 6363/16104 [29:30:39<46:15:23, 17.10s/it]

 40%|███▉      | 6364/16104 [29:30:59<48:27:14, 17.91s/it]

 40%|███▉      | 6365/16104 [29:31:18<49:12:42, 18.19s/it]

 40%|███▉      | 6366/16104 [29:31:33<47:09:05, 17.43s/it]

 40%|███▉      | 6367/16104 [29:31:52<48:05:28, 17.78s/it]

 40%|███▉      | 6368/16104 [29:32:12<49:43:38, 18.39s/it]

 40%|███▉      | 6369/16104 [29:32:28<48:10:09, 17.81s/it]
{'loss': 0.4636, 'learning_rate': 1.3775676522398585e-06, 'rewards/chosen': -0.7013167142868042, 'rewards/rejected': -1.4302644729614258, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7289477586746216, 'policy_logps/rejected': -283.86090087890625, 'policy_logps/chosen': -320.5888977050781, 'referece_logps/rejected': -269.55828857421875, 'referece_logps/chosen': -313.57574462890625, 'logits/rejected': -0.40414735674858093, 'logits/chosen': -0.39225417375564575, 'epoch': 2.37}

 40%|███▉      | 6370/16104 [29:32:42<45:07:29, 16.69s/it]


 40%|███▉      | 6372/16104 [29:33:24<50:28:38, 18.67s/it]

 40%|███▉      | 6373/16104 [29:33:38<46:45:28, 17.30s/it]

 40%|███▉      | 6374/16104 [29:33:53<45:13:29, 16.73s/it]

 40%|███▉      | 6375/16104 [29:34:07<42:26:34, 15.71s/it]

 40%|███▉      | 6376/16104 [29:34:19<39:55:19, 14.77s/it]
{'loss': 0.5832, 'learning_rate': 1.3762636032008854e-06, 'rewards/chosen': -0.9461362361907959, 'rewards/rejected': -1.3531901836395264, 'rewards/accuracies': 0.625, 'rewards/margins': 0.40705400705337524, 'policy_logps/rejected': -366.3392333984375, 'policy_logps/chosen': -276.44512939453125, 'referece_logps/rejected': -352.80731201171875, 'referece_logps/chosen': -266.9837951660156, 'logits/rejected': -0.24889253079891205, 'logits/chosen': -0.19749867916107178, 'epoch': 2.38}


 40%|███▉      | 6378/16104 [29:34:48<40:09:24, 14.86s/it]

 40%|███▉      | 6379/16104 [29:35:08<44:00:47, 16.29s/it]

 40%|███▉      | 6380/16104 [29:35:28<46:39:37, 17.27s/it]

 40%|███▉      | 6381/16104 [29:35:47<48:33:45, 17.98s/it]

 40%|███▉      | 6382/16104 [29:36:07<49:55:45, 18.49s/it]

 40%|███▉      | 6383/16104 [29:36:27<51:32:41, 19.09s/it]

 40%|███▉      | 6384/16104 [29:36:47<52:08:23, 19.31s/it]

 40%|███▉      | 6385/16104 [29:37:08<53:26:54, 19.80s/it]
{'loss': 0.4123, 'learning_rate': 1.3745858732058136e-06, 'rewards/chosen': -1.0250595808029175, 'rewards/rejected': -2.94807505607605, 'rewards/accuracies': 0.75, 'rewards/margins': 1.9230155944824219, 'policy_logps/rejected': -468.144775390625, 'policy_logps/chosen': -423.1658630371094, 'referece_logps/rejected': -438.6639709472656, 'referece_logps/chosen': -412.915283203125, 'logits/rejected': 0.511781632900238, 'logits/chosen': 0.47808876633644104, 'epoch': 2.38}


 40%|███▉      | 6387/16104 [29:37:44<50:27:25, 18.69s/it]

 40%|███▉      | 6388/16104 [29:38:04<51:23:53, 19.04s/it]

 40%|███▉      | 6389/16104 [29:38:23<51:34:28, 19.11s/it]

 40%|███▉      | 6390/16104 [29:38:37<47:19:29, 17.54s/it]

 40%|███▉      | 6391/16104 [29:38:57<49:14:48, 18.25s/it]

 40%|███▉      | 6392/16104 [29:39:14<48:23:51, 17.94s/it]

 40%|███▉      | 6393/16104 [29:39:34<50:08:08, 18.59s/it]

 40%|███▉      | 6394/16104 [29:39:46<44:18:08, 16.43s/it]

 40%|███▉      | 6395/16104 [29:40:04<45:26:00, 16.85s/it]

 40%|███▉      | 6396/16104 [29:40:23<47:43:20, 17.70s/it]

 40%|███▉      | 6397/16104 [29:40:40<46:47:15, 17.35s/it]

 40%|███▉      | 6398/16104 [29:40:55<45:13:33, 16.77s/it]

 40%|███▉      | 6399/16104 [29:41:08<41:44:02, 15.48s/it]

 40%|███▉      | 6400/16104 [29:41:28<45:30:08, 16.88s/it]

 40%|███▉      | 6401/16104 [29:41:43<43:56:37, 16.30s/it]

 40%|███▉      | 6402/16104 [29:41:55<40:35:04, 15.06s/it]

 40%|███▉      | 6403/16104 [29:42:08<38:59:48, 14.47s/it]

 40%|███▉      | 6404/16104 [29:42:28<43:12:38, 16.04s/it]

 40%|███▉      | 6405/16104 [29:42:46<44:34:27, 16.54s/it]
{'loss': 0.5587, 'learning_rate': 1.3708531980801949e-06, 'rewards/chosen': -1.1081217527389526, 'rewards/rejected': -1.761932611465454, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6538109183311462, 'policy_logps/rejected': -472.3578186035156, 'policy_logps/chosen': -432.8125915527344, 'referece_logps/rejected': -454.7384948730469, 'referece_logps/chosen': -421.73138427734375, 'logits/rejected': -0.6909737586975098, 'logits/chosen': -0.7330895662307739, 'epoch': 2.39}


 40%|███▉      | 6407/16104 [29:43:21<47:26:04, 17.61s/it]

 40%|███▉      | 6408/16104 [29:43:33<42:43:08, 15.86s/it]

 40%|███▉      | 6409/16104 [29:43:55<47:25:03, 17.61s/it]

 40%|███▉      | 6410/16104 [29:44:11<46:06:43, 17.12s/it]

 40%|███▉      | 6411/16104 [29:44:22<41:32:28, 15.43s/it]

 40%|███▉      | 6412/16104 [29:44:37<41:26:28, 15.39s/it]

 40%|███▉      | 6413/16104 [29:44:54<42:09:47, 15.66s/it]

 40%|███▉      | 6414/16104 [29:45:10<42:53:52, 15.94s/it]

 40%|███▉      | 6415/16104 [29:45:28<44:20:31, 16.48s/it]

 40%|███▉      | 6416/16104 [29:45:40<40:34:39, 15.08s/it]
{'loss': 0.5452, 'learning_rate': 1.368797665113569e-06, 'rewards/chosen': -0.9709146618843079, 'rewards/rejected': -1.51522696018219, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5443122982978821, 'policy_logps/rejected': -446.52294921875, 'policy_logps/chosen': -320.40496826171875, 'referece_logps/rejected': -431.3707275390625, 'referece_logps/chosen': -310.69580078125, 'logits/rejected': -0.9074916839599609, 'logits/chosen': -0.7940211296081543, 'epoch': 2.39}


 40%|███▉      | 6418/16104 [29:46:09<40:34:04, 15.08s/it]

 40%|███▉      | 6419/16104 [29:46:28<44:11:19, 16.43s/it]

 40%|███▉      | 6420/16104 [29:46:40<40:05:56, 14.91s/it]

 40%|███▉      | 6421/16104 [29:47:00<44:10:41, 16.42s/it]

 40%|███▉      | 6422/16104 [29:47:15<43:26:58, 16.16s/it]

 40%|███▉      | 6423/16104 [29:47:34<45:53:28, 17.07s/it]

 40%|███▉      | 6424/16104 [29:47:55<48:19:42, 17.97s/it]

 40%|███▉      | 6425/16104 [29:48:10<46:05:18, 17.14s/it]

 40%|███▉      | 6426/16104 [29:48:23<42:55:55, 15.97s/it]

 40%|███▉      | 6427/16104 [29:48:40<43:32:21, 16.20s/it]

 40%|███▉      | 6428/16104 [29:48:51<39:15:17, 14.60s/it]

 40%|███▉      | 6429/16104 [29:49:04<38:36:05, 14.36s/it]

 40%|███▉      | 6430/16104 [29:49:19<38:47:00, 14.43s/it]

 40%|███▉      | 6431/16104 [29:49:39<43:01:32, 16.01s/it]

 40%|███▉      | 6432/16104 [29:49:55<42:55:17, 15.98s/it]

 40%|███▉      | 6433/16104 [29:50:10<42:29:24, 15.82s/it]

 40%|███▉      | 6434/16104 [29:50:32<47:21:23, 17.63s/it]

 40%|███▉      | 6435/16104 [29:50:48<46:14:58, 17.22s/it]

 40%|███▉      | 6436/16104 [29:51:04<45:13:45, 16.84s/it]

 40%|███▉      | 6437/16104 [29:51:25<48:36:14, 18.10s/it]

 40%|███▉      | 6438/16104 [29:51:38<44:17:55, 16.50s/it]
{'loss': 0.5192, 'learning_rate': 1.364681193828394e-06, 'rewards/chosen': -0.6777133941650391, 'rewards/rejected': -1.6776806116104126, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9999672174453735, 'policy_logps/rejected': -334.069091796875, 'policy_logps/chosen': -364.4853820800781, 'referece_logps/rejected': -317.292236328125, 'referece_logps/chosen': -357.708251953125, 'logits/rejected': -0.7368398904800415, 'logits/chosen': -0.8031196594238281, 'epoch': 2.4}


 40%|███▉      | 6440/16104 [29:52:10<42:40:36, 15.90s/it]

 40%|███▉      | 6441/16104 [29:52:24<41:24:07, 15.42s/it]

 40%|████      | 6442/16104 [29:52:35<37:38:17, 14.02s/it]

 40%|████      | 6443/16104 [29:52:54<41:55:41, 15.62s/it]

 40%|████      | 6444/16104 [29:53:11<42:32:06, 15.85s/it]
{'loss': 0.5906, 'learning_rate': 1.3635572772808474e-06, 'rewards/chosen': -0.9903431534767151, 'rewards/rejected': -1.734401822090149, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7440587282180786, 'policy_logps/rejected': -420.3879699707031, 'policy_logps/chosen': -349.0137939453125, 'referece_logps/rejected': -403.0439453125, 'referece_logps/chosen': -339.1103515625, 'logits/rejected': -0.6377319693565369, 'logits/chosen': -0.5954045057296753, 'epoch': 2.4}


 40%|████      | 6446/16104 [29:53:45<44:57:59, 16.76s/it]

 40%|████      | 6447/16104 [29:53:57<41:07:40, 15.33s/it]

 40%|████      | 6448/16104 [29:54:17<44:39:23, 16.65s/it]
{'loss': 0.5315, 'learning_rate': 1.3628077053506407e-06, 'rewards/chosen': -0.9250421524047852, 'rewards/rejected': -1.558525800704956, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6334836483001709, 'policy_logps/rejected': -311.5213623046875, 'policy_logps/chosen': -423.0318908691406, 'referece_logps/rejected': -295.93609619140625, 'referece_logps/chosen': -413.7814636230469, 'logits/rejected': -0.6174860000610352, 'logits/chosen': -0.5901919603347778, 'epoch': 2.4}


 40%|████      | 6450/16104 [29:54:39<37:09:10, 13.85s/it]

 40%|████      | 6451/16104 [29:54:53<37:33:55, 14.01s/it]

 40%|████      | 6452/16104 [29:55:05<35:23:24, 13.20s/it]

 40%|████      | 6453/16104 [29:55:17<34:54:16, 13.02s/it]

 40%|████      | 6454/16104 [29:55:33<36:54:48, 13.77s/it]
{'loss': 0.5446, 'learning_rate': 1.3616829073204298e-06, 'rewards/chosen': -0.7969323992729187, 'rewards/rejected': -2.25566029548645, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4587279558181763, 'policy_logps/rejected': -395.408447265625, 'policy_logps/chosen': -287.414306640625, 'referece_logps/rejected': -372.8518371582031, 'referece_logps/chosen': -279.4449768066406, 'logits/rejected': -0.8121519088745117, 'logits/chosen': -0.6602205038070679, 'epoch': 2.4}

 40%|████      | 6455/16104 [29:55:44<34:31:20, 12.88s/it]


 40%|████      | 6457/16104 [29:56:15<39:25:25, 14.71s/it]

 40%|████      | 6458/16104 [29:56:33<41:49:41, 15.61s/it]

 40%|████      | 6459/16104 [29:56:52<44:57:49, 16.78s/it]

 40%|████      | 6460/16104 [29:57:08<43:34:18, 16.26s/it]

 40%|████      | 6461/16104 [29:57:27<46:26:42, 17.34s/it]

 40%|████      | 6462/16104 [29:57:48<49:17:02, 18.40s/it]

 40%|████      | 6463/16104 [29:58:08<50:20:09, 18.80s/it]
{'loss': 0.4997, 'learning_rate': 1.3599947232137807e-06, 'rewards/chosen': -0.87843918800354, 'rewards/rejected': -2.1217076778411865, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2432684898376465, 'policy_logps/rejected': -292.002197265625, 'policy_logps/chosen': -351.26080322265625, 'referece_logps/rejected': -270.78509521484375, 'referece_logps/chosen': -342.4764099121094, 'logits/rejected': -0.8385658264160156, 'logits/chosen': -0.9324079751968384, 'epoch': 2.41}


 40%|████      | 6465/16104 [29:58:45<50:30:14, 18.86s/it]

 40%|████      | 6466/16104 [29:59:01<48:28:10, 18.10s/it]

 40%|████      | 6467/16104 [29:59:15<44:44:42, 16.72s/it]

 40%|████      | 6468/16104 [29:59:36<48:07:55, 17.98s/it]

 40%|████      | 6469/16104 [29:59:49<44:00:53, 16.45s/it]
{'loss': 0.4393, 'learning_rate': 1.358868611491946e-06, 'rewards/chosen': -0.7066025137901306, 'rewards/rejected': -1.1293222904205322, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4227197468280792, 'policy_logps/rejected': -288.00323486328125, 'policy_logps/chosen': -458.72869873046875, 'referece_logps/rejected': -276.71002197265625, 'referece_logps/chosen': -451.66265869140625, 'logits/rejected': -0.8188495635986328, 'logits/chosen': -0.855577290058136, 'epoch': 2.41}


 40%|████      | 6471/16104 [30:00:23<45:11:48, 16.89s/it]

 40%|████      | 6472/16104 [30:00:39<45:07:17, 16.86s/it]

 40%|████      | 6473/16104 [30:00:56<44:35:59, 16.67s/it]

 40%|████      | 6474/16104 [30:01:17<48:10:17, 18.01s/it]

 40%|████      | 6475/16104 [30:01:35<48:42:28, 18.21s/it]
{'loss': 0.4743, 'learning_rate': 1.3577419771626456e-06, 'rewards/chosen': -1.3050891160964966, 'rewards/rejected': -2.39481258392334, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0897235870361328, 'policy_logps/rejected': -341.0255126953125, 'policy_logps/chosen': -359.22442626953125, 'referece_logps/rejected': -317.077392578125, 'referece_logps/chosen': -346.1735534667969, 'logits/rejected': -0.16239005327224731, 'logits/chosen': -0.24671578407287598, 'epoch': 2.41}

 40%|████      | 6476/16104 [30:01:48<44:11:04, 16.52s/it]

 40%|████      | 6477/16104 [30:02:04<43:47:01, 16.37s/it]

 40%|████      | 6478/16104 [30:02:20<43:32:43, 16.29s/it]


 40%|████      | 6480/16104 [30:03:00<48:24:17, 18.11s/it]

 40%|████      | 6481/16104 [30:03:19<49:03:39, 18.35s/it]

 40%|████      | 6482/16104 [30:03:39<50:29:11, 18.89s/it]

 40%|████      | 6483/16104 [30:03:59<51:41:20, 19.34s/it]

 40%|████      | 6484/16104 [30:04:18<51:24:26, 19.24s/it]
{'loss': 0.478, 'learning_rate': 1.3560510493688884e-06, 'rewards/chosen': -1.145632028579712, 'rewards/rejected': -2.37589693069458, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2302649021148682, 'policy_logps/rejected': -439.603759765625, 'policy_logps/chosen': -391.1819763183594, 'referece_logps/rejected': -415.8448181152344, 'referece_logps/chosen': -379.7256774902344, 'logits/rejected': -0.8251701593399048, 'logits/chosen': -0.8147264122962952, 'epoch': 2.42}


 40%|████      | 6486/16104 [30:04:47<44:13:37, 16.55s/it]
{'loss': 0.4763, 'learning_rate': 1.355675129009937e-06, 'rewards/chosen': -1.0108025074005127, 'rewards/rejected': -1.4724098443984985, 'rewards/accuracies': 0.625, 'rewards/margins': 0.46160727739334106, 'policy_logps/rejected': -292.3826904296875, 'policy_logps/chosen': -259.66107177734375, 'referece_logps/rejected': -277.6585693359375, 'referece_logps/chosen': -249.55303955078125, 'logits/rejected': 0.3686930537223816, 'logits/chosen': 0.36371874809265137, 'epoch': 2.42}


 40%|████      | 6488/16104 [30:05:24<46:40:23, 17.47s/it]

 40%|████      | 6489/16104 [30:05:39<44:49:34, 16.78s/it]

 40%|████      | 6490/16104 [30:05:56<44:38:09, 16.71s/it]

 40%|████      | 6491/16104 [30:06:10<42:24:51, 15.88s/it]
{'loss': 0.4141, 'learning_rate': 1.354735076461003e-06, 'rewards/chosen': -0.9067438840866089, 'rewards/rejected': -2.4409544467926025, 'rewards/accuracies': 0.875, 'rewards/margins': 1.534210443496704, 'policy_logps/rejected': -495.28887939453125, 'policy_logps/chosen': -478.6659240722656, 'referece_logps/rejected': -470.8793029785156, 'referece_logps/chosen': -469.5984802246094, 'logits/rejected': -1.0611048936843872, 'logits/chosen': -1.022223949432373, 'epoch': 2.42}


 40%|████      | 6493/16104 [30:06:45<45:21:58, 16.99s/it]
{'loss': 0.4922, 'learning_rate': 1.3543589549405198e-06, 'rewards/chosen': -0.5629337430000305, 'rewards/rejected': -2.5463173389434814, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9833834171295166, 'policy_logps/rejected': -376.5696716308594, 'policy_logps/chosen': -386.5638732910156, 'referece_logps/rejected': -351.1064758300781, 'referece_logps/chosen': -380.9345397949219, 'logits/rejected': 0.4376680254936218, 'logits/chosen': 0.39249104261398315, 'epoch': 2.42}


 40%|████      | 6495/16104 [30:07:20<46:44:37, 17.51s/it]
{'loss': 0.4414, 'learning_rate': 1.353982776082229e-06, 'rewards/chosen': -0.7159243822097778, 'rewards/rejected': -2.4369611740112305, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7210371494293213, 'policy_logps/rejected': -326.2857971191406, 'policy_logps/chosen': -401.7360534667969, 'referece_logps/rejected': -301.9162292480469, 'referece_logps/chosen': -394.5767822265625, 'logits/rejected': -0.2673497796058655, 'logits/chosen': -0.3372757136821747, 'epoch': 2.42}


 40%|████      | 6497/16104 [30:07:56<47:04:51, 17.64s/it]
{'loss': 0.5757, 'learning_rate': 1.3536065399469987e-06, 'rewards/chosen': -0.5422924160957336, 'rewards/rejected': -1.4552085399627686, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9129162430763245, 'policy_logps/rejected': -227.18136596679688, 'policy_logps/chosen': -253.59259033203125, 'referece_logps/rejected': -212.62925720214844, 'referece_logps/chosen': -248.16966247558594, 'logits/rejected': -0.7394577860832214, 'logits/chosen': -0.7628964185714722, 'epoch': 2.42}


 40%|████      | 6499/16104 [30:08:24<43:12:20, 16.19s/it]

 40%|████      | 6500/16104 [30:08:44<45:55:55, 17.22s/it]
{'loss': 0.5814, 'learning_rate': 1.3530420784830648e-06, 'rewards/chosen': -1.4020024538040161, 'rewards/rejected': -3.11728572845459, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7152831554412842, 'policy_logps/rejected': -442.83935546875, 'policy_logps/chosen': -474.8447265625, 'referece_logps/rejected': -411.6664733886719, 'referece_logps/chosen': -460.82464599609375, 'logits/rejected': -0.3751690089702606, 'logits/chosen': -0.3495984673500061, 'epoch': 2.42}

 40%|████      | 6501/16104 [30:09:19<59:51:41, 22.44s/it]


 40%|████      | 6503/16104 [30:09:50<51:18:04, 19.24s/it]
{'loss': 0.5691, 'learning_rate': 1.3524774884884954e-06, 'rewards/chosen': -1.2975679636001587, 'rewards/rejected': -2.610186815261841, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3126188516616821, 'policy_logps/rejected': -414.938232421875, 'policy_logps/chosen': -489.28350830078125, 'referece_logps/rejected': -388.8363952636719, 'referece_logps/chosen': -476.30780029296875, 'logits/rejected': 0.012721743434667587, 'logits/chosen': -0.13693851232528687, 'epoch': 2.42}

 40%|████      | 6504/16104 [30:10:01<44:31:11, 16.69s/it]

 40%|████      | 6505/16104 [30:10:13<40:35:43, 15.22s/it]

 40%|████      | 6506/16104 [30:10:27<39:47:01, 14.92s/it]

 40%|████      | 6507/16104 [30:10:43<40:49:19, 15.31s/it]


 40%|████      | 6509/16104 [30:11:10<38:27:55, 14.43s/it]
{'loss': 0.5852, 'learning_rate': 1.35134792372969e-06, 'rewards/chosen': -0.9745351076126099, 'rewards/rejected': -1.0597225427627563, 'rewards/accuracies': 0.375, 'rewards/margins': 0.08518742769956589, 'policy_logps/rejected': -413.5050048828125, 'policy_logps/chosen': -346.32220458984375, 'referece_logps/rejected': -402.9078063964844, 'referece_logps/chosen': -336.57684326171875, 'logits/rejected': 0.5108118057250977, 'logits/chosen': 0.5028107166290283, 'epoch': 2.43}


 40%|████      | 6511/16104 [30:11:34<34:45:08, 13.04s/it]
{'loss': 0.6083, 'learning_rate': 1.3509712883609778e-06, 'rewards/chosen': -1.109743356704712, 'rewards/rejected': -1.2436469793319702, 'rewards/accuracies': 0.375, 'rewards/margins': 0.13390350341796875, 'policy_logps/rejected': -318.5576171875, 'policy_logps/chosen': -420.08123779296875, 'referece_logps/rejected': -306.1211242675781, 'referece_logps/chosen': -408.9837646484375, 'logits/rejected': -1.3807868957519531, 'logits/chosen': -1.6276026964187622, 'epoch': 2.43}


 40%|████      | 6513/16104 [30:12:10<40:40:03, 15.26s/it]
{'loss': 0.4807, 'learning_rate': 1.3505945962026064e-06, 'rewards/chosen': -0.9904727935791016, 'rewards/rejected': -1.6397995948791504, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6493269205093384, 'policy_logps/rejected': -410.2351989746094, 'policy_logps/chosen': -411.5486755371094, 'referece_logps/rejected': -393.8371887207031, 'referece_logps/chosen': -401.6439514160156, 'logits/rejected': -0.24666407704353333, 'logits/chosen': -0.11162742972373962, 'epoch': 2.43}


 40%|████      | 6515/16104 [30:12:44<44:15:03, 16.61s/it]

 40%|████      | 6516/16104 [30:13:00<43:40:43, 16.40s/it]

 40%|████      | 6517/16104 [30:13:20<46:20:31, 17.40s/it]
{'loss': 0.5342, 'learning_rate': 1.3498410417607013e-06, 'rewards/chosen': -1.2495039701461792, 'rewards/rejected': -2.373530864715576, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1240267753601074, 'policy_logps/rejected': -446.22772216796875, 'policy_logps/chosen': -412.3404541015625, 'referece_logps/rejected': -422.49237060546875, 'referece_logps/chosen': -399.8453674316406, 'logits/rejected': 0.19700245559215546, 'logits/chosen': 0.18759305775165558, 'epoch': 2.43}

 40%|████      | 6518/16104 [30:13:37<46:31:56, 17.48s/it]


 40%|████      | 6520/16104 [30:14:08<42:24:14, 15.93s/it]

 40%|████      | 6521/16104 [30:14:28<45:40:39, 17.16s/it]

 40%|████      | 6522/16104 [30:14:48<48:20:25, 18.16s/it]
{'loss': 0.5025, 'learning_rate': 1.3488987803523807e-06, 'rewards/chosen': -0.7955458164215088, 'rewards/rejected': -1.2751256227493286, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4795798659324646, 'policy_logps/rejected': -312.2200927734375, 'policy_logps/chosen': -380.2585144042969, 'referece_logps/rejected': -299.4688720703125, 'referece_logps/chosen': -372.3030700683594, 'logits/rejected': -0.5981569886207581, 'logits/chosen': -0.5639055967330933, 'epoch': 2.43}


 41%|████      | 6524/16104 [30:15:10<38:23:29, 14.43s/it]
{'loss': 0.587, 'learning_rate': 1.3485217769406376e-06, 'rewards/chosen': -0.9855918884277344, 'rewards/rejected': -1.9019783735275269, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9163864850997925, 'policy_logps/rejected': -423.39239501953125, 'policy_logps/chosen': -266.3717041015625, 'referece_logps/rejected': -404.37261962890625, 'referece_logps/chosen': -256.5157775878906, 'logits/rejected': -0.2138458490371704, 'logits/chosen': -0.01920682191848755, 'epoch': 2.43}


 41%|████      | 6526/16104 [30:15:36<36:02:08, 13.54s/it]

 41%|████      | 6527/16104 [30:15:47<33:40:33, 12.66s/it]

 41%|████      | 6528/16104 [30:16:03<36:07:16, 13.58s/it]
{'loss': 0.5133, 'learning_rate': 1.347767600998231e-06, 'rewards/chosen': -0.47613048553466797, 'rewards/rejected': -2.370131254196167, 'rewards/accuracies': 1.0, 'rewards/margins': 1.894000768661499, 'policy_logps/rejected': -311.51190185546875, 'policy_logps/chosen': -426.6177978515625, 'referece_logps/rejected': -287.81060791015625, 'referece_logps/chosen': -421.8565368652344, 'logits/rejected': -0.8999271392822266, 'logits/chosen': -0.9730890989303589, 'epoch': 2.43}


 41%|████      | 6530/16104 [30:16:28<35:49:25, 13.47s/it]
{'loss': 0.5879, 'learning_rate': 1.347390428589598e-06, 'rewards/chosen': -1.219627022743225, 'rewards/rejected': -2.3306844234466553, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1110574007034302, 'policy_logps/rejected': -626.04541015625, 'policy_logps/chosen': -466.08807373046875, 'referece_logps/rejected': -602.7385864257812, 'referece_logps/chosen': -453.89178466796875, 'logits/rejected': -0.29551172256469727, 'logits/chosen': -0.27381956577301025, 'epoch': 2.43}

 41%|████      | 6531/16104 [30:16:49<41:39:53, 15.67s/it]

 41%|████      | 6532/16104 [30:17:09<45:03:35, 16.95s/it]


 41%|████      | 6534/16104 [30:17:35<39:27:45, 14.84s/it]
{'loss': 0.5776, 'learning_rate': 1.3466359152026195e-06, 'rewards/chosen': -1.148769736289978, 'rewards/rejected': -1.4973186254501343, 'rewards/accuracies': 0.5, 'rewards/margins': 0.34854891896247864, 'policy_logps/rejected': -362.0770263671875, 'policy_logps/chosen': -381.9077453613281, 'referece_logps/rejected': -347.10382080078125, 'referece_logps/chosen': -370.4200744628906, 'logits/rejected': -0.5121245384216309, 'logits/chosen': -0.5148260593414307, 'epoch': 2.43}


 41%|████      | 6536/16104 [30:18:06<40:36:31, 15.28s/it]

 41%|████      | 6537/16104 [30:18:24<42:30:53, 16.00s/it]
{'loss': 0.5826, 'learning_rate': 1.346069882904247e-06, 'rewards/chosen': -1.014020562171936, 'rewards/rejected': -1.3754104375839233, 'rewards/accuracies': 0.875, 'rewards/margins': 0.36138981580734253, 'policy_logps/rejected': -481.8998107910156, 'policy_logps/chosen': -362.17742919921875, 'referece_logps/rejected': -468.14569091796875, 'referece_logps/chosen': -352.0372314453125, 'logits/rejected': -0.40195274353027344, 'logits/chosen': -0.39690330624580383, 'epoch': 2.44}

 41%|████      | 6538/16104 [30:18:45<46:45:15, 17.60s/it]


 41%|████      | 6540/16104 [30:19:21<47:33:18, 17.90s/it]

 41%|████      | 6541/16104 [30:19:32<42:22:14, 15.95s/it]

 41%|████      | 6542/16104 [30:19:49<42:35:23, 16.03s/it]

 41%|████      | 6543/16104 [30:20:04<42:24:54, 15.97s/it]

 41%|████      | 6544/16104 [30:20:16<39:03:50, 14.71s/it]
{'loss': 0.61, 'learning_rate': 1.3447486512609353e-06, 'rewards/chosen': -1.0029146671295166, 'rewards/rejected': -1.3055639266967773, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3026494085788727, 'policy_logps/rejected': -545.6425170898438, 'policy_logps/chosen': -469.49542236328125, 'referece_logps/rejected': -532.5868530273438, 'referece_logps/chosen': -459.4662780761719, 'logits/rejected': 0.031691133975982666, 'logits/chosen': 0.12356796860694885, 'epoch': 2.44}


 41%|████      | 6546/16104 [30:20:38<33:55:46, 12.78s/it]
{'loss': 0.5787, 'learning_rate': 1.3443710308798785e-06, 'rewards/chosen': -0.43472766876220703, 'rewards/rejected': -0.6276195645332336, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1928918957710266, 'policy_logps/rejected': -394.86480712890625, 'policy_logps/chosen': -326.52056884765625, 'referece_logps/rejected': -388.5886535644531, 'referece_logps/chosen': -322.1733093261719, 'logits/rejected': -1.1847202777862549, 'logits/chosen': -1.11762273311615, 'epoch': 2.44}


 41%|████      | 6548/16104 [30:21:12<40:35:25, 15.29s/it]

 41%|████      | 6549/16104 [30:21:32<44:04:35, 16.61s/it]

 41%|████      | 6550/16104 [30:21:45<41:16:36, 15.55s/it]

 41%|████      | 6551/16104 [30:22:04<44:13:39, 16.67s/it]

 41%|████      | 6552/16104 [30:22:21<44:13:34, 16.67s/it]
{'loss': 0.4994, 'learning_rate': 1.3432378356510194e-06, 'rewards/chosen': -0.683313250541687, 'rewards/rejected': -1.3692774772644043, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6859642267227173, 'policy_logps/rejected': -464.88238525390625, 'policy_logps/chosen': -431.9190979003906, 'referece_logps/rejected': -451.1895751953125, 'referece_logps/chosen': -425.08599853515625, 'logits/rejected': -0.24052117764949799, 'logits/chosen': -0.23688992857933044, 'epoch': 2.44}

 41%|████      | 6553/16104 [30:22:36<42:32:21, 16.03s/it]


 41%|████      | 6555/16104 [30:23:07<40:49:06, 15.39s/it]
{'loss': 0.5744, 'learning_rate': 1.3426710504915742e-06, 'rewards/chosen': -0.9410165548324585, 'rewards/rejected': -1.4688113927841187, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5277948975563049, 'policy_logps/rejected': -355.1909484863281, 'policy_logps/chosen': -383.1498718261719, 'referece_logps/rejected': -340.5028381347656, 'referece_logps/chosen': -373.73968505859375, 'logits/rejected': -0.10770536214113235, 'logits/chosen': -0.1729535013437271, 'epoch': 2.44}


 41%|████      | 6557/16104 [30:23:39<41:34:53, 15.68s/it]
{'loss': 0.5469, 'learning_rate': 1.3422931243975955e-06, 'rewards/chosen': -0.34022679924964905, 'rewards/rejected': -1.2109612226486206, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8707343339920044, 'policy_logps/rejected': -384.8255920410156, 'policy_logps/chosen': -429.5249938964844, 'referece_logps/rejected': -372.7159729003906, 'referece_logps/chosen': -426.1226806640625, 'logits/rejected': -0.22270625829696655, 'logits/chosen': -0.15647989511489868, 'epoch': 2.44}


 41%|████      | 6559/16104 [30:24:13<43:57:13, 16.58s/it]

 41%|████      | 6560/16104 [30:24:29<43:33:36, 16.43s/it]
{'loss': 0.5655, 'learning_rate': 1.3417261314279831e-06, 'rewards/chosen': -0.22306518256664276, 'rewards/rejected': -1.1377136707305908, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9146484732627869, 'policy_logps/rejected': -372.6840515136719, 'policy_logps/chosen': -406.04852294921875, 'referece_logps/rejected': -361.306884765625, 'referece_logps/chosen': -403.81787109375, 'logits/rejected': 0.3796231150627136, 'logits/chosen': 0.31466221809387207, 'epoch': 2.44}

 41%|████      | 6561/16104 [30:24:49<46:30:21, 17.54s/it]

 41%|████      | 6562/16104 [30:25:01<42:08:45, 15.90s/it]

 41%|████      | 6563/16104 [30:25:18<42:33:05, 16.06s/it]


 41%|████      | 6565/16104 [30:25:49<41:06:56, 15.52s/it]
{'loss': 0.5118, 'learning_rate': 1.3407808667786244e-06, 'rewards/chosen': -0.7262694835662842, 'rewards/rejected': -1.265586256980896, 'rewards/accuracies': 0.5, 'rewards/margins': 0.539316713809967, 'policy_logps/rejected': -406.4564208984375, 'policy_logps/chosen': -468.7191467285156, 'referece_logps/rejected': -393.8005676269531, 'referece_logps/chosen': -461.4564208984375, 'logits/rejected': -1.017958164215088, 'logits/chosen': -0.8550174832344055, 'epoch': 2.45}

 41%|████      | 6566/16104 [30:26:08<43:44:04, 16.51s/it]


 41%|████      | 6568/16104 [30:26:33<37:44:13, 14.25s/it]
{'loss': 0.5321, 'learning_rate': 1.3402135425054981e-06, 'rewards/chosen': -0.7158184051513672, 'rewards/rejected': -1.010353922843933, 'rewards/accuracies': 0.5, 'rewards/margins': 0.29453542828559875, 'policy_logps/rejected': -452.80657958984375, 'policy_logps/chosen': -515.3538208007812, 'referece_logps/rejected': -442.7030334472656, 'referece_logps/chosen': -508.19561767578125, 'logits/rejected': -0.44579368829727173, 'logits/chosen': -0.569113552570343, 'epoch': 2.45}


 41%|████      | 6570/16104 [30:27:01<37:47:39, 14.27s/it]
{'loss': 0.5772, 'learning_rate': 1.3398352574994396e-06, 'rewards/chosen': -0.8739545941352844, 'rewards/rejected': -1.588200330734253, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7142457962036133, 'policy_logps/rejected': -387.4962463378906, 'policy_logps/chosen': -362.3818054199219, 'referece_logps/rejected': -371.6142272949219, 'referece_logps/chosen': -353.6422119140625, 'logits/rejected': -0.004226118326187134, 'logits/chosen': -0.00783492624759674, 'epoch': 2.45}


 41%|████      | 6572/16104 [30:27:32<40:21:30, 15.24s/it]

 41%|████      | 6573/16104 [30:27:45<39:09:35, 14.79s/it]

 41%|████      | 6574/16104 [30:28:03<41:13:43, 15.57s/it]
{'loss': 0.5171, 'learning_rate': 1.3390785225852312e-06, 'rewards/chosen': -0.6520977020263672, 'rewards/rejected': -1.1680595874786377, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5159618854522705, 'policy_logps/rejected': -400.9013977050781, 'policy_logps/chosen': -382.6870422363281, 'referece_logps/rejected': -389.2208251953125, 'referece_logps/chosen': -376.16607666015625, 'logits/rejected': -0.4622161388397217, 'logits/chosen': -0.393269419670105, 'epoch': 2.45}


 41%|████      | 6576/16104 [30:28:39<44:27:36, 16.80s/it]
{'loss': 0.5785, 'learning_rate': 1.3387000727995263e-06, 'rewards/chosen': -0.5554335713386536, 'rewards/rejected': -1.05303156375885, 'rewards/accuracies': 0.875, 'rewards/margins': 0.49759799242019653, 'policy_logps/rejected': -416.19921875, 'policy_logps/chosen': -411.0486755371094, 'referece_logps/rejected': -405.6689147949219, 'referece_logps/chosen': -405.49432373046875, 'logits/rejected': -0.4607933759689331, 'logits/chosen': -0.33527833223342896, 'epoch': 2.45}

 41%|████      | 6577/16104 [30:28:54<42:50:39, 16.19s/it]


 41%|████      | 6579/16104 [30:29:32<46:39:50, 17.64s/it]
{'loss': 0.5447, 'learning_rate': 1.3381322953824412e-06, 'rewards/chosen': -0.5733841061592102, 'rewards/rejected': -1.0439246892929077, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4705405831336975, 'policy_logps/rejected': -375.1466979980469, 'policy_logps/chosen': -353.0748291015625, 'referece_logps/rejected': -364.70745849609375, 'referece_logps/chosen': -347.3409729003906, 'logits/rejected': 0.1635890156030655, 'logits/chosen': -0.18838337063789368, 'epoch': 2.45}


 41%|████      | 6581/16104 [30:30:09<48:43:00, 18.42s/it]
{'loss': 0.5461, 'learning_rate': 1.337753708701351e-06, 'rewards/chosen': -0.5583282709121704, 'rewards/rejected': -1.2909603118896484, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7326321005821228, 'policy_logps/rejected': -392.7203369140625, 'policy_logps/chosen': -374.76275634765625, 'referece_logps/rejected': -379.8106994628906, 'referece_logps/chosen': -369.1794738769531, 'logits/rejected': -0.6920779347419739, 'logits/chosen': -0.6775296330451965, 'epoch': 2.45}


 41%|████      | 6583/16104 [30:30:43<46:08:25, 17.45s/it]
{'loss': 0.5323, 'learning_rate': 1.3373750673693004e-06, 'rewards/chosen': -1.2738711833953857, 'rewards/rejected': -1.4568065404891968, 'rewards/accuracies': 0.5, 'rewards/margins': 0.18293537199497223, 'policy_logps/rejected': -375.75030517578125, 'policy_logps/chosen': -423.8676452636719, 'referece_logps/rejected': -361.1822204589844, 'referece_logps/chosen': -411.12896728515625, 'logits/rejected': -0.1347978413105011, 'logits/chosen': -0.11308256536722183, 'epoch': 2.45}

 41%|████      | 6584/16104 [30:31:03<47:49:31, 18.09s/it]

 41%|████      | 6585/16104 [30:31:15<43:00:27, 16.27s/it]


 41%|████      | 6587/16104 [30:31:49<43:42:10, 16.53s/it]
{'loss': 0.5518, 'learning_rate': 1.336617620997394e-06, 'rewards/chosen': -0.761665940284729, 'rewards/rejected': -1.7904492616653442, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0287833213806152, 'policy_logps/rejected': -511.278564453125, 'policy_logps/chosen': -607.78564453125, 'referece_logps/rejected': -493.3740539550781, 'referece_logps/chosen': -600.1690673828125, 'logits/rejected': -0.06717456877231598, 'logits/chosen': -0.09867000579833984, 'epoch': 2.45}

 41%|████      | 6588/16104 [30:32:02<41:14:53, 15.60s/it]

 41%|████      | 6589/16104 [30:32:16<39:55:52, 15.11s/it]

 41%|████      | 6590/16104 [30:32:31<39:10:14, 14.82s/it]


 41%|████      | 6592/16104 [30:33:09<45:26:08, 17.20s/it]
{'loss': 0.5675, 'learning_rate': 1.3356705067123627e-06, 'rewards/chosen': -0.8965843915939331, 'rewards/rejected': -1.7492307424545288, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8526464104652405, 'policy_logps/rejected': -426.3558654785156, 'policy_logps/chosen': -362.9786376953125, 'referece_logps/rejected': -408.8636169433594, 'referece_logps/chosen': -354.0128173828125, 'logits/rejected': -0.5091327428817749, 'logits/chosen': -0.19527050852775574, 'epoch': 2.46}

 41%|████      | 6593/16104 [30:33:26<45:22:43, 17.18s/it]


 41%|████      | 6595/16104 [30:33:55<41:44:48, 15.80s/it]

 41%|████      | 6596/16104 [30:34:11<42:20:11, 16.03s/it]
{'loss': 0.5217, 'learning_rate': 1.334912570825893e-06, 'rewards/chosen': -0.5800806283950806, 'rewards/rejected': -0.8757349252700806, 'rewards/accuracies': 0.875, 'rewards/margins': 0.295654296875, 'policy_logps/rejected': -325.26007080078125, 'policy_logps/chosen': -348.9261169433594, 'referece_logps/rejected': -316.5027160644531, 'referece_logps/chosen': -343.12530517578125, 'logits/rejected': 0.518160343170166, 'logits/chosen': 0.5237590670585632, 'epoch': 2.46}


 41%|████      | 6598/16104 [30:34:44<41:51:06, 15.85s/it]

 41%|████      | 6599/16104 [30:34:57<39:54:44, 15.12s/it]
{'loss': 0.5652, 'learning_rate': 1.334343976632198e-06, 'rewards/chosen': -1.4340834617614746, 'rewards/rejected': -1.8818094730377197, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4477260708808899, 'policy_logps/rejected': -516.7283325195312, 'policy_logps/chosen': -451.67938232421875, 'referece_logps/rejected': -497.9102478027344, 'referece_logps/chosen': -437.3385009765625, 'logits/rejected': -0.8494474291801453, 'logits/chosen': -0.8968628644943237, 'epoch': 2.46}

 41%|████      | 6600/16104 [30:35:15<41:49:33, 15.84s/it]


 41%|████      | 6602/16104 [30:35:50<44:36:06, 16.90s/it]
{'loss': 0.3735, 'learning_rate': 1.333775260715212e-06, 'rewards/chosen': -0.7694692611694336, 'rewards/rejected': -1.360595464706421, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5911260843276978, 'policy_logps/rejected': -349.6644287109375, 'policy_logps/chosen': -446.814208984375, 'referece_logps/rejected': -336.0584716796875, 'referece_logps/chosen': -439.1195068359375, 'logits/rejected': -0.41400089859962463, 'logits/chosen': -0.3842640817165375, 'epoch': 2.46}

 41%|████      | 6603/16104 [30:36:07<45:12:41, 17.13s/it]

 41%|████      | 6604/16104 [30:36:27<47:08:54, 17.87s/it]

 41%|████      | 6605/16104 [30:36:41<43:55:48, 16.65s/it]

 41%|████      | 6606/16104 [30:37:01<47:03:08, 17.83s/it]

 41%|████      | 6607/16104 [30:37:22<48:49:51, 18.51s/it]

 41%|████      | 6608/16104 [30:37:41<49:38:24, 18.82s/it]

 41%|████      | 6609/16104 [30:37:57<47:25:22, 17.98s/it]

 41%|████      | 6610/16104 [30:38:15<47:06:16, 17.86s/it]


 41%|████      | 6612/16104 [30:38:38<38:54:44, 14.76s/it]

 41%|████      | 6613/16104 [30:38:54<39:59:03, 15.17s/it]

 41%|████      | 6614/16104 [30:39:08<39:00:08, 14.80s/it]

 41%|████      | 6615/16104 [30:39:28<42:59:51, 16.31s/it]

 41%|████      | 6616/16104 [30:39:46<44:35:00, 16.92s/it]
{'loss': 0.474, 'learning_rate': 1.3311196497350927e-06, 'rewards/chosen': -0.6371389627456665, 'rewards/rejected': -1.3011760711669922, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6640372276306152, 'policy_logps/rejected': -373.512939453125, 'policy_logps/chosen': -275.04052734375, 'referece_logps/rejected': -360.5011901855469, 'referece_logps/chosen': -268.66912841796875, 'logits/rejected': -0.01859194040298462, 'logits/chosen': -0.01477429922670126, 'epoch': 2.46}


 41%|████      | 6618/16104 [30:40:14<39:40:58, 15.06s/it]

 41%|████      | 6619/16104 [30:40:34<43:57:38, 16.69s/it]

 41%|████      | 6620/16104 [30:40:50<43:09:07, 16.38s/it]
{'loss': 0.4813, 'learning_rate': 1.3303604206220843e-06, 'rewards/chosen': -1.4655855894088745, 'rewards/rejected': -2.1614584922790527, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6958726644515991, 'policy_logps/rejected': -383.8725891113281, 'policy_logps/chosen': -320.7994384765625, 'referece_logps/rejected': -362.25799560546875, 'referece_logps/chosen': -306.1435546875, 'logits/rejected': -0.4256756603717804, 'logits/chosen': -0.4086597263813019, 'epoch': 2.47}

 41%|████      | 6621/16104 [30:41:01<38:44:02, 14.70s/it]

 41%|████      | 6622/16104 [30:41:21<43:20:17, 16.45s/it]

 41%|████      | 6623/16104 [30:41:41<46:15:22, 17.56s/it]

 41%|████      | 6624/16104 [30:41:59<45:51:05, 17.41s/it]

 41%|████      | 6625/16104 [30:42:09<40:26:16, 15.36s/it]


 41%|████      | 6627/16104 [30:42:30<34:03:49, 12.94s/it]
{'loss': 0.5997, 'learning_rate': 1.3290312554687896e-06, 'rewards/chosen': -0.766573965549469, 'rewards/rejected': -1.2969474792480469, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5303734540939331, 'policy_logps/rejected': -292.904296875, 'policy_logps/chosen': -299.8784484863281, 'referece_logps/rejected': -279.934814453125, 'referece_logps/chosen': -292.21270751953125, 'logits/rejected': -0.8898333311080933, 'logits/chosen': -0.8934215903282166, 'epoch': 2.47}


 41%|████      | 6629/16104 [30:42:58<36:14:28, 13.77s/it]
{'loss': 0.4279, 'learning_rate': 1.328651374092079e-06, 'rewards/chosen': -0.38424137234687805, 'rewards/rejected': -1.1512950658798218, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7670536637306213, 'policy_logps/rejected': -348.8524169921875, 'policy_logps/chosen': -389.49212646484375, 'referece_logps/rejected': -337.3394470214844, 'referece_logps/chosen': -385.6496887207031, 'logits/rejected': -0.506155252456665, 'logits/chosen': -0.557574987411499, 'epoch': 2.47}

 41%|████      | 6630/16104 [30:43:09<33:52:01, 12.87s/it]


 41%|████      | 6632/16104 [30:43:44<39:37:49, 15.06s/it]
{'loss': 0.4932, 'learning_rate': 1.328081452337215e-06, 'rewards/chosen': -0.984253466129303, 'rewards/rejected': -1.2951762676239014, 'rewards/accuracies': 0.5, 'rewards/margins': 0.310922771692276, 'policy_logps/rejected': -449.9801940917969, 'policy_logps/chosen': -445.4611511230469, 'referece_logps/rejected': -437.0284423828125, 'referece_logps/chosen': -435.6186218261719, 'logits/rejected': -0.1637517511844635, 'logits/chosen': -0.13987044990062714, 'epoch': 2.47}


 41%|████      | 6634/16104 [30:44:20<43:57:05, 16.71s/it]

 41%|████      | 6635/16104 [30:44:32<40:33:11, 15.42s/it]

 41%|████      | 6636/16104 [30:44:52<44:10:06, 16.79s/it]

 41%|████      | 6637/16104 [30:45:10<44:56:38, 17.09s/it]
{'loss': 0.4538, 'learning_rate': 1.327131317418662e-06, 'rewards/chosen': -1.0496052503585815, 'rewards/rejected': -1.640400767326355, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5907953977584839, 'policy_logps/rejected': -319.8366394042969, 'policy_logps/chosen': -326.7409362792969, 'referece_logps/rejected': -303.4326477050781, 'referece_logps/chosen': -316.244873046875, 'logits/rejected': -1.115177035331726, 'logits/chosen': -1.1406440734863281, 'epoch': 2.47}


 41%|████      | 6639/16104 [30:45:44<44:19:53, 16.86s/it]
{'loss': 0.507, 'learning_rate': 1.3267511707661098e-06, 'rewards/chosen': -1.0721443891525269, 'rewards/rejected': -1.6609395742416382, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5887952446937561, 'policy_logps/rejected': -412.12939453125, 'policy_logps/chosen': -486.2335510253906, 'referece_logps/rejected': -395.52001953125, 'referece_logps/chosen': -475.5120849609375, 'logits/rejected': -0.43778517842292786, 'logits/chosen': -0.2998349964618683, 'epoch': 2.47}


 41%|████      | 6641/16104 [30:46:19<44:14:05, 16.83s/it]
{'loss': 0.4135, 'learning_rate': 1.326370971242886e-06, 'rewards/chosen': -0.8242014050483704, 'rewards/rejected': -1.5183862447738647, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6941848397254944, 'policy_logps/rejected': -385.46710205078125, 'policy_logps/chosen': -449.12530517578125, 'referece_logps/rejected': -370.2831726074219, 'referece_logps/chosen': -440.88330078125, 'logits/rejected': 0.13993164896965027, 'logits/chosen': 0.0724756270647049, 'epoch': 2.47}

 41%|████      | 6642/16104 [30:46:34<42:40:39, 16.24s/it]


 41%|████▏     | 6644/16104 [30:47:13<46:57:53, 17.87s/it]
{'loss': 0.5163, 'learning_rate': 1.3258005729601176e-06, 'rewards/chosen': -1.2047617435455322, 'rewards/rejected': -1.5167077779769897, 'rewards/accuracies': 0.375, 'rewards/margins': 0.3119460642337799, 'policy_logps/rejected': -398.8297424316406, 'policy_logps/chosen': -402.4309387207031, 'referece_logps/rejected': -383.6627197265625, 'referece_logps/chosen': -390.3833312988281, 'logits/rejected': -0.007620152086019516, 'logits/chosen': -0.016710538417100906, 'epoch': 2.48}

 41%|████▏     | 6645/16104 [30:47:32<47:51:48, 18.22s/it]


 41%|████▏     | 6647/16104 [30:48:05<44:38:55, 17.00s/it]

 41%|████▏     | 6648/16104 [30:48:16<40:26:53, 15.40s/it]
{'loss': 0.4796, 'learning_rate': 1.3250398574433255e-06, 'rewards/chosen': -0.7028433084487915, 'rewards/rejected': -2.0681705474853516, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3653271198272705, 'policy_logps/rejected': -258.980224609375, 'policy_logps/chosen': -402.67242431640625, 'referece_logps/rejected': -238.29852294921875, 'referece_logps/chosen': -395.64398193359375, 'logits/rejected': -0.8074489235877991, 'logits/chosen': -0.7966850399971008, 'epoch': 2.48}

 41%|████▏     | 6649/16104 [30:48:36<43:42:33, 16.64s/it]


 41%|████▏     | 6651/16104 [30:49:09<43:05:20, 16.41s/it]

 41%|████▏     | 6652/16104 [30:49:29<45:54:35, 17.49s/it]

 41%|████▏     | 6653/16104 [30:49:48<47:31:59, 18.11s/it]
{'loss': 0.4684, 'learning_rate': 1.3240886672651103e-06, 'rewards/chosen': -0.9479257464408875, 'rewards/rejected': -1.8812012672424316, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9332754611968994, 'policy_logps/rejected': -303.18988037109375, 'policy_logps/chosen': -357.53619384765625, 'referece_logps/rejected': -284.37786865234375, 'referece_logps/chosen': -348.0569152832031, 'logits/rejected': -0.02443191409111023, 'logits/chosen': 0.039226993918418884, 'epoch': 2.48}

 41%|████▏     | 6654/16104 [30:50:06<46:51:03, 17.85s/it]

 41%|████▏     | 6655/16104 [30:50:20<43:49:14, 16.70s/it]

 41%|████▏     | 6656/16104 [30:50:36<43:54:36, 16.73s/it]

 41%|████▏     | 6657/16104 [30:50:52<42:42:04, 16.27s/it]

 41%|████▏     | 6658/16104 [30:51:06<41:31:16, 15.82s/it]

 41%|████▏     | 6659/16104 [30:51:26<44:27:34, 16.95s/it]


 41%|████▏     | 6661/16104 [30:51:55<41:27:37, 15.81s/it]
{'loss': 0.4277, 'learning_rate': 1.322566081662134e-06, 'rewards/chosen': -0.7317500710487366, 'rewards/rejected': -1.8117034435272217, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0799534320831299, 'policy_logps/rejected': -245.97335815429688, 'policy_logps/chosen': -584.3002319335938, 'referece_logps/rejected': -227.8563232421875, 'referece_logps/chosen': -576.9827270507812, 'logits/rejected': -0.6332968473434448, 'logits/chosen': -0.8582451939582825, 'epoch': 2.48}

 41%|████▏     | 6662/16104 [30:52:16<46:06:59, 17.58s/it]


 41%|████▏     | 6664/16104 [30:52:41<39:19:50, 15.00s/it]
{'loss': 0.6052, 'learning_rate': 1.3219948965511094e-06, 'rewards/chosen': -1.80472993850708, 'rewards/rejected': -2.2585761547088623, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4538462162017822, 'policy_logps/rejected': -461.43548583984375, 'policy_logps/chosen': -478.5100402832031, 'referece_logps/rejected': -438.8497314453125, 'referece_logps/chosen': -460.46270751953125, 'logits/rejected': -0.7212820649147034, 'logits/chosen': -0.7301421165466309, 'epoch': 2.48}

 41%|████▏     | 6665/16104 [30:52:59<41:28:59, 15.82s/it]

 41%|████▏     | 6666/16104 [30:53:20<46:01:43, 17.56s/it]

 41%|████▏     | 6667/16104 [30:53:32<41:43:43, 15.92s/it]

 41%|████▏     | 6668/16104 [30:53:44<38:41:16, 14.76s/it]


 41%|████▏     | 6670/16104 [30:54:15<40:27:36, 15.44s/it]

 41%|████▏     | 6671/16104 [30:54:27<37:46:12, 14.41s/it]
{'loss': 0.5782, 'learning_rate': 1.3206616757671775e-06, 'rewards/chosen': -1.0106576681137085, 'rewards/rejected': -1.3305763006210327, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3199187219142914, 'policy_logps/rejected': -344.17535400390625, 'policy_logps/chosen': -365.54486083984375, 'referece_logps/rejected': -330.86956787109375, 'referece_logps/chosen': -355.4383239746094, 'logits/rejected': -1.067213773727417, 'logits/chosen': -1.2623685598373413, 'epoch': 2.49}

 41%|████▏     | 6672/16104 [30:54:45<40:17:02, 15.38s/it]


 41%|████▏     | 6674/16104 [30:55:23<45:13:31, 17.27s/it]
{'loss': 0.3913, 'learning_rate': 1.3200901007070495e-06, 'rewards/chosen': -1.188608169555664, 'rewards/rejected': -2.3401355743408203, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1515274047851562, 'policy_logps/rejected': -428.91290283203125, 'policy_logps/chosen': -435.15740966796875, 'referece_logps/rejected': -405.51153564453125, 'referece_logps/chosen': -423.2713317871094, 'logits/rejected': -0.4333032965660095, 'logits/chosen': -0.380198210477829, 'epoch': 2.49}

 41%|████▏     | 6675/16104 [30:55:43<47:08:58, 18.00s/it]

 41%|████▏     | 6676/16104 [30:56:04<49:28:44, 18.89s/it]

 41%|████▏     | 6677/16104 [30:56:19<46:27:23, 17.74s/it]

 41%|████▏     | 6678/16104 [30:56:34<44:10:41, 16.87s/it]

 41%|████▏     | 6679/16104 [30:56:54<46:30:50, 17.77s/it]


 41%|████▏     | 6681/16104 [30:57:27<46:07:47, 17.62s/it]
{'loss': 0.5344, 'learning_rate': 1.3187559727389538e-06, 'rewards/chosen': -1.4032119512557983, 'rewards/rejected': -2.0673329830169678, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6641210913658142, 'policy_logps/rejected': -535.2139282226562, 'policy_logps/chosen': -443.786376953125, 'referece_logps/rejected': -514.5405883789062, 'referece_logps/chosen': -429.7542724609375, 'logits/rejected': -0.34034445881843567, 'logits/chosen': -0.09489928185939789, 'epoch': 2.49}

 41%|████▏     | 6682/16104 [30:57:45<46:03:28, 17.60s/it]


 42%|████▏     | 6684/16104 [30:58:19<46:04:11, 17.61s/it]
{'loss': 0.4921, 'learning_rate': 1.3181840100418446e-06, 'rewards/chosen': -0.8628419637680054, 'rewards/rejected': -1.3552889823913574, 'rewards/accuracies': 0.625, 'rewards/margins': 0.49244701862335205, 'policy_logps/rejected': -563.260498046875, 'policy_logps/chosen': -446.165771484375, 'referece_logps/rejected': -549.7075805664062, 'referece_logps/chosen': -437.537353515625, 'logits/rejected': -0.2409912645816803, 'logits/chosen': -0.23894721269607544, 'epoch': 2.49}


 42%|████▏     | 6686/16104 [30:58:57<48:08:22, 18.40s/it]
{'loss': 0.5041, 'learning_rate': 1.3178026372086958e-06, 'rewards/chosen': -0.49613726139068604, 'rewards/rejected': -2.6431641578674316, 'rewards/accuracies': 0.75, 'rewards/margins': 2.147027015686035, 'policy_logps/rejected': -346.55682373046875, 'policy_logps/chosen': -408.9326477050781, 'referece_logps/rejected': -320.12518310546875, 'referece_logps/chosen': -403.9712829589844, 'logits/rejected': -0.21285364031791687, 'logits/chosen': -0.1951386034488678, 'epoch': 2.49}

 42%|████▏     | 6687/16104 [30:59:20<51:20:31, 19.63s/it]


 42%|████▏     | 6689/16104 [30:59:55<48:33:00, 18.56s/it]
{'loss': 0.5335, 'learning_rate': 1.317230481560632e-06, 'rewards/chosen': -0.5799447298049927, 'rewards/rejected': -1.660942554473877, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0809979438781738, 'policy_logps/rejected': -432.9715270996094, 'policy_logps/chosen': -445.6331787109375, 'referece_logps/rejected': -416.36212158203125, 'referece_logps/chosen': -439.8337097167969, 'logits/rejected': -0.4805516004562378, 'logits/chosen': -0.5207329988479614, 'epoch': 2.49}

 42%|████▏     | 6690/16104 [31:00:06<42:21:40, 16.20s/it]

 42%|████▏     | 6691/16104 [31:00:28<46:49:30, 17.91s/it]

 42%|████▏     | 6692/16104 [31:00:42<43:47:24, 16.75s/it]

 42%|████▏     | 6693/16104 [31:00:58<43:29:51, 16.64s/it]

 42%|████▏     | 6694/16104 [31:01:15<43:21:41, 16.59s/it]

 42%|████▏     | 6695/16104 [31:01:27<40:06:11, 15.34s/it]

 42%|████▏     | 6696/16104 [31:01:39<37:20:10, 14.29s/it]


 42%|████▏     | 6698/16104 [31:02:08<36:36:54, 14.01s/it]

 42%|████▏     | 6699/16104 [31:02:27<41:06:35, 15.74s/it]

 42%|████▏     | 6700/16104 [31:02:45<42:53:53, 16.42s/it]

 42%|████▏     | 6701/16104 [31:03:01<42:35:23, 16.31s/it]
{'loss': 0.4283, 'learning_rate': 1.3149407061235456e-06, 'rewards/chosen': -1.291333794593811, 'rewards/rejected': -1.6946245431900024, 'rewards/accuracies': 0.625, 'rewards/margins': 0.40329092741012573, 'policy_logps/rejected': -355.13604736328125, 'policy_logps/chosen': -249.80703735351562, 'referece_logps/rejected': -338.1898193359375, 'referece_logps/chosen': -236.8936767578125, 'logits/rejected': -0.621395468711853, 'logits/chosen': -0.6116896271705627, 'epoch': 2.5}

 42%|████▏     | 6702/16104 [31:03:13<38:43:57, 14.83s/it]

 42%|████▏     | 6703/16104 [31:03:30<40:42:16, 15.59s/it]

 42%|████▏     | 6704/16104 [31:03:50<43:56:22, 16.83s/it]


 42%|████▏     | 6706/16104 [31:04:18<39:47:23, 15.24s/it]
{'loss': 0.5053, 'learning_rate': 1.3139860908128761e-06, 'rewards/chosen': -0.7065339088439941, 'rewards/rejected': -1.6162889003753662, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9097551107406616, 'policy_logps/rejected': -377.8155517578125, 'policy_logps/chosen': -465.0509948730469, 'referece_logps/rejected': -361.65264892578125, 'referece_logps/chosen': -457.98565673828125, 'logits/rejected': -0.7837281227111816, 'logits/chosen': -1.1127352714538574, 'epoch': 2.5}


 42%|████▏     | 6708/16104 [31:04:52<42:39:33, 16.34s/it]
{'loss': 0.4731, 'learning_rate': 1.3136041557254585e-06, 'rewards/chosen': -0.8114900588989258, 'rewards/rejected': -1.8968040943145752, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0853140354156494, 'policy_logps/rejected': -353.2997741699219, 'policy_logps/chosen': -340.17218017578125, 'referece_logps/rejected': -334.33172607421875, 'referece_logps/chosen': -332.05731201171875, 'logits/rejected': -0.4912196099758148, 'logits/chosen': -0.6464084386825562, 'epoch': 2.5}

 42%|████▏     | 6709/16104 [31:05:07<41:57:34, 16.08s/it]

 42%|████▏     | 6710/16104 [31:05:25<43:30:44, 16.67s/it]

 42%|████▏     | 6711/16104 [31:05:45<45:47:38, 17.55s/it]

 42%|████▏     | 6712/16104 [31:05:57<41:59:41, 16.10s/it]

 42%|████▏     | 6713/16104 [31:06:12<40:47:14, 15.64s/it]

 42%|████▏     | 6714/16104 [31:06:23<37:08:14, 14.24s/it]

 42%|████▏     | 6715/16104 [31:06:37<36:52:34, 14.14s/it]


 42%|████▏     | 6717/16104 [31:07:14<42:46:25, 16.40s/it]
{'loss': 0.4785, 'learning_rate': 1.3118848207750515e-06, 'rewards/chosen': -0.576198935508728, 'rewards/rejected': -1.9396556615829468, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3634568452835083, 'policy_logps/rejected': -351.693115234375, 'policy_logps/chosen': -371.9323425292969, 'referece_logps/rejected': -332.29656982421875, 'referece_logps/chosen': -366.1703186035156, 'logits/rejected': 0.05774875357747078, 'logits/chosen': -0.10609191656112671, 'epoch': 2.5}

 42%|████▏     | 6718/16104 [31:07:30<42:35:37, 16.34s/it]

 42%|████▏     | 6719/16104 [31:07:48<43:40:42, 16.75s/it]

 42%|████▏     | 6720/16104 [31:08:01<40:36:42, 15.58s/it]

 42%|████▏     | 6721/16104 [31:08:22<45:05:07, 17.30s/it]

 42%|████▏     | 6722/16104 [31:08:35<41:30:26, 15.93s/it]

 42%|████▏     | 6723/16104 [31:08:55<44:41:08, 17.15s/it]

 42%|████▏     | 6724/16104 [31:09:15<47:01:52, 18.05s/it]

 42%|████▏     | 6725/16104 [31:09:32<46:02:22, 17.67s/it]

 42%|████▏     | 6726/16104 [31:09:43<41:18:28, 15.86s/it]

 42%|████▏     | 6727/16104 [31:09:59<41:06:39, 15.78s/it]

 42%|████▏     | 6728/16104 [31:10:15<41:45:20, 16.03s/it]

 42%|████▏     | 6729/16104 [31:10:31<41:24:49, 15.90s/it]

 42%|████▏     | 6730/16104 [31:10:46<40:54:54, 15.71s/it]

 42%|████▏     | 6731/16104 [31:11:02<41:12:50, 15.83s/it]

 42%|████▏     | 6732/16104 [31:11:14<37:49:07, 14.53s/it]

 42%|████▏     | 6733/16104 [31:11:36<43:47:05, 16.82s/it]

 42%|████▏     | 6734/16104 [31:11:50<41:31:52, 15.96s/it]

 42%|████▏     | 6735/16104 [31:12:10<44:22:13, 17.05s/it]

 42%|████▏     | 6736/16104 [31:12:28<45:19:37, 17.42s/it]

 42%|████▏     | 6737/16104 [31:12:41<42:02:23, 16.16s/it]

 42%|████▏     | 6738/16104 [31:12:56<40:46:14, 15.67s/it]

 42%|████▏     | 6739/16104 [31:13:08<38:03:15, 14.63s/it]

 42%|████▏     | 6740/16104 [31:13:27<41:52:19, 16.10s/it]

 42%|████▏     | 6741/16104 [31:13:39<38:26:01, 14.78s/it]

 42%|████▏     | 6742/16104 [31:13:59<42:15:06, 16.25s/it]

 42%|████▏     | 6743/16104 [31:14:18<44:29:14, 17.11s/it]

 42%|████▏     | 6744/16104 [31:14:34<43:36:38, 16.77s/it]


 42%|████▏     | 6746/16104 [31:15:08<45:01:02, 17.32s/it]

 42%|████▏     | 6747/16104 [31:15:28<46:50:19, 18.02s/it]

 42%|████▏     | 6748/16104 [31:15:44<45:26:27, 17.48s/it]

 42%|████▏     | 6749/16104 [31:15:58<42:47:25, 16.47s/it]

 42%|████▏     | 6750/16104 [31:16:09<38:30:47, 14.82s/it]

 42%|████▏     | 6751/16104 [31:16:28<41:26:36, 15.95s/it]

 42%|████▏     | 6752/16104 [31:16:43<40:47:54, 15.71s/it]

 42%|████▏     | 6753/16104 [31:16:54<37:00:21, 14.25s/it]

 42%|████▏     | 6754/16104 [31:17:10<38:28:22, 14.81s/it]

 42%|████▏     | 6755/16104 [31:17:22<36:14:52, 13.96s/it]

 42%|████▏     | 6756/16104 [31:17:43<41:59:12, 16.17s/it]

 42%|████▏     | 6757/16104 [31:17:56<39:45:00, 15.31s/it]

 42%|████▏     | 6758/16104 [31:18:10<38:51:47, 14.97s/it]

 42%|████▏     | 6759/16104 [31:18:24<37:34:31, 14.48s/it]

 42%|████▏     | 6760/16104 [31:18:43<41:31:44, 16.00s/it]

 42%|████▏     | 6761/16104 [31:19:06<46:25:07, 17.89s/it]

 42%|████▏     | 6762/16104 [31:19:20<43:25:58, 16.74s/it]

 42%|████▏     | 6763/16104 [31:19:40<46:12:06, 17.81s/it]

 42%|████▏     | 6764/16104 [31:19:57<45:26:48, 17.52s/it]

 42%|████▏     | 6765/16104 [31:20:14<44:51:40, 17.29s/it]

 42%|████▏     | 6766/16104 [31:20:31<44:44:17, 17.25s/it]

 42%|████▏     | 6767/16104 [31:20:48<44:21:38, 17.10s/it]

 42%|████▏     | 6768/16104 [31:21:10<48:26:52, 18.68s/it]

 42%|████▏     | 6769/16104 [31:21:29<49:09:20, 18.96s/it]

 42%|████▏     | 6770/16104 [31:21:45<46:13:36, 17.83s/it]

 42%|████▏     | 6771/16104 [31:21:57<41:53:58, 16.16s/it]

 42%|████▏     | 6772/16104 [31:22:14<42:23:23, 16.35s/it]

 42%|████▏     | 6773/16104 [31:22:34<45:14:39, 17.46s/it]

 42%|████▏     | 6774/16104 [31:22:52<46:10:11, 17.81s/it]

 42%|████▏     | 6775/16104 [31:23:10<46:11:35, 17.83s/it]

 42%|████▏     | 6776/16104 [31:23:23<42:27:55, 16.39s/it]

 42%|████▏     | 6777/16104 [31:23:37<40:31:36, 15.64s/it]

 42%|████▏     | 6778/16104 [31:23:54<41:35:39, 16.06s/it]

 42%|████▏     | 6779/16104 [31:24:14<44:19:18, 17.11s/it]

 42%|████▏     | 6780/16104 [31:24:29<42:31:24, 16.42s/it]

 42%|████▏     | 6781/16104 [31:24:40<38:14:14, 14.77s/it]

 42%|████▏     | 6782/16104 [31:24:57<40:14:40, 15.54s/it]

 42%|████▏     | 6783/16104 [31:25:10<38:27:15, 14.85s/it]

 42%|████▏     | 6784/16104 [31:25:24<37:23:42, 14.44s/it]

 42%|████▏     | 6785/16104 [31:25:43<40:59:15, 15.83s/it]

 42%|████▏     | 6786/16104 [31:26:02<44:03:15, 17.02s/it]

 42%|████▏     | 6787/16104 [31:26:19<43:37:56, 16.86s/it]

 42%|████▏     | 6788/16104 [31:26:33<41:31:49, 16.05s/it]

 42%|████▏     | 6789/16104 [31:26:51<42:48:14, 16.54s/it]

 42%|████▏     | 6790/16104 [31:27:02<38:35:36, 14.92s/it]

 42%|████▏     | 6791/16104 [31:27:13<35:28:02, 13.71s/it]

 42%|████▏     | 6792/16104 [31:27:30<38:03:02, 14.71s/it]

 42%|████▏     | 6793/16104 [31:27:50<41:56:07, 16.21s/it]

 42%|████▏     | 6794/16104 [31:28:11<46:14:25, 17.88s/it]

 42%|████▏     | 6795/16104 [31:28:23<41:13:52, 15.95s/it]

 42%|████▏     | 6796/16104 [31:28:38<40:42:20, 15.74s/it]

 42%|████▏     | 6797/16104 [31:29:00<45:30:43, 17.60s/it]

 42%|████▏     | 6798/16104 [31:29:20<47:44:03, 18.47s/it]

 42%|████▏     | 6799/16104 [31:29:41<49:00:13, 18.96s/it]

 42%|████▏     | 6800/16104 [31:29:59<48:17:27, 18.69s/it]

 42%|████▏     | 6801/16104 [31:30:18<48:37:04, 18.81s/it]

 42%|████▏     | 6802/16104 [31:30:36<48:30:48, 18.78s/it]

 42%|████▏     | 6803/16104 [31:30:55<48:13:25, 18.67s/it]

 42%|████▏     | 6804/16104 [31:31:15<49:00:17, 18.97s/it]

 42%|████▏     | 6805/16104 [31:31:29<45:33:00, 17.63s/it]

 42%|████▏     | 6806/16104 [31:31:49<47:19:43, 18.32s/it]

 42%|████▏     | 6807/16104 [31:32:09<48:40:50, 18.85s/it]

 42%|████▏     | 6808/16104 [31:32:20<42:23:06, 16.41s/it]

 42%|████▏     | 6809/16104 [31:32:34<40:29:55, 15.69s/it]

 42%|████▏     | 6810/16104 [31:32:50<40:53:42, 15.84s/it]

 42%|████▏     | 6811/16104 [31:33:07<42:09:34, 16.33s/it]

 42%|████▏     | 6812/16104 [31:33:28<45:23:06, 17.58s/it]

 42%|████▏     | 6813/16104 [31:33:47<46:52:12, 18.16s/it]

 42%|████▏     | 6814/16104 [31:34:06<47:29:42, 18.41s/it]

 42%|████▏     | 6815/16104 [31:34:19<42:54:18, 16.63s/it]

 42%|████▏     | 6816/16104 [31:34:33<40:34:15, 15.73s/it]
{'loss': 0.5143, 'learning_rate': 1.2929059313659965e-06, 'rewards/chosen': -0.9875779747962952, 'rewards/rejected': -1.0165387392044067, 'rewards/accuracies': 0.5, 'rewards/margins': 0.028960712254047394, 'policy_logps/rejected': -353.775390625, 'policy_logps/chosen': -349.58807373046875, 'referece_logps/rejected': -343.61004638671875, 'referece_logps/chosen': -339.7122802734375, 'logits/rejected': -0.4928416907787323, 'logits/chosen': -0.7512539625167847, 'epoch': 2.54}

 42%|████▏     | 6817/16104 [31:34:46<38:40:43, 14.99s/it]


 42%|████▏     | 6819/16104 [31:35:24<43:57:11, 17.04s/it]

 42%|████▏     | 6820/16104 [31:35:44<46:23:07, 17.99s/it]

 42%|████▏     | 6821/16104 [31:35:57<42:47:32, 16.60s/it]

 42%|████▏     | 6822/16104 [31:36:12<41:49:46, 16.22s/it]

 42%|████▏     | 6823/16104 [31:36:31<43:34:20, 16.90s/it]

 42%|████▏     | 6824/16104 [31:36:47<43:16:50, 16.79s/it]

 42%|████▏     | 6825/16104 [31:37:01<40:33:43, 15.74s/it]

 42%|████▏     | 6826/16104 [31:37:17<41:11:04, 15.98s/it]

 42%|████▏     | 6827/16104 [31:37:34<41:48:13, 16.22s/it]

 42%|████▏     | 6828/16104 [31:37:52<43:15:33, 16.79s/it]

 42%|████▏     | 6829/16104 [31:38:03<38:32:13, 14.96s/it]

 42%|████▏     | 6830/16104 [31:38:15<36:08:23, 14.03s/it]

 42%|████▏     | 6831/16104 [31:38:30<37:01:35, 14.37s/it]

 42%|████▏     | 6832/16104 [31:38:41<34:13:21, 13.29s/it]

 42%|████▏     | 6833/16104 [31:39:01<39:34:07, 15.36s/it]
{'loss': 0.584, 'learning_rate': 1.2896350381504334e-06, 'rewards/chosen': -1.1144628524780273, 'rewards/rejected': -1.096121072769165, 'rewards/accuracies': 0.5, 'rewards/margins': -0.01834183931350708, 'policy_logps/rejected': -318.47979736328125, 'policy_logps/chosen': -442.931884765625, 'referece_logps/rejected': -307.5185546875, 'referece_logps/chosen': -431.7872619628906, 'logits/rejected': 0.11735118925571442, 'logits/chosen': 0.12844416499137878, 'epoch': 2.55}


 42%|████▏     | 6835/16104 [31:39:43<47:11:01, 18.33s/it]

 42%|████▏     | 6836/16104 [31:40:01<46:54:37, 18.22s/it]

 42%|████▏     | 6837/16104 [31:40:21<48:11:50, 18.72s/it]

 42%|████▏     | 6838/16104 [31:40:34<43:25:49, 16.87s/it]
{'loss': 0.4559, 'learning_rate': 1.2886723646274282e-06, 'rewards/chosen': -0.9390141367912292, 'rewards/rejected': -2.5754528045654297, 'rewards/accuracies': 0.625, 'rewards/margins': 1.6364387273788452, 'policy_logps/rejected': -557.512939453125, 'policy_logps/chosen': -540.1799926757812, 'referece_logps/rejected': -531.7583618164062, 'referece_logps/chosen': -530.7898559570312, 'logits/rejected': -1.1462219953536987, 'logits/chosen': -1.1670317649841309, 'epoch': 2.55}


 42%|████▏     | 6840/16104 [31:41:06<42:41:55, 16.59s/it]

 42%|████▏     | 6841/16104 [31:41:27<46:21:45, 18.02s/it]

 42%|████▏     | 6842/16104 [31:41:47<47:35:36, 18.50s/it]
{'loss': 0.5163, 'learning_rate': 1.2879020155706802e-06, 'rewards/chosen': -0.7822576761245728, 'rewards/rejected': -1.8932013511657715, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1109439134597778, 'policy_logps/rejected': -329.1643981933594, 'policy_logps/chosen': -363.0283203125, 'referece_logps/rejected': -310.23236083984375, 'referece_logps/chosen': -355.2057189941406, 'logits/rejected': -0.5607804656028748, 'logits/chosen': -0.5115995407104492, 'epoch': 2.55}


 42%|████▏     | 6844/16104 [31:42:22<45:25:43, 17.66s/it]

 43%|████▎     | 6845/16104 [31:42:41<46:59:26, 18.27s/it]

 43%|████▎     | 6846/16104 [31:43:01<48:00:54, 18.67s/it]
{'loss': 0.4678, 'learning_rate': 1.2871314801755363e-06, 'rewards/chosen': -0.8544944524765015, 'rewards/rejected': -1.7300591468811035, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8755645751953125, 'policy_logps/rejected': -357.46905517578125, 'policy_logps/chosen': -409.57958984375, 'referece_logps/rejected': -340.1684875488281, 'referece_logps/chosen': -401.03466796875, 'logits/rejected': -0.8995311260223389, 'logits/chosen': -0.7925856113433838, 'epoch': 2.55}

 43%|████▎     | 6847/16104 [31:43:20<48:39:36, 18.92s/it]


 43%|████▎     | 6849/16104 [31:43:54<46:05:23, 17.93s/it]
{'loss': 0.5367, 'learning_rate': 1.2865534566446093e-06, 'rewards/chosen': -1.4888112545013428, 'rewards/rejected': -2.3209805488586426, 'rewards/accuracies': 0.625, 'rewards/margins': 0.832169234752655, 'policy_logps/rejected': -432.723388671875, 'policy_logps/chosen': -335.7567443847656, 'referece_logps/rejected': -409.5135192871094, 'referece_logps/chosen': -320.8686218261719, 'logits/rejected': -1.0100539922714233, 'logits/chosen': -0.7157936096191406, 'epoch': 2.55}


 43%|████▎     | 6851/16104 [31:44:29<46:04:15, 17.92s/it]

 43%|████▎     | 6852/16104 [31:44:41<41:33:39, 16.17s/it]
{'loss': 0.5228, 'learning_rate': 1.2859753287892966e-06, 'rewards/chosen': -0.7223607301712036, 'rewards/rejected': -1.7976032495498657, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0752428770065308, 'policy_logps/rejected': -308.6441650390625, 'policy_logps/chosen': -281.4952697753906, 'referece_logps/rejected': -290.6681213378906, 'referece_logps/chosen': -274.2716369628906, 'logits/rejected': -0.7549406290054321, 'logits/chosen': -0.5997978448867798, 'epoch': 2.55}


 43%|████▎     | 6854/16104 [31:45:12<39:43:42, 15.46s/it]

 43%|████▎     | 6855/16104 [31:45:32<42:50:31, 16.68s/it]
{'loss': 0.5291, 'learning_rate': 1.2853970968200758e-06, 'rewards/chosen': -1.3153932094573975, 'rewards/rejected': -2.7989425659179688, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4835498332977295, 'policy_logps/rejected': -478.49468994140625, 'policy_logps/chosen': -420.2276611328125, 'referece_logps/rejected': -450.5052490234375, 'referece_logps/chosen': -407.07373046875, 'logits/rejected': 0.42239537835121155, 'logits/chosen': 0.38579681515693665, 'epoch': 2.55}

 43%|████▎     | 6856/16104 [31:45:51<44:50:40, 17.46s/it]

 43%|████▎     | 6857/16104 [31:46:03<40:33:34, 15.79s/it]


 43%|████▎     | 6859/16104 [31:46:33<38:42:47, 15.07s/it]

 43%|████▎     | 6860/16104 [31:46:54<43:09:49, 16.81s/it]

 43%|████▎     | 6861/16104 [31:47:09<41:55:09, 16.33s/it]

 43%|████▎     | 6862/16104 [31:47:25<41:40:49, 16.24s/it]

 43%|████▎     | 6863/16104 [31:47:39<39:20:00, 15.32s/it]

 43%|████▎     | 6864/16104 [31:47:58<42:42:12, 16.64s/it]
{'loss': 0.5777, 'learning_rate': 1.2836617783342967e-06, 'rewards/chosen': -0.9345489740371704, 'rewards/rejected': -1.5765912532806396, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6420421600341797, 'policy_logps/rejected': -466.69708251953125, 'policy_logps/chosen': -524.4547729492188, 'referece_logps/rejected': -450.93109130859375, 'referece_logps/chosen': -515.1092529296875, 'logits/rejected': -0.3106271028518677, 'logits/chosen': -0.23622867465019226, 'epoch': 2.56}


 43%|████▎     | 6866/16104 [31:48:30<40:43:05, 15.87s/it]

 43%|████▎     | 6867/16104 [31:48:52<45:18:59, 17.66s/it]

 43%|████▎     | 6868/16104 [31:49:02<39:59:39, 15.59s/it]
{'loss': 0.5045, 'learning_rate': 1.2828902269956827e-06, 'rewards/chosen': -0.5118783116340637, 'rewards/rejected': -1.8132305145263672, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3013521432876587, 'policy_logps/rejected': -198.33477783203125, 'policy_logps/chosen': -376.793701171875, 'referece_logps/rejected': -180.20249938964844, 'referece_logps/chosen': -371.6749267578125, 'logits/rejected': 0.046162866055965424, 'logits/chosen': 0.056408580392599106, 'epoch': 2.56}


 43%|████▎     | 6870/16104 [31:49:36<40:33:08, 15.81s/it]

 43%|████▎     | 6871/16104 [31:49:50<38:58:27, 15.20s/it]

 43%|████▎     | 6872/16104 [31:50:04<38:08:07, 14.87s/it]
{'loss': 0.473, 'learning_rate': 1.282118492562446e-06, 'rewards/chosen': -0.3352505564689636, 'rewards/rejected': -0.9487013816833496, 'rewards/accuracies': 0.875, 'rewards/margins': 0.613450825214386, 'policy_logps/rejected': -351.6248779296875, 'policy_logps/chosen': -411.8008117675781, 'referece_logps/rejected': -342.1378173828125, 'referece_logps/chosen': -408.4483642578125, 'logits/rejected': 0.26632124185562134, 'logits/chosen': 0.25672250986099243, 'epoch': 2.56}


 43%|████▎     | 6874/16104 [31:50:38<40:21:49, 15.74s/it]

 43%|████▎     | 6875/16104 [31:50:50<37:24:08, 14.59s/it]
{'loss': 0.5694, 'learning_rate': 1.2815395718821414e-06, 'rewards/chosen': -0.900555431842804, 'rewards/rejected': -1.473891019821167, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5733356475830078, 'policy_logps/rejected': -412.0914611816406, 'policy_logps/chosen': -323.4635314941406, 'referece_logps/rejected': -397.3525085449219, 'referece_logps/chosen': -314.4579772949219, 'logits/rejected': 0.0830293595790863, 'logits/chosen': 0.06149636581540108, 'epoch': 2.56}

 43%|████▎     | 6876/16104 [31:51:09<41:09:24, 16.06s/it]


 43%|████▎     | 6878/16104 [31:51:44<42:57:34, 16.76s/it]
{'loss': 0.4207, 'learning_rate': 1.2809605487028367e-06, 'rewards/chosen': -0.20844174921512604, 'rewards/rejected': -1.964949131011963, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7565075159072876, 'policy_logps/rejected': -588.6002197265625, 'policy_logps/chosen': -372.24908447265625, 'referece_logps/rejected': -568.9508056640625, 'referece_logps/chosen': -370.1647033691406, 'logits/rejected': -0.5252261757850647, 'logits/chosen': -0.3345511555671692, 'epoch': 2.56}

 43%|████▎     | 6879/16104 [31:52:05<46:53:48, 18.30s/it]


 43%|████▎     | 6881/16104 [31:52:42<47:03:35, 18.37s/it]
{'loss': 0.5468, 'learning_rate': 1.2803814232353349e-06, 'rewards/chosen': -1.0577378273010254, 'rewards/rejected': -2.3298230171203613, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2720855474472046, 'policy_logps/rejected': -365.7447509765625, 'policy_logps/chosen': -415.3431701660156, 'referece_logps/rejected': -342.446533203125, 'referece_logps/chosen': -404.7657775878906, 'logits/rejected': -0.5821723937988281, 'logits/chosen': -0.6167122721672058, 'epoch': 2.56}

 43%|████▎     | 6882/16104 [31:52:59<46:01:31, 17.97s/it]


 43%|████▎     | 6884/16104 [31:53:36<46:20:51, 18.10s/it]
{'loss': 0.4921, 'learning_rate': 1.2798021956904759e-06, 'rewards/chosen': -0.6477991342544556, 'rewards/rejected': -3.948185443878174, 'rewards/accuracies': 1.0, 'rewards/margins': 3.300386428833008, 'policy_logps/rejected': -479.7271728515625, 'policy_logps/chosen': -355.8865966796875, 'referece_logps/rejected': -440.2452697753906, 'referece_logps/chosen': -349.40863037109375, 'logits/rejected': 0.04841190576553345, 'logits/chosen': 0.04903149604797363, 'epoch': 2.56}

 43%|████▎     | 6885/16104 [31:53:50<42:45:22, 16.70s/it]


 43%|████▎     | 6887/16104 [31:54:22<41:44:01, 16.30s/it]

 43%|████▎     | 6888/16104 [31:54:40<42:28:05, 16.59s/it]

 43%|████▎     | 6889/16104 [31:55:01<45:39:26, 17.84s/it]

 43%|████▎     | 6890/16104 [31:55:14<42:08:03, 16.46s/it]

 43%|████▎     | 6891/16104 [31:55:27<39:40:10, 15.50s/it]

 43%|████▎     | 6892/16104 [31:55:44<41:00:33, 16.03s/it]
{'loss': 0.6063, 'learning_rate': 1.2782570914631504e-06, 'rewards/chosen': -0.8041024208068848, 'rewards/rejected': -1.189597249031067, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3854948878288269, 'policy_logps/rejected': -367.385986328125, 'policy_logps/chosen': -277.07550048828125, 'referece_logps/rejected': -355.4900207519531, 'referece_logps/chosen': -269.0344543457031, 'logits/rejected': -0.8790535926818848, 'logits/chosen': -0.7614812850952148, 'epoch': 2.57}

 43%|████▎     | 6893/16104 [31:55:56<37:27:42, 14.64s/it]


 43%|████▎     | 6895/16104 [31:56:33<42:57:48, 16.80s/it]

 43%|████▎     | 6896/16104 [31:56:50<42:58:36, 16.80s/it]

 43%|████▎     | 6897/16104 [31:57:03<39:59:41, 15.64s/it]
{'loss': 0.5303, 'learning_rate': 1.2772910352472898e-06, 'rewards/chosen': -0.5432880520820618, 'rewards/rejected': -1.4002926349639893, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8570045828819275, 'policy_logps/rejected': -426.772216796875, 'policy_logps/chosen': -628.2468872070312, 'referece_logps/rejected': -412.7692565917969, 'referece_logps/chosen': -622.8140258789062, 'logits/rejected': -0.009556412696838379, 'logits/chosen': 0.1322517991065979, 'epoch': 2.57}


 43%|████▎     | 6899/16104 [31:57:36<40:22:03, 15.79s/it]
{'loss': 0.5236, 'learning_rate': 1.2769045341878123e-06, 'rewards/chosen': -0.7839117050170898, 'rewards/rejected': -1.7954849004745483, 'rewards/accuracies': 0.75, 'rewards/margins': 1.011573314666748, 'policy_logps/rejected': -208.57923889160156, 'policy_logps/chosen': -168.4210662841797, 'referece_logps/rejected': -190.62440490722656, 'referece_logps/chosen': -160.58193969726562, 'logits/rejected': -0.9248165488243103, 'logits/chosen': -0.9138887524604797, 'epoch': 2.57}


 43%|████▎     | 6901/16104 [31:58:18<46:54:29, 18.35s/it]

 43%|████▎     | 6902/16104 [31:58:34<45:16:38, 17.71s/it]

 43%|████▎     | 6903/16104 [31:58:55<47:42:36, 18.67s/it]

 43%|████▎     | 6904/16104 [31:59:15<48:22:55, 18.93s/it]
{'loss': 0.4163, 'learning_rate': 1.2759380856534962e-06, 'rewards/chosen': -0.36568889021873474, 'rewards/rejected': -1.6441248655319214, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2784359455108643, 'policy_logps/rejected': -272.8669128417969, 'policy_logps/chosen': -475.5159912109375, 'referece_logps/rejected': -256.4256591796875, 'referece_logps/chosen': -471.85906982421875, 'logits/rejected': -0.3400574326515198, 'logits/chosen': -0.17070354521274567, 'epoch': 2.57}

 43%|████▎     | 6905/16104 [31:59:32<46:59:23, 18.39s/it]

 43%|████▎     | 6906/16104 [31:59:48<45:14:53, 17.71s/it]


 43%|████▎     | 6908/16104 [32:00:25<45:47:26, 17.93s/it]

 43%|████▎     | 6909/16104 [32:00:43<45:54:56, 17.98s/it]
{'loss': 0.5506, 'learning_rate': 1.2749713580645034e-06, 'rewards/chosen': -1.2592144012451172, 'rewards/rejected': -2.2288429737091064, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9696285128593445, 'policy_logps/rejected': -338.18060302734375, 'policy_logps/chosen': -360.7396240234375, 'referece_logps/rejected': -315.8922119140625, 'referece_logps/chosen': -348.1474609375, 'logits/rejected': -0.26241356134414673, 'logits/chosen': -0.26124146580696106, 'epoch': 2.57}


 43%|████▎     | 6911/16104 [32:01:15<43:30:07, 17.04s/it]
{'loss': 0.542, 'learning_rate': 1.27458458911258e-06, 'rewards/chosen': -0.9949881434440613, 'rewards/rejected': -1.673214077949524, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6782258749008179, 'policy_logps/rejected': -380.2110595703125, 'policy_logps/chosen': -275.10772705078125, 'referece_logps/rejected': -363.47894287109375, 'referece_logps/chosen': -265.1578674316406, 'logits/rejected': -0.8676594495773315, 'logits/chosen': -0.8908679485321045, 'epoch': 2.57}


 43%|████▎     | 6913/16104 [32:01:47<41:15:22, 16.16s/it]
{'loss': 0.5928, 'learning_rate': 1.2741977757309105e-06, 'rewards/chosen': -0.8611928820610046, 'rewards/rejected': -1.3891053199768066, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5279123187065125, 'policy_logps/rejected': -353.9628601074219, 'policy_logps/chosen': -360.4730529785156, 'referece_logps/rejected': -340.0718078613281, 'referece_logps/chosen': -351.8611145019531, 'logits/rejected': -0.6456745266914368, 'logits/chosen': -0.7205866575241089, 'epoch': 2.58}


 43%|████▎     | 6915/16104 [32:02:22<44:09:17, 17.30s/it]

 43%|████▎     | 6916/16104 [32:02:37<42:06:27, 16.50s/it]

 43%|████▎     | 6917/16104 [32:02:49<38:35:31, 15.12s/it]

 43%|████▎     | 6918/16104 [32:03:01<36:18:43, 14.23s/it]
{'loss': 0.616, 'learning_rate': 1.2732305483073573e-06, 'rewards/chosen': -0.8750314116477966, 'rewards/rejected': -1.6617339849472046, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7867025136947632, 'policy_logps/rejected': -441.8880615234375, 'policy_logps/chosen': -628.0934448242188, 'referece_logps/rejected': -425.27069091796875, 'referece_logps/chosen': -619.3431396484375, 'logits/rejected': -0.1662854254245758, 'logits/chosen': -0.053689420223236084, 'epoch': 2.58}


 43%|████▎     | 6920/16104 [32:03:25<33:10:02, 13.00s/it]

 43%|████▎     | 6921/16104 [32:03:42<36:21:58, 14.26s/it]

 43%|████▎     | 6922/16104 [32:03:53<33:38:42, 13.19s/it]
{'loss': 0.5516, 'learning_rate': 1.2724565673736315e-06, 'rewards/chosen': -1.1069002151489258, 'rewards/rejected': -1.4162222146987915, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3093217611312866, 'policy_logps/rejected': -196.37210083007812, 'policy_logps/chosen': -336.6902160644531, 'referece_logps/rejected': -182.2098846435547, 'referece_logps/chosen': -325.6212158203125, 'logits/rejected': -1.208326816558838, 'logits/chosen': -1.22372567653656, 'epoch': 2.58}

 43%|████▎     | 6923/16104 [32:04:06<33:34:05, 13.16s/it]


 43%|████▎     | 6925/16104 [32:04:28<30:52:30, 12.11s/it]

 43%|████▎     | 6926/16104 [32:04:39<29:58:40, 11.76s/it]

 43%|████▎     | 6927/16104 [32:04:59<35:56:09, 14.10s/it]

 43%|████▎     | 6928/16104 [32:05:17<38:55:06, 15.27s/it]

 43%|████▎     | 6929/16104 [32:05:34<40:33:54, 15.92s/it]

 43%|████▎     | 6930/16104 [32:05:49<39:10:18, 15.37s/it]
{'loss': 0.4774, 'learning_rate': 1.2709080769822546e-06, 'rewards/chosen': -0.7254081964492798, 'rewards/rejected': -1.4980758428573608, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7726675868034363, 'policy_logps/rejected': -463.0254821777344, 'policy_logps/chosen': -508.269775390625, 'referece_logps/rejected': -448.04473876953125, 'referece_logps/chosen': -501.01568603515625, 'logits/rejected': -0.5303240418434143, 'logits/chosen': -0.5482762455940247, 'epoch': 2.58}


 43%|████▎     | 6932/16104 [32:06:24<41:59:25, 16.48s/it]
{'loss': 0.5776, 'learning_rate': 1.2705208446406446e-06, 'rewards/chosen': -1.1622272729873657, 'rewards/rejected': -1.7113394737243652, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5491121411323547, 'policy_logps/rejected': -379.94268798828125, 'policy_logps/chosen': -452.65557861328125, 'referece_logps/rejected': -362.82928466796875, 'referece_logps/chosen': -441.0332946777344, 'logits/rejected': 0.10744954645633698, 'logits/chosen': 0.15797153115272522, 'epoch': 2.58}


 43%|████▎     | 6934/16104 [32:06:51<37:38:39, 14.78s/it]

 43%|████▎     | 6935/16104 [32:07:11<41:57:57, 16.48s/it]

 43%|████▎     | 6936/16104 [32:07:23<38:30:28, 15.12s/it]

 43%|████▎     | 6937/16104 [32:07:38<38:01:45, 14.93s/it]

 43%|████▎     | 6938/16104 [32:07:57<41:35:47, 16.34s/it]

 43%|████▎     | 6939/16104 [32:08:09<37:44:52, 14.83s/it]

 43%|████▎     | 6940/16104 [32:08:30<42:18:39, 16.62s/it]

 43%|████▎     | 6941/16104 [32:08:44<40:29:55, 15.91s/it]
{'loss': 0.5053, 'learning_rate': 1.2687777583271593e-06, 'rewards/chosen': -0.719603955745697, 'rewards/rejected': -1.6703472137451172, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9507431387901306, 'policy_logps/rejected': -338.2869873046875, 'policy_logps/chosen': -455.099609375, 'referece_logps/rejected': -321.58355712890625, 'referece_logps/chosen': -447.9035949707031, 'logits/rejected': -1.165442705154419, 'logits/chosen': -1.1881189346313477, 'epoch': 2.59}


 43%|████▎     | 6943/16104 [32:09:21<43:26:22, 17.07s/it]

 43%|████▎     | 6944/16104 [32:09:31<38:29:26, 15.13s/it]
{'loss': 0.5545, 'learning_rate': 1.2681965335682041e-06, 'rewards/chosen': -0.7025501132011414, 'rewards/rejected': -1.2188386917114258, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5162884593009949, 'policy_logps/rejected': -329.9422302246094, 'policy_logps/chosen': -496.1458740234375, 'referece_logps/rejected': -317.75384521484375, 'referece_logps/chosen': -489.120361328125, 'logits/rejected': -0.669023871421814, 'logits/chosen': -0.8277933597564697, 'epoch': 2.59}


 43%|████▎     | 6946/16104 [32:10:11<44:56:31, 17.67s/it]
{'loss': 0.5048, 'learning_rate': 1.2678089961373635e-06, 'rewards/chosen': -0.8669343590736389, 'rewards/rejected': -1.367633581161499, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5006991624832153, 'policy_logps/rejected': -332.7401428222656, 'policy_logps/chosen': -467.3315124511719, 'referece_logps/rejected': -319.0638122558594, 'referece_logps/chosen': -458.662109375, 'logits/rejected': -0.47284775972366333, 'logits/chosen': -0.42299461364746094, 'epoch': 2.59}

 43%|████▎     | 6947/16104 [32:10:23<40:03:03, 15.75s/it]


 43%|████▎     | 6949/16104 [32:11:00<44:02:13, 17.32s/it]
{'loss': 0.4321, 'learning_rate': 1.2672276087605624e-06, 'rewards/chosen': -1.5141100883483887, 'rewards/rejected': -3.1703126430511475, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6562024354934692, 'policy_logps/rejected': -545.8317260742188, 'policy_logps/chosen': -510.2491760253906, 'referece_logps/rejected': -514.1286010742188, 'referece_logps/chosen': -495.10809326171875, 'logits/rejected': 0.27878135442733765, 'logits/chosen': 0.10415506362915039, 'epoch': 2.59}


 43%|████▎     | 6951/16104 [32:11:32<42:36:46, 16.76s/it]

 43%|████▎     | 6952/16104 [32:11:49<43:25:26, 17.08s/it]
{'loss': 0.4963, 'learning_rate': 1.2666461240952612e-06, 'rewards/chosen': -0.9698095321655273, 'rewards/rejected': -1.457988977432251, 'rewards/accuracies': 0.75, 'rewards/margins': 0.48817959427833557, 'policy_logps/rejected': -364.70806884765625, 'policy_logps/chosen': -470.03082275390625, 'referece_logps/rejected': -350.1282043457031, 'referece_logps/chosen': -460.33270263671875, 'logits/rejected': -0.8583962917327881, 'logits/chosen': -0.9208799004554749, 'epoch': 2.59}

 43%|████▎     | 6953/16104 [32:12:06<43:21:12, 17.06s/it]

 43%|████▎     | 6954/16104 [32:12:22<42:28:30, 16.71s/it]


 43%|████▎     | 6956/16104 [32:12:52<41:03:45, 16.16s/it]

 43%|████▎     | 6957/16104 [32:13:06<38:57:50, 15.34s/it]

 43%|████▎     | 6958/16104 [32:13:23<40:55:37, 16.11s/it]

 43%|████▎     | 6959/16104 [32:13:40<41:02:27, 16.16s/it]

 43%|████▎     | 6960/16104 [32:14:02<45:33:45, 17.94s/it]
{'loss': 0.5704, 'learning_rate': 1.265095024298526e-06, 'rewards/chosen': -1.0587488412857056, 'rewards/rejected': -0.9465781450271606, 'rewards/accuracies': 0.25, 'rewards/margins': -0.11217068135738373, 'policy_logps/rejected': -354.34515380859375, 'policy_logps/chosen': -423.6407165527344, 'referece_logps/rejected': -344.87933349609375, 'referece_logps/chosen': -413.05328369140625, 'logits/rejected': -0.7072815299034119, 'logits/chosen': -0.7865723371505737, 'epoch': 2.59}


 43%|████▎     | 6962/16104 [32:14:38<45:35:08, 17.95s/it]
{'loss': 0.482, 'learning_rate': 1.264707141956796e-06, 'rewards/chosen': -1.3887611627578735, 'rewards/rejected': -2.1088712215423584, 'rewards/accuracies': 0.75, 'rewards/margins': 0.720109760761261, 'policy_logps/rejected': -393.7948303222656, 'policy_logps/chosen': -370.2384033203125, 'referece_logps/rejected': -372.7060546875, 'referece_logps/chosen': -356.35076904296875, 'logits/rejected': 0.08199310302734375, 'logits/chosen': 0.15372858941555023, 'epoch': 2.59}

 43%|████▎     | 6963/16104 [32:14:51<41:32:39, 16.36s/it]

 43%|████▎     | 6964/16104 [32:15:07<41:38:05, 16.40s/it]


 43%|████▎     | 6966/16104 [32:15:32<36:41:17, 14.45s/it]
{'loss': 0.5816, 'learning_rate': 1.2639312488415915e-06, 'rewards/chosen': -0.9359987378120422, 'rewards/rejected': -1.5282493829727173, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5922507047653198, 'policy_logps/rejected': -345.53948974609375, 'policy_logps/chosen': -386.97186279296875, 'referece_logps/rejected': -330.25701904296875, 'referece_logps/chosen': -377.6118469238281, 'logits/rejected': -0.812870979309082, 'logits/chosen': -0.7968536615371704, 'epoch': 2.6}

 43%|████▎     | 6967/16104 [32:15:47<37:14:57, 14.68s/it]

 43%|████▎     | 6968/16104 [32:16:03<38:03:44, 15.00s/it]


 43%|████▎     | 6970/16104 [32:16:36<40:47:16, 16.08s/it]
{'loss': 0.5595, 'learning_rate': 1.2631551849025556e-06, 'rewards/chosen': -0.7976446151733398, 'rewards/rejected': -0.8728040456771851, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0751594826579094, 'policy_logps/rejected': -408.97119140625, 'policy_logps/chosen': -303.27117919921875, 'referece_logps/rejected': -400.24310302734375, 'referece_logps/chosen': -295.294677734375, 'logits/rejected': -0.5029059648513794, 'logits/chosen': -0.34393325448036194, 'epoch': 2.6}


 43%|████▎     | 6972/16104 [32:17:02<37:03:20, 14.61s/it]

 43%|████▎     | 6973/16104 [32:17:16<36:09:40, 14.26s/it]
{'loss': 0.5283, 'learning_rate': 1.2625730251472944e-06, 'rewards/chosen': -1.0485906600952148, 'rewards/rejected': -1.8856791257858276, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8370883464813232, 'policy_logps/rejected': -327.3185729980469, 'policy_logps/chosen': -298.5345153808594, 'referece_logps/rejected': -308.4617919921875, 'referece_logps/chosen': -288.0486145019531, 'logits/rejected': -0.12641799449920654, 'logits/chosen': -0.10116559267044067, 'epoch': 2.6}


 43%|████▎     | 6975/16104 [32:17:50<39:59:19, 15.77s/it]

 43%|████▎     | 6976/16104 [32:18:06<40:35:26, 16.01s/it]
{'loss': 0.5236, 'learning_rate': 1.2619907697981092e-06, 'rewards/chosen': -0.9295535087585449, 'rewards/rejected': -1.655182123184204, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7256284952163696, 'policy_logps/rejected': -350.52325439453125, 'policy_logps/chosen': -501.0011291503906, 'referece_logps/rejected': -333.9714050292969, 'referece_logps/chosen': -491.70562744140625, 'logits/rejected': -1.2440913915634155, 'logits/chosen': -1.2525827884674072, 'epoch': 2.6}

 43%|████▎     | 6977/16104 [32:18:19<38:21:48, 15.13s/it]

 43%|████▎     | 6978/16104 [32:18:33<37:21:58, 14.74s/it]


 43%|████▎     | 6980/16104 [32:19:03<36:26:11, 14.38s/it]

 43%|████▎     | 6981/16104 [32:19:22<40:25:30, 15.95s/it]

 43%|████▎     | 6982/16104 [32:19:40<41:56:41, 16.55s/it]

 43%|████▎     | 6983/16104 [32:20:00<44:30:44, 17.57s/it]
{'loss': 0.5599, 'learning_rate': 1.260631803420007e-06, 'rewards/chosen': -1.2520092725753784, 'rewards/rejected': -1.5597865581512451, 'rewards/accuracies': 0.875, 'rewards/margins': 0.3077770471572876, 'policy_logps/rejected': -396.6310119628906, 'policy_logps/chosen': -328.667724609375, 'referece_logps/rejected': -381.0331115722656, 'referece_logps/chosen': -316.1476745605469, 'logits/rejected': -0.3475194275379181, 'logits/chosen': -0.23061329126358032, 'epoch': 2.6}

 43%|████▎     | 6984/16104 [32:20:17<44:10:53, 17.44s/it]

 43%|████▎     | 6985/16104 [32:20:32<42:02:48, 16.60s/it]

 43%|████▎     | 6986/16104 [32:20:46<39:56:23, 15.77s/it]


 43%|████▎     | 6988/16104 [32:21:22<43:27:46, 17.16s/it]
{'loss': 0.4795, 'learning_rate': 1.2596607967022332e-06, 'rewards/chosen': -0.8895692825317383, 'rewards/rejected': -1.314584493637085, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4250151515007019, 'policy_logps/rejected': -454.8701477050781, 'policy_logps/chosen': -537.0084228515625, 'referece_logps/rejected': -441.7243347167969, 'referece_logps/chosen': -528.11279296875, 'logits/rejected': -0.9411919713020325, 'logits/chosen': -1.0067442655563354, 'epoch': 2.6}

 43%|████▎     | 6989/16104 [32:21:39<42:49:56, 16.92s/it]


 43%|████▎     | 6991/16104 [32:22:21<47:40:53, 18.84s/it]

 43%|████▎     | 6992/16104 [32:22:35<44:04:40, 17.41s/it]
{'loss': 0.4443, 'learning_rate': 1.2588838022135197e-06, 'rewards/chosen': -0.7454355955123901, 'rewards/rejected': -2.2342209815979004, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4887853860855103, 'policy_logps/rejected': -354.69207763671875, 'policy_logps/chosen': -413.47039794921875, 'referece_logps/rejected': -332.349853515625, 'referece_logps/chosen': -406.01611328125, 'logits/rejected': -1.1133935451507568, 'logits/chosen': -1.2878103256225586, 'epoch': 2.61}

 43%|████▎     | 6993/16104 [32:22:55<46:10:16, 18.24s/it]

 43%|████▎     | 6994/16104 [32:23:13<46:17:03, 18.29s/it]

 43%|████▎     | 6995/16104 [32:23:28<43:17:32, 17.11s/it]

 43%|████▎     | 6996/16104 [32:23:42<40:53:12, 16.16s/it]


 43%|████▎     | 6998/16104 [32:24:12<38:42:01, 15.30s/it]
{'loss': 0.6676, 'learning_rate': 1.2577179964682956e-06, 'rewards/chosen': -0.6793087124824524, 'rewards/rejected': -0.900568425655365, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2212596833705902, 'policy_logps/rejected': -616.7328491210938, 'policy_logps/chosen': -540.5647583007812, 'referece_logps/rejected': -607.7271728515625, 'referece_logps/chosen': -533.7716674804688, 'logits/rejected': -0.29183104634284973, 'logits/chosen': -0.2630043029785156, 'epoch': 2.61}

 43%|████▎     | 6999/16104 [32:24:32<42:03:27, 16.63s/it]

 43%|████▎     | 7000/16104 [32:24:49<42:33:01, 16.83s/it]

 43%|████▎     | 7001/16104 [32:25:18<51:46:12, 20.47s/it]


 43%|████▎     | 7003/16104 [32:25:49<45:55:38, 18.17s/it]
{'loss': 0.5139, 'learning_rate': 1.2567462049168745e-06, 'rewards/chosen': -0.9824082851409912, 'rewards/rejected': -1.1074644327163696, 'rewards/accuracies': 0.625, 'rewards/margins': 0.12505611777305603, 'policy_logps/rejected': -442.9687805175781, 'policy_logps/chosen': -619.175537109375, 'referece_logps/rejected': -431.89410400390625, 'referece_logps/chosen': -609.3514404296875, 'logits/rejected': -0.30072155594825745, 'logits/chosen': -0.5625796318054199, 'epoch': 2.61}

 43%|████▎     | 7004/16104 [32:26:08<47:02:33, 18.61s/it]


 44%|████▎     | 7006/16104 [32:26:43<44:51:25, 17.75s/it]

 44%|████▎     | 7007/16104 [32:27:02<46:12:35, 18.29s/it]
{'loss': 0.4483, 'learning_rate': 1.2559685846834121e-06, 'rewards/chosen': -0.658218502998352, 'rewards/rejected': -1.8736019134521484, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2153832912445068, 'policy_logps/rejected': -312.6865234375, 'policy_logps/chosen': -270.3218994140625, 'referece_logps/rejected': -293.9504699707031, 'referece_logps/chosen': -263.73968505859375, 'logits/rejected': -0.4903603792190552, 'logits/chosen': -0.3216586709022522, 'epoch': 2.61}


 44%|████▎     | 7009/16104 [32:27:35<43:42:46, 17.30s/it]
{'loss': 0.4636, 'learning_rate': 1.2555797124089077e-06, 'rewards/chosen': -0.38787841796875, 'rewards/rejected': -1.5150929689407349, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1272145509719849, 'policy_logps/rejected': -350.3742370605469, 'policy_logps/chosen': -456.8829650878906, 'referece_logps/rejected': -335.2233581542969, 'referece_logps/chosen': -453.0042419433594, 'logits/rejected': -0.892597496509552, 'logits/chosen': -0.7532147169113159, 'epoch': 2.61}


 44%|████▎     | 7011/16104 [32:28:16<48:10:23, 19.07s/it]
{'loss': 0.4629, 'learning_rate': 1.2551907987797819e-06, 'rewards/chosen': -0.8752864599227905, 'rewards/rejected': -1.7795673608779907, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9042809009552002, 'policy_logps/rejected': -317.2701416015625, 'policy_logps/chosen': -306.199462890625, 'referece_logps/rejected': -299.4744567871094, 'referece_logps/chosen': -297.4465637207031, 'logits/rejected': -0.3835783898830414, 'logits/chosen': -0.3816509246826172, 'epoch': 2.61}


 44%|████▎     | 7013/16104 [32:28:50<45:49:53, 18.15s/it]

 44%|████▎     | 7014/16104 [32:29:05<43:11:48, 17.11s/it]
{'loss': 0.4338, 'learning_rate': 1.2546073509338373e-06, 'rewards/chosen': -0.5780372619628906, 'rewards/rejected': -1.6547448635101318, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0767076015472412, 'policy_logps/rejected': -411.1512145996094, 'policy_logps/chosen': -368.9971618652344, 'referece_logps/rejected': -394.603759765625, 'referece_logps/chosen': -363.2167663574219, 'logits/rejected': 0.3265835642814636, 'logits/chosen': 0.19734491407871246, 'epoch': 2.61}

 44%|████▎     | 7015/16104 [32:29:20<41:20:30, 16.37s/it]

 44%|████▎     | 7016/16104 [32:29:39<43:50:08, 17.36s/it]

 44%|████▎     | 7017/16104 [32:29:54<41:32:14, 16.46s/it]

 44%|████▎     | 7018/16104 [32:30:06<38:06:32, 15.10s/it]


 44%|████▎     | 7020/16104 [32:30:43<42:26:32, 16.82s/it]

 44%|████▎     | 7021/16104 [32:31:03<44:43:20, 17.73s/it]
{'loss': 0.4111, 'learning_rate': 1.253245612517581e-06, 'rewards/chosen': -0.7318075299263, 'rewards/rejected': -2.2376856803894043, 'rewards/accuracies': 0.75, 'rewards/margins': 1.505878210067749, 'policy_logps/rejected': -355.26513671875, 'policy_logps/chosen': -415.7117919921875, 'referece_logps/rejected': -332.88824462890625, 'referece_logps/chosen': -408.3937072753906, 'logits/rejected': 0.058585025370121, 'logits/chosen': -0.020027756690979004, 'epoch': 2.62}

 44%|████▎     | 7022/16104 [32:31:24<47:22:33, 18.78s/it]

 44%|████▎     | 7023/16104 [32:31:40<45:02:10, 17.85s/it]

 44%|████▎     | 7024/16104 [32:31:58<45:27:42, 18.02s/it]

 44%|████▎     | 7025/16104 [32:32:16<44:51:02, 17.78s/it]

 44%|████▎     | 7026/16104 [32:32:32<43:32:52, 17.27s/it]


 44%|████▎     | 7028/16104 [32:33:09<45:40:29, 18.12s/it]

 44%|████▎     | 7029/16104 [32:33:21<41:03:05, 16.28s/it]

 44%|████▎     | 7030/16104 [32:33:41<43:46:21, 17.37s/it]
{'loss': 0.4625, 'learning_rate': 1.2514940687752925e-06, 'rewards/chosen': -0.4063553214073181, 'rewards/rejected': -2.485689163208008, 'rewards/accuracies': 0.875, 'rewards/margins': 2.079334020614624, 'policy_logps/rejected': -466.7076721191406, 'policy_logps/chosen': -421.14434814453125, 'referece_logps/rejected': -441.85076904296875, 'referece_logps/chosen': -417.0807800292969, 'logits/rejected': -0.9691121578216553, 'logits/chosen': -0.9470012187957764, 'epoch': 2.62}

 44%|████▎     | 7031/16104 [32:33:54<40:39:39, 16.13s/it]


 44%|████▎     | 7033/16104 [32:34:25<38:30:42, 15.28s/it]

 44%|████▎     | 7034/16104 [32:34:43<40:49:59, 16.21s/it]
{'loss': 0.4934, 'learning_rate': 1.2507153400406793e-06, 'rewards/chosen': -0.5847191214561462, 'rewards/rejected': -1.9279463291168213, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3432273864746094, 'policy_logps/rejected': -485.32427978515625, 'policy_logps/chosen': -482.4805908203125, 'referece_logps/rejected': -466.04486083984375, 'referece_logps/chosen': -476.63336181640625, 'logits/rejected': 0.01004055142402649, 'logits/chosen': 0.14166758954524994, 'epoch': 2.62}

 44%|████▎     | 7035/16104 [32:35:05<44:37:01, 17.71s/it]


 44%|████▎     | 7037/16104 [32:35:29<37:18:36, 14.81s/it]
{'loss': 0.5586, 'learning_rate': 1.250131186972387e-06, 'rewards/chosen': -0.9211733341217041, 'rewards/rejected': -1.0980292558670044, 'rewards/accuracies': 0.5, 'rewards/margins': 0.1768559068441391, 'policy_logps/rejected': -286.0326232910156, 'policy_logps/chosen': -311.14788818359375, 'referece_logps/rejected': -275.0523376464844, 'referece_logps/chosen': -301.9361572265625, 'logits/rejected': -0.7989023923873901, 'logits/chosen': -0.7995191216468811, 'epoch': 2.62}


 44%|████▎     | 7039/16104 [32:36:03<40:50:16, 16.22s/it]

 44%|████▎     | 7040/16104 [32:36:19<40:54:40, 16.25s/it]
{'loss': 0.5143, 'learning_rate': 1.249546942839821e-06, 'rewards/chosen': -0.610846996307373, 'rewards/rejected': -1.592682123184204, 'rewards/accuracies': 0.75, 'rewards/margins': 0.981835126876831, 'policy_logps/rejected': -258.7572021484375, 'policy_logps/chosen': -324.48883056640625, 'referece_logps/rejected': -242.8303680419922, 'referece_logps/chosen': -318.38037109375, 'logits/rejected': -0.8823157548904419, 'logits/chosen': -0.9938708543777466, 'epoch': 2.62}

 44%|████▎     | 7041/16104 [32:36:35<40:17:59, 16.01s/it]

 44%|████▎     | 7042/16104 [32:36:54<42:48:58, 17.01s/it]

 44%|████▎     | 7043/16104 [32:37:05<38:05:22, 15.13s/it]


 44%|████▎     | 7045/16104 [32:37:39<41:33:47, 16.52s/it]

 44%|████▍     | 7046/16104 [32:37:56<41:30:15, 16.50s/it]

 44%|████▍     | 7047/16104 [32:38:16<44:06:25, 17.53s/it]

 44%|████▍     | 7048/16104 [32:38:36<46:00:17, 18.29s/it]

 44%|████▍     | 7049/16104 [32:38:53<45:35:58, 18.13s/it]

 44%|████▍     | 7050/16104 [32:39:08<42:37:16, 16.95s/it]

 44%|████▍     | 7051/16104 [32:39:28<45:04:06, 17.92s/it]
{'loss': 0.5328, 'learning_rate': 1.247403938686045e-06, 'rewards/chosen': -0.9473016262054443, 'rewards/rejected': -1.83933687210083, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8920350074768066, 'policy_logps/rejected': -406.1395263671875, 'policy_logps/chosen': -400.75048828125, 'referece_logps/rejected': -387.74615478515625, 'referece_logps/chosen': -391.2774353027344, 'logits/rejected': -0.21360695362091064, 'logits/chosen': -0.2178439497947693, 'epoch': 2.63}

 44%|████▍     | 7052/16104 [32:39:45<44:38:56, 17.76s/it]

 44%|████▍     | 7053/16104 [32:39:57<39:53:29, 15.87s/it]

 44%|████▍     | 7054/16104 [32:40:08<36:44:58, 14.62s/it]

 44%|████▍     | 7055/16104 [32:40:31<42:34:52, 16.94s/it]

 44%|████▍     | 7056/16104 [32:40:50<44:46:00, 17.81s/it]

 44%|████▍     | 7057/16104 [32:41:01<39:21:24, 15.66s/it]

 44%|████▍     | 7058/16104 [32:41:21<42:26:02, 16.89s/it]

 44%|████▍     | 7059/16104 [32:41:33<39:00:59, 15.53s/it]

 44%|████▍     | 7060/16104 [32:41:49<39:06:24, 15.57s/it]

 44%|████▍     | 7061/16104 [32:42:11<44:06:56, 17.56s/it]

 44%|████▍     | 7062/16104 [32:42:22<38:51:19, 15.47s/it]

 44%|████▍     | 7063/16104 [32:42:41<41:46:44, 16.64s/it]


 44%|████▍     | 7065/16104 [32:43:16<42:19:09, 16.85s/it]
{'loss': 0.4266, 'learning_rate': 1.2446747288465543e-06, 'rewards/chosen': -0.6635416150093079, 'rewards/rejected': -2.919416666030884, 'rewards/accuracies': 0.875, 'rewards/margins': 2.2558751106262207, 'policy_logps/rejected': -335.9996643066406, 'policy_logps/chosen': -385.98602294921875, 'referece_logps/rejected': -306.8055114746094, 'referece_logps/chosen': -379.3505859375, 'logits/rejected': -0.039083365350961685, 'logits/chosen': -0.1949194073677063, 'epoch': 2.63}

 44%|████▍     | 7066/16104 [32:43:34<42:53:20, 17.08s/it]

 44%|████▍     | 7067/16104 [32:43:51<42:59:57, 17.13s/it]

 44%|████▍     | 7068/16104 [32:44:11<45:05:19, 17.96s/it]


 44%|████▍     | 7070/16104 [32:44:40<40:34:07, 16.17s/it]
{'loss': 0.42, 'learning_rate': 1.243699539790198e-06, 'rewards/chosen': -1.1405177116394043, 'rewards/rejected': -2.0323562622070312, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8918384313583374, 'policy_logps/rejected': -455.3924865722656, 'policy_logps/chosen': -567.184814453125, 'referece_logps/rejected': -435.0690002441406, 'referece_logps/chosen': -555.7796630859375, 'logits/rejected': -0.09972470998764038, 'logits/chosen': 0.0009440258145332336, 'epoch': 2.63}

 44%|████▍     | 7071/16104 [32:44:57<41:32:51, 16.56s/it]

 44%|████▍     | 7072/16104 [32:45:08<37:10:27, 14.82s/it]

 44%|████▍     | 7073/16104 [32:45:27<40:27:16, 16.13s/it]

 44%|████▍     | 7074/16104 [32:45:40<37:33:55, 14.98s/it]

 44%|████▍     | 7075/16104 [32:45:59<41:06:54, 16.39s/it]

 44%|████▍     | 7076/16104 [32:46:20<44:14:12, 17.64s/it]


 44%|████▍     | 7078/16104 [32:46:56<44:42:08, 17.83s/it]
{'loss': 0.4631, 'learning_rate': 1.2421387250901983e-06, 'rewards/chosen': -1.33139169216156, 'rewards/rejected': -3.3884201049804688, 'rewards/accuracies': 0.625, 'rewards/margins': 2.057028293609619, 'policy_logps/rejected': -523.0352783203125, 'policy_logps/chosen': -488.0587158203125, 'referece_logps/rejected': -489.151123046875, 'referece_logps/chosen': -474.744873046875, 'logits/rejected': -0.35181522369384766, 'logits/chosen': -0.22232341766357422, 'epoch': 2.64}

 44%|████▍     | 7079/16104 [32:47:14<44:59:29, 17.95s/it]

 44%|████▍     | 7080/16104 [32:47:25<39:44:16, 15.85s/it]

 44%|████▍     | 7081/16104 [32:47:38<37:09:56, 14.83s/it]

 44%|████▍     | 7082/16104 [32:47:51<35:48:46, 14.29s/it]

 44%|████▍     | 7083/16104 [32:48:06<36:10:39, 14.44s/it]

 44%|████▍     | 7084/16104 [32:48:25<39:59:24, 15.96s/it]

 44%|████▍     | 7085/16104 [32:48:42<40:14:46, 16.06s/it]

 44%|████▍     | 7086/16104 [32:49:01<43:01:09, 17.17s/it]

 44%|████▍     | 7087/16104 [32:49:21<45:12:28, 18.05s/it]

 44%|████▍     | 7088/16104 [32:49:39<44:52:30, 17.92s/it]

 44%|████▍     | 7089/16104 [32:49:51<40:38:13, 16.23s/it]


 44%|████▍     | 7091/16104 [32:50:23<39:01:19, 15.59s/it]
{'loss': 0.6298, 'learning_rate': 1.2396010659893238e-06, 'rewards/chosen': -1.0073347091674805, 'rewards/rejected': -1.2853683233261108, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2780335545539856, 'policy_logps/rejected': -434.37884521484375, 'policy_logps/chosen': -481.28009033203125, 'referece_logps/rejected': -421.5251770019531, 'referece_logps/chosen': -471.2067565917969, 'logits/rejected': -0.5623538494110107, 'logits/chosen': -0.7172658443450928, 'epoch': 2.64}

 44%|████▍     | 7092/16104 [32:50:38<38:39:00, 15.44s/it]

 44%|████▍     | 7093/16104 [32:50:55<39:47:53, 15.90s/it]

 44%|████▍     | 7094/16104 [32:51:15<43:21:29, 17.32s/it]

 44%|████▍     | 7095/16104 [32:51:38<47:07:18, 18.83s/it]

 44%|████▍     | 7096/16104 [32:51:53<44:20:09, 17.72s/it]

 44%|████▍     | 7097/16104 [32:52:11<44:37:55, 17.84s/it]

 44%|████▍     | 7098/16104 [32:52:30<45:51:20, 18.33s/it]

 44%|████▍     | 7099/16104 [32:52:48<45:39:26, 18.25s/it]

 44%|████▍     | 7100/16104 [32:53:01<41:13:15, 16.48s/it]

 44%|████▍     | 7101/16104 [32:53:16<40:11:12, 16.07s/it]

 44%|████▍     | 7102/16104 [32:53:28<37:07:03, 14.84s/it]


 44%|████▍     | 7104/16104 [32:53:53<33:42:24, 13.48s/it]

 44%|████▍     | 7105/16104 [32:54:09<35:32:50, 14.22s/it]
{'loss': 0.5801, 'learning_rate': 1.2368663709980453e-06, 'rewards/chosen': -1.2411950826644897, 'rewards/rejected': -1.1530927419662476, 'rewards/accuracies': 0.625, 'rewards/margins': -0.08810234069824219, 'policy_logps/rejected': -421.97467041015625, 'policy_logps/chosen': -342.6280822753906, 'referece_logps/rejected': -410.4437255859375, 'referece_logps/chosen': -330.21612548828125, 'logits/rejected': -0.18409287929534912, 'logits/chosen': -0.06936442852020264, 'epoch': 2.65}

 44%|████▍     | 7106/16104 [32:54:21<34:24:25, 13.77s/it]

 44%|████▍     | 7107/16104 [32:54:35<34:43:15, 13.89s/it]

 44%|████▍     | 7108/16104 [32:54:54<38:16:25, 15.32s/it]

 44%|████▍     | 7109/16104 [32:55:07<36:45:03, 14.71s/it]

 44%|████▍     | 7110/16104 [32:55:21<35:57:09, 14.39s/it]

 44%|████▍     | 7111/16104 [32:55:37<36:50:11, 14.75s/it]

 44%|████▍     | 7112/16104 [32:55:47<33:51:49, 13.56s/it]

 44%|████▍     | 7113/16104 [32:56:04<35:58:14, 14.40s/it]

 44%|████▍     | 7114/16104 [32:56:25<40:48:22, 16.34s/it]


 44%|████▍     | 7116/16104 [32:56:55<39:56:47, 16.00s/it]
{'loss': 0.4455, 'learning_rate': 1.234716363510927e-06, 'rewards/chosen': -0.7327021360397339, 'rewards/rejected': -1.0124727487564087, 'rewards/accuracies': 0.875, 'rewards/margins': 0.2797705829143524, 'policy_logps/rejected': -403.4517517089844, 'policy_logps/chosen': -377.6561279296875, 'referece_logps/rejected': -393.3270263671875, 'referece_logps/chosen': -370.3291015625, 'logits/rejected': 0.17756876349449158, 'logits/chosen': 0.19247999787330627, 'epoch': 2.65}

 44%|████▍     | 7117/16104 [32:57:15<42:55:49, 17.20s/it]

 44%|████▍     | 7118/16104 [32:57:32<43:14:38, 17.32s/it]

 44%|████▍     | 7119/16104 [32:57:49<43:03:38, 17.25s/it]

 44%|████▍     | 7120/16104 [32:58:09<44:53:10, 17.99s/it]

 44%|████▍     | 7121/16104 [32:58:28<45:12:22, 18.12s/it]

 44%|████▍     | 7122/16104 [32:58:44<43:52:32, 17.59s/it]

 44%|████▍     | 7123/16104 [32:59:04<45:22:53, 18.19s/it]

 44%|████▍     | 7124/16104 [32:59:22<45:30:37, 18.24s/it]

 44%|████▍     | 7125/16104 [32:59:33<39:54:59, 16.00s/it]

 44%|████▍     | 7126/16104 [32:59:52<42:44:03, 17.14s/it]

 44%|████▍     | 7127/16104 [33:00:11<43:25:12, 17.41s/it]

 44%|████▍     | 7128/16104 [33:00:22<39:12:32, 15.73s/it]

 44%|████▍     | 7129/16104 [33:00:37<38:10:09, 15.31s/it]

 44%|████▍     | 7130/16104 [33:00:49<36:09:26, 14.50s/it]

 44%|████▍     | 7131/16104 [33:01:03<35:11:41, 14.12s/it]

 44%|████▍     | 7132/16104 [33:01:20<37:47:11, 15.16s/it]

 44%|████▍     | 7133/16104 [33:01:32<35:19:27, 14.18s/it]

 44%|████▍     | 7134/16104 [33:01:49<37:19:44, 14.98s/it]

 44%|████▍     | 7135/16104 [33:02:02<36:19:09, 14.58s/it]


 44%|████▍     | 7137/16104 [33:02:35<37:44:07, 15.15s/it]
{'loss': 0.5724, 'learning_rate': 1.2306086224062248e-06, 'rewards/chosen': -0.9881574511528015, 'rewards/rejected': -1.2440279722213745, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2558704614639282, 'policy_logps/rejected': -354.2814025878906, 'policy_logps/chosen': -579.51025390625, 'referece_logps/rejected': -341.8410949707031, 'referece_logps/chosen': -569.628662109375, 'logits/rejected': -0.399711012840271, 'logits/chosen': -0.4633904695510864, 'epoch': 2.66}

 44%|████▍     | 7138/16104 [33:02:54<40:17:37, 16.18s/it]

 44%|████▍     | 7139/16104 [33:03:09<39:50:58, 16.00s/it]

 44%|████▍     | 7140/16104 [33:03:22<37:27:24, 15.04s/it]

 44%|████▍     | 7141/16104 [33:03:36<36:49:07, 14.79s/it]


 44%|████▍     | 7143/16104 [33:04:08<37:06:27, 14.91s/it]

 44%|████▍     | 7144/16104 [33:04:27<40:32:32, 16.29s/it]

 44%|████▍     | 7145/16104 [33:04:39<37:11:15, 14.94s/it]

 44%|████▍     | 7146/16104 [33:04:52<35:53:21, 14.42s/it]

 44%|████▍     | 7147/16104 [33:05:10<38:10:13, 15.34s/it]

 44%|████▍     | 7148/16104 [33:05:28<40:03:37, 16.10s/it]

 44%|████▍     | 7149/16104 [33:05:49<43:34:29, 17.52s/it]

 44%|████▍     | 7150/16104 [33:06:11<47:00:20, 18.90s/it]

 44%|████▍     | 7151/16104 [33:06:25<43:50:17, 17.63s/it]

 44%|████▍     | 7152/16104 [33:06:45<45:25:29, 18.27s/it]

 44%|████▍     | 7153/16104 [33:07:05<46:24:16, 18.66s/it]

 44%|████▍     | 7154/16104 [33:07:26<48:26:17, 19.48s/it]

 44%|████▍     | 7155/16104 [33:07:46<48:30:51, 19.52s/it]

 44%|████▍     | 7156/16104 [33:08:01<45:45:36, 18.41s/it]

 44%|████▍     | 7157/16104 [33:08:16<42:45:47, 17.21s/it]

 44%|████▍     | 7158/16104 [33:08:34<43:09:03, 17.36s/it]

 44%|████▍     | 7159/16104 [33:08:49<41:54:56, 16.87s/it]

 44%|████▍     | 7160/16104 [33:09:05<41:17:09, 16.62s/it]

 44%|████▍     | 7161/16104 [33:09:18<38:02:40, 15.31s/it]

 44%|████▍     | 7162/16104 [33:09:37<40:58:17, 16.49s/it]

 44%|████▍     | 7163/16104 [33:09:54<41:44:39, 16.81s/it]

 44%|████▍     | 7164/16104 [33:10:15<44:55:48, 18.09s/it]

 44%|████▍     | 7165/16104 [33:10:33<44:21:32, 17.86s/it]
{'loss': 0.5364, 'learning_rate': 1.2251252475804083e-06, 'rewards/chosen': -0.7184762954711914, 'rewards/rejected': -1.429654598236084, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7111783027648926, 'policy_logps/rejected': -441.2244567871094, 'policy_logps/chosen': -498.968505859375, 'referece_logps/rejected': -426.92791748046875, 'referece_logps/chosen': -491.78375244140625, 'logits/rejected': -0.39106249809265137, 'logits/chosen': -0.3851466774940491, 'epoch': 2.67}


 45%|████▍     | 7167/16104 [33:11:10<44:23:45, 17.88s/it]

 45%|████▍     | 7168/16104 [33:11:26<43:09:26, 17.39s/it]

 45%|████▍     | 7169/16104 [33:11:46<45:05:37, 18.17s/it]

 45%|████▍     | 7170/16104 [33:12:01<43:07:27, 17.38s/it]

 45%|████▍     | 7171/16104 [33:12:21<44:26:20, 17.91s/it]

 45%|████▍     | 7172/16104 [33:12:35<42:10:29, 17.00s/it]

 45%|████▍     | 7173/16104 [33:12:57<45:43:58, 18.43s/it]

 45%|████▍     | 7174/16104 [33:13:17<46:31:38, 18.76s/it]
{'loss': 0.4335, 'learning_rate': 1.2233612096190426e-06, 'rewards/chosen': -0.7764847278594971, 'rewards/rejected': -1.5025469064712524, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7260621786117554, 'policy_logps/rejected': -455.763427734375, 'policy_logps/chosen': -467.84429931640625, 'referece_logps/rejected': -440.7379150390625, 'referece_logps/chosen': -460.0794677734375, 'logits/rejected': -0.7360881567001343, 'logits/chosen': -0.8288273215293884, 'epoch': 2.67}


 45%|████▍     | 7176/16104 [33:13:49<44:17:16, 17.86s/it]

 45%|████▍     | 7177/16104 [33:14:02<40:55:05, 16.50s/it]

 45%|████▍     | 7178/16104 [33:14:22<43:05:35, 17.38s/it]

 45%|████▍     | 7179/16104 [33:14:35<39:55:35, 16.10s/it]

 45%|████▍     | 7180/16104 [33:14:54<41:44:00, 16.84s/it]

 45%|████▍     | 7181/16104 [33:15:13<43:54:38, 17.72s/it]

 45%|████▍     | 7182/16104 [33:15:31<43:47:59, 17.67s/it]
{'loss': 0.4312, 'learning_rate': 1.2217925612915535e-06, 'rewards/chosen': -0.8785301446914673, 'rewards/rejected': -2.308842658996582, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4303126335144043, 'policy_logps/rejected': -436.04522705078125, 'policy_logps/chosen': -351.05291748046875, 'referece_logps/rejected': -412.95684814453125, 'referece_logps/chosen': -342.267578125, 'logits/rejected': 0.07236312329769135, 'logits/chosen': 0.08231928944587708, 'epoch': 2.68}


 45%|████▍     | 7184/16104 [33:16:05<42:53:25, 17.31s/it]

 45%|████▍     | 7185/16104 [33:16:27<46:32:16, 18.78s/it]

 45%|████▍     | 7186/16104 [33:16:45<46:11:59, 18.65s/it]

 45%|████▍     | 7187/16104 [33:16:57<40:50:56, 16.49s/it]

 45%|████▍     | 7188/16104 [33:17:16<42:54:02, 17.32s/it]

 45%|████▍     | 7189/16104 [33:17:31<41:19:47, 16.69s/it]

 45%|████▍     | 7190/16104 [33:17:47<40:24:45, 16.32s/it]

 45%|████▍     | 7191/16104 [33:17:59<37:19:07, 15.07s/it]

 45%|████▍     | 7192/16104 [33:18:21<42:42:15, 17.25s/it]

 45%|████▍     | 7193/16104 [33:18:38<41:57:24, 16.95s/it]

 45%|████▍     | 7194/16104 [33:18:51<39:18:09, 15.88s/it]

 45%|████▍     | 7195/16104 [33:19:08<40:06:45, 16.21s/it]

 45%|████▍     | 7196/16104 [33:19:22<38:23:00, 15.51s/it]

 45%|████▍     | 7197/16104 [33:19:37<38:22:59, 15.51s/it]

 45%|████▍     | 7198/16104 [33:19:56<40:50:28, 16.51s/it]

 45%|████▍     | 7199/16104 [33:20:15<42:53:33, 17.34s/it]

 45%|████▍     | 7200/16104 [33:20:35<44:35:29, 18.03s/it]
{'loss': 0.5676, 'learning_rate': 1.2182610093186343e-06, 'rewards/chosen': -0.8452644944190979, 'rewards/rejected': -1.482009768486023, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6367451548576355, 'policy_logps/rejected': -307.7174987792969, 'policy_logps/chosen': -372.87811279296875, 'referece_logps/rejected': -292.8973693847656, 'referece_logps/chosen': -364.4254455566406, 'logits/rejected': -1.3375104665756226, 'logits/chosen': -1.2906155586242676, 'epoch': 2.68}


 45%|████▍     | 7202/16104 [33:21:04<39:15:21, 15.88s/it]

 45%|████▍     | 7203/16104 [33:21:17<37:13:46, 15.06s/it]

 45%|████▍     | 7204/16104 [33:21:35<39:40:17, 16.05s/it]

 45%|████▍     | 7205/16104 [33:21:53<41:12:30, 16.67s/it]

 45%|████▍     | 7206/16104 [33:22:16<45:22:32, 18.36s/it]

 45%|████▍     | 7207/16104 [33:22:30<42:26:54, 17.18s/it]

 45%|████▍     | 7208/16104 [33:22:45<40:47:04, 16.50s/it]

 45%|████▍     | 7209/16104 [33:22:59<38:29:52, 15.58s/it]

 45%|████▍     | 7210/16104 [33:23:12<36:34:12, 14.80s/it]

 45%|████▍     | 7211/16104 [33:23:27<37:23:38, 15.14s/it]

 45%|████▍     | 7212/16104 [33:23:49<42:08:28, 17.06s/it]

 45%|████▍     | 7213/16104 [33:24:07<42:55:03, 17.38s/it]
{'loss': 0.4247, 'learning_rate': 1.2157086622869385e-06, 'rewards/chosen': -1.1221129894256592, 'rewards/rejected': -2.5613324642181396, 'rewards/accuracies': 0.875, 'rewards/margins': 1.439219355583191, 'policy_logps/rejected': -376.9775390625, 'policy_logps/chosen': -319.67578125, 'referece_logps/rejected': -351.3642578125, 'referece_logps/chosen': -308.4546813964844, 'logits/rejected': -0.5927332043647766, 'logits/chosen': -0.42837342619895935, 'epoch': 2.69}


 45%|████▍     | 7215/16104 [33:24:45<44:49:58, 18.16s/it]

 45%|████▍     | 7216/16104 [33:24:58<41:08:12, 16.66s/it]
{'loss': 0.5374, 'learning_rate': 1.2151194490711177e-06, 'rewards/chosen': -1.0205233097076416, 'rewards/rejected': -0.8323899507522583, 'rewards/accuracies': 0.5, 'rewards/margins': -0.1881333291530609, 'policy_logps/rejected': -292.76104736328125, 'policy_logps/chosen': -435.7175598144531, 'referece_logps/rejected': -284.4371337890625, 'referece_logps/chosen': -425.5123596191406, 'logits/rejected': -0.13067412376403809, 'logits/chosen': -0.26657170057296753, 'epoch': 2.69}

 45%|████▍     | 7217/16104 [33:25:15<41:10:50, 16.68s/it]


 45%|████▍     | 7219/16104 [33:25:44<38:54:58, 15.77s/it]

 45%|████▍     | 7220/16104 [33:26:00<39:27:23, 15.99s/it]

 45%|████▍     | 7221/16104 [33:26:20<41:45:03, 16.92s/it]

 45%|████▍     | 7222/16104 [33:26:39<43:21:00, 17.57s/it]

 45%|████▍     | 7223/16104 [33:27:00<46:30:21, 18.85s/it]

 45%|████▍     | 7224/16104 [33:27:15<42:57:59, 17.42s/it]

 45%|████▍     | 7225/16104 [33:27:35<45:29:46, 18.45s/it]

 45%|████▍     | 7226/16104 [33:27:50<42:43:44, 17.33s/it]

 45%|████▍     | 7227/16104 [33:28:09<43:51:38, 17.79s/it]

 45%|████▍     | 7228/16104 [33:28:30<46:23:41, 18.82s/it]

 45%|████▍     | 7229/16104 [33:28:47<45:05:55, 18.29s/it]

 45%|████▍     | 7230/16104 [33:29:08<46:47:27, 18.98s/it]

 45%|████▍     | 7231/16104 [33:29:22<43:01:45, 17.46s/it]

 45%|████▍     | 7232/16104 [33:29:39<42:31:45, 17.26s/it]

 45%|████▍     | 7233/16104 [33:29:55<41:45:02, 16.94s/it]

 45%|████▍     | 7234/16104 [33:30:09<39:30:27, 16.03s/it]

 45%|████▍     | 7235/16104 [33:30:23<37:58:18, 15.41s/it]

 45%|████▍     | 7236/16104 [33:30:42<41:01:15, 16.65s/it]

 45%|████▍     | 7237/16104 [33:31:00<41:38:14, 16.90s/it]

 45%|████▍     | 7238/16104 [33:31:18<42:30:53, 17.26s/it]
{'loss': 0.6077, 'learning_rate': 1.210796172956285e-06, 'rewards/chosen': -1.08624267578125, 'rewards/rejected': -1.3901184797286987, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3038758337497711, 'policy_logps/rejected': -280.6432189941406, 'policy_logps/chosen': -303.3224792480469, 'referece_logps/rejected': -266.7420654296875, 'referece_logps/chosen': -292.46002197265625, 'logits/rejected': -1.4126628637313843, 'logits/chosen': -1.273461103439331, 'epoch': 2.7}


 45%|████▍     | 7240/16104 [33:31:42<35:56:08, 14.59s/it]

 45%|████▍     | 7241/16104 [33:31:56<35:05:14, 14.25s/it]

 45%|████▍     | 7242/16104 [33:32:08<33:14:59, 13.51s/it]

 45%|████▍     | 7243/16104 [33:32:27<37:36:38, 15.28s/it]

 45%|████▍     | 7244/16104 [33:32:39<34:54:43, 14.19s/it]

 45%|████▍     | 7245/16104 [33:32:58<38:58:44, 15.84s/it]

 45%|████▍     | 7246/16104 [33:33:10<35:48:50, 14.56s/it]

 45%|████▌     | 7247/16104 [33:33:28<38:50:13, 15.79s/it]

 45%|████▌     | 7248/16104 [33:33:50<42:47:05, 17.39s/it]

 45%|████▌     | 7249/16104 [33:34:09<44:23:51, 18.05s/it]

 45%|████▌     | 7250/16104 [33:34:25<42:38:45, 17.34s/it]

 45%|████▌     | 7251/16104 [33:34:40<41:01:50, 16.68s/it]

 45%|████▌     | 7252/16104 [33:35:02<44:55:07, 18.27s/it]
{'loss': 0.4477, 'learning_rate': 1.2080428430805524e-06, 'rewards/chosen': -0.7967288494110107, 'rewards/rejected': -1.763260006904602, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9665310978889465, 'policy_logps/rejected': -355.4520568847656, 'policy_logps/chosen': -459.4735107421875, 'referece_logps/rejected': -337.8194885253906, 'referece_logps/chosen': -451.5062561035156, 'logits/rejected': -0.8773037791252136, 'logits/chosen': -0.8889053463935852, 'epoch': 2.7}


 45%|████▌     | 7254/16104 [33:35:37<44:30:57, 18.11s/it]
{'loss': 0.4927, 'learning_rate': 1.207649375080666e-06, 'rewards/chosen': -1.0893406867980957, 'rewards/rejected': -1.5993525981903076, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5100120306015015, 'policy_logps/rejected': -365.48822021484375, 'policy_logps/chosen': -321.72711181640625, 'referece_logps/rejected': -349.4947204589844, 'referece_logps/chosen': -310.83367919921875, 'logits/rejected': -1.0515114068984985, 'logits/chosen': -0.9574695825576782, 'epoch': 2.7}


 45%|████▌     | 7256/16104 [33:36:11<41:48:51, 17.01s/it]

 45%|████▌     | 7257/16104 [33:36:33<45:16:59, 18.43s/it]

 45%|████▌     | 7258/16104 [33:36:52<46:04:04, 18.75s/it]

 45%|████▌     | 7259/16104 [33:37:12<46:45:28, 19.03s/it]

 45%|████▌     | 7260/16104 [33:37:31<46:53:48, 19.09s/it]
{'loss': 0.4328, 'learning_rate': 1.2064687697407937e-06, 'rewards/chosen': -1.6186683177947998, 'rewards/rejected': -2.0652990341186523, 'rewards/accuracies': 0.5, 'rewards/margins': 0.44663068652153015, 'policy_logps/rejected': -546.3818359375, 'policy_logps/chosen': -497.63385009765625, 'referece_logps/rejected': -525.7288818359375, 'referece_logps/chosen': -481.4471435546875, 'logits/rejected': -0.6202576160430908, 'logits/chosen': -0.6507840156555176, 'epoch': 2.7}


 45%|████▌     | 7262/16104 [33:38:11<47:30:15, 19.34s/it]

 45%|████▌     | 7263/16104 [33:38:32<49:03:15, 19.97s/it]

 45%|████▌     | 7264/16104 [33:38:50<47:35:53, 19.38s/it]

 45%|████▌     | 7265/16104 [33:39:11<48:40:01, 19.82s/it]

 45%|████▌     | 7266/16104 [33:39:29<47:11:08, 19.22s/it]

 45%|████▌     | 7267/16104 [33:39:41<42:01:55, 17.12s/it]

 45%|████▌     | 7268/16104 [33:39:54<39:16:35, 16.00s/it]

 45%|████▌     | 7269/16104 [33:40:15<42:27:38, 17.30s/it]
{'loss': 0.5367, 'learning_rate': 1.2046972985064074e-06, 'rewards/chosen': -0.7178792953491211, 'rewards/rejected': -1.3617204427719116, 'rewards/accuracies': 0.875, 'rewards/margins': 0.643841028213501, 'policy_logps/rejected': -275.4109802246094, 'policy_logps/chosen': -346.1978454589844, 'referece_logps/rejected': -261.79376220703125, 'referece_logps/chosen': -339.01904296875, 'logits/rejected': -1.1291985511779785, 'logits/chosen': -1.3618900775909424, 'epoch': 2.71}


 45%|████▌     | 7271/16104 [33:40:51<43:03:44, 17.55s/it]
{'loss': 0.5011, 'learning_rate': 1.2043035469436385e-06, 'rewards/chosen': -1.0950450897216797, 'rewards/rejected': -1.6477311849594116, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5526860952377319, 'policy_logps/rejected': -422.4095764160156, 'policy_logps/chosen': -390.592529296875, 'referece_logps/rejected': -405.9322814941406, 'referece_logps/chosen': -379.6420593261719, 'logits/rejected': -0.34886252880096436, 'logits/chosen': -0.3144303858280182, 'epoch': 2.71}

 45%|████▌     | 7272/16104 [33:41:08<42:25:47, 17.29s/it]


 45%|████▌     | 7274/16104 [33:41:43<42:13:08, 17.21s/it]
{'loss': 0.5115, 'learning_rate': 1.2037128576360743e-06, 'rewards/chosen': -0.7575900554656982, 'rewards/rejected': -2.331259250640869, 'rewards/accuracies': 0.75, 'rewards/margins': 1.573669195175171, 'policy_logps/rejected': -495.2415466308594, 'policy_logps/chosen': -502.0959167480469, 'referece_logps/rejected': -471.9289245605469, 'referece_logps/chosen': -494.5200500488281, 'logits/rejected': -0.8509238362312317, 'logits/chosen': -0.8892570734024048, 'epoch': 2.71}

 45%|████▌     | 7275/16104 [33:42:00<42:00:04, 17.13s/it]


 45%|████▌     | 7277/16104 [33:42:40<45:22:05, 18.50s/it]
{'loss': 0.5618, 'learning_rate': 1.2031220941635742e-06, 'rewards/chosen': -0.9447385668754578, 'rewards/rejected': -1.6323013305664062, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6875627040863037, 'policy_logps/rejected': -321.6011047363281, 'policy_logps/chosen': -384.3143615722656, 'referece_logps/rejected': -305.278076171875, 'referece_logps/chosen': -374.86700439453125, 'logits/rejected': 0.3876722455024719, 'logits/chosen': 0.3460308313369751, 'epoch': 2.71}


 45%|████▌     | 7279/16104 [33:43:16<45:00:09, 18.36s/it]

 45%|████▌     | 7280/16104 [33:43:33<44:32:21, 18.17s/it]

 45%|████▌     | 7281/16104 [33:43:45<39:56:42, 16.30s/it]
{'loss': 0.5745, 'learning_rate': 1.2023342945376387e-06, 'rewards/chosen': -0.7227716445922852, 'rewards/rejected': -0.9534834027290344, 'rewards/accuracies': 0.5, 'rewards/margins': 0.23071175813674927, 'policy_logps/rejected': -429.15106201171875, 'policy_logps/chosen': -511.0615539550781, 'referece_logps/rejected': -419.6162109375, 'referece_logps/chosen': -503.8338623046875, 'logits/rejected': -0.6050502061843872, 'logits/chosen': -0.6864306330680847, 'epoch': 2.71}

 45%|████▌     | 7282/16104 [33:44:02<40:35:23, 16.56s/it]

 45%|████▌     | 7283/16104 [33:44:21<41:45:55, 17.05s/it]


 45%|████▌     | 7285/16104 [33:44:59<45:04:33, 18.40s/it]

 45%|████▌     | 7286/16104 [33:45:16<43:27:41, 17.74s/it]

 45%|████▌     | 7287/16104 [33:45:36<45:17:50, 18.50s/it]

 45%|████▌     | 7288/16104 [33:45:54<44:51:44, 18.32s/it]
{'loss': 0.4895, 'learning_rate': 1.2009553303848875e-06, 'rewards/chosen': -0.9197663068771362, 'rewards/rejected': -0.8054519891738892, 'rewards/accuracies': 0.375, 'rewards/margins': -0.11431434750556946, 'policy_logps/rejected': -671.7291259765625, 'policy_logps/chosen': -623.0679321289062, 'referece_logps/rejected': -663.6746215820312, 'referece_logps/chosen': -613.8703002929688, 'logits/rejected': -0.2102314829826355, 'logits/chosen': -0.32104599475860596, 'epoch': 2.72}


 45%|████▌     | 7290/16104 [33:46:24<41:16:06, 16.86s/it]

 45%|████▌     | 7291/16104 [33:46:37<38:43:00, 15.82s/it]

 45%|████▌     | 7292/16104 [33:46:55<40:25:56, 16.52s/it]
{'loss': 0.5396, 'learning_rate': 1.200167171855675e-06, 'rewards/chosen': -0.4789520502090454, 'rewards/rejected': -2.026427745819092, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5474756956100464, 'policy_logps/rejected': -378.0809020996094, 'policy_logps/chosen': -380.3156433105469, 'referece_logps/rejected': -357.816650390625, 'referece_logps/chosen': -375.5261535644531, 'logits/rejected': -0.056635648012161255, 'logits/chosen': -0.09380954504013062, 'epoch': 2.72}

 45%|████▌     | 7293/16104 [33:47:15<42:39:10, 17.43s/it]


 45%|████▌     | 7295/16104 [33:47:46<40:21:44, 16.49s/it]

 45%|████▌     | 7296/16104 [33:47:58<37:13:51, 15.22s/it]
{'loss': 0.536, 'learning_rate': 1.1993788837725602e-06, 'rewards/chosen': -0.4812021255493164, 'rewards/rejected': -0.987886905670166, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5066846609115601, 'policy_logps/rejected': -471.09588623046875, 'policy_logps/chosen': -598.3816528320312, 'referece_logps/rejected': -461.2170715332031, 'referece_logps/chosen': -593.569580078125, 'logits/rejected': -0.7248827219009399, 'logits/chosen': -0.6746357679367065, 'epoch': 2.72}

 45%|████▌     | 7297/16104 [33:48:17<40:03:34, 16.37s/it]


 45%|████▌     | 7299/16104 [33:48:50<39:29:17, 16.15s/it]

 45%|████▌     | 7300/16104 [33:49:08<40:37:56, 16.61s/it]

 45%|████▌     | 7301/16104 [33:49:26<41:40:39, 17.04s/it]
{'loss': 0.4, 'learning_rate': 1.198393342260761e-06, 'rewards/chosen': -0.8602307438850403, 'rewards/rejected': -2.073317050933838, 'rewards/accuracies': 0.75, 'rewards/margins': 1.213086485862732, 'policy_logps/rejected': -298.6907958984375, 'policy_logps/chosen': -321.1741943359375, 'referece_logps/rejected': -277.9576416015625, 'referece_logps/chosen': -312.5718994140625, 'logits/rejected': -1.374388575553894, 'logits/chosen': -1.2585697174072266, 'epoch': 2.72}

 45%|████▌     | 7302/16104 [33:49:41<40:37:25, 16.61s/it]

 45%|████▌     | 7303/16104 [33:49:57<39:47:36, 16.28s/it]


 45%|████▌     | 7305/16104 [33:50:28<38:44:49, 15.85s/it]

 45%|████▌     | 7306/16104 [33:50:40<35:53:44, 14.69s/it]
{'loss': 0.4962, 'learning_rate': 1.19740760011486e-06, 'rewards/chosen': -0.8519302606582642, 'rewards/rejected': -1.1878896951675415, 'rewards/accuracies': 0.875, 'rewards/margins': 0.33595943450927734, 'policy_logps/rejected': -411.23553466796875, 'policy_logps/chosen': -304.4310302734375, 'referece_logps/rejected': -399.3566589355469, 'referece_logps/chosen': -295.9117126464844, 'logits/rejected': 0.0362529456615448, 'logits/chosen': 0.11069311201572418, 'epoch': 2.72}


 45%|████▌     | 7308/16104 [33:51:12<38:05:38, 15.59s/it]
{'loss': 0.4569, 'learning_rate': 1.1970132473022445e-06, 'rewards/chosen': -0.8068353533744812, 'rewards/rejected': -1.6333305835723877, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8264952898025513, 'policy_logps/rejected': -282.4422912597656, 'policy_logps/chosen': -281.6989440917969, 'referece_logps/rejected': -266.1090087890625, 'referece_logps/chosen': -273.6305847167969, 'logits/rejected': -1.593986988067627, 'logits/chosen': -1.5679702758789062, 'epoch': 2.72}


 45%|████▌     | 7310/16104 [33:51:42<37:04:56, 15.18s/it]

 45%|████▌     | 7311/16104 [33:52:00<39:20:10, 16.10s/it]

 45%|████▌     | 7312/16104 [33:52:18<40:26:18, 16.56s/it]

 45%|████▌     | 7313/16104 [33:52:29<36:59:34, 15.15s/it]
{'loss': 0.6121, 'learning_rate': 1.1960272259433974e-06, 'rewards/chosen': -1.1286516189575195, 'rewards/rejected': -1.7681092023849487, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6394575834274292, 'policy_logps/rejected': -316.6492004394531, 'policy_logps/chosen': -267.0147705078125, 'referece_logps/rejected': -298.9681091308594, 'referece_logps/chosen': -255.72825622558594, 'logits/rejected': -1.1753814220428467, 'logits/chosen': -1.0870834589004517, 'epoch': 2.72}


 45%|████▌     | 7315/16104 [33:53:06<41:48:58, 17.13s/it]

 45%|████▌     | 7316/16104 [33:53:24<42:28:16, 17.40s/it]

 45%|████▌     | 7317/16104 [33:53:38<39:33:44, 16.21s/it]

 45%|████▌     | 7318/16104 [33:53:54<39:24:01, 16.14s/it]

 45%|████▌     | 7319/16104 [33:54:12<40:49:17, 16.73s/it]
{'loss': 0.5922, 'learning_rate': 1.1948437387220797e-06, 'rewards/chosen': -1.3720543384552002, 'rewards/rejected': -2.376058578491211, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0040041208267212, 'policy_logps/rejected': -293.9593200683594, 'policy_logps/chosen': -335.6124572753906, 'referece_logps/rejected': -270.1986999511719, 'referece_logps/chosen': -321.8919372558594, 'logits/rejected': -0.7284696102142334, 'logits/chosen': -0.6951507925987244, 'epoch': 2.73}

 45%|████▌     | 7320/16104 [33:54:29<41:18:55, 16.93s/it]

 45%|████▌     | 7321/16104 [33:54:47<41:57:30, 17.20s/it]

 45%|████▌     | 7322/16104 [33:55:05<42:34:21, 17.45s/it]

 45%|████▌     | 7323/16104 [33:55:25<44:12:55, 18.13s/it]


 45%|████▌     | 7325/16104 [33:55:57<41:52:40, 17.17s/it]
{'loss': 0.4715, 'learning_rate': 1.193659967756826e-06, 'rewards/chosen': -0.5563894510269165, 'rewards/rejected': -1.6418187618255615, 'rewards/accuracies': 1.0, 'rewards/margins': 1.0854294300079346, 'policy_logps/rejected': -294.31591796875, 'policy_logps/chosen': -353.0685729980469, 'referece_logps/rejected': -277.897705078125, 'referece_logps/chosen': -347.50469970703125, 'logits/rejected': -0.6885057687759399, 'logits/chosen': -0.7100365161895752, 'epoch': 2.73}


 45%|████▌     | 7327/16104 [33:56:29<39:57:31, 16.39s/it]

 46%|████▌     | 7328/16104 [33:56:50<43:48:07, 17.97s/it]

 46%|████▌     | 7329/16104 [33:57:04<40:27:51, 16.60s/it]
{'loss': 0.4974, 'learning_rate': 1.192870630329087e-06, 'rewards/chosen': -1.2219748497009277, 'rewards/rejected': -2.8323469161987305, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6103720664978027, 'policy_logps/rejected': -320.8660583496094, 'policy_logps/chosen': -367.36578369140625, 'referece_logps/rejected': -292.5426025390625, 'referece_logps/chosen': -355.14599609375, 'logits/rejected': -0.8793107867240906, 'logits/chosen': -1.014411211013794, 'epoch': 2.73}

 46%|████▌     | 7330/16104 [33:57:24<42:52:10, 17.59s/it]


 46%|████▌     | 7332/16104 [33:57:56<41:31:48, 17.04s/it]

 46%|████▌     | 7333/16104 [33:58:10<39:37:45, 16.27s/it]
{'loss': 0.4708, 'learning_rate': 1.1920811680699756e-06, 'rewards/chosen': -1.3852548599243164, 'rewards/rejected': -2.074443817138672, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6891891956329346, 'policy_logps/rejected': -401.03753662109375, 'policy_logps/chosen': -458.1154479980469, 'referece_logps/rejected': -380.2930603027344, 'referece_logps/chosen': -444.2629089355469, 'logits/rejected': 0.056091900914907455, 'logits/chosen': -0.06399865448474884, 'epoch': 2.73}

 46%|████▌     | 7334/16104 [33:58:24<37:30:46, 15.40s/it]


 46%|████▌     | 7336/16104 [33:58:58<38:32:23, 15.82s/it]

 46%|████▌     | 7337/16104 [33:59:14<38:59:47, 16.01s/it]

 46%|████▌     | 7338/16104 [33:59:36<43:20:21, 17.80s/it]
{'loss': 0.5169, 'learning_rate': 1.1910941654803958e-06, 'rewards/chosen': -1.6040847301483154, 'rewards/rejected': -2.29424786567688, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6901630759239197, 'policy_logps/rejected': -349.2131042480469, 'policy_logps/chosen': -425.0616760253906, 'referece_logps/rejected': -326.2706298828125, 'referece_logps/chosen': -409.02081298828125, 'logits/rejected': -1.081272006034851, 'logits/chosen': -1.1959375143051147, 'epoch': 2.73}


 46%|████▌     | 7340/16104 [34:00:14<44:44:54, 18.38s/it]

 46%|████▌     | 7341/16104 [34:00:34<45:42:36, 18.78s/it]

 46%|████▌     | 7342/16104 [34:00:46<41:03:10, 16.87s/it]

 46%|████▌     | 7343/16104 [34:01:06<43:11:10, 17.75s/it]
{'loss': 0.4802, 'learning_rate': 1.1901069696383319e-06, 'rewards/chosen': -0.573948085308075, 'rewards/rejected': -1.8245995044708252, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2506517171859741, 'policy_logps/rejected': -527.683349609375, 'policy_logps/chosen': -461.813232421875, 'referece_logps/rejected': -509.4373474121094, 'referece_logps/chosen': -456.07379150390625, 'logits/rejected': -0.9184222221374512, 'logits/chosen': -0.8078137636184692, 'epoch': 2.74}

 46%|████▌     | 7344/16104 [34:01:26<44:34:31, 18.32s/it]


 46%|████▌     | 7346/16104 [34:01:59<42:41:19, 17.55s/it]
{'loss': 0.4273, 'learning_rate': 1.1895145597872047e-06, 'rewards/chosen': -1.3074822425842285, 'rewards/rejected': -2.342367172241211, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0348846912384033, 'policy_logps/rejected': -211.04537963867188, 'policy_logps/chosen': -363.0853576660156, 'referece_logps/rejected': -187.6217041015625, 'referece_logps/chosen': -350.0105285644531, 'logits/rejected': -1.351806640625, 'logits/chosen': -1.407365322113037, 'epoch': 2.74}


 46%|████▌     | 7348/16104 [34:02:33<40:47:21, 16.77s/it]
{'loss': 0.6529, 'learning_rate': 1.189119581542129e-06, 'rewards/chosen': -0.6434552669525146, 'rewards/rejected': -1.4698563814163208, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8264012336730957, 'policy_logps/rejected': -183.69789123535156, 'policy_logps/chosen': -323.0495300292969, 'referece_logps/rejected': -168.99932861328125, 'referece_logps/chosen': -316.614990234375, 'logits/rejected': -0.6296012997627258, 'logits/chosen': -0.5840080976486206, 'epoch': 2.74}


 46%|████▌     | 7350/16104 [34:03:01<37:19:18, 15.35s/it]
{'loss': 0.5255, 'learning_rate': 1.1887245726961558e-06, 'rewards/chosen': -0.3107059597969055, 'rewards/rejected': -1.351104974746704, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0403990745544434, 'policy_logps/rejected': -495.064453125, 'policy_logps/chosen': -505.2729797363281, 'referece_logps/rejected': -481.55340576171875, 'referece_logps/chosen': -502.1658935546875, 'logits/rejected': 0.2309548407793045, 'logits/chosen': 0.22451253235340118, 'epoch': 2.74}

 46%|████▌     | 7351/16104 [34:03:14<35:47:37, 14.72s/it]


 46%|████▌     | 7353/16104 [34:03:51<40:33:02, 16.68s/it]

 46%|████▌     | 7354/16104 [34:04:06<39:40:51, 16.33s/it]

 46%|████▌     | 7355/16104 [34:04:24<40:59:12, 16.87s/it]

 46%|████▌     | 7356/16104 [34:04:37<37:38:00, 15.49s/it]

 46%|████▌     | 7357/16104 [34:04:52<37:51:19, 15.58s/it]
{'loss': 0.6138, 'learning_rate': 1.1873418016759987e-06, 'rewards/chosen': -1.1486396789550781, 'rewards/rejected': -1.3446238040924072, 'rewards/accuracies': 0.625, 'rewards/margins': 0.1959840953350067, 'policy_logps/rejected': -336.9215393066406, 'policy_logps/chosen': -292.9913024902344, 'referece_logps/rejected': -323.47528076171875, 'referece_logps/chosen': -281.5049133300781, 'logits/rejected': -1.0476810932159424, 'logits/chosen': -1.0632368326187134, 'epoch': 2.74}


 46%|████▌     | 7359/16104 [34:05:17<34:07:51, 14.05s/it]
{'loss': 0.6338, 'learning_rate': 1.1869466559170071e-06, 'rewards/chosen': -0.5421357154846191, 'rewards/rejected': -1.0025218725204468, 'rewards/accuracies': 0.875, 'rewards/margins': 0.46038618683815, 'policy_logps/rejected': -426.7257995605469, 'policy_logps/chosen': -465.38519287109375, 'referece_logps/rejected': -416.70062255859375, 'referece_logps/chosen': -459.9638366699219, 'logits/rejected': -0.3040696382522583, 'logits/chosen': -0.20212817192077637, 'epoch': 2.74}

 46%|████▌     | 7360/16104 [34:05:32<34:18:01, 14.12s/it]


 46%|████▌     | 7362/16104 [34:06:06<38:18:07, 15.77s/it]

 46%|████▌     | 7363/16104 [34:06:19<36:10:25, 14.90s/it]
{'loss': 0.5971, 'learning_rate': 1.1861562737150574e-06, 'rewards/chosen': -1.2656084299087524, 'rewards/rejected': -1.3457748889923096, 'rewards/accuracies': 0.625, 'rewards/margins': 0.08016643673181534, 'policy_logps/rejected': -467.5743713378906, 'policy_logps/chosen': -474.8487548828125, 'referece_logps/rejected': -454.1166076660156, 'referece_logps/chosen': -462.1926574707031, 'logits/rejected': -0.04023420810699463, 'logits/chosen': 0.06764940172433853, 'epoch': 2.74}


 46%|████▌     | 7365/16104 [34:06:41<31:01:21, 12.78s/it]

 46%|████▌     | 7366/16104 [34:06:59<34:46:31, 14.33s/it]
{'loss': 0.596, 'learning_rate': 1.1855634079669087e-06, 'rewards/chosen': -1.130086898803711, 'rewards/rejected': -1.7168861627578735, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5867992043495178, 'policy_logps/rejected': -397.56829833984375, 'policy_logps/chosen': -370.1144714355469, 'referece_logps/rejected': -380.39947509765625, 'referece_logps/chosen': -358.8135986328125, 'logits/rejected': -0.8664841651916504, 'logits/chosen': -0.9432264566421509, 'epoch': 2.74}

 46%|████▌     | 7367/16104 [34:07:20<39:55:35, 16.45s/it]


 46%|████▌     | 7369/16104 [34:07:57<42:37:15, 17.57s/it]
{'loss': 0.5481, 'learning_rate': 1.1849704746614234e-06, 'rewards/chosen': -1.5026166439056396, 'rewards/rejected': -2.698683261871338, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1960667371749878, 'policy_logps/rejected': -641.123291015625, 'policy_logps/chosen': -406.8282165527344, 'referece_logps/rejected': -614.136474609375, 'referece_logps/chosen': -391.8020324707031, 'logits/rejected': -0.9976018667221069, 'logits/chosen': -0.8446125984191895, 'epoch': 2.75}

 46%|████▌     | 7370/16104 [34:08:18<45:16:27, 18.66s/it]


 46%|████▌     | 7372/16104 [34:08:59<47:33:00, 19.60s/it]
{'loss': 0.601, 'learning_rate': 1.1843774740144672e-06, 'rewards/chosen': -0.9674095511436462, 'rewards/rejected': -1.833442211151123, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8660327792167664, 'policy_logps/rejected': -477.1935119628906, 'policy_logps/chosen': -521.403564453125, 'referece_logps/rejected': -458.859130859375, 'referece_logps/chosen': -511.7294616699219, 'logits/rejected': 0.03667375445365906, 'logits/chosen': 0.0821211040019989, 'epoch': 2.75}

 46%|████▌     | 7373/16104 [34:09:14<43:42:06, 18.02s/it]


 46%|████▌     | 7375/16104 [34:09:39<37:07:44, 15.31s/it]
{'loss': 0.5549, 'learning_rate': 1.1837844062419327e-06, 'rewards/chosen': -0.8085368275642395, 'rewards/rejected': -1.385870337486267, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5773335695266724, 'policy_logps/rejected': -379.77886962890625, 'policy_logps/chosen': -382.8856506347656, 'referece_logps/rejected': -365.920166015625, 'referece_logps/chosen': -374.80029296875, 'logits/rejected': -0.8903641104698181, 'logits/chosen': -0.8827343583106995, 'epoch': 2.75}

 46%|████▌     | 7376/16104 [34:09:57<39:03:57, 16.11s/it]

 46%|████▌     | 7377/16104 [34:10:17<41:36:56, 17.17s/it]

 46%|████▌     | 7378/16104 [34:10:31<39:27:41, 16.28s/it]

 46%|████▌     | 7379/16104 [34:10:42<35:58:18, 14.84s/it]

 46%|████▌     | 7380/16104 [34:11:02<39:19:01, 16.22s/it]

 46%|████▌     | 7381/16104 [34:11:15<37:01:12, 15.28s/it]


 46%|████▌     | 7383/16104 [34:11:45<37:16:14, 15.39s/it]

 46%|████▌     | 7384/16104 [34:12:08<42:15:03, 17.44s/it]

 46%|████▌     | 7385/16104 [34:12:27<43:54:01, 18.13s/it]
{'loss': 0.4921, 'learning_rate': 1.1818070316434056e-06, 'rewards/chosen': -0.837015688419342, 'rewards/rejected': -1.3983746767044067, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5613588690757751, 'policy_logps/rejected': -420.893310546875, 'policy_logps/chosen': -524.926025390625, 'referece_logps/rejected': -406.9095764160156, 'referece_logps/chosen': -516.555908203125, 'logits/rejected': 0.38811132311820984, 'logits/chosen': 0.3891405165195465, 'epoch': 2.75}


 46%|████▌     | 7387/16104 [34:13:00<41:52:04, 17.29s/it]

 46%|████▌     | 7388/16104 [34:13:19<43:49:12, 18.10s/it]
{'loss': 0.5068, 'learning_rate': 1.1812136754887026e-06, 'rewards/chosen': -0.7104965448379517, 'rewards/rejected': -1.2193334102630615, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5088369846343994, 'policy_logps/rejected': -442.283935546875, 'policy_logps/chosen': -428.72967529296875, 'referece_logps/rejected': -430.0906066894531, 'referece_logps/chosen': -421.6247253417969, 'logits/rejected': -0.5537416934967041, 'logits/chosen': -0.34850287437438965, 'epoch': 2.75}

 46%|████▌     | 7389/16104 [34:13:31<39:07:24, 16.16s/it]


 46%|████▌     | 7391/16104 [34:14:02<38:56:54, 16.09s/it]
{'loss': 0.5435, 'learning_rate': 1.1806202533602527e-06, 'rewards/chosen': -0.531285285949707, 'rewards/rejected': -1.173769235610962, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6424839496612549, 'policy_logps/rejected': -327.94830322265625, 'policy_logps/chosen': -397.3948669433594, 'referece_logps/rejected': -316.2106018066406, 'referece_logps/chosen': -392.08203125, 'logits/rejected': -0.5159624814987183, 'logits/chosen': -0.5060192346572876, 'epoch': 2.75}

 46%|████▌     | 7392/16104 [34:14:22<42:12:04, 17.44s/it]

 46%|████▌     | 7393/16104 [34:14:43<44:50:37, 18.53s/it]

 46%|████▌     | 7394/16104 [34:14:56<40:44:01, 16.84s/it]


 46%|████▌     | 7396/16104 [34:15:32<41:33:40, 17.18s/it]
{'loss': 0.5908, 'learning_rate': 1.1796310704579746e-06, 'rewards/chosen': -0.859910786151886, 'rewards/rejected': -1.1949973106384277, 'rewards/accuracies': 0.875, 'rewards/margins': 0.335086464881897, 'policy_logps/rejected': -591.0888061523438, 'policy_logps/chosen': -532.87158203125, 'referece_logps/rejected': -579.1387939453125, 'referece_logps/chosen': -524.2725219726562, 'logits/rejected': -1.7079228162765503, 'logits/chosen': -1.8028547763824463, 'epoch': 2.76}

 46%|████▌     | 7397/16104 [34:15:48<40:57:30, 16.93s/it]

 46%|████▌     | 7398/16104 [34:16:03<39:02:54, 16.15s/it]


 46%|████▌     | 7400/16104 [34:16:32<37:24:06, 15.47s/it]
{'loss': 0.5321, 'learning_rate': 1.1788395932929874e-06, 'rewards/chosen': -0.6744422912597656, 'rewards/rejected': -0.9396254420280457, 'rewards/accuracies': 0.75, 'rewards/margins': 0.26518309116363525, 'policy_logps/rejected': -432.72137451171875, 'policy_logps/chosen': -323.06671142578125, 'referece_logps/rejected': -423.32513427734375, 'referece_logps/chosen': -316.3222961425781, 'logits/rejected': 0.14707690477371216, 'logits/chosen': 0.24339008331298828, 'epoch': 2.76}

 46%|████▌     | 7401/16104 [34:16:43<34:18:38, 14.19s/it]

 46%|████▌     | 7402/16104 [34:17:01<36:44:31, 15.20s/it]

 46%|████▌     | 7403/16104 [34:17:16<37:09:29, 15.37s/it]


 46%|████▌     | 7405/16104 [34:17:52<39:19:15, 16.27s/it]
{'loss': 0.5143, 'learning_rate': 1.1778500841232344e-06, 'rewards/chosen': -1.349708080291748, 'rewards/rejected': -1.982751727104187, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6330437660217285, 'policy_logps/rejected': -420.669677734375, 'policy_logps/chosen': -358.94696044921875, 'referece_logps/rejected': -400.8421325683594, 'referece_logps/chosen': -345.4498596191406, 'logits/rejected': -0.08370146155357361, 'logits/chosen': 0.027525559067726135, 'epoch': 2.76}

 46%|████▌     | 7406/16104 [34:18:05<37:34:57, 15.56s/it]

 46%|████▌     | 7407/16104 [34:18:19<36:02:46, 14.92s/it]

 46%|████▌     | 7408/16104 [34:18:41<41:07:34, 17.03s/it]

 46%|████▌     | 7409/16104 [34:18:59<41:39:20, 17.25s/it]


 46%|████▌     | 7411/16104 [34:19:30<39:15:01, 16.25s/it]

 46%|████▌     | 7412/16104 [34:19:46<39:03:09, 16.17s/it]
{'loss': 0.4953, 'learning_rate': 1.1764644693469555e-06, 'rewards/chosen': -1.0327268838882446, 'rewards/rejected': -1.5600022077560425, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5272752642631531, 'policy_logps/rejected': -419.98382568359375, 'policy_logps/chosen': -359.1716003417969, 'referece_logps/rejected': -404.3837585449219, 'referece_logps/chosen': -348.84429931640625, 'logits/rejected': -0.6373893022537231, 'logits/chosen': -0.6461848616600037, 'epoch': 2.76}

 46%|████▌     | 7413/16104 [34:19:58<35:44:24, 14.80s/it]

 46%|████▌     | 7414/16104 [34:20:17<39:10:13, 16.23s/it]

 46%|████▌     | 7415/16104 [34:20:35<40:31:41, 16.79s/it]


 46%|████▌     | 7417/16104 [34:21:10<40:17:54, 16.70s/it]
{'loss': 0.4274, 'learning_rate': 1.1754745301975382e-06, 'rewards/chosen': -0.8064085245132446, 'rewards/rejected': -1.583756923675537, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7773483991622925, 'policy_logps/rejected': -374.3049011230469, 'policy_logps/chosen': -386.3104553222656, 'referece_logps/rejected': -358.4673156738281, 'referece_logps/chosen': -378.2464294433594, 'logits/rejected': -0.1782294660806656, 'logits/chosen': -0.08851112425327301, 'epoch': 2.76}

 46%|████▌     | 7418/16104 [34:21:29<42:17:47, 17.53s/it]


 46%|████▌     | 7420/16104 [34:22:02<41:36:11, 17.25s/it]
{'loss': 0.5413, 'learning_rate': 1.1748804814647212e-06, 'rewards/chosen': -1.2226932048797607, 'rewards/rejected': -1.4835566282272339, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2608633041381836, 'policy_logps/rejected': -470.3048095703125, 'policy_logps/chosen': -382.62060546875, 'referece_logps/rejected': -455.46929931640625, 'referece_logps/chosen': -370.39361572265625, 'logits/rejected': -1.1664516925811768, 'logits/chosen': -1.0724204778671265, 'epoch': 2.76}

 46%|████▌     | 7421/16104 [34:22:15<38:24:55, 15.93s/it]

 46%|████▌     | 7422/16104 [34:22:29<37:30:03, 15.55s/it]

 46%|████▌     | 7423/16104 [34:22:43<36:10:23, 15.00s/it]

 46%|████▌     | 7424/16104 [34:23:00<37:28:01, 15.54s/it]

 46%|████▌     | 7425/16104 [34:23:21<41:09:37, 17.07s/it]

 46%|████▌     | 7426/16104 [34:23:33<37:39:44, 15.62s/it]

 46%|████▌     | 7427/16104 [34:23:53<40:56:57, 16.99s/it]

 46%|████▌     | 7428/16104 [34:24:11<41:55:59, 17.40s/it]

 46%|████▌     | 7429/16104 [34:24:32<44:06:20, 18.30s/it]


 46%|████▌     | 7431/16104 [34:25:14<47:15:57, 19.62s/it]

 46%|████▌     | 7432/16104 [34:25:34<47:35:05, 19.75s/it]
{'loss': 0.5663, 'learning_rate': 1.1725036520160675e-06, 'rewards/chosen': -1.2185152769088745, 'rewards/rejected': -1.5578702688217163, 'rewards/accuracies': 0.625, 'rewards/margins': 0.33935508131980896, 'policy_logps/rejected': -435.11767578125, 'policy_logps/chosen': -384.78094482421875, 'referece_logps/rejected': -419.5389709472656, 'referece_logps/chosen': -372.59576416015625, 'logits/rejected': -0.48884180188179016, 'logits/chosen': -0.38597822189331055, 'epoch': 2.77}

 46%|████▌     | 7433/16104 [34:25:51<45:27:55, 18.88s/it]

 46%|████▌     | 7434/16104 [34:26:12<46:49:07, 19.44s/it]


 46%|████▌     | 7436/16104 [34:26:47<43:20:13, 18.00s/it]

 46%|████▌     | 7437/16104 [34:27:06<44:35:03, 18.52s/it]
{'loss': 0.4522, 'learning_rate': 1.1715130090494297e-06, 'rewards/chosen': -0.8996272087097168, 'rewards/rejected': -1.463584542274475, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5639573931694031, 'policy_logps/rejected': -388.7361145019531, 'policy_logps/chosen': -350.2452392578125, 'referece_logps/rejected': -374.1002502441406, 'referece_logps/chosen': -341.24896240234375, 'logits/rejected': -0.7395718693733215, 'logits/chosen': -0.6711838245391846, 'epoch': 2.77}

 46%|████▌     | 7438/16104 [34:27:28<46:36:21, 19.36s/it]

 46%|████▌     | 7439/16104 [34:27:46<45:42:43, 18.99s/it]


 46%|████▌     | 7441/16104 [34:28:29<48:40:29, 20.23s/it]

 46%|████▌     | 7442/16104 [34:28:48<48:12:09, 20.03s/it]
{'loss': 0.4594, 'learning_rate': 1.1705221926326238e-06, 'rewards/chosen': -0.9241132140159607, 'rewards/rejected': -1.4452002048492432, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5210869312286377, 'policy_logps/rejected': -376.0021057128906, 'policy_logps/chosen': -268.64178466796875, 'referece_logps/rejected': -361.55010986328125, 'referece_logps/chosen': -259.400634765625, 'logits/rejected': 0.22615674138069153, 'logits/chosen': 0.33090490102767944, 'epoch': 2.77}

 46%|████▌     | 7443/16104 [34:29:08<48:08:23, 20.01s/it]

 46%|████▌     | 7444/16104 [34:29:29<49:01:52, 20.38s/it]


 46%|████▌     | 7446/16104 [34:30:08<47:52:38, 19.91s/it]
{'loss': 0.5098, 'learning_rate': 1.1697294152884015e-06, 'rewards/chosen': -0.44483262300491333, 'rewards/rejected': -1.2181700468063354, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7733374834060669, 'policy_logps/rejected': -263.7481994628906, 'policy_logps/chosen': -364.3943176269531, 'referece_logps/rejected': -251.56649780273438, 'referece_logps/chosen': -359.94598388671875, 'logits/rejected': -0.21899157762527466, 'logits/chosen': -0.2987883985042572, 'epoch': 2.77}


 46%|████▌     | 7448/16104 [34:30:41<43:25:41, 18.06s/it]

 46%|████▋     | 7449/16104 [34:30:53<38:54:28, 16.18s/it]
{'loss': 0.5382, 'learning_rate': 1.1691347601606684e-06, 'rewards/chosen': -0.9288647174835205, 'rewards/rejected': -1.436099886894226, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5072352290153503, 'policy_logps/rejected': -361.5465393066406, 'policy_logps/chosen': -525.534912109375, 'referece_logps/rejected': -347.1855163574219, 'referece_logps/chosen': -516.2462768554688, 'logits/rejected': -0.28110483288764954, 'logits/chosen': -0.30351704359054565, 'epoch': 2.78}


 46%|████▋     | 7451/16104 [34:31:23<36:39:02, 15.25s/it]
{'loss': 0.5224, 'learning_rate': 1.1687382891864686e-06, 'rewards/chosen': -0.4468170404434204, 'rewards/rejected': -1.1018849611282349, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6550679206848145, 'policy_logps/rejected': -349.4291687011719, 'policy_logps/chosen': -320.83477783203125, 'referece_logps/rejected': -338.41033935546875, 'referece_logps/chosen': -316.3665771484375, 'logits/rejected': -0.26066020131111145, 'logits/chosen': -0.22398023307323456, 'epoch': 2.78}

 46%|████▋     | 7452/16104 [34:31:36<35:22:19, 14.72s/it]

 46%|████▋     | 7453/16104 [34:31:58<40:27:37, 16.84s/it]


 46%|████▋     | 7455/16104 [34:32:27<36:34:27, 15.22s/it]
{'loss': 0.5125, 'learning_rate': 1.1679452653930466e-06, 'rewards/chosen': -0.8346298336982727, 'rewards/rejected': -1.11435067653656, 'rewards/accuracies': 0.625, 'rewards/margins': 0.27972090244293213, 'policy_logps/rejected': -388.61932373046875, 'policy_logps/chosen': -422.3038635253906, 'referece_logps/rejected': -377.475830078125, 'referece_logps/chosen': -413.95758056640625, 'logits/rejected': 0.02806156873703003, 'logits/chosen': 0.004638761281967163, 'epoch': 2.78}


 46%|████▋     | 7457/16104 [34:33:03<40:25:39, 16.83s/it]

 46%|████▋     | 7458/16104 [34:33:19<39:42:28, 16.53s/it]
{'loss': 0.5142, 'learning_rate': 1.1673504261862123e-06, 'rewards/chosen': -1.4220423698425293, 'rewards/rejected': -2.0430636405944824, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6210211515426636, 'policy_logps/rejected': -448.8201904296875, 'policy_logps/chosen': -426.74322509765625, 'referece_logps/rejected': -428.38958740234375, 'referece_logps/chosen': -412.5227966308594, 'logits/rejected': -0.2836841940879822, 'logits/chosen': -0.36573147773742676, 'epoch': 2.78}


 46%|████▋     | 7460/16104 [34:33:53<40:35:57, 16.91s/it]
{'loss': 0.5031, 'learning_rate': 1.1669538328535047e-06, 'rewards/chosen': -0.5449320077896118, 'rewards/rejected': -1.5946533679962158, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0497212409973145, 'policy_logps/rejected': -493.0777282714844, 'policy_logps/chosen': -358.87774658203125, 'referece_logps/rejected': -477.1312255859375, 'referece_logps/chosen': -353.428466796875, 'logits/rejected': -0.9390909671783447, 'logits/chosen': -1.0033214092254639, 'epoch': 2.78}

 46%|████▋     | 7461/16104 [34:34:05<36:40:48, 15.28s/it]

 46%|████▋     | 7462/16104 [34:34:18<35:23:00, 14.74s/it]


 46%|████▋     | 7464/16104 [34:34:47<34:13:03, 14.26s/it]

 46%|████▋     | 7465/16104 [34:35:03<35:28:19, 14.78s/it]
{'loss': 0.6143, 'learning_rate': 1.1659622314744647e-06, 'rewards/chosen': -0.8817731142044067, 'rewards/rejected': -1.4344953298568726, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5527222752571106, 'policy_logps/rejected': -342.2825622558594, 'policy_logps/chosen': -406.4227294921875, 'referece_logps/rejected': -327.9375915527344, 'referece_logps/chosen': -397.6049499511719, 'logits/rejected': -0.6326364874839783, 'logits/chosen': -0.84316086769104, 'epoch': 2.78}


 46%|████▋     | 7467/16104 [34:35:33<36:42:42, 15.30s/it]
{'loss': 0.4919, 'learning_rate': 1.1655655438724109e-06, 'rewards/chosen': -0.6638662815093994, 'rewards/rejected': -1.7348703145980835, 'rewards/accuracies': 0.875, 'rewards/margins': 1.071004033088684, 'policy_logps/rejected': -404.64697265625, 'policy_logps/chosen': -360.3590087890625, 'referece_logps/rejected': -387.29827880859375, 'referece_logps/chosen': -353.7203369140625, 'logits/rejected': -1.2442477941513062, 'logits/chosen': -1.1912994384765625, 'epoch': 2.78}

 46%|████▋     | 7468/16104 [34:35:50<37:48:06, 15.76s/it]

 46%|████▋     | 7469/16104 [34:36:00<34:06:29, 14.22s/it]

 46%|████▋     | 7470/16104 [34:36:20<37:41:49, 15.72s/it]

 46%|████▋     | 7471/16104 [34:36:30<34:13:37, 14.27s/it]

 46%|████▋     | 7472/16104 [34:36:50<38:05:57, 15.89s/it]


 46%|████▋     | 7474/16104 [34:37:13<32:48:11, 13.68s/it]

 46%|████▋     | 7475/16104 [34:37:25<31:32:46, 13.16s/it]
{'loss': 0.4671, 'learning_rate': 1.1639785262092646e-06, 'rewards/chosen': -0.9188026189804077, 'rewards/rejected': -1.895738124847412, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9769355654716492, 'policy_logps/rejected': -351.1927185058594, 'policy_logps/chosen': -361.885498046875, 'referece_logps/rejected': -332.2353210449219, 'referece_logps/chosen': -352.6974792480469, 'logits/rejected': -0.2155044823884964, 'logits/chosen': -0.30898359417915344, 'epoch': 2.79}

 46%|████▋     | 7476/16104 [34:37:44<35:24:52, 14.78s/it]

 46%|████▋     | 7477/16104 [34:38:02<38:08:27, 15.92s/it]

 46%|████▋     | 7478/16104 [34:38:18<38:08:57, 15.92s/it]


 46%|████▋     | 7480/16104 [34:38:51<39:24:16, 16.45s/it]
{'loss': 0.5109, 'learning_rate': 1.1629864243292146e-06, 'rewards/chosen': -1.0073654651641846, 'rewards/rejected': -2.539504289627075, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5321389436721802, 'policy_logps/rejected': -519.2159423828125, 'policy_logps/chosen': -402.4129333496094, 'referece_logps/rejected': -493.8209228515625, 'referece_logps/chosen': -392.33929443359375, 'logits/rejected': 0.7390188574790955, 'logits/chosen': 0.8518900871276855, 'epoch': 2.79}

 46%|████▋     | 7481/16104 [34:39:06<38:20:52, 16.01s/it]

 46%|████▋     | 7482/16104 [34:39:22<38:19:31, 16.00s/it]

 46%|████▋     | 7483/16104 [34:39:42<40:56:41, 17.10s/it]

 46%|████▋     | 7484/16104 [34:40:03<43:49:41, 18.30s/it]

 46%|████▋     | 7485/16104 [34:40:23<45:05:36, 18.83s/it]

 46%|████▋     | 7486/16104 [34:40:43<45:45:57, 19.12s/it]

 46%|████▋     | 7487/16104 [34:41:04<47:08:04, 19.69s/it]

 46%|████▋     | 7488/16104 [34:41:20<44:47:55, 18.72s/it]

 47%|████▋     | 7489/16104 [34:41:31<38:58:37, 16.29s/it]

 47%|████▋     | 7490/16104 [34:41:49<40:06:04, 16.76s/it]

 47%|████▋     | 7491/16104 [34:42:08<42:06:19, 17.60s/it]

 47%|████▋     | 7492/16104 [34:42:27<43:00:09, 17.98s/it]

 47%|████▋     | 7493/16104 [34:42:41<39:41:28, 16.59s/it]

 47%|████▋     | 7494/16104 [34:42:53<36:50:02, 15.40s/it]

 47%|████▋     | 7495/16104 [34:43:10<37:39:44, 15.75s/it]

 47%|████▋     | 7496/16104 [34:43:31<41:29:31, 17.35s/it]

 47%|████▋     | 7497/16104 [34:43:43<37:55:38, 15.86s/it]

 47%|████▋     | 7498/16104 [34:44:03<41:00:52, 17.16s/it]

 47%|████▋     | 7499/16104 [34:44:22<42:12:11, 17.66s/it]

 47%|████▋     | 7500/16104 [34:44:39<41:38:55, 17.43s/it]

 47%|████▋     | 7501/16104 [34:45:14<53:57:16, 22.58s/it]

 47%|████▋     | 7502/16104 [34:45:36<53:39:28, 22.46s/it]

 47%|████▋     | 7503/16104 [34:45:56<52:05:20, 21.80s/it]

 47%|████▋     | 7504/16104 [34:46:12<48:01:20, 20.10s/it]

 47%|████▋     | 7505/16104 [34:46:29<45:23:06, 19.00s/it]

 47%|████▋     | 7506/16104 [34:46:49<45:56:37, 19.24s/it]

 47%|████▋     | 7507/16104 [34:47:01<41:17:29, 17.29s/it]

 47%|████▋     | 7508/16104 [34:47:22<43:36:09, 18.26s/it]

 47%|████▋     | 7509/16104 [34:47:44<46:11:56, 19.35s/it]

 47%|████▋     | 7510/16104 [34:48:03<46:14:16, 19.37s/it]

 47%|████▋     | 7511/16104 [34:48:25<48:16:23, 20.22s/it]

 47%|████▋     | 7512/16104 [34:48:39<43:24:53, 18.19s/it]

 47%|████▋     | 7513/16104 [34:48:58<44:23:29, 18.60s/it]

 47%|████▋     | 7514/16104 [34:49:17<44:06:13, 18.48s/it]

 47%|████▋     | 7515/16104 [34:49:36<44:56:41, 18.84s/it]

 47%|████▋     | 7516/16104 [34:49:47<39:28:01, 16.54s/it]

 47%|████▋     | 7517/16104 [34:50:04<39:09:39, 16.42s/it]

 47%|████▋     | 7518/16104 [34:50:23<41:26:52, 17.38s/it]

 47%|████▋     | 7519/16104 [34:50:43<42:56:28, 18.01s/it]

 47%|████▋     | 7520/16104 [34:50:55<39:13:10, 16.45s/it]

 47%|████▋     | 7521/16104 [34:51:15<41:29:06, 17.40s/it]

 47%|████▋     | 7522/16104 [34:51:28<38:29:43, 16.15s/it]

 47%|████▋     | 7523/16104 [34:51:49<41:25:29, 17.38s/it]


 47%|████▋     | 7525/16104 [34:52:19<39:25:44, 16.55s/it]

 47%|████▋     | 7526/16104 [34:52:33<37:45:02, 15.84s/it]

 47%|████▋     | 7527/16104 [34:52:48<36:53:01, 15.48s/it]

 47%|████▋     | 7528/16104 [34:53:04<37:24:33, 15.70s/it]

 47%|████▋     | 7529/16104 [34:53:25<40:58:29, 17.20s/it]

 47%|████▋     | 7530/16104 [34:53:41<40:14:54, 16.90s/it]

 47%|████▋     | 7531/16104 [34:53:57<39:55:58, 16.77s/it]

 47%|████▋     | 7532/16104 [34:54:15<40:27:15, 16.99s/it]

 47%|████▋     | 7533/16104 [34:54:28<37:54:43, 15.92s/it]

 47%|████▋     | 7534/16104 [34:54:40<35:01:31, 14.71s/it]

 47%|████▋     | 7535/16104 [34:55:00<38:34:31, 16.21s/it]

 47%|████▋     | 7536/16104 [34:55:12<35:46:45, 15.03s/it]

 47%|████▋     | 7537/16104 [34:55:33<40:18:16, 16.94s/it]

 47%|████▋     | 7538/16104 [34:55:53<42:04:09, 17.68s/it]

 47%|████▋     | 7539/16104 [34:56:12<43:07:54, 18.13s/it]

 47%|████▋     | 7540/16104 [34:56:29<42:21:12, 17.80s/it]

 47%|████▋     | 7541/16104 [34:56:49<43:41:53, 18.37s/it]

 47%|████▋     | 7542/16104 [34:57:09<44:58:11, 18.91s/it]

 47%|████▋     | 7543/16104 [34:57:21<40:10:32, 16.89s/it]

 47%|████▋     | 7544/16104 [34:57:38<39:51:03, 16.76s/it]

 47%|████▋     | 7545/16104 [34:57:49<35:41:53, 15.02s/it]

 47%|████▋     | 7546/16104 [34:58:02<34:18:14, 14.43s/it]

 47%|████▋     | 7547/16104 [34:58:20<37:00:02, 15.57s/it]

 47%|████▋     | 7548/16104 [34:58:32<34:20:06, 14.45s/it]

 47%|████▋     | 7549/16104 [34:58:50<36:45:15, 15.47s/it]

 47%|████▋     | 7550/16104 [34:59:09<39:50:32, 16.77s/it]

 47%|████▋     | 7551/16104 [34:59:28<41:00:25, 17.26s/it]

 47%|████▋     | 7552/16104 [34:59:48<42:58:03, 18.09s/it]

 47%|████▋     | 7553/16104 [35:00:00<38:51:14, 16.36s/it]

 47%|████▋     | 7554/16104 [35:00:16<38:15:42, 16.11s/it]

 47%|████▋     | 7555/16104 [35:00:37<41:51:10, 17.62s/it]

 47%|████▋     | 7556/16104 [35:00:48<37:05:22, 15.62s/it]

 47%|████▋     | 7557/16104 [35:00:59<34:15:36, 14.43s/it]

 47%|████▋     | 7558/16104 [35:01:16<35:58:55, 15.16s/it]

 47%|████▋     | 7559/16104 [35:01:32<36:33:56, 15.41s/it]

 47%|████▋     | 7560/16104 [35:01:47<36:02:10, 15.18s/it]

 47%|████▋     | 7561/16104 [35:01:59<33:32:56, 14.14s/it]

 47%|████▋     | 7562/16104 [35:02:14<34:42:23, 14.63s/it]

 47%|████▋     | 7563/16104 [35:02:26<32:15:41, 13.60s/it]

 47%|████▋     | 7564/16104 [35:02:39<32:25:56, 13.67s/it]

 47%|████▋     | 7565/16104 [35:02:59<36:45:21, 15.50s/it]

 47%|████▋     | 7566/16104 [35:03:11<33:58:03, 14.32s/it]

 47%|████▋     | 7567/16104 [35:03:31<38:23:54, 16.19s/it]

 47%|████▋     | 7568/16104 [35:03:45<36:58:47, 15.60s/it]

 47%|████▋     | 7569/16104 [35:04:00<36:27:19, 15.38s/it]

 47%|████▋     | 7570/16104 [35:04:11<33:12:37, 14.01s/it]

 47%|████▋     | 7571/16104 [35:04:31<37:26:43, 15.80s/it]

 47%|████▋     | 7572/16104 [35:04:48<38:04:56, 16.07s/it]

 47%|████▋     | 7573/16104 [35:05:04<38:24:41, 16.21s/it]

 47%|████▋     | 7574/16104 [35:05:24<40:46:18, 17.21s/it]

 47%|████▋     | 7575/16104 [35:05:36<37:23:42, 15.78s/it]

 47%|████▋     | 7576/16104 [35:05:55<39:19:59, 16.60s/it]

 47%|████▋     | 7577/16104 [35:06:11<38:51:34, 16.41s/it]

 47%|████▋     | 7578/16104 [35:06:26<38:08:16, 16.10s/it]

 47%|████▋     | 7579/16104 [35:06:42<38:11:24, 16.13s/it]

 47%|████▋     | 7580/16104 [35:06:53<34:23:50, 14.53s/it]

 47%|████▋     | 7581/16104 [35:07:08<34:55:32, 14.75s/it]

 47%|████▋     | 7582/16104 [35:07:26<36:43:38, 15.51s/it]

 47%|████▋     | 7583/16104 [35:07:43<38:07:04, 16.10s/it]
{'loss': 0.5454, 'learning_rate': 1.1425139145081064e-06, 'rewards/chosen': -1.019616723060608, 'rewards/rejected': -1.0433727502822876, 'rewards/accuracies': 0.5, 'rewards/margins': 0.023756101727485657, 'policy_logps/rejected': -375.51336669921875, 'policy_logps/chosen': -364.42431640625, 'referece_logps/rejected': -365.07965087890625, 'referece_logps/chosen': -354.2281799316406, 'logits/rejected': 0.1900731325149536, 'logits/chosen': 0.09657720476388931, 'epoch': 2.83}


 47%|████▋     | 7585/16104 [35:08:13<36:32:36, 15.44s/it]

 47%|████▋     | 7586/16104 [35:08:24<33:27:55, 14.14s/it]

 47%|████▋     | 7587/16104 [35:08:42<36:23:01, 15.38s/it]

 47%|████▋     | 7588/16104 [35:08:55<34:22:01, 14.53s/it]

 47%|████▋     | 7589/16104 [35:09:05<31:41:43, 13.40s/it]

 47%|████▋     | 7590/16104 [35:09:16<30:04:09, 12.71s/it]
{'loss': 0.5904, 'learning_rate': 1.1411202602515554e-06, 'rewards/chosen': -1.1853054761886597, 'rewards/rejected': -1.699428677558899, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5141233205795288, 'policy_logps/rejected': -467.63446044921875, 'policy_logps/chosen': -489.332275390625, 'referece_logps/rejected': -450.64013671875, 'referece_logps/chosen': -477.47918701171875, 'logits/rejected': -0.19054554402828217, 'logits/chosen': -0.1827910840511322, 'epoch': 2.83}


 47%|████▋     | 7592/16104 [35:09:53<37:15:46, 15.76s/it]

 47%|████▋     | 7593/16104 [35:10:13<39:55:34, 16.89s/it]
{'loss': 0.4699, 'learning_rate': 1.1405228940663157e-06, 'rewards/chosen': -1.2664358615875244, 'rewards/rejected': -1.9383747577667236, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6719388365745544, 'policy_logps/rejected': -490.7746887207031, 'policy_logps/chosen': -379.3182678222656, 'referece_logps/rejected': -471.3908996582031, 'referece_logps/chosen': -366.6539306640625, 'logits/rejected': 0.24027788639068604, 'logits/chosen': 0.23589012026786804, 'epoch': 2.83}


 47%|████▋     | 7595/16104 [35:10:36<33:46:53, 14.29s/it]

 47%|████▋     | 7596/16104 [35:10:57<38:02:00, 16.09s/it]
{'loss': 0.5911, 'learning_rate': 1.1399254767214611e-06, 'rewards/chosen': -0.9014454483985901, 'rewards/rejected': -1.2150993347167969, 'rewards/accuracies': 0.625, 'rewards/margins': 0.31365376710891724, 'policy_logps/rejected': -398.0123291015625, 'policy_logps/chosen': -483.2430114746094, 'referece_logps/rejected': -385.8613586425781, 'referece_logps/chosen': -474.2284851074219, 'logits/rejected': -0.4878208041191101, 'logits/chosen': -0.6401834487915039, 'epoch': 2.83}


 47%|████▋     | 7598/16104 [35:11:35<41:30:14, 17.57s/it]

 47%|████▋     | 7599/16104 [35:11:49<38:34:35, 16.33s/it]
{'loss': 0.5212, 'learning_rate': 1.1393280084344906e-06, 'rewards/chosen': -0.08917903155088425, 'rewards/rejected': -1.8610683679580688, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7718894481658936, 'policy_logps/rejected': -278.070556640625, 'policy_logps/chosen': -312.4809875488281, 'referece_logps/rejected': -259.45989990234375, 'referece_logps/chosen': -311.5892333984375, 'logits/rejected': -0.6553975939750671, 'logits/chosen': -0.6674344539642334, 'epoch': 2.83}


 47%|████▋     | 7601/16104 [35:12:23<38:28:13, 16.29s/it]

 47%|████▋     | 7602/16104 [35:12:37<37:25:48, 15.85s/it]
{'loss': 0.5457, 'learning_rate': 1.1387304894229229e-06, 'rewards/chosen': -0.7697683572769165, 'rewards/rejected': -1.1065518856048584, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3367835283279419, 'policy_logps/rejected': -375.5530700683594, 'policy_logps/chosen': -434.6028137207031, 'referece_logps/rejected': -364.4875793457031, 'referece_logps/chosen': -426.90509033203125, 'logits/rejected': -0.062260083854198456, 'logits/chosen': -0.02364163100719452, 'epoch': 2.83}


 47%|████▋     | 7604/16104 [35:13:15<41:09:54, 17.43s/it]

 47%|████▋     | 7605/16104 [35:13:35<42:59:53, 18.21s/it]

 47%|████▋     | 7606/16104 [35:13:52<42:43:52, 18.10s/it]
{'loss': 0.421, 'learning_rate': 1.1379337188785602e-06, 'rewards/chosen': -0.5052868127822876, 'rewards/rejected': -1.4306604862213135, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9253737926483154, 'policy_logps/rejected': -442.9259948730469, 'policy_logps/chosen': -494.5535583496094, 'referece_logps/rejected': -428.619384765625, 'referece_logps/chosen': -489.500732421875, 'logits/rejected': -0.24231359362602234, 'logits/chosen': -0.26537230610847473, 'epoch': 2.83}


 47%|████▋     | 7608/16104 [35:14:29<43:16:49, 18.34s/it]

 47%|████▋     | 7609/16104 [35:14:47<42:56:17, 18.20s/it]

 47%|████▋     | 7610/16104 [35:15:07<43:59:28, 18.64s/it]

 47%|████▋     | 7611/16104 [35:15:27<45:23:15, 19.24s/it]

 47%|████▋     | 7612/16104 [35:15:41<41:01:32, 17.39s/it]

 47%|████▋     | 7613/16104 [35:15:55<39:00:36, 16.54s/it]
{'loss': 0.546, 'learning_rate': 1.1365391559190853e-06, 'rewards/chosen': -0.8835680484771729, 'rewards/rejected': -2.1255042552948, 'rewards/accuracies': 0.75, 'rewards/margins': 1.241936206817627, 'policy_logps/rejected': -376.68670654296875, 'policy_logps/chosen': -378.9678649902344, 'referece_logps/rejected': -355.431640625, 'referece_logps/chosen': -370.1322021484375, 'logits/rejected': -0.8653074502944946, 'logits/chosen': -1.0209826231002808, 'epoch': 2.84}


 47%|████▋     | 7615/16104 [35:16:23<35:28:58, 15.05s/it]

 47%|████▋     | 7616/16104 [35:16:43<38:47:39, 16.45s/it]
{'loss': 0.5704, 'learning_rate': 1.1359414030693385e-06, 'rewards/chosen': -0.7956180572509766, 'rewards/rejected': -1.74836003780365, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9527419805526733, 'policy_logps/rejected': -390.54681396484375, 'policy_logps/chosen': -419.0557861328125, 'referece_logps/rejected': -373.063232421875, 'referece_logps/chosen': -411.0995788574219, 'logits/rejected': -0.2519986629486084, 'logits/chosen': -0.2784927487373352, 'epoch': 2.84}

 47%|████▋     | 7617/16104 [35:16:56<36:16:55, 15.39s/it]


 47%|████▋     | 7619/16104 [35:17:24<34:21:19, 14.58s/it]
{'loss': 0.5476, 'learning_rate': 1.1353436007279417e-06, 'rewards/chosen': -1.0710562467575073, 'rewards/rejected': -1.5168312788009644, 'rewards/accuracies': 0.625, 'rewards/margins': 0.44577497243881226, 'policy_logps/rejected': -419.639404296875, 'policy_logps/chosen': -372.7948303222656, 'referece_logps/rejected': -404.4710998535156, 'referece_logps/chosen': -362.08428955078125, 'logits/rejected': -0.576953113079071, 'logits/chosen': -0.5721623301506042, 'epoch': 2.84}

 47%|████▋     | 7620/16104 [35:17:44<38:30:40, 16.34s/it]


 47%|████▋     | 7622/16104 [35:18:20<39:20:49, 16.70s/it]
{'loss': 0.5745, 'learning_rate': 1.134745749112535e-06, 'rewards/chosen': -0.906757652759552, 'rewards/rejected': -1.4387532472610474, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5319955945014954, 'policy_logps/rejected': -423.9162902832031, 'policy_logps/chosen': -359.7815856933594, 'referece_logps/rejected': -409.5287780761719, 'referece_logps/chosen': -350.7139892578125, 'logits/rejected': -0.6218553781509399, 'logits/chosen': -0.621707022190094, 'epoch': 2.84}


 47%|████▋     | 7624/16104 [35:18:41<32:23:01, 13.75s/it]
{'loss': 0.5999, 'learning_rate': 1.1343471541019646e-06, 'rewards/chosen': -0.7487418055534363, 'rewards/rejected': -1.0312930345535278, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2825513780117035, 'policy_logps/rejected': -569.8473510742188, 'policy_logps/chosen': -449.0403137207031, 'referece_logps/rejected': -559.5343627929688, 'referece_logps/chosen': -441.55291748046875, 'logits/rejected': -0.6066182851791382, 'logits/chosen': -0.3843629062175751, 'epoch': 2.84}


 47%|████▋     | 7626/16104 [35:19:03<28:37:34, 12.16s/it]

 47%|████▋     | 7627/16104 [35:19:16<29:04:20, 12.35s/it]

 47%|████▋     | 7628/16104 [35:19:31<30:58:37, 13.16s/it]
{'loss': 0.5358, 'learning_rate': 1.1335498989303384e-06, 'rewards/chosen': -1.115342378616333, 'rewards/rejected': -1.3448712825775146, 'rewards/accuracies': 0.75, 'rewards/margins': 0.22952884435653687, 'policy_logps/rejected': -259.8779602050781, 'policy_logps/chosen': -411.1339111328125, 'referece_logps/rejected': -246.42926025390625, 'referece_logps/chosen': -399.98046875, 'logits/rejected': -1.3700510263442993, 'logits/chosen': -1.363450288772583, 'epoch': 2.84}


 47%|████▋     | 7630/16104 [35:20:11<39:40:32, 16.86s/it]

 47%|████▋     | 7631/16104 [35:20:23<35:52:28, 15.24s/it]
{'loss': 0.5254, 'learning_rate': 1.132951900798917e-06, 'rewards/chosen': -0.7945327162742615, 'rewards/rejected': -1.4413527250289917, 'rewards/accuracies': 0.875, 'rewards/margins': 0.646820068359375, 'policy_logps/rejected': -426.1717529296875, 'policy_logps/chosen': -340.40045166015625, 'referece_logps/rejected': -411.75830078125, 'referece_logps/chosen': -332.455078125, 'logits/rejected': 0.055726200342178345, 'logits/chosen': 0.22103971242904663, 'epoch': 2.84}


 47%|████▋     | 7633/16104 [35:20:58<39:01:16, 16.58s/it]

 47%|████▋     | 7634/16104 [35:21:18<41:36:06, 17.68s/it]

 47%|████▋     | 7635/16104 [35:21:38<42:54:35, 18.24s/it]

 47%|████▋     | 7636/16104 [35:21:51<39:38:09, 16.85s/it]

 47%|████▋     | 7637/16104 [35:22:07<38:42:00, 16.45s/it]

 47%|████▋     | 7638/16104 [35:22:24<39:18:04, 16.71s/it]
{'loss': 0.5563, 'learning_rate': 1.131556383966972e-06, 'rewards/chosen': -1.9001398086547852, 'rewards/rejected': -1.4845597743988037, 'rewards/accuracies': 0.25, 'rewards/margins': -0.415580153465271, 'policy_logps/rejected': -412.3500671386719, 'policy_logps/chosen': -426.9482727050781, 'referece_logps/rejected': -397.5044860839844, 'referece_logps/chosen': -407.94683837890625, 'logits/rejected': -0.14671480655670166, 'logits/chosen': -0.10766876488924026, 'epoch': 2.85}


 47%|████▋     | 7640/16104 [35:23:00<40:29:22, 17.22s/it]

 47%|████▋     | 7641/16104 [35:23:18<41:11:21, 17.52s/it]

 47%|████▋     | 7642/16104 [35:23:37<42:26:54, 18.06s/it]
{'loss': 0.5186, 'learning_rate': 1.130758828522678e-06, 'rewards/chosen': -1.2450125217437744, 'rewards/rejected': -1.6986868381500244, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4536742866039276, 'policy_logps/rejected': -463.9916687011719, 'policy_logps/chosen': -421.1842041015625, 'referece_logps/rejected': -447.00482177734375, 'referece_logps/chosen': -408.7341003417969, 'logits/rejected': 0.07671806216239929, 'logits/chosen': 0.022303342819213867, 'epoch': 2.85}

 47%|████▋     | 7643/16104 [35:23:56<43:14:31, 18.40s/it]


 47%|████▋     | 7645/16104 [35:24:21<36:02:38, 15.34s/it]

 47%|████▋     | 7646/16104 [35:24:32<33:04:49, 14.08s/it]

 47%|████▋     | 7647/16104 [35:24:43<31:01:17, 13.21s/it]

 47%|████▋     | 7648/16104 [35:24:58<32:02:06, 13.64s/it]
{'loss': 0.569, 'learning_rate': 1.1295623368347337e-06, 'rewards/chosen': -0.7124865055084229, 'rewards/rejected': -1.2131149768829346, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5006285309791565, 'policy_logps/rejected': -410.84381103515625, 'policy_logps/chosen': -499.11639404296875, 'referece_logps/rejected': -398.7126770019531, 'referece_logps/chosen': -491.99151611328125, 'logits/rejected': -0.7136478424072266, 'logits/chosen': -0.7746124267578125, 'epoch': 2.85}


 48%|████▊     | 7650/16104 [35:25:20<28:39:08, 12.20s/it]

 48%|████▊     | 7651/16104 [35:25:36<31:11:55, 13.29s/it]

 48%|████▊     | 7652/16104 [35:25:46<29:23:47, 12.52s/it]

 48%|████▊     | 7653/16104 [35:26:08<35:50:00, 15.26s/it]

 48%|████▊     | 7654/16104 [35:26:22<34:47:37, 14.82s/it]

 48%|████▊     | 7655/16104 [35:26:38<35:28:59, 15.12s/it]
{'loss': 0.6039, 'learning_rate': 1.1281661915210929e-06, 'rewards/chosen': -1.0671216249465942, 'rewards/rejected': -1.43024480342865, 'rewards/accuracies': 0.625, 'rewards/margins': 0.36312317848205566, 'policy_logps/rejected': -406.29119873046875, 'policy_logps/chosen': -460.44586181640625, 'referece_logps/rejected': -391.9887390136719, 'referece_logps/chosen': -449.774658203125, 'logits/rejected': -0.24419012665748596, 'logits/chosen': -0.30458083748817444, 'epoch': 2.85}

 48%|████▊     | 7656/16104 [35:26:55<37:03:55, 15.79s/it]

 48%|████▊     | 7657/16104 [35:27:15<39:49:38, 16.97s/it]


 48%|████▊     | 7659/16104 [35:27:52<42:11:29, 17.99s/it]

 48%|████▊     | 7660/16104 [35:28:13<43:47:18, 18.67s/it]

 48%|████▊     | 7661/16104 [35:28:23<38:20:54, 16.35s/it]

 48%|████▊     | 7662/16104 [35:28:42<39:46:51, 16.96s/it]
{'loss': 0.5527, 'learning_rate': 1.1267697921644858e-06, 'rewards/chosen': -0.5940618515014648, 'rewards/rejected': -1.43886399269104, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8448021411895752, 'policy_logps/rejected': -303.6385192871094, 'policy_logps/chosen': -302.8546142578125, 'referece_logps/rejected': -289.2498779296875, 'referece_logps/chosen': -296.91400146484375, 'logits/rejected': -1.4114991426467896, 'logits/chosen': -1.5337207317352295, 'epoch': 2.85}


 48%|████▊     | 7664/16104 [35:29:14<40:08:45, 17.12s/it]

 48%|████▊     | 7665/16104 [35:29:32<40:32:47, 17.30s/it]
{'loss': 0.5217, 'learning_rate': 1.126171258215008e-06, 'rewards/chosen': -0.5126116275787354, 'rewards/rejected': -1.4023313522338867, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8897197842597961, 'policy_logps/rejected': -516.92333984375, 'policy_logps/chosen': -430.7221984863281, 'referece_logps/rejected': -502.9000244140625, 'referece_logps/chosen': -425.5960693359375, 'logits/rejected': -0.5503931641578674, 'logits/chosen': -0.4487559199333191, 'epoch': 2.86}

 48%|████▊     | 7666/16104 [35:29:51<41:38:14, 17.76s/it]


 48%|████▊     | 7668/16104 [35:30:29<43:09:56, 18.42s/it]

 48%|████▊     | 7669/16104 [35:30:40<38:01:17, 16.23s/it]
{'loss': 0.4747, 'learning_rate': 1.1253731415327686e-06, 'rewards/chosen': -0.490216463804245, 'rewards/rejected': -1.1442782878875732, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6540619134902954, 'policy_logps/rejected': -724.2537841796875, 'policy_logps/chosen': -644.8779296875, 'referece_logps/rejected': -712.8110961914062, 'referece_logps/chosen': -639.9756469726562, 'logits/rejected': -0.777935266494751, 'logits/chosen': -0.6733118295669556, 'epoch': 2.86}


 48%|████▊     | 7671/16104 [35:31:12<36:58:52, 15.79s/it]
{'loss': 0.5098, 'learning_rate': 1.1249740527299592e-06, 'rewards/chosen': -0.7117620706558228, 'rewards/rejected': -1.8481522798538208, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1363903284072876, 'policy_logps/rejected': -322.17181396484375, 'policy_logps/chosen': -332.5564270019531, 'referece_logps/rejected': -303.6902770996094, 'referece_logps/chosen': -325.4388122558594, 'logits/rejected': -0.7382394075393677, 'logits/chosen': -0.7161349058151245, 'epoch': 2.86}


 48%|████▊     | 7673/16104 [35:31:46<38:01:46, 16.24s/it]
{'loss': 0.5159, 'learning_rate': 1.1245749437054563e-06, 'rewards/chosen': -0.7871755957603455, 'rewards/rejected': -1.500308632850647, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7131330370903015, 'policy_logps/rejected': -426.8670959472656, 'policy_logps/chosen': -487.4931640625, 'referece_logps/rejected': -411.864013671875, 'referece_logps/chosen': -479.6213684082031, 'logits/rejected': 0.18311472237110138, 'logits/chosen': -0.05839857459068298, 'epoch': 2.86}


 48%|████▊     | 7675/16104 [35:32:19<37:48:31, 16.15s/it]
{'loss': 0.5399, 'learning_rate': 1.1241758145238387e-06, 'rewards/chosen': -1.2130130529403687, 'rewards/rejected': -1.9322835206985474, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7192703485488892, 'policy_logps/rejected': -366.98345947265625, 'policy_logps/chosen': -429.7182922363281, 'referece_logps/rejected': -347.6606140136719, 'referece_logps/chosen': -417.588134765625, 'logits/rejected': -0.982974112033844, 'logits/chosen': -0.9795640110969543, 'epoch': 2.86}


 48%|████▊     | 7677/16104 [35:32:50<36:50:13, 15.74s/it]
{'loss': 0.4749, 'learning_rate': 1.1237766652496878e-06, 'rewards/chosen': -0.3847244381904602, 'rewards/rejected': -1.6874068975448608, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3026825189590454, 'policy_logps/rejected': -425.82891845703125, 'policy_logps/chosen': -315.2085266113281, 'referece_logps/rejected': -408.9548645019531, 'referece_logps/chosen': -311.36126708984375, 'logits/rejected': 0.20310397446155548, 'logits/chosen': 0.13734205067157745, 'epoch': 2.86}

 48%|████▊     | 7678/16104 [35:33:09<39:44:44, 16.98s/it]


 48%|████▊     | 7680/16104 [35:33:42<38:15:19, 16.35s/it]
{'loss': 0.498, 'learning_rate': 1.1231779038062438e-06, 'rewards/chosen': -1.214155912399292, 'rewards/rejected': -1.2678380012512207, 'rewards/accuracies': 0.625, 'rewards/margins': 0.05368204414844513, 'policy_logps/rejected': -300.8848876953125, 'policy_logps/chosen': -278.90869140625, 'referece_logps/rejected': -288.20648193359375, 'referece_logps/chosen': -266.76715087890625, 'logits/rejected': -0.6298857927322388, 'logits/chosen': -0.5589836835861206, 'epoch': 2.86}

 48%|████▊     | 7681/16104 [35:34:01<40:03:30, 17.12s/it]


 48%|████▊     | 7683/16104 [35:34:34<39:09:18, 16.74s/it]

 48%|████▊     | 7684/16104 [35:34:52<40:04:47, 17.14s/it]

 48%|████▊     | 7685/16104 [35:35:08<39:25:24, 16.86s/it]
{'loss': 0.5066, 'learning_rate': 1.1221798685195082e-06, 'rewards/chosen': -0.9062576293945312, 'rewards/rejected': -2.1010379791259766, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1947803497314453, 'policy_logps/rejected': -284.7472839355469, 'policy_logps/chosen': -266.0425720214844, 'referece_logps/rejected': -263.7369079589844, 'referece_logps/chosen': -256.97998046875, 'logits/rejected': -0.916071891784668, 'logits/chosen': -1.0149668455123901, 'epoch': 2.86}

 48%|████▊     | 7686/16104 [35:35:23<38:27:12, 16.44s/it]


 48%|████▊     | 7688/16104 [35:35:52<35:05:54, 15.01s/it]

 48%|████▊     | 7689/16104 [35:36:04<33:19:25, 14.26s/it]

 48%|████▊     | 7690/16104 [35:36:24<36:56:14, 15.80s/it]

 48%|████▊     | 7691/16104 [35:36:41<37:38:09, 16.10s/it]

 48%|████▊     | 7692/16104 [35:37:00<39:57:47, 17.10s/it]

 48%|████▊     | 7693/16104 [35:37:13<36:49:10, 15.76s/it]

 48%|████▊     | 7694/16104 [35:37:25<34:21:08, 14.70s/it]

 48%|████▊     | 7695/16104 [35:37:43<36:44:03, 15.73s/it]

 48%|████▊     | 7696/16104 [35:38:03<39:28:16, 16.90s/it]
{'loss': 0.642, 'learning_rate': 1.119983757379369e-06, 'rewards/chosen': -0.8740664720535278, 'rewards/rejected': -1.0321733951568604, 'rewards/accuracies': 0.75, 'rewards/margins': 0.15810689330101013, 'policy_logps/rejected': -426.2895202636719, 'policy_logps/chosen': -501.74249267578125, 'referece_logps/rejected': -415.9677734375, 'referece_logps/chosen': -493.00189208984375, 'logits/rejected': 0.4463580250740051, 'logits/chosen': 0.5116163492202759, 'epoch': 2.87}

 48%|████▊     | 7697/16104 [35:38:19<39:16:48, 16.82s/it]


 48%|████▊     | 7699/16104 [35:38:57<41:34:55, 17.81s/it]
{'loss': 0.5118, 'learning_rate': 1.1193847156005268e-06, 'rewards/chosen': -0.7189497351646423, 'rewards/rejected': -1.77842378616333, 'rewards/accuracies': 0.875, 'rewards/margins': 1.059473991394043, 'policy_logps/rejected': -343.9342041015625, 'policy_logps/chosen': -560.028076171875, 'referece_logps/rejected': -326.1499938964844, 'referece_logps/chosen': -552.8385620117188, 'logits/rejected': -0.6364113688468933, 'logits/chosen': -0.7763638496398926, 'epoch': 2.87}

 48%|████▊     | 7700/16104 [35:39:11<39:24:04, 16.88s/it]


 48%|████▊     | 7702/16104 [35:39:51<42:49:37, 18.35s/it]
{'loss': 0.5044, 'learning_rate': 1.118785630357763e-06, 'rewards/chosen': -0.5895942449569702, 'rewards/rejected': -2.35375714302063, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7641628980636597, 'policy_logps/rejected': -318.36529541015625, 'policy_logps/chosen': -436.0584716796875, 'referece_logps/rejected': -294.8277282714844, 'referece_logps/chosen': -430.1625671386719, 'logits/rejected': -0.5029128193855286, 'logits/chosen': -0.3901956081390381, 'epoch': 2.87}


 48%|████▊     | 7704/16104 [35:40:27<42:28:54, 18.21s/it]
{'loss': 0.4515, 'learning_rate': 1.1183862161570034e-06, 'rewards/chosen': -0.7261024117469788, 'rewards/rejected': -1.5467609167099, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8206585049629211, 'policy_logps/rejected': -344.9818115234375, 'policy_logps/chosen': -272.7149963378906, 'referece_logps/rejected': -329.5141906738281, 'referece_logps/chosen': -265.4539794921875, 'logits/rejected': -0.5542997121810913, 'logits/chosen': -0.3951871693134308, 'epoch': 2.87}

 48%|████▊     | 7705/16104 [35:40:46<43:28:54, 18.64s/it]


 48%|████▊     | 7707/16104 [35:41:13<37:30:54, 16.08s/it]
{'loss': 0.5192, 'learning_rate': 1.1177870589590587e-06, 'rewards/chosen': -0.6419917345046997, 'rewards/rejected': -1.2365695238113403, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5945777297019958, 'policy_logps/rejected': -477.89788818359375, 'policy_logps/chosen': -471.5399169921875, 'referece_logps/rejected': -465.5321960449219, 'referece_logps/chosen': -465.1200256347656, 'logits/rejected': -0.8064778447151184, 'logits/chosen': -0.6515287160873413, 'epoch': 2.87}

 48%|████▊     | 7708/16104 [35:41:24<33:40:38, 14.44s/it]


 48%|████▊     | 7710/16104 [35:41:45<29:13:15, 12.53s/it]

 48%|████▊     | 7711/16104 [35:42:03<32:49:12, 14.08s/it]

 48%|████▊     | 7712/16104 [35:42:13<30:20:33, 13.02s/it]
{'loss': 0.5943, 'learning_rate': 1.116788368442946e-06, 'rewards/chosen': -0.5600738525390625, 'rewards/rejected': -1.0212467908859253, 'rewards/accuracies': 0.625, 'rewards/margins': 0.46117284893989563, 'policy_logps/rejected': -285.3778991699219, 'policy_logps/chosen': -360.02703857421875, 'referece_logps/rejected': -275.1654357910156, 'referece_logps/chosen': -354.42626953125, 'logits/rejected': -0.8370446562767029, 'logits/chosen': -0.960867166519165, 'epoch': 2.87}


 48%|████▊     | 7714/16104 [35:42:37<29:20:16, 12.59s/it]
{'loss': 0.5879, 'learning_rate': 1.1163888591098557e-06, 'rewards/chosen': -0.8350566625595093, 'rewards/rejected': -1.1917201280593872, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3566635251045227, 'policy_logps/rejected': -363.32086181640625, 'policy_logps/chosen': -370.4734802246094, 'referece_logps/rejected': -351.4036560058594, 'referece_logps/chosen': -362.1229248046875, 'logits/rejected': -0.5581365823745728, 'logits/chosen': -0.6106053590774536, 'epoch': 2.87}

 48%|████▊     | 7715/16104 [35:42:52<30:54:19, 13.26s/it]

 48%|████▊     | 7716/16104 [35:43:04<29:53:28, 12.83s/it]

 48%|████▊     | 7717/16104 [35:43:18<31:01:34, 13.32s/it]

 48%|████▊     | 7718/16104 [35:43:38<35:12:03, 15.11s/it]

 48%|████▊     | 7719/16104 [35:43:54<35:47:05, 15.36s/it]


 48%|████▊     | 7721/16104 [35:44:25<37:35:19, 16.14s/it]

 48%|████▊     | 7722/16104 [35:44:45<40:11:49, 17.26s/it]

 48%|████▊     | 7723/16104 [35:45:05<41:51:46, 17.98s/it]
{'loss': 0.5244, 'learning_rate': 1.11459083499153e-06, 'rewards/chosen': -0.5780515670776367, 'rewards/rejected': -0.7775018215179443, 'rewards/accuracies': 0.625, 'rewards/margins': 0.19945025444030762, 'policy_logps/rejected': -348.9190979003906, 'policy_logps/chosen': -434.52191162109375, 'referece_logps/rejected': -341.14404296875, 'referece_logps/chosen': -428.7414245605469, 'logits/rejected': -0.9290201663970947, 'logits/chosen': -1.0054441690444946, 'epoch': 2.88}


 48%|████▊     | 7725/16104 [35:45:38<40:34:51, 17.44s/it]
{'loss': 0.5495, 'learning_rate': 1.1141912228794698e-06, 'rewards/chosen': -0.8341710567474365, 'rewards/rejected': -1.8284530639648438, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9942818880081177, 'policy_logps/rejected': -375.7878723144531, 'policy_logps/chosen': -358.6916198730469, 'referece_logps/rejected': -357.5033264160156, 'referece_logps/chosen': -350.34991455078125, 'logits/rejected': -0.5543808937072754, 'logits/chosen': -0.514683187007904, 'epoch': 2.88}

 48%|████▊     | 7726/16104 [35:45:50<37:06:02, 15.94s/it]


 48%|████▊     | 7728/16104 [35:46:15<33:40:01, 14.47s/it]

 48%|████▊     | 7729/16104 [35:46:27<31:40:32, 13.62s/it]
{'loss': 0.5487, 'learning_rate': 1.113391943289149e-06, 'rewards/chosen': -0.725995659828186, 'rewards/rejected': -1.0105657577514648, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2845700681209564, 'policy_logps/rejected': -356.2579345703125, 'policy_logps/chosen': -344.7857971191406, 'referece_logps/rejected': -346.15228271484375, 'referece_logps/chosen': -337.52587890625, 'logits/rejected': -0.52872234582901, 'logits/chosen': -0.6253098249435425, 'epoch': 2.88}


 48%|████▊     | 7731/16104 [35:46:56<32:30:11, 13.97s/it]
{'loss': 0.6072, 'learning_rate': 1.112992275940217e-06, 'rewards/chosen': -1.0446715354919434, 'rewards/rejected': -1.4545974731445312, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4099259376525879, 'policy_logps/rejected': -345.15057373046875, 'policy_logps/chosen': -361.0661315917969, 'referece_logps/rejected': -330.6045837402344, 'referece_logps/chosen': -350.61944580078125, 'logits/rejected': -0.21327240765094757, 'logits/chosen': -0.40590548515319824, 'epoch': 2.88}

 48%|████▊     | 7732/16104 [35:47:06<30:08:20, 12.96s/it]

 48%|████▊     | 7733/16104 [35:47:23<32:46:34, 14.10s/it]


 48%|████▊     | 7735/16104 [35:47:48<30:25:13, 13.09s/it]
{'loss': 0.6148, 'learning_rate': 1.1121928864581554e-06, 'rewards/chosen': -1.2126320600509644, 'rewards/rejected': -1.0732979774475098, 'rewards/accuracies': 0.5, 'rewards/margins': -0.13933423161506653, 'policy_logps/rejected': -492.32794189453125, 'policy_logps/chosen': -350.77532958984375, 'referece_logps/rejected': -481.59490966796875, 'referece_logps/chosen': -338.64898681640625, 'logits/rejected': -1.4536036252975464, 'logits/chosen': -1.3398374319076538, 'epoch': 2.88}

 48%|████▊     | 7736/16104 [35:47:58<28:46:39, 12.38s/it]


 48%|████▊     | 7738/16104 [35:48:28<31:33:42, 13.58s/it]

 48%|████▊     | 7739/16104 [35:48:44<33:12:54, 14.29s/it]
{'loss': 0.4642, 'learning_rate': 1.111393424361658e-06, 'rewards/chosen': -0.4328586459159851, 'rewards/rejected': -1.9249204397201538, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4920616149902344, 'policy_logps/rejected': -582.2119140625, 'policy_logps/chosen': -467.49981689453125, 'referece_logps/rejected': -562.9627685546875, 'referece_logps/chosen': -463.17120361328125, 'logits/rejected': -0.6223618984222412, 'logits/chosen': -0.28528526425361633, 'epoch': 2.88}

 48%|████▊     | 7740/16104 [35:49:06<38:47:03, 16.69s/it]


 48%|████▊     | 7742/16104 [35:49:37<38:05:02, 16.40s/it]

 48%|████▊     | 7743/16104 [35:49:55<39:06:18, 16.84s/it]
{'loss': 0.488, 'learning_rate': 1.1105938901681592e-06, 'rewards/chosen': -2.2383172512054443, 'rewards/rejected': -2.6805810928344727, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4422634541988373, 'policy_logps/rejected': -473.70635986328125, 'policy_logps/chosen': -392.87158203125, 'referece_logps/rejected': -446.9005432128906, 'referece_logps/chosen': -370.4884338378906, 'logits/rejected': -0.7667645215988159, 'logits/chosen': -0.7750368118286133, 'epoch': 2.88}

 48%|████▊     | 7744/16104 [35:50:14<40:31:19, 17.45s/it]


 48%|████▊     | 7746/16104 [35:50:52<41:16:09, 17.78s/it]

 48%|████▊     | 7747/16104 [35:51:11<42:32:44, 18.33s/it]
{'loss': 0.5066, 'learning_rate': 1.109794284395141e-06, 'rewards/chosen': -0.8146772384643555, 'rewards/rejected': -1.3129067420959473, 'rewards/accuracies': 0.875, 'rewards/margins': 0.4982295036315918, 'policy_logps/rejected': -306.95782470703125, 'policy_logps/chosen': -363.8930358886719, 'referece_logps/rejected': -293.8287353515625, 'referece_logps/chosen': -355.74627685546875, 'logits/rejected': -1.49260675907135, 'logits/chosen': -1.580838680267334, 'epoch': 2.89}


 48%|████▊     | 7749/16104 [35:51:50<44:00:58, 18.97s/it]

 48%|████▊     | 7750/16104 [35:52:10<44:37:10, 19.23s/it]
{'loss': 0.5077, 'learning_rate': 1.1091945334026412e-06, 'rewards/chosen': -0.6091787219047546, 'rewards/rejected': -1.5637407302856445, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9545618295669556, 'policy_logps/rejected': -428.7986755371094, 'policy_logps/chosen': -386.36627197265625, 'referece_logps/rejected': -413.1612243652344, 'referece_logps/chosen': -380.27447509765625, 'logits/rejected': -0.4845656752586365, 'logits/chosen': -0.47223562002182007, 'epoch': 2.89}

 48%|████▊     | 7751/16104 [35:52:25<41:57:22, 18.08s/it]


 48%|████▊     | 7753/16104 [35:52:56<39:08:56, 16.88s/it]
{'loss': 0.5491, 'learning_rate': 1.1085947426561183e-06, 'rewards/chosen': -1.0445539951324463, 'rewards/rejected': -2.169374942779541, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1248208284378052, 'policy_logps/rejected': -454.4629211425781, 'policy_logps/chosen': -390.4400329589844, 'referece_logps/rejected': -432.7691650390625, 'referece_logps/chosen': -379.9945068359375, 'logits/rejected': -0.6310492753982544, 'logits/chosen': -0.48778197169303894, 'epoch': 2.89}

 48%|████▊     | 7754/16104 [35:53:15<40:56:50, 17.65s/it]

 48%|████▊     | 7755/16104 [35:53:33<40:52:48, 17.63s/it]


 48%|████▊     | 7757/16104 [35:54:04<38:08:24, 16.45s/it]

 48%|████▊     | 7758/16104 [35:54:24<40:25:44, 17.44s/it]

 48%|████▊     | 7759/16104 [35:54:42<40:55:41, 17.66s/it]
{'loss': 0.5451, 'learning_rate': 1.107395042774474e-06, 'rewards/chosen': -0.8708486557006836, 'rewards/rejected': -2.472705841064453, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6018571853637695, 'policy_logps/rejected': -335.16815185546875, 'policy_logps/chosen': -344.5747375488281, 'referece_logps/rejected': -310.44110107421875, 'referece_logps/chosen': -335.8662414550781, 'logits/rejected': -0.6539019346237183, 'logits/chosen': -0.5837171673774719, 'epoch': 2.89}

 48%|████▊     | 7760/16104 [35:54:55<37:42:05, 16.27s/it]


 48%|████▊     | 7762/16104 [35:55:32<40:05:05, 17.30s/it]
{'loss': 0.4785, 'learning_rate': 1.106795134076122e-06, 'rewards/chosen': -0.7644127011299133, 'rewards/rejected': -2.0126118659973145, 'rewards/accuracies': 0.875, 'rewards/margins': 1.248199224472046, 'policy_logps/rejected': -371.6451416015625, 'policy_logps/chosen': -345.2416687011719, 'referece_logps/rejected': -351.51904296875, 'referece_logps/chosen': -337.5975646972656, 'logits/rejected': -0.5463007092475891, 'logits/chosen': -0.5655438899993896, 'epoch': 2.89}


 48%|████▊     | 7764/16104 [35:56:10<42:43:33, 18.44s/it]
{'loss': 0.4283, 'learning_rate': 1.1063951733301367e-06, 'rewards/chosen': -0.7941356897354126, 'rewards/rejected': -2.5295464992523193, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7354106903076172, 'policy_logps/rejected': -420.16436767578125, 'policy_logps/chosen': -585.4465942382812, 'referece_logps/rejected': -394.8689270019531, 'referece_logps/chosen': -577.5052490234375, 'logits/rejected': 0.038207150995731354, 'logits/chosen': 0.04554273188114166, 'epoch': 2.89}

 48%|████▊     | 7765/16104 [35:56:25<40:32:39, 17.50s/it]

 48%|████▊     | 7766/16104 [35:56:45<42:07:48, 18.19s/it]

 48%|████▊     | 7767/16104 [35:57:05<43:05:34, 18.61s/it]


 48%|████▊     | 7769/16104 [35:57:44<44:15:51, 19.12s/it]
{'loss': 0.5194, 'learning_rate': 1.1053951962889428e-06, 'rewards/chosen': -1.8344591856002808, 'rewards/rejected': -2.9589102268218994, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1244511604309082, 'policy_logps/rejected': -505.80230712890625, 'policy_logps/chosen': -437.49847412109375, 'referece_logps/rejected': -476.2132568359375, 'referece_logps/chosen': -419.1539001464844, 'logits/rejected': -0.4557717442512512, 'logits/chosen': -0.5151444673538208, 'epoch': 2.89}

 48%|████▊     | 7770/16104 [35:58:05<45:26:07, 19.63s/it]

 48%|████▊     | 7771/16104 [35:58:22<43:59:31, 19.01s/it]


 48%|████▊     | 7773/16104 [35:58:54<40:28:06, 17.49s/it]

 48%|████▊     | 7774/16104 [35:59:10<39:41:57, 17.16s/it]
{'loss': 0.5029, 'learning_rate': 1.1043951126621634e-06, 'rewards/chosen': -1.048518419265747, 'rewards/rejected': -2.1696341037750244, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1211156845092773, 'policy_logps/rejected': -268.597900390625, 'policy_logps/chosen': -274.5951232910156, 'referece_logps/rejected': -246.90155029296875, 'referece_logps/chosen': -264.1099548339844, 'logits/rejected': -1.6206345558166504, 'logits/chosen': -1.552150845527649, 'epoch': 2.9}

 48%|████▊     | 7775/16104 [35:59:23<36:32:00, 15.79s/it]


 48%|████▊     | 7777/16104 [35:59:50<33:36:55, 14.53s/it]

 48%|████▊     | 7778/16104 [36:00:10<37:26:50, 16.19s/it]
{'loss': 0.4326, 'learning_rate': 1.1035949696987613e-06, 'rewards/chosen': -0.6665464639663696, 'rewards/rejected': -1.4898728132247925, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8233263492584229, 'policy_logps/rejected': -382.2691955566406, 'policy_logps/chosen': -343.0611877441406, 'referece_logps/rejected': -367.37042236328125, 'referece_logps/chosen': -336.3957214355469, 'logits/rejected': -0.8203922510147095, 'logits/chosen': -0.837985098361969, 'epoch': 2.9}


 48%|████▊     | 7780/16104 [36:00:44<38:59:30, 16.86s/it]
{'loss': 0.5064, 'learning_rate': 1.103194873041084e-06, 'rewards/chosen': -0.7082358002662659, 'rewards/rejected': -1.5144052505493164, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8061696290969849, 'policy_logps/rejected': -413.93988037109375, 'policy_logps/chosen': -346.396728515625, 'referece_logps/rejected': -398.7958068847656, 'referece_logps/chosen': -339.31439208984375, 'logits/rejected': -0.6477450728416443, 'logits/chosen': -0.5679614543914795, 'epoch': 2.9}

 48%|████▊     | 7781/16104 [36:01:03<40:24:08, 17.48s/it]


 48%|████▊     | 7783/16104 [36:01:36<39:12:48, 16.97s/it]
{'loss': 0.5174, 'learning_rate': 1.1025946967666746e-06, 'rewards/chosen': -0.9655538201332092, 'rewards/rejected': -1.9047871828079224, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9392332434654236, 'policy_logps/rejected': -477.0831604003906, 'policy_logps/chosen': -582.6651000976562, 'referece_logps/rejected': -458.0352783203125, 'referece_logps/chosen': -573.009521484375, 'logits/rejected': 0.1695607453584671, 'logits/chosen': 0.3781919479370117, 'epoch': 2.9}

 48%|████▊     | 7784/16104 [36:01:51<37:54:12, 16.40s/it]

 48%|████▊     | 7785/16104 [36:02:03<35:05:47, 15.19s/it]

 48%|████▊     | 7786/16104 [36:02:15<32:44:00, 14.17s/it]


 48%|████▊     | 7788/16104 [36:02:52<37:53:44, 16.41s/it]

 48%|████▊     | 7789/16104 [36:03:04<34:49:38, 15.08s/it]

 48%|████▊     | 7790/16104 [36:03:16<32:45:14, 14.18s/it]

 48%|████▊     | 7791/16104 [36:03:28<31:29:42, 13.64s/it]
{'loss': 0.5638, 'learning_rate': 1.100994044689001e-06, 'rewards/chosen': -1.142124891281128, 'rewards/rejected': -1.0704078674316406, 'rewards/accuracies': 0.5, 'rewards/margins': -0.07171712815761566, 'policy_logps/rejected': -363.0502014160156, 'policy_logps/chosen': -468.71722412109375, 'referece_logps/rejected': -352.3460998535156, 'referece_logps/chosen': -457.2959289550781, 'logits/rejected': -0.7632370591163635, 'logits/chosen': -1.0429940223693848, 'epoch': 2.9}


 48%|████▊     | 7793/16104 [36:04:01<34:33:21, 14.97s/it]
{'loss': 0.4798, 'learning_rate': 1.1005938406538103e-06, 'rewards/chosen': -0.7823484539985657, 'rewards/rejected': -2.0421879291534424, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2598395347595215, 'policy_logps/rejected': -298.4933776855469, 'policy_logps/chosen': -298.5554504394531, 'referece_logps/rejected': -278.071533203125, 'referece_logps/chosen': -290.73193359375, 'logits/rejected': -0.8156405687332153, 'logits/chosen': -0.6915221810340881, 'epoch': 2.9}


 48%|████▊     | 7795/16104 [36:04:30<34:49:40, 15.09s/it]
{'loss': 0.4922, 'learning_rate': 1.1001936203418178e-06, 'rewards/chosen': -1.3586801290512085, 'rewards/rejected': -2.4448070526123047, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0861269235610962, 'policy_logps/rejected': -313.2552795410156, 'policy_logps/chosen': -266.5147399902344, 'referece_logps/rejected': -288.80718994140625, 'referece_logps/chosen': -252.9279022216797, 'logits/rejected': -0.6069188714027405, 'logits/chosen': -0.5740272402763367, 'epoch': 2.9}

 48%|████▊     | 7796/16104 [36:04:43<33:08:19, 14.36s/it]


 48%|████▊     | 7798/16104 [36:05:16<36:15:54, 15.72s/it]

 48%|████▊     | 7799/16104 [36:05:32<36:30:20, 15.82s/it]
{'loss': 0.6078, 'learning_rate': 1.099393131146466e-06, 'rewards/chosen': -0.9658123850822449, 'rewards/rejected': -1.445767879486084, 'rewards/accuracies': 0.75, 'rewards/margins': 0.47995543479919434, 'policy_logps/rejected': -334.15557861328125, 'policy_logps/chosen': -294.72650146484375, 'referece_logps/rejected': -319.6979064941406, 'referece_logps/chosen': -285.068359375, 'logits/rejected': -0.6972113251686096, 'logits/chosen': -0.7040441632270813, 'epoch': 2.91}


 48%|████▊     | 7801/16104 [36:06:09<39:49:12, 17.27s/it]
{'loss': 0.4646, 'learning_rate': 1.0989928623926312e-06, 'rewards/chosen': -0.8112261891365051, 'rewards/rejected': -2.416696548461914, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6054702997207642, 'policy_logps/rejected': -306.6432800292969, 'policy_logps/chosen': -290.17303466796875, 'referece_logps/rejected': -282.476318359375, 'referece_logps/chosen': -282.060791015625, 'logits/rejected': -0.24436546862125397, 'logits/chosen': -0.2801266312599182, 'epoch': 2.91}

 48%|████▊     | 7802/16104 [36:06:20<35:22:01, 15.34s/it]


 48%|████▊     | 7804/16104 [36:06:55<37:37:35, 16.32s/it]
{'loss': 0.5037, 'learning_rate': 1.098392429248835e-06, 'rewards/chosen': -1.032973289489746, 'rewards/rejected': -2.398672103881836, 'rewards/accuracies': 1.0, 'rewards/margins': 1.365699291229248, 'policy_logps/rejected': -289.44140625, 'policy_logps/chosen': -243.95059204101562, 'referece_logps/rejected': -265.4546813964844, 'referece_logps/chosen': -233.62086486816406, 'logits/rejected': -0.5556507706642151, 'logits/chosen': -0.383394718170166, 'epoch': 2.91}

 48%|████▊     | 7805/16104 [36:07:08<35:22:19, 15.34s/it]

 48%|████▊     | 7806/16104 [36:07:28<38:25:05, 16.67s/it]


 48%|████▊     | 7808/16104 [36:08:07<42:14:59, 18.33s/it]

 48%|████▊     | 7809/16104 [36:08:19<37:47:50, 16.40s/it]
{'loss': 0.5771, 'learning_rate': 1.097391627847479e-06, 'rewards/chosen': -1.2010451555252075, 'rewards/rejected': -1.2047122716903687, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0036672577261924744, 'policy_logps/rejected': -472.70379638671875, 'policy_logps/chosen': -298.9334716796875, 'referece_logps/rejected': -460.6567077636719, 'referece_logps/chosen': -286.92303466796875, 'logits/rejected': -0.5230720043182373, 'logits/chosen': -0.4157412052154541, 'epoch': 2.91}

 48%|████▊     | 7810/16104 [36:08:29<33:46:29, 14.66s/it]

 49%|████▊     | 7811/16104 [36:08:42<32:22:04, 14.05s/it]


 49%|████▊     | 7813/16104 [36:09:19<37:58:00, 16.49s/it]
{'loss': 0.566, 'learning_rate': 1.0965909157638429e-06, 'rewards/chosen': -0.7926019430160522, 'rewards/rejected': -1.5725816488265991, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7799797058105469, 'policy_logps/rejected': -368.31622314453125, 'policy_logps/chosen': -309.8226623535156, 'referece_logps/rejected': -352.5904235839844, 'referece_logps/chosen': -301.8966369628906, 'logits/rejected': -0.31907254457473755, 'logits/chosen': -0.2908845841884613, 'epoch': 2.91}


 49%|████▊     | 7815/16104 [36:09:45<34:23:31, 14.94s/it]
{'loss': 0.583, 'learning_rate': 1.0961905362459845e-06, 'rewards/chosen': -1.2295619249343872, 'rewards/rejected': -1.5414841175079346, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3119221031665802, 'policy_logps/rejected': -234.63296508789062, 'policy_logps/chosen': -231.05531311035156, 'referece_logps/rejected': -219.2181396484375, 'referece_logps/chosen': -218.7596893310547, 'logits/rejected': -1.6583433151245117, 'logits/chosen': -1.3461697101593018, 'epoch': 2.91}

 49%|████▊     | 7816/16104 [36:10:00<34:16:45, 14.89s/it]

 49%|████▊     | 7817/16104 [36:10:18<36:12:03, 15.73s/it]


 49%|████▊     | 7819/16104 [36:10:47<35:22:00, 15.37s/it]
{'loss': 0.5486, 'learning_rate': 1.0953897305821094e-06, 'rewards/chosen': -0.9173555970191956, 'rewards/rejected': -0.9704029560089111, 'rewards/accuracies': 0.625, 'rewards/margins': 0.05304739624261856, 'policy_logps/rejected': -464.99212646484375, 'policy_logps/chosen': -421.46636962890625, 'referece_logps/rejected': -455.2881164550781, 'referece_logps/chosen': -412.2928161621094, 'logits/rejected': -0.5171275734901428, 'logits/chosen': -0.42798054218292236, 'epoch': 2.91}

 49%|████▊     | 7820/16104 [36:11:07<38:51:42, 16.89s/it]

 49%|████▊     | 7821/16104 [36:11:20<36:08:37, 15.71s/it]


 49%|████▊     | 7823/16104 [36:11:53<37:48:24, 16.44s/it]
{'loss': 0.5052, 'learning_rate': 1.0945888631792803e-06, 'rewards/chosen': -1.0300006866455078, 'rewards/rejected': -2.025160312652588, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9951596260070801, 'policy_logps/rejected': -315.2700500488281, 'policy_logps/chosen': -526.0294189453125, 'referece_logps/rejected': -295.0184631347656, 'referece_logps/chosen': -515.7293701171875, 'logits/rejected': -0.3510916233062744, 'logits/chosen': -0.3698384463787079, 'epoch': 2.91}

 49%|████▊     | 7824/16104 [36:12:11<38:36:27, 16.79s/it]

 49%|████▊     | 7825/16104 [36:12:29<39:25:02, 17.14s/it]

 49%|████▊     | 7826/16104 [36:12:48<40:48:40, 17.75s/it]

 49%|████▊     | 7827/16104 [36:13:04<39:53:44, 17.35s/it]

 49%|████▊     | 7828/16104 [36:13:22<39:57:54, 17.38s/it]

 49%|████▊     | 7829/16104 [36:13:42<42:05:42, 18.31s/it]

 49%|████▊     | 7830/16104 [36:13:57<39:28:52, 17.18s/it]

 49%|████▊     | 7831/16104 [36:14:13<38:44:47, 16.86s/it]

 49%|████▊     | 7832/16104 [36:14:28<37:13:19, 16.20s/it]

 49%|████▊     | 7833/16104 [36:14:44<37:24:35, 16.28s/it]


 49%|████▊     | 7835/16104 [36:15:17<36:32:48, 15.91s/it]
{'loss': 0.5761, 'learning_rate': 1.0921858957207082e-06, 'rewards/chosen': -0.5587770938873291, 'rewards/rejected': -1.748502254486084, 'rewards/accuracies': 0.75, 'rewards/margins': 1.189725399017334, 'policy_logps/rejected': -375.91668701171875, 'policy_logps/chosen': -364.1127624511719, 'referece_logps/rejected': -358.43170166015625, 'referece_logps/chosen': -358.52496337890625, 'logits/rejected': -0.6933216452598572, 'logits/chosen': -0.7392996549606323, 'epoch': 2.92}

 49%|████▊     | 7836/16104 [36:15:31<35:06:53, 15.29s/it]

 49%|████▊     | 7837/16104 [36:15:51<38:06:37, 16.60s/it]


 49%|████▊     | 7839/16104 [36:16:29<41:15:17, 17.97s/it]
{'loss': 0.5031, 'learning_rate': 1.0913847865458995e-06, 'rewards/chosen': -1.4535112380981445, 'rewards/rejected': -1.9717316627502441, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5182203054428101, 'policy_logps/rejected': -433.5302734375, 'policy_logps/chosen': -331.55535888671875, 'referece_logps/rejected': -413.8129577636719, 'referece_logps/chosen': -317.0202331542969, 'logits/rejected': -0.9451147317886353, 'logits/chosen': -0.7446607351303101, 'epoch': 2.92}


 49%|████▊     | 7841/16104 [36:17:06<41:07:17, 17.92s/it]
{'loss': 0.5064, 'learning_rate': 1.0909842097460222e-06, 'rewards/chosen': -1.0190914869308472, 'rewards/rejected': -1.6605185270309448, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6414269804954529, 'policy_logps/rejected': -442.9700622558594, 'policy_logps/chosen': -387.19061279296875, 'referece_logps/rejected': -426.36480712890625, 'referece_logps/chosen': -376.99969482421875, 'logits/rejected': -0.38123446702957153, 'logits/chosen': -0.38236716389656067, 'epoch': 2.92}

 49%|████▊     | 7842/16104 [36:17:25<42:21:57, 18.46s/it]

 49%|████▊     | 7843/16104 [36:17:38<38:34:43, 16.81s/it]

 49%|████▊     | 7844/16104 [36:17:52<36:26:38, 15.88s/it]

 49%|████▊     | 7845/16104 [36:18:12<39:15:41, 17.11s/it]

 49%|████▊     | 7846/16104 [36:18:34<42:45:31, 18.64s/it]

 49%|████▊     | 7847/16104 [36:18:54<43:42:23, 19.06s/it]

 49%|████▊     | 7848/16104 [36:19:14<44:08:20, 19.25s/it]

 49%|████▊     | 7849/16104 [36:19:26<39:25:40, 17.19s/it]

 49%|████▊     | 7850/16104 [36:19:44<39:55:45, 17.42s/it]

 49%|████▉     | 7851/16104 [36:19:58<37:38:45, 16.42s/it]

 49%|████▉     | 7852/16104 [36:20:20<41:29:27, 18.10s/it]

 49%|████▉     | 7853/16104 [36:20:40<42:36:03, 18.59s/it]

 49%|████▉     | 7854/16104 [36:20:57<41:17:01, 18.01s/it]

 49%|████▉     | 7855/16104 [36:21:13<40:15:22, 17.57s/it]


 49%|████▉     | 7857/16104 [36:21:52<42:39:35, 18.62s/it]
{'loss': 0.5169, 'learning_rate': 1.0877790708038625e-06, 'rewards/chosen': -0.5504397749900818, 'rewards/rejected': -1.9057157039642334, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3552757501602173, 'policy_logps/rejected': -322.9698486328125, 'policy_logps/chosen': -402.55645751953125, 'referece_logps/rejected': -303.9127197265625, 'referece_logps/chosen': -397.05206298828125, 'logits/rejected': -0.7308225631713867, 'logits/chosen': -0.5130037069320679, 'epoch': 2.93}

 49%|████▉     | 7858/16104 [36:22:07<40:07:14, 17.52s/it]

 49%|████▉     | 7859/16104 [36:22:21<37:41:42, 16.46s/it]

 49%|████▉     | 7860/16104 [36:22:38<37:59:26, 16.59s/it]

 49%|████▉     | 7861/16104 [36:22:50<34:46:44, 15.19s/it]

 49%|████▉     | 7862/16104 [36:23:05<35:15:06, 15.40s/it]

 49%|████▉     | 7863/16104 [36:23:19<33:54:05, 14.81s/it]

 49%|████▉     | 7864/16104 [36:23:35<34:45:07, 15.18s/it]


 49%|████▉     | 7866/16104 [36:24:02<32:11:40, 14.07s/it]
{'loss': 0.4753, 'learning_rate': 1.085975778554467e-06, 'rewards/chosen': -0.6690229773521423, 'rewards/rejected': -2.069058895111084, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4000358581542969, 'policy_logps/rejected': -211.865966796875, 'policy_logps/chosen': -312.73052978515625, 'referece_logps/rejected': -191.17538452148438, 'referece_logps/chosen': -306.0403137207031, 'logits/rejected': -0.8406906127929688, 'logits/chosen': -0.760519802570343, 'epoch': 2.93}

 49%|████▉     | 7867/16104 [36:24:21<35:37:20, 15.57s/it]

 49%|████▉     | 7868/16104 [36:24:41<38:20:52, 16.76s/it]

 49%|████▉     | 7869/16104 [36:24:55<36:53:22, 16.13s/it]


 49%|████▉     | 7871/16104 [36:25:24<35:24:43, 15.48s/it]
{'loss': 0.5042, 'learning_rate': 1.0849738274232012e-06, 'rewards/chosen': -0.904697597026825, 'rewards/rejected': -1.9600412845611572, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0553433895111084, 'policy_logps/rejected': -574.6451416015625, 'policy_logps/chosen': -497.1968688964844, 'referece_logps/rejected': -555.044677734375, 'referece_logps/chosen': -488.1499328613281, 'logits/rejected': 0.081655353307724, 'logits/chosen': 0.15570324659347534, 'epoch': 2.93}

 49%|████▉     | 7872/16104 [36:25:36<32:51:44, 14.37s/it]

 49%|████▉     | 7873/16104 [36:25:47<30:16:57, 13.24s/it]


 49%|████▉     | 7875/16104 [36:26:08<27:25:06, 12.00s/it]
{'loss': 0.5309, 'learning_rate': 1.0841722045973805e-06, 'rewards/chosen': -1.060820460319519, 'rewards/rejected': -1.6097674369812012, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5489469170570374, 'policy_logps/rejected': -381.7747497558594, 'policy_logps/chosen': -320.7961120605469, 'referece_logps/rejected': -365.67706298828125, 'referece_logps/chosen': -310.18792724609375, 'logits/rejected': -0.17098408937454224, 'logits/chosen': -0.15862151980400085, 'epoch': 2.93}

 49%|████▉     | 7876/16104 [36:26:19<26:32:09, 11.61s/it]

 49%|████▉     | 7877/16104 [36:26:33<28:30:18, 12.47s/it]

 49%|████▉     | 7878/16104 [36:26:51<31:53:20, 13.96s/it]

 49%|████▉     | 7879/16104 [36:27:04<31:27:17, 13.77s/it]

 49%|████▉     | 7880/16104 [36:27:15<29:41:44, 13.00s/it]

 49%|████▉     | 7881/16104 [36:27:29<30:23:35, 13.31s/it]

 49%|████▉     | 7882/16104 [36:27:49<34:46:31, 15.23s/it]

 49%|████▉     | 7883/16104 [36:28:09<37:59:20, 16.64s/it]

 49%|████▉     | 7884/16104 [36:28:25<37:58:19, 16.63s/it]

 49%|████▉     | 7885/16104 [36:28:37<34:12:36, 14.98s/it]

 49%|████▉     | 7886/16104 [36:28:54<35:56:20, 15.74s/it]

 49%|████▉     | 7887/16104 [36:29:14<38:27:28, 16.85s/it]

 49%|████▉     | 7888/16104 [36:29:27<35:53:16, 15.72s/it]

 49%|████▉     | 7889/16104 [36:29:44<36:55:55, 16.18s/it]

 49%|████▉     | 7890/16104 [36:30:02<38:14:39, 16.76s/it]

 49%|████▉     | 7891/16104 [36:30:24<41:48:23, 18.33s/it]

 49%|████▉     | 7892/16104 [36:30:42<41:39:40, 18.26s/it]

 49%|████▉     | 7893/16104 [36:30:58<40:10:24, 17.61s/it]

 49%|████▉     | 7894/16104 [36:31:12<37:20:14, 16.37s/it]

 49%|████▉     | 7895/16104 [36:31:23<34:06:29, 14.96s/it]


 49%|████▉     | 7897/16104 [36:31:54<35:21:00, 15.51s/it]
{'loss': 0.4899, 'learning_rate': 1.0797623191624493e-06, 'rewards/chosen': -1.2993159294128418, 'rewards/rejected': -1.6790735721588135, 'rewards/accuracies': 0.625, 'rewards/margins': 0.37975773215293884, 'policy_logps/rejected': -399.8426208496094, 'policy_logps/chosen': -227.10118103027344, 'referece_logps/rejected': -383.0518798828125, 'referece_logps/chosen': -214.10800170898438, 'logits/rejected': -0.6968492269515991, 'logits/chosen': -0.6698063611984253, 'epoch': 2.94}

 49%|████▉     | 7898/16104 [36:32:05<32:04:13, 14.07s/it]

 49%|████▉     | 7899/16104 [36:32:25<35:49:23, 15.72s/it]

 49%|████▉     | 7900/16104 [36:32:38<33:54:08, 14.88s/it]


 49%|████▉     | 7902/16104 [36:33:02<31:01:54, 13.62s/it]
{'loss': 0.4541, 'learning_rate': 1.0787598515802645e-06, 'rewards/chosen': -0.9143096804618835, 'rewards/rejected': -1.1858177185058594, 'rewards/accuracies': 0.625, 'rewards/margins': 0.27150803804397583, 'policy_logps/rejected': -380.58135986328125, 'policy_logps/chosen': -406.56610107421875, 'referece_logps/rejected': -368.72314453125, 'referece_logps/chosen': -397.4229736328125, 'logits/rejected': -0.32328638434410095, 'logits/chosen': -0.38521310687065125, 'epoch': 2.94}

 49%|████▉     | 7903/16104 [36:33:19<32:57:58, 14.47s/it]

 49%|████▉     | 7904/16104 [36:33:39<36:44:02, 16.13s/it]

 49%|████▉     | 7905/16104 [36:34:01<40:53:18, 17.95s/it]

 49%|████▉     | 7906/16104 [36:34:18<40:01:55, 17.58s/it]

 49%|████▉     | 7907/16104 [36:34:38<41:46:52, 18.35s/it]

 49%|████▉     | 7908/16104 [36:34:57<42:30:30, 18.67s/it]


 49%|████▉     | 7910/16104 [36:35:35<42:51:11, 18.83s/it]
{'loss': 0.5288, 'learning_rate': 1.0771557381997687e-06, 'rewards/chosen': -0.6325899362564087, 'rewards/rejected': -1.3364386558532715, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7038487195968628, 'policy_logps/rejected': -653.5570068359375, 'policy_logps/chosen': -694.2693481445312, 'referece_logps/rejected': -640.192626953125, 'referece_logps/chosen': -687.9434814453125, 'logits/rejected': 0.10871586203575134, 'logits/chosen': 0.3139416575431824, 'epoch': 2.95}

 49%|████▉     | 7911/16104 [36:35:49<39:44:48, 17.46s/it]

 49%|████▉     | 7912/16104 [36:36:08<41:04:17, 18.05s/it]

 49%|████▉     | 7913/16104 [36:36:28<42:06:28, 18.51s/it]

 49%|████▉     | 7914/16104 [36:36:50<44:11:30, 19.42s/it]

 49%|████▉     | 7915/16104 [36:37:02<39:11:07, 17.23s/it]

 49%|████▉     | 7916/16104 [36:37:17<37:37:58, 16.55s/it]

 49%|████▉     | 7917/16104 [36:37:28<33:46:20, 14.85s/it]

 49%|████▉     | 7918/16104 [36:37:42<33:15:44, 14.63s/it]

 49%|████▉     | 7919/16104 [36:38:00<35:47:05, 15.74s/it]

 49%|████▉     | 7920/16104 [36:38:20<38:30:51, 16.94s/it]

 49%|████▉     | 7921/16104 [36:38:39<40:18:48, 17.74s/it]

 49%|████▉     | 7922/16104 [36:38:54<38:26:06, 16.91s/it]


 49%|████▉     | 7924/16104 [36:39:26<37:59:30, 16.72s/it]

 49%|████▉     | 7925/16104 [36:39:39<35:14:54, 15.51s/it]

 49%|████▉     | 7926/16104 [36:39:56<36:29:37, 16.06s/it]

 49%|████▉     | 7927/16104 [36:40:16<39:12:13, 17.26s/it]

 49%|████▉     | 7928/16104 [36:40:32<38:06:37, 16.78s/it]

 49%|████▉     | 7929/16104 [36:40:50<39:12:04, 17.26s/it]

 49%|████▉     | 7930/16104 [36:41:11<41:22:11, 18.22s/it]
{'loss': 0.4299, 'learning_rate': 1.0731445899300356e-06, 'rewards/chosen': -0.7631132006645203, 'rewards/rejected': -2.1482677459716797, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3851544857025146, 'policy_logps/rejected': -338.006591796875, 'policy_logps/chosen': -466.9707946777344, 'referece_logps/rejected': -316.52392578125, 'referece_logps/chosen': -459.3396301269531, 'logits/rejected': -0.6952685713768005, 'logits/chosen': -0.8185963034629822, 'epoch': 2.95}


 49%|████▉     | 7932/16104 [36:41:45<39:39:15, 17.47s/it]

 49%|████▉     | 7933/16104 [36:42:01<38:40:51, 17.04s/it]

 49%|████▉     | 7934/16104 [36:42:15<36:51:31, 16.24s/it]

 49%|████▉     | 7935/16104 [36:42:26<32:57:27, 14.52s/it]
{'loss': 0.5511, 'learning_rate': 1.0721416154003183e-06, 'rewards/chosen': -1.3069597482681274, 'rewards/rejected': -1.4404045343399048, 'rewards/accuracies': 0.5, 'rewards/margins': 0.13344481587409973, 'policy_logps/rejected': -415.1471252441406, 'policy_logps/chosen': -400.04833984375, 'referece_logps/rejected': -400.7430725097656, 'referece_logps/chosen': -386.9787292480469, 'logits/rejected': -0.1877203732728958, 'logits/chosen': -0.36570146679878235, 'epoch': 2.96}


 49%|████▉     | 7937/16104 [36:43:00<36:03:45, 15.90s/it]

 49%|████▉     | 7938/16104 [36:43:15<35:46:01, 15.77s/it]

 49%|████▉     | 7939/16104 [36:43:31<35:47:52, 15.78s/it]

 49%|████▉     | 7940/16104 [36:43:49<37:19:54, 16.46s/it]

 49%|████▉     | 7941/16104 [36:44:09<39:49:13, 17.56s/it]

 49%|████▉     | 7942/16104 [36:44:23<37:23:41, 16.49s/it]

 49%|████▉     | 7943/16104 [36:44:37<35:48:45, 15.80s/it]

 49%|████▉     | 7944/16104 [36:44:51<34:06:39, 15.05s/it]

 49%|████▉     | 7945/16104 [36:45:02<31:37:52, 13.96s/it]
{'loss': 0.4608, 'learning_rate': 1.0701354484859972e-06, 'rewards/chosen': -1.1764520406723022, 'rewards/rejected': -2.5617196559906006, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3852673768997192, 'policy_logps/rejected': -413.84619140625, 'policy_logps/chosen': -361.7242431640625, 'referece_logps/rejected': -388.22900390625, 'referece_logps/chosen': -349.959716796875, 'logits/rejected': -0.7789416313171387, 'logits/chosen': -0.6345106363296509, 'epoch': 2.96}


 49%|████▉     | 7947/16104 [36:45:34<33:36:42, 14.83s/it]

 49%|████▉     | 7948/16104 [36:45:47<31:45:21, 14.02s/it]

 49%|████▉     | 7949/16104 [36:46:03<33:34:59, 14.83s/it]

 49%|████▉     | 7950/16104 [36:46:21<35:26:42, 15.65s/it]

 49%|████▉     | 7951/16104 [36:46:41<38:16:48, 16.90s/it]

 49%|████▉     | 7952/16104 [36:46:57<38:09:11, 16.85s/it]

 49%|████▉     | 7953/16104 [36:47:11<36:11:40, 15.99s/it]

 49%|████▉     | 7954/16104 [36:47:33<39:44:01, 17.55s/it]

 49%|████▉     | 7955/16104 [36:47:51<40:13:32, 17.77s/it]

 49%|████▉     | 7956/16104 [36:48:03<36:15:23, 16.02s/it]
{'loss': 0.5203, 'learning_rate': 1.0679283375073094e-06, 'rewards/chosen': -1.0702723264694214, 'rewards/rejected': -1.092585563659668, 'rewards/accuracies': 0.5, 'rewards/margins': 0.022313296794891357, 'policy_logps/rejected': -452.6876220703125, 'policy_logps/chosen': -373.07720947265625, 'referece_logps/rejected': -441.7617492675781, 'referece_logps/chosen': -362.3744812011719, 'logits/rejected': -0.5133085250854492, 'logits/chosen': -0.3983544707298279, 'epoch': 2.96}

 49%|████▉     | 7957/16104 [36:48:16<34:12:21, 15.11s/it]


 49%|████▉     | 7959/16104 [36:48:58<40:35:18, 17.94s/it]

 49%|████▉     | 7960/16104 [36:49:13<39:00:15, 17.24s/it]

 49%|████▉     | 7961/16104 [36:49:30<38:50:52, 17.17s/it]
{'loss': 0.5301, 'learning_rate': 1.066924994682034e-06, 'rewards/chosen': -0.6504589319229126, 'rewards/rejected': -2.130655288696289, 'rewards/accuracies': 1.0, 'rewards/margins': 1.480196237564087, 'policy_logps/rejected': -510.19061279296875, 'policy_logps/chosen': -509.1746826171875, 'referece_logps/rejected': -488.884033203125, 'referece_logps/chosen': -502.6700439453125, 'logits/rejected': -0.2518550157546997, 'logits/chosen': -0.22807258367538452, 'epoch': 2.97}


 49%|████▉     | 7963/16104 [36:50:03<38:19:16, 16.95s/it]

 49%|████▉     | 7964/16104 [36:50:23<40:07:34, 17.75s/it]

 49%|████▉     | 7965/16104 [36:50:41<40:14:45, 17.80s/it]
{'loss': 0.5349, 'learning_rate': 1.0661222716428729e-06, 'rewards/chosen': -0.868482768535614, 'rewards/rejected': -1.4166618585586548, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5481791496276855, 'policy_logps/rejected': -354.49847412109375, 'policy_logps/chosen': -337.7731628417969, 'referece_logps/rejected': -340.3319091796875, 'referece_logps/chosen': -329.08831787109375, 'logits/rejected': -0.11748918890953064, 'logits/chosen': -0.2064886838197708, 'epoch': 2.97}


 49%|████▉     | 7967/16104 [36:51:04<33:23:40, 14.77s/it]

 49%|████▉     | 7968/16104 [36:51:21<34:35:21, 15.30s/it]

 49%|████▉     | 7969/16104 [36:51:38<35:31:06, 15.72s/it]

 49%|████▉     | 7970/16104 [36:51:58<38:26:19, 17.01s/it]
{'loss': 0.4879, 'learning_rate': 1.0651188077226236e-06, 'rewards/chosen': -0.7721438407897949, 'rewards/rejected': -2.7756855487823486, 'rewards/accuracies': 0.75, 'rewards/margins': 2.0035414695739746, 'policy_logps/rejected': -445.8923034667969, 'policy_logps/chosen': -462.30072021484375, 'referece_logps/rejected': -418.13543701171875, 'referece_logps/chosen': -454.57928466796875, 'logits/rejected': -0.0740555077791214, 'logits/chosen': -0.0795825719833374, 'epoch': 2.97}

 49%|████▉     | 7971/16104 [36:52:16<39:23:07, 17.43s/it]


 50%|████▉     | 7973/16104 [36:52:49<38:56:17, 17.24s/it]
{'loss': 0.5529, 'learning_rate': 1.0645166976954634e-06, 'rewards/chosen': -0.614890456199646, 'rewards/rejected': -1.9803030490875244, 'rewards/accuracies': 1.0, 'rewards/margins': 1.3654124736785889, 'policy_logps/rejected': -387.054931640625, 'policy_logps/chosen': -322.34197998046875, 'referece_logps/rejected': -367.25189208984375, 'referece_logps/chosen': -316.1930847167969, 'logits/rejected': -0.4107825458049774, 'logits/chosen': -0.30028507113456726, 'epoch': 2.97}


 50%|████▉     | 7975/16104 [36:53:22<38:04:02, 16.86s/it]
{'loss': 0.4783, 'learning_rate': 1.0641152779480803e-06, 'rewards/chosen': -0.49163082242012024, 'rewards/rejected': -1.8963696956634521, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4047386646270752, 'policy_logps/rejected': -349.27154541015625, 'policy_logps/chosen': -215.36740112304688, 'referece_logps/rejected': -330.307861328125, 'referece_logps/chosen': -210.45108032226562, 'logits/rejected': -0.8363831043243408, 'logits/chosen': -0.6498831510543823, 'epoch': 2.97}

 50%|████▉     | 7976/16104 [36:53:42<39:55:58, 17.69s/it]


 50%|████▉     | 7978/16104 [36:54:13<37:00:50, 16.40s/it]
{'loss': 0.5815, 'learning_rate': 1.0635131288954746e-06, 'rewards/chosen': -0.7037849426269531, 'rewards/rejected': -2.221015453338623, 'rewards/accuracies': 0.875, 'rewards/margins': 1.51723051071167, 'policy_logps/rejected': -381.2421569824219, 'policy_logps/chosen': -454.18853759765625, 'referece_logps/rejected': -359.031982421875, 'referece_logps/chosen': -447.15069580078125, 'logits/rejected': -0.07629500329494476, 'logits/chosen': -0.020922735333442688, 'epoch': 2.97}


 50%|████▉     | 7980/16104 [36:54:42<34:18:12, 15.20s/it]

 50%|████▉     | 7981/16104 [36:54:59<36:02:54, 15.98s/it]

 50%|████▉     | 7982/16104 [36:55:15<35:32:38, 15.75s/it]
{'loss': 0.4021, 'learning_rate': 1.0627102275608205e-06, 'rewards/chosen': -1.1947213411331177, 'rewards/rejected': -2.6249570846557617, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4302356243133545, 'policy_logps/rejected': -393.0531005859375, 'policy_logps/chosen': -362.95269775390625, 'referece_logps/rejected': -366.8035583496094, 'referece_logps/chosen': -351.0054931640625, 'logits/rejected': -0.736699104309082, 'logits/chosen': -0.587949812412262, 'epoch': 2.97}


 50%|████▉     | 7984/16104 [36:55:43<33:16:10, 14.75s/it]
{'loss': 0.5093, 'learning_rate': 1.0623087616405705e-06, 'rewards/chosen': -0.6572420597076416, 'rewards/rejected': -1.9459941387176514, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2887519598007202, 'policy_logps/rejected': -511.1655578613281, 'policy_logps/chosen': -497.8256530761719, 'referece_logps/rejected': -491.70562744140625, 'referece_logps/chosen': -491.25323486328125, 'logits/rejected': -0.11660447716712952, 'logits/chosen': -0.10637141019105911, 'epoch': 2.97}


 50%|████▉     | 7986/16104 [36:56:22<38:45:25, 17.19s/it]

 50%|████▉     | 7987/16104 [36:56:41<39:59:56, 17.74s/it]

 50%|████▉     | 7988/16104 [36:56:59<40:22:58, 17.91s/it]
{'loss': 0.398, 'learning_rate': 1.0615057996190255e-06, 'rewards/chosen': -0.9837266206741333, 'rewards/rejected': -2.6731882095336914, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6894617080688477, 'policy_logps/rejected': -283.1285095214844, 'policy_logps/chosen': -251.28231811523438, 'referece_logps/rejected': -256.3966064453125, 'referece_logps/chosen': -241.44508361816406, 'logits/rejected': -0.5511720180511475, 'logits/chosen': -0.659845769405365, 'epoch': 2.98}


 50%|████▉     | 7990/16104 [36:57:36<41:25:41, 18.38s/it]
{'loss': 0.4487, 'learning_rate': 1.0611043036476555e-06, 'rewards/chosen': -0.6630956530570984, 'rewards/rejected': -2.725600242614746, 'rewards/accuracies': 0.875, 'rewards/margins': 2.062504529953003, 'policy_logps/rejected': -406.7099914550781, 'policy_logps/chosen': -400.30352783203125, 'referece_logps/rejected': -379.4539794921875, 'referece_logps/chosen': -393.6725769042969, 'logits/rejected': -0.03991188108921051, 'logits/chosen': 0.11840076744556427, 'epoch': 2.98}


 50%|████▉     | 7992/16104 [36:58:14<41:58:00, 18.62s/it]

 50%|████▉     | 7993/16104 [36:58:28<39:00:09, 17.31s/it]

 50%|████▉     | 7994/16104 [36:58:45<38:56:11, 17.28s/it]

 50%|████▉     | 7995/16104 [36:59:05<40:36:05, 18.03s/it]

 50%|████▉     | 7996/16104 [36:59:20<38:22:50, 17.04s/it]

 50%|████▉     | 7997/16104 [36:59:39<40:00:43, 17.77s/it]

 50%|████▉     | 7998/16104 [36:59:59<41:12:41, 18.30s/it]

 50%|████▉     | 7999/16104 [37:00:17<41:11:10, 18.29s/it]

 50%|████▉     | 8000/16104 [37:00:37<42:03:17, 18.68s/it]

 50%|████▉     | 8001/16104 [37:01:11<52:37:56, 23.38s/it]

 50%|████▉     | 8002/16104 [37:01:24<45:35:42, 20.26s/it]

 50%|████▉     | 8003/16104 [37:01:46<46:27:50, 20.65s/it]

 50%|████▉     | 8004/16104 [37:02:07<46:53:47, 20.84s/it]

 50%|████▉     | 8005/16104 [37:02:18<40:22:40, 17.95s/it]

 50%|████▉     | 8006/16104 [37:02:37<40:56:58, 18.20s/it]

 50%|████▉     | 8007/16104 [37:02:55<40:46:05, 18.13s/it]

 50%|████▉     | 8008/16104 [37:03:12<40:02:46, 17.81s/it]

 50%|████▉     | 8009/16104 [37:03:31<41:11:30, 18.32s/it]

 50%|████▉     | 8010/16104 [37:03:52<42:40:21, 18.98s/it]
{'loss': 0.6197, 'learning_rate': 1.057088810862768e-06, 'rewards/chosen': -0.8948723077774048, 'rewards/rejected': -1.3421529531478882, 'rewards/accuracies': 0.625, 'rewards/margins': 0.447280615568161, 'policy_logps/rejected': -459.75299072265625, 'policy_logps/chosen': -534.9403686523438, 'referece_logps/rejected': -446.33148193359375, 'referece_logps/chosen': -525.9916381835938, 'logits/rejected': 0.01950986124575138, 'logits/chosen': -0.07404078543186188, 'epoch': 2.98}


 50%|████▉     | 8012/16104 [37:04:24<39:12:37, 17.44s/it]
{'loss': 0.5293, 'learning_rate': 1.0566872097065786e-06, 'rewards/chosen': -1.0460970401763916, 'rewards/rejected': -1.7919355630874634, 'rewards/accuracies': 0.75, 'rewards/margins': 0.745838463306427, 'policy_logps/rejected': -335.63934326171875, 'policy_logps/chosen': -408.9084167480469, 'referece_logps/rejected': -317.7200012207031, 'referece_logps/chosen': -398.44744873046875, 'logits/rejected': -1.019472360610962, 'logits/chosen': -0.9487631916999817, 'epoch': 2.99}

 50%|████▉     | 8013/16104 [37:04:35<34:36:40, 15.40s/it]


 50%|████▉     | 8015/16104 [37:05:05<34:40:07, 15.43s/it]

 50%|████▉     | 8016/16104 [37:05:19<34:00:48, 15.14s/it]
{'loss': 0.5491, 'learning_rate': 1.0558839799419982e-06, 'rewards/chosen': -0.6219977736473083, 'rewards/rejected': -1.2259024381637573, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6039047241210938, 'policy_logps/rejected': -312.2704162597656, 'policy_logps/chosen': -478.80743408203125, 'referece_logps/rejected': -300.01141357421875, 'referece_logps/chosen': -472.58746337890625, 'logits/rejected': -0.25452858209609985, 'logits/chosen': -0.3823651671409607, 'epoch': 2.99}


 50%|████▉     | 8018/16104 [37:05:56<38:41:23, 17.23s/it]

 50%|████▉     | 8019/16104 [37:06:16<40:22:04, 17.97s/it]

 50%|████▉     | 8020/16104 [37:06:36<41:16:48, 18.38s/it]

 50%|████▉     | 8021/16104 [37:06:54<41:30:52, 18.49s/it]

 50%|████▉     | 8022/16104 [37:07:08<38:00:07, 16.93s/it]
{'loss': 0.608, 'learning_rate': 1.0546790676393964e-06, 'rewards/chosen': -1.0603071451187134, 'rewards/rejected': -1.3185813426971436, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2582741975784302, 'policy_logps/rejected': -443.95947265625, 'policy_logps/chosen': -297.4620056152344, 'referece_logps/rejected': -430.7736511230469, 'referece_logps/chosen': -286.85894775390625, 'logits/rejected': -0.8590513467788696, 'logits/chosen': -0.6485891938209534, 'epoch': 2.99}


 50%|████▉     | 8024/16104 [37:07:41<38:00:37, 16.94s/it]
{'loss': 0.5914, 'learning_rate': 1.054277412423617e-06, 'rewards/chosen': -1.3931264877319336, 'rewards/rejected': -1.5351654291152954, 'rewards/accuracies': 0.375, 'rewards/margins': 0.14203894138336182, 'policy_logps/rejected': -347.5580749511719, 'policy_logps/chosen': -442.0592041015625, 'referece_logps/rejected': -332.2064208984375, 'referece_logps/chosen': -428.1279296875, 'logits/rejected': -1.0343068838119507, 'logits/chosen': -1.1309499740600586, 'epoch': 2.99}


 50%|████▉     | 8026/16104 [37:08:19<40:36:24, 18.10s/it]

 50%|████▉     | 8027/16104 [37:08:38<41:37:59, 18.56s/it]
{'loss': 0.5348, 'learning_rate': 1.053674913153122e-06, 'rewards/chosen': -0.9439138770103455, 'rewards/rejected': -1.5639086961746216, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6199949383735657, 'policy_logps/rejected': -374.14398193359375, 'policy_logps/chosen': -336.7050476074219, 'referece_logps/rejected': -358.5048828125, 'referece_logps/chosen': -327.265869140625, 'logits/rejected': -0.4465966522693634, 'logits/chosen': -0.5158001780509949, 'epoch': 2.99}


 50%|████▉     | 8029/16104 [37:09:12<39:53:55, 17.79s/it]
{'loss': 0.5895, 'learning_rate': 1.053273236103022e-06, 'rewards/chosen': -0.8544226288795471, 'rewards/rejected': -1.700339674949646, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8459170460700989, 'policy_logps/rejected': -380.5537109375, 'policy_logps/chosen': -401.94000244140625, 'referece_logps/rejected': -363.5503234863281, 'referece_logps/chosen': -393.395751953125, 'logits/rejected': -0.12137618660926819, 'logits/chosen': -0.12653398513793945, 'epoch': 2.99}


 50%|████▉     | 8031/16104 [37:09:36<32:47:31, 14.62s/it]

 50%|████▉     | 8032/16104 [37:09:56<36:39:34, 16.35s/it]

 50%|████▉     | 8033/16104 [37:10:14<37:51:24, 16.89s/it]

 50%|████▉     | 8034/16104 [37:10:36<41:02:32, 18.31s/it]
{'loss': 0.4061, 'learning_rate': 1.0522690059074943e-06, 'rewards/chosen': -0.8629431128501892, 'rewards/rejected': -2.0173134803771973, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1543704271316528, 'policy_logps/rejected': -337.4907531738281, 'policy_logps/chosen': -411.2784423828125, 'referece_logps/rejected': -317.317626953125, 'referece_logps/chosen': -402.6490478515625, 'logits/rejected': -0.21745072305202484, 'logits/chosen': -0.2694621682167053, 'epoch': 2.99}

 50%|████▉     | 8035/16104 [37:10:55<41:46:25, 18.64s/it]

 50%|████▉     | 8036/16104 [37:11:07<37:15:02, 16.62s/it]

 50%|████▉     | 8037/16104 [37:11:19<34:07:02, 15.23s/it]

 50%|████▉     | 8038/16104 [37:11:39<37:17:40, 16.65s/it]

 50%|████▉     | 8039/16104 [37:11:57<38:16:39, 17.09s/it]


 50%|████▉     | 8041/16104 [37:12:26<34:35:05, 15.44s/it]
{'loss': 0.537, 'learning_rate': 1.0508629950575297e-06, 'rewards/chosen': -1.063970923423767, 'rewards/rejected': -1.567698359489441, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5037273168563843, 'policy_logps/rejected': -359.5641784667969, 'policy_logps/chosen': -410.4080810546875, 'referece_logps/rejected': -343.8871765136719, 'referece_logps/chosen': -399.76837158203125, 'logits/rejected': -0.6390860080718994, 'logits/chosen': -0.5630410313606262, 'epoch': 3.0}


 50%|████▉     | 8043/16104 [37:12:52<31:29:08, 14.06s/it]

 50%|████▉     | 8044/16104 [37:13:05<30:33:37, 13.65s/it]

 50%|████▉     | 8045/16104 [37:13:19<30:36:11, 13.67s/it]
{'loss': 0.445, 'learning_rate': 1.0500595148423923e-06, 'rewards/chosen': -0.5163679122924805, 'rewards/rejected': -1.3063786029815674, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7900106906890869, 'policy_logps/rejected': -428.3853759765625, 'policy_logps/chosen': -330.6580810546875, 'referece_logps/rejected': -415.3216247558594, 'referece_logps/chosen': -325.494384765625, 'logits/rejected': -0.16152423620224, 'logits/chosen': -0.08783566951751709, 'epoch': 3.0}


 50%|████▉     | 8047/16104 [37:13:50<33:45:12, 15.08s/it]

 50%|████▉     | 8048/16104 [37:14:03<32:03:04, 14.32s/it]
{'loss': 0.484, 'learning_rate': 1.0494568833901347e-06, 'rewards/chosen': -0.8771358132362366, 'rewards/rejected': -2.30226731300354, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4251315593719482, 'policy_logps/rejected': -421.53570556640625, 'policy_logps/chosen': -399.6005554199219, 'referece_logps/rejected': -398.51300048828125, 'referece_logps/chosen': -390.8291931152344, 'logits/rejected': -0.9100828766822815, 'logits/chosen': -0.7974463105201721, 'epoch': 3.0}


 50%|████▉     | 8050/16104 [37:14:38<36:30:37, 16.32s/it]
{'loss': 0.4733, 'learning_rate': 1.0490551190719906e-06, 'rewards/chosen': -0.6960951685905457, 'rewards/rejected': -2.8449580669403076, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1488630771636963, 'policy_logps/rejected': -461.0269775390625, 'policy_logps/chosen': -471.6816101074219, 'referece_logps/rejected': -432.5774230957031, 'referece_logps/chosen': -464.7206726074219, 'logits/rejected': 0.7490311861038208, 'logits/chosen': 0.7621458172798157, 'epoch': 3.0}


 50%|█████     | 8052/16104 [37:15:02<31:38:08, 14.14s/it]

 50%|█████     | 8053/16104 [37:15:22<35:35:41, 15.92s/it]

 50%|█████     | 8054/16104 [37:15:35<33:21:32, 14.92s/it]

 50%|█████     | 8055/16104 [37:15:55<36:27:57, 16.31s/it]
{'loss': 0.6031, 'learning_rate': 1.0480506736924152e-06, 'rewards/chosen': -1.2518779039382935, 'rewards/rejected': -1.348007082939148, 'rewards/accuracies': 0.625, 'rewards/margins': 0.09612920135259628, 'policy_logps/rejected': -316.8758239746094, 'policy_logps/chosen': -356.617919921875, 'referece_logps/rejected': -303.395751953125, 'referece_logps/chosen': -344.09912109375, 'logits/rejected': -0.7235331535339355, 'logits/chosen': -0.9551553726196289, 'epoch': 3.0}


 50%|█████     | 8057/16104 [37:16:27<35:26:31, 15.86s/it]
{'loss': 0.5337, 'learning_rate': 1.0476488818775517e-06, 'rewards/chosen': -1.1504911184310913, 'rewards/rejected': -1.859002709388733, 'rewards/accuracies': 0.625, 'rewards/margins': 0.708511471748352, 'policy_logps/rejected': -356.52294921875, 'policy_logps/chosen': -394.658935546875, 'referece_logps/rejected': -337.9329528808594, 'referece_logps/chosen': -383.15399169921875, 'logits/rejected': 0.3386388421058655, 'logits/chosen': 0.27412793040275574, 'epoch': 3.0}

 50%|█████     | 8058/16104 [37:16:38<32:05:54, 14.36s/it]

 50%|█████     | 8059/16104 [37:16:50<30:45:49, 13.77s/it]


 50%|█████     | 8061/16104 [37:17:27<36:25:01, 16.30s/it]
{'loss': 0.6255, 'learning_rate': 1.0468452751830518e-06, 'rewards/chosen': -0.7085333466529846, 'rewards/rejected': -1.3574336767196655, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6489003300666809, 'policy_logps/rejected': -313.3384094238281, 'policy_logps/chosen': -301.86456298828125, 'referece_logps/rejected': -299.7640686035156, 'referece_logps/chosen': -294.7792053222656, 'logits/rejected': -1.6595104932785034, 'logits/chosen': -1.5336941480636597, 'epoch': 3.0}


 50%|█████     | 8063/16104 [37:17:57<34:43:50, 15.55s/it]
{'loss': 0.5673, 'learning_rate': 1.046443460433444e-06, 'rewards/chosen': -0.78765869140625, 'rewards/rejected': -1.075587511062622, 'rewards/accuracies': 0.625, 'rewards/margins': 0.28792881965637207, 'policy_logps/rejected': -341.6245422363281, 'policy_logps/chosen': -335.185791015625, 'referece_logps/rejected': -330.8686828613281, 'referece_logps/chosen': -327.3092041015625, 'logits/rejected': -0.8057461380958557, 'logits/chosen': -0.7771303653717041, 'epoch': 3.0}

 50%|█████     | 8064/16104 [37:18:10<32:45:52, 14.67s/it]


 50%|█████     | 8066/16104 [37:18:47<36:44:29, 16.46s/it]

 50%|█████     | 8067/16104 [37:19:05<37:31:24, 16.81s/it]

 50%|█████     | 8068/16104 [37:19:25<39:22:18, 17.64s/it]

 50%|█████     | 8069/16104 [37:19:35<34:45:22, 15.57s/it]
{'loss': 0.5513, 'learning_rate': 1.0452379713553936e-06, 'rewards/chosen': -0.7483192682266235, 'rewards/rejected': -1.5706430673599243, 'rewards/accuracies': 1.0, 'rewards/margins': 0.8223238587379456, 'policy_logps/rejected': -545.6171875, 'policy_logps/chosen': -407.15087890625, 'referece_logps/rejected': -529.9108276367188, 'referece_logps/chosen': -399.667724609375, 'logits/rejected': -1.1097345352172852, 'logits/chosen': -0.9358603954315186, 'epoch': 3.01}


 50%|█████     | 8071/16104 [37:19:57<29:21:26, 13.16s/it]
{'loss': 0.6481, 'learning_rate': 1.044836126936364e-06, 'rewards/chosen': -0.7208542823791504, 'rewards/rejected': -0.9972438216209412, 'rewards/accuracies': 0.625, 'rewards/margins': 0.27638956904411316, 'policy_logps/rejected': -322.0848083496094, 'policy_logps/chosen': -453.41937255859375, 'referece_logps/rejected': -312.11236572265625, 'referece_logps/chosen': -446.2107849121094, 'logits/rejected': -0.30590614676475525, 'logits/chosen': -0.310362309217453, 'epoch': 3.01}


 50%|█████     | 8073/16104 [37:20:28<32:37:23, 14.62s/it]

 50%|█████     | 8074/16104 [37:20:45<34:31:14, 15.48s/it]
{'loss': 0.501, 'learning_rate': 1.0442333467253788e-06, 'rewards/chosen': -0.9811978936195374, 'rewards/rejected': -1.6479604244232178, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6667625904083252, 'policy_logps/rejected': -301.88055419921875, 'policy_logps/chosen': -347.17169189453125, 'referece_logps/rejected': -285.40093994140625, 'referece_logps/chosen': -337.3597106933594, 'logits/rejected': -0.6461510062217712, 'logits/chosen': -0.3928423523902893, 'epoch': 3.01}


 50%|█████     | 8076/16104 [37:21:15<34:34:07, 15.50s/it]

 50%|█████     | 8077/16104 [37:21:28<32:53:25, 14.75s/it]
{'loss': 0.5274, 'learning_rate': 1.0436305504105341e-06, 'rewards/chosen': -1.220254898071289, 'rewards/rejected': -1.5664761066436768, 'rewards/accuracies': 0.75, 'rewards/margins': 0.3462211489677429, 'policy_logps/rejected': -519.4376831054688, 'policy_logps/chosen': -552.520751953125, 'referece_logps/rejected': -503.7729187011719, 'referece_logps/chosen': -540.3181762695312, 'logits/rejected': 0.2609707713127136, 'logits/chosen': 0.2783237099647522, 'epoch': 3.01}


 50%|█████     | 8079/16104 [37:22:01<35:18:19, 15.84s/it]
{'loss': 0.4704, 'learning_rate': 1.0432286773624223e-06, 'rewards/chosen': -0.6196821331977844, 'rewards/rejected': -1.7335591316223145, 'rewards/accuracies': 1.0, 'rewards/margins': 1.1138770580291748, 'policy_logps/rejected': -470.5161437988281, 'policy_logps/chosen': -461.3969421386719, 'referece_logps/rejected': -453.18060302734375, 'referece_logps/chosen': -455.2001647949219, 'logits/rejected': -0.06919331103563309, 'logits/chosen': -0.07111981511116028, 'epoch': 3.01}


 50%|█████     | 8081/16104 [37:22:34<36:16:02, 16.27s/it]

 50%|█████     | 8082/16104 [37:22:50<36:14:27, 16.26s/it]

 50%|█████     | 8083/16104 [37:23:09<38:13:14, 17.15s/it]
{'loss': 0.4555, 'learning_rate': 1.042424910347101e-06, 'rewards/chosen': -1.166416049003601, 'rewards/rejected': -2.129589080810547, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9631730318069458, 'policy_logps/rejected': -406.218017578125, 'policy_logps/chosen': -419.70806884765625, 'referece_logps/rejected': -384.92218017578125, 'referece_logps/chosen': -408.0439453125, 'logits/rejected': -0.23962056636810303, 'logits/chosen': -0.3015345335006714, 'epoch': 3.01}


 50%|█████     | 8085/16104 [37:23:46<39:32:11, 17.75s/it]

 50%|█████     | 8086/16104 [37:24:04<39:30:55, 17.74s/it]

 50%|█████     | 8087/16104 [37:24:22<39:49:05, 17.88s/it]
{'loss': 0.4754, 'learning_rate': 1.0416211158731679e-06, 'rewards/chosen': -0.8896821737289429, 'rewards/rejected': -1.6870101690292358, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7973279356956482, 'policy_logps/rejected': -331.50811767578125, 'policy_logps/chosen': -459.42034912109375, 'referece_logps/rejected': -314.6380615234375, 'referece_logps/chosen': -450.52349853515625, 'logits/rejected': -0.43400508165359497, 'logits/chosen': -0.5193554162979126, 'epoch': 3.01}


 50%|█████     | 8089/16104 [37:24:55<38:28:19, 17.28s/it]
{'loss': 0.5932, 'learning_rate': 1.0412192085017955e-06, 'rewards/chosen': -0.9067650437355042, 'rewards/rejected': -1.2365325689315796, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3297674059867859, 'policy_logps/rejected': -275.22235107421875, 'policy_logps/chosen': -341.8824768066406, 'referece_logps/rejected': -262.85699462890625, 'referece_logps/chosen': -332.8147888183594, 'logits/rejected': -0.7574887275695801, 'logits/chosen': -0.8697013258934021, 'epoch': 3.01}

 50%|█████     | 8090/16104 [37:25:06<34:23:15, 15.45s/it]

 50%|█████     | 8091/16104 [37:25:26<37:23:54, 16.80s/it]


 50%|█████     | 8093/16104 [37:25:59<37:32:00, 16.87s/it]

 50%|█████     | 8094/16104 [37:26:19<39:19:21, 17.67s/it]
{'loss': 0.5576, 'learning_rate': 1.0402144110362897e-06, 'rewards/chosen': -0.5732981562614441, 'rewards/rejected': -2.437690019607544, 'rewards/accuracies': 0.625, 'rewards/margins': 1.8643919229507446, 'policy_logps/rejected': -634.2543334960938, 'policy_logps/chosen': -641.9260864257812, 'referece_logps/rejected': -609.87744140625, 'referece_logps/chosen': -636.193115234375, 'logits/rejected': -0.9500876069068909, 'logits/chosen': -0.9308069944381714, 'epoch': 3.02}

 50%|█████     | 8095/16104 [37:26:40<41:46:08, 18.77s/it]

 50%|█████     | 8096/16104 [37:26:55<38:52:30, 17.48s/it]

 50%|█████     | 8097/16104 [37:27:14<40:22:48, 18.16s/it]

 50%|█████     | 8098/16104 [37:27:26<36:13:34, 16.29s/it]


 50%|█████     | 8100/16104 [37:27:57<35:52:02, 16.13s/it]

 50%|█████     | 8101/16104 [37:28:14<36:20:21, 16.35s/it]

 50%|█████     | 8102/16104 [37:28:27<34:11:30, 15.38s/it]

 50%|█████     | 8103/16104 [37:28:45<35:56:18, 16.17s/it]
{'loss': 0.5105, 'learning_rate': 1.038405673796349e-06, 'rewards/chosen': -0.5754778385162354, 'rewards/rejected': -1.5552616119384766, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9797837734222412, 'policy_logps/rejected': -427.83294677734375, 'policy_logps/chosen': -442.07806396484375, 'referece_logps/rejected': -412.28033447265625, 'referece_logps/chosen': -436.32330322265625, 'logits/rejected': 0.09635750204324722, 'logits/chosen': 0.2759433686733246, 'epoch': 3.02}

 50%|█████     | 8104/16104 [37:29:05<38:07:51, 17.16s/it]


 50%|█████     | 8106/16104 [37:29:32<33:31:59, 15.09s/it]

 50%|█████     | 8107/16104 [37:29:50<35:21:58, 15.92s/it]

 50%|█████     | 8108/16104 [37:30:10<38:07:32, 17.17s/it]

 50%|█████     | 8109/16104 [37:30:24<35:58:36, 16.20s/it]

 50%|█████     | 8110/16104 [37:30:36<33:13:53, 14.97s/it]

 50%|█████     | 8111/16104 [37:30:54<35:30:41, 15.99s/it]

 50%|█████     | 8112/16104 [37:31:14<38:12:28, 17.21s/it]
{'loss': 0.494, 'learning_rate': 1.0365968107166212e-06, 'rewards/chosen': -0.932265043258667, 'rewards/rejected': -1.701216220855713, 'rewards/accuracies': 0.625, 'rewards/margins': 0.768951416015625, 'policy_logps/rejected': -384.6457214355469, 'policy_logps/chosen': -345.171875, 'referece_logps/rejected': -367.6335754394531, 'referece_logps/chosen': -335.8492431640625, 'logits/rejected': -0.63789302110672, 'logits/chosen': -0.9541062116622925, 'epoch': 3.02}


 50%|█████     | 8114/16104 [37:31:43<34:30:23, 15.55s/it]
{'loss': 0.47, 'learning_rate': 1.0361948246502005e-06, 'rewards/chosen': -0.6366344690322876, 'rewards/rejected': -1.4206414222717285, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7840070724487305, 'policy_logps/rejected': -238.12548828125, 'policy_logps/chosen': -345.8868713378906, 'referece_logps/rejected': -223.9190673828125, 'referece_logps/chosen': -339.5205383300781, 'logits/rejected': -0.11301380395889282, 'logits/chosen': -0.1226966381072998, 'epoch': 3.02}


 50%|█████     | 8116/16104 [37:32:18<36:24:12, 16.41s/it]

 50%|█████     | 8117/16104 [37:32:30<33:20:16, 15.03s/it]
{'loss': 0.6592, 'learning_rate': 1.0355918345898072e-06, 'rewards/chosen': -1.0588454008102417, 'rewards/rejected': -0.9411568641662598, 'rewards/accuracies': 0.625, 'rewards/margins': -0.11768849194049835, 'policy_logps/rejected': -255.38803100585938, 'policy_logps/chosen': -417.06005859375, 'referece_logps/rejected': -245.97645568847656, 'referece_logps/chosen': -406.4715576171875, 'logits/rejected': -0.44342297315597534, 'logits/chosen': -0.5695290565490723, 'epoch': 3.02}

 50%|█████     | 8118/16104 [37:32:41<30:32:19, 13.77s/it]


 50%|█████     | 8120/16104 [37:33:16<35:03:29, 15.81s/it]
{'loss': 0.5902, 'learning_rate': 1.034988831571635e-06, 'rewards/chosen': -1.1872080564498901, 'rewards/rejected': -1.401344656944275, 'rewards/accuracies': 0.75, 'rewards/margins': 0.21413668990135193, 'policy_logps/rejected': -390.325439453125, 'policy_logps/chosen': -341.063720703125, 'referece_logps/rejected': -376.3119812011719, 'referece_logps/chosen': -329.191650390625, 'logits/rejected': -0.6009676456451416, 'logits/chosen': -0.5266266465187073, 'epoch': 3.03}


 50%|█████     | 8122/16104 [37:33:54<38:14:07, 17.24s/it]

 50%|█████     | 8123/16104 [37:34:11<38:28:49, 17.36s/it]

 50%|█████     | 8124/16104 [37:34:32<40:50:46, 18.43s/it]

 50%|█████     | 8125/16104 [37:34:46<37:27:54, 16.90s/it]

 50%|█████     | 8126/16104 [37:35:00<36:00:44, 16.25s/it]
{'loss': 0.4695, 'learning_rate': 1.0337827875400914e-06, 'rewards/chosen': -0.9968226552009583, 'rewards/rejected': -3.0233864784240723, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0265634059906006, 'policy_logps/rejected': -477.2307434082031, 'policy_logps/chosen': -294.57763671875, 'referece_logps/rejected': -446.9968566894531, 'referece_logps/chosen': -284.6094055175781, 'logits/rejected': -0.8560113906860352, 'logits/chosen': -0.7269669771194458, 'epoch': 3.03}


 50%|█████     | 8128/16104 [37:35:35<36:59:56, 16.70s/it]

 50%|█████     | 8129/16104 [37:35:46<33:34:29, 15.16s/it]

 50%|█████     | 8130/16104 [37:36:00<32:38:23, 14.74s/it]

 50%|█████     | 8131/16104 [37:36:12<30:39:27, 13.84s/it]

 50%|█████     | 8132/16104 [37:36:32<35:01:03, 15.81s/it]

 51%|█████     | 8133/16104 [37:36:46<33:45:00, 15.24s/it]

 51%|█████     | 8134/16104 [37:36:59<31:56:17, 14.43s/it]
{'loss': 0.3647, 'learning_rate': 1.0321746526068004e-06, 'rewards/chosen': -0.6299982070922852, 'rewards/rejected': -2.479076862335205, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8490791320800781, 'policy_logps/rejected': -519.1067504882812, 'policy_logps/chosen': -406.3438720703125, 'referece_logps/rejected': -494.3159484863281, 'referece_logps/chosen': -400.0438537597656, 'logits/rejected': -0.42110300064086914, 'logits/chosen': -0.29508984088897705, 'epoch': 3.03}

 51%|█████     | 8135/16104 [37:37:19<35:57:15, 16.24s/it]

 51%|█████     | 8136/16104 [37:37:41<39:43:12, 17.95s/it]

 51%|█████     | 8137/16104 [37:37:57<38:24:05, 17.35s/it]


 51%|█████     | 8139/16104 [37:38:28<37:11:12, 16.81s/it]
{'loss': 0.5234, 'learning_rate': 1.0311695257097516e-06, 'rewards/chosen': -1.692035436630249, 'rewards/rejected': -2.4980194568634033, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8059839010238647, 'policy_logps/rejected': -400.15777587890625, 'policy_logps/chosen': -341.2694091796875, 'referece_logps/rejected': -375.1775817871094, 'referece_logps/chosen': -324.3490295410156, 'logits/rejected': -1.0309014320373535, 'logits/chosen': -1.126043438911438, 'epoch': 3.03}


 51%|█████     | 8141/16104 [37:38:56<33:57:22, 15.35s/it]
{'loss': 0.3625, 'learning_rate': 1.0307674660679681e-06, 'rewards/chosen': -1.7692859172821045, 'rewards/rejected': -3.2395148277282715, 'rewards/accuracies': 0.875, 'rewards/margins': 1.470228672027588, 'policy_logps/rejected': -475.9264831542969, 'policy_logps/chosen': -504.03436279296875, 'referece_logps/rejected': -443.5313415527344, 'referece_logps/chosen': -486.3414611816406, 'logits/rejected': -1.4368449449539185, 'logits/chosen': -1.4140441417694092, 'epoch': 3.03}

 51%|█████     | 8142/16104 [37:39:17<37:45:37, 17.07s/it]

 51%|█████     | 8143/16104 [37:39:35<38:22:36, 17.35s/it]

 51%|█████     | 8144/16104 [37:39:53<39:01:14, 17.65s/it]


 51%|█████     | 8146/16104 [37:40:21<33:56:13, 15.35s/it]
{'loss': 0.6517, 'learning_rate': 1.0297622953253415e-06, 'rewards/chosen': -1.1952154636383057, 'rewards/rejected': -1.7212483882904053, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5260327458381653, 'policy_logps/rejected': -397.1574401855469, 'policy_logps/chosen': -334.24090576171875, 'referece_logps/rejected': -379.94500732421875, 'referece_logps/chosen': -322.28875732421875, 'logits/rejected': -0.8940181136131287, 'logits/chosen': -0.7888611555099487, 'epoch': 3.04}

 51%|█████     | 8147/16104 [37:40:32<31:05:51, 14.07s/it]

 51%|█████     | 8148/16104 [37:40:48<32:14:12, 14.59s/it]

 51%|█████     | 8149/16104 [37:41:07<35:30:45, 16.07s/it]

 51%|█████     | 8150/16104 [37:41:23<35:39:22, 16.14s/it]

 51%|█████     | 8151/16104 [37:41:43<37:59:42, 17.20s/it]


 51%|█████     | 8153/16104 [37:42:21<39:26:26, 17.86s/it]
{'loss': 0.5203, 'learning_rate': 1.028355005947981e-06, 'rewards/chosen': -0.8264610171318054, 'rewards/rejected': -1.6666603088378906, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8401992321014404, 'policy_logps/rejected': -284.74981689453125, 'policy_logps/chosen': -272.81951904296875, 'referece_logps/rejected': -268.0832214355469, 'referece_logps/chosen': -264.554931640625, 'logits/rejected': -1.523891806602478, 'logits/chosen': -1.4363558292388916, 'epoch': 3.04}

 51%|█████     | 8154/16104 [37:42:40<40:31:59, 18.35s/it]


 51%|█████     | 8156/16104 [37:43:13<38:40:37, 17.52s/it]
{'loss': 0.5887, 'learning_rate': 1.0277518645613025e-06, 'rewards/chosen': -1.5707457065582275, 'rewards/rejected': -2.006589889526367, 'rewards/accuracies': 0.625, 'rewards/margins': 0.43584415316581726, 'policy_logps/rejected': -363.7474670410156, 'policy_logps/chosen': -426.6484375, 'referece_logps/rejected': -343.68157958984375, 'referece_logps/chosen': -410.9410095214844, 'logits/rejected': -0.582548975944519, 'logits/chosen': -0.5821928381919861, 'epoch': 3.04}


 51%|█████     | 8158/16104 [37:43:45<36:20:27, 16.46s/it]

 51%|█████     | 8159/16104 [37:44:05<38:54:22, 17.63s/it]

 51%|█████     | 8160/16104 [37:44:17<35:06:58, 15.91s/it]

 51%|█████     | 8161/16104 [37:44:33<35:08:34, 15.93s/it]
{'loss': 0.5248, 'learning_rate': 1.026746606573028e-06, 'rewards/chosen': -1.0393410921096802, 'rewards/rejected': -1.7076852321624756, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6683441996574402, 'policy_logps/rejected': -256.7235107421875, 'policy_logps/chosen': -277.82318115234375, 'referece_logps/rejected': -239.6466827392578, 'referece_logps/chosen': -267.4297790527344, 'logits/rejected': -0.7026879787445068, 'logits/chosen': -0.753828763961792, 'epoch': 3.04}

 51%|█████     | 8162/16104 [37:44:50<36:12:48, 16.42s/it]

 51%|█████     | 8163/16104 [37:45:06<35:38:07, 16.16s/it]

 51%|█████     | 8164/16104 [37:45:20<34:07:32, 15.47s/it]

 51%|█████     | 8165/16104 [37:45:36<34:28:18, 15.63s/it]


 51%|█████     | 8167/16104 [37:46:15<38:59:29, 17.69s/it]
{'loss': 0.4466, 'learning_rate': 1.0255402613722828e-06, 'rewards/chosen': -1.258431077003479, 'rewards/rejected': -1.6181623935699463, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3597312569618225, 'policy_logps/rejected': -275.71533203125, 'policy_logps/chosen': -233.08624267578125, 'referece_logps/rejected': -259.53369140625, 'referece_logps/chosen': -220.50193786621094, 'logits/rejected': -1.4337459802627563, 'logits/chosen': -1.364648699760437, 'epoch': 3.04}


 51%|█████     | 8169/16104 [37:46:51<39:07:36, 17.75s/it]
{'loss': 0.4456, 'learning_rate': 1.0251381379534204e-06, 'rewards/chosen': -0.7882686257362366, 'rewards/rejected': -3.1009044647216797, 'rewards/accuracies': 1.0, 'rewards/margins': 2.312635660171509, 'policy_logps/rejected': -502.7713623046875, 'policy_logps/chosen': -473.47235107421875, 'referece_logps/rejected': -471.76239013671875, 'referece_logps/chosen': -465.5896911621094, 'logits/rejected': -0.03550043702125549, 'logits/chosen': -0.07945835590362549, 'epoch': 3.04}

 51%|█████     | 8170/16104 [37:47:10<39:41:51, 18.01s/it]


 51%|█████     | 8172/16104 [37:47:43<37:46:47, 17.15s/it]
{'loss': 0.5707, 'learning_rate': 1.0245349452188413e-06, 'rewards/chosen': -0.9974762201309204, 'rewards/rejected': -2.467796802520752, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4703205823898315, 'policy_logps/rejected': -727.1719970703125, 'policy_logps/chosen': -571.3193359375, 'referece_logps/rejected': -702.4940185546875, 'referece_logps/chosen': -561.344482421875, 'logits/rejected': -0.5450354218482971, 'logits/chosen': -0.43944352865219116, 'epoch': 3.04}


 51%|█████     | 8174/16104 [37:48:17<37:52:25, 17.19s/it]
{'loss': 0.3938, 'learning_rate': 1.0241328117531546e-06, 'rewards/chosen': -0.8079980611801147, 'rewards/rejected': -2.0094189643859863, 'rewards/accuracies': 0.75, 'rewards/margins': 1.201420783996582, 'policy_logps/rejected': -508.47711181640625, 'policy_logps/chosen': -353.1104736328125, 'referece_logps/rejected': -488.3829345703125, 'referece_logps/chosen': -345.03045654296875, 'logits/rejected': -0.661119282245636, 'logits/chosen': -0.4270293712615967, 'epoch': 3.05}

 51%|█████     | 8175/16104 [37:48:38<40:31:01, 18.40s/it]

 51%|█████     | 8176/16104 [37:48:56<39:57:54, 18.15s/it]

 51%|█████     | 8177/16104 [37:49:17<41:51:51, 19.01s/it]


 51%|█████     | 8179/16104 [37:49:49<39:38:00, 18.00s/it]

 51%|█████     | 8180/16104 [37:50:09<40:55:59, 18.60s/it]
{'loss': 0.3839, 'learning_rate': 1.0229263881872027e-06, 'rewards/chosen': -0.7003160715103149, 'rewards/rejected': -2.9124135971069336, 'rewards/accuracies': 0.875, 'rewards/margins': 2.212097644805908, 'policy_logps/rejected': -456.579345703125, 'policy_logps/chosen': -425.06573486328125, 'referece_logps/rejected': -427.4552307128906, 'referece_logps/chosen': -418.0625915527344, 'logits/rejected': 0.37183094024658203, 'logits/chosen': 0.37532705068588257, 'epoch': 3.05}


 51%|█████     | 8182/16104 [37:50:47<41:26:53, 18.84s/it]
{'loss': 0.5798, 'learning_rate': 1.0225242394924864e-06, 'rewards/chosen': -0.9471079111099243, 'rewards/rejected': -2.0549232959747314, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1078155040740967, 'policy_logps/rejected': -409.7080993652344, 'policy_logps/chosen': -381.8312072753906, 'referece_logps/rejected': -389.1589050292969, 'referece_logps/chosen': -372.3601379394531, 'logits/rejected': -1.2594218254089355, 'logits/chosen': -1.3387352228164673, 'epoch': 3.05}

 51%|█████     | 8183/16104 [37:50:58<36:06:28, 16.41s/it]

 51%|█████     | 8184/16104 [37:51:13<35:08:20, 15.97s/it]

 51%|█████     | 8185/16104 [37:51:32<37:20:45, 16.98s/it]


 51%|█████     | 8187/16104 [37:52:13<41:29:19, 18.87s/it]
{'loss': 0.5149, 'learning_rate': 1.0215188519529885e-06, 'rewards/chosen': -0.9680134654045105, 'rewards/rejected': -2.328031063079834, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3600175380706787, 'policy_logps/rejected': -408.2314758300781, 'policy_logps/chosen': -382.03704833984375, 'referece_logps/rejected': -384.951171875, 'referece_logps/chosen': -372.3569641113281, 'logits/rejected': 0.13004283607006073, 'logits/chosen': 0.048782508820295334, 'epoch': 3.05}


 51%|█████     | 8189/16104 [37:52:45<37:40:28, 17.14s/it]
{'loss': 0.5392, 'learning_rate': 1.02111669078692e-06, 'rewards/chosen': -1.4468728303909302, 'rewards/rejected': -2.1273255348205566, 'rewards/accuracies': 0.5, 'rewards/margins': 0.6804524660110474, 'policy_logps/rejected': -383.7588806152344, 'policy_logps/chosen': -329.0676574707031, 'referece_logps/rejected': -362.48565673828125, 'referece_logps/chosen': -314.5989074707031, 'logits/rejected': -0.908437967300415, 'logits/chosen': -0.8188410401344299, 'epoch': 3.05}


 51%|█████     | 8191/16104 [37:53:15<34:34:15, 15.73s/it]
{'loss': 0.584, 'learning_rate': 1.0207145262040197e-06, 'rewards/chosen': -0.7509734034538269, 'rewards/rejected': -1.7435847520828247, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9926115274429321, 'policy_logps/rejected': -320.54473876953125, 'policy_logps/chosen': -346.1478271484375, 'referece_logps/rejected': -303.1089172363281, 'referece_logps/chosen': -338.6380920410156, 'logits/rejected': -1.3029805421829224, 'logits/chosen': -1.3285220861434937, 'epoch': 3.05}

 51%|█████     | 8192/16104 [37:53:30<34:06:56, 15.52s/it]

 51%|█████     | 8193/16104 [37:53:45<33:31:45, 15.26s/it]

 51%|█████     | 8194/16104 [37:54:00<33:38:32, 15.31s/it]

 51%|█████     | 8195/16104 [37:54:17<34:15:06, 15.59s/it]

 51%|█████     | 8196/16104 [37:54:36<36:57:31, 16.82s/it]

 51%|█████     | 8197/16104 [37:54:51<35:43:17, 16.26s/it]

 51%|█████     | 8198/16104 [37:55:11<37:57:25, 17.28s/it]

 51%|█████     | 8199/16104 [37:55:29<38:32:54, 17.56s/it]

 51%|█████     | 8200/16104 [37:55:51<41:34:25, 18.94s/it]

 51%|█████     | 8201/16104 [37:56:05<38:13:26, 17.41s/it]

 51%|█████     | 8202/16104 [37:56:25<39:32:59, 18.02s/it]

 51%|█████     | 8203/16104 [37:56:39<37:21:16, 17.02s/it]


 51%|█████     | 8205/16104 [37:57:08<34:35:06, 15.76s/it]
{'loss': 0.4497, 'learning_rate': 1.0178992839186522e-06, 'rewards/chosen': -0.8368305563926697, 'rewards/rejected': -1.686421275138855, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8495907187461853, 'policy_logps/rejected': -364.98822021484375, 'policy_logps/chosen': -376.3666687011719, 'referece_logps/rejected': -348.1240234375, 'referece_logps/chosen': -367.99835205078125, 'logits/rejected': -1.2928849458694458, 'logits/chosen': -1.182859182357788, 'epoch': 3.06}

 51%|█████     | 8206/16104 [37:57:19<31:30:14, 14.36s/it]

 51%|█████     | 8207/16104 [37:57:33<31:12:21, 14.23s/it]


 51%|█████     | 8209/16104 [37:58:04<33:20:11, 15.20s/it]

 51%|█████     | 8210/16104 [37:58:16<31:16:16, 14.26s/it]
{'loss': 0.562, 'learning_rate': 1.0168938046933883e-06, 'rewards/chosen': -1.0983189344406128, 'rewards/rejected': -1.8312674760818481, 'rewards/accuracies': 0.5, 'rewards/margins': 0.7329486608505249, 'policy_logps/rejected': -597.9801025390625, 'policy_logps/chosen': -372.8927917480469, 'referece_logps/rejected': -579.6674194335938, 'referece_logps/chosen': -361.9096374511719, 'logits/rejected': 0.16564655303955078, 'logits/chosen': 0.24700134992599487, 'epoch': 3.06}

 51%|█████     | 8211/16104 [37:58:32<32:45:46, 14.94s/it]

 51%|█████     | 8212/16104 [37:58:47<32:34:27, 14.86s/it]


 51%|█████     | 8214/16104 [37:59:18<34:07:27, 15.57s/it]
{'loss': 0.6046, 'learning_rate': 1.0160894089634475e-06, 'rewards/chosen': -1.0954887866973877, 'rewards/rejected': -1.4239134788513184, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3284246623516083, 'policy_logps/rejected': -440.6494445800781, 'policy_logps/chosen': -490.0627136230469, 'referece_logps/rejected': -426.4102783203125, 'referece_logps/chosen': -479.10784912109375, 'logits/rejected': -1.2589741945266724, 'logits/chosen': -1.2172436714172363, 'epoch': 3.06}

 51%|█████     | 8215/16104 [37:59:34<34:28:52, 15.73s/it]

 51%|█████     | 8216/16104 [37:59:45<31:08:13, 14.21s/it]

 51%|█████     | 8217/16104 [37:59:57<29:55:02, 13.66s/it]

 51%|█████     | 8218/16104 [38:00:15<32:22:37, 14.78s/it]

 51%|█████     | 8219/16104 [38:00:25<29:42:22, 13.56s/it]

 51%|█████     | 8220/16104 [38:00:43<32:32:47, 14.86s/it]

 51%|█████     | 8221/16104 [38:01:00<33:59:30, 15.52s/it]


 51%|█████     | 8223/16104 [38:01:32<33:36:40, 15.35s/it]

 51%|█████     | 8224/16104 [38:01:52<36:37:34, 16.73s/it]
{'loss': 0.384, 'learning_rate': 1.0140783752183164e-06, 'rewards/chosen': -0.5609908103942871, 'rewards/rejected': -2.58516526222229, 'rewards/accuracies': 0.5, 'rewards/margins': 2.024174451828003, 'policy_logps/rejected': -370.5879821777344, 'policy_logps/chosen': -363.53790283203125, 'referece_logps/rejected': -344.7362976074219, 'referece_logps/chosen': -357.92803955078125, 'logits/rejected': -0.8737276792526245, 'logits/chosen': -0.9224978685379028, 'epoch': 3.06}


 51%|█████     | 8226/16104 [38:02:28<37:55:20, 17.33s/it]
{'loss': 0.4719, 'learning_rate': 1.0136761613750242e-06, 'rewards/chosen': -1.1814931631088257, 'rewards/rejected': -1.5778169631958008, 'rewards/accuracies': 0.625, 'rewards/margins': 0.39632391929626465, 'policy_logps/rejected': -303.04632568359375, 'policy_logps/chosen': -290.53985595703125, 'referece_logps/rejected': -287.26812744140625, 'referece_logps/chosen': -278.7249450683594, 'logits/rejected': -0.5103448629379272, 'logits/chosen': -0.601106584072113, 'epoch': 3.06}

 51%|█████     | 8227/16104 [38:02:45<37:55:35, 17.33s/it]

 51%|█████     | 8228/16104 [38:03:03<38:29:11, 17.59s/it]

 51%|█████     | 8229/16104 [38:03:22<38:49:32, 17.75s/it]

 51%|█████     | 8230/16104 [38:03:39<38:39:36, 17.68s/it]

 51%|█████     | 8231/16104 [38:03:52<35:23:29, 16.18s/it]


 51%|█████     | 8233/16104 [38:04:14<29:47:54, 13.63s/it]

 51%|█████     | 8234/16104 [38:04:28<29:55:07, 13.69s/it]
{'loss': 0.5082, 'learning_rate': 1.0120672845236645e-06, 'rewards/chosen': -0.5141620635986328, 'rewards/rejected': -1.5142203569412231, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0000581741333008, 'policy_logps/rejected': -413.46380615234375, 'policy_logps/chosen': -573.2548828125, 'referece_logps/rejected': -398.3215637207031, 'referece_logps/chosen': -568.11328125, 'logits/rejected': -1.5378873348236084, 'logits/chosen': -1.577452540397644, 'epoch': 3.07}

 51%|█████     | 8235/16104 [38:04:43<30:44:27, 14.06s/it]


 51%|█████     | 8237/16104 [38:05:14<33:17:19, 15.23s/it]

 51%|█████     | 8238/16104 [38:05:26<31:20:13, 14.34s/it]
{'loss': 0.5311, 'learning_rate': 1.0112628341222199e-06, 'rewards/chosen': -0.7915698289871216, 'rewards/rejected': -2.797015428543091, 'rewards/accuracies': 0.75, 'rewards/margins': 2.005445718765259, 'policy_logps/rejected': -467.72998046875, 'policy_logps/chosen': -487.26953125, 'referece_logps/rejected': -439.7597961425781, 'referece_logps/chosen': -479.35382080078125, 'logits/rejected': -0.8666369915008545, 'logits/chosen': -0.8441567420959473, 'epoch': 3.07}

 51%|█████     | 8239/16104 [38:05:45<33:46:06, 15.46s/it]


 51%|█████     | 8241/16104 [38:06:20<36:45:31, 16.83s/it]
{'loss': 0.4636, 'learning_rate': 1.0106594915088443e-06, 'rewards/chosen': -0.6287624835968018, 'rewards/rejected': -1.992679238319397, 'rewards/accuracies': 0.625, 'rewards/margins': 1.3639167547225952, 'policy_logps/rejected': -382.77197265625, 'policy_logps/chosen': -413.9002990722656, 'referece_logps/rejected': -362.8451843261719, 'referece_logps/chosen': -407.6126708984375, 'logits/rejected': -0.7930507063865662, 'logits/chosen': -0.9111010432243347, 'epoch': 3.07}

 51%|█████     | 8242/16104 [38:06:32<33:06:53, 15.16s/it]

 51%|█████     | 8243/16104 [38:06:45<31:56:51, 14.63s/it]


 51%|█████     | 8245/16104 [38:07:10<30:13:57, 13.85s/it]
{'loss': 0.4601, 'learning_rate': 1.0098550286922394e-06, 'rewards/chosen': -1.0725467205047607, 'rewards/rejected': -1.803647518157959, 'rewards/accuracies': 0.5, 'rewards/margins': 0.731100857257843, 'policy_logps/rejected': -339.34539794921875, 'policy_logps/chosen': -359.17291259765625, 'referece_logps/rejected': -321.3089599609375, 'referece_logps/chosen': -348.4474182128906, 'logits/rejected': -0.7384182214736938, 'logits/chosen': -0.9107743501663208, 'epoch': 3.07}

 51%|█████     | 8246/16104 [38:07:23<29:16:59, 13.42s/it]

 51%|█████     | 8247/16104 [38:07:33<27:28:54, 12.59s/it]

 51%|█████     | 8248/16104 [38:07:49<29:29:52, 13.52s/it]

 51%|█████     | 8249/16104 [38:08:00<27:37:35, 12.66s/it]

 51%|█████     | 8250/16104 [38:08:17<30:25:51, 13.95s/it]


 51%|█████     | 8252/16104 [38:08:42<28:47:03, 13.20s/it]

 51%|█████     | 8253/16104 [38:08:55<28:04:17, 12.87s/it]
{'loss': 0.5884, 'learning_rate': 1.0082460844443385e-06, 'rewards/chosen': -1.0476139783859253, 'rewards/rejected': -0.9778355360031128, 'rewards/accuracies': 0.375, 'rewards/margins': -0.06977836787700653, 'policy_logps/rejected': -413.1426696777344, 'policy_logps/chosen': -410.2221984863281, 'referece_logps/rejected': -403.3642883300781, 'referece_logps/chosen': -399.74609375, 'logits/rejected': -0.37657612562179565, 'logits/chosen': -0.3444730341434479, 'epoch': 3.07}


 51%|█████▏    | 8255/16104 [38:09:20<27:36:48, 12.67s/it]

 51%|█████▏    | 8256/16104 [38:09:37<30:03:51, 13.79s/it]
{'loss': 0.5197, 'learning_rate': 1.0076427246237606e-06, 'rewards/chosen': -1.533192753791809, 'rewards/rejected': -2.230440139770508, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6972475051879883, 'policy_logps/rejected': -425.22186279296875, 'policy_logps/chosen': -380.3455810546875, 'referece_logps/rejected': -402.9174499511719, 'referece_logps/chosen': -365.01361083984375, 'logits/rejected': -0.9004544615745544, 'logits/chosen': -0.7724562883377075, 'epoch': 3.08}

 51%|█████▏    | 8257/16104 [38:09:56<33:51:00, 15.53s/it]

 51%|█████▏    | 8258/16104 [38:10:16<36:19:12, 16.66s/it]

 51%|█████▏    | 8259/16104 [38:10:33<36:42:46, 16.85s/it]

 51%|█████▏    | 8260/16104 [38:10:48<35:18:30, 16.20s/it]

 51%|█████▏    | 8261/16104 [38:11:07<37:13:42, 17.09s/it]

 51%|█████▏    | 8262/16104 [38:11:22<36:01:45, 16.54s/it]

 51%|█████▏    | 8263/16104 [38:11:38<35:56:12, 16.50s/it]

 51%|█████▏    | 8264/16104 [38:11:58<37:45:58, 17.34s/it]

 51%|█████▏    | 8265/16104 [38:12:09<33:41:54, 15.48s/it]

 51%|█████▏    | 8266/16104 [38:12:29<37:05:57, 17.04s/it]

 51%|█████▏    | 8267/16104 [38:12:41<33:36:17, 15.44s/it]

 51%|█████▏    | 8268/16104 [38:12:58<34:41:23, 15.94s/it]

 51%|█████▏    | 8269/16104 [38:13:17<36:25:15, 16.73s/it]

 51%|█████▏    | 8270/16104 [38:13:34<36:39:30, 16.85s/it]

 51%|█████▏    | 8271/16104 [38:13:54<38:56:44, 17.90s/it]

 51%|█████▏    | 8272/16104 [38:14:12<38:56:51, 17.90s/it]

 51%|█████▏    | 8273/16104 [38:14:26<35:58:16, 16.54s/it]

 51%|█████▏    | 8274/16104 [38:14:37<32:29:09, 14.94s/it]

 51%|█████▏    | 8275/16104 [38:14:50<31:08:52, 14.32s/it]

 51%|█████▏    | 8276/16104 [38:15:03<30:34:17, 14.06s/it]

 51%|█████▏    | 8277/16104 [38:15:23<34:22:45, 15.81s/it]

 51%|█████▏    | 8278/16104 [38:15:43<37:18:14, 17.16s/it]

 51%|█████▏    | 8279/16104 [38:16:01<37:33:11, 17.28s/it]

 51%|█████▏    | 8280/16104 [38:16:23<40:40:36, 18.72s/it]

 51%|█████▏    | 8281/16104 [38:16:41<40:31:59, 18.65s/it]

 51%|█████▏    | 8282/16104 [38:17:01<41:07:10, 18.92s/it]

 51%|█████▏    | 8283/16104 [38:17:21<42:03:27, 19.36s/it]

 51%|█████▏    | 8284/16104 [38:17:35<38:18:28, 17.64s/it]

 51%|█████▏    | 8285/16104 [38:17:55<39:31:50, 18.20s/it]

 51%|█████▏    | 8286/16104 [38:18:14<40:32:55, 18.67s/it]

 51%|█████▏    | 8287/16104 [38:18:26<36:07:04, 16.63s/it]

 51%|█████▏    | 8288/16104 [38:18:37<32:20:21, 14.90s/it]

 51%|█████▏    | 8289/16104 [38:18:54<33:25:18, 15.40s/it]

 51%|█████▏    | 8290/16104 [38:19:12<35:30:56, 16.36s/it]

 51%|█████▏    | 8291/16104 [38:19:30<36:09:32, 16.66s/it]

 51%|█████▏    | 8292/16104 [38:19:52<39:40:43, 18.29s/it]

 51%|█████▏    | 8293/16104 [38:20:07<37:35:41, 17.33s/it]

 52%|█████▏    | 8294/16104 [38:20:24<37:46:58, 17.42s/it]

 52%|█████▏    | 8295/16104 [38:20:39<35:57:20, 16.58s/it]

 52%|█████▏    | 8296/16104 [38:20:52<33:57:03, 15.65s/it]

 52%|█████▏    | 8297/16104 [38:21:05<31:49:10, 14.67s/it]

 52%|█████▏    | 8298/16104 [38:21:18<30:39:38, 14.14s/it]

 52%|█████▏    | 8299/16104 [38:21:29<28:47:31, 13.28s/it]

 52%|█████▏    | 8300/16104 [38:21:47<31:55:36, 14.73s/it]


 52%|█████▏    | 8302/16104 [38:22:19<34:12:19, 15.78s/it]

 52%|█████▏    | 8303/16104 [38:22:33<32:57:35, 15.21s/it]

 52%|█████▏    | 8304/16104 [38:22:48<32:53:46, 15.18s/it]

 52%|█████▏    | 8305/16104 [38:23:08<35:53:03, 16.56s/it]

 52%|█████▏    | 8306/16104 [38:23:28<38:18:56, 17.69s/it]

 52%|█████▏    | 8307/16104 [38:23:43<36:27:10, 16.83s/it]

 52%|█████▏    | 8308/16104 [38:23:55<33:14:53, 15.35s/it]

 52%|█████▏    | 8309/16104 [38:24:14<35:46:44, 16.52s/it]

 52%|█████▏    | 8310/16104 [38:24:27<33:25:35, 15.44s/it]

 52%|█████▏    | 8311/16104 [38:24:40<31:25:33, 14.52s/it]

 52%|█████▏    | 8312/16104 [38:25:00<34:54:14, 16.13s/it]

 52%|█████▏    | 8313/16104 [38:25:19<37:09:57, 17.17s/it]

 52%|█████▏    | 8314/16104 [38:25:39<39:04:28, 18.06s/it]

 52%|█████▏    | 8315/16104 [38:26:00<40:29:48, 18.72s/it]

 52%|█████▏    | 8316/16104 [38:26:16<39:04:12, 18.06s/it]

 52%|█████▏    | 8317/16104 [38:26:28<35:13:51, 16.29s/it]

 52%|█████▏    | 8318/16104 [38:26:44<35:12:07, 16.28s/it]

 52%|█████▏    | 8319/16104 [38:27:01<35:23:22, 16.37s/it]

 52%|█████▏    | 8320/16104 [38:27:20<37:02:06, 17.13s/it]

 52%|█████▏    | 8321/16104 [38:27:37<36:47:31, 17.02s/it]

 52%|█████▏    | 8322/16104 [38:27:58<39:47:11, 18.41s/it]

 52%|█████▏    | 8323/16104 [38:28:15<38:41:49, 17.90s/it]

 52%|█████▏    | 8324/16104 [38:28:33<38:53:12, 17.99s/it]

 52%|█████▏    | 8325/16104 [38:28:51<38:50:08, 17.97s/it]

 52%|█████▏    | 8326/16104 [38:29:11<40:01:45, 18.53s/it]

 52%|█████▏    | 8327/16104 [38:29:28<39:10:16, 18.13s/it]
{'loss': 0.3974, 'learning_rate': 9.933628811519632e-07, 'rewards/chosen': -1.3133615255355835, 'rewards/rejected': -2.2181689739227295, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9048073887825012, 'policy_logps/rejected': -328.2396240234375, 'policy_logps/chosen': -292.436767578125, 'referece_logps/rejected': -306.05792236328125, 'referece_logps/chosen': -279.3031311035156, 'logits/rejected': -0.9106292128562927, 'logits/chosen': -0.8766957521438599, 'epoch': 3.1}


 52%|█████▏    | 8329/16104 [38:29:54<33:24:16, 15.47s/it]

 52%|█████▏    | 8330/16104 [38:30:12<34:31:04, 15.98s/it]

 52%|█████▏    | 8331/16104 [38:30:29<35:09:49, 16.29s/it]

 52%|█████▏    | 8332/16104 [38:30:46<35:37:00, 16.50s/it]

 52%|█████▏    | 8333/16104 [38:31:00<34:05:33, 15.79s/it]

 52%|█████▏    | 8334/16104 [38:31:18<35:43:16, 16.55s/it]

 52%|█████▏    | 8335/16104 [38:31:29<32:06:13, 14.88s/it]

 52%|█████▏    | 8336/16104 [38:31:40<29:27:53, 13.66s/it]

 52%|█████▏    | 8337/16104 [38:32:00<33:35:35, 15.57s/it]

 52%|█████▏    | 8338/16104 [38:32:12<31:37:31, 14.66s/it]

 52%|█████▏    | 8339/16104 [38:32:26<30:52:43, 14.32s/it]

 52%|█████▏    | 8340/16104 [38:32:44<33:21:14, 15.47s/it]

 52%|█████▏    | 8341/16104 [38:33:03<35:24:23, 16.42s/it]

 52%|█████▏    | 8342/16104 [38:33:19<35:21:53, 16.40s/it]

 52%|█████▏    | 8343/16104 [38:33:39<37:40:01, 17.47s/it]

 52%|█████▏    | 8344/16104 [38:33:59<39:15:30, 18.21s/it]

 52%|█████▏    | 8345/16104 [38:34:10<34:24:27, 15.96s/it]

 52%|█████▏    | 8346/16104 [38:34:30<36:58:13, 17.16s/it]

 52%|█████▏    | 8347/16104 [38:34:41<33:00:18, 15.32s/it]

 52%|█████▏    | 8348/16104 [38:34:52<30:11:24, 14.01s/it]

 52%|█████▏    | 8349/16104 [38:35:03<28:50:56, 13.39s/it]
{'loss': 0.5551, 'learning_rate': 9.889382796374844e-07, 'rewards/chosen': -0.4593219459056854, 'rewards/rejected': -1.2701818943023682, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8108599185943604, 'policy_logps/rejected': -457.9600524902344, 'policy_logps/chosen': -460.16546630859375, 'referece_logps/rejected': -445.25823974609375, 'referece_logps/chosen': -455.57220458984375, 'logits/rejected': -0.6402637958526611, 'logits/chosen': -0.5959185361862183, 'epoch': 3.11}


 52%|█████▏    | 8351/16104 [38:35:46<37:26:37, 17.39s/it]

 52%|█████▏    | 8352/16104 [38:36:03<37:10:36, 17.26s/it]

 52%|█████▏    | 8353/16104 [38:36:19<36:43:43, 17.06s/it]

 52%|█████▏    | 8354/16104 [38:36:39<38:22:06, 17.82s/it]

 52%|█████▏    | 8355/16104 [38:36:58<39:24:51, 18.31s/it]

 52%|█████▏    | 8356/16104 [38:37:19<40:36:37, 18.87s/it]

 52%|█████▏    | 8357/16104 [38:37:35<39:03:43, 18.15s/it]

 52%|█████▏    | 8358/16104 [38:37:46<34:33:38, 16.06s/it]

 52%|█████▏    | 8359/16104 [38:38:05<36:33:23, 16.99s/it]
{'loss': 0.541, 'learning_rate': 9.869271635187657e-07, 'rewards/chosen': -0.9694330096244812, 'rewards/rejected': -1.9151904582977295, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9457575678825378, 'policy_logps/rejected': -420.3079833984375, 'policy_logps/chosen': -412.95758056640625, 'referece_logps/rejected': -401.15606689453125, 'referece_logps/chosen': -403.26324462890625, 'logits/rejected': -0.9148851633071899, 'logits/chosen': -0.9501065015792847, 'epoch': 3.11}


 52%|█████▏    | 8361/16104 [38:38:37<35:51:00, 16.67s/it]

 52%|█████▏    | 8362/16104 [38:38:50<33:30:57, 15.58s/it]

 52%|█████▏    | 8363/16104 [38:39:05<32:42:03, 15.21s/it]

 52%|█████▏    | 8364/16104 [38:39:20<32:35:25, 15.16s/it]

 52%|█████▏    | 8365/16104 [38:39:41<36:53:54, 17.16s/it]

 52%|█████▏    | 8366/16104 [38:39:56<35:14:19, 16.39s/it]

 52%|█████▏    | 8367/16104 [38:40:16<37:17:07, 17.35s/it]

 52%|█████▏    | 8368/16104 [38:40:35<38:38:36, 17.98s/it]
{'loss': 0.5513, 'learning_rate': 9.851172039941238e-07, 'rewards/chosen': -0.8876375555992126, 'rewards/rejected': -0.9318925738334656, 'rewards/accuracies': 0.625, 'rewards/margins': 0.04425507038831711, 'policy_logps/rejected': -573.8695068359375, 'policy_logps/chosen': -500.6422119140625, 'referece_logps/rejected': -564.5505981445312, 'referece_logps/chosen': -491.7658386230469, 'logits/rejected': -0.868716835975647, 'logits/chosen': -0.7879410982131958, 'epoch': 3.12}

 52%|█████▏    | 8369/16104 [38:40:53<38:29:01, 17.91s/it]


 52%|█████▏    | 8371/16104 [38:41:22<35:18:51, 16.44s/it]

 52%|█████▏    | 8372/16104 [38:41:42<37:18:16, 17.37s/it]

 52%|█████▏    | 8373/16104 [38:41:59<37:03:19, 17.26s/it]

 52%|█████▏    | 8374/16104 [38:42:18<38:05:09, 17.74s/it]
{'loss': 0.4793, 'learning_rate': 9.839105910365524e-07, 'rewards/chosen': -0.8984724283218384, 'rewards/rejected': -1.5787835121154785, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6803112030029297, 'policy_logps/rejected': -239.34120178222656, 'policy_logps/chosen': -261.84930419921875, 'referece_logps/rejected': -223.55337524414062, 'referece_logps/chosen': -252.86460876464844, 'logits/rejected': -0.6128125190734863, 'logits/chosen': -0.7572455406188965, 'epoch': 3.12}

 52%|█████▏    | 8375/16104 [38:42:37<39:20:33, 18.32s/it]

 52%|█████▏    | 8376/16104 [38:42:49<35:14:23, 16.42s/it]


 52%|█████▏    | 8378/16104 [38:43:15<31:25:33, 14.64s/it]
{'loss': 0.499, 'learning_rate': 9.831061953066116e-07, 'rewards/chosen': -0.7096326947212219, 'rewards/rejected': -1.347254753112793, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6376219987869263, 'policy_logps/rejected': -281.0806884765625, 'policy_logps/chosen': -378.1824645996094, 'referece_logps/rejected': -267.608154296875, 'referece_logps/chosen': -371.08612060546875, 'logits/rejected': -0.6001895070075989, 'logits/chosen': -0.5571573376655579, 'epoch': 3.12}


 52%|█████▏    | 8380/16104 [38:43:47<32:05:33, 14.96s/it]

 52%|█████▏    | 8381/16104 [38:44:02<32:12:58, 15.02s/it]
{'loss': 0.5602, 'learning_rate': 9.825029056562222e-07, 'rewards/chosen': -0.8205744028091431, 'rewards/rejected': -1.7758307456970215, 'rewards/accuracies': 0.875, 'rewards/margins': 0.955256462097168, 'policy_logps/rejected': -335.17852783203125, 'policy_logps/chosen': -391.232177734375, 'referece_logps/rejected': -317.42022705078125, 'referece_logps/chosen': -383.0264892578125, 'logits/rejected': -0.7024334669113159, 'logits/chosen': -0.7509987354278564, 'epoch': 3.12}


 52%|█████▏    | 8383/16104 [38:44:26<28:33:32, 13.32s/it]

 52%|█████▏    | 8384/16104 [38:44:37<27:04:14, 12.62s/it]

 52%|█████▏    | 8385/16104 [38:44:53<29:20:55, 13.69s/it]
{'loss': 0.5399, 'learning_rate': 9.816985294027052e-07, 'rewards/chosen': -0.6902633905410767, 'rewards/rejected': -1.4909712076187134, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8007078766822815, 'policy_logps/rejected': -276.06109619140625, 'policy_logps/chosen': -318.75836181640625, 'referece_logps/rejected': -261.1513671875, 'referece_logps/chosen': -311.8557434082031, 'logits/rejected': -1.1021521091461182, 'logits/chosen': -1.1361110210418701, 'epoch': 3.12}


 52%|█████▏    | 8387/16104 [38:45:26<32:44:49, 15.28s/it]

 52%|█████▏    | 8388/16104 [38:45:38<31:00:18, 14.47s/it]

 52%|█████▏    | 8389/16104 [38:45:54<31:39:16, 14.77s/it]

 52%|█████▏    | 8390/16104 [38:46:14<34:58:02, 16.32s/it]

 52%|█████▏    | 8391/16104 [38:46:36<38:42:04, 18.06s/it]

 52%|█████▏    | 8392/16104 [38:46:58<41:28:38, 19.36s/it]

 52%|█████▏    | 8393/16104 [38:47:18<41:36:51, 19.43s/it]
{'loss': 0.479, 'learning_rate': 9.800898129519808e-07, 'rewards/chosen': -1.0609453916549683, 'rewards/rejected': -1.8152743577957153, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7543289661407471, 'policy_logps/rejected': -488.5793762207031, 'policy_logps/chosen': -402.44073486328125, 'referece_logps/rejected': -470.4266357421875, 'referece_logps/chosen': -391.831298828125, 'logits/rejected': -1.0245665311813354, 'logits/chosen': -1.0334099531173706, 'epoch': 3.13}

 52%|█████▏    | 8394/16104 [38:47:36<40:37:35, 18.97s/it]


 52%|█████▏    | 8396/16104 [38:48:00<33:26:44, 15.62s/it]

 52%|█████▏    | 8397/16104 [38:48:19<35:04:24, 16.38s/it]

 52%|█████▏    | 8398/16104 [38:48:32<33:10:51, 15.50s/it]

 52%|█████▏    | 8399/16104 [38:48:45<31:17:36, 14.62s/it]

 52%|█████▏    | 8400/16104 [38:49:00<31:59:29, 14.95s/it]

 52%|█████▏    | 8401/16104 [38:49:18<33:47:47, 15.79s/it]

 52%|█████▏    | 8402/16104 [38:49:35<34:17:43, 16.03s/it]

 52%|█████▏    | 8403/16104 [38:49:53<35:30:38, 16.60s/it]

 52%|█████▏    | 8404/16104 [38:50:05<32:56:27, 15.40s/it]

 52%|█████▏    | 8405/16104 [38:50:19<31:48:36, 14.87s/it]
{'loss': 0.55, 'learning_rate': 9.776768362256574e-07, 'rewards/chosen': -0.575208306312561, 'rewards/rejected': -1.48397696018219, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9087686538696289, 'policy_logps/rejected': -403.8354187011719, 'policy_logps/chosen': -365.39569091796875, 'referece_logps/rejected': -388.99566650390625, 'referece_logps/chosen': -359.6436462402344, 'logits/rejected': 0.042077064514160156, 'logits/chosen': 0.06850564479827881, 'epoch': 3.13}


 52%|█████▏    | 8407/16104 [38:50:43<29:10:05, 13.64s/it]

 52%|█████▏    | 8408/16104 [38:50:54<27:28:22, 12.85s/it]

 52%|█████▏    | 8409/16104 [38:51:14<32:09:10, 15.04s/it]

 52%|█████▏    | 8410/16104 [38:51:35<35:36:29, 16.66s/it]

 52%|█████▏    | 8411/16104 [38:51:49<34:13:02, 16.01s/it]

 52%|█████▏    | 8412/16104 [38:52:03<32:42:22, 15.31s/it]

 52%|█████▏    | 8413/16104 [38:52:21<34:33:14, 16.17s/it]

 52%|█████▏    | 8414/16104 [38:52:34<32:40:41, 15.30s/it]

 52%|█████▏    | 8415/16104 [38:52:48<31:39:39, 14.82s/it]

 52%|█████▏    | 8416/16104 [38:53:03<31:53:17, 14.93s/it]

 52%|█████▏    | 8417/16104 [38:53:23<35:06:28, 16.44s/it]

 52%|█████▏    | 8418/16104 [38:53:35<31:58:37, 14.98s/it]

 52%|█████▏    | 8419/16104 [38:53:55<35:19:09, 16.55s/it]

 52%|█████▏    | 8420/16104 [38:54:15<37:18:25, 17.48s/it]

 52%|█████▏    | 8421/16104 [38:54:25<32:51:37, 15.40s/it]
{'loss': 0.4792, 'learning_rate': 9.744597386277173e-07, 'rewards/chosen': -0.8058897852897644, 'rewards/rejected': -2.203634738922119, 'rewards/accuracies': 1.0, 'rewards/margins': 1.39774489402771, 'policy_logps/rejected': -343.15313720703125, 'policy_logps/chosen': -391.26416015625, 'referece_logps/rejected': -321.1168212890625, 'referece_logps/chosen': -383.20526123046875, 'logits/rejected': 0.10008551180362701, 'logits/chosen': 0.015034130774438381, 'epoch': 3.14}


 52%|█████▏    | 8423/16104 [38:55:03<36:53:17, 17.29s/it]

 52%|█████▏    | 8424/16104 [38:55:19<36:15:42, 17.00s/it]

 52%|█████▏    | 8425/16104 [38:55:30<32:38:53, 15.31s/it]
{'loss': 0.4947, 'learning_rate': 9.736555042528479e-07, 'rewards/chosen': -0.5776005983352661, 'rewards/rejected': -1.2645233869552612, 'rewards/accuracies': 1.0, 'rewards/margins': 0.6869228482246399, 'policy_logps/rejected': -451.0823059082031, 'policy_logps/chosen': -587.9058837890625, 'referece_logps/rejected': -438.43707275390625, 'referece_logps/chosen': -582.1298828125, 'logits/rejected': -0.8700867295265198, 'logits/chosen': -1.066528558731079, 'epoch': 3.14}

 52%|█████▏    | 8426/16104 [38:55:50<35:30:45, 16.65s/it]


 52%|█████▏    | 8428/16104 [38:56:19<33:28:56, 15.70s/it]

 52%|█████▏    | 8429/16104 [38:56:36<34:05:27, 15.99s/it]

 52%|█████▏    | 8430/16104 [38:56:47<31:23:09, 14.72s/it]

 52%|█████▏    | 8431/16104 [38:56:59<29:32:44, 13.86s/it]

 52%|█████▏    | 8432/16104 [38:57:13<29:25:22, 13.81s/it]

 52%|█████▏    | 8433/16104 [38:57:35<34:24:58, 16.15s/it]

 52%|█████▏    | 8434/16104 [38:57:53<36:09:58, 16.98s/it]

 52%|█████▏    | 8435/16104 [38:58:13<37:58:14, 17.82s/it]

 52%|█████▏    | 8436/16104 [38:58:31<37:52:23, 17.78s/it]

 52%|█████▏    | 8437/16104 [38:58:43<34:26:33, 16.17s/it]

 52%|█████▏    | 8438/16104 [38:58:55<31:42:26, 14.89s/it]
{'loss': 0.4682, 'learning_rate': 9.710418629884355e-07, 'rewards/chosen': -0.8439285755157471, 'rewards/rejected': -2.513059139251709, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6691306829452515, 'policy_logps/rejected': -355.5386047363281, 'policy_logps/chosen': -441.8878173828125, 'referece_logps/rejected': -330.40802001953125, 'referece_logps/chosen': -433.44854736328125, 'logits/rejected': -0.7023985385894775, 'logits/chosen': -0.7603951692581177, 'epoch': 3.14}

 52%|█████▏    | 8439/16104 [38:59:12<32:51:40, 15.43s/it]


 52%|█████▏    | 8441/16104 [38:59:39<30:21:16, 14.26s/it]

 52%|█████▏    | 8442/16104 [38:59:57<32:38:54, 15.34s/it]

 52%|█████▏    | 8443/16104 [39:00:17<35:38:35, 16.75s/it]

 52%|█████▏    | 8444/16104 [39:00:31<34:02:34, 16.00s/it]

 52%|█████▏    | 8445/16104 [39:00:51<36:10:15, 17.00s/it]
{'loss': 0.4454, 'learning_rate': 9.696345985522108e-07, 'rewards/chosen': -0.766075849533081, 'rewards/rejected': -2.057044744491577, 'rewards/accuracies': 1.0, 'rewards/margins': 1.290968894958496, 'policy_logps/rejected': -326.3152160644531, 'policy_logps/chosen': -289.74505615234375, 'referece_logps/rejected': -305.7447814941406, 'referece_logps/chosen': -282.08428955078125, 'logits/rejected': -0.7848253846168518, 'logits/chosen': -0.7149720191955566, 'epoch': 3.15}


 52%|█████▏    | 8447/16104 [39:01:30<38:47:15, 18.24s/it]
{'loss': 0.4347, 'learning_rate': 9.692325339320318e-07, 'rewards/chosen': -1.3128188848495483, 'rewards/rejected': -2.5124731063842773, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1996543407440186, 'policy_logps/rejected': -344.4888610839844, 'policy_logps/chosen': -493.9051513671875, 'referece_logps/rejected': -319.3641357421875, 'referece_logps/chosen': -480.7770080566406, 'logits/rejected': -0.3643360733985901, 'logits/chosen': -0.3375559151172638, 'epoch': 3.15}

 52%|█████▏    | 8448/16104 [39:01:44<36:25:39, 17.13s/it]

 52%|█████▏    | 8449/16104 [39:01:57<33:32:00, 15.77s/it]


 52%|█████▏    | 8451/16104 [39:02:31<34:59:37, 16.46s/it]
{'loss': 0.5927, 'learning_rate': 9.684284196919168e-07, 'rewards/chosen': -1.3763483762741089, 'rewards/rejected': -1.5531402826309204, 'rewards/accuracies': 0.375, 'rewards/margins': 0.1767919957637787, 'policy_logps/rejected': -408.4381408691406, 'policy_logps/chosen': -303.851318359375, 'referece_logps/rejected': -392.90673828125, 'referece_logps/chosen': -290.0878601074219, 'logits/rejected': -0.10386727005243301, 'logits/chosen': 0.007450267672538757, 'epoch': 3.15}


 52%|█████▏    | 8453/16104 [39:03:03<35:03:37, 16.50s/it]
{'loss': 0.5218, 'learning_rate': 9.680263702020924e-07, 'rewards/chosen': -0.8027584552764893, 'rewards/rejected': -1.0899903774261475, 'rewards/accuracies': 0.5, 'rewards/margins': 0.287231981754303, 'policy_logps/rejected': -311.542724609375, 'policy_logps/chosen': -385.8099670410156, 'referece_logps/rejected': -300.6427917480469, 'referece_logps/chosen': -377.7823791503906, 'logits/rejected': 0.08959215879440308, 'logits/chosen': 0.18356627225875854, 'epoch': 3.15}

 52%|█████▏    | 8454/16104 [39:03:18<34:10:31, 16.08s/it]

 53%|█████▎    | 8455/16104 [39:03:31<31:44:48, 14.94s/it]

 53%|█████▎    | 8456/16104 [39:03:51<34:57:10, 16.45s/it]


 53%|█████▎    | 8458/16104 [39:04:14<29:48:48, 14.04s/it]
{'loss': 0.4597, 'learning_rate': 9.670212692541666e-07, 'rewards/chosen': -1.1137778759002686, 'rewards/rejected': -1.9446310997009277, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8308532238006592, 'policy_logps/rejected': -380.8899230957031, 'policy_logps/chosen': -374.6708984375, 'referece_logps/rejected': -361.443603515625, 'referece_logps/chosen': -363.53314208984375, 'logits/rejected': 0.1061236560344696, 'logits/chosen': 0.16455641388893127, 'epoch': 3.15}


 53%|█████▎    | 8460/16104 [39:04:43<30:09:15, 14.20s/it]
{'loss': 0.544, 'learning_rate': 9.66619238156415e-07, 'rewards/chosen': -0.7866405844688416, 'rewards/rejected': -1.9264904260635376, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1398500204086304, 'policy_logps/rejected': -559.4981689453125, 'policy_logps/chosen': -450.3870849609375, 'referece_logps/rejected': -540.2332763671875, 'referece_logps/chosen': -442.52069091796875, 'logits/rejected': -0.07765510678291321, 'logits/chosen': 0.13377544283866882, 'epoch': 3.15}


 53%|█████▎    | 8462/16104 [39:05:12<30:58:49, 14.59s/it]

 53%|█████▎    | 8463/16104 [39:05:32<34:07:11, 16.08s/it]

 53%|█████▎    | 8464/16104 [39:05:51<36:14:57, 17.08s/it]
{'loss': 0.5343, 'learning_rate': 9.658151922296988e-07, 'rewards/chosen': -1.0536978244781494, 'rewards/rejected': -1.8313138484954834, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7776159644126892, 'policy_logps/rejected': -454.035400390625, 'policy_logps/chosen': -514.7984008789062, 'referece_logps/rejected': -435.7222595214844, 'referece_logps/chosen': -504.26141357421875, 'logits/rejected': -1.0722734928131104, 'logits/chosen': -1.1205525398254395, 'epoch': 3.15}


 53%|█████▎    | 8466/16104 [39:06:14<29:49:27, 14.06s/it]
{'loss': 0.6124, 'learning_rate': 9.654131775308342e-07, 'rewards/chosen': -0.5474773645401001, 'rewards/rejected': -1.1569424867630005, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6094651818275452, 'policy_logps/rejected': -514.9063720703125, 'policy_logps/chosen': -385.1744079589844, 'referece_logps/rejected': -503.3369445800781, 'referece_logps/chosen': -379.69964599609375, 'logits/rejected': -1.3198398351669312, 'logits/chosen': -1.1815621852874756, 'epoch': 3.15}

 53%|█████▎    | 8467/16104 [39:06:25<27:54:07, 13.15s/it]


 53%|█████▎    | 8469/16104 [39:06:48<26:13:34, 12.37s/it]

 53%|█████▎    | 8470/16104 [39:07:02<27:08:29, 12.80s/it]
{'loss': 0.6379, 'learning_rate': 9.646091649873383e-07, 'rewards/chosen': -0.9363584518432617, 'rewards/rejected': -0.8243854641914368, 'rewards/accuracies': 0.5, 'rewards/margins': -0.11197300255298615, 'policy_logps/rejected': -607.4312744140625, 'policy_logps/chosen': -400.463134765625, 'referece_logps/rejected': -599.1874389648438, 'referece_logps/chosen': -391.0995788574219, 'logits/rejected': -0.4447612762451172, 'logits/chosen': -0.44933533668518066, 'epoch': 3.16}

 53%|█████▎    | 8471/16104 [39:07:12<25:46:58, 12.16s/it]


 53%|█████▎    | 8473/16104 [39:07:42<27:42:42, 13.07s/it]

 53%|█████▎    | 8474/16104 [39:08:01<31:55:41, 15.06s/it]

 53%|█████▎    | 8475/16104 [39:08:14<30:35:24, 14.43s/it]

 53%|█████▎    | 8476/16104 [39:08:28<30:04:23, 14.19s/it]

 53%|█████▎    | 8477/16104 [39:08:48<33:46:29, 15.94s/it]

 53%|█████▎    | 8478/16104 [39:09:04<33:30:54, 15.82s/it]
{'loss': 0.5406, 'learning_rate': 9.630012091385835e-07, 'rewards/chosen': -1.4206598997116089, 'rewards/rejected': -1.7299593687057495, 'rewards/accuracies': 0.375, 'rewards/margins': 0.30929943919181824, 'policy_logps/rejected': -381.3830871582031, 'policy_logps/chosen': -303.32257080078125, 'referece_logps/rejected': -364.0835266113281, 'referece_logps/chosen': -289.115966796875, 'logits/rejected': -0.301200807094574, 'logits/chosen': -0.17287752032279968, 'epoch': 3.16}


 53%|█████▎    | 8480/16104 [39:09:40<35:38:39, 16.83s/it]
{'loss': 0.609, 'learning_rate': 9.625992349804564e-07, 'rewards/chosen': -0.9106439352035522, 'rewards/rejected': -1.0181220769882202, 'rewards/accuracies': 0.5, 'rewards/margins': 0.1074780523777008, 'policy_logps/rejected': -375.3213195800781, 'policy_logps/chosen': -319.6858215332031, 'referece_logps/rejected': -365.1401062011719, 'referece_logps/chosen': -310.5793762207031, 'logits/rejected': -0.19776412844657898, 'logits/chosen': -0.44972145557403564, 'epoch': 3.16}


 53%|█████▎    | 8482/16104 [39:10:14<36:33:14, 17.27s/it]

 53%|█████▎    | 8483/16104 [39:10:34<38:35:46, 18.23s/it]

 53%|█████▎    | 8484/16104 [39:10:54<39:33:02, 18.69s/it]
{'loss': 0.4607, 'learning_rate': 9.617953048843758e-07, 'rewards/chosen': -1.6210925579071045, 'rewards/rejected': -2.432941198348999, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8118484616279602, 'policy_logps/rejected': -488.8282775878906, 'policy_logps/chosen': -447.1546325683594, 'referece_logps/rejected': -464.4988708496094, 'referece_logps/chosen': -430.9437561035156, 'logits/rejected': 0.11558452248573303, 'logits/chosen': 0.03214731812477112, 'epoch': 3.16}


 53%|█████▎    | 8486/16104 [39:11:22<34:15:05, 16.19s/it]
{'loss': 0.5119, 'learning_rate': 9.613933490765042e-07, 'rewards/chosen': -1.3927712440490723, 'rewards/rejected': -1.9481748342514038, 'rewards/accuracies': 0.625, 'rewards/margins': 0.555403470993042, 'policy_logps/rejected': -291.6737976074219, 'policy_logps/chosen': -386.125, 'referece_logps/rejected': -272.1920471191406, 'referece_logps/chosen': -372.19732666015625, 'logits/rejected': -1.0040580034255981, 'logits/chosen': -1.1757233142852783, 'epoch': 3.16}

 53%|█████▎    | 8487/16104 [39:11:37<33:22:31, 15.77s/it]

 53%|█████▎    | 8488/16104 [39:11:55<34:48:22, 16.45s/it]

 53%|█████▎    | 8489/16104 [39:12:11<34:26:08, 16.28s/it]


 53%|█████▎    | 8491/16104 [39:12:40<32:06:51, 15.19s/it]
{'loss': 0.5692, 'learning_rate': 9.603884870289831e-07, 'rewards/chosen': -1.581286907196045, 'rewards/rejected': -1.9471989870071411, 'rewards/accuracies': 0.625, 'rewards/margins': 0.36591222882270813, 'policy_logps/rejected': -361.1530456542969, 'policy_logps/chosen': -372.3632507324219, 'referece_logps/rejected': -341.6810607910156, 'referece_logps/chosen': -356.5504150390625, 'logits/rejected': -0.8421390652656555, 'logits/chosen': -1.0339460372924805, 'epoch': 3.16}


 53%|█████▎    | 8493/16104 [39:13:14<33:49:28, 16.00s/it]
{'loss': 0.4851, 'learning_rate': 9.599865533695623e-07, 'rewards/chosen': -1.042310357093811, 'rewards/rejected': -2.493929624557495, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4516191482543945, 'policy_logps/rejected': -580.8365478515625, 'policy_logps/chosen': -443.90545654296875, 'referece_logps/rejected': -555.8972778320312, 'referece_logps/chosen': -433.48236083984375, 'logits/rejected': -0.6076147556304932, 'logits/chosen': -0.5698682069778442, 'epoch': 3.16}

 53%|█████▎    | 8494/16104 [39:13:27<31:56:03, 15.11s/it]

 53%|█████▎    | 8495/16104 [39:13:49<36:09:20, 17.11s/it]

 53%|█████▎    | 8496/16104 [39:14:10<38:42:06, 18.31s/it]


 53%|█████▎    | 8498/16104 [39:14:36<32:38:08, 15.45s/it]

 53%|█████▎    | 8499/16104 [39:14:56<35:44:06, 16.92s/it]
{'loss': 0.5218, 'learning_rate': 9.587807914982044e-07, 'rewards/chosen': -0.7870450019836426, 'rewards/rejected': -1.5186814069747925, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7316363453865051, 'policy_logps/rejected': -296.92041015625, 'policy_logps/chosen': -356.1861877441406, 'referece_logps/rejected': -281.733642578125, 'referece_logps/chosen': -348.31573486328125, 'logits/rejected': -0.6836486458778381, 'logits/chosen': -0.671455442905426, 'epoch': 3.17}

 53%|█████▎    | 8500/16104 [39:15:10<33:27:01, 15.84s/it]

 53%|█████▎    | 8501/16104 [39:15:40<42:25:35, 20.09s/it]

 53%|█████▎    | 8502/16104 [39:15:56<39:51:59, 18.88s/it]

 53%|█████▎    | 8503/16104 [39:16:13<38:57:06, 18.45s/it]

 53%|█████▎    | 8504/16104 [39:16:33<39:54:49, 18.91s/it]


 53%|█████▎    | 8506/16104 [39:17:14<41:21:56, 19.60s/it]

 53%|█████▎    | 8507/16104 [39:17:27<36:40:37, 17.38s/it]
{'loss': 0.4598, 'learning_rate': 9.571732026803975e-07, 'rewards/chosen': -1.3432509899139404, 'rewards/rejected': -1.8615256547927856, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5182745456695557, 'policy_logps/rejected': -430.8862609863281, 'policy_logps/chosen': -394.7894592285156, 'referece_logps/rejected': -412.2710266113281, 'referece_logps/chosen': -381.3569641113281, 'logits/rejected': 0.42749467492103577, 'logits/chosen': 0.3565337657928467, 'epoch': 3.17}

 53%|█████▎    | 8508/16104 [39:17:38<32:49:14, 15.55s/it]


 53%|█████▎    | 8510/16104 [39:18:09<32:18:38, 15.32s/it]
{'loss': 0.4839, 'learning_rate': 9.565703852351189e-07, 'rewards/chosen': -0.7249493598937988, 'rewards/rejected': -1.8062708377838135, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0813214778900146, 'policy_logps/rejected': -486.60186767578125, 'policy_logps/chosen': -395.2185974121094, 'referece_logps/rejected': -468.5391540527344, 'referece_logps/chosen': -387.9690856933594, 'logits/rejected': -0.8467259407043457, 'logits/chosen': -0.8412850499153137, 'epoch': 3.17}


 53%|█████▎    | 8512/16104 [39:18:43<34:53:06, 16.54s/it]
{'loss': 0.4628, 'learning_rate': 9.561685157087466e-07, 'rewards/chosen': -0.5593180060386658, 'rewards/rejected': -1.744695782661438, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1853777170181274, 'policy_logps/rejected': -542.133544921875, 'policy_logps/chosen': -409.7822265625, 'referece_logps/rejected': -524.6867065429688, 'referece_logps/chosen': -404.18902587890625, 'logits/rejected': -0.174142524600029, 'logits/chosen': -0.17078804969787598, 'epoch': 3.17}


 53%|█████▎    | 8514/16104 [39:19:15<35:00:03, 16.60s/it]

 53%|█████▎    | 8515/16104 [39:19:35<37:15:56, 17.68s/it]
{'loss': 0.5049, 'learning_rate': 9.555657247374711e-07, 'rewards/chosen': -1.8739354610443115, 'rewards/rejected': -2.5048723220825195, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6309365630149841, 'policy_logps/rejected': -303.80194091796875, 'policy_logps/chosen': -400.96478271484375, 'referece_logps/rejected': -278.7532043457031, 'referece_logps/chosen': -382.2254333496094, 'logits/rejected': -0.8637040257453918, 'logits/chosen': -1.0326027870178223, 'epoch': 3.17}

 53%|█████▎    | 8516/16104 [39:19:56<39:15:31, 18.63s/it]


 53%|█████▎    | 8518/16104 [39:20:29<36:56:10, 17.53s/it]
{'loss': 0.487, 'learning_rate': 9.549629499432067e-07, 'rewards/chosen': -0.9710022211074829, 'rewards/rejected': -2.3964080810546875, 'rewards/accuracies': 0.75, 'rewards/margins': 1.425405740737915, 'policy_logps/rejected': -399.03204345703125, 'policy_logps/chosen': -371.2632141113281, 'referece_logps/rejected': -375.0679931640625, 'referece_logps/chosen': -361.55322265625, 'logits/rejected': -0.16718390583992004, 'logits/chosen': -0.12150982022285461, 'epoch': 3.17}

 53%|█████▎    | 8519/16104 [39:20:44<35:09:29, 16.69s/it]


 53%|█████▎    | 8521/16104 [39:21:13<32:08:00, 15.26s/it]
{'loss': 0.5197, 'learning_rate': 9.54360191545403e-07, 'rewards/chosen': -1.1713244915008545, 'rewards/rejected': -1.5637935400009155, 'rewards/accuracies': 0.75, 'rewards/margins': 0.39246904850006104, 'policy_logps/rejected': -337.362548828125, 'policy_logps/chosen': -249.77529907226562, 'referece_logps/rejected': -321.7246398925781, 'referece_logps/chosen': -238.06204223632812, 'logits/rejected': -0.12665876746177673, 'logits/chosen': -0.037548407912254333, 'epoch': 3.17}


 53%|█████▎    | 8523/16104 [39:21:43<31:59:36, 15.19s/it]

 53%|█████▎    | 8524/16104 [39:22:05<36:06:21, 17.15s/it]

 53%|█████▎    | 8525/16104 [39:22:21<35:22:08, 16.80s/it]
{'loss': 0.5201, 'learning_rate': 9.535565395665562e-07, 'rewards/chosen': -1.2158448696136475, 'rewards/rejected': -1.6087076663970947, 'rewards/accuracies': 0.625, 'rewards/margins': 0.392863005399704, 'policy_logps/rejected': -392.5841369628906, 'policy_logps/chosen': -396.16326904296875, 'referece_logps/rejected': -376.49700927734375, 'referece_logps/chosen': -384.0048522949219, 'logits/rejected': -0.2088029384613037, 'logits/chosen': -0.15443402528762817, 'epoch': 3.18}

 53%|█████▎    | 8526/16104 [39:22:32<31:55:15, 15.16s/it]


 53%|█████▎    | 8528/16104 [39:23:13<37:28:03, 17.80s/it]
{'loss': 0.5903, 'learning_rate': 9.529538202805436e-07, 'rewards/chosen': -1.2728444337844849, 'rewards/rejected': -2.342345952987671, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0695013999938965, 'policy_logps/rejected': -382.9364013671875, 'policy_logps/chosen': -312.6114196777344, 'referece_logps/rejected': -359.512939453125, 'referece_logps/chosen': -299.8829650878906, 'logits/rejected': -0.7736803889274597, 'logits/chosen': -0.7144859433174133, 'epoch': 3.18}

 53%|█████▎    | 8529/16104 [39:23:28<35:30:22, 16.87s/it]

 53%|█████▎    | 8530/16104 [39:23:46<36:10:53, 17.20s/it]

 53%|█████▎    | 8531/16104 [39:24:04<36:35:31, 17.39s/it]


 53%|█████▎    | 8533/16104 [39:24:43<39:25:03, 18.74s/it]
{'loss': 0.3879, 'learning_rate': 9.519493263075849e-07, 'rewards/chosen': -0.8486337661743164, 'rewards/rejected': -1.826280117034912, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9776464700698853, 'policy_logps/rejected': -397.3070068359375, 'policy_logps/chosen': -320.30267333984375, 'referece_logps/rejected': -379.044189453125, 'referece_logps/chosen': -311.81634521484375, 'logits/rejected': 0.6621737480163574, 'logits/chosen': 0.7427209615707397, 'epoch': 3.18}

 53%|█████▎    | 8534/16104 [39:24:56<35:44:54, 17.00s/it]

 53%|█████▎    | 8535/16104 [39:25:16<37:19:14, 17.75s/it]

 53%|█████▎    | 8536/16104 [39:25:32<36:31:40, 17.38s/it]


 53%|█████▎    | 8538/16104 [39:26:01<33:11:11, 15.79s/it]

 53%|█████▎    | 8539/16104 [39:26:12<29:56:33, 14.25s/it]
{'loss': 0.5402, 'learning_rate': 9.507439977726909e-07, 'rewards/chosen': -1.423356294631958, 'rewards/rejected': -2.113373279571533, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6900171041488647, 'policy_logps/rejected': -356.2036437988281, 'policy_logps/chosen': -317.61041259765625, 'referece_logps/rejected': -335.06988525390625, 'referece_logps/chosen': -303.3768615722656, 'logits/rejected': -0.5276069045066833, 'logits/chosen': -0.5961325168609619, 'epoch': 3.18}

 53%|█████▎    | 8540/16104 [39:26:30<32:32:56, 15.49s/it]

 53%|█████▎    | 8541/16104 [39:26:41<29:42:02, 14.14s/it]

 53%|█████▎    | 8542/16104 [39:26:56<30:22:00, 14.46s/it]

 53%|█████▎    | 8543/16104 [39:27:12<31:09:18, 14.83s/it]


 53%|█████▎    | 8545/16104 [39:27:48<34:41:59, 16.53s/it]
{'loss': 0.5877, 'learning_rate': 9.495387409675431e-07, 'rewards/chosen': -1.1974890232086182, 'rewards/rejected': -0.8903365731239319, 'rewards/accuracies': 0.375, 'rewards/margins': -0.30715250968933105, 'policy_logps/rejected': -394.0726013183594, 'policy_logps/chosen': -469.0333251953125, 'referece_logps/rejected': -385.16925048828125, 'referece_logps/chosen': -457.0584411621094, 'logits/rejected': -1.0045909881591797, 'logits/chosen': -1.1845781803131104, 'epoch': 3.18}


 53%|█████▎    | 8547/16104 [39:28:22<35:17:57, 16.82s/it]

 53%|█████▎    | 8548/16104 [39:28:39<35:45:57, 17.04s/it]
{'loss': 0.6208, 'learning_rate': 9.489361400121195e-07, 'rewards/chosen': -0.7143272757530212, 'rewards/rejected': -1.5464286804199219, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8321014642715454, 'policy_logps/rejected': -647.87255859375, 'policy_logps/chosen': -560.1973876953125, 'referece_logps/rejected': -632.4083251953125, 'referece_logps/chosen': -553.0541381835938, 'logits/rejected': 0.38793885707855225, 'logits/chosen': 0.2887756824493408, 'epoch': 3.18}

 53%|█████▎    | 8549/16104 [39:29:00<38:13:39, 18.22s/it]

 53%|█████▎    | 8550/16104 [39:29:18<38:02:36, 18.13s/it]


 53%|█████▎    | 8552/16104 [39:29:55<38:21:35, 18.29s/it]
{'loss': 0.5899, 'learning_rate': 9.481327010282114e-07, 'rewards/chosen': -1.0991348028182983, 'rewards/rejected': -0.9381976127624512, 'rewards/accuracies': 0.375, 'rewards/margins': -0.16093720495700836, 'policy_logps/rejected': -285.6415100097656, 'policy_logps/chosen': -309.1350402832031, 'referece_logps/rejected': -276.2595520019531, 'referece_logps/chosen': -298.1436767578125, 'logits/rejected': -0.07091027498245239, 'logits/chosen': -0.09119623899459839, 'epoch': 3.19}

 53%|█████▎    | 8553/16104 [39:30:06<33:39:33, 16.05s/it]


 53%|█████▎    | 8555/16104 [39:30:46<37:35:09, 17.92s/it]

 53%|█████▎    | 8556/16104 [39:31:01<36:01:05, 17.18s/it]

 53%|█████▎    | 8557/16104 [39:31:21<37:44:39, 18.00s/it]

 53%|█████▎    | 8558/16104 [39:31:38<36:42:45, 17.51s/it]
{'loss': 0.5218, 'learning_rate': 9.469276056585867e-07, 'rewards/chosen': -0.8489057421684265, 'rewards/rejected': -1.9480581283569336, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0991523265838623, 'policy_logps/rejected': -330.2828063964844, 'policy_logps/chosen': -289.7689208984375, 'referece_logps/rejected': -310.80224609375, 'referece_logps/chosen': -281.2798767089844, 'logits/rejected': 0.36261892318725586, 'logits/chosen': 0.30622950196266174, 'epoch': 3.19}

 53%|█████▎    | 8559/16104 [39:31:57<37:55:56, 18.10s/it]


 53%|█████▎    | 8561/16104 [39:32:30<35:01:04, 16.71s/it]

 53%|█████▎    | 8562/16104 [39:32:43<33:12:17, 15.85s/it]

 53%|█████▎    | 8563/16104 [39:33:02<34:44:01, 16.58s/it]

 53%|█████▎    | 8564/16104 [39:33:20<35:50:49, 17.12s/it]
{'loss': 0.4006, 'learning_rate': 9.457225875763829e-07, 'rewards/chosen': -1.0367435216903687, 'rewards/rejected': -2.788102149963379, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7513586282730103, 'policy_logps/rejected': -312.7712707519531, 'policy_logps/chosen': -390.33392333984375, 'referece_logps/rejected': -284.8902587890625, 'referece_logps/chosen': -379.96649169921875, 'logits/rejected': -0.6856548190116882, 'logits/chosen': -0.7648512721061707, 'epoch': 3.19}

 53%|█████▎    | 8565/16104 [39:33:37<35:46:28, 17.08s/it]

 53%|█████▎    | 8566/16104 [39:33:54<35:57:56, 17.18s/it]

 53%|█████▎    | 8567/16104 [39:34:10<35:05:48, 16.76s/it]


 53%|█████▎    | 8569/16104 [39:34:47<37:05:15, 17.72s/it]

 53%|█████▎    | 8570/16104 [39:35:06<37:30:46, 17.92s/it]

 53%|█████▎    | 8571/16104 [39:35:24<37:27:49, 17.90s/it]
{'loss': 0.4718, 'learning_rate': 9.443168331709717e-07, 'rewards/chosen': -1.3527051210403442, 'rewards/rejected': -2.0413074493408203, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6886021494865417, 'policy_logps/rejected': -430.8550109863281, 'policy_logps/chosen': -355.673828125, 'referece_logps/rejected': -410.44189453125, 'referece_logps/chosen': -342.14678955078125, 'logits/rejected': -1.2152119874954224, 'logits/chosen': -1.1236939430236816, 'epoch': 3.19}


 53%|█████▎    | 8573/16104 [39:35:56<34:38:07, 16.56s/it]

 53%|█████▎    | 8574/16104 [39:36:14<35:26:57, 16.95s/it]
{'loss': 0.5643, 'learning_rate': 9.437144006220058e-07, 'rewards/chosen': -0.6790631413459778, 'rewards/rejected': -1.1352827548980713, 'rewards/accuracies': 0.75, 'rewards/margins': 0.45621955394744873, 'policy_logps/rejected': -467.5871887207031, 'policy_logps/chosen': -476.9501647949219, 'referece_logps/rejected': -456.2343444824219, 'referece_logps/chosen': -470.1595458984375, 'logits/rejected': -1.2727261781692505, 'logits/chosen': -1.27699875831604, 'epoch': 3.19}


 53%|█████▎    | 8576/16104 [39:36:52<37:18:40, 17.84s/it]
{'loss': 0.5891, 'learning_rate': 9.433127902934213e-07, 'rewards/chosen': -0.6128151416778564, 'rewards/rejected': -0.8511409759521484, 'rewards/accuracies': 0.5, 'rewards/margins': 0.23832589387893677, 'policy_logps/rejected': -385.1763916015625, 'policy_logps/chosen': -559.37353515625, 'referece_logps/rejected': -376.66497802734375, 'referece_logps/chosen': -553.245361328125, 'logits/rejected': -0.4517342746257782, 'logits/chosen': -0.6144793033599854, 'epoch': 3.2}


 53%|█████▎    | 8578/16104 [39:37:16<31:27:20, 15.05s/it]
{'loss': 0.5826, 'learning_rate': 9.429111891372319e-07, 'rewards/chosen': -0.7551082968711853, 'rewards/rejected': -1.4039287567138672, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6488205194473267, 'policy_logps/rejected': -390.9037170410156, 'policy_logps/chosen': -430.5436706542969, 'referece_logps/rejected': -376.8644714355469, 'referece_logps/chosen': -422.9925231933594, 'logits/rejected': 0.009477440267801285, 'logits/chosen': -0.006746374070644379, 'epoch': 3.2}

 53%|█████▎    | 8579/16104 [39:37:28<29:05:47, 13.92s/it]


 53%|█████▎    | 8581/16104 [39:38:00<32:13:45, 15.42s/it]
{'loss': 0.5224, 'learning_rate': 9.423088047433363e-07, 'rewards/chosen': -1.1563725471496582, 'rewards/rejected': -1.7182239294052124, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5618513822555542, 'policy_logps/rejected': -460.0917053222656, 'policy_logps/chosen': -503.1058349609375, 'referece_logps/rejected': -442.909423828125, 'referece_logps/chosen': -491.5421447753906, 'logits/rejected': -0.3520706295967102, 'logits/chosen': -0.35970839858055115, 'epoch': 3.2}

 53%|█████▎    | 8582/16104 [39:38:12<30:24:12, 14.55s/it]

 53%|█████▎    | 8583/16104 [39:38:24<28:49:53, 13.80s/it]

 53%|█████▎    | 8584/16104 [39:38:45<32:52:40, 15.74s/it]

 53%|█████▎    | 8585/16104 [39:39:05<35:42:48, 17.10s/it]

 53%|█████▎    | 8586/16104 [39:39:23<36:24:08, 17.43s/it]

 53%|█████▎    | 8587/16104 [39:39:43<37:41:33, 18.05s/it]

 53%|█████▎    | 8588/16104 [39:40:02<38:19:13, 18.35s/it]

 53%|█████▎    | 8589/16104 [39:40:23<39:57:46, 19.14s/it]

 53%|█████▎    | 8590/16104 [39:40:41<39:28:29, 18.91s/it]

 53%|█████▎    | 8591/16104 [39:41:03<41:14:17, 19.76s/it]

 53%|█████▎    | 8592/16104 [39:41:25<42:51:11, 20.54s/it]

 53%|█████▎    | 8593/16104 [39:41:43<41:11:15, 19.74s/it]

 53%|█████▎    | 8594/16104 [39:41:59<38:37:22, 18.51s/it]


 53%|█████▎    | 8596/16104 [39:42:40<40:54:30, 19.62s/it]
{'loss': 0.4776, 'learning_rate': 9.39297202210827e-07, 'rewards/chosen': -0.5099343657493591, 'rewards/rejected': -1.2334492206573486, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7235147953033447, 'policy_logps/rejected': -613.0455322265625, 'policy_logps/chosen': -335.1732482910156, 'referece_logps/rejected': -600.7110595703125, 'referece_logps/chosen': -330.07391357421875, 'logits/rejected': -0.805343747138977, 'logits/chosen': -0.587988555431366, 'epoch': 3.2}

 53%|█████▎    | 8597/16104 [39:43:01<41:27:55, 19.88s/it]

 53%|█████▎    | 8598/16104 [39:43:14<37:26:52, 17.96s/it]

 53%|█████▎    | 8599/16104 [39:43:34<38:39:39, 18.54s/it]

 53%|█████▎    | 8600/16104 [39:43:51<37:33:15, 18.02s/it]

 53%|█████▎    | 8601/16104 [39:44:12<39:27:04, 18.93s/it]

 53%|█████▎    | 8602/16104 [39:44:27<36:52:02, 17.69s/it]

 53%|█████▎    | 8603/16104 [39:44:46<37:47:24, 18.14s/it]

 53%|█████▎    | 8604/16104 [39:45:01<35:48:36, 17.19s/it]


 53%|█████▎    | 8606/16104 [39:45:37<36:11:23, 17.38s/it]
{'loss': 0.5035, 'learning_rate': 9.372897724391797e-07, 'rewards/chosen': -0.923481822013855, 'rewards/rejected': -1.3694387674331665, 'rewards/accuracies': 0.75, 'rewards/margins': 0.44595691561698914, 'policy_logps/rejected': -451.7420654296875, 'policy_logps/chosen': -400.4834289550781, 'referece_logps/rejected': -438.04766845703125, 'referece_logps/chosen': -391.2486572265625, 'logits/rejected': -0.14992624521255493, 'logits/chosen': -0.2605465054512024, 'epoch': 3.21}

 53%|█████▎    | 8607/16104 [39:45:56<37:28:58, 18.00s/it]

 53%|█████▎    | 8608/16104 [39:46:12<36:13:40, 17.40s/it]

 53%|█████▎    | 8609/16104 [39:46:30<36:28:10, 17.52s/it]

 53%|█████▎    | 8610/16104 [39:46:51<38:35:33, 18.54s/it]

 53%|█████▎    | 8611/16104 [39:47:06<36:27:09, 17.51s/it]

 53%|█████▎    | 8612/16104 [39:47:25<37:23:47, 17.97s/it]

 53%|█████▎    | 8613/16104 [39:47:43<37:38:15, 18.09s/it]

 53%|█████▎    | 8614/16104 [39:47:56<34:04:21, 16.38s/it]

 53%|█████▎    | 8615/16104 [39:48:14<35:11:50, 16.92s/it]

 54%|█████▎    | 8616/16104 [39:48:32<35:47:27, 17.21s/it]


 54%|█████▎    | 8618/16104 [39:49:05<34:18:11, 16.50s/it]
{'loss': 0.4864, 'learning_rate': 9.348811922773763e-07, 'rewards/chosen': -0.9076710343360901, 'rewards/rejected': -2.29182767868042, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3841569423675537, 'policy_logps/rejected': -320.4685363769531, 'policy_logps/chosen': -269.5451965332031, 'referece_logps/rejected': -297.5502624511719, 'referece_logps/chosen': -260.468505859375, 'logits/rejected': -0.4994795620441437, 'logits/chosen': -0.39344269037246704, 'epoch': 3.21}

 54%|█████▎    | 8619/16104 [39:49:24<36:13:06, 17.42s/it]

 54%|█████▎    | 8620/16104 [39:49:44<37:35:06, 18.08s/it]

 54%|█████▎    | 8621/16104 [39:50:00<36:15:38, 17.44s/it]

 54%|█████▎    | 8622/16104 [39:50:20<37:51:07, 18.21s/it]

 54%|█████▎    | 8623/16104 [39:50:35<36:00:26, 17.33s/it]

 54%|█████▎    | 8624/16104 [39:50:46<32:06:08, 15.45s/it]

 54%|█████▎    | 8625/16104 [39:50:59<30:37:17, 14.74s/it]

 54%|█████▎    | 8626/16104 [39:51:20<34:05:22, 16.41s/it]

 54%|█████▎    | 8627/16104 [39:51:38<35:17:56, 17.00s/it]

 54%|█████▎    | 8628/16104 [39:51:50<32:06:55, 15.46s/it]

 54%|█████▎    | 8629/16104 [39:52:12<36:08:16, 17.40s/it]

 54%|█████▎    | 8630/16104 [39:52:33<38:14:14, 18.42s/it]

 54%|█████▎    | 8631/16104 [39:52:48<36:32:49, 17.61s/it]

 54%|█████▎    | 8632/16104 [39:53:00<32:50:53, 15.83s/it]

 54%|█████▎    | 8633/16104 [39:53:14<31:27:47, 15.16s/it]


 54%|█████▎    | 8635/16104 [39:53:43<31:33:44, 15.21s/it]
{'loss': 0.5597, 'learning_rate': 9.314696897064564e-07, 'rewards/chosen': -0.4916481375694275, 'rewards/rejected': -2.0004351139068604, 'rewards/accuracies': 0.875, 'rewards/margins': 1.508786916732788, 'policy_logps/rejected': -447.1784362792969, 'policy_logps/chosen': -418.97955322265625, 'referece_logps/rejected': -427.174072265625, 'referece_logps/chosen': -414.06304931640625, 'logits/rejected': -0.2981196939945221, 'logits/chosen': -0.08822153508663177, 'epoch': 3.22}

 54%|█████▎    | 8636/16104 [39:54:00<32:42:14, 15.77s/it]

 54%|█████▎    | 8637/16104 [39:54:11<29:28:45, 14.21s/it]

 54%|█████▎    | 8638/16104 [39:54:23<28:16:02, 13.63s/it]

 54%|█████▎    | 8639/16104 [39:54:34<26:28:06, 12.76s/it]


 54%|█████▎    | 8641/16104 [39:55:05<30:27:33, 14.69s/it]
{'loss': 0.444, 'learning_rate': 9.302658192018145e-07, 'rewards/chosen': -1.1408648490905762, 'rewards/rejected': -2.728450298309326, 'rewards/accuracies': 0.75, 'rewards/margins': 1.58758544921875, 'policy_logps/rejected': -457.9512634277344, 'policy_logps/chosen': -403.5638427734375, 'referece_logps/rejected': -430.6667785644531, 'referece_logps/chosen': -392.15521240234375, 'logits/rejected': 0.20573386549949646, 'logits/chosen': 0.28331100940704346, 'epoch': 3.22}

 54%|█████▎    | 8642/16104 [39:55:20<30:24:31, 14.67s/it]

 54%|█████▎    | 8643/16104 [39:55:39<33:14:28, 16.04s/it]

 54%|█████▎    | 8644/16104 [39:55:55<33:03:12, 15.95s/it]

 54%|█████▎    | 8645/16104 [39:56:10<32:25:26, 15.65s/it]

 54%|█████▎    | 8646/16104 [39:56:28<33:54:32, 16.37s/it]

 54%|█████▎    | 8647/16104 [39:56:50<37:20:22, 18.03s/it]

 54%|█████▎    | 8648/16104 [39:57:02<33:44:06, 16.29s/it]

 54%|█████▎    | 8649/16104 [39:57:17<32:41:40, 15.79s/it]


 54%|█████▎    | 8651/16104 [39:57:52<35:01:32, 16.92s/it]
{'loss': 0.5245, 'learning_rate': 9.2825959489617e-07, 'rewards/chosen': -0.8893600106239319, 'rewards/rejected': -1.0037904977798462, 'rewards/accuracies': 0.5, 'rewards/margins': 0.11443035304546356, 'policy_logps/rejected': -302.9728088378906, 'policy_logps/chosen': -357.9865417480469, 'referece_logps/rejected': -292.9349060058594, 'referece_logps/chosen': -349.0929260253906, 'logits/rejected': -1.364759087562561, 'logits/chosen': -1.3427666425704956, 'epoch': 3.22}


 54%|█████▎    | 8653/16104 [39:58:24<33:53:24, 16.37s/it]
{'loss': 0.4963, 'learning_rate': 9.278583845996817e-07, 'rewards/chosen': -0.9524273872375488, 'rewards/rejected': -1.3965517282485962, 'rewards/accuracies': 0.75, 'rewards/margins': 0.44412434101104736, 'policy_logps/rejected': -297.8103332519531, 'policy_logps/chosen': -347.6957702636719, 'referece_logps/rejected': -283.8448486328125, 'referece_logps/chosen': -338.1715087890625, 'logits/rejected': -0.7001838684082031, 'logits/chosen': -0.7100657224655151, 'epoch': 3.22}

 54%|█████▎    | 8654/16104 [39:58:41<34:37:40, 16.73s/it]

 54%|█████▎    | 8655/16104 [39:58:54<32:26:54, 15.68s/it]


 54%|█████▍    | 8657/16104 [39:59:26<31:50:50, 15.40s/it]
{'loss': 0.4907, 'learning_rate': 9.27055999090707e-07, 'rewards/chosen': -0.984122633934021, 'rewards/rejected': -2.1894185543060303, 'rewards/accuracies': 0.625, 'rewards/margins': 1.2052960395812988, 'policy_logps/rejected': -441.4442138671875, 'policy_logps/chosen': -484.2296447753906, 'referece_logps/rejected': -419.54998779296875, 'referece_logps/chosen': -474.3884582519531, 'logits/rejected': -0.7195278406143188, 'logits/chosen': -0.6832984089851379, 'epoch': 3.23}

 54%|█████▍    | 8658/16104 [39:59:46<34:57:26, 16.90s/it]

 54%|█████▍    | 8659/16104 [39:59:59<32:30:33, 15.72s/it]

 54%|█████▍    | 8660/16104 [40:00:17<34:03:44, 16.47s/it]

 54%|█████▍    | 8661/16104 [40:00:37<36:12:48, 17.52s/it]

 54%|█████▍    | 8662/16104 [40:00:57<37:28:56, 18.13s/it]

 54%|█████▍    | 8663/16104 [40:01:16<38:21:21, 18.56s/it]

 54%|█████▍    | 8664/16104 [40:01:35<38:27:54, 18.61s/it]

 54%|█████▍    | 8665/16104 [40:01:50<35:59:23, 17.42s/it]

 54%|█████▍    | 8666/16104 [40:02:07<35:55:50, 17.39s/it]

 54%|█████▍    | 8667/16104 [40:02:24<35:38:40, 17.25s/it]


 54%|█████▍    | 8669/16104 [40:02:48<29:49:59, 14.45s/it]
{'loss': 0.5198, 'learning_rate': 9.246491279095617e-07, 'rewards/chosen': -0.8025752902030945, 'rewards/rejected': -2.0926461219787598, 'rewards/accuracies': 1.0, 'rewards/margins': 1.290070652961731, 'policy_logps/rejected': -333.0855712890625, 'policy_logps/chosen': -340.07305908203125, 'referece_logps/rejected': -312.1590881347656, 'referece_logps/chosen': -332.0472717285156, 'logits/rejected': -0.7314720749855042, 'logits/chosen': -0.5468007326126099, 'epoch': 3.23}

 54%|█████▍    | 8670/16104 [40:03:04<31:02:28, 15.03s/it]

 54%|█████▍    | 8671/16104 [40:03:24<34:16:21, 16.60s/it]

 54%|█████▍    | 8672/16104 [40:03:44<36:17:06, 17.58s/it]

 54%|█████▍    | 8673/16104 [40:04:05<38:00:55, 18.42s/it]

 54%|█████▍    | 8674/16104 [40:04:25<38:58:29, 18.88s/it]

 54%|█████▍    | 8675/16104 [40:04:45<39:36:56, 19.20s/it]

 54%|█████▍    | 8676/16104 [40:05:02<38:41:58, 18.76s/it]

 54%|█████▍    | 8677/16104 [40:05:21<38:50:21, 18.83s/it]

 54%|█████▍    | 8678/16104 [40:05:35<35:36:36, 17.26s/it]

 54%|█████▍    | 8679/16104 [40:05:50<34:34:08, 16.76s/it]

 54%|█████▍    | 8680/16104 [40:06:09<35:31:10, 17.22s/it]

 54%|█████▍    | 8681/16104 [40:06:22<32:54:11, 15.96s/it]


 54%|█████▍    | 8683/16104 [40:06:50<30:58:52, 15.03s/it]
{'loss': 0.4756, 'learning_rate': 9.218416672656478e-07, 'rewards/chosen': -0.4835781157016754, 'rewards/rejected': -0.9498775601387024, 'rewards/accuracies': 0.625, 'rewards/margins': 0.46629947423934937, 'policy_logps/rejected': -444.2701110839844, 'policy_logps/chosen': -402.39056396484375, 'referece_logps/rejected': -434.7713317871094, 'referece_logps/chosen': -397.5548095703125, 'logits/rejected': 0.39837974309921265, 'logits/chosen': 0.3291652202606201, 'epoch': 3.24}

 54%|█████▍    | 8684/16104 [40:07:09<33:06:54, 16.07s/it]

 54%|█████▍    | 8685/16104 [40:07:28<35:16:13, 17.11s/it]

 54%|█████▍    | 8686/16104 [40:07:47<36:17:54, 17.62s/it]

 54%|█████▍    | 8687/16104 [40:08:05<36:44:26, 17.83s/it]

 54%|█████▍    | 8688/16104 [40:08:26<38:28:20, 18.68s/it]

 54%|█████▍    | 8689/16104 [40:08:47<40:17:10, 19.56s/it]

 54%|█████▍    | 8690/16104 [40:09:00<35:40:48, 17.33s/it]

 54%|█████▍    | 8691/16104 [40:09:19<37:14:11, 18.08s/it]

 54%|█████▍    | 8692/16104 [40:09:38<37:22:40, 18.15s/it]

 54%|█████▍    | 8693/16104 [40:09:59<39:22:18, 19.13s/it]

 54%|█████▍    | 8694/16104 [40:10:19<39:44:42, 19.31s/it]

 54%|█████▍    | 8695/16104 [40:10:35<37:41:00, 18.31s/it]

 54%|█████▍    | 8696/16104 [40:10:47<34:05:49, 16.57s/it]

 54%|█████▍    | 8697/16104 [40:11:09<37:12:25, 18.08s/it]

 54%|█████▍    | 8698/16104 [40:11:28<37:32:54, 18.25s/it]


 54%|█████▍    | 8700/16104 [40:12:11<40:57:06, 19.91s/it]

 54%|█████▍    | 8701/16104 [40:12:32<41:35:41, 20.23s/it]

 54%|█████▍    | 8702/16104 [40:12:54<42:53:57, 20.86s/it]
{'loss': 0.4669, 'learning_rate': 9.180325375184937e-07, 'rewards/chosen': -0.8460970520973206, 'rewards/rejected': -2.2591769695281982, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4130796194076538, 'policy_logps/rejected': -504.26263427734375, 'policy_logps/chosen': -512.4658813476562, 'referece_logps/rejected': -481.67083740234375, 'referece_logps/chosen': -504.0048828125, 'logits/rejected': 0.4875220060348511, 'logits/chosen': 0.5241622924804688, 'epoch': 3.24}


 54%|█████▍    | 8704/16104 [40:13:26<37:36:15, 18.29s/it]

 54%|█████▍    | 8705/16104 [40:13:43<36:38:00, 17.82s/it]
{'loss': 0.5011, 'learning_rate': 9.174312039713464e-07, 'rewards/chosen': -0.558933436870575, 'rewards/rejected': -1.538610577583313, 'rewards/accuracies': 0.625, 'rewards/margins': 0.979677140712738, 'policy_logps/rejected': -257.81988525390625, 'policy_logps/chosen': -379.3113708496094, 'referece_logps/rejected': -242.4337615966797, 'referece_logps/chosen': -373.7220458984375, 'logits/rejected': -0.5185378789901733, 'logits/chosen': -0.5217419862747192, 'epoch': 3.24}


 54%|█████▍    | 8707/16104 [40:14:21<37:16:01, 18.14s/it]

 54%|█████▍    | 8708/16104 [40:14:40<38:08:28, 18.57s/it]

 54%|█████▍    | 8709/16104 [40:14:52<33:44:25, 16.43s/it]

 54%|█████▍    | 8710/16104 [40:15:06<32:35:31, 15.87s/it]

 54%|█████▍    | 8711/16104 [40:15:22<32:37:34, 15.89s/it]

 54%|█████▍    | 8712/16104 [40:15:36<31:12:29, 15.20s/it]
{'loss': 0.5907, 'learning_rate': 9.160282096416316e-07, 'rewards/chosen': -0.919002890586853, 'rewards/rejected': -2.45471453666687, 'rewards/accuracies': 0.5, 'rewards/margins': 1.5357115268707275, 'policy_logps/rejected': -466.7864990234375, 'policy_logps/chosen': -435.14996337890625, 'referece_logps/rejected': -442.2393493652344, 'referece_logps/chosen': -425.95989990234375, 'logits/rejected': -0.5952931046485901, 'logits/chosen': -0.579261064529419, 'epoch': 3.25}

 54%|█████▍    | 8713/16104 [40:15:57<35:00:57, 17.06s/it]


 54%|█████▍    | 8715/16104 [40:16:29<34:05:32, 16.61s/it]

 54%|█████▍    | 8716/16104 [40:16:48<35:56:45, 17.52s/it]

 54%|█████▍    | 8717/16104 [40:17:04<34:44:58, 16.93s/it]

 54%|█████▍    | 8718/16104 [40:17:21<34:33:12, 16.84s/it]

 54%|█████▍    | 8719/16104 [40:17:41<36:40:16, 17.88s/it]

 54%|█████▍    | 8720/16104 [40:17:54<34:02:04, 16.59s/it]

 54%|█████▍    | 8721/16104 [40:18:14<35:35:14, 17.35s/it]

 54%|█████▍    | 8722/16104 [40:18:35<38:00:28, 18.54s/it]

 54%|█████▍    | 8723/16104 [40:18:50<35:48:44, 17.47s/it]
{'loss': 0.4875, 'learning_rate': 9.13823841620477e-07, 'rewards/chosen': -1.4871973991394043, 'rewards/rejected': -2.422292709350586, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9350950717926025, 'policy_logps/rejected': -284.644287109375, 'policy_logps/chosen': -311.0665588378906, 'referece_logps/rejected': -260.42132568359375, 'referece_logps/chosen': -296.1946105957031, 'logits/rejected': -0.9842982292175293, 'logits/chosen': -0.9227746725082397, 'epoch': 3.25}


 54%|█████▍    | 8725/16104 [40:19:26<36:18:29, 17.71s/it]

 54%|█████▍    | 8726/16104 [40:19:44<36:05:47, 17.61s/it]

 54%|█████▍    | 8727/16104 [40:20:02<36:32:34, 17.83s/it]

 54%|█████▍    | 8728/16104 [40:20:17<34:37:14, 16.90s/it]
{'loss': 0.6581, 'learning_rate': 9.128219949469969e-07, 'rewards/chosen': -1.294762134552002, 'rewards/rejected': -1.2260245084762573, 'rewards/accuracies': 0.75, 'rewards/margins': -0.06873741745948792, 'policy_logps/rejected': -504.46246337890625, 'policy_logps/chosen': -525.5391845703125, 'referece_logps/rejected': -492.20220947265625, 'referece_logps/chosen': -512.591552734375, 'logits/rejected': 0.5625016093254089, 'logits/chosen': 0.5115064978599548, 'epoch': 3.25}


 54%|█████▍    | 8730/16104 [40:20:55<37:03:45, 18.09s/it]

 54%|█████▍    | 8731/16104 [40:21:09<34:35:45, 16.89s/it]

 54%|█████▍    | 8732/16104 [40:21:24<33:24:16, 16.31s/it]

 54%|█████▍    | 8733/16104 [40:21:35<30:12:05, 14.75s/it]

 54%|█████▍    | 8734/16104 [40:21:52<31:51:53, 15.56s/it]
{'loss': 0.3849, 'learning_rate': 9.116198954026576e-07, 'rewards/chosen': -2.03469181060791, 'rewards/rejected': -3.124894380569458, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0902026891708374, 'policy_logps/rejected': -466.78369140625, 'policy_logps/chosen': -393.5814514160156, 'referece_logps/rejected': -435.53472900390625, 'referece_logps/chosen': -373.2345275878906, 'logits/rejected': 0.44274359941482544, 'logits/chosen': 0.3865658640861511, 'epoch': 3.25}


 54%|█████▍    | 8736/16104 [40:22:31<36:02:07, 17.61s/it]
{'loss': 0.3726, 'learning_rate': 9.112192240691616e-07, 'rewards/chosen': -0.9427280426025391, 'rewards/rejected': -2.2747418880462646, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3320138454437256, 'policy_logps/rejected': -312.8759765625, 'policy_logps/chosen': -382.6394348144531, 'referece_logps/rejected': -290.1285400390625, 'referece_logps/chosen': -373.212158203125, 'logits/rejected': -0.1997896283864975, 'logits/chosen': -0.11478136479854584, 'epoch': 3.25}


 54%|█████▍    | 8738/16104 [40:23:05<36:20:38, 17.76s/it]
{'loss': 0.4743, 'learning_rate': 9.108185671010292e-07, 'rewards/chosen': -0.9504980444908142, 'rewards/rejected': -2.0199737548828125, 'rewards/accuracies': 0.625, 'rewards/margins': 1.069475769996643, 'policy_logps/rejected': -513.0914306640625, 'policy_logps/chosen': -327.33282470703125, 'referece_logps/rejected': -492.8916320800781, 'referece_logps/chosen': -317.8278503417969, 'logits/rejected': -0.729052722454071, 'logits/chosen': -0.7026069760322571, 'epoch': 3.26}

 54%|█████▍    | 8739/16104 [40:23:25<37:50:07, 18.49s/it]

 54%|█████▍    | 8740/16104 [40:23:39<35:11:57, 17.21s/it]


 54%|█████▍    | 8742/16104 [40:24:15<36:03:56, 17.64s/it]

 54%|█████▍    | 8743/16104 [40:24:34<36:51:48, 18.03s/it]

 54%|█████▍    | 8744/16104 [40:24:54<38:00:25, 18.59s/it]

 54%|█████▍    | 8745/16104 [40:25:07<34:33:25, 16.91s/it]

 54%|█████▍    | 8746/16104 [40:25:27<36:44:42, 17.98s/it]

 54%|█████▍    | 8747/16104 [40:25:40<33:30:37, 16.40s/it]

 54%|█████▍    | 8748/16104 [40:25:54<32:15:33, 15.79s/it]
{'loss': 0.5261, 'learning_rate': 9.088155000097514e-07, 'rewards/chosen': -0.9398400783538818, 'rewards/rejected': -2.0037853717803955, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0639452934265137, 'policy_logps/rejected': -293.74853515625, 'policy_logps/chosen': -278.40673828125, 'referece_logps/rejected': -273.710693359375, 'referece_logps/chosen': -269.00836181640625, 'logits/rejected': -0.47043168544769287, 'logits/chosen': -0.5446871519088745, 'epoch': 3.26}


 54%|█████▍    | 8750/16104 [40:26:23<31:01:37, 15.19s/it]

 54%|█████▍    | 8751/16104 [40:26:38<31:04:42, 15.22s/it]

 54%|█████▍    | 8752/16104 [40:26:51<29:31:20, 14.46s/it]

 54%|█████▍    | 8753/16104 [40:27:11<32:43:19, 16.02s/it]

 54%|█████▍    | 8754/16104 [40:27:30<34:50:04, 17.06s/it]

 54%|█████▍    | 8755/16104 [40:27:41<31:09:49, 15.27s/it]

 54%|█████▍    | 8756/16104 [40:28:01<33:56:07, 16.63s/it]

 54%|█████▍    | 8757/16104 [40:28:15<32:30:58, 15.93s/it]

 54%|█████▍    | 8758/16104 [40:28:31<32:34:41, 15.97s/it]

 54%|█████▍    | 8759/16104 [40:28:47<32:20:46, 15.85s/it]

 54%|█████▍    | 8760/16104 [40:29:03<32:39:36, 16.01s/it]

 54%|█████▍    | 8761/16104 [40:29:22<34:27:03, 16.89s/it]

 54%|█████▍    | 8762/16104 [40:29:36<32:33:29, 15.96s/it]

 54%|█████▍    | 8763/16104 [40:29:51<31:53:18, 15.64s/it]

 54%|█████▍    | 8764/16104 [40:30:04<30:18:08, 14.86s/it]

 54%|█████▍    | 8765/16104 [40:30:21<31:33:39, 15.48s/it]
{'loss': 0.5339, 'learning_rate': 9.054111368207198e-07, 'rewards/chosen': -1.2460683584213257, 'rewards/rejected': -1.7548198699951172, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5087515711784363, 'policy_logps/rejected': -422.588134765625, 'policy_logps/chosen': -301.1963806152344, 'referece_logps/rejected': -405.0399475097656, 'referece_logps/chosen': -288.73565673828125, 'logits/rejected': -0.543474555015564, 'logits/chosen': -0.436972439289093, 'epoch': 3.27}


 54%|█████▍    | 8767/16104 [40:30:52<31:47:36, 15.60s/it]

 54%|█████▍    | 8768/16104 [40:31:04<29:44:25, 14.59s/it]
{'loss': 0.5946, 'learning_rate': 9.048104805008181e-07, 'rewards/chosen': -1.2640944719314575, 'rewards/rejected': -1.5640591382980347, 'rewards/accuracies': 0.5, 'rewards/margins': 0.29996463656425476, 'policy_logps/rejected': -308.4560546875, 'policy_logps/chosen': -375.1817321777344, 'referece_logps/rejected': -292.8154602050781, 'referece_logps/chosen': -362.54083251953125, 'logits/rejected': -0.7061607837677002, 'logits/chosen': -0.6590397953987122, 'epoch': 3.27}


 54%|█████▍    | 8770/16104 [40:31:32<28:44:57, 14.11s/it]

 54%|█████▍    | 8771/16104 [40:31:48<29:50:31, 14.65s/it]

 54%|█████▍    | 8772/16104 [40:32:03<30:01:39, 14.74s/it]

 54%|█████▍    | 8773/16104 [40:32:23<33:02:25, 16.23s/it]

 54%|█████▍    | 8774/16104 [40:32:43<35:24:03, 17.39s/it]

 54%|█████▍    | 8775/16104 [40:33:05<38:27:02, 18.89s/it]

 54%|█████▍    | 8776/16104 [40:33:19<35:11:43, 17.29s/it]

 55%|█████▍    | 8777/16104 [40:33:39<36:46:01, 18.06s/it]

 55%|█████▍    | 8778/16104 [40:33:57<36:44:49, 18.06s/it]
{'loss': 0.5192, 'learning_rate': 9.028085442841759e-07, 'rewards/chosen': -0.6968488693237305, 'rewards/rejected': -1.7146519422531128, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0178031921386719, 'policy_logps/rejected': -409.85809326171875, 'policy_logps/chosen': -341.2108459472656, 'referece_logps/rejected': -392.7115478515625, 'referece_logps/chosen': -334.2424011230469, 'logits/rejected': -0.33873170614242554, 'logits/chosen': -0.3558243215084076, 'epoch': 3.27}


 55%|█████▍    | 8780/16104 [40:34:32<36:00:25, 17.70s/it]

 55%|█████▍    | 8781/16104 [40:34:43<31:54:21, 15.69s/it]

 55%|█████▍    | 8782/16104 [40:34:58<32:01:17, 15.74s/it]

 55%|█████▍    | 8783/16104 [40:35:09<28:56:40, 14.23s/it]

 55%|█████▍    | 8784/16104 [40:35:31<33:22:35, 16.41s/it]

 55%|█████▍    | 8785/16104 [40:35:48<33:53:00, 16.67s/it]
{'loss': 0.5424, 'learning_rate': 9.014074223789549e-07, 'rewards/chosen': -0.8572399616241455, 'rewards/rejected': -1.666864037513733, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8096241354942322, 'policy_logps/rejected': -273.31939697265625, 'policy_logps/chosen': -273.09564208984375, 'referece_logps/rejected': -256.6507568359375, 'referece_logps/chosen': -264.523193359375, 'logits/rejected': -0.42462801933288574, 'logits/chosen': -0.5158231258392334, 'epoch': 3.27}

 55%|█████▍    | 8786/16104 [40:36:04<33:40:44, 16.57s/it]

 55%|█████▍    | 8787/16104 [40:36:18<32:01:13, 15.75s/it]


 55%|█████▍    | 8789/16104 [40:36:55<35:07:21, 17.29s/it]

 55%|█████▍    | 8790/16104 [40:37:16<36:57:52, 18.19s/it]

 55%|█████▍    | 8791/16104 [40:37:33<36:22:13, 17.90s/it]

 55%|█████▍    | 8792/16104 [40:37:53<37:34:30, 18.50s/it]
{'loss': 0.4854, 'learning_rate': 9.000064958977421e-07, 'rewards/chosen': -0.9899146556854248, 'rewards/rejected': -1.2226873636245728, 'rewards/accuracies': 0.75, 'rewards/margins': 0.23277272284030914, 'policy_logps/rejected': -326.4975280761719, 'policy_logps/chosen': -265.0949401855469, 'referece_logps/rejected': -314.2706604003906, 'referece_logps/chosen': -255.19578552246094, 'logits/rejected': -0.018063098192214966, 'logits/chosen': 0.05939215421676636, 'epoch': 3.28}

 55%|█████▍    | 8793/16104 [40:38:10<36:56:56, 18.19s/it]


 55%|█████▍    | 8795/16104 [40:38:41<33:44:28, 16.62s/it]

 55%|█████▍    | 8796/16104 [40:39:01<35:40:07, 17.57s/it]
{'loss': 0.5499, 'learning_rate': 8.99206055289947e-07, 'rewards/chosen': -0.6598546504974365, 'rewards/rejected': -1.9359017610549927, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2760471105575562, 'policy_logps/rejected': -527.117919921875, 'policy_logps/chosen': -420.0150451660156, 'referece_logps/rejected': -507.7588806152344, 'referece_logps/chosen': -413.41650390625, 'logits/rejected': -1.0362743139266968, 'logits/chosen': -0.9308326840400696, 'epoch': 3.28}


 55%|█████▍    | 8798/16104 [40:39:36<35:04:00, 17.28s/it]

 55%|█████▍    | 8799/16104 [40:39:53<35:02:59, 17.27s/it]

 55%|█████▍    | 8800/16104 [40:40:08<33:42:41, 16.62s/it]

 55%|█████▍    | 8801/16104 [40:40:29<36:27:01, 17.97s/it]

 55%|█████▍    | 8802/16104 [40:40:41<32:45:21, 16.15s/it]

 55%|█████▍    | 8803/16104 [40:40:59<33:55:33, 16.73s/it]

 55%|█████▍    | 8804/16104 [40:41:15<33:25:17, 16.48s/it]
{'loss': 0.4392, 'learning_rate': 8.976053703025295e-07, 'rewards/chosen': -0.683602511882782, 'rewards/rejected': -1.9533236026763916, 'rewards/accuracies': 0.875, 'rewards/margins': 1.269721269607544, 'policy_logps/rejected': -478.0093078613281, 'policy_logps/chosen': -371.8583068847656, 'referece_logps/rejected': -458.47607421875, 'referece_logps/chosen': -365.0223083496094, 'logits/rejected': -0.5611430406570435, 'logits/chosen': -0.31666845083236694, 'epoch': 3.28}


 55%|█████▍    | 8806/16104 [40:41:42<30:43:43, 15.16s/it]

 55%|█████▍    | 8807/16104 [40:42:01<33:17:37, 16.43s/it]

 55%|█████▍    | 8808/16104 [40:42:21<35:16:52, 17.41s/it]
{'loss': 0.6223, 'learning_rate': 8.968051269589161e-07, 'rewards/chosen': -0.6583591103553772, 'rewards/rejected': -0.85498046875, 'rewards/accuracies': 0.5, 'rewards/margins': 0.19662141799926758, 'policy_logps/rejected': -490.5390625, 'policy_logps/chosen': -515.697998046875, 'referece_logps/rejected': -481.9892578125, 'referece_logps/chosen': -509.1144104003906, 'logits/rejected': 0.00813351571559906, 'logits/chosen': -0.016341067850589752, 'epoch': 3.28}


 55%|█████▍    | 8810/16104 [40:42:51<32:10:47, 15.88s/it]

 55%|█████▍    | 8811/16104 [40:43:08<32:41:43, 16.14s/it]
{'loss': 0.5466, 'learning_rate': 8.962049882542565e-07, 'rewards/chosen': -1.0414084196090698, 'rewards/rejected': -1.0062212944030762, 'rewards/accuracies': 0.5, 'rewards/margins': -0.03518715500831604, 'policy_logps/rejected': -351.60089111328125, 'policy_logps/chosen': -396.7036437988281, 'referece_logps/rejected': -341.5386657714844, 'referece_logps/chosen': -386.2895812988281, 'logits/rejected': -1.0014663934707642, 'logits/chosen': -0.9046196341514587, 'epoch': 3.28}


 55%|█████▍    | 8813/16104 [40:43:38<31:23:14, 15.50s/it]

 55%|█████▍    | 8814/16104 [40:43:52<30:24:44, 15.02s/it]
{'loss': 0.5154, 'learning_rate': 8.95604887337837e-07, 'rewards/chosen': -0.7227686643600464, 'rewards/rejected': -1.5364394187927246, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8136708736419678, 'policy_logps/rejected': -399.5853576660156, 'policy_logps/chosen': -512.50146484375, 'referece_logps/rejected': -384.22100830078125, 'referece_logps/chosen': -505.2737121582031, 'logits/rejected': 0.1429411619901657, 'logits/chosen': 0.09721335768699646, 'epoch': 3.28}

 55%|█████▍    | 8815/16104 [40:44:09<31:40:07, 15.64s/it]


 55%|█████▍    | 8817/16104 [40:44:50<36:52:25, 18.22s/it]
{'loss': 0.5323, 'learning_rate': 8.950048244281336e-07, 'rewards/chosen': -0.8901538848876953, 'rewards/rejected': -1.9089914560317993, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0188376903533936, 'policy_logps/rejected': -402.6746826171875, 'policy_logps/chosen': -473.0955810546875, 'referece_logps/rejected': -383.5847473144531, 'referece_logps/chosen': -464.19403076171875, 'logits/rejected': -0.846937894821167, 'logits/chosen': -0.9596285820007324, 'epoch': 3.29}


 55%|█████▍    | 8819/16104 [40:45:18<32:44:07, 16.18s/it]
{'loss': 0.5551, 'learning_rate': 8.946048037110575e-07, 'rewards/chosen': -1.165486216545105, 'rewards/rejected': -2.630826234817505, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4653398990631104, 'policy_logps/rejected': -503.9059143066406, 'policy_logps/chosen': -396.2041015625, 'referece_logps/rejected': -477.5976867675781, 'referece_logps/chosen': -384.54925537109375, 'logits/rejected': 0.11025670170783997, 'logits/chosen': 0.06090278923511505, 'epoch': 3.29}

 55%|█████▍    | 8820/16104 [40:45:33<31:57:31, 15.80s/it]

 55%|█████▍    | 8821/16104 [40:45:47<31:10:38, 15.41s/it]

 55%|█████▍    | 8822/16104 [40:46:07<33:40:32, 16.65s/it]


 55%|█████▍    | 8824/16104 [40:46:34<30:46:16, 15.22s/it]

 55%|█████▍    | 8825/16104 [40:46:56<34:48:47, 17.22s/it]
{'loss': 0.4505, 'learning_rate': 8.934048441408886e-07, 'rewards/chosen': -0.39319247007369995, 'rewards/rejected': -1.7777760028839111, 'rewards/accuracies': 0.875, 'rewards/margins': 1.3845834732055664, 'policy_logps/rejected': -313.3946533203125, 'policy_logps/chosen': -290.65478515625, 'referece_logps/rejected': -295.6169128417969, 'referece_logps/chosen': -286.7228698730469, 'logits/rejected': -1.3008568286895752, 'logits/chosen': -1.033079743385315, 'epoch': 3.29}


 55%|█████▍    | 8827/16104 [40:47:22<30:29:10, 15.08s/it]

 55%|█████▍    | 8828/16104 [40:47:40<32:11:53, 15.93s/it]

 55%|█████▍    | 8829/16104 [40:47:56<32:10:23, 15.92s/it]

 55%|█████▍    | 8830/16104 [40:48:16<34:34:32, 17.11s/it]

 55%|█████▍    | 8831/16104 [40:48:27<30:49:08, 15.25s/it]

 55%|█████▍    | 8832/16104 [40:48:38<28:19:13, 14.02s/it]

 55%|█████▍    | 8833/16104 [40:48:54<29:43:33, 14.72s/it]

 55%|█████▍    | 8834/16104 [40:49:10<30:20:01, 15.02s/it]
{'loss': 0.5603, 'learning_rate': 8.916051963892082e-07, 'rewards/chosen': -1.5455039739608765, 'rewards/rejected': -1.98195481300354, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4364507794380188, 'policy_logps/rejected': -401.55999755859375, 'policy_logps/chosen': -407.1337890625, 'referece_logps/rejected': -381.74041748046875, 'referece_logps/chosen': -391.6787414550781, 'logits/rejected': -0.7339447736740112, 'logits/chosen': -0.7315856218338013, 'epoch': 3.29}

 55%|█████▍    | 8835/16104 [40:49:28<31:59:11, 15.84s/it]


 55%|█████▍    | 8837/16104 [40:50:05<35:12:13, 17.44s/it]
{'loss': 0.4596, 'learning_rate': 8.910053924398692e-07, 'rewards/chosen': -0.8540415167808533, 'rewards/rejected': -1.7468149662017822, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8927733302116394, 'policy_logps/rejected': -405.0865478515625, 'policy_logps/chosen': -587.5759887695312, 'referece_logps/rejected': -387.618408203125, 'referece_logps/chosen': -579.0355224609375, 'logits/rejected': -0.3437310755252838, 'logits/chosen': -0.5837626457214355, 'epoch': 3.29}


 55%|█████▍    | 8839/16104 [40:50:36<33:48:56, 16.76s/it]
{'loss': 0.4591, 'learning_rate': 8.906055451719623e-07, 'rewards/chosen': -0.7649772763252258, 'rewards/rejected': -1.6318612098693848, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8668838739395142, 'policy_logps/rejected': -415.577392578125, 'policy_logps/chosen': -433.1922912597656, 'referece_logps/rejected': -399.2587890625, 'referece_logps/chosen': -425.54254150390625, 'logits/rejected': -0.46587568521499634, 'logits/chosen': -0.5259211659431458, 'epoch': 3.29}


 55%|█████▍    | 8841/16104 [40:51:15<36:33:50, 18.12s/it]

 55%|█████▍    | 8842/16104 [40:51:34<37:14:51, 18.46s/it]
{'loss': 0.6503, 'learning_rate': 8.900058074793258e-07, 'rewards/chosen': -1.281463861465454, 'rewards/rejected': -2.0524814128875732, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7710176706314087, 'policy_logps/rejected': -480.0540771484375, 'policy_logps/chosen': -443.30914306640625, 'referece_logps/rejected': -459.5292663574219, 'referece_logps/chosen': -430.4945373535156, 'logits/rejected': 0.5171570777893066, 'logits/chosen': 0.5152060985565186, 'epoch': 3.29}

 55%|█████▍    | 8843/16104 [40:51:46<33:11:42, 16.46s/it]

 55%|█████▍    | 8844/16104 [40:51:59<31:30:41, 15.63s/it]


 55%|█████▍    | 8846/16104 [40:52:40<36:34:31, 18.14s/it]

 55%|█████▍    | 8847/16104 [40:52:59<36:43:08, 18.22s/it]
{'loss': 0.507, 'learning_rate': 8.890063337553077e-07, 'rewards/chosen': -0.3921475410461426, 'rewards/rejected': -1.793821930885315, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4016743898391724, 'policy_logps/rejected': -524.1067504882812, 'policy_logps/chosen': -452.4826354980469, 'referece_logps/rejected': -506.16851806640625, 'referece_logps/chosen': -448.5611267089844, 'logits/rejected': -0.7934023141860962, 'logits/chosen': -0.7889536619186401, 'epoch': 3.3}


 55%|█████▍    | 8849/16104 [40:53:29<33:37:37, 16.69s/it]

 55%|█████▍    | 8850/16104 [40:53:41<31:01:47, 15.40s/it]
{'loss': 0.5206, 'learning_rate': 8.884067033349108e-07, 'rewards/chosen': -0.5393592119216919, 'rewards/rejected': -1.1635308265686035, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6241714358329773, 'policy_logps/rejected': -640.2781982421875, 'policy_logps/chosen': -622.0870971679688, 'referece_logps/rejected': -628.6429443359375, 'referece_logps/chosen': -616.6934814453125, 'logits/rejected': -0.7150095105171204, 'logits/chosen': -0.8574081063270569, 'epoch': 3.3}


 55%|█████▍    | 8852/16104 [40:54:20<35:39:18, 17.70s/it]
{'loss': 0.4993, 'learning_rate': 8.88006972278577e-07, 'rewards/chosen': -1.0778049230575562, 'rewards/rejected': -2.6421332359313965, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5643281936645508, 'policy_logps/rejected': -520.2872314453125, 'policy_logps/chosen': -527.0770874023438, 'referece_logps/rejected': -493.865966796875, 'referece_logps/chosen': -516.2990112304688, 'logits/rejected': 0.0015951842069625854, 'logits/chosen': -0.04457368701696396, 'epoch': 3.3}


 55%|█████▍    | 8854/16104 [40:54:51<32:16:55, 16.03s/it]
{'loss': 0.4974, 'learning_rate': 8.876072593435145e-07, 'rewards/chosen': -0.816208004951477, 'rewards/rejected': -1.0192705392837524, 'rewards/accuracies': 0.75, 'rewards/margins': 0.20306263864040375, 'policy_logps/rejected': -293.31005859375, 'policy_logps/chosen': -272.0363464355469, 'referece_logps/rejected': -283.1173400878906, 'referece_logps/chosen': -263.8742370605469, 'logits/rejected': -0.15005552768707275, 'logits/chosen': -0.2354029417037964, 'epoch': 3.3}

 55%|█████▍    | 8855/16104 [40:55:02<29:24:03, 14.60s/it]

 55%|█████▍    | 8856/16104 [40:55:18<30:07:02, 14.96s/it]


 55%|█████▌    | 8858/16104 [40:55:45<28:23:01, 14.10s/it]

 55%|█████▌    | 8859/16104 [40:56:05<32:14:09, 16.02s/it]

 55%|█████▌    | 8860/16104 [40:56:24<34:10:54, 16.99s/it]
{'loss': 0.5927, 'learning_rate': 8.864082299127027e-07, 'rewards/chosen': -1.0019972324371338, 'rewards/rejected': -1.0357418060302734, 'rewards/accuracies': 0.375, 'rewards/margins': 0.03374454379081726, 'policy_logps/rejected': -375.6815185546875, 'policy_logps/chosen': -441.68902587890625, 'referece_logps/rejected': -365.3241271972656, 'referece_logps/chosen': -431.6690673828125, 'logits/rejected': -0.5572620630264282, 'logits/chosen': -0.617838442325592, 'epoch': 3.3}


 55%|█████▌    | 8862/16104 [40:57:01<34:59:49, 17.40s/it]

 55%|█████▌    | 8863/16104 [40:57:21<36:24:26, 18.10s/it]

 55%|█████▌    | 8864/16104 [40:57:41<37:27:50, 18.63s/it]
{'loss': 0.4438, 'learning_rate': 8.856089687508396e-07, 'rewards/chosen': -1.0966392755508423, 'rewards/rejected': -1.5642316341400146, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4675922691822052, 'policy_logps/rejected': -387.636474609375, 'policy_logps/chosen': -340.15234375, 'referece_logps/rejected': -371.994140625, 'referece_logps/chosen': -329.18597412109375, 'logits/rejected': -1.2341498136520386, 'logits/chosen': -1.1699131727218628, 'epoch': 3.3}

 55%|█████▌    | 8865/16104 [40:58:00<38:02:10, 18.92s/it]

 55%|█████▌    | 8866/16104 [40:58:12<33:49:36, 16.82s/it]


 55%|█████▌    | 8868/16104 [40:58:49<35:42:53, 17.77s/it]
{'loss': 0.3751, 'learning_rate': 8.848097816261136e-07, 'rewards/chosen': -0.46790942549705505, 'rewards/rejected': -1.6076337099075317, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1397243738174438, 'policy_logps/rejected': -375.8091125488281, 'policy_logps/chosen': -451.9999694824219, 'referece_logps/rejected': -359.7327575683594, 'referece_logps/chosen': -447.3208923339844, 'logits/rejected': -0.31638282537460327, 'logits/chosen': -0.3402555584907532, 'epoch': 3.3}

 55%|█████▌    | 8869/16104 [40:59:00<31:32:20, 15.69s/it]


 55%|█████▌    | 8871/16104 [40:59:41<36:16:52, 18.06s/it]

 55%|█████▌    | 8872/16104 [40:59:59<36:29:30, 18.17s/it]

 55%|█████▌    | 8873/16104 [41:00:11<32:18:58, 16.09s/it]

 55%|█████▌    | 8874/16104 [41:00:25<31:04:24, 15.47s/it]
{'loss': 0.6266, 'learning_rate': 8.836111408901441e-07, 'rewards/chosen': -0.809646487236023, 'rewards/rejected': -2.229997158050537, 'rewards/accuracies': 1.0, 'rewards/margins': 1.420350432395935, 'policy_logps/rejected': -394.0215148925781, 'policy_logps/chosen': -417.0842590332031, 'referece_logps/rejected': -371.7215270996094, 'referece_logps/chosen': -408.9878234863281, 'logits/rejected': -0.5845407843589783, 'logits/chosen': -0.48229196667671204, 'epoch': 3.31}


 55%|█████▌    | 8876/16104 [41:00:47<26:49:10, 13.36s/it]
{'loss': 0.5826, 'learning_rate': 8.83211631557054e-07, 'rewards/chosen': -0.7657191157341003, 'rewards/rejected': -0.9136099219322205, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1478908509016037, 'policy_logps/rejected': -525.777099609375, 'policy_logps/chosen': -501.3548583984375, 'referece_logps/rejected': -516.6409912109375, 'referece_logps/chosen': -493.6976318359375, 'logits/rejected': -0.46674787998199463, 'logits/chosen': -0.5107541084289551, 'epoch': 3.31}

 55%|█████▌    | 8877/16104 [41:00:58<25:22:00, 12.64s/it]

 55%|█████▌    | 8878/16104 [41:01:18<29:32:59, 14.72s/it]

 55%|█████▌    | 8879/16104 [41:01:38<32:54:49, 16.40s/it]


 55%|█████▌    | 8881/16104 [41:02:13<33:34:53, 16.74s/it]
{'loss': 0.4648, 'learning_rate': 8.822129410409413e-07, 'rewards/chosen': -1.4700782299041748, 'rewards/rejected': -2.653609037399292, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1835308074951172, 'policy_logps/rejected': -305.5535888671875, 'policy_logps/chosen': -445.70556640625, 'referece_logps/rejected': -279.01751708984375, 'referece_logps/chosen': -431.0047912597656, 'logits/rejected': -0.8113669753074646, 'logits/chosen': -0.8948870897293091, 'epoch': 3.31}


 55%|█████▌    | 8883/16104 [41:02:52<36:37:50, 18.26s/it]
{'loss': 0.4464, 'learning_rate': 8.818134981308163e-07, 'rewards/chosen': -0.6292972564697266, 'rewards/rejected': -2.2391531467437744, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6098557710647583, 'policy_logps/rejected': -454.47039794921875, 'policy_logps/chosen': -710.418212890625, 'referece_logps/rejected': -432.0788879394531, 'referece_logps/chosen': -704.125244140625, 'logits/rejected': -0.9482240080833435, 'logits/chosen': -1.1419901847839355, 'epoch': 3.31}


 55%|█████▌    | 8885/16104 [41:03:20<31:44:56, 15.83s/it]
{'loss': 0.4611, 'learning_rate': 8.814140743441105e-07, 'rewards/chosen': -0.6187721490859985, 'rewards/rejected': -0.9953296184539795, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3765575587749481, 'policy_logps/rejected': -550.7986450195312, 'policy_logps/chosen': -681.5548706054688, 'referece_logps/rejected': -540.8453369140625, 'referece_logps/chosen': -675.3670654296875, 'logits/rejected': -0.2851242125034332, 'logits/chosen': -0.3421485126018524, 'epoch': 3.31}

 55%|█████▌    | 8886/16104 [41:03:30<28:48:33, 14.37s/it]


 55%|█████▌    | 8888/16104 [41:04:01<28:57:15, 14.45s/it]
{'loss': 0.5641, 'learning_rate': 8.808149746618402e-07, 'rewards/chosen': -0.765262246131897, 'rewards/rejected': -1.0691649913787842, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3039027154445648, 'policy_logps/rejected': -541.965576171875, 'policy_logps/chosen': -478.1586608886719, 'referece_logps/rejected': -531.2739868164062, 'referece_logps/chosen': -470.50604248046875, 'logits/rejected': -0.028711527585983276, 'logits/chosen': 0.1340724229812622, 'epoch': 3.31}

 55%|█████▌    | 8889/16104 [41:04:16<29:10:12, 14.55s/it]


 55%|█████▌    | 8891/16104 [41:04:47<30:13:36, 15.09s/it]
{'loss': 0.4756, 'learning_rate': 8.802159183707911e-07, 'rewards/chosen': -0.5938677191734314, 'rewards/rejected': -1.301656723022461, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7077890634536743, 'policy_logps/rejected': -418.4569091796875, 'policy_logps/chosen': -432.6870422363281, 'referece_logps/rejected': -405.4403381347656, 'referece_logps/chosen': -426.7484436035156, 'logits/rejected': -1.303547978401184, 'logits/chosen': -1.264422059059143, 'epoch': 3.31}


 55%|█████▌    | 8893/16104 [41:05:25<33:52:21, 16.91s/it]

 55%|█████▌    | 8894/16104 [41:05:42<33:31:10, 16.74s/it]
{'loss': 0.4507, 'learning_rate': 8.796169056890593e-07, 'rewards/chosen': -0.7367424368858337, 'rewards/rejected': -1.7317997217178345, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9950573444366455, 'policy_logps/rejected': -271.23846435546875, 'policy_logps/chosen': -388.19384765625, 'referece_logps/rejected': -253.9204864501953, 'referece_logps/chosen': -380.8264465332031, 'logits/rejected': 0.4609070420265198, 'logits/chosen': 0.41310808062553406, 'epoch': 3.31}


 55%|█████▌    | 8896/16104 [41:06:16<33:52:52, 16.92s/it]

 55%|█████▌    | 8897/16104 [41:06:33<34:03:45, 17.01s/it]

 55%|█████▌    | 8898/16104 [41:06:44<30:20:55, 15.16s/it]
{'loss': 0.4714, 'learning_rate': 8.788182903270597e-07, 'rewards/chosen': -1.3534011840820312, 'rewards/rejected': -1.8092962503433228, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4558950662612915, 'policy_logps/rejected': -447.40374755859375, 'policy_logps/chosen': -475.6257019042969, 'referece_logps/rejected': -429.3107604980469, 'referece_logps/chosen': -462.09173583984375, 'logits/rejected': 0.14477092027664185, 'logits/chosen': 0.07334120571613312, 'epoch': 3.32}


 55%|█████▌    | 8900/16104 [41:07:26<36:18:30, 18.14s/it]
{'loss': 0.492, 'learning_rate': 8.784190120258536e-07, 'rewards/chosen': -0.8382396101951599, 'rewards/rejected': -1.898998498916626, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0607589483261108, 'policy_logps/rejected': -296.7205810546875, 'policy_logps/chosen': -489.67620849609375, 'referece_logps/rejected': -277.7305908203125, 'referece_logps/chosen': -481.29376220703125, 'logits/rejected': -1.325107216835022, 'logits/chosen': -1.5052239894866943, 'epoch': 3.32}


 55%|█████▌    | 8902/16104 [41:08:04<37:43:30, 18.86s/it]
{'loss': 0.493, 'learning_rate': 8.780197533973189e-07, 'rewards/chosen': -0.7947813272476196, 'rewards/rejected': -1.3690696954727173, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5742883086204529, 'policy_logps/rejected': -317.87176513671875, 'policy_logps/chosen': -286.446533203125, 'referece_logps/rejected': -304.1810607910156, 'referece_logps/chosen': -278.49871826171875, 'logits/rejected': -0.5120149850845337, 'logits/chosen': -0.40676963329315186, 'epoch': 3.32}

 55%|█████▌    | 8903/16104 [41:08:19<35:24:58, 17.71s/it]

 55%|█████▌    | 8904/16104 [41:08:31<31:55:33, 15.96s/it]

 55%|█████▌    | 8905/16104 [41:08:43<29:40:12, 14.84s/it]


 55%|█████▌    | 8907/16104 [41:09:18<31:47:56, 15.91s/it]

 55%|█████▌    | 8908/16104 [41:09:37<33:58:09, 16.99s/it]

 55%|█████▌    | 8909/16104 [41:09:53<33:23:59, 16.71s/it]
{'loss': 0.4225, 'learning_rate': 8.766225040524104e-07, 'rewards/chosen': -1.2055286169052124, 'rewards/rejected': -1.4503151178359985, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2447863519191742, 'policy_logps/rejected': -339.60235595703125, 'policy_logps/chosen': -337.3875732421875, 'referece_logps/rejected': -325.0992126464844, 'referece_logps/chosen': -325.332275390625, 'logits/rejected': -0.3061121702194214, 'logits/chosen': -0.26107776165008545, 'epoch': 3.32}


 55%|█████▌    | 8911/16104 [41:10:31<35:19:16, 17.68s/it]
{'loss': 0.3758, 'learning_rate': 8.762233347503122e-07, 'rewards/chosen': -0.9197642803192139, 'rewards/rejected': -1.461935043334961, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5421708226203918, 'policy_logps/rejected': -457.27197265625, 'policy_logps/chosen': -421.9821472167969, 'referece_logps/rejected': -442.6526184082031, 'referece_logps/chosen': -412.78448486328125, 'logits/rejected': -0.35065194964408875, 'logits/chosen': -0.44877031445503235, 'epoch': 3.32}


 55%|█████▌    | 8913/16104 [41:11:04<34:31:01, 17.28s/it]

 55%|█████▌    | 8914/16104 [41:11:20<33:23:58, 16.72s/it]
{'loss': 0.386, 'learning_rate': 8.756246183697493e-07, 'rewards/chosen': -0.6142447590827942, 'rewards/rejected': -1.5859075784683228, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9716627597808838, 'policy_logps/rejected': -504.87750244140625, 'policy_logps/chosen': -397.55145263671875, 'referece_logps/rejected': -489.0184020996094, 'referece_logps/chosen': -391.40899658203125, 'logits/rejected': -0.5176847577095032, 'logits/chosen': -0.5963854789733887, 'epoch': 3.32}


 55%|█████▌    | 8916/16104 [41:12:00<36:52:38, 18.47s/it]
{'loss': 0.4324, 'learning_rate': 8.752254992586166e-07, 'rewards/chosen': -0.6349713802337646, 'rewards/rejected': -2.478017568588257, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8430461883544922, 'policy_logps/rejected': -372.7148132324219, 'policy_logps/chosen': -259.8338928222656, 'referece_logps/rejected': -347.93463134765625, 'referece_logps/chosen': -253.4841766357422, 'logits/rejected': -0.5654664635658264, 'logits/chosen': -0.5908026695251465, 'epoch': 3.32}


 55%|█████▌    | 8918/16104 [41:12:36<37:02:02, 18.55s/it]
{'loss': 0.4111, 'learning_rate': 8.748264003368882e-07, 'rewards/chosen': -1.1260079145431519, 'rewards/rejected': -2.767800807952881, 'rewards/accuracies': 0.875, 'rewards/margins': 1.641793131828308, 'policy_logps/rejected': -422.9113464355469, 'policy_logps/chosen': -348.78253173828125, 'referece_logps/rejected': -395.2333068847656, 'referece_logps/chosen': -337.5224609375, 'logits/rejected': -0.9012108445167542, 'logits/chosen': -1.0263553857803345, 'epoch': 3.32}

 55%|█████▌    | 8919/16104 [41:12:55<36:59:23, 18.53s/it]

 55%|█████▌    | 8920/16104 [41:13:13<37:09:43, 18.62s/it]

 55%|█████▌    | 8921/16104 [41:13:28<34:33:44, 17.32s/it]

 55%|█████▌    | 8922/16104 [41:13:47<35:51:25, 17.97s/it]


 55%|█████▌    | 8924/16104 [41:14:14<30:59:45, 15.54s/it]

 55%|█████▌    | 8925/16104 [41:14:34<33:34:55, 16.84s/it]
{'loss': 0.5005, 'learning_rate': 8.73429714034703e-07, 'rewards/chosen': -0.7660498023033142, 'rewards/rejected': -1.4905036687850952, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7244539260864258, 'policy_logps/rejected': -333.65283203125, 'policy_logps/chosen': -318.97918701171875, 'referece_logps/rejected': -318.747802734375, 'referece_logps/chosen': -311.31866455078125, 'logits/rejected': -0.26130393147468567, 'logits/chosen': -0.2658635377883911, 'epoch': 3.33}

 55%|█████▌    | 8926/16104 [41:14:48<31:36:55, 15.86s/it]

 55%|█████▌    | 8927/16104 [41:15:05<32:41:52, 16.40s/it]

 55%|█████▌    | 8928/16104 [41:15:25<34:42:18, 17.41s/it]

 55%|█████▌    | 8929/16104 [41:15:45<36:01:55, 18.08s/it]

 55%|█████▌    | 8930/16104 [41:16:03<36:01:54, 18.08s/it]

 55%|█████▌    | 8931/16104 [41:16:15<32:34:02, 16.35s/it]


 55%|█████▌    | 8933/16104 [41:16:54<35:46:32, 17.96s/it]

 55%|█████▌    | 8934/16104 [41:17:12<35:54:35, 18.03s/it]
{'loss': 0.503, 'learning_rate': 8.71634343530186e-07, 'rewards/chosen': -1.352429986000061, 'rewards/rejected': -1.8715543746948242, 'rewards/accuracies': 0.375, 'rewards/margins': 0.5191243290901184, 'policy_logps/rejected': -421.34417724609375, 'policy_logps/chosen': -442.86102294921875, 'referece_logps/rejected': -402.62860107421875, 'referece_logps/chosen': -429.33673095703125, 'logits/rejected': -0.15428486466407776, 'logits/chosen': -0.27637872099876404, 'epoch': 3.33}

 55%|█████▌    | 8935/16104 [41:17:32<36:43:28, 18.44s/it]

 55%|█████▌    | 8936/16104 [41:17:48<35:09:22, 17.66s/it]

 55%|█████▌    | 8937/16104 [41:18:07<36:14:49, 18.21s/it]

 56%|█████▌    | 8938/16104 [41:18:18<31:43:55, 15.94s/it]


 56%|█████▌    | 8940/16104 [41:18:50<31:23:50, 15.78s/it]
{'loss': 0.5484, 'learning_rate': 8.70437663165266e-07, 'rewards/chosen': -0.5773235559463501, 'rewards/rejected': -1.313808798789978, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7364852428436279, 'policy_logps/rejected': -369.5494384765625, 'policy_logps/chosen': -361.8831481933594, 'referece_logps/rejected': -356.4113464355469, 'referece_logps/chosen': -356.1098937988281, 'logits/rejected': 0.5559983253479004, 'logits/chosen': 0.7115893363952637, 'epoch': 3.33}

 56%|█████▌    | 8941/16104 [41:19:12<34:33:57, 17.37s/it]

 56%|█████▌    | 8942/16104 [41:19:30<35:01:34, 17.61s/it]

 56%|█████▌    | 8943/16104 [41:19:41<31:33:19, 15.86s/it]

 56%|█████▌    | 8944/16104 [41:20:03<34:58:42, 17.59s/it]

 56%|█████▌    | 8945/16104 [41:20:17<32:46:37, 16.48s/it]


 56%|█████▌    | 8947/16104 [41:20:57<35:58:32, 18.10s/it]
{'loss': 0.5027, 'learning_rate': 8.69041774661942e-07, 'rewards/chosen': -0.9966978430747986, 'rewards/rejected': -1.9111573696136475, 'rewards/accuracies': 0.5, 'rewards/margins': 0.9144594669342041, 'policy_logps/rejected': -329.0924987792969, 'policy_logps/chosen': -364.8487854003906, 'referece_logps/rejected': -309.9809265136719, 'referece_logps/chosen': -354.88177490234375, 'logits/rejected': -0.2205248475074768, 'logits/chosen': -0.2785193622112274, 'epoch': 3.33}


 56%|█████▌    | 8949/16104 [41:21:35<36:45:21, 18.49s/it]
{'loss': 0.5103, 'learning_rate': 8.686429969317295e-07, 'rewards/chosen': 0.016290094703435898, 'rewards/rejected': -1.650214433670044, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6665046215057373, 'policy_logps/rejected': -492.1248779296875, 'policy_logps/chosen': -523.223388671875, 'referece_logps/rejected': -475.6226806640625, 'referece_logps/chosen': -523.3862915039062, 'logits/rejected': -1.2052685022354126, 'logits/chosen': -1.1624372005462646, 'epoch': 3.33}


 56%|█████▌    | 8951/16104 [41:21:59<30:09:14, 15.18s/it]

 56%|█████▌    | 8952/16104 [41:22:19<32:58:02, 16.59s/it]

 56%|█████▌    | 8953/16104 [41:22:39<34:51:08, 17.55s/it]

 56%|█████▌    | 8954/16104 [41:22:55<34:09:10, 17.20s/it]
{'loss': 0.5853, 'learning_rate': 8.676461457357776e-07, 'rewards/chosen': -0.9367689490318298, 'rewards/rejected': -1.718456506729126, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7816876173019409, 'policy_logps/rejected': -394.4883728027344, 'policy_logps/chosen': -225.26467895507812, 'referece_logps/rejected': -377.30377197265625, 'referece_logps/chosen': -215.89698791503906, 'logits/rejected': -0.4359104633331299, 'logits/chosen': -0.3266897201538086, 'epoch': 3.34}

 56%|█████▌    | 8955/16104 [41:23:12<34:13:16, 17.23s/it]

 56%|█████▌    | 8956/16104 [41:23:28<33:03:49, 16.65s/it]

 56%|█████▌    | 8957/16104 [41:23:39<29:41:10, 14.95s/it]

 56%|█████▌    | 8958/16104 [41:23:57<31:52:03, 16.05s/it]

 56%|█████▌    | 8959/16104 [41:24:16<33:14:04, 16.75s/it]

 56%|█████▌    | 8960/16104 [41:24:26<29:46:12, 15.00s/it]

 56%|█████▌    | 8961/16104 [41:24:38<27:25:05, 13.82s/it]

 56%|█████▌    | 8962/16104 [41:24:53<28:27:35, 14.35s/it]

 56%|█████▌    | 8963/16104 [41:25:13<31:53:47, 16.08s/it]


 56%|█████▌    | 8965/16104 [41:25:49<33:07:48, 16.71s/it]
{'loss': 0.486, 'learning_rate': 8.654535456714281e-07, 'rewards/chosen': -0.799335777759552, 'rewards/rejected': -1.5390164852142334, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7396807074546814, 'policy_logps/rejected': -255.76268005371094, 'policy_logps/chosen': -293.3211364746094, 'referece_logps/rejected': -240.37249755859375, 'referece_logps/chosen': -285.3277587890625, 'logits/rejected': -0.2860208749771118, 'logits/chosen': -0.2265588939189911, 'epoch': 3.34}

 56%|█████▌    | 8966/16104 [41:26:00<30:06:42, 15.19s/it]

 56%|█████▌    | 8967/16104 [41:26:12<28:00:45, 14.13s/it]

 56%|█████▌    | 8968/16104 [41:26:31<31:05:26, 15.68s/it]

 56%|█████▌    | 8969/16104 [41:26:44<29:01:07, 14.64s/it]

 56%|█████▌    | 8970/16104 [41:27:03<32:03:07, 16.17s/it]

 56%|█████▌    | 8971/16104 [41:27:19<31:56:05, 16.12s/it]

 56%|█████▌    | 8972/16104 [41:27:39<33:53:57, 17.11s/it]


 56%|█████▌    | 8974/16104 [41:28:09<32:17:50, 16.31s/it]
{'loss': 0.4682, 'learning_rate': 8.636600895183245e-07, 'rewards/chosen': -0.27000731229782104, 'rewards/rejected': -0.9369499683380127, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6669425368309021, 'policy_logps/rejected': -463.6247863769531, 'policy_logps/chosen': -498.15191650390625, 'referece_logps/rejected': -454.25531005859375, 'referece_logps/chosen': -495.4518127441406, 'logits/rejected': -0.43476778268814087, 'logits/chosen': -0.43850985169410706, 'epoch': 3.34}

 56%|█████▌    | 8975/16104 [41:28:26<32:46:28, 16.55s/it]

 56%|█████▌    | 8976/16104 [41:28:44<33:40:22, 17.01s/it]

 56%|█████▌    | 8977/16104 [41:29:02<34:14:44, 17.30s/it]

 56%|█████▌    | 8978/16104 [41:29:22<35:34:17, 17.97s/it]

 56%|█████▌    | 8979/16104 [41:29:43<37:20:31, 18.87s/it]

 56%|█████▌    | 8980/16104 [41:29:56<34:12:40, 17.29s/it]

 56%|█████▌    | 8981/16104 [41:30:16<35:56:31, 18.17s/it]

 56%|█████▌    | 8982/16104 [41:30:37<37:15:55, 18.84s/it]

 56%|█████▌    | 8983/16104 [41:30:56<37:40:47, 19.05s/it]


 56%|█████▌    | 8985/16104 [41:31:25<32:48:06, 16.59s/it]

 56%|█████▌    | 8986/16104 [41:31:45<34:43:20, 17.56s/it]
{'loss': 0.6355, 'learning_rate': 8.612695105770774e-07, 'rewards/chosen': -0.9308916330337524, 'rewards/rejected': -2.0241479873657227, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0932564735412598, 'policy_logps/rejected': -356.2546691894531, 'policy_logps/chosen': -395.5149230957031, 'referece_logps/rejected': -336.01318359375, 'referece_logps/chosen': -386.20599365234375, 'logits/rejected': -0.4959767460823059, 'logits/chosen': -0.6039523482322693, 'epoch': 3.35}

 56%|█████▌    | 8987/16104 [41:32:04<35:09:00, 17.78s/it]


 56%|█████▌    | 8989/16104 [41:32:29<30:11:55, 15.28s/it]
{'loss': 0.4371, 'learning_rate': 8.606719915655092e-07, 'rewards/chosen': -0.6457656621932983, 'rewards/rejected': -2.1118526458740234, 'rewards/accuracies': 0.875, 'rewards/margins': 1.4660871028900146, 'policy_logps/rejected': -395.3346862792969, 'policy_logps/chosen': -370.6069641113281, 'referece_logps/rejected': -374.2161560058594, 'referece_logps/chosen': -364.1492919921875, 'logits/rejected': -0.5485903024673462, 'logits/chosen': -0.48517876863479614, 'epoch': 3.35}

 56%|█████▌    | 8990/16104 [41:32:49<32:53:01, 16.64s/it]

 56%|█████▌    | 8991/16104 [41:33:07<33:33:12, 16.98s/it]

 56%|█████▌    | 8992/16104 [41:33:19<30:39:04, 15.52s/it]

 56%|█████▌    | 8993/16104 [41:33:32<29:27:47, 14.92s/it]

 56%|█████▌    | 8994/16104 [41:33:48<29:44:12, 15.06s/it]

 56%|█████▌    | 8995/16104 [41:34:05<30:49:52, 15.61s/it]

 56%|█████▌    | 8996/16104 [41:34:21<31:01:19, 15.71s/it]

 56%|█████▌    | 8997/16104 [41:34:33<29:08:10, 14.76s/it]

 56%|█████▌    | 8998/16104 [41:34:48<29:21:57, 14.88s/it]

 56%|█████▌    | 8999/16104 [41:35:08<32:10:50, 16.31s/it]

 56%|█████▌    | 9000/16104 [41:35:25<32:25:14, 16.43s/it]


 56%|█████▌    | 9002/16104 [41:36:06<35:21:20, 17.92s/it]
{'loss': 0.5302, 'learning_rate': 8.58083331458972e-07, 'rewards/chosen': -1.0515025854110718, 'rewards/rejected': -1.3751676082611084, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3236650228500366, 'policy_logps/rejected': -294.4401550292969, 'policy_logps/chosen': -351.54638671875, 'referece_logps/rejected': -280.6884765625, 'referece_logps/chosen': -341.0313720703125, 'logits/rejected': -1.0222859382629395, 'logits/chosen': -1.0192731618881226, 'epoch': 3.35}

 56%|█████▌    | 9003/16104 [41:36:17<31:14:41, 15.84s/it]

 56%|█████▌    | 9004/16104 [41:36:36<33:29:40, 16.98s/it]

 56%|█████▌    | 9005/16104 [41:36:52<32:58:16, 16.72s/it]

 56%|█████▌    | 9006/16104 [41:37:10<33:42:50, 17.10s/it]

 56%|█████▌    | 9007/16104 [41:37:23<30:53:46, 15.67s/it]


 56%|█████▌    | 9009/16104 [41:38:00<34:13:55, 17.37s/it]
{'loss': 0.4139, 'learning_rate': 8.566898382825558e-07, 'rewards/chosen': -1.2589317560195923, 'rewards/rejected': -2.823632001876831, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5647001266479492, 'policy_logps/rejected': -315.5013732910156, 'policy_logps/chosen': -352.5333251953125, 'referece_logps/rejected': -287.2650451660156, 'referece_logps/chosen': -339.9440002441406, 'logits/rejected': -0.8681063055992126, 'logits/chosen': -0.9265251755714417, 'epoch': 3.36}

 56%|█████▌    | 9010/16104 [41:38:21<36:39:13, 18.60s/it]

 56%|█████▌    | 9011/16104 [41:38:36<34:31:57, 17.53s/it]

 56%|█████▌    | 9012/16104 [41:38:53<33:54:21, 17.21s/it]

 56%|█████▌    | 9013/16104 [41:39:12<35:15:50, 17.90s/it]

 56%|█████▌    | 9014/16104 [41:39:33<37:17:53, 18.94s/it]


 56%|█████▌    | 9016/16104 [41:40:10<36:42:27, 18.64s/it]
{'loss': 0.4216, 'learning_rate': 8.552966291665316e-07, 'rewards/chosen': -1.3730809688568115, 'rewards/rejected': -2.1523637771606445, 'rewards/accuracies': 0.875, 'rewards/margins': 0.779282808303833, 'policy_logps/rejected': -255.75762939453125, 'policy_logps/chosen': -239.59295654296875, 'referece_logps/rejected': -234.2340087890625, 'referece_logps/chosen': -225.86215209960938, 'logits/rejected': -0.5645972490310669, 'logits/chosen': -0.5840137004852295, 'epoch': 3.36}

 56%|█████▌    | 9017/16104 [41:40:23<33:09:01, 16.84s/it]


 56%|█████▌    | 9019/16104 [41:41:02<35:55:56, 18.26s/it]
{'loss': 0.4624, 'learning_rate': 8.546996271870051e-07, 'rewards/chosen': -0.7343520522117615, 'rewards/rejected': -2.5828311443328857, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8484790325164795, 'policy_logps/rejected': -254.07394409179688, 'policy_logps/chosen': -281.6072998046875, 'referece_logps/rejected': -228.24562072753906, 'referece_logps/chosen': -274.2637634277344, 'logits/rejected': -0.14096079766750336, 'logits/chosen': -0.09532660245895386, 'epoch': 3.36}

 56%|█████▌    | 9020/16104 [41:41:20<35:47:02, 18.18s/it]

 56%|█████▌    | 9021/16104 [41:41:37<35:06:16, 17.84s/it]

 56%|█████▌    | 9022/16104 [41:41:55<35:17:54, 17.94s/it]

 56%|█████▌    | 9023/16104 [41:42:08<32:03:10, 16.30s/it]

 56%|█████▌    | 9024/16104 [41:42:25<32:55:26, 16.74s/it]

 56%|█████▌    | 9025/16104 [41:42:45<34:36:19, 17.60s/it]

 56%|█████▌    | 9026/16104 [41:43:04<35:46:00, 18.19s/it]

 56%|█████▌    | 9027/16104 [41:43:24<36:15:14, 18.44s/it]

 56%|█████▌    | 9028/16104 [41:43:43<37:09:47, 18.91s/it]

 56%|█████▌    | 9029/16104 [41:44:01<36:13:25, 18.43s/it]

 56%|█████▌    | 9030/16104 [41:44:17<34:41:07, 17.65s/it]

 56%|█████▌    | 9031/16104 [41:44:38<36:42:20, 18.68s/it]

 56%|█████▌    | 9032/16104 [41:44:56<36:24:13, 18.53s/it]

 56%|█████▌    | 9033/16104 [41:45:16<37:01:22, 18.85s/it]

 56%|█████▌    | 9034/16104 [41:45:35<37:25:18, 19.06s/it]

 56%|█████▌    | 9035/16104 [41:45:52<36:09:36, 18.42s/it]

 56%|█████▌    | 9036/16104 [41:46:04<32:22:08, 16.49s/it]

 56%|█████▌    | 9037/16104 [41:46:22<33:22:52, 17.00s/it]

 56%|█████▌    | 9038/16104 [41:46:33<29:44:52, 15.16s/it]

 56%|█████▌    | 9039/16104 [41:46:47<29:06:53, 14.84s/it]

 56%|█████▌    | 9040/16104 [41:46:59<27:38:00, 14.08s/it]

 56%|█████▌    | 9041/16104 [41:47:12<26:50:34, 13.68s/it]

 56%|█████▌    | 9042/16104 [41:47:29<28:27:39, 14.51s/it]

 56%|█████▌    | 9043/16104 [41:47:46<30:00:27, 15.30s/it]

 56%|█████▌    | 9044/16104 [41:48:01<30:03:47, 15.33s/it]

 56%|█████▌    | 9045/16104 [41:48:17<30:28:44, 15.54s/it]

 56%|█████▌    | 9046/16104 [41:48:32<29:49:44, 15.21s/it]

 56%|█████▌    | 9047/16104 [41:48:47<29:48:04, 15.20s/it]

 56%|█████▌    | 9048/16104 [41:49:03<30:29:14, 15.55s/it]

 56%|█████▌    | 9049/16104 [41:49:22<32:20:24, 16.50s/it]

 56%|█████▌    | 9050/16104 [41:49:34<29:45:49, 15.19s/it]

 56%|█████▌    | 9051/16104 [41:49:55<32:54:34, 16.80s/it]

 56%|█████▌    | 9052/16104 [41:50:11<32:26:13, 16.56s/it]

 56%|█████▌    | 9053/16104 [41:50:24<30:17:52, 15.47s/it]

 56%|█████▌    | 9054/16104 [41:50:35<27:58:20, 14.28s/it]

 56%|█████▌    | 9055/16104 [41:50:48<27:20:26, 13.96s/it]

 56%|█████▌    | 9056/16104 [41:51:00<26:05:20, 13.33s/it]

 56%|█████▌    | 9057/16104 [41:51:12<25:19:36, 12.94s/it]

 56%|█████▌    | 9058/16104 [41:51:25<25:11:37, 12.87s/it]

 56%|█████▋    | 9059/16104 [41:51:37<24:50:53, 12.70s/it]

 56%|█████▋    | 9060/16104 [41:51:57<28:50:47, 14.74s/it]

 56%|█████▋    | 9061/16104 [41:52:11<28:42:10, 14.67s/it]

 56%|█████▋    | 9062/16104 [41:52:24<27:23:30, 14.00s/it]

 56%|█████▋    | 9063/16104 [41:52:42<30:02:02, 15.36s/it]

 56%|█████▋    | 9064/16104 [41:53:04<33:55:26, 17.35s/it]

 56%|█████▋    | 9065/16104 [41:53:20<32:54:08, 16.83s/it]

 56%|█████▋    | 9066/16104 [41:53:39<34:33:43, 17.68s/it]

 56%|█████▋    | 9067/16104 [41:53:57<34:32:41, 17.67s/it]

 56%|█████▋    | 9068/16104 [41:54:17<35:42:41, 18.27s/it]

 56%|█████▋    | 9069/16104 [41:54:39<38:06:26, 19.50s/it]

 56%|█████▋    | 9070/16104 [41:55:00<38:47:01, 19.85s/it]

 56%|█████▋    | 9071/16104 [41:55:13<34:56:06, 17.88s/it]

 56%|█████▋    | 9072/16104 [41:55:26<31:49:42, 16.29s/it]

 56%|█████▋    | 9073/16104 [41:55:44<32:54:43, 16.85s/it]

 56%|█████▋    | 9074/16104 [41:56:00<32:19:38, 16.55s/it]

 56%|█████▋    | 9075/16104 [41:56:14<31:19:01, 16.04s/it]

 56%|█████▋    | 9076/16104 [41:56:32<32:12:00, 16.49s/it]

 56%|█████▋    | 9077/16104 [41:56:46<30:50:00, 15.80s/it]

 56%|█████▋    | 9078/16104 [41:56:57<28:09:52, 14.43s/it]


 56%|█████▋    | 9080/16104 [41:57:39<34:09:50, 17.51s/it]

 56%|█████▋    | 9081/16104 [41:58:01<36:46:18, 18.85s/it]
{'loss': 0.5078, 'learning_rate': 8.423737486028428e-07, 'rewards/chosen': -0.7831987738609314, 'rewards/rejected': -1.3189959526062012, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5357971787452698, 'policy_logps/rejected': -352.85821533203125, 'policy_logps/chosen': -548.6712646484375, 'referece_logps/rejected': -339.6683044433594, 'referece_logps/chosen': -540.8392333984375, 'logits/rejected': -0.07086686044931412, 'logits/chosen': -0.06022762134671211, 'epoch': 3.38}


 56%|█████▋    | 9083/16104 [41:58:27<30:58:59, 15.89s/it]

 56%|█████▋    | 9084/16104 [41:58:39<28:54:38, 14.83s/it]

 56%|█████▋    | 9085/16104 [41:58:57<30:44:02, 15.76s/it]

 56%|█████▋    | 9086/16104 [41:59:09<28:53:23, 14.82s/it]

 56%|█████▋    | 9087/16104 [41:59:31<32:52:50, 16.87s/it]

 56%|█████▋    | 9088/16104 [41:59:49<33:42:55, 17.30s/it]

 56%|█████▋    | 9089/16104 [42:00:07<34:01:32, 17.46s/it]

 56%|█████▋    | 9090/16104 [42:00:26<34:57:28, 17.94s/it]

 56%|█████▋    | 9091/16104 [42:00:49<37:26:14, 19.22s/it]

 56%|█████▋    | 9092/16104 [42:01:09<38:17:40, 19.66s/it]

 56%|█████▋    | 9093/16104 [42:01:24<35:38:07, 18.30s/it]

 56%|█████▋    | 9094/16104 [42:01:46<37:36:13, 19.31s/it]

 56%|█████▋    | 9095/16104 [42:02:02<35:50:06, 18.41s/it]

 56%|█████▋    | 9096/16104 [42:02:21<35:42:42, 18.35s/it]
{'loss': 0.5346, 'learning_rate': 8.393952907675595e-07, 'rewards/chosen': -0.8704235553741455, 'rewards/rejected': -1.2208778858184814, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3504544198513031, 'policy_logps/rejected': -419.2154846191406, 'policy_logps/chosen': -445.7091064453125, 'referece_logps/rejected': -407.0067138671875, 'referece_logps/chosen': -437.0048522949219, 'logits/rejected': -0.11140292882919312, 'logits/chosen': -0.14571809768676758, 'epoch': 3.39}


 56%|█████▋    | 9098/16104 [42:02:52<32:20:01, 16.61s/it]

 57%|█████▋    | 9099/16104 [42:03:03<29:06:42, 14.96s/it]

 57%|█████▋    | 9100/16104 [42:03:21<30:28:23, 15.66s/it]

 57%|█████▋    | 9101/16104 [42:03:36<30:27:52, 15.66s/it]

 57%|█████▋    | 9102/16104 [42:03:54<31:34:36, 16.23s/it]

 57%|█████▋    | 9103/16104 [42:04:14<33:34:08, 17.26s/it]

 57%|█████▋    | 9104/16104 [42:04:29<32:29:40, 16.71s/it]

 57%|█████▋    | 9105/16104 [42:04:42<30:29:45, 15.69s/it]

 57%|█████▋    | 9106/16104 [42:05:01<32:01:24, 16.47s/it]

 57%|█████▋    | 9107/16104 [42:05:15<30:33:40, 15.72s/it]

 57%|█████▋    | 9108/16104 [42:05:30<30:22:32, 15.63s/it]

 57%|█████▋    | 9109/16104 [42:05:50<32:56:02, 16.95s/it]

 57%|█████▋    | 9110/16104 [42:06:08<33:47:17, 17.39s/it]

 57%|█████▋    | 9111/16104 [42:06:28<34:53:10, 17.96s/it]

 57%|█████▋    | 9112/16104 [42:06:39<30:47:49, 15.86s/it]

 57%|█████▋    | 9113/16104 [42:06:52<29:34:03, 15.23s/it]

 57%|█████▋    | 9114/16104 [42:07:05<27:49:45, 14.33s/it]

 57%|█████▋    | 9115/16104 [42:07:21<28:46:41, 14.82s/it]

 57%|█████▋    | 9116/16104 [42:07:36<29:14:34, 15.07s/it]

 57%|█████▋    | 9117/16104 [42:07:55<31:15:32, 16.11s/it]

 57%|█████▋    | 9118/16104 [42:08:09<30:15:52, 15.60s/it]
{'loss': 0.5142, 'learning_rate': 8.350295377412724e-07, 'rewards/chosen': -1.1768450736999512, 'rewards/rejected': -2.327324390411377, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1504791975021362, 'policy_logps/rejected': -311.1008605957031, 'policy_logps/chosen': -347.4537658691406, 'referece_logps/rejected': -287.8276062011719, 'referece_logps/chosen': -335.685302734375, 'logits/rejected': -0.07372982054948807, 'logits/chosen': 0.0014726966619491577, 'epoch': 3.4}


 57%|█████▋    | 9120/16104 [42:08:33<26:45:57, 13.80s/it]

 57%|█████▋    | 9121/16104 [42:08:49<28:23:05, 14.63s/it]

 57%|█████▋    | 9122/16104 [42:09:09<31:17:17, 16.13s/it]

 57%|█████▋    | 9123/16104 [42:09:25<30:52:46, 15.92s/it]

 57%|█████▋    | 9124/16104 [42:09:38<29:42:19, 15.32s/it]

 57%|█████▋    | 9125/16104 [42:09:57<31:27:05, 16.22s/it]

 57%|█████▋    | 9126/16104 [42:10:08<28:44:55, 14.83s/it]

 57%|█████▋    | 9127/16104 [42:10:25<30:00:39, 15.49s/it]
{'loss': 0.5839, 'learning_rate': 8.332444739472306e-07, 'rewards/chosen': -0.9539706707000732, 'rewards/rejected': -1.6598716974258423, 'rewards/accuracies': 0.75, 'rewards/margins': 0.705901026725769, 'policy_logps/rejected': -309.6166076660156, 'policy_logps/chosen': -328.0879211425781, 'referece_logps/rejected': -293.0179138183594, 'referece_logps/chosen': -318.5482177734375, 'logits/rejected': -1.1485790014266968, 'logits/chosen': -1.1602556705474854, 'epoch': 3.4}


 57%|█████▋    | 9129/16104 [42:11:02<33:17:26, 17.18s/it]
{'loss': 0.5424, 'learning_rate': 8.328478670993404e-07, 'rewards/chosen': -1.6103280782699585, 'rewards/rejected': -1.8851131200790405, 'rewards/accuracies': 0.75, 'rewards/margins': 0.27478504180908203, 'policy_logps/rejected': -384.5474853515625, 'policy_logps/chosen': -412.85772705078125, 'referece_logps/rejected': -365.69635009765625, 'referece_logps/chosen': -396.75445556640625, 'logits/rejected': -0.08502453565597534, 'logits/chosen': -0.15935176610946655, 'epoch': 3.4}


 57%|█████▋    | 9131/16104 [42:11:35<32:32:59, 16.80s/it]

 57%|█████▋    | 9132/16104 [42:11:50<31:08:56, 16.08s/it]
{'loss': 0.4806, 'learning_rate': 8.322530075595732e-07, 'rewards/chosen': -0.4829636812210083, 'rewards/rejected': -2.7543952465057373, 'rewards/accuracies': 0.625, 'rewards/margins': 2.2714314460754395, 'policy_logps/rejected': -288.1817626953125, 'policy_logps/chosen': -254.4224395751953, 'referece_logps/rejected': -260.6378173828125, 'referece_logps/chosen': -249.59280395507812, 'logits/rejected': -0.8617908954620361, 'logits/chosen': -0.8178369998931885, 'epoch': 3.4}

 57%|█████▋    | 9133/16104 [42:12:07<31:35:44, 16.32s/it]

 57%|█████▋    | 9134/16104 [42:12:26<33:29:31, 17.30s/it]

 57%|█████▋    | 9135/16104 [42:12:45<34:06:03, 17.62s/it]


 57%|█████▋    | 9137/16104 [42:13:13<30:18:29, 15.66s/it]

 57%|█████▋    | 9138/16104 [42:13:31<31:37:39, 16.35s/it]

 57%|█████▋    | 9139/16104 [42:13:45<30:10:29, 15.60s/it]

 57%|█████▋    | 9140/16104 [42:14:07<33:56:51, 17.55s/it]

 57%|█████▋    | 9141/16104 [42:14:22<32:02:43, 16.57s/it]
{'loss': 0.5257, 'learning_rate': 8.304687962323425e-07, 'rewards/chosen': -1.2916972637176514, 'rewards/rejected': -2.402045726776123, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1103485822677612, 'policy_logps/rejected': -435.9279479980469, 'policy_logps/chosen': -320.1854553222656, 'referece_logps/rejected': -411.9075012207031, 'referece_logps/chosen': -307.2684631347656, 'logits/rejected': -0.3916614353656769, 'logits/chosen': -0.11217013001441956, 'epoch': 3.41}

 57%|█████▋    | 9142/16104 [42:14:37<31:09:33, 16.11s/it]

 57%|█████▋    | 9143/16104 [42:14:49<28:49:13, 14.90s/it]

 57%|█████▋    | 9144/16104 [42:15:00<26:55:57, 13.93s/it]

 57%|█████▋    | 9145/16104 [42:15:14<27:02:00, 13.98s/it]


 57%|█████▋    | 9147/16104 [42:15:52<31:48:32, 16.46s/it]

 57%|█████▋    | 9148/16104 [42:16:10<32:53:21, 17.02s/it]
{'loss': 0.4904, 'learning_rate': 8.290814600507582e-07, 'rewards/chosen': -1.2067739963531494, 'rewards/rejected': -2.419642925262451, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2128691673278809, 'policy_logps/rejected': -456.88671875, 'policy_logps/chosen': -312.9391784667969, 'referece_logps/rejected': -432.6903076171875, 'referece_logps/chosen': -300.8714294433594, 'logits/rejected': -0.7537162899971008, 'logits/chosen': -0.5706713795661926, 'epoch': 3.41}


 57%|█████▋    | 9150/16104 [42:16:52<36:43:46, 19.01s/it]
{'loss': 0.5467, 'learning_rate': 8.286851403899802e-07, 'rewards/chosen': -0.9846570491790771, 'rewards/rejected': -1.283691644668579, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2990345358848572, 'policy_logps/rejected': -438.4718322753906, 'policy_logps/chosen': -488.84271240234375, 'referece_logps/rejected': -425.6349182128906, 'referece_logps/chosen': -478.99615478515625, 'logits/rejected': -0.07772254943847656, 'logits/chosen': 0.05217854678630829, 'epoch': 3.41}

 57%|█████▋    | 9151/16104 [42:17:03<31:57:17, 16.54s/it]

 57%|█████▋    | 9152/16104 [42:17:21<32:50:15, 17.00s/it]


 57%|█████▋    | 9154/16104 [42:18:00<34:46:16, 18.01s/it]

 57%|█████▋    | 9155/16104 [42:18:18<35:09:47, 18.22s/it]

 57%|█████▋    | 9156/16104 [42:18:38<36:02:05, 18.67s/it]

 57%|█████▋    | 9157/16104 [42:18:59<37:37:11, 19.49s/it]

 57%|█████▋    | 9158/16104 [42:19:10<32:34:26, 16.88s/it]
{'loss': 0.5449, 'learning_rate': 8.271001395877409e-07, 'rewards/chosen': -1.7130330801010132, 'rewards/rejected': -2.7120347023010254, 'rewards/accuracies': 0.875, 'rewards/margins': 0.999001681804657, 'policy_logps/rejected': -415.83544921875, 'policy_logps/chosen': -417.85992431640625, 'referece_logps/rejected': -388.7151184082031, 'referece_logps/chosen': -400.7296142578125, 'logits/rejected': -0.6394117474555969, 'logits/chosen': -0.6278868913650513, 'epoch': 3.41}


 57%|█████▋    | 9160/16104 [42:19:50<35:33:55, 18.44s/it]

 57%|█████▋    | 9161/16104 [42:20:06<34:11:07, 17.73s/it]

 57%|█████▋    | 9162/16104 [42:20:27<36:07:37, 18.73s/it]

 57%|█████▋    | 9163/16104 [42:20:46<35:47:59, 18.57s/it]

 57%|█████▋    | 9164/16104 [42:21:04<35:56:58, 18.65s/it]

 57%|█████▋    | 9165/16104 [42:21:23<36:11:20, 18.78s/it]

 57%|█████▋    | 9166/16104 [42:21:42<35:54:53, 18.64s/it]

 57%|█████▋    | 9167/16104 [42:22:00<35:23:23, 18.37s/it]

 57%|█████▋    | 9168/16104 [42:22:21<36:53:37, 19.15s/it]

 57%|█████▋    | 9169/16104 [42:22:40<37:09:35, 19.29s/it]
{'loss': 0.3731, 'learning_rate': 8.249214952060988e-07, 'rewards/chosen': -0.6253986954689026, 'rewards/rejected': -2.145136833190918, 'rewards/accuracies': 1.0, 'rewards/margins': 1.5197384357452393, 'policy_logps/rejected': -434.60595703125, 'policy_logps/chosen': -354.90673828125, 'referece_logps/rejected': -413.1546325683594, 'referece_logps/chosen': -348.65277099609375, 'logits/rejected': -0.536435067653656, 'logits/chosen': -0.3944407105445862, 'epoch': 3.42}


 57%|█████▋    | 9171/16104 [42:23:12<34:41:59, 18.02s/it]

 57%|█████▋    | 9172/16104 [42:23:24<30:41:27, 15.94s/it]

 57%|█████▋    | 9173/16104 [42:23:45<33:42:58, 17.51s/it]

 57%|█████▋    | 9174/16104 [42:24:04<34:53:30, 18.13s/it]
{'loss': 0.4329, 'learning_rate': 8.239314849539637e-07, 'rewards/chosen': -1.5054904222488403, 'rewards/rejected': -3.1228532791137695, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6173628568649292, 'policy_logps/rejected': -348.957275390625, 'policy_logps/chosen': -477.76910400390625, 'referece_logps/rejected': -317.728759765625, 'referece_logps/chosen': -462.7142028808594, 'logits/rejected': 0.09279055148363113, 'logits/chosen': -0.10855376720428467, 'epoch': 3.42}

 57%|█████▋    | 9175/16104 [42:24:19<33:02:13, 17.16s/it]


 57%|█████▋    | 9177/16104 [42:24:50<32:05:08, 16.68s/it]

 57%|█████▋    | 9178/16104 [42:25:10<33:46:36, 17.56s/it]
{'loss': 0.4617, 'learning_rate': 8.231396049053359e-07, 'rewards/chosen': -0.7009079456329346, 'rewards/rejected': -2.0433719158172607, 'rewards/accuracies': 0.75, 'rewards/margins': 1.3424638509750366, 'policy_logps/rejected': -438.2190856933594, 'policy_logps/chosen': -542.708984375, 'referece_logps/rejected': -417.78533935546875, 'referece_logps/chosen': -535.6998901367188, 'logits/rejected': 0.33915048837661743, 'logits/chosen': 0.3207337260246277, 'epoch': 3.42}

 57%|█████▋    | 9179/16104 [42:25:28<33:44:19, 17.54s/it]


 57%|█████▋    | 9181/16104 [42:26:04<34:13:24, 17.80s/it]

 57%|█████▋    | 9182/16104 [42:26:16<30:57:43, 16.10s/it]
{'loss': 0.4535, 'learning_rate': 8.223478393257993e-07, 'rewards/chosen': -0.816940188407898, 'rewards/rejected': -1.8520090579986572, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0350689888000488, 'policy_logps/rejected': -363.5160827636719, 'policy_logps/chosen': -463.4525451660156, 'referece_logps/rejected': -344.9959716796875, 'referece_logps/chosen': -455.28314208984375, 'logits/rejected': -1.169532060623169, 'logits/chosen': -1.377924919128418, 'epoch': 3.42}


 57%|█████▋    | 9184/16104 [42:26:46<29:54:02, 15.56s/it]

 57%|█████▋    | 9185/16104 [42:27:03<30:43:25, 15.99s/it]

 57%|█████▋    | 9186/16104 [42:27:18<30:11:04, 15.71s/it]

 57%|█████▋    | 9187/16104 [42:27:29<27:19:02, 14.22s/it]

 57%|█████▋    | 9188/16104 [42:27:41<26:00:11, 13.54s/it]
{'loss': 0.5954, 'learning_rate': 8.211604067070126e-07, 'rewards/chosen': -0.8833529353141785, 'rewards/rejected': -1.9406145811080933, 'rewards/accuracies': 0.875, 'rewards/margins': 1.05726158618927, 'policy_logps/rejected': -315.64398193359375, 'policy_logps/chosen': -442.78863525390625, 'referece_logps/rejected': -296.2378234863281, 'referece_logps/chosen': -433.9551696777344, 'logits/rejected': -0.24582454562187195, 'logits/chosen': 0.1760529726743698, 'epoch': 3.42}


 57%|█████▋    | 9190/16104 [42:28:04<23:56:45, 12.47s/it]

 57%|█████▋    | 9191/16104 [42:28:14<22:54:21, 11.93s/it]

 57%|█████▋    | 9192/16104 [42:28:31<25:27:29, 13.26s/it]
{'loss': 0.6179, 'learning_rate': 8.203689295420253e-07, 'rewards/chosen': -0.9309284687042236, 'rewards/rejected': -1.4262160062789917, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4952875077724457, 'policy_logps/rejected': -351.040283203125, 'policy_logps/chosen': -389.018798828125, 'referece_logps/rejected': -336.7781677246094, 'referece_logps/chosen': -379.70953369140625, 'logits/rejected': -0.11972690373659134, 'logits/chosen': -0.03655213862657547, 'epoch': 3.42}

 57%|█████▋    | 9193/16104 [42:28:42<23:58:55, 12.49s/it]

 57%|█████▋    | 9194/16104 [42:29:00<27:13:35, 14.18s/it]

 57%|█████▋    | 9195/16104 [42:29:20<30:28:25, 15.88s/it]


 57%|█████▋    | 9197/16104 [42:29:47<28:24:51, 14.81s/it]

 57%|█████▋    | 9198/16104 [42:30:04<29:39:18, 15.46s/it]
{'loss': 0.5786, 'learning_rate': 8.191819319465166e-07, 'rewards/chosen': -0.9818058013916016, 'rewards/rejected': -1.8346627950668335, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8528568148612976, 'policy_logps/rejected': -307.64044189453125, 'policy_logps/chosen': -524.587646484375, 'referece_logps/rejected': -289.2937927246094, 'referece_logps/chosen': -514.7695922851562, 'logits/rejected': -0.30424007773399353, 'logits/chosen': -0.16892778873443604, 'epoch': 3.43}


 57%|█████▋    | 9200/16104 [42:30:32<28:46:23, 15.00s/it]
{'loss': 0.4853, 'learning_rate': 8.187863245112975e-07, 'rewards/chosen': -1.3764368295669556, 'rewards/rejected': -1.950969934463501, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5745329856872559, 'policy_logps/rejected': -331.12158203125, 'policy_logps/chosen': -413.5569763183594, 'referece_logps/rejected': -311.61187744140625, 'referece_logps/chosen': -399.7926025390625, 'logits/rejected': -1.3465099334716797, 'logits/chosen': -1.17476224899292, 'epoch': 3.43}


 57%|█████▋    | 9202/16104 [42:31:06<30:08:21, 15.72s/it]

 57%|█████▋    | 9203/16104 [42:31:20<29:11:47, 15.23s/it]
{'loss': 0.5289, 'learning_rate': 8.181929683565944e-07, 'rewards/chosen': -1.4689589738845825, 'rewards/rejected': -2.267676591873169, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7987176179885864, 'policy_logps/rejected': -408.0379943847656, 'policy_logps/chosen': -325.43505859375, 'referece_logps/rejected': -385.36126708984375, 'referece_logps/chosen': -310.7454833984375, 'logits/rejected': -0.18011100590229034, 'logits/chosen': -0.20489318668842316, 'epoch': 3.43}


 57%|█████▋    | 9205/16104 [42:31:57<32:22:29, 16.89s/it]
{'loss': 0.4778, 'learning_rate': 8.177974343455522e-07, 'rewards/chosen': -0.809788167476654, 'rewards/rejected': -1.8428537845611572, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0330655574798584, 'policy_logps/rejected': -392.7790832519531, 'policy_logps/chosen': -634.1636962890625, 'referece_logps/rejected': -374.3504943847656, 'referece_logps/chosen': -626.0657958984375, 'logits/rejected': -1.0156984329223633, 'logits/chosen': -1.0628015995025635, 'epoch': 3.43}

 57%|█████▋    | 9206/16104 [42:32:14<32:19:11, 16.87s/it]

 57%|█████▋    | 9207/16104 [42:32:34<34:22:18, 17.94s/it]

 57%|█████▋    | 9208/16104 [42:32:48<32:05:33, 16.75s/it]

 57%|█████▋    | 9209/16104 [42:33:08<33:43:58, 17.61s/it]

 57%|█████▋    | 9210/16104 [42:33:24<32:59:16, 17.23s/it]


 57%|█████▋    | 9212/16104 [42:33:57<31:28:59, 16.45s/it]

 57%|█████▋    | 9213/16104 [42:34:09<29:05:34, 15.20s/it]
{'loss': 0.6038, 'learning_rate': 8.16215593758067e-07, 'rewards/chosen': -1.2187718152999878, 'rewards/rejected': -1.1698023080825806, 'rewards/accuracies': 0.375, 'rewards/margins': -0.04896952211856842, 'policy_logps/rejected': -347.84039306640625, 'policy_logps/chosen': -475.2797546386719, 'referece_logps/rejected': -336.14239501953125, 'referece_logps/chosen': -463.092041015625, 'logits/rejected': -0.3730763792991638, 'logits/chosen': -0.5705243349075317, 'epoch': 3.43}


 57%|█████▋    | 9215/16104 [42:34:41<30:09:22, 15.76s/it]
{'loss': 0.5833, 'learning_rate': 8.158202077953086e-07, 'rewards/chosen': -0.9617795944213867, 'rewards/rejected': -1.2322841882705688, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2705046832561493, 'policy_logps/rejected': -489.690185546875, 'policy_logps/chosen': -481.6712951660156, 'referece_logps/rejected': -477.3673400878906, 'referece_logps/chosen': -472.05352783203125, 'logits/rejected': -0.08058518171310425, 'logits/chosen': -0.04748521000146866, 'epoch': 3.43}

 57%|█████▋    | 9216/16104 [42:35:00<31:43:55, 16.58s/it]


 57%|█████▋    | 9218/16104 [42:35:29<29:02:48, 15.19s/it]

 57%|█████▋    | 9219/16104 [42:35:43<28:48:47, 15.07s/it]

 57%|█████▋    | 9220/16104 [42:36:00<29:59:09, 15.68s/it]

 57%|█████▋    | 9221/16104 [42:36:11<27:07:05, 14.18s/it]
{'loss': 0.5423, 'learning_rate': 8.146342289725418e-07, 'rewards/chosen': -0.9433754682540894, 'rewards/rejected': -1.4596024751663208, 'rewards/accuracies': 0.5, 'rewards/margins': 0.5162270069122314, 'policy_logps/rejected': -443.0654296875, 'policy_logps/chosen': -398.7734069824219, 'referece_logps/rejected': -428.46942138671875, 'referece_logps/chosen': -389.33966064453125, 'logits/rejected': -0.9312522411346436, 'logits/chosen': -0.922535240650177, 'epoch': 3.44}


 57%|█████▋    | 9223/16104 [42:36:33<24:06:44, 12.62s/it]
{'loss': 0.5328, 'learning_rate': 8.142389626000114e-07, 'rewards/chosen': -0.7399246692657471, 'rewards/rejected': -1.6178975105285645, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8779729604721069, 'policy_logps/rejected': -407.08526611328125, 'policy_logps/chosen': -322.99127197265625, 'referece_logps/rejected': -390.9063415527344, 'referece_logps/chosen': -315.5920104980469, 'logits/rejected': -0.9589400887489319, 'logits/chosen': -0.8994148373603821, 'epoch': 3.44}


 57%|█████▋    | 9225/16104 [42:37:05<28:04:49, 14.70s/it]

 57%|█████▋    | 9226/16104 [42:37:19<27:35:21, 14.44s/it]

 57%|█████▋    | 9227/16104 [42:37:39<30:46:49, 16.11s/it]
{'loss': 0.5595, 'learning_rate': 8.134485200912874e-07, 'rewards/chosen': -1.2847867012023926, 'rewards/rejected': -1.3467158079147339, 'rewards/accuracies': 0.5, 'rewards/margins': 0.06192895770072937, 'policy_logps/rejected': -332.422119140625, 'policy_logps/chosen': -378.46051025390625, 'referece_logps/rejected': -318.9549560546875, 'referece_logps/chosen': -365.6126708984375, 'logits/rejected': -0.4826306700706482, 'logits/chosen': -0.4629862308502197, 'epoch': 3.44}

 57%|█████▋    | 9228/16104 [42:37:52<29:11:49, 15.29s/it]

 57%|█████▋    | 9229/16104 [42:38:08<29:44:21, 15.57s/it]


 57%|█████▋    | 9231/16104 [42:38:35<27:23:11, 14.34s/it]
{'loss': 0.5658, 'learning_rate': 8.126581983240012e-07, 'rewards/chosen': -1.3505091667175293, 'rewards/rejected': -1.7701778411865234, 'rewards/accuracies': 0.5, 'rewards/margins': 0.4196687638759613, 'policy_logps/rejected': -468.45245361328125, 'policy_logps/chosen': -419.65728759765625, 'referece_logps/rejected': -450.75067138671875, 'referece_logps/chosen': -406.1521911621094, 'logits/rejected': -0.4200654923915863, 'logits/chosen': -0.4197881817817688, 'epoch': 3.44}

 57%|█████▋    | 9232/16104 [42:38:46<25:15:15, 13.23s/it]


 57%|█████▋    | 9234/16104 [42:39:23<30:11:45, 15.82s/it]
{'loss': 0.4165, 'learning_rate': 8.120655365428189e-07, 'rewards/chosen': -0.7686022520065308, 'rewards/rejected': -1.8552569150924683, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0866546630859375, 'policy_logps/rejected': -659.1818237304688, 'policy_logps/chosen': -594.3890380859375, 'referece_logps/rejected': -640.629150390625, 'referece_logps/chosen': -586.7030029296875, 'logits/rejected': -0.3953326344490051, 'logits/chosen': -0.07665976881980896, 'epoch': 3.44}


 57%|█████▋    | 9236/16104 [42:40:05<35:04:25, 18.38s/it]
{'loss': 0.4391, 'learning_rate': 8.116704666868004e-07, 'rewards/chosen': -0.6749982833862305, 'rewards/rejected': -1.8983738422393799, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2233755588531494, 'policy_logps/rejected': -339.7952575683594, 'policy_logps/chosen': -281.2221984863281, 'referece_logps/rejected': -320.8115234375, 'referece_logps/chosen': -274.4721984863281, 'logits/rejected': -0.6135897636413574, 'logits/chosen': -0.677147626876831, 'epoch': 3.44}

 57%|█████▋    | 9237/16104 [42:40:20<33:08:21, 17.37s/it]

 57%|█████▋    | 9238/16104 [42:40:40<34:23:00, 18.03s/it]


 57%|█████▋    | 9240/16104 [42:41:18<35:21:04, 18.54s/it]
{'loss': 0.4942, 'learning_rate': 8.108804184578708e-07, 'rewards/chosen': -0.8461726903915405, 'rewards/rejected': -1.4317582845687866, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5855857133865356, 'policy_logps/rejected': -410.5224304199219, 'policy_logps/chosen': -342.9275207519531, 'referece_logps/rejected': -396.20489501953125, 'referece_logps/chosen': -334.4658203125, 'logits/rejected': -0.37448519468307495, 'logits/chosen': -0.36352723836898804, 'epoch': 3.44}

 57%|█████▋    | 9241/16104 [42:41:34<34:01:23, 17.85s/it]


 57%|█████▋    | 9243/16104 [42:42:04<30:18:36, 15.90s/it]

 57%|█████▋    | 9244/16104 [42:42:21<31:25:06, 16.49s/it]
{'loss': 0.5352, 'learning_rate': 8.100904926325284e-07, 'rewards/chosen': -1.1034786701202393, 'rewards/rejected': -1.2857893705368042, 'rewards/accuracies': 0.375, 'rewards/margins': 0.18231074512004852, 'policy_logps/rejected': -393.216796875, 'policy_logps/chosen': -370.91796875, 'referece_logps/rejected': -380.35888671875, 'referece_logps/chosen': -359.8831481933594, 'logits/rejected': -0.4663337469100952, 'logits/chosen': -0.5021082162857056, 'epoch': 3.44}

 57%|█████▋    | 9245/16104 [42:42:32<28:05:28, 14.74s/it]

 57%|█████▋    | 9246/16104 [42:42:45<26:48:33, 14.07s/it]

 57%|█████▋    | 9247/16104 [42:42:57<25:56:49, 13.62s/it]

 57%|█████▋    | 9248/16104 [42:43:15<28:10:55, 14.80s/it]


 57%|█████▋    | 9250/16104 [42:43:49<30:14:22, 15.88s/it]
{'loss': 0.4736, 'learning_rate': 8.089058345196043e-07, 'rewards/chosen': -0.8848137259483337, 'rewards/rejected': -1.3975263833999634, 'rewards/accuracies': 0.75, 'rewards/margins': 0.5127126574516296, 'policy_logps/rejected': -376.28021240234375, 'policy_logps/chosen': -497.3297424316406, 'referece_logps/rejected': -362.3049621582031, 'referece_logps/chosen': -488.48162841796875, 'logits/rejected': -0.6795127987861633, 'logits/chosen': -0.6239839792251587, 'epoch': 3.45}

 57%|█████▋    | 9251/16104 [42:44:11<33:36:37, 17.66s/it]


 57%|█████▋    | 9253/16104 [42:44:36<28:42:14, 15.08s/it]

 57%|█████▋    | 9254/16104 [42:44:56<31:19:39, 16.46s/it]
{'loss': 0.5013, 'learning_rate': 8.081162169398274e-07, 'rewards/chosen': -0.7069970965385437, 'rewards/rejected': -1.2459664344787598, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5389692187309265, 'policy_logps/rejected': -454.2027893066406, 'policy_logps/chosen': -420.3194885253906, 'referece_logps/rejected': -441.74310302734375, 'referece_logps/chosen': -413.24951171875, 'logits/rejected': 0.34535282850265503, 'logits/chosen': 0.45126262307167053, 'epoch': 3.45}

 57%|█████▋    | 9255/16104 [42:45:06<27:59:17, 14.71s/it]

 57%|█████▋    | 9256/16104 [42:45:17<25:45:04, 13.54s/it]


 57%|█████▋    | 9258/16104 [42:45:48<26:42:42, 14.05s/it]
{'loss': 0.592, 'learning_rate': 8.073267235527077e-07, 'rewards/chosen': -0.9650196433067322, 'rewards/rejected': -1.4415016174316406, 'rewards/accuracies': 0.5, 'rewards/margins': 0.47648197412490845, 'policy_logps/rejected': -478.6310729980469, 'policy_logps/chosen': -362.9407958984375, 'referece_logps/rejected': -464.2160339355469, 'referece_logps/chosen': -353.2906188964844, 'logits/rejected': -0.260938823223114, 'logits/chosen': -0.07644549012184143, 'epoch': 3.45}


 58%|█████▊    | 9260/16104 [42:46:20<28:56:13, 15.22s/it]
{'loss': 0.4699, 'learning_rate': 8.069320235910794e-07, 'rewards/chosen': -1.2877638339996338, 'rewards/rejected': -1.2408431768417358, 'rewards/accuracies': 0.375, 'rewards/margins': -0.04692060500383377, 'policy_logps/rejected': -333.2388610839844, 'policy_logps/chosen': -223.07000732421875, 'referece_logps/rejected': -320.8304443359375, 'referece_logps/chosen': -210.19235229492188, 'logits/rejected': -0.26937392354011536, 'logits/chosen': -0.32896101474761963, 'epoch': 3.45}

 58%|█████▊    | 9261/16104 [42:46:38<30:22:05, 15.98s/it]

 58%|█████▊    | 9262/16104 [42:46:53<30:10:31, 15.88s/it]

 58%|█████▊    | 9263/16104 [42:47:09<30:23:34, 15.99s/it]


 58%|█████▊    | 9265/16104 [42:47:38<29:02:17, 15.29s/it]

 58%|█████▊    | 9266/16104 [42:47:56<30:53:15, 16.26s/it]

 58%|█████▊    | 9267/16104 [42:48:16<32:50:29, 17.29s/it]
{'loss': 0.4678, 'learning_rate': 8.05550820157689e-07, 'rewards/chosen': -1.5102639198303223, 'rewards/rejected': -1.7347886562347412, 'rewards/accuracies': 0.5, 'rewards/margins': 0.2245246171951294, 'policy_logps/rejected': -364.314453125, 'policy_logps/chosen': -397.4736022949219, 'referece_logps/rejected': -346.96661376953125, 'referece_logps/chosen': -382.3709411621094, 'logits/rejected': -0.8481689095497131, 'logits/chosen': -0.8888323903083801, 'epoch': 3.45}

 58%|█████▊    | 9268/16104 [42:48:31<31:21:17, 16.51s/it]

 58%|█████▊    | 9269/16104 [42:48:49<32:22:47, 17.05s/it]


 58%|█████▊    | 9271/16104 [42:49:18<29:33:37, 15.57s/it]

 58%|█████▊    | 9272/16104 [42:49:38<31:59:00, 16.85s/it]
{'loss': 0.4996, 'learning_rate': 8.045644820915429e-07, 'rewards/chosen': -0.9207172393798828, 'rewards/rejected': -1.815346598625183, 'rewards/accuracies': 0.5, 'rewards/margins': 0.8946293592453003, 'policy_logps/rejected': -349.5016784667969, 'policy_logps/chosen': -457.0091857910156, 'referece_logps/rejected': -331.34820556640625, 'referece_logps/chosen': -447.802001953125, 'logits/rejected': -1.1956671476364136, 'logits/chosen': -0.9850358963012695, 'epoch': 3.45}

 58%|█████▊    | 9273/16104 [42:49:51<29:45:44, 15.69s/it]

 58%|█████▊    | 9274/16104 [42:50:08<30:30:46, 16.08s/it]

 58%|█████▊    | 9275/16104 [42:50:19<27:53:08, 14.70s/it]


 58%|█████▊    | 9277/16104 [42:50:50<27:39:45, 14.59s/it]
{'loss': 0.5281, 'learning_rate': 8.035783416682672e-07, 'rewards/chosen': -1.1523526906967163, 'rewards/rejected': -1.5556453466415405, 'rewards/accuracies': 0.75, 'rewards/margins': 0.4032926559448242, 'policy_logps/rejected': -319.5627136230469, 'policy_logps/chosen': -384.1860046386719, 'referece_logps/rejected': -304.00628662109375, 'referece_logps/chosen': -372.6625061035156, 'logits/rejected': -0.5347956418991089, 'logits/chosen': -0.5751184225082397, 'epoch': 3.46}

 58%|█████▊    | 9278/16104 [42:51:03<26:54:02, 14.19s/it]

 58%|█████▊    | 9279/16104 [42:51:23<29:56:19, 15.79s/it]

 58%|█████▊    | 9280/16104 [42:51:38<29:29:00, 15.55s/it]

 58%|█████▊    | 9281/16104 [42:51:51<28:05:48, 14.82s/it]

 58%|█████▊    | 9282/16104 [42:52:03<26:45:27, 14.12s/it]

 58%|█████▊    | 9283/16104 [42:52:24<30:15:04, 15.97s/it]


 58%|█████▊    | 9285/16104 [42:52:52<28:52:13, 15.24s/it]
{'loss': 0.4629, 'learning_rate': 8.020009305773278e-07, 'rewards/chosen': -1.0720032453536987, 'rewards/rejected': -2.5026586055755615, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4306552410125732, 'policy_logps/rejected': -291.0428161621094, 'policy_logps/chosen': -335.972900390625, 'referece_logps/rejected': -266.0162048339844, 'referece_logps/chosen': -325.25286865234375, 'logits/rejected': -0.9357221126556396, 'logits/chosen': -0.7599291801452637, 'epoch': 3.46}

 58%|█████▊    | 9286/16104 [42:53:10<30:12:02, 15.95s/it]

 58%|█████▊    | 9287/16104 [42:53:23<28:38:23, 15.12s/it]

 58%|█████▊    | 9288/16104 [42:53:40<29:37:48, 15.65s/it]


 58%|█████▊    | 9290/16104 [42:54:04<26:17:17, 13.89s/it]

 58%|█████▊    | 9291/16104 [42:54:24<29:47:55, 15.75s/it]
{'loss': 0.564, 'learning_rate': 8.008182084312285e-07, 'rewards/chosen': -1.0477066040039062, 'rewards/rejected': -1.2871310710906982, 'rewards/accuracies': 0.625, 'rewards/margins': 0.2394244223833084, 'policy_logps/rejected': -177.7172393798828, 'policy_logps/chosen': -198.40023803710938, 'referece_logps/rejected': -164.84591674804688, 'referece_logps/chosen': -187.92318725585938, 'logits/rejected': -1.495875358581543, 'logits/chosen': -1.3439382314682007, 'epoch': 3.46}

 58%|█████▊    | 9292/16104 [42:54:37<28:13:31, 14.92s/it]


 58%|█████▊    | 9294/16104 [42:55:12<30:15:48, 16.00s/it]
{'loss': 0.4942, 'learning_rate': 8.002269560235306e-07, 'rewards/chosen': -0.41988301277160645, 'rewards/rejected': -1.9328151941299438, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5129320621490479, 'policy_logps/rejected': -386.6100769042969, 'policy_logps/chosen': -539.5238037109375, 'referece_logps/rejected': -367.2818908691406, 'referece_logps/chosen': -535.3250122070312, 'logits/rejected': -0.5665524005889893, 'logits/chosen': -0.5906120538711548, 'epoch': 3.46}


 58%|█████▊    | 9296/16104 [42:55:41<27:50:48, 14.73s/it]

 58%|█████▊    | 9297/16104 [42:55:53<26:20:00, 13.93s/it]
{'loss': 0.3798, 'learning_rate': 7.996357763464156e-07, 'rewards/chosen': -0.7580846548080444, 'rewards/rejected': -3.3360695838928223, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5779848098754883, 'policy_logps/rejected': -407.336669921875, 'policy_logps/chosen': -423.96875, 'referece_logps/rejected': -373.9759521484375, 'referece_logps/chosen': -416.387939453125, 'logits/rejected': -0.8116363883018494, 'logits/chosen': -0.6374079585075378, 'epoch': 3.46}

 58%|█████▊    | 9298/16104 [42:56:12<29:32:06, 15.62s/it]

 58%|█████▊    | 9299/16104 [42:56:25<28:01:49, 14.83s/it]

 58%|█████▊    | 9300/16104 [42:56:37<26:28:54, 14.01s/it]

 58%|█████▊    | 9301/16104 [42:56:57<29:41:24, 15.71s/it]

 58%|█████▊    | 9302/16104 [42:57:17<32:10:36, 17.03s/it]


 58%|█████▊    | 9304/16104 [42:57:46<30:31:39, 16.16s/it]
{'loss': 0.4352, 'learning_rate': 7.982566411499205e-07, 'rewards/chosen': -1.6306049823760986, 'rewards/rejected': -2.4711461067199707, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8405412435531616, 'policy_logps/rejected': -468.91357421875, 'policy_logps/chosen': -433.6488952636719, 'referece_logps/rejected': -444.20208740234375, 'referece_logps/chosen': -417.34283447265625, 'logits/rejected': -0.046036139130592346, 'logits/chosen': 0.13788917660713196, 'epoch': 3.47}

 58%|█████▊    | 9305/16104 [42:58:06<32:34:09, 17.25s/it]

 58%|█████▊    | 9306/16104 [42:58:20<30:49:19, 16.32s/it]

 58%|█████▊    | 9307/16104 [42:58:36<30:37:22, 16.22s/it]


 58%|█████▊    | 9309/16104 [42:59:03<27:15:28, 14.44s/it]
{'loss': 0.5787, 'learning_rate': 7.972717892479579e-07, 'rewards/chosen': -1.357742428779602, 'rewards/rejected': -1.4415394067764282, 'rewards/accuracies': 0.625, 'rewards/margins': 0.08379703760147095, 'policy_logps/rejected': -343.8226318359375, 'policy_logps/chosen': -332.27099609375, 'referece_logps/rejected': -329.4072265625, 'referece_logps/chosen': -318.6935729980469, 'logits/rejected': -0.39502134919166565, 'logits/chosen': -0.26010265946388245, 'epoch': 3.47}

 58%|█████▊    | 9310/16104 [42:59:13<25:10:02, 13.34s/it]

 58%|█████▊    | 9311/16104 [42:59:24<23:37:17, 12.52s/it]


 58%|█████▊    | 9313/16104 [43:00:01<29:26:29, 15.61s/it]
{'loss': 0.4881, 'learning_rate': 7.964840552914981e-07, 'rewards/chosen': -0.856762170791626, 'rewards/rejected': -1.648085594177246, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7913234829902649, 'policy_logps/rejected': -238.04086303710938, 'policy_logps/chosen': -242.6553955078125, 'referece_logps/rejected': -221.55999755859375, 'referece_logps/chosen': -234.08773803710938, 'logits/rejected': -0.2630902826786041, 'logits/chosen': -0.3057566285133362, 'epoch': 3.47}

 58%|█████▊    | 9314/16104 [43:00:20<31:18:12, 16.60s/it]

 58%|█████▊    | 9315/16104 [43:00:32<28:50:41, 15.30s/it]


 58%|█████▊    | 9317/16104 [43:01:11<32:55:43, 17.47s/it]

 58%|█████▊    | 9318/16104 [43:01:31<34:19:10, 18.21s/it]
{'loss': 0.4655, 'learning_rate': 7.954995731387737e-07, 'rewards/chosen': -0.6872280240058899, 'rewards/rejected': -1.8621456623077393, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1749176979064941, 'policy_logps/rejected': -364.9745788574219, 'policy_logps/chosen': -535.5839233398438, 'referece_logps/rejected': -346.35308837890625, 'referece_logps/chosen': -528.711669921875, 'logits/rejected': -0.16044338047504425, 'logits/chosen': -0.029973112046718597, 'epoch': 3.47}

 58%|█████▊    | 9319/16104 [43:01:46<32:41:18, 17.34s/it]

 58%|█████▊    | 9320/16104 [43:02:06<34:00:57, 18.05s/it]


 58%|█████▊    | 9322/16104 [43:02:37<32:04:20, 17.02s/it]

 58%|█████▊    | 9323/16104 [43:02:59<35:00:06, 18.58s/it]

 58%|█████▊    | 9324/16104 [43:03:13<32:25:35, 17.22s/it]

 58%|█████▊    | 9325/16104 [43:03:31<32:38:31, 17.33s/it]
{'loss': 0.454, 'learning_rate': 7.941216457890081e-07, 'rewards/chosen': -0.7002792954444885, 'rewards/rejected': -3.0372474193573, 'rewards/accuracies': 1.0, 'rewards/margins': 2.336968183517456, 'policy_logps/rejected': -334.4361267089844, 'policy_logps/chosen': -329.7291564941406, 'referece_logps/rejected': -304.06365966796875, 'referece_logps/chosen': -322.72637939453125, 'logits/rejected': 0.29394951462745667, 'logits/chosen': 0.33110061287879944, 'epoch': 3.47}


 58%|█████▊    | 9327/16104 [43:04:05<32:00:56, 17.01s/it]

 58%|█████▊    | 9328/16104 [43:04:23<32:49:52, 17.44s/it]
{'loss': 0.5459, 'learning_rate': 7.935312302592062e-07, 'rewards/chosen': -0.990070641040802, 'rewards/rejected': -1.7406803369522095, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7506097555160522, 'policy_logps/rejected': -367.1546325683594, 'policy_logps/chosen': -258.4080505371094, 'referece_logps/rejected': -349.74786376953125, 'referece_logps/chosen': -248.50735473632812, 'logits/rejected': -0.10533176362514496, 'logits/chosen': 0.00019120797514915466, 'epoch': 3.48}

 58%|█████▊    | 9329/16104 [43:04:36<30:20:16, 16.12s/it]


 58%|█████▊    | 9331/16104 [43:05:05<28:34:55, 15.19s/it]

 58%|█████▊    | 9332/16104 [43:05:19<27:44:06, 14.74s/it]

 58%|█████▊    | 9333/16104 [43:05:39<30:35:14, 16.26s/it]

 58%|█████▊    | 9334/16104 [43:05:54<29:42:08, 15.79s/it]

 58%|█████▊    | 9335/16104 [43:06:13<31:53:14, 16.96s/it]
{'loss': 0.5726, 'learning_rate': 7.921538867155178e-07, 'rewards/chosen': -1.1103218793869019, 'rewards/rejected': -0.8511905670166016, 'rewards/accuracies': 0.375, 'rewards/margins': -0.2591312527656555, 'policy_logps/rejected': -426.6825256347656, 'policy_logps/chosen': -381.34283447265625, 'referece_logps/rejected': -418.1706237792969, 'referece_logps/chosen': -370.2396240234375, 'logits/rejected': -0.7272117733955383, 'logits/chosen': -0.7152759432792664, 'epoch': 3.48}

 58%|█████▊    | 9336/16104 [43:06:32<33:08:25, 17.63s/it]


 58%|█████▊    | 9338/16104 [43:07:06<31:38:25, 16.83s/it]

 58%|█████▊    | 9339/16104 [43:07:23<31:52:43, 16.96s/it]
{'loss': 0.5904, 'learning_rate': 7.913670180572936e-07, 'rewards/chosen': -1.251457929611206, 'rewards/rejected': -2.917454719543457, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6659969091415405, 'policy_logps/rejected': -591.4964599609375, 'policy_logps/chosen': -490.0668029785156, 'referece_logps/rejected': -562.3218994140625, 'referece_logps/chosen': -477.55218505859375, 'logits/rejected': 0.2358100712299347, 'logits/chosen': 0.27388566732406616, 'epoch': 3.48}


 58%|█████▊    | 9341/16104 [43:07:51<28:31:44, 15.19s/it]
{'loss': 0.5024, 'learning_rate': 7.909736343338107e-07, 'rewards/chosen': -1.281896948814392, 'rewards/rejected': -1.3724420070648193, 'rewards/accuracies': 0.5, 'rewards/margins': 0.09054490923881531, 'policy_logps/rejected': -380.5191650390625, 'policy_logps/chosen': -407.52899169921875, 'referece_logps/rejected': -366.7947692871094, 'referece_logps/chosen': -394.71002197265625, 'logits/rejected': -0.48994526267051697, 'logits/chosen': -0.519413411617279, 'epoch': 3.48}


 58%|█████▊    | 9343/16104 [43:08:19<26:54:18, 14.33s/it]

 58%|█████▊    | 9344/16104 [43:08:35<27:48:32, 14.81s/it]

 58%|█████▊    | 9345/16104 [43:08:46<25:28:46, 13.57s/it]
{'loss': 0.4482, 'learning_rate': 7.901869684163646e-07, 'rewards/chosen': -0.6329927444458008, 'rewards/rejected': -1.5004767179489136, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8674840927124023, 'policy_logps/rejected': -325.037109375, 'policy_logps/chosen': -491.3161926269531, 'referece_logps/rejected': -310.0323181152344, 'referece_logps/chosen': -484.9862976074219, 'logits/rejected': -0.5564666390419006, 'logits/chosen': -0.504252552986145, 'epoch': 3.48}

 58%|█████▊    | 9346/16104 [43:08:57<23:53:18, 12.73s/it]

 58%|█████▊    | 9347/16104 [43:09:10<24:23:21, 12.99s/it]

 58%|█████▊    | 9348/16104 [43:09:23<24:02:36, 12.81s/it]


 58%|█████▊    | 9350/16104 [43:09:58<28:42:50, 15.31s/it]
{'loss': 0.4883, 'learning_rate': 7.892038270437152e-07, 'rewards/chosen': -1.0157212018966675, 'rewards/rejected': -1.7793724536895752, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7636513113975525, 'policy_logps/rejected': -378.8636779785156, 'policy_logps/chosen': -507.6282958984375, 'referece_logps/rejected': -361.0699768066406, 'referece_logps/chosen': -497.4710693359375, 'logits/rejected': -0.19450098276138306, 'logits/chosen': -0.25822845101356506, 'epoch': 3.48}

 58%|█████▊    | 9351/16104 [43:10:11<27:42:44, 14.77s/it]

 58%|█████▊    | 9352/16104 [43:10:31<30:27:21, 16.24s/it]


 58%|█████▊    | 9354/16104 [43:11:09<33:37:45, 17.94s/it]
{'loss': 0.4392, 'learning_rate': 7.884174673853309e-07, 'rewards/chosen': -0.9842752814292908, 'rewards/rejected': -1.7955994606018066, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8113241791725159, 'policy_logps/rejected': -592.0604248046875, 'policy_logps/chosen': -730.7943725585938, 'referece_logps/rejected': -574.1044921875, 'referece_logps/chosen': -720.95166015625, 'logits/rejected': -0.9290990829467773, 'logits/chosen': -0.9721527099609375, 'epoch': 3.49}

 58%|█████▊    | 9355/16104 [43:11:25<32:15:51, 17.21s/it]

 58%|█████▊    | 9356/16104 [43:11:37<29:20:49, 15.66s/it]


 58%|█████▊    | 9358/16104 [43:12:18<33:40:09, 17.97s/it]
{'loss': 0.3853, 'learning_rate': 7.876312446691959e-07, 'rewards/chosen': -1.2241406440734863, 'rewards/rejected': -2.887148141860962, 'rewards/accuracies': 0.75, 'rewards/margins': 1.6630076169967651, 'policy_logps/rejected': -376.05389404296875, 'policy_logps/chosen': -332.46209716796875, 'referece_logps/rejected': -347.1824035644531, 'referece_logps/chosen': -320.2206726074219, 'logits/rejected': -0.2902261018753052, 'logits/chosen': -0.13705694675445557, 'epoch': 3.49}

 58%|█████▊    | 9359/16104 [43:12:37<34:21:37, 18.34s/it]


 58%|█████▊    | 9361/16104 [43:13:10<32:19:45, 17.26s/it]
{'loss': 0.4227, 'learning_rate': 7.870416678065637e-07, 'rewards/chosen': -0.7482576370239258, 'rewards/rejected': -1.632771611213684, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8845139741897583, 'policy_logps/rejected': -442.7958068847656, 'policy_logps/chosen': -499.3686828613281, 'referece_logps/rejected': -426.46807861328125, 'referece_logps/chosen': -491.88604736328125, 'logits/rejected': -0.6408230066299438, 'logits/chosen': -0.5961672067642212, 'epoch': 3.49}

 58%|█████▊    | 9362/16104 [43:13:27<32:12:33, 17.20s/it]

 58%|█████▊    | 9363/16104 [43:13:47<34:01:43, 18.17s/it]

 58%|█████▊    | 9364/16104 [43:14:03<32:19:57, 17.27s/it]

 58%|█████▊    | 9365/16104 [43:14:24<34:33:21, 18.46s/it]

 58%|█████▊    | 9366/16104 [43:14:37<31:34:59, 16.87s/it]

 58%|█████▊    | 9367/16104 [43:14:53<30:59:18, 16.56s/it]


 58%|█████▊    | 9369/16104 [43:15:28<32:28:44, 17.36s/it]
{'loss': 0.5198, 'learning_rate': 7.854698424623915e-07, 'rewards/chosen': -1.1739816665649414, 'rewards/rejected': -1.8260043859481812, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6520228385925293, 'policy_logps/rejected': -426.97509765625, 'policy_logps/chosen': -467.4267578125, 'referece_logps/rejected': -408.7150573730469, 'referece_logps/chosen': -455.68695068359375, 'logits/rejected': -0.3059176206588745, 'logits/chosen': -0.43934276700019836, 'epoch': 3.49}


 58%|█████▊    | 9371/16104 [43:16:04<33:18:35, 17.81s/it]
{'loss': 0.4769, 'learning_rate': 7.85076972748681e-07, 'rewards/chosen': -0.9588921070098877, 'rewards/rejected': -3.2842166423797607, 'rewards/accuracies': 0.75, 'rewards/margins': 2.325324535369873, 'policy_logps/rejected': -530.9970703125, 'policy_logps/chosen': -377.48699951171875, 'referece_logps/rejected': -498.1549072265625, 'referece_logps/chosen': -367.89813232421875, 'logits/rejected': -0.34512612223625183, 'logits/chosen': -0.24875538051128387, 'epoch': 3.49}

 58%|█████▊    | 9372/16104 [43:16:20<32:02:29, 17.13s/it]


 58%|█████▊    | 9374/16104 [43:16:51<29:30:15, 15.78s/it]
{'loss': 0.5644, 'learning_rate': 7.844877334031277e-07, 'rewards/chosen': -0.8437573313713074, 'rewards/rejected': -1.471609115600586, 'rewards/accuracies': 0.625, 'rewards/margins': 0.6278519034385681, 'policy_logps/rejected': -320.464111328125, 'policy_logps/chosen': -254.16688537597656, 'referece_logps/rejected': -305.7480163574219, 'referece_logps/chosen': -245.72930908203125, 'logits/rejected': -0.6920944452285767, 'logits/chosen': -0.660797119140625, 'epoch': 3.49}

 58%|█████▊    | 9375/16104 [43:17:06<29:09:16, 15.60s/it]

 58%|█████▊    | 9376/16104 [43:17:21<29:13:30, 15.64s/it]

 58%|█████▊    | 9377/16104 [43:17:32<26:24:04, 14.13s/it]

 58%|█████▊    | 9378/16104 [43:17:44<25:09:39, 13.47s/it]

 58%|█████▊    | 9379/16104 [43:17:58<25:26:52, 13.62s/it]

 58%|█████▊    | 9380/16104 [43:18:14<26:52:50, 14.39s/it]

 58%|█████▊    | 9381/16104 [43:18:34<29:57:28, 16.04s/it]

 58%|█████▊    | 9382/16104 [43:18:49<29:14:37, 15.66s/it]

 58%|█████▊    | 9383/16104 [43:19:09<31:40:26, 16.97s/it]


 58%|█████▊    | 9385/16104 [43:19:46<33:28:29, 17.94s/it]
{'loss': 0.4595, 'learning_rate': 7.823278620420939e-07, 'rewards/chosen': -1.1397615671157837, 'rewards/rejected': -2.1401126384735107, 'rewards/accuracies': 0.75, 'rewards/margins': 1.000351071357727, 'policy_logps/rejected': -481.1922912597656, 'policy_logps/chosen': -449.2325134277344, 'referece_logps/rejected': -459.7911682128906, 'referece_logps/chosen': -437.8348693847656, 'logits/rejected': -0.367252916097641, 'logits/chosen': -0.1928648054599762, 'epoch': 3.5}

 58%|█████▊    | 9386/16104 [43:20:06<34:15:42, 18.36s/it]

 58%|█████▊    | 9387/16104 [43:20:17<30:23:30, 16.29s/it]

 58%|█████▊    | 9388/16104 [43:20:32<29:26:03, 15.78s/it]

 58%|█████▊    | 9389/16104 [43:20:48<29:33:13, 15.84s/it]

 58%|█████▊    | 9390/16104 [43:21:08<31:44:52, 17.02s/it]


 58%|█████▊    | 9392/16104 [43:21:37<29:14:12, 15.68s/it]
{'loss': 0.4218, 'learning_rate': 7.80953952510771e-07, 'rewards/chosen': -0.48034191131591797, 'rewards/rejected': -2.4390432834625244, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9587011337280273, 'policy_logps/rejected': -399.9771423339844, 'policy_logps/chosen': -415.31890869140625, 'referece_logps/rejected': -375.5867004394531, 'referece_logps/chosen': -410.5154724121094, 'logits/rejected': 0.2116391509771347, 'logits/chosen': 0.34498071670532227, 'epoch': 3.5}

 58%|█████▊    | 9393/16104 [43:21:47<26:24:36, 14.17s/it]

 58%|█████▊    | 9394/16104 [43:21:59<25:11:38, 13.52s/it]

 58%|█████▊    | 9395/16104 [43:22:18<27:47:19, 14.91s/it]

 58%|█████▊    | 9396/16104 [43:22:37<30:27:15, 16.34s/it]

 58%|█████▊    | 9397/16104 [43:22:57<32:26:00, 17.41s/it]

 58%|█████▊    | 9398/16104 [43:23:16<33:23:58, 17.93s/it]


 58%|█████▊    | 9400/16104 [43:23:49<31:45:16, 17.05s/it]
{'loss': 0.5695, 'learning_rate': 7.793843019961356e-07, 'rewards/chosen': -1.232831358909607, 'rewards/rejected': -1.144787073135376, 'rewards/accuracies': 0.5, 'rewards/margins': -0.08804435282945633, 'policy_logps/rejected': -295.9499206542969, 'policy_logps/chosen': -418.9066467285156, 'referece_logps/rejected': -284.5020446777344, 'referece_logps/chosen': -406.57830810546875, 'logits/rejected': -0.8894791007041931, 'logits/chosen': -0.9406720399856567, 'epoch': 3.5}

 58%|█████▊    | 9401/16104 [43:24:05<31:33:53, 16.95s/it]

 58%|█████▊    | 9402/16104 [43:24:20<30:33:08, 16.41s/it]

 58%|█████▊    | 9403/16104 [43:24:34<28:41:32, 15.41s/it]

 58%|█████▊    | 9404/16104 [43:24:52<30:28:11, 16.37s/it]

 58%|█████▊    | 9405/16104 [43:25:04<27:50:41, 14.96s/it]

 58%|█████▊    | 9406/16104 [43:25:22<29:23:52, 15.80s/it]

 58%|█████▊    | 9407/16104 [43:25:40<30:43:43, 16.52s/it]


 58%|█████▊    | 9409/16104 [43:26:09<28:22:54, 15.26s/it]

 58%|█████▊    | 9410/16104 [43:26:27<29:44:06, 15.99s/it]
{'loss': 0.5224, 'learning_rate': 7.774230425156247e-07, 'rewards/chosen': -0.5188673138618469, 'rewards/rejected': -2.2878053188323975, 'rewards/accuracies': 0.75, 'rewards/margins': 1.7689380645751953, 'policy_logps/rejected': -367.27093505859375, 'policy_logps/chosen': -395.8475646972656, 'referece_logps/rejected': -344.39288330078125, 'referece_logps/chosen': -390.65887451171875, 'logits/rejected': -0.18333078920841217, 'logits/chosen': -0.09110906720161438, 'epoch': 3.51}

 58%|█████▊    | 9411/16104 [43:26:41<28:58:34, 15.59s/it]


 58%|█████▊    | 9413/16104 [43:27:07<26:26:58, 14.23s/it]
{'loss': 0.4748, 'learning_rate': 7.768348398814118e-07, 'rewards/chosen': -0.5851083397865295, 'rewards/rejected': -2.498936653137207, 'rewards/accuracies': 0.875, 'rewards/margins': 1.9138282537460327, 'policy_logps/rejected': -619.5164794921875, 'policy_logps/chosen': -344.55633544921875, 'referece_logps/rejected': -594.527099609375, 'referece_logps/chosen': -338.7052307128906, 'logits/rejected': 0.34521472454071045, 'logits/chosen': 0.472067266702652, 'epoch': 3.51}

 58%|█████▊    | 9414/16104 [43:27:19<25:15:59, 13.60s/it]


 58%|█████▊    | 9416/16104 [43:27:49<26:36:25, 14.32s/it]
{'loss': 0.471, 'learning_rate': 7.762467184940573e-07, 'rewards/chosen': -0.9316375851631165, 'rewards/rejected': -1.6798691749572754, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7482315301895142, 'policy_logps/rejected': -349.2060546875, 'policy_logps/chosen': -266.1349792480469, 'referece_logps/rejected': -332.4073791503906, 'referece_logps/chosen': -256.8185729980469, 'logits/rejected': -0.9898371696472168, 'logits/chosen': -0.9595068097114563, 'epoch': 3.51}

 58%|█████▊    | 9417/16104 [43:28:03<26:35:07, 14.31s/it]

 58%|█████▊    | 9418/16104 [43:28:24<29:58:53, 16.14s/it]

 58%|█████▊    | 9419/16104 [43:28:44<32:18:02, 17.39s/it]

 58%|█████▊    | 9420/16104 [43:29:01<32:13:55, 17.36s/it]


 59%|█████▊    | 9422/16104 [43:29:31<29:45:09, 16.03s/it]
{'loss': 0.4696, 'learning_rate': 7.750707203163543e-07, 'rewards/chosen': -1.392767071723938, 'rewards/rejected': -2.6024112701416016, 'rewards/accuracies': 0.875, 'rewards/margins': 1.2096443176269531, 'policy_logps/rejected': -380.356201171875, 'policy_logps/chosen': -246.67117309570312, 'referece_logps/rejected': -354.3321228027344, 'referece_logps/chosen': -232.74346923828125, 'logits/rejected': -0.977411150932312, 'logits/chosen': -0.789589524269104, 'epoch': 3.51}


 59%|█████▊    | 9424/16104 [43:29:59<28:10:04, 15.18s/it]
{'loss': 0.4397, 'learning_rate': 7.746787936295468e-07, 'rewards/chosen': -0.07666891813278198, 'rewards/rejected': -1.2670587301254272, 'rewards/accuracies': 0.875, 'rewards/margins': 1.19038987159729, 'policy_logps/rejected': -503.14739990234375, 'policy_logps/chosen': -501.994140625, 'referece_logps/rejected': -490.47686767578125, 'referece_logps/chosen': -501.2274475097656, 'logits/rejected': -0.2778483033180237, 'logits/chosen': -0.21618130803108215, 'epoch': 3.51}

 59%|█████▊    | 9425/16104 [43:30:15<28:35:06, 15.41s/it]


 59%|█████▊    | 9427/16104 [43:30:49<29:41:42, 16.01s/it]
{'loss': 0.4836, 'learning_rate': 7.740909719789874e-07, 'rewards/chosen': -1.0473260879516602, 'rewards/rejected': -2.0828354358673096, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0355092287063599, 'policy_logps/rejected': -462.15484619140625, 'policy_logps/chosen': -516.4170532226562, 'referece_logps/rejected': -441.32647705078125, 'referece_logps/chosen': -505.94378662109375, 'logits/rejected': -0.1394212245941162, 'logits/chosen': -0.31175294518470764, 'epoch': 3.51}


 59%|█████▊    | 9429/16104 [43:31:15<27:07:48, 14.63s/it]
{'loss': 0.5535, 'learning_rate': 7.736991365575208e-07, 'rewards/chosen': -1.829262614250183, 'rewards/rejected': -3.0608296394348145, 'rewards/accuracies': 0.75, 'rewards/margins': 1.2315670251846313, 'policy_logps/rejected': -520.9453125, 'policy_logps/chosen': -497.02423095703125, 'referece_logps/rejected': -490.3370361328125, 'referece_logps/chosen': -478.73162841796875, 'logits/rejected': 0.24198991060256958, 'logits/chosen': 0.2216176688671112, 'epoch': 3.51}

 59%|█████▊    | 9430/16104 [43:31:35<30:04:20, 16.22s/it]

 59%|█████▊    | 9431/16104 [43:31:47<27:30:18, 14.84s/it]

 59%|█████▊    | 9432/16104 [43:32:05<29:25:15, 15.87s/it]

 59%|█████▊    | 9433/16104 [43:32:19<28:14:12, 15.24s/it]

 59%|█████▊    | 9434/16104 [43:32:32<27:18:46, 14.74s/it]


 59%|█████▊    | 9436/16104 [43:33:09<30:35:59, 16.52s/it]
{'loss': 0.5103, 'learning_rate': 7.723280013580287e-07, 'rewards/chosen': -0.848289966583252, 'rewards/rejected': -1.5541563034057617, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7058664560317993, 'policy_logps/rejected': -370.0556945800781, 'policy_logps/chosen': -250.93572998046875, 'referece_logps/rejected': -354.51409912109375, 'referece_logps/chosen': -242.45281982421875, 'logits/rejected': -1.3767582178115845, 'logits/chosen': -1.2167402505874634, 'epoch': 3.52}

 59%|█████▊    | 9437/16104 [43:33:23<28:47:39, 15.55s/it]

 59%|█████▊    | 9438/16104 [43:33:38<28:51:35, 15.59s/it]


 59%|█████▊    | 9440/16104 [43:34:01<25:09:54, 13.59s/it]
{'loss': 0.4866, 'learning_rate': 7.715446979696833e-07, 'rewards/chosen': -0.9941026568412781, 'rewards/rejected': -1.4430328607559204, 'rewards/accuracies': 0.875, 'rewards/margins': 0.44893014430999756, 'policy_logps/rejected': -477.02227783203125, 'policy_logps/chosen': -383.29376220703125, 'referece_logps/rejected': -462.5919494628906, 'referece_logps/chosen': -373.3527526855469, 'logits/rejected': -0.8109748959541321, 'logits/chosen': -0.5730292797088623, 'epoch': 3.52}

 59%|█████▊    | 9441/16104 [43:34:15<25:04:31, 13.55s/it]


 59%|█████▊    | 9443/16104 [43:34:46<27:18:37, 14.76s/it]
{'loss': 0.5482, 'learning_rate': 7.709573174356564e-07, 'rewards/chosen': -0.7353029847145081, 'rewards/rejected': -1.2466402053833008, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5113372802734375, 'policy_logps/rejected': -385.2931823730469, 'policy_logps/chosen': -396.6335144042969, 'referece_logps/rejected': -372.8267517089844, 'referece_logps/chosen': -389.28045654296875, 'logits/rejected': -0.02376629412174225, 'logits/chosen': -0.06506040692329407, 'epoch': 3.52}


 59%|█████▊    | 9445/16104 [43:35:21<29:38:32, 16.03s/it]
{'loss': 0.4, 'learning_rate': 7.705657767256975e-07, 'rewards/chosen': -0.21799544990062714, 'rewards/rejected': -2.0301661491394043, 'rewards/accuracies': 0.875, 'rewards/margins': 1.8121707439422607, 'policy_logps/rejected': -438.1363220214844, 'policy_logps/chosen': -519.662109375, 'referece_logps/rejected': -417.8346252441406, 'referece_logps/chosen': -517.4821166992188, 'logits/rejected': -0.7768499255180359, 'logits/chosen': -0.7474459409713745, 'epoch': 3.52}

 59%|█████▊    | 9446/16104 [43:35:37<29:31:32, 15.96s/it]

 59%|█████▊    | 9447/16104 [43:35:54<30:17:19, 16.38s/it]

 59%|█████▊    | 9448/16104 [43:36:14<32:02:29, 17.33s/it]

 59%|█████▊    | 9449/16104 [43:36:30<31:20:05, 16.95s/it]

 59%|█████▊    | 9450/16104 [43:36:51<33:21:58, 18.05s/it]

 59%|█████▊    | 9451/16104 [43:37:11<34:23:20, 18.61s/it]

 59%|█████▊    | 9452/16104 [43:37:28<33:45:43, 18.27s/it]

 59%|█████▊    | 9453/16104 [43:37:44<32:42:14, 17.70s/it]

 59%|█████▊    | 9454/16104 [43:38:05<34:02:17, 18.43s/it]

 59%|█████▊    | 9455/16104 [43:38:15<29:47:37, 16.13s/it]

 59%|█████▊    | 9456/16104 [43:38:28<27:58:00, 15.14s/it]

 59%|█████▊    | 9457/16104 [43:38:47<29:55:17, 16.21s/it]

 59%|█████▊    | 9458/16104 [43:39:05<30:59:33, 16.79s/it]

 59%|█████▊    | 9459/16104 [43:39:27<33:46:58, 18.30s/it]

 59%|█████▊    | 9460/16104 [43:39:41<31:22:43, 17.00s/it]

 59%|█████▊    | 9461/16104 [43:40:00<32:48:41, 17.78s/it]

 59%|█████▉    | 9462/16104 [43:40:11<28:51:42, 15.64s/it]

 59%|█████▉    | 9463/16104 [43:40:29<30:07:06, 16.33s/it]


 59%|█████▉    | 9465/16104 [43:41:07<32:50:09, 17.81s/it]

 59%|█████▉    | 9466/16104 [43:41:19<29:25:19, 15.96s/it]

 59%|█████▉    | 9467/16104 [43:41:35<29:31:55, 16.02s/it]

 59%|█████▉    | 9468/16104 [43:41:47<27:22:26, 14.85s/it]

 59%|█████▉    | 9469/16104 [43:42:05<28:51:19, 15.66s/it]

 59%|█████▉    | 9470/16104 [43:42:20<28:51:04, 15.66s/it]

 59%|█████▉    | 9471/16104 [43:42:31<26:02:22, 14.13s/it]
{'loss': 0.4893, 'learning_rate': 7.654791488415006e-07, 'rewards/chosen': -1.0301868915557861, 'rewards/rejected': -1.560388207435608, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5302013754844666, 'policy_logps/rejected': -256.60504150390625, 'policy_logps/chosen': -318.28973388671875, 'referece_logps/rejected': -241.00115966796875, 'referece_logps/chosen': -307.9878845214844, 'logits/rejected': -0.22060850262641907, 'logits/chosen': -0.5542441606521606, 'epoch': 3.53}

 59%|█████▉    | 9472/16104 [43:42:52<29:45:38, 16.15s/it]


 59%|█████▉    | 9474/16104 [43:43:25<30:16:21, 16.44s/it]

 59%|█████▉    | 9475/16104 [43:43:37<27:34:35, 14.98s/it]

 59%|█████▉    | 9476/16104 [43:43:47<25:12:21, 13.69s/it]

 59%|█████▉    | 9477/16104 [43:44:03<26:05:14, 14.17s/it]

 59%|█████▉    | 9478/16104 [43:44:19<27:05:07, 14.72s/it]

 59%|█████▉    | 9479/16104 [43:44:41<31:07:22, 16.91s/it]

 59%|█████▉    | 9480/16104 [43:44:57<30:37:37, 16.65s/it]

 59%|█████▉    | 9481/16104 [43:45:19<33:48:08, 18.37s/it]

 59%|█████▉    | 9482/16104 [43:45:38<33:58:22, 18.47s/it]
{'loss': 0.3476, 'learning_rate': 7.633290364778283e-07, 'rewards/chosen': -1.0175399780273438, 'rewards/rejected': -2.1714155673980713, 'rewards/accuracies': 0.875, 'rewards/margins': 1.1538755893707275, 'policy_logps/rejected': -418.1923828125, 'policy_logps/chosen': -401.2895812988281, 'referece_logps/rejected': -396.47821044921875, 'referece_logps/chosen': -391.1141357421875, 'logits/rejected': -0.37229543924331665, 'logits/chosen': -0.20950916409492493, 'epoch': 3.53}


 59%|█████▉    | 9484/16104 [43:46:12<32:44:45, 17.81s/it]

 59%|█████▉    | 9485/16104 [43:46:32<33:44:17, 18.35s/it]

 59%|█████▉    | 9486/16104 [43:46:43<29:48:52, 16.22s/it]

 59%|█████▉    | 9487/16104 [43:47:04<32:27:12, 17.66s/it]
{'loss': 0.351, 'learning_rate': 7.623520949941737e-07, 'rewards/chosen': -1.30078125, 'rewards/rejected': -2.911128044128418, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6103471517562866, 'policy_logps/rejected': -307.6680603027344, 'policy_logps/chosen': -464.1754150390625, 'referece_logps/rejected': -278.5567626953125, 'referece_logps/chosen': -451.1675720214844, 'logits/rejected': -0.6741825342178345, 'logits/chosen': -0.7505167722702026, 'epoch': 3.53}


 59%|█████▉    | 9489/16104 [43:47:33<30:09:20, 16.41s/it]

 59%|█████▉    | 9490/16104 [43:47:50<30:04:34, 16.37s/it]
{'loss': 0.6076, 'learning_rate': 7.61766045400133e-07, 'rewards/chosen': -1.1308774948120117, 'rewards/rejected': -2.786529302597046, 'rewards/accuracies': 0.875, 'rewards/margins': 1.6556519269943237, 'policy_logps/rejected': -355.8985900878906, 'policy_logps/chosen': -392.7873229980469, 'referece_logps/rejected': -328.0332946777344, 'referece_logps/chosen': -381.47857666015625, 'logits/rejected': -0.4705403447151184, 'logits/chosen': -0.4384227395057678, 'epoch': 3.54}

 59%|█████▉    | 9491/16104 [43:48:04<29:03:09, 15.82s/it]


 59%|█████▉    | 9493/16104 [43:48:45<33:25:56, 18.21s/it]

 59%|█████▉    | 9494/16104 [43:49:03<33:27:14, 18.22s/it]
{'loss': 0.5062, 'learning_rate': 7.609847808961214e-07, 'rewards/chosen': -1.258732557296753, 'rewards/rejected': -2.6972925662994385, 'rewards/accuracies': 0.875, 'rewards/margins': 1.438559889793396, 'policy_logps/rejected': -458.59063720703125, 'policy_logps/chosen': -308.03326416015625, 'referece_logps/rejected': -431.61767578125, 'referece_logps/chosen': -295.4459533691406, 'logits/rejected': -0.6287401914596558, 'logits/chosen': -0.6641891598701477, 'epoch': 3.54}


 59%|█████▉    | 9496/16104 [43:49:41<33:47:48, 18.41s/it]

 59%|█████▉    | 9497/16104 [43:49:57<32:22:53, 17.64s/it]

 59%|█████▉    | 9498/16104 [43:50:11<30:15:12, 16.49s/it]

 59%|█████▉    | 9499/16104 [43:50:31<32:09:05, 17.52s/it]

 59%|█████▉    | 9500/16104 [43:50:51<33:24:08, 18.21s/it]
{'loss': 0.5068, 'learning_rate': 7.598131743558442e-07, 'rewards/chosen': -1.5117820501327515, 'rewards/rejected': -1.5918421745300293, 'rewards/accuracies': 0.5, 'rewards/margins': 0.08006006479263306, 'policy_logps/rejected': -382.81256103515625, 'policy_logps/chosen': -332.6451416015625, 'referece_logps/rejected': -366.8941650390625, 'referece_logps/chosen': -317.52728271484375, 'logits/rejected': 0.16828399896621704, 'logits/chosen': 0.17368736863136292, 'epoch': 3.54}

 59%|█████▉    | 9501/16104 [43:51:27<43:11:12, 23.55s/it]


 59%|█████▉    | 9503/16104 [43:52:02<38:21:57, 20.92s/it]

 59%|█████▉    | 9504/16104 [43:52:24<38:50:57, 21.19s/it]
{'loss': 0.4507, 'learning_rate': 7.590322975433856e-07, 'rewards/chosen': -1.5006998777389526, 'rewards/rejected': -1.99810791015625, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4974082112312317, 'policy_logps/rejected': -445.83184814453125, 'policy_logps/chosen': -496.8150634765625, 'referece_logps/rejected': -425.85076904296875, 'referece_logps/chosen': -481.80804443359375, 'logits/rejected': -0.5409337282180786, 'logits/chosen': -0.49379515647888184, 'epoch': 3.54}


 59%|█████▉    | 9506/16104 [43:52:53<31:58:51, 17.45s/it]

 59%|█████▉    | 9507/16104 [43:53:05<28:50:06, 15.74s/it]

 59%|█████▉    | 9508/16104 [43:53:23<30:07:21, 16.44s/it]
{'loss': 0.4456, 'learning_rate': 7.582515766920965e-07, 'rewards/chosen': -1.0350284576416016, 'rewards/rejected': -2.5131847858428955, 'rewards/accuracies': 0.625, 'rewards/margins': 1.4781564474105835, 'policy_logps/rejected': -777.091796875, 'policy_logps/chosen': -466.83758544921875, 'referece_logps/rejected': -751.9599609375, 'referece_logps/chosen': -456.4873046875, 'logits/rejected': -0.38960909843444824, 'logits/chosen': -0.3501482307910919, 'epoch': 3.54}

 59%|█████▉    | 9509/16104 [43:53:37<28:42:45, 15.67s/it]

 59%|█████▉    | 9510/16104 [43:53:53<28:48:15, 15.73s/it]


 59%|█████▉    | 9512/16104 [43:54:30<31:26:33, 17.17s/it]
{'loss': 0.4508, 'learning_rate': 7.57471012307281e-07, 'rewards/chosen': -1.1409047842025757, 'rewards/rejected': -1.9173122644424438, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7764074802398682, 'policy_logps/rejected': -302.3531799316406, 'policy_logps/chosen': -459.0729675292969, 'referece_logps/rejected': -283.1800537109375, 'referece_logps/chosen': -447.66387939453125, 'logits/rejected': -0.20156411826610565, 'logits/chosen': -0.22830581665039062, 'epoch': 3.54}

 59%|█████▉    | 9513/16104 [43:54:41<27:55:58, 15.26s/it]


 59%|█████▉    | 9515/16104 [43:55:08<26:48:40, 14.65s/it]

 59%|█████▉    | 9516/16104 [43:55:26<28:31:30, 15.59s/it]

 59%|█████▉    | 9517/16104 [43:55:40<27:21:32, 14.95s/it]

 59%|█████▉    | 9518/16104 [43:55:56<28:00:43, 15.31s/it]

 59%|█████▉    | 9519/16104 [43:56:08<26:26:52, 14.46s/it]
{'loss': 0.4723, 'learning_rate': 7.561054026508078e-07, 'rewards/chosen': -0.8351802229881287, 'rewards/rejected': -2.069516181945801, 'rewards/accuracies': 1.0, 'rewards/margins': 1.2343361377716064, 'policy_logps/rejected': -366.3610534667969, 'policy_logps/chosen': -371.16082763671875, 'referece_logps/rejected': -345.66583251953125, 'referece_logps/chosen': -362.8089904785156, 'logits/rejected': -1.0848442316055298, 'logits/chosen': -0.924094557762146, 'epoch': 3.55}

 59%|█████▉    | 9520/16104 [43:56:27<28:44:25, 15.71s/it]


 59%|█████▉    | 9522/16104 [43:56:59<28:35:05, 15.63s/it]

 59%|█████▉    | 9523/16104 [43:57:20<31:06:39, 17.02s/it]

 59%|█████▉    | 9524/16104 [43:57:39<32:32:36, 17.80s/it]

 59%|█████▉    | 9525/16104 [43:57:58<33:07:25, 18.13s/it]

 59%|█████▉    | 9526/16104 [43:58:11<30:29:37, 16.69s/it]

 59%|█████▉    | 9527/16104 [43:58:29<30:45:40, 16.84s/it]

 59%|█████▉    | 9528/16104 [43:58:51<33:35:38, 18.39s/it]

 59%|█████▉    | 9529/16104 [43:59:10<34:21:21, 18.81s/it]

 59%|█████▉    | 9530/16104 [43:59:30<34:53:35, 19.11s/it]

 59%|█████▉    | 9531/16104 [43:59:49<34:26:00, 18.86s/it]

 59%|█████▉    | 9532/16104 [44:00:08<34:52:42, 19.11s/it]

 59%|█████▉    | 9533/16104 [44:00:19<30:31:53, 16.73s/it]
{'loss': 0.4802, 'learning_rate': 7.533756363413321e-07, 'rewards/chosen': -0.9420931339263916, 'rewards/rejected': -2.0596585273742676, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1175655126571655, 'policy_logps/rejected': -238.8663787841797, 'policy_logps/chosen': -271.55230712890625, 'referece_logps/rejected': -218.26979064941406, 'referece_logps/chosen': -262.13134765625, 'logits/rejected': -0.26057136058807373, 'logits/chosen': -0.05594414472579956, 'epoch': 3.55}

 59%|█████▉    | 9534/16104 [44:00:39<32:04:11, 17.57s/it]


 59%|█████▉    | 9536/16104 [44:01:13<31:07:07, 17.06s/it]

 59%|█████▉    | 9537/16104 [44:01:28<29:59:17, 16.44s/it]

 59%|█████▉    | 9538/16104 [44:01:41<28:13:18, 15.47s/it]

 59%|█████▉    | 9539/16104 [44:01:58<28:55:47, 15.86s/it]

 59%|█████▉    | 9540/16104 [44:02:16<30:14:41, 16.59s/it]

 59%|█████▉    | 9541/16104 [44:02:30<28:39:15, 15.72s/it]
{'loss': 0.4856, 'learning_rate': 7.518166464134626e-07, 'rewards/chosen': -0.7018648386001587, 'rewards/rejected': -1.6450546979904175, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9431898593902588, 'policy_logps/rejected': -484.8154602050781, 'policy_logps/chosen': -525.7011108398438, 'referece_logps/rejected': -468.36492919921875, 'referece_logps/chosen': -518.6824951171875, 'logits/rejected': -0.24318459630012512, 'logits/chosen': -0.3390035331249237, 'epoch': 3.55}


 59%|█████▉    | 9543/16104 [44:03:05<30:28:22, 16.72s/it]

 59%|█████▉    | 9544/16104 [44:03:25<32:09:11, 17.65s/it]

 59%|█████▉    | 9545/16104 [44:03:44<33:09:38, 18.20s/it]

 59%|█████▉    | 9546/16104 [44:03:58<30:46:40, 16.90s/it]

 59%|█████▉    | 9547/16104 [44:04:12<29:12:08, 16.03s/it]

 59%|█████▉    | 9548/16104 [44:04:32<31:35:02, 17.34s/it]

 59%|█████▉    | 9549/16104 [44:04:52<32:54:07, 18.07s/it]

 59%|█████▉    | 9550/16104 [44:05:04<29:33:18, 16.23s/it]

 59%|█████▉    | 9551/16104 [44:05:16<27:20:29, 15.02s/it]

 59%|█████▉    | 9552/16104 [44:05:29<25:51:42, 14.21s/it]
{'loss': 0.6234, 'learning_rate': 7.496740852094268e-07, 'rewards/chosen': -0.6418712139129639, 'rewards/rejected': -1.1986064910888672, 'rewards/accuracies': 0.875, 'rewards/margins': 0.5567352771759033, 'policy_logps/rejected': -364.6737060546875, 'policy_logps/chosen': -488.14312744140625, 'referece_logps/rejected': -352.6876220703125, 'referece_logps/chosen': -481.7244567871094, 'logits/rejected': -0.24585162103176117, 'logits/chosen': -0.03062310814857483, 'epoch': 3.56}

 59%|█████▉    | 9553/16104 [44:05:47<28:20:28, 15.57s/it]

 59%|█████▉    | 9554/16104 [44:06:00<26:31:47, 14.58s/it]

 59%|█████▉    | 9555/16104 [44:06:16<27:11:55, 14.95s/it]


 59%|█████▉    | 9557/16104 [44:06:48<28:16:11, 15.54s/it]

 59%|█████▉    | 9558/16104 [44:07:08<30:38:26, 16.85s/it]

 59%|█████▉    | 9559/16104 [44:07:24<30:07:11, 16.57s/it]
{'loss': 0.469, 'learning_rate': 7.483112744548266e-07, 'rewards/chosen': -0.40724316239356995, 'rewards/rejected': -1.562638521194458, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1553953886032104, 'policy_logps/rejected': -297.9759826660156, 'policy_logps/chosen': -244.32705688476562, 'referece_logps/rejected': -282.3495788574219, 'referece_logps/chosen': -240.254638671875, 'logits/rejected': -0.9067734479904175, 'logits/chosen': -0.9225286841392517, 'epoch': 3.56}


 59%|█████▉    | 9561/16104 [44:07:57<29:09:02, 16.04s/it]

 59%|█████▉    | 9562/16104 [44:08:12<29:03:17, 15.99s/it]
{'loss': 0.4457, 'learning_rate': 7.477273652642275e-07, 'rewards/chosen': -1.2043801546096802, 'rewards/rejected': -2.215770959854126, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0113909244537354, 'policy_logps/rejected': -623.87646484375, 'policy_logps/chosen': -496.0268249511719, 'referece_logps/rejected': -601.71875, 'referece_logps/chosen': -483.98297119140625, 'logits/rejected': -0.44988173246383667, 'logits/chosen': -0.33328011631965637, 'epoch': 3.56}


 59%|█████▉    | 9564/16104 [44:08:43<28:09:54, 15.50s/it]

 59%|█████▉    | 9565/16104 [44:09:05<31:24:02, 17.29s/it]
{'loss': 0.5109, 'learning_rate': 7.471435479175304e-07, 'rewards/chosen': -1.1210702657699585, 'rewards/rejected': -2.581691026687622, 'rewards/accuracies': 0.875, 'rewards/margins': 1.460620641708374, 'policy_logps/rejected': -401.00274658203125, 'policy_logps/chosen': -330.6852722167969, 'referece_logps/rejected': -375.18585205078125, 'referece_logps/chosen': -319.47454833984375, 'logits/rejected': -0.9133168458938599, 'logits/chosen': -0.8144285678863525, 'epoch': 3.56}


 59%|█████▉    | 9567/16104 [44:09:37<30:49:21, 16.97s/it]


 59%|█████▉    | 9568/16104 [44:09:57<32:06:36, 17.69s/it]

 59%|█████▉    | 9569/16104 [44:10:09<29:17:00, 16.13s/it]

 59%|█████▉    | 9570/16104 [44:10:25<29:10:09, 16.07s/it]

 59%|█████▉    | 9571/16104 [44:10:41<28:43:19, 15.83s/it]

 59%|█████▉    | 9572/16104 [44:10:55<28:15:22, 15.57s/it]

 59%|█████▉    | 9573/16104 [44:11:09<27:22:47, 15.09s/it]

 59%|█████▉    | 9574/16104 [44:11:31<30:43:23, 16.94s/it]

 59%|█████▉    | 9575/16104 [44:11:50<32:04:17, 17.68s/it]

 59%|█████▉    | 9576/16104 [44:12:07<31:30:58, 17.38s/it]
{'loss': 0.4541, 'learning_rate': 7.450036735230989e-07, 'rewards/chosen': -1.8542275428771973, 'rewards/rejected': -2.6259617805480957, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7717342972755432, 'policy_logps/rejected': -487.87847900390625, 'policy_logps/chosen': -387.7044982910156, 'referece_logps/rejected': -461.6188659667969, 'referece_logps/chosen': -369.1622314453125, 'logits/rejected': -1.3712105751037598, 'logits/chosen': -1.2498409748077393, 'epoch': 3.57}

 59%|█████▉    | 9577/16104 [44:12:26<32:19:30, 17.83s/it]

 59%|█████▉    | 9578/16104 [44:12:44<32:43:30, 18.05s/it]

 59%|█████▉    | 9579/16104 [44:12:56<29:21:13, 16.20s/it]


 59%|█████▉    | 9581/16104 [44:13:29<29:32:44, 16.31s/it]

 60%|█████▉    | 9582/16104 [44:13:45<29:06:03, 16.06s/it]
{'loss': 0.5537, 'learning_rate': 7.43836994706982e-07, 'rewards/chosen': -1.6073740720748901, 'rewards/rejected': -1.6275771856307983, 'rewards/accuracies': 0.5, 'rewards/margins': 0.02020324021577835, 'policy_logps/rejected': -523.8961181640625, 'policy_logps/chosen': -463.2077331542969, 'referece_logps/rejected': -507.6202392578125, 'referece_logps/chosen': -447.134033203125, 'logits/rejected': -0.6108109951019287, 'logits/chosen': -0.5613859295845032, 'epoch': 3.57}

 60%|█████▉    | 9583/16104 [44:13:56<26:42:45, 14.75s/it]


 60%|█████▉    | 9585/16104 [44:14:30<28:27:05, 15.71s/it]
{'loss': 0.3351, 'learning_rate': 7.432537950831257e-07, 'rewards/chosen': -0.9622917771339417, 'rewards/rejected': -1.489638090133667, 'rewards/accuracies': 1.0, 'rewards/margins': 0.5273464322090149, 'policy_logps/rejected': -334.3779296875, 'policy_logps/chosen': -468.1033630371094, 'referece_logps/rejected': -319.4815368652344, 'referece_logps/chosen': -458.4804992675781, 'logits/rejected': 0.2485814243555069, 'logits/chosen': 0.10496014356613159, 'epoch': 3.57}

 60%|█████▉    | 9586/16104 [44:14:45<28:08:35, 15.54s/it]


 60%|█████▉    | 9588/16104 [44:15:19<29:40:35, 16.40s/it]
{'loss': 0.4506, 'learning_rate': 7.426706889318462e-07, 'rewards/chosen': -1.050502061843872, 'rewards/rejected': -2.8674659729003906, 'rewards/accuracies': 1.0, 'rewards/margins': 1.816964030265808, 'policy_logps/rejected': -265.5621643066406, 'policy_logps/chosen': -334.66363525390625, 'referece_logps/rejected': -236.88751220703125, 'referece_logps/chosen': -324.15863037109375, 'logits/rejected': -0.0994701087474823, 'logits/chosen': -0.28748205304145813, 'epoch': 3.57}

 60%|█████▉    | 9589/16104 [44:15:39<31:25:55, 17.37s/it]


 60%|█████▉    | 9591/16104 [44:16:16<32:11:44, 17.80s/it]
{'loss': 0.4549, 'learning_rate': 7.420876764654325e-07, 'rewards/chosen': -0.8016178607940674, 'rewards/rejected': -2.7118232250213623, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9102052450180054, 'policy_logps/rejected': -367.24005126953125, 'policy_logps/chosen': -326.10369873046875, 'referece_logps/rejected': -340.121826171875, 'referece_logps/chosen': -318.0875244140625, 'logits/rejected': -0.9683880805969238, 'logits/chosen': -0.9049230813980103, 'epoch': 3.57}

 60%|█████▉    | 9592/16104 [44:16:37<33:53:43, 18.74s/it]

 60%|█████▉    | 9593/16104 [44:16:56<34:16:06, 18.95s/it]


 60%|█████▉    | 9595/16104 [44:17:35<34:21:23, 19.00s/it]

 60%|█████▉    | 9596/16104 [44:17:47<30:24:56, 16.82s/it]

 60%|█████▉    | 9597/16104 [44:18:03<29:57:29, 16.57s/it]

 60%|█████▉    | 9598/16104 [44:18:21<30:43:11, 17.00s/it]
{'loss': 0.5419, 'learning_rate': 7.407276795660677e-07, 'rewards/chosen': -1.2432876825332642, 'rewards/rejected': -3.401998996734619, 'rewards/accuracies': 0.875, 'rewards/margins': 2.1587111949920654, 'policy_logps/rejected': -468.1789245605469, 'policy_logps/chosen': -554.7951049804688, 'referece_logps/rejected': -434.158935546875, 'referece_logps/chosen': -542.3621826171875, 'logits/rejected': -0.3150123357772827, 'logits/chosen': -0.417221337556839, 'epoch': 3.58}

 60%|█████▉    | 9599/16104 [44:18:32<27:36:21, 15.28s/it]

 60%|█████▉    | 9600/16104 [44:18:43<25:08:28, 13.92s/it]


 60%|█████▉    | 9602/16104 [44:19:11<24:45:36, 13.71s/it]

 60%|█████▉    | 9603/16104 [44:19:22<23:10:31, 12.83s/it]
{'loss': 0.5289, 'learning_rate': 7.397565676930252e-07, 'rewards/chosen': -0.6636157631874084, 'rewards/rejected': -1.5192482471466064, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8556324243545532, 'policy_logps/rejected': -256.0323181152344, 'policy_logps/chosen': -431.20550537109375, 'referece_logps/rejected': -240.83981323242188, 'referece_logps/chosen': -424.5693359375, 'logits/rejected': -0.8995382785797119, 'logits/chosen': -0.9721219539642334, 'epoch': 3.58}


 60%|█████▉    | 9605/16104 [44:19:52<24:16:36, 13.45s/it]

 60%|█████▉    | 9606/16104 [44:20:06<24:41:17, 13.68s/it]

 60%|█████▉    | 9607/16104 [44:20:18<23:35:47, 13.07s/it]

 60%|█████▉    | 9608/16104 [44:20:29<22:56:59, 12.72s/it]
{'loss': 0.5403, 'learning_rate': 7.387857190027423e-07, 'rewards/chosen': -0.8628204464912415, 'rewards/rejected': -1.206286072731018, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3434655964374542, 'policy_logps/rejected': -516.1563720703125, 'policy_logps/chosen': -516.84228515625, 'referece_logps/rejected': -504.09356689453125, 'referece_logps/chosen': -508.2140808105469, 'logits/rejected': -0.6124414205551147, 'logits/chosen': -0.5433670878410339, 'epoch': 3.58}

 60%|█████▉    | 9609/16104 [44:20:49<26:44:22, 14.82s/it]

 60%|█████▉    | 9610/16104 [44:21:01<24:54:23, 13.81s/it]

 60%|█████▉    | 9611/16104 [44:21:22<29:15:31, 16.22s/it]


 60%|█████▉    | 9613/16104 [44:21:50<27:24:42, 15.20s/it]

 60%|█████▉    | 9614/16104 [44:22:04<26:48:28, 14.87s/it]
{'loss': 0.537, 'learning_rate': 7.376210493580211e-07, 'rewards/chosen': -1.1501704454421997, 'rewards/rejected': -2.070289134979248, 'rewards/accuracies': 0.625, 'rewards/margins': 0.9201186299324036, 'policy_logps/rejected': -483.6888427734375, 'policy_logps/chosen': -336.9621887207031, 'referece_logps/rejected': -462.9859619140625, 'referece_logps/chosen': -325.4604797363281, 'logits/rejected': -0.37516361474990845, 'logits/chosen': -0.18304547667503357, 'epoch': 3.58}


 60%|█████▉    | 9616/16104 [44:22:36<28:35:55, 15.87s/it]
{'loss': 0.5848, 'learning_rate': 7.372329109689377e-07, 'rewards/chosen': -0.8690259456634521, 'rewards/rejected': -1.853904366493225, 'rewards/accuracies': 0.75, 'rewards/margins': 0.984878420829773, 'policy_logps/rejected': -501.6474304199219, 'policy_logps/chosen': -476.65899658203125, 'referece_logps/rejected': -483.1083984375, 'referece_logps/chosen': -467.9687194824219, 'logits/rejected': 0.555987536907196, 'logits/chosen': 0.6679795980453491, 'epoch': 3.58}


 60%|█████▉    | 9618/16104 [44:23:08<28:56:07, 16.06s/it]
{'loss': 0.4932, 'learning_rate': 7.368448150974444e-07, 'rewards/chosen': -0.6625560522079468, 'rewards/rejected': -1.7160028219223022, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0534467697143555, 'policy_logps/rejected': -275.02117919921875, 'policy_logps/chosen': -301.1198425292969, 'referece_logps/rejected': -257.8611755371094, 'referece_logps/chosen': -294.4942626953125, 'logits/rejected': -0.29923927783966064, 'logits/chosen': -0.35245180130004883, 'epoch': 3.58}

 60%|█████▉    | 9619/16104 [44:23:23<28:09:41, 15.63s/it]


 60%|█████▉    | 9621/16104 [44:23:51<26:27:39, 14.69s/it]
{'loss': 0.5575, 'learning_rate': 7.362627511480524e-07, 'rewards/chosen': -0.8779197931289673, 'rewards/rejected': -0.8965745568275452, 'rewards/accuracies': 0.5, 'rewards/margins': 0.01865483820438385, 'policy_logps/rejected': -367.7975158691406, 'policy_logps/chosen': -404.1841125488281, 'referece_logps/rejected': -358.831787109375, 'referece_logps/chosen': -395.4049377441406, 'logits/rejected': 0.12724018096923828, 'logits/chosen': 0.12594202160835266, 'epoch': 3.58}


 60%|█████▉    | 9623/16104 [44:24:22<26:03:24, 14.47s/it]

 60%|█████▉    | 9624/16104 [44:24:32<24:02:17, 13.35s/it]

 60%|█████▉    | 9625/16104 [44:24:52<27:38:12, 15.36s/it]
{'loss': 0.4734, 'learning_rate': 7.354868152798059e-07, 'rewards/chosen': -1.0643699169158936, 'rewards/rejected': -2.0738253593444824, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0094552040100098, 'policy_logps/rejected': -420.6534423828125, 'policy_logps/chosen': -339.52203369140625, 'referece_logps/rejected': -399.9151916503906, 'referece_logps/chosen': -328.8783264160156, 'logits/rejected': 0.01920616626739502, 'logits/chosen': 0.31452029943466187, 'epoch': 3.59}


 60%|█████▉    | 9627/16104 [44:25:30<31:20:07, 17.42s/it]
{'loss': 0.558, 'learning_rate': 7.350989115144781e-07, 'rewards/chosen': -1.2482548952102661, 'rewards/rejected': -1.3548507690429688, 'rewards/accuracies': 0.5, 'rewards/margins': 0.10659588128328323, 'policy_logps/rejected': -305.8589172363281, 'policy_logps/chosen': -396.0158996582031, 'referece_logps/rejected': -292.3104248046875, 'referece_logps/chosen': -383.5332946777344, 'logits/rejected': 0.6572862267494202, 'logits/chosen': 0.7604655027389526, 'epoch': 3.59}


 60%|█████▉    | 9629/16104 [44:26:06<31:46:57, 17.67s/it]

 60%|█████▉    | 9630/16104 [44:26:24<31:58:02, 17.78s/it]
{'loss': 0.5231, 'learning_rate': 7.345171362540107e-07, 'rewards/chosen': -0.7338961362838745, 'rewards/rejected': -1.471031904220581, 'rewards/accuracies': 0.875, 'rewards/margins': 0.7371357083320618, 'policy_logps/rejected': -726.322021484375, 'policy_logps/chosen': -529.8016967773438, 'referece_logps/rejected': -711.6117553710938, 'referece_logps/chosen': -522.4627685546875, 'logits/rejected': -1.1272025108337402, 'logits/chosen': -1.021172285079956, 'epoch': 3.59}

 60%|█████▉    | 9631/16104 [44:26:37<29:34:25, 16.45s/it]


 60%|█████▉    | 9633/16104 [44:27:14<30:53:47, 17.19s/it]

 60%|█████▉    | 9634/16104 [44:27:34<32:09:38, 17.89s/it]
{'loss': 0.4298, 'learning_rate': 7.337415862928982e-07, 'rewards/chosen': -1.1373109817504883, 'rewards/rejected': -1.8381072282791138, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7007962465286255, 'policy_logps/rejected': -184.37518310546875, 'policy_logps/chosen': -202.3576202392578, 'referece_logps/rejected': -165.99412536621094, 'referece_logps/chosen': -190.98451232910156, 'logits/rejected': -1.1904480457305908, 'logits/chosen': -1.217856526374817, 'epoch': 3.59}


 60%|█████▉    | 9636/16104 [44:28:05<29:15:49, 16.29s/it]

 60%|█████▉    | 9637/16104 [44:28:24<31:09:04, 17.34s/it]
{'loss': 0.4794, 'learning_rate': 7.331600368862053e-07, 'rewards/chosen': -0.9055762887001038, 'rewards/rejected': -1.3895574808120728, 'rewards/accuracies': 0.625, 'rewards/margins': 0.4839811325073242, 'policy_logps/rejected': -312.24169921875, 'policy_logps/chosen': -343.1519470214844, 'referece_logps/rejected': -298.34613037109375, 'referece_logps/chosen': -334.0961608886719, 'logits/rejected': -0.6690795421600342, 'logits/chosen': -0.6333419680595398, 'epoch': 3.59}

 60%|█████▉    | 9638/16104 [44:28:41<30:50:17, 17.17s/it]

 60%|█████▉    | 9639/16104 [44:28:56<29:17:47, 16.31s/it]

 60%|█████▉    | 9640/16104 [44:29:15<31:15:12, 17.41s/it]

 60%|█████▉    | 9641/16104 [44:29:29<29:16:22, 16.31s/it]


 60%|█████▉    | 9643/16104 [44:30:08<31:54:43, 17.78s/it]
{'loss': 0.4525, 'learning_rate': 7.319972297266213e-07, 'rewards/chosen': -1.1901495456695557, 'rewards/rejected': -2.7701637744903564, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5800143480300903, 'policy_logps/rejected': -256.1046142578125, 'policy_logps/chosen': -355.94580078125, 'referece_logps/rejected': -228.40296936035156, 'referece_logps/chosen': -344.0443420410156, 'logits/rejected': -0.09341725707054138, 'logits/chosen': -0.09538744390010834, 'epoch': 3.59}


 60%|█████▉    | 9645/16104 [44:30:34<27:46:12, 15.48s/it]
{'loss': 0.5299, 'learning_rate': 7.31609713985999e-07, 'rewards/chosen': -0.7847152352333069, 'rewards/rejected': -1.80624520778656, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0215299129486084, 'policy_logps/rejected': -317.7982482910156, 'policy_logps/chosen': -326.7513427734375, 'referece_logps/rejected': -299.73577880859375, 'referece_logps/chosen': -318.9041748046875, 'logits/rejected': 0.07367250323295593, 'logits/chosen': 0.08428043127059937, 'epoch': 3.59}

 60%|█████▉    | 9646/16104 [44:30:51<28:27:48, 15.87s/it]

 60%|█████▉    | 9647/16104 [44:31:04<26:34:30, 14.82s/it]


 60%|█████▉    | 9649/16104 [44:31:39<28:41:30, 16.00s/it]

 60%|█████▉    | 9650/16104 [44:31:51<26:38:33, 14.86s/it]
{'loss': 0.5124, 'learning_rate': 7.306411147667425e-07, 'rewards/chosen': -0.9617288708686829, 'rewards/rejected': -1.8020987510681152, 'rewards/accuracies': 0.375, 'rewards/margins': 0.8403699398040771, 'policy_logps/rejected': -410.0696105957031, 'policy_logps/chosen': -271.4202880859375, 'referece_logps/rejected': -392.0486145019531, 'referece_logps/chosen': -261.802978515625, 'logits/rejected': -0.08275500684976578, 'logits/chosen': -0.2369590848684311, 'epoch': 3.6}


 60%|█████▉    | 9652/16104 [44:32:24<28:58:15, 16.16s/it]

 60%|█████▉    | 9653/16104 [44:32:39<28:07:53, 15.70s/it]

 60%|█████▉    | 9654/16104 [44:32:59<30:27:00, 17.00s/it]

 60%|█████▉    | 9655/16104 [44:33:18<31:44:39, 17.72s/it]

 60%|█████▉    | 9656/16104 [44:33:39<33:13:55, 18.55s/it]
{'loss': 0.4828, 'learning_rate': 7.294791553593555e-07, 'rewards/chosen': -0.8345358371734619, 'rewards/rejected': -1.904870629310608, 'rewards/accuracies': 0.875, 'rewards/margins': 1.070334792137146, 'policy_logps/rejected': -505.27392578125, 'policy_logps/chosen': -412.6461486816406, 'referece_logps/rejected': -486.2252197265625, 'referece_logps/chosen': -404.30078125, 'logits/rejected': -0.21572156250476837, 'logits/chosen': 0.14204686880111694, 'epoch': 3.6}


 60%|█████▉    | 9658/16104 [44:34:05<28:16:44, 15.79s/it]

 60%|█████▉    | 9659/16104 [44:34:24<30:18:30, 16.93s/it]

 60%|█████▉    | 9660/16104 [44:34:43<31:03:21, 17.35s/it]
{'loss': 0.4639, 'learning_rate': 7.287047345109952e-07, 'rewards/chosen': -1.1640019416809082, 'rewards/rejected': -1.1844693422317505, 'rewards/accuracies': 0.625, 'rewards/margins': 0.020467355847358704, 'policy_logps/rejected': -353.66754150390625, 'policy_logps/chosen': -321.7745361328125, 'referece_logps/rejected': -341.8228454589844, 'referece_logps/chosen': -310.134521484375, 'logits/rejected': -1.1187273263931274, 'logits/chosen': -1.0170583724975586, 'epoch': 3.6}

 60%|█████▉    | 9661/16104 [44:35:04<33:01:44, 18.45s/it]

 60%|█████▉    | 9662/16104 [44:35:23<33:35:46, 18.77s/it]


 60%|██████    | 9664/16104 [44:36:01<33:50:45, 18.92s/it]
{'loss': 0.5133, 'learning_rate': 7.279304892526674e-07, 'rewards/chosen': -0.9241893291473389, 'rewards/rejected': -1.4507638216018677, 'rewards/accuracies': 0.625, 'rewards/margins': 0.5265745520591736, 'policy_logps/rejected': -318.6129150390625, 'policy_logps/chosen': -375.1685485839844, 'referece_logps/rejected': -304.10528564453125, 'referece_logps/chosen': -365.9266662597656, 'logits/rejected': -0.265123188495636, 'logits/chosen': -0.32963114976882935, 'epoch': 3.6}

 60%|██████    | 9665/16104 [44:36:17<32:20:44, 18.08s/it]


 60%|██████    | 9667/16104 [44:36:49<30:57:04, 17.31s/it]
{'loss': 0.5309, 'learning_rate': 7.273499208413361e-07, 'rewards/chosen': -0.8501807451248169, 'rewards/rejected': -1.6555708646774292, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8053902387619019, 'policy_logps/rejected': -264.5129699707031, 'policy_logps/chosen': -328.3360595703125, 'referece_logps/rejected': -247.95726013183594, 'referece_logps/chosen': -319.8342590332031, 'logits/rejected': -0.8592666387557983, 'logits/chosen': -0.7307091355323792, 'epoch': 3.6}


 60%|██████    | 9669/16104 [44:37:20<29:33:11, 16.53s/it]
{'loss': 0.5395, 'learning_rate': 7.269629303666462e-07, 'rewards/chosen': -0.9405012726783752, 'rewards/rejected': -1.8338459730148315, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8933447599411011, 'policy_logps/rejected': -334.70330810546875, 'policy_logps/chosen': -357.0897521972656, 'referece_logps/rejected': -316.3648986816406, 'referece_logps/chosen': -347.68475341796875, 'logits/rejected': -0.18182119727134705, 'logits/chosen': -0.3158095180988312, 'epoch': 3.6}

 60%|██████    | 9670/16104 [44:37:36<29:02:38, 16.25s/it]


 60%|██████    | 9672/16104 [44:38:17<33:08:46, 18.55s/it]
{'loss': 0.5237, 'learning_rate': 7.263825275104514e-07, 'rewards/chosen': -0.7512185573577881, 'rewards/rejected': -1.4797422885894775, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7285236716270447, 'policy_logps/rejected': -444.63140869140625, 'policy_logps/chosen': -324.23077392578125, 'referece_logps/rejected': -429.8339538574219, 'referece_logps/chosen': -316.7185974121094, 'logits/rejected': -0.4639333486557007, 'logits/chosen': -0.31962788105010986, 'epoch': 3.6}

 60%|██████    | 9673/16104 [44:38:38<34:17:24, 19.20s/it]

 60%|██████    | 9674/16104 [44:38:54<32:44:10, 18.33s/it]

 60%|██████    | 9675/16104 [44:39:08<30:07:54, 16.87s/it]

 60%|██████    | 9676/16104 [44:39:30<32:50:01, 18.39s/it]


 60%|██████    | 9678/16104 [44:40:01<30:12:30, 16.92s/it]

 60%|██████    | 9679/16104 [44:40:17<29:17:22, 16.41s/it]

 60%|██████    | 9680/16104 [44:40:35<30:12:03, 16.92s/it]
{'loss': 0.5426, 'learning_rate': 7.24835274140247e-07, 'rewards/chosen': -1.2694251537322998, 'rewards/rejected': -2.338280439376831, 'rewards/accuracies': 0.75, 'rewards/margins': 1.0688555240631104, 'policy_logps/rejected': -413.5591735839844, 'policy_logps/chosen': -274.798583984375, 'referece_logps/rejected': -390.1763610839844, 'referece_logps/chosen': -262.10430908203125, 'logits/rejected': -0.651812732219696, 'logits/chosen': -0.4832763671875, 'epoch': 3.61}

 60%|██████    | 9681/16104 [44:40:52<30:37:51, 17.17s/it]

 60%|██████    | 9682/16104 [44:41:04<27:38:56, 15.50s/it]


 60%|██████    | 9684/16104 [44:41:31<25:54:41, 14.53s/it]
{'loss': 0.6104, 'learning_rate': 7.240619143465037e-07, 'rewards/chosen': -0.9762573838233948, 'rewards/rejected': -1.2751609086990356, 'rewards/accuracies': 0.625, 'rewards/margins': 0.29890352487564087, 'policy_logps/rejected': -381.5298156738281, 'policy_logps/chosen': -363.2796325683594, 'referece_logps/rejected': -368.7781982421875, 'referece_logps/chosen': -353.5170593261719, 'logits/rejected': -0.41529566049575806, 'logits/chosen': -0.40494054555892944, 'epoch': 3.61}


 60%|██████    | 9686/16104 [44:42:05<28:46:39, 16.14s/it]

 60%|██████    | 9687/16104 [44:42:25<30:49:20, 17.29s/it]
{'loss': 0.5885, 'learning_rate': 7.234820116767952e-07, 'rewards/chosen': -0.9018900394439697, 'rewards/rejected': -1.7701029777526855, 'rewards/accuracies': 0.875, 'rewards/margins': 0.868212878704071, 'policy_logps/rejected': -416.0802917480469, 'policy_logps/chosen': -307.8167724609375, 'referece_logps/rejected': -398.3793029785156, 'referece_logps/chosen': -298.7978820800781, 'logits/rejected': -0.6975527405738831, 'logits/chosen': -0.7203038930892944, 'epoch': 3.61}

 60%|██████    | 9688/16104 [44:42:38<28:25:02, 15.94s/it]


 60%|██████    | 9690/16104 [44:43:17<31:46:36, 17.84s/it]
{'loss': 0.6087, 'learning_rate': 7.22902209677899e-07, 'rewards/chosen': -1.1666675806045532, 'rewards/rejected': -1.3553416728973389, 'rewards/accuracies': 0.625, 'rewards/margins': 0.18867415189743042, 'policy_logps/rejected': -488.7974853515625, 'policy_logps/chosen': -542.1740112304688, 'referece_logps/rejected': -475.2440490722656, 'referece_logps/chosen': -530.50732421875, 'logits/rejected': -0.03939612954854965, 'logits/chosen': -0.08027301728725433, 'epoch': 3.61}

 60%|██████    | 9691/16104 [44:43:33<30:19:01, 17.02s/it]


 60%|██████    | 9693/16104 [44:44:01<28:11:21, 15.83s/it]
{'loss': 0.4166, 'learning_rate': 7.223225085609006e-07, 'rewards/chosen': -0.8020495772361755, 'rewards/rejected': -1.663684606552124, 'rewards/accuracies': 0.625, 'rewards/margins': 0.8616350889205933, 'policy_logps/rejected': -475.88616943359375, 'policy_logps/chosen': -596.0219116210938, 'referece_logps/rejected': -459.24932861328125, 'referece_logps/chosen': -588.0013427734375, 'logits/rejected': -0.4729236960411072, 'logits/chosen': -0.48819780349731445, 'epoch': 3.61}


 60%|██████    | 9695/16104 [44:44:36<28:43:21, 16.13s/it]
{'loss': 0.5364, 'learning_rate': 7.219360972992903e-07, 'rewards/chosen': -1.903677225112915, 'rewards/rejected': -2.097038745880127, 'rewards/accuracies': 0.625, 'rewards/margins': 0.19336152076721191, 'policy_logps/rejected': -597.8248291015625, 'policy_logps/chosen': -453.6468200683594, 'referece_logps/rejected': -576.8544311523438, 'referece_logps/chosen': -434.6100769042969, 'logits/rejected': 0.028225792571902275, 'logits/chosen': 0.2226557433605194, 'epoch': 3.61}


 60%|██████    | 9697/16104 [44:45:08<28:27:57, 15.99s/it]

 60%|██████    | 9698/16104 [44:45:28<30:28:23, 17.13s/it]
{'loss': 0.4766, 'learning_rate': 7.213565647877696e-07, 'rewards/chosen': -1.8122425079345703, 'rewards/rejected': -2.123745918273926, 'rewards/accuracies': 0.625, 'rewards/margins': 0.3115035593509674, 'policy_logps/rejected': -399.686767578125, 'policy_logps/chosen': -338.5293273925781, 'referece_logps/rejected': -378.4493103027344, 'referece_logps/chosen': -320.40692138671875, 'logits/rejected': -0.9483211040496826, 'logits/chosen': -0.9121954441070557, 'epoch': 3.61}


 60%|██████    | 9700/16104 [44:46:02<29:45:57, 16.73s/it]

 60%|██████    | 9701/16104 [44:46:22<31:33:18, 17.74s/it]

 60%|██████    | 9702/16104 [44:46:38<30:53:02, 17.37s/it]

 60%|██████    | 9703/16104 [44:46:54<30:09:12, 16.96s/it]
{'loss': 0.4542, 'learning_rate': 7.203909028052211e-07, 'rewards/chosen': -1.4219722747802734, 'rewards/rejected': -2.4303009510040283, 'rewards/accuracies': 0.625, 'rewards/margins': 1.0083285570144653, 'policy_logps/rejected': -270.5400085449219, 'policy_logps/chosen': -352.75433349609375, 'referece_logps/rejected': -246.23699951171875, 'referece_logps/chosen': -338.5346374511719, 'logits/rejected': -0.4998929500579834, 'logits/chosen': -0.6642684936523438, 'epoch': 3.62}

 60%|██████    | 9704/16104 [44:47:07<27:58:47, 15.74s/it]


 60%|██████    | 9706/16104 [44:47:42<29:16:35, 16.47s/it]

 60%|██████    | 9707/16104 [44:48:02<31:03:37, 17.48s/it]

 60%|██████    | 9708/16104 [44:48:14<28:10:27, 15.86s/it]

 60%|██████    | 9709/16104 [44:48:26<26:01:26, 14.65s/it]

 60%|██████    | 9710/16104 [44:48:46<28:45:08, 16.19s/it]
{'loss': 0.4806, 'learning_rate': 7.190394512971632e-07, 'rewards/chosen': -0.8636186718940735, 'rewards/rejected': -1.8520771265029907, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9884583353996277, 'policy_logps/rejected': -538.9876708984375, 'policy_logps/chosen': -420.4345397949219, 'referece_logps/rejected': -520.4668579101562, 'referece_logps/chosen': -411.7983093261719, 'logits/rejected': -0.35811981558799744, 'logits/chosen': -0.24953676760196686, 'epoch': 3.62}

 60%|██████    | 9711/16104 [44:49:05<30:32:56, 17.20s/it]


 60%|██████    | 9713/16104 [44:49:48<34:08:46, 19.23s/it]

 60%|██████    | 9714/16104 [44:50:08<34:30:24, 19.44s/it]
{'loss': 0.5668, 'learning_rate': 7.182674431585702e-07, 'rewards/chosen': -0.8753752112388611, 'rewards/rejected': -1.262811303138733, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3874360918998718, 'policy_logps/rejected': -449.74188232421875, 'policy_logps/chosen': -428.0421142578125, 'referece_logps/rejected': -437.1137390136719, 'referece_logps/chosen': -419.28839111328125, 'logits/rejected': -0.6294801831245422, 'logits/chosen': -0.6803785562515259, 'epoch': 3.62}


 60%|██████    | 9716/16104 [44:50:40<30:50:29, 17.38s/it]
{'loss': 0.5261, 'learning_rate': 7.178815074375539e-07, 'rewards/chosen': -0.8010156750679016, 'rewards/rejected': -1.9567065238952637, 'rewards/accuracies': 0.75, 'rewards/margins': 1.1556909084320068, 'policy_logps/rejected': -322.78369140625, 'policy_logps/chosen': -268.67999267578125, 'referece_logps/rejected': -303.21661376953125, 'referece_logps/chosen': -260.6698303222656, 'logits/rejected': -0.7295371890068054, 'logits/chosen': -0.7181297540664673, 'epoch': 3.62}

 60%|██████    | 9717/16104 [44:50:55<29:44:45, 16.77s/it]

 60%|██████    | 9718/16104 [44:51:09<28:15:36, 15.93s/it]

 60%|██████    | 9719/16104 [44:51:24<27:32:26, 15.53s/it]


 60%|██████    | 9721/16104 [44:52:00<29:36:12, 16.70s/it]
{'loss': 0.4726, 'learning_rate': 7.169168679850344e-07, 'rewards/chosen': -0.7332519888877869, 'rewards/rejected': -2.170595407485962, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4373433589935303, 'policy_logps/rejected': -404.65283203125, 'policy_logps/chosen': -356.1384582519531, 'referece_logps/rejected': -382.9468688964844, 'referece_logps/chosen': -348.8059387207031, 'logits/rejected': -0.7144920229911804, 'logits/chosen': -0.7181917428970337, 'epoch': 3.62}

 60%|██████    | 9722/16104 [44:52:13<27:38:53, 15.60s/it]


 60%|██████    | 9724/16104 [44:52:47<28:35:24, 16.13s/it]
{'loss': 0.5779, 'learning_rate': 7.163382216657033e-07, 'rewards/chosen': -1.0201740264892578, 'rewards/rejected': -2.1304070949554443, 'rewards/accuracies': 0.875, 'rewards/margins': 1.110232949256897, 'policy_logps/rejected': -522.8818359375, 'policy_logps/chosen': -580.8837280273438, 'referece_logps/rejected': -501.5777282714844, 'referece_logps/chosen': -570.6820068359375, 'logits/rejected': 0.1495848298072815, 'logits/chosen': 0.06658491492271423, 'epoch': 3.62}


 60%|██████    | 9726/16104 [44:53:18<28:32:45, 16.11s/it]

 60%|██████    | 9727/16104 [44:53:38<30:35:43, 17.27s/it]
{'loss': 0.5043, 'learning_rate': 7.157596786179958e-07, 'rewards/chosen': -0.9297506809234619, 'rewards/rejected': -1.919857144355774, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9901063442230225, 'policy_logps/rejected': -452.1085205078125, 'policy_logps/chosen': -472.8392639160156, 'referece_logps/rejected': -432.909912109375, 'referece_logps/chosen': -463.5417175292969, 'logits/rejected': -0.1577734798192978, 'logits/chosen': -0.27586519718170166, 'epoch': 3.62}

 60%|██████    | 9728/16104 [44:53:51<28:09:05, 15.89s/it]

 60%|██████    | 9729/16104 [44:54:09<29:16:51, 16.54s/it]

 60%|██████    | 9730/16104 [44:54:25<29:09:25, 16.47s/it]

 60%|██████    | 9731/16104 [44:54:42<29:08:52, 16.47s/it]

 60%|██████    | 9732/16104 [44:54:59<29:38:08, 16.74s/it]

 60%|██████    | 9733/16104 [44:55:17<30:22:25, 17.16s/it]


 60%|██████    | 9735/16104 [44:55:50<29:52:32, 16.89s/it]

 60%|██████    | 9736/16104 [44:56:03<27:30:24, 15.55s/it]
{'loss': 0.5004, 'learning_rate': 7.140246712107034e-07, 'rewards/chosen': -0.909702479839325, 'rewards/rejected': -1.8294005393981934, 'rewards/accuracies': 0.5, 'rewards/margins': 0.919698178768158, 'policy_logps/rejected': -448.8290100097656, 'policy_logps/chosen': -534.0353393554688, 'referece_logps/rejected': -430.5350341796875, 'referece_logps/chosen': -524.9382934570312, 'logits/rejected': -0.5788028836250305, 'logits/chosen': -0.5882675051689148, 'epoch': 3.63}


 60%|██████    | 9738/16104 [44:56:24<23:07:34, 13.08s/it]
{'loss': 0.5746, 'learning_rate': 7.136392410592897e-07, 'rewards/chosen': -1.055986762046814, 'rewards/rejected': -1.4043824672698975, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3483957350254059, 'policy_logps/rejected': -426.7384033203125, 'policy_logps/chosen': -454.1944580078125, 'referece_logps/rejected': -412.694580078125, 'referece_logps/chosen': -443.63458251953125, 'logits/rejected': -0.8375186920166016, 'logits/chosen': -0.8137475252151489, 'epoch': 3.63}

 60%|██████    | 9739/16104 [44:56:35<22:01:16, 12.46s/it]

 60%|██████    | 9740/16104 [44:56:46<21:05:39, 11.93s/it]


 60%|██████    | 9742/16104 [44:57:19<25:53:09, 14.65s/it]

 61%|██████    | 9743/16104 [44:57:37<27:39:45, 15.66s/it]
{'loss': 0.5008, 'learning_rate': 7.126758685337245e-07, 'rewards/chosen': -0.6585136651992798, 'rewards/rejected': -1.0513725280761719, 'rewards/accuracies': 0.5, 'rewards/margins': 0.3928588330745697, 'policy_logps/rejected': -400.96478271484375, 'policy_logps/chosen': -460.270263671875, 'referece_logps/rejected': -390.4510498046875, 'referece_logps/chosen': -453.68511962890625, 'logits/rejected': -0.5123520493507385, 'logits/chosen': -0.4839608669281006, 'epoch': 3.63}

 61%|██████    | 9744/16104 [44:57:50<26:25:07, 14.95s/it]


 61%|██████    | 9746/16104 [44:58:26<29:06:28, 16.48s/it]

 61%|██████    | 9747/16104 [44:58:39<26:51:54, 15.21s/it]
{'loss': 0.5743, 'learning_rate': 7.119053796764301e-07, 'rewards/chosen': -1.3725069761276245, 'rewards/rejected': -2.1556849479675293, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7831780910491943, 'policy_logps/rejected': -299.78955078125, 'policy_logps/chosen': -295.7550048828125, 'referece_logps/rejected': -278.23272705078125, 'referece_logps/chosen': -282.02996826171875, 'logits/rejected': -0.5346707701683044, 'logits/chosen': -0.3837791681289673, 'epoch': 3.63}

 61%|██████    | 9748/16104 [44:58:56<27:47:52, 15.74s/it]

 61%|██████    | 9749/16104 [44:59:12<27:55:03, 15.81s/it]

 61%|██████    | 9750/16104 [44:59:24<25:48:09, 14.62s/it]


 61%|██████    | 9752/16104 [44:59:49<24:07:55, 13.68s/it]

 61%|██████    | 9753/16104 [45:00:08<27:17:40, 15.47s/it]

 61%|██████    | 9754/16104 [45:00:23<26:41:16, 15.13s/it]
{'loss': 0.4078, 'learning_rate': 7.105574731528105e-07, 'rewards/chosen': -1.1564669609069824, 'rewards/rejected': -2.3021080493927, 'rewards/accuracies': 0.625, 'rewards/margins': 1.1456410884857178, 'policy_logps/rejected': -391.95928955078125, 'policy_logps/chosen': -534.7103271484375, 'referece_logps/rejected': -368.93817138671875, 'referece_logps/chosen': -523.1456909179688, 'logits/rejected': -0.3950936496257782, 'logits/chosen': -0.6042143106460571, 'epoch': 3.63}

 61%|██████    | 9755/16104 [45:00:42<28:41:53, 16.27s/it]


 61%|██████    | 9757/16104 [45:01:18<30:15:28, 17.16s/it]

 61%|██████    | 9758/16104 [45:01:39<31:55:40, 18.11s/it]

 61%|██████    | 9759/16104 [45:01:57<31:55:04, 18.11s/it]

 61%|██████    | 9760/16104 [45:02:11<29:55:15, 16.98s/it]

 61%|██████    | 9761/16104 [45:02:27<29:16:00, 16.61s/it]
{'loss': 0.5438, 'learning_rate': 7.092101403439669e-07, 'rewards/chosen': -1.683443307876587, 'rewards/rejected': -2.4763638973236084, 'rewards/accuracies': 0.375, 'rewards/margins': 0.7929206490516663, 'policy_logps/rejected': -404.1196594238281, 'policy_logps/chosen': -306.0436096191406, 'referece_logps/rejected': -379.35601806640625, 'referece_logps/chosen': -289.2091979980469, 'logits/rejected': -0.7422158122062683, 'logits/chosen': -0.735409140586853, 'epoch': 3.64}

 61%|██████    | 9762/16104 [45:02:38<26:28:02, 15.02s/it]

 61%|██████    | 9763/16104 [45:03:00<29:48:07, 16.92s/it]


 61%|██████    | 9765/16104 [45:03:29<27:52:20, 15.83s/it]
{'loss': 0.522, 'learning_rate': 7.084404944957962e-07, 'rewards/chosen': -0.40017247200012207, 'rewards/rejected': -0.8894519805908203, 'rewards/accuracies': 0.625, 'rewards/margins': 0.489279568195343, 'policy_logps/rejected': -591.2122802734375, 'policy_logps/chosen': -577.3399658203125, 'referece_logps/rejected': -582.3177490234375, 'referece_logps/chosen': -573.3382568359375, 'logits/rejected': 0.1820695847272873, 'logits/chosen': 0.08862947672605515, 'epoch': 3.64}

 61%|██████    | 9766/16104 [45:03:42<26:06:40, 14.83s/it]

 61%|██████    | 9767/16104 [45:04:00<27:58:42, 15.89s/it]


 61%|██████    | 9769/16104 [45:04:39<31:17:54, 17.79s/it]
{'loss': 0.6105, 'learning_rate': 7.076710373532523e-07, 'rewards/chosen': -0.8654431700706482, 'rewards/rejected': -1.590248465538025, 'rewards/accuracies': 0.75, 'rewards/margins': 0.7248051762580872, 'policy_logps/rejected': -314.35882568359375, 'policy_logps/chosen': -373.30108642578125, 'referece_logps/rejected': -298.4563293457031, 'referece_logps/chosen': -364.6466369628906, 'logits/rejected': 0.11919514834880829, 'logits/chosen': 0.13139307498931885, 'epoch': 3.64}

 61%|██████    | 9770/16104 [45:04:54<29:49:18, 16.95s/it]

 61%|██████    | 9771/16104 [45:05:14<31:18:07, 17.79s/it]

 61%|██████    | 9772/16104 [45:05:30<30:28:35, 17.33s/it]


 61%|██████    | 9774/16104 [45:05:53<24:59:31, 14.21s/it]
{'loss': 0.5082, 'learning_rate': 7.06709482051043e-07, 'rewards/chosen': -0.9483196139335632, 'rewards/rejected': -1.586604118347168, 'rewards/accuracies': 0.875, 'rewards/margins': 0.6382845640182495, 'policy_logps/rejected': -391.68475341796875, 'policy_logps/chosen': -356.2287292480469, 'referece_logps/rejected': -375.81878662109375, 'referece_logps/chosen': -346.7455139160156, 'logits/rejected': -0.8404381275177002, 'logits/chosen': -0.8282584547996521, 'epoch': 3.64}

 61%|██████    | 9775/16104 [45:06:12<27:30:33, 15.65s/it]

 61%|██████    | 9776/16104 [45:06:32<29:53:44, 17.01s/it]


 61%|██████    | 9778/16104 [45:07:07<30:38:53, 17.44s/it]

 61%|██████    | 9779/16104 [45:07:27<31:43:31, 18.06s/it]

 61%|██████    | 9780/16104 [45:07:45<31:43:09, 18.06s/it]
{'loss': 0.496, 'learning_rate': 7.055560072900306e-07, 'rewards/chosen': -1.080576777458191, 'rewards/rejected': -2.079043388366699, 'rewards/accuracies': 0.75, 'rewards/margins': 0.9984667301177979, 'policy_logps/rejected': -542.5017700195312, 'policy_logps/chosen': -444.7320861816406, 'referece_logps/rejected': -521.7113647460938, 'referece_logps/chosen': -433.9263000488281, 'logits/rejected': -0.974435031414032, 'logits/chosen': -0.9368535280227661, 'epoch': 3.64}


 61%|██████    | 9782/16104 [45:08:13<27:38:07, 15.74s/it]

 61%|██████    | 9783/16104 [45:08:33<29:55:57, 17.05s/it]
{'loss': 0.5222, 'learning_rate': 7.049794306001411e-07, 'rewards/chosen': -0.8042194843292236, 'rewards/rejected': -1.6733211278915405, 'rewards/accuracies': 0.75, 'rewards/margins': 0.8691015839576721, 'policy_logps/rejected': -311.7936706542969, 'policy_logps/chosen': -344.5835876464844, 'referece_logps/rejected': -295.0604553222656, 'referece_logps/chosen': -336.5413818359375, 'logits/rejected': -0.6178562641143799, 'logits/chosen': -0.6327588558197021, 'epoch': 3.64}


 61%|██████    | 9785/16104 [45:09:12<31:31:03, 17.96s/it]
{'loss': 0.4822, 'learning_rate': 7.045951057978e-07, 'rewards/chosen': -1.1987007856369019, 'rewards/rejected': -1.8574934005737305, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6587924361228943, 'policy_logps/rejected': -366.0537414550781, 'policy_logps/chosen': -425.2437744140625, 'referece_logps/rejected': -347.4787902832031, 'referece_logps/chosen': -413.2567138671875, 'logits/rejected': 0.42548221349716187, 'logits/chosen': 0.4290239214897156, 'epoch': 3.65}

 61%|██████    | 9786/16104 [45:09:25<28:58:25, 16.51s/it]

 61%|██████    | 9787/16104 [45:09:46<31:25:00, 17.90s/it]

 61%|██████    | 9788/16104 [45:10:02<30:21:54, 17.31s/it]

 61%|██████    | 9789/16104 [45:10:14<27:44:02, 15.81s/it]


 61%|██████    | 9791/16104 [45:10:41<25:39:58, 14.64s/it]
{'loss': 0.4817, 'learning_rate': 7.034424184312033e-07, 'rewards/chosen': -0.9896517395973206, 'rewards/rejected': -1.9708478450775146, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9811961650848389, 'policy_logps/rejected': -501.2855224609375, 'policy_logps/chosen': -438.603759765625, 'referece_logps/rejected': -481.57708740234375, 'referece_logps/chosen': -428.707275390625, 'logits/rejected': -0.7742343544960022, 'logits/chosen': -0.8496845960617065, 'epoch': 3.65}


 61%|██████    | 9793/16104 [45:11:15<28:16:22, 16.13s/it]
{'loss': 0.4556, 'learning_rate': 7.030582851963835e-07, 'rewards/chosen': -0.9248802661895752, 'rewards/rejected': -1.5669596195220947, 'rewards/accuracies': 0.75, 'rewards/margins': 0.6420794129371643, 'policy_logps/rejected': -235.93841552734375, 'policy_logps/chosen': -262.10369873046875, 'referece_logps/rejected': -220.26882934570312, 'referece_logps/chosen': -252.85491943359375, 'logits/rejected': 0.06327107548713684, 'logits/chosen': 0.0007295990362763405, 'epoch': 3.65}

 61%|██████    | 9794/16104 [45:11:29<26:53:27, 15.34s/it]

 61%|██████    | 9795/16104 [45:11:45<27:11:38, 15.52s/it]


 61%|██████    | 9797/16104 [45:12:24<30:50:35, 17.61s/it]
{'loss': 0.5192, 'learning_rate': 7.022901629307572e-07, 'rewards/chosen': -0.9957185983657837, 'rewards/rejected': -2.0159687995910645, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0202502012252808, 'policy_logps/rejected': -361.976806640625, 'policy_logps/chosen': -501.35650634765625, 'referece_logps/rejected': -341.817138671875, 'referece_logps/chosen': -491.3993225097656, 'logits/rejected': -0.07078126817941666, 'logits/chosen': -0.08342544734477997, 'epoch': 3.65}

 61%|██████    | 9798/16104 [45:12:39<29:52:28, 17.05s/it]

 61%|██████    | 9799/16104 [45:12:58<30:53:42, 17.64s/it]

 61%|██████    | 9800/16104 [45:13:11<28:27:56, 16.26s/it]

 61%|██████    | 9801/16104 [45:13:27<28:12:06, 16.11s/it]

 61%|██████    | 9802/16104 [45:13:41<26:48:52, 15.32s/it]

 61%|██████    | 9803/16104 [45:13:55<26:12:14, 14.97s/it]

 61%|██████    | 9804/16104 [45:14:07<24:28:34, 13.99s/it]

 61%|██████    | 9805/16104 [45:14:21<24:39:45, 14.10s/it]

 61%|██████    | 9806/16104 [45:14:39<26:53:30, 15.37s/it]

 61%|██████    | 9807/16104 [45:14:51<24:53:38, 14.23s/it]

 61%|██████    | 9808/16104 [45:15:09<27:11:04, 15.54s/it]

 61%|██████    | 9809/16104 [45:15:23<26:11:31, 14.98s/it]

 61%|██████    | 9810/16104 [45:15:43<28:35:57, 16.36s/it]

 61%|██████    | 9811/16104 [45:15:59<28:45:04, 16.45s/it]

 61%|██████    | 9812/16104 [45:16:16<28:41:34, 16.42s/it]

 61%|██████    | 9813/16104 [45:16:35<30:01:28, 17.18s/it]

 61%|██████    | 9814/16104 [45:16:49<28:27:11, 16.28s/it]

 61%|██████    | 9815/16104 [45:17:06<28:39:45, 16.41s/it]

 61%|██████    | 9816/16104 [45:17:28<31:43:05, 18.16s/it]

 61%|██████    | 9817/16104 [45:17:41<29:15:50, 16.76s/it]

 61%|██████    | 9818/16104 [45:17:56<28:09:22, 16.13s/it]

 61%|██████    | 9819/16104 [45:18:15<29:54:29, 17.13s/it]

 61%|██████    | 9820/16104 [45:18:28<27:47:16, 15.92s/it]

 61%|██████    | 9821/16104 [45:18:43<27:13:57, 15.60s/it]

 61%|██████    | 9822/16104 [45:19:01<28:10:35, 16.15s/it]

 61%|██████    | 9823/16104 [45:19:22<31:00:13, 17.77s/it]

 61%|██████    | 9824/16104 [45:19:40<30:54:22, 17.72s/it]

 61%|██████    | 9825/16104 [45:19:59<31:26:15, 18.02s/it]

 61%|██████    | 9826/16104 [45:20:19<32:31:37, 18.65s/it]

 61%|██████    | 9827/16104 [45:20:38<32:58:55, 18.92s/it]

 61%|██████    | 9828/16104 [45:21:00<34:40:53, 19.89s/it]

 61%|██████    | 9829/16104 [45:21:23<36:04:12, 20.69s/it]

 61%|██████    | 9830/16104 [45:21:44<36:02:13, 20.68s/it]

 61%|██████    | 9831/16104 [45:21:56<31:32:09, 18.10s/it]

 61%|██████    | 9832/16104 [45:22:11<29:59:01, 17.21s/it]

 61%|██████    | 9833/16104 [45:22:26<28:59:15, 16.64s/it]

 61%|██████    | 9834/16104 [45:22:44<29:46:33, 17.10s/it]

 61%|██████    | 9835/16104 [45:23:02<29:57:01, 17.20s/it]

 61%|██████    | 9836/16104 [45:23:21<31:12:50, 17.93s/it]

 61%|██████    | 9837/16104 [45:23:41<32:07:43, 18.46s/it]

 61%|██████    | 9838/16104 [45:24:02<33:19:27, 19.15s/it]

 61%|██████    | 9839/16104 [45:24:17<31:08:17, 17.89s/it]

 61%|██████    | 9840/16104 [45:24:37<32:07:24, 18.46s/it]

 61%|██████    | 9841/16104 [45:24:50<29:27:18, 16.93s/it]

 61%|██████    | 9842/16104 [45:25:06<29:05:57, 16.73s/it]

 61%|██████    | 9843/16104 [45:25:28<31:40:46, 18.22s/it]

 61%|██████    | 9844/16104 [45:25:45<30:54:07, 17.77s/it]

 61%|██████    | 9845/16104 [45:26:00<29:34:59, 17.02s/it]

 61%|██████    | 9846/16104 [45:26:13<27:20:22, 15.73s/it]

 61%|██████    | 9847/16104 [45:26:36<31:14:57, 17.98s/it]

 61%|██████    | 9848/16104 [45:26:56<32:25:20, 18.66s/it]

 61%|██████    | 9849/16104 [45:27:08<28:46:09, 16.56s/it]


 61%|██████    | 9851/16104 [45:27:35<26:03:13, 15.00s/it]

 61%|██████    | 9852/16104 [45:27:56<29:19:49, 16.89s/it]
{'loss': 0.5705, 'learning_rate': 6.917482354205569e-07, 'rewards/chosen': -0.7615751028060913, 'rewards/rejected': -2.177407741546631, 'rewards/accuracies': 0.75, 'rewards/margins': 1.4158326387405396, 'policy_logps/rejected': -383.0039367675781, 'policy_logps/chosen': -507.92950439453125, 'referece_logps/rejected': -361.2298583984375, 'referece_logps/chosen': -500.313720703125, 'logits/rejected': -1.0575817823410034, 'logits/chosen': -1.134985089302063, 'epoch': 3.67}


 61%|██████    | 9854/16104 [45:28:29<28:59:37, 16.70s/it]

 61%|██████    | 9855/16104 [45:28:42<26:50:43, 15.47s/it]

 61%|██████    | 9856/16104 [45:28:53<24:39:51, 14.21s/it]

 61%|██████    | 9857/16104 [45:29:10<25:52:54, 14.92s/it]

 61%|██████    | 9858/16104 [45:29:29<28:28:28, 16.41s/it]

 61%|██████    | 9859/16104 [45:29:46<28:45:08, 16.57s/it]

 61%|██████    | 9860/16104 [45:30:06<30:30:25, 17.59s/it]

 61%|██████    | 9861/16104 [45:30:17<26:54:25, 15.52s/it]
{'loss': 0.5233, 'learning_rate': 6.900267496951857e-07, 'rewards/chosen': -0.8977376818656921, 'rewards/rejected': -0.9141138792037964, 'rewards/accuracies': 0.5, 'rewards/margins': 0.016376197338104248, 'policy_logps/rejected': -367.8561096191406, 'policy_logps/chosen': -435.2274169921875, 'referece_logps/rejected': -358.7149658203125, 'referece_logps/chosen': -426.25, 'logits/rejected': -0.5739606022834778, 'logits/chosen': -0.6618527173995972, 'epoch': 3.67}


 61%|██████    | 9863/16104 [45:30:50<27:05:36, 15.63s/it]

 61%|██████▏   | 9864/16104 [45:31:06<27:31:01, 15.88s/it]

 61%|██████▏   | 9865/16104 [45:31:21<26:44:22, 15.43s/it]

 61%|██████▏   | 9866/16104 [45:31:36<26:51:56, 15.50s/it]

 61%|██████▏   | 9867/16104 [45:31:56<28:55:37, 16.70s/it]

 61%|██████▏   | 9868/16104 [45:32:15<30:31:07, 17.62s/it]

 61%|██████▏   | 9869/16104 [45:32:26<26:55:44, 15.55s/it]

 61%|██████▏   | 9870/16104 [45:32:47<29:50:08, 17.23s/it]

 61%|██████▏   | 9871/16104 [45:33:11<33:01:41, 19.08s/it]

 61%|██████▏   | 9872/16104 [45:33:23<29:15:19, 16.90s/it]

 61%|██████▏   | 9873/16104 [45:33:33<26:00:00, 15.02s/it]

 61%|██████▏   | 9874/16104 [45:33:44<23:47:22, 13.75s/it]

 61%|██████▏   | 9875/16104 [45:34:02<26:06:37, 15.09s/it]

 61%|██████▏   | 9876/16104 [45:34:19<26:45:55, 15.47s/it]
{'loss': 0.468, 'learning_rate': 6.871598666177396e-07, 'rewards/chosen': -0.9244030714035034, 'rewards/rejected': -1.9085361957550049, 'rewards/accuracies': 0.875, 'rewards/margins': 0.9841331243515015, 'policy_logps/rejected': -348.2935791015625, 'policy_logps/chosen': -564.8510131835938, 'referece_logps/rejected': -329.20819091796875, 'referece_logps/chosen': -555.6069946289062, 'logits/rejected': -0.6672742366790771, 'logits/chosen': -0.7438504099845886, 'epoch': 3.68}


 61%|██████▏   | 9878/16104 [45:34:53<28:15:29, 16.34s/it]

 61%|██████▏   | 9879/16104 [45:35:05<25:46:47, 14.91s/it]
{'loss': 0.5565, 'learning_rate': 6.865868308508846e-07, 'rewards/chosen': -0.774580717086792, 'rewards/rejected': -1.445096731185913, 'rewards/accuracies': 1.0, 'rewards/margins': 0.6705160737037659, 'policy_logps/rejected': -275.4267272949219, 'policy_logps/chosen': -529.6307373046875, 'referece_logps/rejected': -260.97576904296875, 'referece_logps/chosen': -521.8848876953125, 'logits/rejected': -1.1706606149673462, 'logits/chosen': -1.2305164337158203, 'epoch': 3.68}


 61%|██████▏   | 9881/16104 [45:35:37<25:56:43, 15.01s/it]

 61%|██████▏   | 9882/16104 [45:35:52<26:02:56, 15.07s/it]
{'loss': 0.5521, 'learning_rate': 6.86013909187124e-07, 'rewards/chosen': -1.121827483177185, 'rewards/rejected': -2.148005962371826, 'rewards/accuracies': 0.875, 'rewards/margins': 1.0261785984039307, 'policy_logps/rejected': -381.5594787597656, 'policy_logps/chosen': -609.8417358398438, 'referece_logps/rejected': -360.0794372558594, 'referece_logps/chosen': -598.62353515625, 'logits/rejected': -0.6107208132743835, 'logits/chosen': -0.9071781039237976, 'epoch': 3.68}