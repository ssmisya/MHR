{"train/loss": 0.6942, "train/learning_rate": 2.112676056338028e-07, "train/rewards/chosen": -0.008411789312958717, "train/rewards/rejected": -0.0016197203658521175, "train/rewards/accuracies": 0.25, "train/rewards/margins": -0.006792068015784025, "train/policy_logps/rejected": -455.51202392578125, "train/policy_logps/chosen": -415.0643615722656, "train/referece_logps/rejected": -455.4958190917969, "train/referece_logps/chosen": -414.980224609375, "train/logits/rejected": -1.1995112895965576, "train/logits/chosen": -0.9175807237625122, "train/epoch": 0.01, "train/global_step": 15, "_timestamp": 1711695431.2257144, "_runtime": 169.26451539993286, "_step": 14}