{"train/loss": 0.6966, "train/learning_rate": 4.415584415584415e-07, "train/rewards/chosen": -0.004519081674516201, "train/rewards/rejected": -0.014672551304101944, "train/rewards/accuracies": 0.5625, "train/rewards/margins": 0.010153471492230892, "train/policy_logps/rejected": -270.9929504394531, "train/policy_logps/chosen": -395.3888244628906, "train/referece_logps/rejected": -270.8462219238281, "train/referece_logps/chosen": -395.3436584472656, "train/logits/rejected": -0.9729745388031006, "train/logits/chosen": -0.662940263748169, "train/epoch": 0.02, "train/global_step": 34, "_timestamp": 1709996121.9604921, "_runtime": 732.2277121543884, "_step": 33}