{"train/loss": 0.4389, "train/learning_rate": 5.345275018298063e-07, "train/rewards/chosen": -0.4140743315219879, "train/rewards/rejected": -2.024362325668335, "train/rewards/accuracies": 1.0, "train/rewards/margins": 1.6102880239486694, "train/policy_logps/rejected": -293.4889221191406, "train/policy_logps/chosen": -373.801025390625, "train/referece_logps/rejected": -273.24530029296875, "train/referece_logps/chosen": -369.6602783203125, "train/logits/rejected": -1.0560638904571533, "train/logits/chosen": -0.8557060360908508, "train/epoch": 1.99, "train/global_step": 3130, "_timestamp": 1711730291.4421709, "_runtime": 33700.634567976, "_step": 3129}