{"train/loss": 0.4458, "train/learning_rate": 5.638987228648237e-07, "train/rewards/chosen": -0.242146298289299, "train/rewards/rejected": -1.1561301946640015, "train/rewards/accuracies": 0.75, "train/rewards/margins": 0.9139840006828308, "train/policy_logps/rejected": -285.8193054199219, "train/policy_logps/chosen": -315.9797058105469, "train/referece_logps/rejected": -274.25799560546875, "train/referece_logps/chosen": -313.5582275390625, "train/logits/rejected": -0.16687512397766113, "train/logits/chosen": -0.25775590538978577, "train/epoch": 1.96, "train/global_step": 3135, "_timestamp": 1711730284.0428932, "_runtime": 33705.50903606415, "_step": 3134}