{"train/loss": 0.2451, "train/learning_rate": 6.868552896356117e-07, "train/rewards/chosen": -1.0502331256866455, "train/rewards/rejected": -4.7038445472717285, "train/rewards/accuracies": 1.0, "train/rewards/margins": 3.653611660003662, "train/policy_logps/rejected": -257.41461181640625, "train/policy_logps/chosen": -268.2171325683594, "train/referece_logps/rejected": -210.3761444091797, "train/referece_logps/chosen": -257.71478271484375, "train/logits/rejected": -0.17141443490982056, "train/logits/chosen": -0.23138011991977692, "train/epoch": 1.84, "train/global_step": 1647, "_timestamp": 1711730279.2984612, "_runtime": 32770.23217129707, "_step": 1646}