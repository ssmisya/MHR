{"train/loss": 0.4515, "train/learning_rate": 6.936621816789104e-07, "train/rewards/chosen": -1.4349024295806885, "train/rewards/rejected": -2.2584633827209473, "train/rewards/accuracies": 0.75, "train/rewards/margins": 0.8235608339309692, "train/policy_logps/rejected": -417.7596435546875, "train/policy_logps/chosen": -392.91961669921875, "train/referece_logps/rejected": -395.1750183105469, "train/referece_logps/chosen": -378.57061767578125, "train/logits/rejected": 0.2197943776845932, "train/logits/chosen": 0.13861066102981567, "train/epoch": 3.67, "train/global_step": 9842, "_timestamp": 1712466025.8122163, "_runtime": 164147.94598436356, "_step": 9841}