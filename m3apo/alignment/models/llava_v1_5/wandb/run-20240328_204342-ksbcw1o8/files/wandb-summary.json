{"train/loss": 0.4056, "train/learning_rate": 1.99859138873288e-06, "train/rewards/chosen": -0.8116356134414673, "train/rewards/rejected": -1.6501702070236206, "train/rewards/accuracies": 0.75, "train/rewards/margins": 0.8385343551635742, "train/policy_logps/rejected": -392.06396484375, "train/policy_logps/chosen": -398.12567138671875, "train/referece_logps/rejected": -375.5622253417969, "train/referece_logps/chosen": -390.00933837890625, "train/logits/rejected": -0.4051409959793091, "train/logits/chosen": -0.4930281937122345, "train/epoch": 0.14, "train/global_step": 250, "_timestamp": 1711634460.8105264, "_runtime": 4637.876497268677, "_step": 249}