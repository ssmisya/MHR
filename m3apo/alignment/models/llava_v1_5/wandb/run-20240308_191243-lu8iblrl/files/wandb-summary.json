{"train/loss": 0.6985, "train/learning_rate": 1.99970388732558e-06, "train/rewards/chosen": -0.026617148891091347, "train/rewards/rejected": 0.0075639719143509865, "train/rewards/accuracies": 0.375, "train/rewards/margins": -0.03418111801147461, "train/policy_logps/rejected": -392.19683837890625, "train/policy_logps/chosen": -434.48089599609375, "train/referece_logps/rejected": -392.2724914550781, "train/referece_logps/chosen": -434.2146911621094, "train/logits/rejected": -0.626926839351654, "train/logits/chosen": -0.7491762638092041, "train/epoch": 0.11, "train/global_step": 55, "_timestamp": 1709897522.795788, "_runtime": 1159.0308859348297, "_step": 54}