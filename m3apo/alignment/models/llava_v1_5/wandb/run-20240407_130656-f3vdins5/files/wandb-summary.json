{"train/loss": 0.5988, "train/learning_rate": 1.3528538960892405e-06, "train/rewards/chosen": -0.7557266354560852, "train/rewards/rejected": -1.4000414609909058, "train/rewards/accuracies": 0.75, "train/rewards/margins": 0.6443147659301758, "train/policy_logps/rejected": -389.86614990234375, "train/policy_logps/chosen": -539.0501098632812, "train/referece_logps/rejected": -375.86572265625, "train/referece_logps/chosen": -531.4927978515625, "train/logits/rejected": 0.8352009654045105, "train/logits/chosen": 0.8747418522834778, "train/epoch": 2.42, "train/global_step": 6501, "_timestamp": 1712575516.177412, "_runtime": 109099.22845506668, "_step": 6500}