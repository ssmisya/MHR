phoenix-srun: job 2579919 queued and waiting for resources
phoenix-srun: job 2579919 has been allocated resources
phoenix-srun: Job 2579919 scheduled successfully!
Current QUOTA_TYPE is [reserved], which means the job has occupied quota in RESERVED_TOTAL under your partition.
Current PHX_PRIORITY is normal

[2024-03-07 22:10:11,805] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:23<00:23, 23.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 15.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 16.47s/it]
Some weights of the model checkpoint at /mnt/petrelfs/songmingyang/songmingyang/model/mm/ckpts/sft_palo/checkpoint-1000 were not used when initializing LlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.class_embedding', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.pre_layrnorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight']
- This IS expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
  0%|          | 0/1735 [00:00<?, ?it/s]  0%|          | 1/1735 [00:26<12:39:33, 26.28s/it]  0%|          | 2/1735 [00:45<10:40:04, 22.16s/it]  0%|          | 3/1735 [01:10<11:12:49, 23.31s/it]  0%|          | 4/1735 [01:33<11:07:33, 23.14s/it]  0%|          | 5/1735 [01:50<10:04:46, 20.97s/it]  0%|          | 6/1735 [02:15<10:46:33, 22.44s/it]  0%|          | 7/1735 [02:33<9:59:51, 20.83s/it]   0%|          | 8/1735 [02:48<9:07:58, 19.04s/it]  1%|          | 9/1735 [03:02<8:28:11, 17.67s/it]  1%|          | 10/1735 [03:22<8:42:12, 18.16s/it]  1%|          | 11/1735 [03:41<8:51:54, 18.51s/it]  1%|          | 12/1735 [03:59<8:43:32, 18.23s/it]  1%|          | 13/1735 [04:24<9:47:55, 20.49s/it]  1%|          | 14/1735 [04:37<8:39:06, 18.10s/it]  1%|          | 15/1735 [04:54<8:28:52, 17.75s/it]  1%|          | 16/1735 [05:08<8:00:28, 16.77s/it]  1%|          | 17/1735 [05:31<8:49:53, 18.51s/it]  1%|          | 18/1735 [05:47<8:25:39, 17.67s/it]  1%|          | 19/1735 [06:06<8:44:43, 18.35s/it]  1%|          | 20/1735 [06:23<8:25:11, 17.67s/it]  1%|          | 21/1735 [06:36<7:49:58, 16.45s/it]  1%|▏         | 22/1735 [06:54<8:02:03, 16.88s/it]  1%|▏         | 23/1735 [07:20<9:15:29, 19.47s/it]  1%|▏         | 24/1735 [07:43<9:47:29, 20.60s/it]  1%|▏         | 25/1735 [08:03<9:44:21, 20.50s/it]  1%|▏         | 26/1735 [08:20<9:11:30, 19.36s/it]  2%|▏         | 27/1735 [08:37<8:53:10, 18.73s/it]  2%|▏         | 28/1735 [08:55<8:49:03, 18.60s/it]  2%|▏         | 29/1735 [09:11<8:20:17, 17.60s/it]  2%|▏         | 30/1735 [09:31<8:42:46, 18.40s/it]  2%|▏         | 31/1735 [09:59<10:09:54, 21.48s/it]  2%|▏         | 32/1735 [10:20<9:57:52, 21.06s/it]   2%|▏         | 33/1735 [10:48<10:59:31, 23.25s/it]  2%|▏         | 34/1735 [11:05<10:05:43, 21.37s/it]  2%|▏         | 35/1735 [11:20<9:12:04, 19.49s/it]   2%|▏         | 36/1735 [11:41<9:27:57, 20.06s/it]  2%|▏         | 37/1735 [11:55<8:35:06, 18.20s/it]  2%|▏         | 38/1735 [12:14<8:37:45, 18.31s/it]  2%|▏         | 39/1735 [12:42<9:59:22, 21.20s/it]  2%|▏         | 40/1735 [13:00<9:33:53, 20.31s/it]  2%|▏         | 41/1735 [13:15<8:49:22, 18.75s/it]  2%|▏         | 42/1735 [13:33<8:40:51, 18.46s/it]  2%|▏         | 43/1735 [13:48<8:16:09, 17.59s/it]  3%|▎         | 44/1735 [14:05<8:07:52, 17.31s/it]  3%|▎         | 45/1735 [14:24<8:22:17, 17.83s/it]  3%|▎         | 46/1735 [14:41<8:16:57, 17.65s/it]  3%|▎         | 47/1735 [14:59<8:16:28, 17.65s/it]  3%|▎         | 48/1735 [15:19<8:36:12, 18.36s/it]  3%|▎         | 49/1735 [15:37<8:32:26, 18.24s/it]  3%|▎         | 50/1735 [15:52<8:01:13, 17.14s/it]  3%|▎         | 51/1735 [16:20<9:31:51, 20.37s/it]  3%|▎         | 52/1735 [16:41<9:42:16, 20.76s/it]  3%|▎         | 53/1735 [16:54<8:32:36, 18.29s/it]  3%|▎         | 54/1735 [17:22<9:53:39, 21.19s/it]  3%|▎         | 55/1735 [17:38<9:15:12, 19.83s/it]  3%|▎         | 56/1735 [17:58<9:10:11, 19.66s/it]  3%|▎         | 57/1735 [18:25<10:18:38, 22.12s/it]  3%|▎         | 58/1735 [18:42<9:28:04, 20.32s/it]   3%|▎         | 59/1735 [18:59<8:59:31, 19.31s/it]  3%|▎         | 60/1735 [19:15<8:39:01, 18.59s/it]  4%|▎         | 61/1735 [19:36<8:56:18, 19.22s/it]  4%|▎         | 62/1735 [20:04<10:08:43, 21.83s/it]  4%|▎         | 63/1735 [20:26<10:05:38, 21.73s/it]  4%|▎         | 64/1735 [20:46<9:56:14, 21.41s/it]   4%|▎         | 65/1735 [21:05<9:35:05, 20.66s/it]  4%|▍         | 66/1735 [21:18<8:31:02, 18.37s/it]  4%|▍         | 67/1735 [21:35<8:14:08, 17.78s/it]  4%|▍         | 68/1735 [21:52<8:09:21, 17.61s/it]  4%|▍         | 69/1735 [22:13<8:41:14, 18.77s/it]  4%|▍         | 70/1735 [22:32<8:36:42, 18.62s/it]  4%|▍         | 71/1735 [22:55<9:14:02, 19.98s/it]  4%|▍         | 72/1735 [23:12<8:52:43, 19.22s/it]  4%|▍         | 73/1735 [23:31<8:49:40, 19.12s/it]  4%|▍         | 74/1735 [23:59<10:02:09, 21.75s/it]  4%|▍         | 75/1735 [24:16<9:26:08, 20.46s/it]   4%|▍         | 76/1735 [24:36<9:17:28, 20.16s/it]  4%|▍         | 77/1735 [24:49<8:18:19, 18.03s/it]  4%|▍         | 78/1735 [25:03<7:48:30, 16.96s/it]  5%|▍         | 79/1735 [25:22<8:06:02, 17.61s/it]  5%|▍         | 80/1735 [25:42<8:25:38, 18.33s/it]  5%|▍         | 81/1735 [26:01<8:29:07, 18.47s/it]  5%|▍         | 82/1735 [26:22<8:44:14, 19.03s/it]  5%|▍         | 83/1735 [26:44<9:12:07, 20.05s/it]  5%|▍         | 84/1735 [27:11<10:05:28, 22.00s/it]  5%|▍         | 85/1735 [27:30<9:40:16, 21.10s/it]   5%|▍         | 86/1735 [27:55<10:16:26, 22.43s/it]  5%|▌         | 87/1735 [28:13<9:41:01, 21.15s/it]   5%|▌         | 88/1735 [28:28<8:50:08, 19.31s/it]  5%|▌         | 89/1735 [28:45<8:27:20, 18.49s/it]  5%|▌         | 90/1735 [29:13<9:44:29, 21.32s/it]  5%|▌         | 91/1735 [29:29<9:03:10, 19.82s/it]  5%|▌         | 92/1735 [29:49<9:01:00, 19.76s/it]  5%|▌         | 93/1735 [30:17<10:07:51, 22.21s/it]  5%|▌         | 94/1735 [30:32<9:13:49, 20.25s/it]   5%|▌         | 95/1735 [31:00<10:16:23, 22.55s/it]  6%|▌         | 96/1735 [31:14<9:05:13, 19.96s/it]   6%|▌         | 97/1735 [31:40<9:52:57, 21.72s/it]  6%|▌         | 98/1735 [31:52<8:36:43, 18.94s/it]  6%|▌         | 99/1735 [32:18<9:27:38, 20.82s/it]  6%|▌         | 100/1735 [32:36<9:09:15, 20.16s/it]  6%|▌         | 101/1735 [32:53<8:37:42, 19.01s/it]  6%|▌         | 102/1735 [33:16<9:14:55, 20.39s/it]  6%|▌         | 103/1735 [33:41<9:50:09, 21.70s/it]  6%|▌         | 104/1735 [33:57<9:05:15, 20.06s/it]  6%|▌         | 105/1735 [34:15<8:48:21, 19.45s/it]  6%|▌         | 106/1735 [34:36<8:56:16, 19.75s/it]  6%|▌         | 107/1735 [34:49<8:03:07, 17.81s/it]  6%|▌         | 108/1735 [35:12<8:48:41, 19.50s/it]  6%|▋         | 109/1735 [35:40<9:57:04, 22.03s/it]  6%|▋         | 110/1735 [35:55<8:57:18, 19.84s/it]  6%|▋         | 111/1735 [36:14<8:48:39, 19.53s/it]  6%|▋         | 112/1735 [36:28<8:03:11, 17.86s/it]  7%|▋         | 113/1735 [36:46<8:02:51, 17.86s/it]  7%|▋         | 114/1735 [37:00<7:34:14, 16.81s/it]  7%|▋         | 115/1735 [37:21<8:07:40, 18.06s/it]  7%|▋         | 116/1735 [37:49<9:28:09, 21.06s/it]  7%|▋         | 117/1735 [38:17<10:23:23, 23.12s/it]  7%|▋         | 118/1735 [38:38<10:01:57, 22.34s/it]  7%|▋         | 119/1735 [38:53<9:08:40, 20.37s/it]   7%|▋         | 120/1735 [39:10<8:37:17, 19.22s/it]  7%|▋         | 121/1735 [39:25<8:03:16, 17.97s/it]  7%|▋         | 122/1735 [39:40<7:38:55, 17.07s/it]  7%|▋         | 123/1735 [40:08<9:04:09, 20.25s/it]  7%|▋         | 124/1735 [40:20<8:02:26, 17.97s/it]  7%|▋         | 125/1735 [40:36<7:48:30, 17.46s/it]  7%|▋         | 126/1735 [41:04<9:12:30, 20.60s/it]  7%|▋         | 127/1735 [41:19<8:24:42, 18.83s/it]  7%|▋         | 128/1735 [41:34<7:56:38, 17.80s/it]  7%|▋         | 129/1735 [41:55<8:18:08, 18.61s/it]  7%|▋         | 130/1735 [42:10<7:46:52, 17.45s/it]  8%|▊         | 131/1735 [42:29<7:58:57, 17.92s/it]  8%|▊         | 132/1735 [42:57<9:19:11, 20.93s/it]  8%|▊         | 133/1735 [43:14<8:45:57, 19.70s/it]  8%|▊         | 134/1735 [43:28<8:05:26, 18.19s/it]  8%|▊         | 135/1735 [43:50<8:37:30, 19.41s/it]  8%|▊         | 136/1735 [44:13<9:00:09, 20.27s/it]  8%|▊         | 137/1735 [44:33<8:57:21, 20.18s/it]  8%|▊         | 138/1735 [44:46<8:05:14, 18.23s/it]  8%|▊         | 139/1735 [45:08<8:29:17, 19.15s/it]  8%|▊         | 140/1735 [45:28<8:40:10, 19.57s/it]  8%|▊         | 141/1735 [45:50<8:54:11, 20.11s/it]  8%|▊         | 142/1735 [46:03<7:59:40, 18.07s/it]  8%|▊         | 143/1735 [46:19<7:40:17, 17.35s/it]  8%|▊         | 144/1735 [46:45<8:49:57, 19.99s/it]  8%|▊         | 145/1735 [47:07<9:11:01, 20.79s/it]  8%|▊         | 146/1735 [47:26<8:56:38, 20.26s/it]  8%|▊         | 147/1735 [47:44<8:32:06, 19.35s/it]  9%|▊         | 148/1735 [48:04<8:43:11, 19.78s/it]  9%|▊         | 149/1735 [48:21<8:18:50, 18.87s/it]  9%|▊         | 150/1735 [48:47<9:12:41, 20.92s/it]  9%|▊         | 151/1735 [49:03<8:36:00, 19.55s/it]  9%|▉         | 152/1735 [49:18<7:59:51, 18.19s/it]  9%|▉         | 153/1735 [49:46<9:16:31, 21.11s/it]  9%|▉         | 154/1735 [50:05<8:55:24, 20.32s/it]  9%|▉         | 155/1735 [50:30<9:35:48, 21.87s/it]  9%|▉         | 156/1735 [50:46<8:46:07, 19.99s/it]  9%|▉         | 157/1735 [51:01<8:05:54, 18.48s/it]  9%|▉         | 158/1735 [51:22<8:31:15, 19.45s/it]  9%|▉         | 159/1735 [51:47<9:12:39, 21.04s/it]  9%|▉         | 160/1735 [52:04<8:43:05, 19.93s/it]  9%|▉         | 161/1735 [52:26<8:57:38, 20.49s/it]  9%|▉         | 162/1735 [52:50<9:19:02, 21.32s/it]  9%|▉         | 163/1735 [53:03<8:16:13, 18.94s/it]  9%|▉         | 164/1735 [53:23<8:21:07, 19.14s/it] 10%|▉         | 165/1735 [53:45<8:44:53, 20.06s/it] 10%|▉         | 166/1735 [54:00<8:10:10, 18.74s/it] 10%|▉         | 167/1735 [54:22<8:30:50, 19.55s/it] 10%|▉         | 168/1735 [54:39<8:11:08, 18.81s/it] 10%|▉         | 169/1735 [54:55<7:45:45, 17.85s/it] 10%|▉         | 170/1735 [55:09<7:15:54, 16.71s/it] 10%|▉         | 171/1735 [55:26<7:17:36, 16.79s/it] 10%|▉         | 172/1735 [55:46<7:48:42, 17.99s/it] 10%|▉         | 173/1735 [56:03<7:37:55, 17.59s/it] 10%|█         | 174/1735 [56:26<8:16:42, 19.09s/it] 10%|█         | 175/1735 [56:49<8:48:43, 20.34s/it] 10%|█         | 176/1735 [57:16<9:43:46, 22.47s/it] 10%|█         | 177/1735 [57:31<8:44:03, 20.18s/it] 10%|█         | 178/1735 [57:47<8:06:42, 18.76s/it] 10%|█         | 179/1735 [58:04<7:55:46, 18.35s/it] 10%|█         | 180/1735 [58:32<9:09:15, 21.19s/it] 10%|█         | 181/1735 [58:51<8:51:44, 20.53s/it] 10%|█         | 182/1735 [59:04<7:52:31, 18.26s/it] 11%|█         | 183/1735 [59:26<8:19:48, 19.32s/it] 11%|█         | 184/1735 [59:44<8:09:53, 18.95s/it] 11%|█         | 185/1735 [1:00:03<8:12:02, 19.05s/it] 11%|█         | 186/1735 [1:00:17<7:36:49, 17.69s/it] 11%|█         | 187/1735 [1:00:42<8:27:21, 19.67s/it] 11%|█         | 188/1735 [1:01:05<8:57:14, 20.84s/it] 11%|█         | 189/1735 [1:01:33<9:51:14, 22.95s/it] 11%|█         | 190/1735 [1:01:47<8:42:10, 20.28s/it] 11%|█         | 191/1735 [1:01:58<7:30:44, 17.52s/it] 11%|█         | 192/1735 [1:02:16<7:35:40, 17.72s/it] 11%|█         | 193/1735 [1:02:34<7:30:55, 17.55s/it] 11%|█         | 194/1735 [1:02:50<7:22:55, 17.25s/it] 11%|█         | 195/1735 [1:03:04<6:56:00, 16.21s/it] 11%|█▏        | 196/1735 [1:03:30<8:09:43, 19.09s/it] 11%|█▏        | 197/1735 [1:03:55<8:59:06, 21.03s/it] 11%|█▏        | 198/1735 [1:04:13<8:31:36, 19.97s/it] 11%|█▏        | 199/1735 [1:04:34<8:40:40, 20.34s/it] 12%|█▏        | 200/1735 [1:04:51<8:11:20, 19.21s/it] 12%|█▏        | 201/1735 [1:05:10<8:09:59, 19.17s/it] 12%|█▏        | 202/1735 [1:05:35<8:54:08, 20.91s/it] 12%|█▏        | 203/1735 [1:05:58<9:13:26, 21.68s/it] 12%|█▏        | 204/1735 [1:06:19<9:06:20, 21.41s/it] 12%|█▏        | 205/1735 [1:06:40<9:07:23, 21.47s/it] 12%|phoenix-srun: Force Terminated job 2579919
phoenix-srun: Job step aborted: Waiting up to 2 seconds for job step to finish.
phoenix-srun: Easily find out why your job was killed by following the link below:
	https://docs.phoenix.sensetime.com/FAQ/SlurmFAQ/Find-out-why-my-job-was-killed/
█▏        | 206/1735 [1:07:00<8:51:00, 20.84s/it] 12%|█▏        | 207/1735 [1:07:16<8:17:37, 19.54s/it] 12%|█▏        | 208/1735 [1:07:36<8:18:29, 19.59s/it] 12%|█▏        | 209/1735 [1:07:57<8:29:27, 20.03s/it]slurmstepd: error: *** STEP 2579919.0 ON SH-IDCA1404-10-140-54-100 CANCELLED AT 2024-03-07T23:18:53 ***
phoenix-srun: error: SH-IDCA1404-10-140-54-100: task 0: Terminated
phoenix-srun: launch/slurm: _step_signal: Terminating StepId=2579919.0
