{"train/loss": 0.6905, "train/learning_rate": 7.497656982193065e-09, "train/rewards/chosen": 0.0025281310081481934, "train/rewards/rejected": -0.012452935799956322, "train/rewards/accuracies": 0.625, "train/rewards/margins": 0.01498106587678194, "train/policy_logps/rejected": -327.79150390625, "train/policy_logps/chosen": -301.081298828125, "train/referece_logps/rejected": -327.6669921875, "train/referece_logps/chosen": -301.1065673828125, "train/logits/rejected": -0.7640012502670288, "train/logits/chosen": -0.3372518718242645, "train/epoch": 0.0, "train/global_step": 4, "_timestamp": 1709392362.99343, "_runtime": 111.98120093345642, "_step": 3}