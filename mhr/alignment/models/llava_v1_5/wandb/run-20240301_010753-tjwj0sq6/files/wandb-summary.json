{"train/loss": 0.6931, "train/learning_rate": 1.9746111704292816e-06, "train/rewards/chosen": -2010.7119140625, "train/rewards/rejected": -2010.7119140625, "train/rewards/accuracies": 0.0, "train/rewards/margins": 0.0, "train/policy_logps/rejected": -20383.033203125, "train/policy_logps/chosen": -20383.033203125, "train/referece_logps/rejected": -275.91363525390625, "train/referece_logps/chosen": -275.91363525390625, "train/logits/rejected": 1.9314608573913574, "train/logits/chosen": 1.9314608573913574, "train/epoch": 0.1, "train/global_step": 1773, "_timestamp": 1709265966.4992876, "_runtime": 39492.52277159691, "_step": 1772}