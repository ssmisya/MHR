{"train/loss": 0.3473, "train/learning_rate": 1.8576451474218976e-06, "train/rewards/chosen": -1.7552413940429688, "train/rewards/rejected": -3.7563326358795166, "train/rewards/accuracies": 0.8125, "train/rewards/margins": 2.001091241836548, "train/policy_logps/rejected": -362.6272277832031, "train/policy_logps/chosen": -438.2598876953125, "train/referece_logps/rejected": -325.0638732910156, "train/referece_logps/chosen": -420.7074279785156, "train/logits/rejected": -0.3090273141860962, "train/logits/chosen": -0.36158570647239685, "train/epoch": 0.2, "train/global_step": 6994, "_timestamp": 1709614902.5402904, "_runtime": 146397.86011624336, "_step": 6993}