{"train/loss": 0.6931, "train/learning_rate": 2.214022140221402e-08, "train/rewards/chosen": -0.02174377627670765, "train/rewards/rejected": -0.001028680708259344, "train/rewards/accuracies": 0.25, "train/rewards/margins": -0.02071509324014187, "train/policy_logps/rejected": -289.9349365234375, "train/policy_logps/chosen": -395.5956726074219, "train/referece_logps/rejected": -289.9246826171875, "train/referece_logps/chosen": -395.378173828125, "train/logits/rejected": -0.8890843987464905, "train/logits/chosen": -0.9895773530006409, "train/epoch": 0.0, "train/global_step": 3, "_timestamp": 1709996122.1944685, "_runtime": 76.37135243415833, "_step": 2}