{"train/loss": 0.6862, "train/learning_rate": 1.99970388732558e-06, "train/rewards/chosen": 0.007103158161044121, "train/rewards/rejected": -0.0052311900071799755, "train/rewards/accuracies": 0.625, "train/rewards/margins": 0.012334348633885384, "train/policy_logps/rejected": -392.302978515625, "train/policy_logps/chosen": -434.2635803222656, "train/referece_logps/rejected": -392.2506408691406, "train/referece_logps/chosen": -434.3346252441406, "train/logits/rejected": -0.6254266500473022, "train/logits/chosen": -0.7475317120552063, "train/epoch": 0.11, "train/global_step": 55, "_timestamp": 1709894946.1801136, "_runtime": 1158.0223145484924, "_step": 54}