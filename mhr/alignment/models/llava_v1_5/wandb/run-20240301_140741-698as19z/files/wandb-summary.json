{"train/loss": 0.2627, "train/learning_rate": 1.526691923246488e-06, "train/rewards/chosen": -3.339257001876831, "train/rewards/rejected": -6.211357116699219, "train/rewards/accuracies": 0.8125, "train/rewards/margins": 2.872100830078125, "train/policy_logps/rejected": -297.6932373046875, "train/policy_logps/chosen": -306.5307922363281, "train/referece_logps/rejected": -235.57965087890625, "train/referece_logps/chosen": -273.1382141113281, "train/logits/rejected": 0.1426229178905487, "train/logits/chosen": -0.4034894108772278, "train/epoch": 0.34, "train/global_step": 12217, "_timestamp": 1709528968.9851875, "_runtime": 255707.3886935711, "_step": 12216}