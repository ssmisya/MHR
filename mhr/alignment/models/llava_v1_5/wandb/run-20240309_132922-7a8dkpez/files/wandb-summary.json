{"train/loss": 0.681, "train/learning_rate": 1.99970388732558e-06, "train/rewards/chosen": 0.01995840109884739, "train/rewards/rejected": -0.014714335091412067, "train/rewards/accuracies": 0.75, "train/rewards/margins": 0.03467273712158203, "train/policy_logps/rejected": -392.4155578613281, "train/policy_logps/chosen": -434.082275390625, "train/referece_logps/rejected": -392.2684020996094, "train/referece_logps/chosen": -434.2818603515625, "train/logits/rejected": -0.6258590221405029, "train/logits/chosen": -0.7480716109275818, "train/epoch": 0.11, "train/global_step": 55, "_timestamp": 1709963319.5740197, "_runtime": 1157.190348625183, "_step": 54}