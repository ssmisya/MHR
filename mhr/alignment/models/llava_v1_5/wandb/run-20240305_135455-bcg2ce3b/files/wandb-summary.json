{"train/loss": 0.6559, "train/learning_rate": 1.992492206112064e-06, "train/rewards/chosen": -0.39271071553230286, "train/rewards/rejected": -0.5402700901031494, "train/rewards/accuracies": 0.5625, "train/rewards/margins": 0.14755935966968536, "train/policy_logps/rejected": -516.1319580078125, "train/policy_logps/chosen": -397.4285583496094, "train/referece_logps/rejected": -510.7292175292969, "train/referece_logps/chosen": -393.50146484375, "train/logits/rejected": -1.0928622484207153, "train/logits/chosen": -1.082425594329834, "train/epoch": 0.21, "train/global_step": 67, "_timestamp": 1709619489.5318155, "_runtime": 1394.04540848732, "_step": 66}