  0%|          | 0/4149 [00:00<?, ?it/s]/mnt/petrelfs/songmingyang/code/mm/MAPO/m3apo/alignment/trainer/llava_dpo_trainer.py:135: UserWarning: compute_loss is only implemented for DPODataCollatorWithPadding, and you passed a datacollator that is different than DPODataCollatorWithPadding - you might see unexpected behavior. Alternatively, you can implement your own prediction_step method if you are using a custom data collator
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/4149 [00:24<28:20:45, 24.60s/it]

  0%|          | 2/4149 [00:46<26:22:45, 22.90s/it]

  0%|          | 3/4149 [01:07<25:24:11, 22.06s/it]
{'loss': 0.6986, 'learning_rate': 4.8e-08, 'rewards/chosen': 0.00872802734375, 'rewards/rejected': -0.01884431764483452, 'rewards/accuracies': 0.75, 'rewards/margins': 0.02757234498858452, 'policy_logps/rejected': -498.96466064453125, 'policy_logps/chosen': -440.955322265625, 'referece_logps/rejected': -498.7761535644531, 'referece_logps/chosen': -441.0426330566406, 'logits/rejected': -0.47941192984580994, 'logits/chosen': -0.3441733419895172, 'epoch': 0.0}
[2024-03-09 01:03:30,686] [WARNING] [stage3.py:2069:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time


  0%|          | 5/4149 [01:49<24:49:40, 21.57s/it]

  0%|          | 6/4149 [02:10<24:31:37, 21.31s/it]

  0%|          | 7/4149 [02:31<24:17:46, 21.12s/it]

  0%|          | 8/4149 [02:52<24:16:54, 21.11s/it]

  0%|          | 9/4149 [03:13<24:16:51, 21.11s/it]

  0%|          | 10/4149 [03:34<24:13:10, 21.07s/it]

  0%|          | 11/4149 [03:55<24:07:30, 20.99s/it]

  0%|          | 12/4149 [04:16<24:03:36, 20.94s/it]

  0%|          | 13/4149 [04:36<23:40:39, 20.61s/it]

  0%|          | 14/4149 [04:57<23:49:56, 20.75s/it]

  0%|          | 15/4149 [05:18<23:57:13, 20.86s/it]

  0%|          | 16/4149 [05:39<23:55:39, 20.84s/it]

  0%|          | 17/4149 [05:59<23:50:56, 20.78s/it]

  0%|          | 18/4149 [06:20<23:53:00, 20.81s/it]

  0%|          | 19/4149 [06:41<23:56:33, 20.87s/it]
{'loss': 0.6953, 'learning_rate': 3.0399999999999997e-07, 'rewards/chosen': 0.004853248130530119, 'rewards/rejected': -0.007329463958740234, 'rewards/accuracies': 0.375, 'rewards/margins': 0.012182711623609066, 'policy_logps/rejected': -434.2479248046875, 'policy_logps/chosen': -408.0187683105469, 'referece_logps/rejected': -434.17462158203125, 'referece_logps/chosen': -408.06732177734375, 'logits/rejected': -0.579071044921875, 'logits/chosen': -0.6341903209686279, 'epoch': 0.01}


  1%|          | 21/4149 [07:24<24:08:59, 21.06s/it]

  1%|          | 22/4149 [07:44<24:01:05, 20.95s/it]

  1%|          | 23/4149 [08:05<24:02:16, 20.97s/it]
{'loss': 0.6862, 'learning_rate': 3.6799999999999996e-07, 'rewards/chosen': 0.018220623955130577, 'rewards/rejected': -0.003384827869012952, 'rewards/accuracies': 0.625, 'rewards/margins': 0.021605458110570908, 'policy_logps/rejected': -443.7438049316406, 'policy_logps/chosen': -381.50732421875, 'referece_logps/rejected': -443.7099304199219, 'referece_logps/chosen': -381.68951416015625, 'logits/rejected': -0.5112574696540833, 'logits/chosen': -0.4763774573802948, 'epoch': 0.02}


  1%|          | 25/4149 [08:46<23:31:56, 20.54s/it]

  1%|          | 26/4149 [09:07<23:43:25, 20.71s/it]

  1%|          | 27/4149 [09:28<23:45:39, 20.75s/it]

  1%|          | 28/4149 [09:49<23:52:25, 20.86s/it]

  1%|          | 29/4149 [10:10<23:56:36, 20.92s/it]

  1%|          | 30/4149 [10:31<23:58:41, 20.96s/it]

  1%|          | 31/4149 [10:52<23:56:33, 20.93s/it]

  1%|          | 32/4149 [11:13<23:58:04, 20.96s/it]

  1%|          | 33/4149 [11:34<23:59:41, 20.99s/it]

  1%|          | 34/4149 [11:54<23:41:34, 20.73s/it]

  1%|          | 35/4149 [12:15<23:48:48, 20.84s/it]

  1%|          | 36/4149 [12:36<23:44:15, 20.78s/it]
{'loss': 0.692, 'learning_rate': 5.76e-07, 'rewards/chosen': -0.006141090765595436, 'rewards/rejected': -0.003226662054657936, 'rewards/accuracies': 0.375, 'rewards/margins': -0.0029144296422600746, 'policy_logps/rejected': -322.3168640136719, 'policy_logps/chosen': -380.2832336425781, 'referece_logps/rejected': -322.28460693359375, 'referece_logps/chosen': -380.2218017578125, 'logits/rejected': -0.13332438468933105, 'logits/chosen': -0.09208221733570099, 'epoch': 0.03}


  1%|          | 38/4149 [13:18<23:51:53, 20.90s/it]
{'loss': 0.6933, 'learning_rate': 6.079999999999999e-07, 'rewards/chosen': 0.0035717017017304897, 'rewards/rejected': -0.018471289426088333, 'rewards/accuracies': 0.75, 'rewards/margins': 0.02204299159348011, 'policy_logps/rejected': -473.72491455078125, 'policy_logps/chosen': -497.6596984863281, 'referece_logps/rejected': -473.54022216796875, 'referece_logps/chosen': -497.69537353515625, 'logits/rejected': -0.6389991044998169, 'logits/chosen': -0.6465588212013245, 'epoch': 0.03}


  1%|          | 40/4149 [13:59<23:47:26, 20.84s/it]

  1%|          | 41/4149 [14:20<23:47:09, 20.84s/it]

  1%|          | 42/4149 [14:41<23:46:50, 20.85s/it]

  1%|          | 43/4149 [15:02<23:47:34, 20.86s/it]

  1%|          | 44/4149 [15:23<23:46:23, 20.85s/it]

  1%|          | 45/4149 [15:44<23:45:28, 20.84s/it]

  1%|          | 46/4149 [16:05<23:49:57, 20.91s/it]

  1%|          | 47/4149 [16:26<23:53:20, 20.97s/it]

  1%|          | 48/4149 [16:47<23:55:21, 21.00s/it]

  1%|          | 49/4149 [17:08<23:52:16, 20.96s/it]

  1%|          | 50/4149 [17:29<23:52:36, 20.97s/it]

  1%|          | 51/4149 [17:50<23:54:30, 21.00s/it]

  1%|▏         | 52/4149 [18:11<23:49:09, 20.93s/it]

  1%|▏         | 53/4149 [18:32<23:52:33, 20.98s/it]

  1%|▏         | 54/4149 [18:53<23:53:28, 21.00s/it]

  1%|▏         | 55/4149 [19:14<23:54:20, 21.02s/it]

  1%|▏         | 56/4149 [19:34<23:47:12, 20.92s/it]

  1%|▏         | 57/4149 [19:56<23:50:47, 20.98s/it]

  1%|▏         | 58/4149 [20:16<23:48:04, 20.94s/it]

  1%|▏         | 59/4149 [20:37<23:49:04, 20.96s/it]

  1%|▏         | 60/4149 [20:59<23:51:28, 21.00s/it]

  1%|▏         | 61/4149 [21:20<23:51:09, 21.01s/it]

  1%|▏         | 62/4149 [21:40<23:40:49, 20.86s/it]

  2%|▏         | 63/4149 [22:01<23:39:45, 20.85s/it]

  2%|▏         | 64/4149 [22:22<23:42:40, 20.90s/it]

  2%|▏         | 65/4149 [22:43<23:45:01, 20.94s/it]

  2%|▏         | 66/4149 [23:04<23:39:21, 20.86s/it]

  2%|▏         | 67/4149 [23:24<23:37:23, 20.83s/it]

  2%|▏         | 68/4149 [23:45<23:32:56, 20.77s/it]

  2%|▏         | 69/4149 [24:06<23:38:39, 20.86s/it]

  2%|▏         | 70/4149 [24:27<23:43:01, 20.93s/it]

  2%|▏         | 71/4149 [24:48<23:36:54, 20.85s/it]

  2%|▏         | 72/4149 [25:09<23:39:49, 20.90s/it]

  2%|▏         | 73/4149 [25:29<23:33:04, 20.80s/it]

  2%|▏         | 74/4149 [25:51<23:39:15, 20.90s/it]

  2%|▏         | 75/4149 [26:11<23:35:06, 20.84s/it]

  2%|▏         | 76/4149 [26:32<23:38:03, 20.89s/it]

  2%|▏         | 77/4149 [26:53<23:38:59, 20.91s/it]
{'loss': 0.6915, 'learning_rate': 1.232e-06, 'rewards/chosen': -0.0022082324139773846, 'rewards/rejected': -0.01664891466498375, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.014440679922699928, 'policy_logps/rejected': -362.3502502441406, 'policy_logps/chosen': -378.811279296875, 'referece_logps/rejected': -362.1837463378906, 'referece_logps/chosen': -378.7891540527344, 'logits/rejected': -0.4733986258506775, 'logits/chosen': -0.5945205688476562, 'epoch': 0.06}


  2%|▏         | 79/4149 [27:35<23:41:05, 20.95s/it]

  2%|▏         | 80/4149 [27:56<23:45:30, 21.02s/it]

  2%|▏         | 81/4149 [28:17<23:48:03, 21.06s/it]

  2%|▏         | 82/4149 [28:38<23:46:51, 21.05s/it]

  2%|▏         | 83/4149 [28:59<23:46:28, 21.05s/it]

  2%|▏         | 84/4149 [29:21<23:48:14, 21.08s/it]

  2%|▏         | 85/4149 [29:42<23:48:11, 21.09s/it]

  2%|▏         | 86/4149 [30:03<23:52:12, 21.15s/it]
{'loss': 0.6922, 'learning_rate': 1.3759999999999998e-06, 'rewards/chosen': -0.009927555918693542, 'rewards/rejected': 0.015804005786776543, 'rewards/accuracies': 0.375, 'rewards/margins': -0.025731563568115234, 'policy_logps/rejected': -543.1973876953125, 'policy_logps/chosen': -484.01904296875, 'referece_logps/rejected': -543.35546875, 'referece_logps/chosen': -483.9197692871094, 'logits/rejected': -0.017902575433254242, 'logits/chosen': -0.02006109245121479, 'epoch': 0.06}


  2%|▏         | 88/4149 [30:45<23:51:51, 21.16s/it]
{'loss': 0.6907, 'learning_rate': 1.408e-06, 'rewards/chosen': 0.01143341138958931, 'rewards/rejected': -0.007039928808808327, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.018473342061042786, 'policy_logps/rejected': -433.60528564453125, 'policy_logps/chosen': -406.24578857421875, 'referece_logps/rejected': -433.5348815917969, 'referece_logps/chosen': -406.360107421875, 'logits/rejected': -0.057390257716178894, 'logits/chosen': -0.10222846269607544, 'epoch': 0.06}


  2%|▏         | 90/4149 [31:27<23:41:34, 21.01s/it]
{'loss': 0.684, 'learning_rate': 1.44e-06, 'rewards/chosen': -0.025209786370396614, 'rewards/rejected': -0.052101798355579376, 'rewards/accuracies': 0.625, 'rewards/margins': 0.02689201571047306, 'policy_logps/rejected': -301.3660888671875, 'policy_logps/chosen': -333.06097412109375, 'referece_logps/rejected': -300.8450622558594, 'referece_logps/chosen': -332.8089294433594, 'logits/rejected': 0.014098802581429482, 'logits/chosen': 0.03956242650747299, 'epoch': 0.07}


  2%|▏         | 92/4149 [32:09<23:41:05, 21.02s/it]
{'loss': 0.6938, 'learning_rate': 1.4719999999999998e-06, 'rewards/chosen': -0.011823272332549095, 'rewards/rejected': 0.021762466058135033, 'rewards/accuracies': 0.3125, 'rewards/margins': -0.03358573839068413, 'policy_logps/rejected': -509.56268310546875, 'policy_logps/chosen': -409.7041015625, 'referece_logps/rejected': -509.78033447265625, 'referece_logps/chosen': -409.5858459472656, 'logits/rejected': -0.38262465596199036, 'logits/chosen': -0.3949158787727356, 'epoch': 0.07}


  2%|▏         | 94/4149 [32:51<23:35:01, 20.94s/it]

  2%|▏         | 95/4149 [33:11<23:11:18, 20.59s/it]

  2%|▏         | 96/4149 [33:32<23:21:40, 20.75s/it]

  2%|▏         | 97/4149 [33:53<23:28:49, 20.86s/it]

  2%|▏         | 98/4149 [34:14<23:31:22, 20.90s/it]

  2%|▏         | 99/4149 [34:35<23:32:34, 20.93s/it]

  2%|▏         | 100/4149 [34:56<23:35:32, 20.98s/it]
{'loss': 0.6995, 'learning_rate': 1.6e-06, 'rewards/chosen': -0.023363973945379257, 'rewards/rejected': -0.021038103848695755, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0023258673027157784, 'policy_logps/rejected': -293.3232116699219, 'policy_logps/chosen': -247.70382690429688, 'referece_logps/rejected': -293.1128234863281, 'referece_logps/chosen': -247.47018432617188, 'logits/rejected': -0.564538836479187, 'logits/chosen': -0.5953163504600525, 'epoch': 0.07}


  2%|▏         | 102/4149 [35:38<23:29:20, 20.89s/it]
{'loss': 0.6997, 'learning_rate': 1.6319999999999998e-06, 'rewards/chosen': 0.0023157126270234585, 'rewards/rejected': 0.0050567747093737125, 'rewards/accuracies': 0.5625, 'rewards/margins': -0.0027410630136728287, 'policy_logps/rejected': -454.6626281738281, 'policy_logps/chosen': -463.3697204589844, 'referece_logps/rejected': -454.71319580078125, 'referece_logps/chosen': -463.3929138183594, 'logits/rejected': -0.467844158411026, 'logits/chosen': -0.5670653581619263, 'epoch': 0.07}


  3%|▎         | 104/4149 [36:20<23:32:53, 20.96s/it]
{'loss': 0.6835, 'learning_rate': 1.6639999999999999e-06, 'rewards/chosen': 0.005667497403919697, 'rewards/rejected': 7.535098120570183e-06, 'rewards/accuracies': 0.5, 'rewards/margins': 0.005659961141645908, 'policy_logps/rejected': -408.11376953125, 'policy_logps/chosen': -439.458251953125, 'referece_logps/rejected': -408.1138916015625, 'referece_logps/chosen': -439.5149230957031, 'logits/rejected': -0.34225285053253174, 'logits/chosen': -0.2189236581325531, 'epoch': 0.08}


  3%|▎         | 106/4149 [37:01<23:29:41, 20.92s/it]
{'loss': 0.6933, 'learning_rate': 1.696e-06, 'rewards/chosen': 0.0005570417270064354, 'rewards/rejected': -0.015593813732266426, 'rewards/accuracies': 0.625, 'rewards/margins': 0.016150856390595436, 'policy_logps/rejected': -398.03240966796875, 'policy_logps/chosen': -422.7335510253906, 'referece_logps/rejected': -397.8764953613281, 'referece_logps/chosen': -422.7391357421875, 'logits/rejected': -0.749953031539917, 'logits/chosen': -0.7663560509681702, 'epoch': 0.08}

  3%|▎         | 107/4149 [37:22<23:31:34, 20.95s/it]


  3%|▎         | 109/4149 [38:04<23:20:53, 20.81s/it]
{'loss': 0.6892, 'learning_rate': 1.744e-06, 'rewards/chosen': 0.0029657362028956413, 'rewards/rejected': -0.006516648456454277, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.009482384659349918, 'policy_logps/rejected': -369.54742431640625, 'policy_logps/chosen': -318.64117431640625, 'referece_logps/rejected': -369.48223876953125, 'referece_logps/chosen': -318.67083740234375, 'logits/rejected': -0.2737809121608734, 'logits/chosen': -0.19873429834842682, 'epoch': 0.08}


  3%|▎         | 111/4149 [38:46<23:27:40, 20.92s/it]
{'loss': 0.6988, 'learning_rate': 1.776e-06, 'rewards/chosen': 0.0006568909157067537, 'rewards/rejected': 0.016000699251890182, 'rewards/accuracies': 0.3125, 'rewards/margins': -0.015343810431659222, 'policy_logps/rejected': -325.21478271484375, 'policy_logps/chosen': -308.8901672363281, 'referece_logps/rejected': -325.3747863769531, 'referece_logps/chosen': -308.896728515625, 'logits/rejected': -0.5405772924423218, 'logits/chosen': -0.48658353090286255, 'epoch': 0.08}


  3%|▎         | 113/4149 [39:27<23:24:13, 20.88s/it]

  3%|▎         | 114/4149 [39:48<23:20:50, 20.83s/it]
{'loss': 0.6885, 'learning_rate': 1.824e-06, 'rewards/chosen': 0.011115837842226028, 'rewards/rejected': -0.005545997992157936, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.016661833971738815, 'policy_logps/rejected': -384.1072082519531, 'policy_logps/chosen': -429.6616516113281, 'referece_logps/rejected': -384.0517578125, 'referece_logps/chosen': -429.7727966308594, 'logits/rejected': -0.09519802033901215, 'logits/chosen': -0.17811988294124603, 'epoch': 0.08}


  3%|▎         | 116/4149 [40:29<23:11:18, 20.70s/it]
{'loss': 0.6834, 'learning_rate': 1.856e-06, 'rewards/chosen': 0.002541160210967064, 'rewards/rejected': -0.026748083531856537, 'rewards/accuracies': 0.625, 'rewards/margins': 0.02928924560546875, 'policy_logps/rejected': -360.5704650878906, 'policy_logps/chosen': -529.2439575195312, 'referece_logps/rejected': -360.3030090332031, 'referece_logps/chosen': -529.2694091796875, 'logits/rejected': -0.4780113399028778, 'logits/chosen': -0.4735572338104248, 'epoch': 0.08}


  3%|▎         | 118/4149 [41:12<23:32:07, 21.02s/it]
{'loss': 0.6897, 'learning_rate': 1.8879999999999998e-06, 'rewards/chosen': -0.02075662836432457, 'rewards/rejected': -0.025876425206661224, 'rewards/accuracies': 0.5, 'rewards/margins': 0.005119800567626953, 'policy_logps/rejected': -398.57586669921875, 'policy_logps/chosen': -408.14862060546875, 'referece_logps/rejected': -398.31707763671875, 'referece_logps/chosen': -407.9410400390625, 'logits/rejected': 0.13326093554496765, 'logits/chosen': 0.019196435809135437, 'epoch': 0.09}


  3%|▎         | 120/4149 [41:54<23:32:51, 21.04s/it]
{'loss': 0.6829, 'learning_rate': 1.92e-06, 'rewards/chosen': -0.023419905453920364, 'rewards/rejected': -0.01241154596209526, 'rewards/accuracies': 0.4375, 'rewards/margins': -0.011008361354470253, 'policy_logps/rejected': -331.9110107421875, 'policy_logps/chosen': -333.1942138671875, 'referece_logps/rejected': -331.78692626953125, 'referece_logps/chosen': -332.96002197265625, 'logits/rejected': -0.7565679550170898, 'logits/chosen': -0.8327724933624268, 'epoch': 0.09}


  3%|▎         | 122/4149 [42:36<23:31:09, 21.03s/it]
{'loss': 0.6939, 'learning_rate': 1.9519999999999997e-06, 'rewards/chosen': -0.02887134999036789, 'rewards/rejected': -0.021519850939512253, 'rewards/accuracies': 0.4375, 'rewards/margins': -0.007351492997258902, 'policy_logps/rejected': -386.5158386230469, 'policy_logps/chosen': -481.7284240722656, 'referece_logps/rejected': -386.30059814453125, 'referece_logps/chosen': -481.439697265625, 'logits/rejected': -0.34596481919288635, 'logits/chosen': -0.31563082337379456, 'epoch': 0.09}


  3%|▎         | 124/4149 [43:18<23:27:49, 20.99s/it]
{'loss': 0.6829, 'learning_rate': 1.984e-06, 'rewards/chosen': -0.007661724463105202, 'rewards/rejected': -0.03629312291741371, 'rewards/accuracies': 0.625, 'rewards/margins': 0.02863140031695366, 'policy_logps/rejected': -434.17779541015625, 'policy_logps/chosen': -399.3714294433594, 'referece_logps/rejected': -433.8148193359375, 'referece_logps/chosen': -399.2947998046875, 'logits/rejected': -0.4650459587574005, 'logits/chosen': -0.48504525423049927, 'epoch': 0.09}


  3%|▎         | 126/4149 [44:00<23:26:08, 20.97s/it]
{'loss': 0.69, 'learning_rate': 1.9999996952429343e-06, 'rewards/chosen': -0.006821250542998314, 'rewards/rejected': -0.024614429101347923, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.01779317855834961, 'policy_logps/rejected': -349.1755676269531, 'policy_logps/chosen': -407.36602783203125, 'referece_logps/rejected': -348.9294128417969, 'referece_logps/chosen': -407.2978515625, 'logits/rejected': -0.5167595148086548, 'logits/chosen': -0.5153300762176514, 'epoch': 0.09}

