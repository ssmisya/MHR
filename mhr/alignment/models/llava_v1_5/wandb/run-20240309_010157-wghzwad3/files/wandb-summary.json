{"train/loss": 0.6814, "train/learning_rate": 1.999998780971922e-06, "train/rewards/chosen": 0.01658511348068714, "train/rewards/rejected": -0.02687535248696804, "train/rewards/accuracies": 0.75, "train/rewards/margins": 0.043460458517074585, "train/policy_logps/rejected": -362.9630432128906, "train/policy_logps/chosen": -307.2230529785156, "train/referece_logps/rejected": -362.6943054199219, "train/referece_logps/chosen": -307.3889465332031, "train/logits/rejected": -0.6803237199783325, "train/logits/chosen": -0.5952344536781311, "train/epoch": 0.09, "train/global_step": 127, "_timestamp": 1709919983.5255933, "_runtime": 2666.420120239258, "_step": 126}