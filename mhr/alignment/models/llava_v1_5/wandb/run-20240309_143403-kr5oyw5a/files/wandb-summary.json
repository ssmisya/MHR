{"train/loss": 0.6919, "train/learning_rate": 1.99970388732558e-06, "train/rewards/chosen": -0.016088392585515976, "train/rewards/rejected": -0.004606723785400391, "train/rewards/accuracies": 0.375, "train/rewards/margins": -0.011481666006147861, "train/policy_logps/rejected": -392.3968811035156, "train/policy_logps/chosen": -434.32623291015625, "train/referece_logps/rejected": -392.3507995605469, "train/referece_logps/chosen": -434.16534423828125, "train/logits/rejected": -0.6263059973716736, "train/logits/chosen": -0.7480708956718445, "train/epoch": 0.11, "train/global_step": 55, "_timestamp": 1709967200.656003, "_runtime": 1157.6147799491882, "_step": 54}