{"train/loss": 0.6812, "train/learning_rate": 1.99970388732558e-06, "train/rewards/chosen": 0.017076589167118073, "train/rewards/rejected": -0.013028623536229134, "train/rewards/accuracies": 0.5625, "train/rewards/margins": 0.030105212703347206, "train/policy_logps/rejected": -392.429443359375, "train/policy_logps/chosen": -434.1997375488281, "train/referece_logps/rejected": -392.29913330078125, "train/referece_logps/chosen": -434.3704833984375, "train/logits/rejected": -0.6252284646034241, "train/logits/chosen": -0.7477253079414368, "train/epoch": 0.11, "train/global_step": 55, "_timestamp": 1709967991.2789886, "_runtime": 1158.0395035743713, "_step": 54}